/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "./node_modules/@deck.gl/core/dist/esm/controllers/controller.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/controllers/controller.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Controller)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _transition_manager__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./transition-manager */ \"./node_modules/@deck.gl/core/dist/esm/controllers/transition-manager.js\");\n/* harmony import */ var _transitions_linear_interpolator__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../transitions/linear-interpolator */ \"./node_modules/@deck.gl/core/dist/esm/transitions/linear-interpolator.js\");\n\n\n\nconst NO_TRANSITION_PROPS = {\n  transitionDuration: 0\n};\nconst DEFAULT_INERTIA = 300;\n\nconst INERTIA_EASING = t => 1 - (1 - t) * (1 - t);\n\nconst EVENT_TYPES = {\n  WHEEL: ['wheel'],\n  PAN: ['panstart', 'panmove', 'panend'],\n  PINCH: ['pinchstart', 'pinchmove', 'pinchend'],\n  TRIPLE_PAN: ['tripanstart', 'tripanmove', 'tripanend'],\n  DOUBLE_TAP: ['doubletap'],\n  KEYBOARD: ['keydown']\n};\nconst pinchEventWorkaround = {};\nclass Controller {\n  constructor(opts) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"props\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"state\", {});\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"transitionManager\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"eventManager\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"onViewStateChange\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"onStateChange\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"makeViewport\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_controllerState\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_events\", {});\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_interactionState\", {\n      isDragging: false\n    });\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_customEvents\", []);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_eventStartBlocked\", null);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_panMove\", false);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"invertPan\", false);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"dragMode\", 'rotate');\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"inertia\", 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"scrollZoom\", true);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"dragPan\", true);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"dragRotate\", true);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"doubleClickZoom\", true);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"touchZoom\", true);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"touchRotate\", false);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"keyboard\", true);\n\n    this.transitionManager = new _transition_manager__WEBPACK_IMPORTED_MODULE_1__[\"default\"]({ ...opts,\n      getControllerState: props => new this.ControllerState(props),\n      onViewStateChange: this._onTransition.bind(this),\n      onStateChange: this._setInteractionState.bind(this)\n    });\n    this.handleEvent = this.handleEvent.bind(this);\n    this.eventManager = opts.eventManager;\n\n    this.onViewStateChange = opts.onViewStateChange || (() => {});\n\n    this.onStateChange = opts.onStateChange || (() => {});\n\n    this.makeViewport = opts.makeViewport;\n  }\n\n  set events(customEvents) {\n    this.toggleEvents(this._customEvents, false);\n    this.toggleEvents(customEvents, true);\n    this._customEvents = customEvents;\n\n    if (this.props) {\n      this.setProps(this.props);\n    }\n  }\n\n  finalize() {\n    for (const eventName in this._events) {\n      if (this._events[eventName]) {\n        var _this$eventManager;\n\n        (_this$eventManager = this.eventManager) === null || _this$eventManager === void 0 ? void 0 : _this$eventManager.off(eventName, this.handleEvent);\n      }\n    }\n\n    this.transitionManager.finalize();\n  }\n\n  handleEvent(event) {\n    this._controllerState = undefined;\n    const eventStartBlocked = this._eventStartBlocked;\n\n    switch (event.type) {\n      case 'panstart':\n        return eventStartBlocked ? false : this._onPanStart(event);\n\n      case 'panmove':\n        return this._onPan(event);\n\n      case 'panend':\n        return this._onPanEnd(event);\n\n      case 'pinchstart':\n        return eventStartBlocked ? false : this._onPinchStart(event);\n\n      case 'pinchmove':\n        return this._onPinch(event);\n\n      case 'pinchend':\n        return this._onPinchEnd(event);\n\n      case 'tripanstart':\n        return eventStartBlocked ? false : this._onTriplePanStart(event);\n\n      case 'tripanmove':\n        return this._onTriplePan(event);\n\n      case 'tripanend':\n        return this._onTriplePanEnd(event);\n\n      case 'doubletap':\n        return this._onDoubleTap(event);\n\n      case 'wheel':\n        return this._onWheel(event);\n\n      case 'keydown':\n        return this._onKeyDown(event);\n\n      default:\n        return false;\n    }\n  }\n\n  get controllerState() {\n    this._controllerState = this._controllerState || new this.ControllerState({\n      makeViewport: this.makeViewport,\n      ...this.props,\n      ...this.state\n    });\n    return this._controllerState;\n  }\n\n  getCenter(event) {\n    const {\n      x,\n      y\n    } = this.props;\n    const {\n      offsetCenter\n    } = event;\n    return [offsetCenter.x - x, offsetCenter.y - y];\n  }\n\n  isPointInBounds(pos, event) {\n    const {\n      width,\n      height\n    } = this.props;\n\n    if (event && event.handled) {\n      return false;\n    }\n\n    const inside = pos[0] >= 0 && pos[0] <= width && pos[1] >= 0 && pos[1] <= height;\n\n    if (inside && event) {\n      event.stopPropagation();\n    }\n\n    return inside;\n  }\n\n  isFunctionKeyPressed(event) {\n    const {\n      srcEvent\n    } = event;\n    return Boolean(srcEvent.metaKey || srcEvent.altKey || srcEvent.ctrlKey || srcEvent.shiftKey);\n  }\n\n  isDragging() {\n    return this._interactionState.isDragging || false;\n  }\n\n  blockEvents(timeout) {\n    const timer = setTimeout(() => {\n      if (this._eventStartBlocked === timer) {\n        this._eventStartBlocked = null;\n      }\n    }, timeout);\n    this._eventStartBlocked = timer;\n  }\n\n  setProps(props) {\n    if (props.dragMode) {\n      this.dragMode = props.dragMode;\n    }\n\n    this.props = props;\n\n    if (!('transitionInterpolator' in props)) {\n      props.transitionInterpolator = this._getTransitionProps().transitionInterpolator;\n    }\n\n    this.transitionManager.processViewStateChange(props);\n    const {\n      inertia\n    } = props;\n    this.inertia = Number.isFinite(inertia) ? inertia : inertia === true ? DEFAULT_INERTIA : 0;\n    const {\n      scrollZoom = true,\n      dragPan = true,\n      dragRotate = true,\n      doubleClickZoom = true,\n      touchZoom = true,\n      touchRotate = false,\n      keyboard = true\n    } = props;\n    const isInteractive = Boolean(this.onViewStateChange);\n    this.toggleEvents(EVENT_TYPES.WHEEL, isInteractive && scrollZoom);\n    this.toggleEvents(EVENT_TYPES.PAN, isInteractive);\n    this.toggleEvents(EVENT_TYPES.PINCH, isInteractive && (touchZoom || touchRotate));\n    this.toggleEvents(EVENT_TYPES.TRIPLE_PAN, isInteractive && touchRotate);\n    this.toggleEvents(EVENT_TYPES.DOUBLE_TAP, isInteractive && doubleClickZoom);\n    this.toggleEvents(EVENT_TYPES.KEYBOARD, isInteractive && keyboard);\n    this.scrollZoom = scrollZoom;\n    this.dragPan = dragPan;\n    this.dragRotate = dragRotate;\n    this.doubleClickZoom = doubleClickZoom;\n    this.touchZoom = touchZoom;\n    this.touchRotate = touchRotate;\n    this.keyboard = keyboard;\n  }\n\n  updateTransition() {\n    this.transitionManager.updateTransition();\n  }\n\n  toggleEvents(eventNames, enabled) {\n    if (this.eventManager) {\n      eventNames.forEach(eventName => {\n        if (this._events[eventName] !== enabled) {\n          this._events[eventName] = enabled;\n\n          if (enabled) {\n            this.eventManager.on(eventName, this.handleEvent);\n          } else {\n            this.eventManager.off(eventName, this.handleEvent);\n          }\n        }\n      });\n    }\n  }\n\n  updateViewport(newControllerState, extraProps = null, interactionState = {}) {\n    const viewState = { ...newControllerState.getViewportProps(),\n      ...extraProps\n    };\n    const changed = this.controllerState !== newControllerState;\n    this.state = newControllerState.getState();\n\n    this._setInteractionState(interactionState);\n\n    if (changed) {\n      const oldViewState = this.controllerState && this.controllerState.getViewportProps();\n\n      if (this.onViewStateChange) {\n        this.onViewStateChange({\n          viewState,\n          interactionState: this._interactionState,\n          oldViewState\n        });\n      }\n    }\n  }\n\n  _onTransition(params) {\n    this.onViewStateChange({ ...params,\n      interactionState: this._interactionState\n    });\n  }\n\n  _setInteractionState(newStates) {\n    Object.assign(this._interactionState, newStates);\n    this.onStateChange(this._interactionState);\n  }\n\n  _onPanStart(event) {\n    const pos = this.getCenter(event);\n\n    if (!this.isPointInBounds(pos, event)) {\n      return false;\n    }\n\n    let alternateMode = this.isFunctionKeyPressed(event) || event.rightButton || false;\n\n    if (this.invertPan || this.dragMode === 'pan') {\n      alternateMode = !alternateMode;\n    }\n\n    const newControllerState = this.controllerState[alternateMode ? 'panStart' : 'rotateStart']({\n      pos\n    });\n    this._panMove = alternateMode;\n    this.updateViewport(newControllerState, NO_TRANSITION_PROPS, {\n      isDragging: true\n    });\n    return true;\n  }\n\n  _onPan(event) {\n    if (!this.isDragging()) {\n      return false;\n    }\n\n    return this._panMove ? this._onPanMove(event) : this._onPanRotate(event);\n  }\n\n  _onPanEnd(event) {\n    if (!this.isDragging()) {\n      return false;\n    }\n\n    return this._panMove ? this._onPanMoveEnd(event) : this._onPanRotateEnd(event);\n  }\n\n  _onPanMove(event) {\n    if (!this.dragPan) {\n      return false;\n    }\n\n    const pos = this.getCenter(event);\n    const newControllerState = this.controllerState.pan({\n      pos\n    });\n    this.updateViewport(newControllerState, NO_TRANSITION_PROPS, {\n      isDragging: true,\n      isPanning: true\n    });\n    return true;\n  }\n\n  _onPanMoveEnd(event) {\n    const {\n      inertia\n    } = this;\n\n    if (this.dragPan && inertia && event.velocity) {\n      const pos = this.getCenter(event);\n      const endPos = [pos[0] + event.velocityX * inertia / 2, pos[1] + event.velocityY * inertia / 2];\n      const newControllerState = this.controllerState.pan({\n        pos: endPos\n      }).panEnd();\n      this.updateViewport(newControllerState, { ...this._getTransitionProps(),\n        transitionDuration: inertia,\n        transitionEasing: INERTIA_EASING\n      }, {\n        isDragging: false,\n        isPanning: true\n      });\n    } else {\n      const newControllerState = this.controllerState.panEnd();\n      this.updateViewport(newControllerState, null, {\n        isDragging: false,\n        isPanning: false\n      });\n    }\n\n    return true;\n  }\n\n  _onPanRotate(event) {\n    if (!this.dragRotate) {\n      return false;\n    }\n\n    const pos = this.getCenter(event);\n    const newControllerState = this.controllerState.rotate({\n      pos\n    });\n    this.updateViewport(newControllerState, NO_TRANSITION_PROPS, {\n      isDragging: true,\n      isRotating: true\n    });\n    return true;\n  }\n\n  _onPanRotateEnd(event) {\n    const {\n      inertia\n    } = this;\n\n    if (this.dragRotate && inertia && event.velocity) {\n      const pos = this.getCenter(event);\n      const endPos = [pos[0] + event.velocityX * inertia / 2, pos[1] + event.velocityY * inertia / 2];\n      const newControllerState = this.controllerState.rotate({\n        pos: endPos\n      }).rotateEnd();\n      this.updateViewport(newControllerState, { ...this._getTransitionProps(),\n        transitionDuration: inertia,\n        transitionEasing: INERTIA_EASING\n      }, {\n        isDragging: false,\n        isRotating: true\n      });\n    } else {\n      const newControllerState = this.controllerState.rotateEnd();\n      this.updateViewport(newControllerState, null, {\n        isDragging: false,\n        isRotating: false\n      });\n    }\n\n    return true;\n  }\n\n  _onWheel(event) {\n    if (!this.scrollZoom) {\n      return false;\n    }\n\n    const pos = this.getCenter(event);\n\n    if (!this.isPointInBounds(pos, event)) {\n      return false;\n    }\n\n    event.srcEvent.preventDefault();\n    const {\n      speed = 0.01,\n      smooth = false\n    } = this.scrollZoom === true ? {} : this.scrollZoom;\n    const {\n      delta\n    } = event;\n    let scale = 2 / (1 + Math.exp(-Math.abs(delta * speed)));\n\n    if (delta < 0 && scale !== 0) {\n      scale = 1 / scale;\n    }\n\n    const newControllerState = this.controllerState.zoom({\n      pos,\n      scale\n    });\n    this.updateViewport(newControllerState, { ...this._getTransitionProps({\n        around: pos\n      }),\n      transitionDuration: smooth ? 250 : 1\n    }, {\n      isZooming: true,\n      isPanning: true\n    });\n    return true;\n  }\n\n  _onTriplePanStart(event) {\n    const pos = this.getCenter(event);\n\n    if (!this.isPointInBounds(pos, event)) {\n      return false;\n    }\n\n    const newControllerState = this.controllerState.rotateStart({\n      pos\n    });\n    this.updateViewport(newControllerState, NO_TRANSITION_PROPS, {\n      isDragging: true\n    });\n    return true;\n  }\n\n  _onTriplePan(event) {\n    if (!this.touchRotate) {\n      return false;\n    }\n\n    if (!this.isDragging()) {\n      return false;\n    }\n\n    const pos = this.getCenter(event);\n    pos[0] -= event.deltaX;\n    const newControllerState = this.controllerState.rotate({\n      pos\n    });\n    this.updateViewport(newControllerState, NO_TRANSITION_PROPS, {\n      isDragging: true,\n      isRotating: true\n    });\n    return true;\n  }\n\n  _onTriplePanEnd(event) {\n    if (!this.isDragging()) {\n      return false;\n    }\n\n    const {\n      inertia\n    } = this;\n\n    if (this.touchRotate && inertia && event.velocityY) {\n      const pos = this.getCenter(event);\n      const endPos = [pos[0], pos[1] += event.velocityY * inertia / 2];\n      const newControllerState = this.controllerState.rotate({\n        pos: endPos\n      });\n      this.updateViewport(newControllerState, { ...this._getTransitionProps(),\n        transitionDuration: inertia,\n        transitionEasing: INERTIA_EASING\n      }, {\n        isDragging: false,\n        isRotating: true\n      });\n      this.blockEvents(inertia);\n    } else {\n      const newControllerState = this.controllerState.rotateEnd();\n      this.updateViewport(newControllerState, null, {\n        isDragging: false,\n        isRotating: false\n      });\n    }\n\n    return true;\n  }\n\n  _onPinchStart(event) {\n    const pos = this.getCenter(event);\n\n    if (!this.isPointInBounds(pos, event)) {\n      return false;\n    }\n\n    const newControllerState = this.controllerState.zoomStart({\n      pos\n    }).rotateStart({\n      pos\n    });\n    pinchEventWorkaround._startPinchRotation = event.rotation;\n    pinchEventWorkaround._lastPinchEvent = event;\n    this.updateViewport(newControllerState, NO_TRANSITION_PROPS, {\n      isDragging: true\n    });\n    return true;\n  }\n\n  _onPinch(event) {\n    if (!this.touchZoom && !this.touchRotate) {\n      return false;\n    }\n\n    if (!this.isDragging()) {\n      return false;\n    }\n\n    let newControllerState = this.controllerState;\n\n    if (this.touchZoom) {\n      const {\n        scale\n      } = event;\n      const pos = this.getCenter(event);\n      newControllerState = newControllerState.zoom({\n        pos,\n        scale\n      });\n    }\n\n    if (this.touchRotate) {\n      const {\n        rotation\n      } = event;\n      newControllerState = newControllerState.rotate({\n        deltaAngleX: pinchEventWorkaround._startPinchRotation - rotation\n      });\n    }\n\n    this.updateViewport(newControllerState, NO_TRANSITION_PROPS, {\n      isDragging: true,\n      isPanning: this.touchZoom,\n      isZooming: this.touchZoom,\n      isRotating: this.touchRotate\n    });\n    pinchEventWorkaround._lastPinchEvent = event;\n    return true;\n  }\n\n  _onPinchEnd(event) {\n    if (!this.isDragging()) {\n      return false;\n    }\n\n    const {\n      inertia\n    } = this;\n    const {\n      _lastPinchEvent\n    } = pinchEventWorkaround;\n\n    if (this.touchZoom && inertia && _lastPinchEvent && event.scale !== _lastPinchEvent.scale) {\n      const pos = this.getCenter(event);\n      let newControllerState = this.controllerState.rotateEnd();\n      const z = Math.log2(event.scale);\n\n      const velocityZ = (z - Math.log2(_lastPinchEvent.scale)) / (event.deltaTime - _lastPinchEvent.deltaTime);\n\n      const endScale = Math.pow(2, z + velocityZ * inertia / 2);\n      newControllerState = newControllerState.zoom({\n        pos,\n        scale: endScale\n      }).zoomEnd();\n      this.updateViewport(newControllerState, { ...this._getTransitionProps({\n          around: pos\n        }),\n        transitionDuration: inertia,\n        transitionEasing: INERTIA_EASING\n      }, {\n        isDragging: false,\n        isPanning: this.touchZoom,\n        isZooming: this.touchZoom,\n        isRotating: false\n      });\n      this.blockEvents(inertia);\n    } else {\n      const newControllerState = this.controllerState.zoomEnd().rotateEnd();\n      this.updateViewport(newControllerState, null, {\n        isDragging: false,\n        isPanning: false,\n        isZooming: false,\n        isRotating: false\n      });\n    }\n\n    pinchEventWorkaround._startPinchRotation = null;\n    pinchEventWorkaround._lastPinchEvent = null;\n    return true;\n  }\n\n  _onDoubleTap(event) {\n    if (!this.doubleClickZoom) {\n      return false;\n    }\n\n    const pos = this.getCenter(event);\n\n    if (!this.isPointInBounds(pos, event)) {\n      return false;\n    }\n\n    const isZoomOut = this.isFunctionKeyPressed(event);\n    const newControllerState = this.controllerState.zoom({\n      pos,\n      scale: isZoomOut ? 0.5 : 2\n    });\n    this.updateViewport(newControllerState, this._getTransitionProps({\n      around: pos\n    }), {\n      isZooming: true,\n      isPanning: true\n    });\n    this.blockEvents(100);\n    return true;\n  }\n\n  _onKeyDown(event) {\n    if (!this.keyboard) {\n      return false;\n    }\n\n    const funcKey = this.isFunctionKeyPressed(event);\n    const {\n      zoomSpeed,\n      moveSpeed,\n      rotateSpeedX,\n      rotateSpeedY\n    } = this.keyboard === true ? {} : this.keyboard;\n    const {\n      controllerState\n    } = this;\n    let newControllerState;\n    const interactionState = {};\n\n    switch (event.srcEvent.code) {\n      case 'Minus':\n        newControllerState = funcKey ? controllerState.zoomOut(zoomSpeed).zoomOut(zoomSpeed) : controllerState.zoomOut(zoomSpeed);\n        interactionState.isZooming = true;\n        break;\n\n      case 'Equal':\n        newControllerState = funcKey ? controllerState.zoomIn(zoomSpeed).zoomIn(zoomSpeed) : controllerState.zoomIn(zoomSpeed);\n        interactionState.isZooming = true;\n        break;\n\n      case 'ArrowLeft':\n        if (funcKey) {\n          newControllerState = controllerState.rotateLeft(rotateSpeedX);\n          interactionState.isRotating = true;\n        } else {\n          newControllerState = controllerState.moveLeft(moveSpeed);\n          interactionState.isPanning = true;\n        }\n\n        break;\n\n      case 'ArrowRight':\n        if (funcKey) {\n          newControllerState = controllerState.rotateRight(rotateSpeedX);\n          interactionState.isRotating = true;\n        } else {\n          newControllerState = controllerState.moveRight(moveSpeed);\n          interactionState.isPanning = true;\n        }\n\n        break;\n\n      case 'ArrowUp':\n        if (funcKey) {\n          newControllerState = controllerState.rotateUp(rotateSpeedY);\n          interactionState.isRotating = true;\n        } else {\n          newControllerState = controllerState.moveUp(moveSpeed);\n          interactionState.isPanning = true;\n        }\n\n        break;\n\n      case 'ArrowDown':\n        if (funcKey) {\n          newControllerState = controllerState.rotateDown(rotateSpeedY);\n          interactionState.isRotating = true;\n        } else {\n          newControllerState = controllerState.moveDown(moveSpeed);\n          interactionState.isPanning = true;\n        }\n\n        break;\n\n      default:\n        return false;\n    }\n\n    this.updateViewport(newControllerState, this._getTransitionProps(), interactionState);\n    return true;\n  }\n\n  _getTransitionProps(opts) {\n    const {\n      transition\n    } = this;\n\n    if (!transition || !transition.transitionInterpolator) {\n      return NO_TRANSITION_PROPS;\n    }\n\n    return opts ? { ...transition,\n      transitionInterpolator: new _transitions_linear_interpolator__WEBPACK_IMPORTED_MODULE_2__[\"default\"]({ ...opts,\n        ...transition.transitionInterpolator.opts,\n        makeViewport: this.controllerState.makeViewport\n      })\n    } : transition;\n  }\n\n}\n//# sourceMappingURL=controller.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/controllers/controller.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/controllers/map-controller.js":
/*!***************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/controllers/map-controller.js ***!
  \***************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   MapState: () => (/* binding */ MapState),\n/* harmony export */   \"default\": () => (/* binding */ MapController)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _math_gl_core__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! @math.gl/core */ \"./node_modules/@math.gl/core/dist/esm/lib/common.js\");\n/* harmony import */ var _controller__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./controller */ \"./node_modules/@deck.gl/core/dist/esm/controllers/controller.js\");\n/* harmony import */ var _view_state__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./view-state */ \"./node_modules/@deck.gl/core/dist/esm/controllers/view-state.js\");\n/* harmony import */ var _math_gl_web_mercator__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @math.gl/web-mercator */ \"./node_modules/@math.gl/web-mercator/dist/esm/index.js\");\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/assert */ \"./node_modules/@deck.gl/core/dist/esm/utils/assert.js\");\n/* harmony import */ var _transitions_linear_interpolator__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../transitions/linear-interpolator */ \"./node_modules/@deck.gl/core/dist/esm/transitions/linear-interpolator.js\");\n\n\n\n\n\n\n\nconst PITCH_MOUSE_THRESHOLD = 5;\nconst PITCH_ACCEL = 1.2;\nclass MapState extends _view_state__WEBPACK_IMPORTED_MODULE_2__[\"default\"] {\n  constructor(options) {\n    const {\n      width,\n      height,\n      latitude,\n      longitude,\n      zoom,\n      bearing = 0,\n      pitch = 0,\n      altitude = 1.5,\n      position = [0, 0, 0],\n      maxZoom = 20,\n      minZoom = 0,\n      maxPitch = 60,\n      minPitch = 0,\n      startPanLngLat,\n      startZoomLngLat,\n      startRotatePos,\n      startBearing,\n      startPitch,\n      startZoom,\n      normalize = true\n    } = options;\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_3__[\"default\"])(Number.isFinite(longitude));\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_3__[\"default\"])(Number.isFinite(latitude));\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_3__[\"default\"])(Number.isFinite(zoom));\n    super({\n      width,\n      height,\n      latitude,\n      longitude,\n      zoom,\n      bearing,\n      pitch,\n      altitude,\n      maxZoom,\n      minZoom,\n      maxPitch,\n      minPitch,\n      normalize,\n      position\n    }, {\n      startPanLngLat,\n      startZoomLngLat,\n      startRotatePos,\n      startBearing,\n      startPitch,\n      startZoom\n    });\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"makeViewport\", void 0);\n\n    this.makeViewport = options.makeViewport;\n  }\n\n  panStart({\n    pos\n  }) {\n    return this._getUpdatedState({\n      startPanLngLat: this._unproject(pos)\n    });\n  }\n\n  pan({\n    pos,\n    startPos\n  }) {\n    const startPanLngLat = this.getState().startPanLngLat || this._unproject(startPos);\n\n    if (!startPanLngLat) {\n      return this;\n    }\n\n    const viewport = this.makeViewport(this.getViewportProps());\n    const newProps = viewport.panByPosition(startPanLngLat, pos);\n    return this._getUpdatedState(newProps);\n  }\n\n  panEnd() {\n    return this._getUpdatedState({\n      startPanLngLat: null\n    });\n  }\n\n  rotateStart({\n    pos\n  }) {\n    return this._getUpdatedState({\n      startRotatePos: pos,\n      startBearing: this.getViewportProps().bearing,\n      startPitch: this.getViewportProps().pitch\n    });\n  }\n\n  rotate({\n    pos,\n    deltaAngleX = 0,\n    deltaAngleY = 0\n  }) {\n    const {\n      startRotatePos,\n      startBearing,\n      startPitch\n    } = this.getState();\n\n    if (!startRotatePos || startBearing === undefined || startPitch === undefined) {\n      return this;\n    }\n\n    let newRotation;\n\n    if (pos) {\n      newRotation = this._getNewRotation(pos, startRotatePos, startPitch, startBearing);\n    } else {\n      newRotation = {\n        bearing: startBearing + deltaAngleX,\n        pitch: startPitch + deltaAngleY\n      };\n    }\n\n    return this._getUpdatedState(newRotation);\n  }\n\n  rotateEnd() {\n    return this._getUpdatedState({\n      startBearing: null,\n      startPitch: null\n    });\n  }\n\n  zoomStart({\n    pos\n  }) {\n    return this._getUpdatedState({\n      startZoomLngLat: this._unproject(pos),\n      startZoom: this.getViewportProps().zoom\n    });\n  }\n\n  zoom({\n    pos,\n    startPos,\n    scale\n  }) {\n    let {\n      startZoom,\n      startZoomLngLat\n    } = this.getState();\n\n    if (!startZoomLngLat) {\n      startZoom = this.getViewportProps().zoom;\n      startZoomLngLat = this._unproject(startPos) || this._unproject(pos);\n    }\n\n    if (!startZoomLngLat) {\n      return this;\n    }\n\n    const {\n      maxZoom,\n      minZoom\n    } = this.getViewportProps();\n    let zoom = startZoom + Math.log2(scale);\n    zoom = (0,_math_gl_core__WEBPACK_IMPORTED_MODULE_4__.clamp)(zoom, minZoom, maxZoom);\n    const zoomedViewport = this.makeViewport({ ...this.getViewportProps(),\n      zoom\n    });\n    return this._getUpdatedState({\n      zoom,\n      ...zoomedViewport.panByPosition(startZoomLngLat, pos)\n    });\n  }\n\n  zoomEnd() {\n    return this._getUpdatedState({\n      startZoomLngLat: null,\n      startZoom: null\n    });\n  }\n\n  zoomIn(speed = 2) {\n    return this._zoomFromCenter(speed);\n  }\n\n  zoomOut(speed = 2) {\n    return this._zoomFromCenter(1 / speed);\n  }\n\n  moveLeft(speed = 100) {\n    return this._panFromCenter([speed, 0]);\n  }\n\n  moveRight(speed = 100) {\n    return this._panFromCenter([-speed, 0]);\n  }\n\n  moveUp(speed = 100) {\n    return this._panFromCenter([0, speed]);\n  }\n\n  moveDown(speed = 100) {\n    return this._panFromCenter([0, -speed]);\n  }\n\n  rotateLeft(speed = 15) {\n    return this._getUpdatedState({\n      bearing: this.getViewportProps().bearing - speed\n    });\n  }\n\n  rotateRight(speed = 15) {\n    return this._getUpdatedState({\n      bearing: this.getViewportProps().bearing + speed\n    });\n  }\n\n  rotateUp(speed = 10) {\n    return this._getUpdatedState({\n      pitch: this.getViewportProps().pitch + speed\n    });\n  }\n\n  rotateDown(speed = 10) {\n    return this._getUpdatedState({\n      pitch: this.getViewportProps().pitch - speed\n    });\n  }\n\n  shortestPathFrom(viewState) {\n    const fromProps = viewState.getViewportProps();\n    const props = { ...this.getViewportProps()\n    };\n    const {\n      bearing,\n      longitude\n    } = props;\n\n    if (Math.abs(bearing - fromProps.bearing) > 180) {\n      props.bearing = bearing < 0 ? bearing + 360 : bearing - 360;\n    }\n\n    if (Math.abs(longitude - fromProps.longitude) > 180) {\n      props.longitude = longitude < 0 ? longitude + 360 : longitude - 360;\n    }\n\n    return props;\n  }\n\n  applyConstraints(props) {\n    const {\n      maxZoom,\n      minZoom,\n      zoom\n    } = props;\n    props.zoom = (0,_math_gl_core__WEBPACK_IMPORTED_MODULE_4__.clamp)(zoom, minZoom, maxZoom);\n    const {\n      maxPitch,\n      minPitch,\n      pitch\n    } = props;\n    props.pitch = (0,_math_gl_core__WEBPACK_IMPORTED_MODULE_4__.clamp)(pitch, minPitch, maxPitch);\n    const {\n      normalize = true\n    } = props;\n\n    if (normalize) {\n      Object.assign(props, (0,_math_gl_web_mercator__WEBPACK_IMPORTED_MODULE_1__.normalizeViewportProps)(props));\n    }\n\n    return props;\n  }\n\n  _zoomFromCenter(scale) {\n    const {\n      width,\n      height\n    } = this.getViewportProps();\n    return this.zoom({\n      pos: [width / 2, height / 2],\n      scale\n    });\n  }\n\n  _panFromCenter(offset) {\n    const {\n      width,\n      height\n    } = this.getViewportProps();\n    return this.pan({\n      startPos: [width / 2, height / 2],\n      pos: [width / 2 + offset[0], height / 2 + offset[1]]\n    });\n  }\n\n  _getUpdatedState(newProps) {\n    return new this.constructor({\n      makeViewport: this.makeViewport,\n      ...this.getViewportProps(),\n      ...this.getState(),\n      ...newProps\n    });\n  }\n\n  _unproject(pos) {\n    const viewport = this.makeViewport(this.getViewportProps());\n    return pos && viewport.unproject(pos);\n  }\n\n  _getNewRotation(pos, startPos, startPitch, startBearing) {\n    const deltaX = pos[0] - startPos[0];\n    const deltaY = pos[1] - startPos[1];\n    const centerY = pos[1];\n    const startY = startPos[1];\n    const {\n      width,\n      height\n    } = this.getViewportProps();\n    const deltaScaleX = deltaX / width;\n    let deltaScaleY = 0;\n\n    if (deltaY > 0) {\n      if (Math.abs(height - startY) > PITCH_MOUSE_THRESHOLD) {\n        deltaScaleY = deltaY / (startY - height) * PITCH_ACCEL;\n      }\n    } else if (deltaY < 0) {\n      if (startY > PITCH_MOUSE_THRESHOLD) {\n        deltaScaleY = 1 - centerY / startY;\n      }\n    }\n\n    deltaScaleY = (0,_math_gl_core__WEBPACK_IMPORTED_MODULE_4__.clamp)(deltaScaleY, -1, 1);\n    const {\n      minPitch,\n      maxPitch\n    } = this.getViewportProps();\n    const bearing = startBearing + 180 * deltaScaleX;\n    let pitch = startPitch;\n\n    if (deltaScaleY > 0) {\n      pitch = startPitch + deltaScaleY * (maxPitch - startPitch);\n    } else if (deltaScaleY < 0) {\n      pitch = startPitch - deltaScaleY * (minPitch - startPitch);\n    }\n\n    return {\n      pitch,\n      bearing\n    };\n  }\n\n}\nclass MapController extends _controller__WEBPACK_IMPORTED_MODULE_5__[\"default\"] {\n  constructor(...args) {\n    super(...args);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"ControllerState\", MapState);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"transition\", {\n      transitionDuration: 300,\n      transitionInterpolator: new _transitions_linear_interpolator__WEBPACK_IMPORTED_MODULE_6__[\"default\"]({\n        transitionProps: {\n          compare: ['longitude', 'latitude', 'zoom', 'bearing', 'pitch', 'position'],\n          required: ['longitude', 'latitude', 'zoom']\n        }\n      })\n    });\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"dragMode\", 'pan');\n  }\n\n  setProps(props) {\n    props.position = props.position || [0, 0, 0];\n    const oldProps = this.props;\n    super.setProps(props);\n    const dimensionChanged = !oldProps || oldProps.height !== props.height;\n\n    if (dimensionChanged) {\n      this.updateViewport(new this.ControllerState({\n        makeViewport: this.makeViewport,\n        ...props,\n        ...this.state\n      }));\n    }\n  }\n\n}\n//# sourceMappingURL=map-controller.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/controllers/map-controller.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/controllers/transition-manager.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/controllers/transition-manager.js ***!
  \*******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   TRANSITION_EVENTS: () => (/* binding */ TRANSITION_EVENTS),\n/* harmony export */   \"default\": () => (/* binding */ TransitionManager)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _transitions_transition__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../transitions/transition */ \"./node_modules/@deck.gl/core/dist/esm/transitions/transition.js\");\n\n\n\nconst noop = () => {};\n\nconst TRANSITION_EVENTS = {\n  BREAK: 1,\n  SNAP_TO_END: 2,\n  IGNORE: 3\n};\n\nconst DEFAULT_EASING = t => t;\n\nconst DEFAULT_INTERRUPTION = TRANSITION_EVENTS.BREAK;\nclass TransitionManager {\n  constructor(opts) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"getControllerState\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"props\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"propsInTransition\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"transition\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"onViewStateChange\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"onStateChange\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_onTransitionUpdate\", transition => {\n      const {\n        time,\n        settings: {\n          interpolator,\n          startProps,\n          endProps,\n          duration,\n          easing\n        }\n      } = transition;\n      const t = easing(time / duration);\n      const viewport = interpolator.interpolateProps(startProps, endProps, t);\n      this.propsInTransition = this.getControllerState({ ...this.props,\n        ...viewport\n      }).getViewportProps();\n      this.onViewStateChange({\n        viewState: this.propsInTransition,\n        oldViewState: this.props\n      });\n    });\n\n    this.getControllerState = opts.getControllerState;\n    this.propsInTransition = null;\n    this.transition = new _transitions_transition__WEBPACK_IMPORTED_MODULE_1__[\"default\"](opts.timeline);\n    this.onViewStateChange = opts.onViewStateChange || noop;\n    this.onStateChange = opts.onStateChange || noop;\n  }\n\n  finalize() {\n    this.transition.cancel();\n  }\n\n  getViewportInTransition() {\n    return this.propsInTransition;\n  }\n\n  processViewStateChange(nextProps) {\n    let transitionTriggered = false;\n    const currentProps = this.props;\n    this.props = nextProps;\n\n    if (!currentProps || this._shouldIgnoreViewportChange(currentProps, nextProps)) {\n      return false;\n    }\n\n    if (this._isTransitionEnabled(nextProps)) {\n      let startProps = currentProps;\n\n      if (this.transition.inProgress) {\n        const {\n          interruption,\n          endProps\n        } = this.transition.settings;\n        startProps = { ...currentProps,\n          ...(interruption === TRANSITION_EVENTS.SNAP_TO_END ? endProps : this.propsInTransition || currentProps)\n        };\n      }\n\n      this._triggerTransition(startProps, nextProps);\n\n      transitionTriggered = true;\n    } else {\n      this.transition.cancel();\n    }\n\n    return transitionTriggered;\n  }\n\n  updateTransition() {\n    this.transition.update();\n  }\n\n  _isTransitionEnabled(props) {\n    const {\n      transitionDuration,\n      transitionInterpolator\n    } = props;\n    return (transitionDuration > 0 || transitionDuration === 'auto') && Boolean(transitionInterpolator);\n  }\n\n  _isUpdateDueToCurrentTransition(props) {\n    if (this.transition.inProgress && this.propsInTransition) {\n      return this.transition.settings.interpolator.arePropsEqual(props, this.propsInTransition);\n    }\n\n    return false;\n  }\n\n  _shouldIgnoreViewportChange(currentProps, nextProps) {\n    if (this.transition.inProgress) {\n      return this.transition.settings.interruption === TRANSITION_EVENTS.IGNORE || this._isUpdateDueToCurrentTransition(nextProps);\n    }\n\n    if (this._isTransitionEnabled(nextProps)) {\n      return nextProps.transitionInterpolator.arePropsEqual(currentProps, nextProps);\n    }\n\n    return true;\n  }\n\n  _triggerTransition(startProps, endProps) {\n    const startViewstate = this.getControllerState(startProps);\n    const endViewStateProps = this.getControllerState(endProps).shortestPathFrom(startViewstate);\n    const transitionInterpolator = endProps.transitionInterpolator;\n    const duration = transitionInterpolator.getDuration ? transitionInterpolator.getDuration(startProps, endProps) : endProps.transitionDuration;\n\n    if (duration === 0) {\n      return;\n    }\n\n    const initialProps = transitionInterpolator.initializeProps(startProps, endViewStateProps);\n    this.propsInTransition = {};\n    const transitionSettings = {\n      duration,\n      easing: endProps.transitionEasing || DEFAULT_EASING,\n      interpolator: transitionInterpolator,\n      interruption: endProps.transitionInterruption || DEFAULT_INTERRUPTION,\n      startProps: initialProps.start,\n      endProps: initialProps.end,\n      onStart: endProps.onTransitionStart,\n      onUpdate: this._onTransitionUpdate,\n      onInterrupt: this._onTransitionEnd(endProps.onTransitionInterrupt),\n      onEnd: this._onTransitionEnd(endProps.onTransitionEnd)\n    };\n    this.transition.start(transitionSettings);\n    this.onStateChange({\n      inTransition: true\n    });\n    this.updateTransition();\n  }\n\n  _onTransitionEnd(callback) {\n    return transition => {\n      this.propsInTransition = null;\n      this.onStateChange({\n        inTransition: false,\n        isZooming: false,\n        isPanning: false,\n        isRotating: false\n      });\n      callback === null || callback === void 0 ? void 0 : callback(transition);\n    };\n  }\n\n}\n//# sourceMappingURL=transition-manager.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/controllers/transition-manager.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/controllers/view-state.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/controllers/view-state.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ ViewState)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n\nclass ViewState {\n  constructor(props, state) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_viewportProps\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_state\", void 0);\n\n    this._viewportProps = this.applyConstraints(props);\n    this._state = state;\n  }\n\n  getViewportProps() {\n    return this._viewportProps;\n  }\n\n  getState() {\n    return this._state;\n  }\n\n}\n//# sourceMappingURL=view-state.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/controllers/view-state.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/debug/index.js":
/*!************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/debug/index.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ debug),\n/* harmony export */   register: () => (/* binding */ register)\n/* harmony export */ });\n/* harmony import */ var _utils_log__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/log */ \"./node_modules/@deck.gl/core/dist/esm/utils/log.js\");\n/* harmony import */ var _loggers__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./loggers */ \"./node_modules/@deck.gl/core/dist/esm/debug/loggers.js\");\n\n\nlet loggers = {};\n\nif (true) {\n  loggers = (0,_loggers__WEBPACK_IMPORTED_MODULE_0__.getLoggers)(_utils_log__WEBPACK_IMPORTED_MODULE_1__[\"default\"]);\n}\n\nfunction register(handlers) {\n  loggers = handlers;\n}\nfunction debug(eventType, arg1, arg2, arg3) {\n  if (_utils_log__WEBPACK_IMPORTED_MODULE_1__[\"default\"].level > 0 && loggers[eventType]) {\n    loggers[eventType].call(null, arg1, arg2, arg3);\n  }\n}\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/debug/index.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/debug/loggers.js":
/*!**************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/debug/loggers.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getLoggers: () => (/* binding */ getLoggers)\n/* harmony export */ });\nconst logState = {\n  attributeUpdateStart: -1,\n  attributeManagerUpdateStart: -1,\n  attributeUpdateMessages: []\n};\nconst LOG_LEVEL_MAJOR_UPDATE = 1;\nconst LOG_LEVEL_MINOR_UPDATE = 2;\nconst LOG_LEVEL_UPDATE_DETAIL = 3;\nconst LOG_LEVEL_INFO = 4;\nconst LOG_LEVEL_DRAW = 2;\nconst getLoggers = log => ({\n  'layer.changeFlag': (layer, key, flags) => {\n    log.log(LOG_LEVEL_UPDATE_DETAIL, \"\".concat(layer.id, \" \").concat(key, \": \"), flags[key])();\n  },\n  'layer.initialize': layer => {\n    log.log(LOG_LEVEL_MAJOR_UPDATE, \"Initializing \".concat(layer))();\n  },\n  'layer.update': (layer, needsUpdate) => {\n    if (needsUpdate) {\n      const flags = layer.getChangeFlags();\n      log.log(LOG_LEVEL_MINOR_UPDATE, \"Updating \".concat(layer, \" because: \").concat(Object.keys(flags).filter(key => flags[key]).join(', ')))();\n    } else {\n      log.log(LOG_LEVEL_INFO, \"\".concat(layer, \" does not need update\"))();\n    }\n  },\n  'layer.matched': (layer, changed) => {\n    if (changed) {\n      log.log(LOG_LEVEL_INFO, \"Matched \".concat(layer, \", state transfered\"))();\n    }\n  },\n  'layer.finalize': layer => {\n    log.log(LOG_LEVEL_MAJOR_UPDATE, \"Finalizing \".concat(layer))();\n  },\n  'compositeLayer.renderLayers': (layer, updated, subLayers) => {\n    if (updated) {\n      log.log(LOG_LEVEL_MINOR_UPDATE, \"Composite layer rendered new subLayers \".concat(layer), subLayers)();\n    } else {\n      log.log(LOG_LEVEL_INFO, \"Composite layer reused subLayers \".concat(layer), subLayers)();\n    }\n  },\n  'layerManager.setLayers': (layerManager, updated, layers) => {\n    if (updated) {\n      log.log(LOG_LEVEL_MINOR_UPDATE, \"Updating \".concat(layers.length, \" deck layers\"))();\n    }\n  },\n  'layerManager.activateViewport': (layerManager, viewport) => {\n    log.log(LOG_LEVEL_UPDATE_DETAIL, 'Viewport changed', viewport)();\n  },\n  'attributeManager.invalidate': (attributeManager, trigger, attributeNames) => {\n    log.log(LOG_LEVEL_MAJOR_UPDATE, attributeNames ? \"invalidated attributes \".concat(attributeNames, \" (\").concat(trigger, \") for \").concat(attributeManager.id) : \"invalidated all attributes for \".concat(attributeManager.id))();\n  },\n  'attributeManager.updateStart': attributeManager => {\n    logState.attributeUpdateMessages.length = 0;\n    logState.attributeManagerUpdateStart = Date.now();\n  },\n  'attributeManager.updateEnd': (attributeManager, numInstances) => {\n    const timeMs = Math.round(Date.now() - logState.attributeManagerUpdateStart);\n    log.groupCollapsed(LOG_LEVEL_MINOR_UPDATE, \"Updated attributes for \".concat(numInstances, \" instances in \").concat(attributeManager.id, \" in \").concat(timeMs, \"ms\"))();\n\n    for (const updateMessage of logState.attributeUpdateMessages) {\n      log.log(LOG_LEVEL_UPDATE_DETAIL, updateMessage)();\n    }\n\n    log.groupEnd(LOG_LEVEL_MINOR_UPDATE)();\n  },\n  'attribute.updateStart': attribute => {\n    logState.attributeUpdateStart = Date.now();\n  },\n  'attribute.allocate': (attribute, numInstances) => {\n    const message = \"\".concat(attribute.id, \" allocated \").concat(numInstances);\n    logState.attributeUpdateMessages.push(message);\n  },\n  'attribute.updateEnd': (attribute, numInstances) => {\n    const timeMs = Math.round(Date.now() - logState.attributeUpdateStart);\n    const message = \"\".concat(attribute.id, \" updated \").concat(numInstances, \" in \").concat(timeMs, \"ms\");\n    logState.attributeUpdateMessages.push(message);\n  },\n  'deckRenderer.renderLayers': (deckRenderer, renderStats, opts) => {\n    const {\n      pass,\n      redrawReason,\n      stats\n    } = opts;\n\n    for (const status of renderStats) {\n      const {\n        totalCount,\n        visibleCount,\n        compositeCount,\n        pickableCount\n      } = status;\n      const primitiveCount = totalCount - compositeCount;\n      const hiddenCount = primitiveCount - visibleCount;\n      log.log(LOG_LEVEL_DRAW, \"RENDER #\".concat(deckRenderer.renderCount, \"   \").concat(visibleCount, \" (of \").concat(totalCount, \" layers) to \").concat(pass, \" because \").concat(redrawReason, \"   (\").concat(hiddenCount, \" hidden, \").concat(compositeCount, \" composite \").concat(pickableCount, \" pickable)\"))();\n\n      if (stats) {\n        stats.get('Redraw Layers').add(visibleCount);\n      }\n    }\n  }\n});\n//# sourceMappingURL=loggers.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/debug/loggers.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/effects/lighting/ambient-light.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/effects/lighting/ambient-light.js ***!
  \*******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   AmbientLight: () => (/* binding */ AmbientLight)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n\nconst DEFAULT_LIGHT_COLOR = [255, 255, 255];\nconst DEFAULT_LIGHT_INTENSITY = 1.0;\nlet idCount = 0;\nclass AmbientLight {\n  constructor(props = {}) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"id\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"color\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"intensity\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"type\", 'ambient');\n\n    const {\n      color = DEFAULT_LIGHT_COLOR\n    } = props;\n    const {\n      intensity = DEFAULT_LIGHT_INTENSITY\n    } = props;\n    this.id = props.id || \"ambient-\".concat(idCount++);\n    this.color = color;\n    this.intensity = intensity;\n  }\n\n}\n//# sourceMappingURL=ambient-light.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/effects/lighting/ambient-light.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/effects/lighting/directional-light.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/effects/lighting/directional-light.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   DirectionalLight: () => (/* binding */ DirectionalLight)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _math_gl_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @math.gl/core */ \"./node_modules/@math.gl/core/dist/esm/classes/vector3.js\");\n\n\nconst DEFAULT_LIGHT_COLOR = [255, 255, 255];\nconst DEFAULT_LIGHT_INTENSITY = 1.0;\nconst DEFAULT_LIGHT_DIRECTION = [0.0, 0.0, -1.0];\nlet idCount = 0;\nclass DirectionalLight {\n  constructor(props = {}) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"id\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"color\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"intensity\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"type\", 'directional');\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"direction\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"shadow\", void 0);\n\n    const {\n      color = DEFAULT_LIGHT_COLOR\n    } = props;\n    const {\n      intensity = DEFAULT_LIGHT_INTENSITY\n    } = props;\n    const {\n      direction = DEFAULT_LIGHT_DIRECTION\n    } = props;\n    const {\n      _shadow = false\n    } = props;\n    this.id = props.id || \"directional-\".concat(idCount++);\n    this.color = color;\n    this.intensity = intensity;\n    this.type = 'directional';\n    this.direction = new _math_gl_core__WEBPACK_IMPORTED_MODULE_1__[\"default\"](direction).normalize().toArray();\n    this.shadow = _shadow;\n  }\n\n  getProjectedLight(opts) {\n    return this;\n  }\n\n}\n//# sourceMappingURL=directional-light.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/effects/lighting/directional-light.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/effects/lighting/lighting-effect.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/effects/lighting/lighting-effect.js ***!
  \*********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ LightingEffect)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/engine/dist/esm/lib/program-manager.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/texture-2d.js\");\n/* harmony import */ var _ambient_light__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./ambient-light */ \"./node_modules/@deck.gl/core/dist/esm/effects/lighting/ambient-light.js\");\n/* harmony import */ var _directional_light__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./directional-light */ \"./node_modules/@deck.gl/core/dist/esm/effects/lighting/directional-light.js\");\n/* harmony import */ var _math_gl_core__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! @math.gl/core */ \"./node_modules/@math.gl/core/dist/esm/classes/matrix4.js\");\n/* harmony import */ var _math_gl_core__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! @math.gl/core */ \"./node_modules/@math.gl/core/dist/esm/classes/vector3.js\");\n/* harmony import */ var _passes_shadow_pass__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../passes/shadow-pass */ \"./node_modules/@deck.gl/core/dist/esm/passes/shadow-pass.js\");\n/* harmony import */ var _shaderlib_shadow_shadow__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../shaderlib/shadow/shadow */ \"./node_modules/@deck.gl/core/dist/esm/shaderlib/shadow/shadow.js\");\n\n\n\n\n\n\n\nconst DEFAULT_AMBIENT_LIGHT_PROPS = {\n  color: [255, 255, 255],\n  intensity: 1.0\n};\nconst DEFAULT_DIRECTIONAL_LIGHT_PROPS = [{\n  color: [255, 255, 255],\n  intensity: 1.0,\n  direction: [-1, 3, -1]\n}, {\n  color: [255, 255, 255],\n  intensity: 0.9,\n  direction: [1, -8, -2.5]\n}];\nconst DEFAULT_SHADOW_COLOR = [0, 0, 0, 200 / 255];\nclass LightingEffect {\n  constructor(props = {}) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"id\", 'lighting-effect');\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"props\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"shadowColor\", DEFAULT_SHADOW_COLOR);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"shadow\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"ambientLight\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"directionalLights\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"pointLights\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"shadowPasses\", []);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"shadowMaps\", []);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"dummyShadowMap\", null);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"programManager\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"shadowMatrices\", void 0);\n\n    this.setProps(props);\n  }\n\n  setProps(props) {\n    this.ambientLight = null;\n    this.directionalLights = [];\n    this.pointLights = [];\n\n    for (const key in props) {\n      const lightSource = props[key];\n\n      switch (lightSource.type) {\n        case 'ambient':\n          this.ambientLight = lightSource;\n          break;\n\n        case 'directional':\n          this.directionalLights.push(lightSource);\n          break;\n\n        case 'point':\n          this.pointLights.push(lightSource);\n          break;\n\n        default:\n      }\n    }\n\n    this._applyDefaultLights();\n\n    this.shadow = this.directionalLights.some(light => light.shadow);\n    this.props = props;\n  }\n\n  preRender(gl, {\n    layers,\n    layerFilter,\n    viewports,\n    onViewportActive,\n    views\n  }) {\n    if (!this.shadow) return;\n    this.shadowMatrices = this._calculateMatrices();\n\n    if (this.shadowPasses.length === 0) {\n      this._createShadowPasses(gl);\n    }\n\n    if (!this.programManager) {\n      this.programManager = _luma_gl_core__WEBPACK_IMPORTED_MODULE_1__[\"default\"].getDefaultProgramManager(gl);\n\n      if (_shaderlib_shadow_shadow__WEBPACK_IMPORTED_MODULE_2__[\"default\"]) {\n        this.programManager.addDefaultModule(_shaderlib_shadow_shadow__WEBPACK_IMPORTED_MODULE_2__[\"default\"]);\n      }\n    }\n\n    if (!this.dummyShadowMap) {\n      this.dummyShadowMap = new _luma_gl_core__WEBPACK_IMPORTED_MODULE_3__[\"default\"](gl, {\n        width: 1,\n        height: 1\n      });\n    }\n\n    for (let i = 0; i < this.shadowPasses.length; i++) {\n      const shadowPass = this.shadowPasses[i];\n      shadowPass.render({\n        layers,\n        layerFilter,\n        viewports,\n        onViewportActive,\n        views,\n        moduleParameters: {\n          shadowLightId: i,\n          dummyShadowMap: this.dummyShadowMap,\n          shadowMatrices: this.shadowMatrices\n        }\n      });\n    }\n  }\n\n  getModuleParameters(layer) {\n    const parameters = this.shadow ? {\n      shadowMaps: this.shadowMaps,\n      dummyShadowMap: this.dummyShadowMap,\n      shadowColor: this.shadowColor,\n      shadowMatrices: this.shadowMatrices\n    } : {};\n    parameters.lightSources = {\n      ambientLight: this.ambientLight,\n      directionalLights: this.directionalLights.map(directionalLight => directionalLight.getProjectedLight({\n        layer\n      })),\n      pointLights: this.pointLights.map(pointLight => pointLight.getProjectedLight({\n        layer\n      }))\n    };\n    return parameters;\n  }\n\n  cleanup() {\n    for (const shadowPass of this.shadowPasses) {\n      shadowPass.delete();\n    }\n\n    this.shadowPasses.length = 0;\n    this.shadowMaps.length = 0;\n\n    if (this.dummyShadowMap) {\n      this.dummyShadowMap.delete();\n      this.dummyShadowMap = null;\n    }\n\n    if (this.shadow && this.programManager) {\n      this.programManager.removeDefaultModule(_shaderlib_shadow_shadow__WEBPACK_IMPORTED_MODULE_2__[\"default\"]);\n      this.programManager = null;\n    }\n  }\n\n  _calculateMatrices() {\n    const lightMatrices = [];\n\n    for (const light of this.directionalLights) {\n      const viewMatrix = new _math_gl_core__WEBPACK_IMPORTED_MODULE_4__[\"default\"]().lookAt({\n        eye: new _math_gl_core__WEBPACK_IMPORTED_MODULE_5__[\"default\"](light.direction).negate()\n      });\n      lightMatrices.push(viewMatrix);\n    }\n\n    return lightMatrices;\n  }\n\n  _createShadowPasses(gl) {\n    for (let i = 0; i < this.directionalLights.length; i++) {\n      const shadowPass = new _passes_shadow_pass__WEBPACK_IMPORTED_MODULE_6__[\"default\"](gl);\n      this.shadowPasses[i] = shadowPass;\n      this.shadowMaps[i] = shadowPass.shadowMap;\n    }\n  }\n\n  _applyDefaultLights() {\n    const {\n      ambientLight,\n      pointLights,\n      directionalLights\n    } = this;\n\n    if (!ambientLight && pointLights.length === 0 && directionalLights.length === 0) {\n      this.ambientLight = new _ambient_light__WEBPACK_IMPORTED_MODULE_7__.AmbientLight(DEFAULT_AMBIENT_LIGHT_PROPS);\n      this.directionalLights.push(new _directional_light__WEBPACK_IMPORTED_MODULE_8__.DirectionalLight(DEFAULT_DIRECTIONAL_LIGHT_PROPS[0]), new _directional_light__WEBPACK_IMPORTED_MODULE_8__.DirectionalLight(DEFAULT_DIRECTIONAL_LIGHT_PROPS[1]));\n    }\n  }\n\n}\n//# sourceMappingURL=lighting-effect.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/effects/lighting/lighting-effect.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/lib/attribute/attribute-manager.js":
/*!********************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/lib/attribute/attribute-manager.js ***!
  \********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ AttributeManager)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _attribute__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./attribute */ \"./node_modules/@deck.gl/core/dist/esm/lib/attribute/attribute.js\");\n/* harmony import */ var _utils_log__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../utils/log */ \"./node_modules/@deck.gl/core/dist/esm/utils/log.js\");\n/* harmony import */ var _utils_memoize__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../utils/memoize */ \"./node_modules/@deck.gl/core/dist/esm/utils/memoize.js\");\n/* harmony import */ var _utils_math_utils__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../utils/math-utils */ \"./node_modules/@deck.gl/core/dist/esm/utils/math-utils.js\");\n/* harmony import */ var _debug__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../debug */ \"./node_modules/@deck.gl/core/dist/esm/debug/index.js\");\n/* harmony import */ var _attribute_transition_manager__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./attribute-transition-manager */ \"./node_modules/@deck.gl/core/dist/esm/lib/attribute/attribute-transition-manager.js\");\n\n\n\n\n\n\n\nconst TRACE_INVALIDATE = 'attributeManager.invalidate';\nconst TRACE_UPDATE_START = 'attributeManager.updateStart';\nconst TRACE_UPDATE_END = 'attributeManager.updateEnd';\nconst TRACE_ATTRIBUTE_UPDATE_START = 'attribute.updateStart';\nconst TRACE_ATTRIBUTE_ALLOCATE = 'attribute.allocate';\nconst TRACE_ATTRIBUTE_UPDATE_END = 'attribute.updateEnd';\nclass AttributeManager {\n  constructor(gl, {\n    id = 'attribute-manager',\n    stats,\n    timeline\n  } = {}) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"id\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"gl\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"attributes\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"updateTriggers\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"needsRedraw\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"userData\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"stats\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"attributeTransitionManager\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"mergeBoundsMemoized\", (0,_utils_memoize__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(_utils_math_utils__WEBPACK_IMPORTED_MODULE_2__.mergeBounds));\n\n    this.id = id;\n    this.gl = gl;\n    this.attributes = {};\n    this.updateTriggers = {};\n    this.needsRedraw = true;\n    this.userData = {};\n    this.stats = stats;\n    this.attributeTransitionManager = new _attribute_transition_manager__WEBPACK_IMPORTED_MODULE_3__[\"default\"](gl, {\n      id: \"\".concat(id, \"-transitions\"),\n      timeline\n    });\n    Object.seal(this);\n  }\n\n  finalize() {\n    for (const attributeName in this.attributes) {\n      this.attributes[attributeName].delete();\n    }\n\n    this.attributeTransitionManager.finalize();\n  }\n\n  getNeedsRedraw(opts = {\n    clearRedrawFlags: false\n  }) {\n    const redraw = this.needsRedraw;\n    this.needsRedraw = this.needsRedraw && !opts.clearRedrawFlags;\n    return redraw && this.id;\n  }\n\n  setNeedsRedraw() {\n    this.needsRedraw = true;\n  }\n\n  add(attributes) {\n    this._add(attributes);\n  }\n\n  addInstanced(attributes) {\n    this._add(attributes, {\n      instanced: 1\n    });\n  }\n\n  remove(attributeNameArray) {\n    for (const name of attributeNameArray) {\n      if (this.attributes[name] !== undefined) {\n        this.attributes[name].delete();\n        delete this.attributes[name];\n      }\n    }\n  }\n\n  invalidate(triggerName, dataRange) {\n    const invalidatedAttributes = this._invalidateTrigger(triggerName, dataRange);\n\n    (0,_debug__WEBPACK_IMPORTED_MODULE_4__[\"default\"])(TRACE_INVALIDATE, this, triggerName, invalidatedAttributes);\n  }\n\n  invalidateAll(dataRange) {\n    for (const attributeName in this.attributes) {\n      this.attributes[attributeName].setNeedsUpdate(attributeName, dataRange);\n    }\n\n    (0,_debug__WEBPACK_IMPORTED_MODULE_4__[\"default\"])(TRACE_INVALIDATE, this, 'all');\n  }\n\n  update({\n    data,\n    numInstances,\n    startIndices = null,\n    transitions,\n    props = {},\n    buffers = {},\n    context = {}\n  }) {\n    let updated = false;\n    (0,_debug__WEBPACK_IMPORTED_MODULE_4__[\"default\"])(TRACE_UPDATE_START, this);\n\n    if (this.stats) {\n      this.stats.get('Update Attributes').timeStart();\n    }\n\n    for (const attributeName in this.attributes) {\n      const attribute = this.attributes[attributeName];\n      const accessorName = attribute.settings.accessor;\n      attribute.startIndices = startIndices;\n      attribute.numInstances = numInstances;\n\n      if (props[attributeName]) {\n        _utils_log__WEBPACK_IMPORTED_MODULE_5__[\"default\"].removed(\"props.\".concat(attributeName), \"data.attributes.\".concat(attributeName))();\n      }\n\n      if (attribute.setExternalBuffer(buffers[attributeName])) {} else if (attribute.setBinaryValue(typeof accessorName === 'string' ? buffers[accessorName] : undefined, data.startIndices)) {} else if (typeof accessorName === 'string' && !buffers[accessorName] && attribute.setConstantValue(props[accessorName])) {} else if (attribute.needsUpdate()) {\n        updated = true;\n\n        this._updateAttribute({\n          attribute,\n          numInstances,\n          data,\n          props,\n          context\n        });\n      }\n\n      this.needsRedraw = this.needsRedraw || attribute.needsRedraw();\n    }\n\n    if (updated) {\n      (0,_debug__WEBPACK_IMPORTED_MODULE_4__[\"default\"])(TRACE_UPDATE_END, this, numInstances);\n    }\n\n    if (this.stats) {\n      this.stats.get('Update Attributes').timeEnd();\n    }\n\n    this.attributeTransitionManager.update({\n      attributes: this.attributes,\n      numInstances,\n      transitions\n    });\n  }\n\n  updateTransition() {\n    const {\n      attributeTransitionManager\n    } = this;\n    const transitionUpdated = attributeTransitionManager.run();\n    this.needsRedraw = this.needsRedraw || transitionUpdated;\n    return transitionUpdated;\n  }\n\n  getAttributes() {\n    return this.attributes;\n  }\n\n  getBounds(attributeNames) {\n    const bounds = attributeNames.map(attributeName => {\n      var _this$attributes$attr;\n\n      return (_this$attributes$attr = this.attributes[attributeName]) === null || _this$attributes$attr === void 0 ? void 0 : _this$attributes$attr.getBounds();\n    });\n    return this.mergeBoundsMemoized(bounds);\n  }\n\n  getChangedAttributes(opts = {\n    clearChangedFlags: false\n  }) {\n    const {\n      attributes,\n      attributeTransitionManager\n    } = this;\n    const changedAttributes = { ...attributeTransitionManager.getAttributes()\n    };\n\n    for (const attributeName in attributes) {\n      const attribute = attributes[attributeName];\n\n      if (attribute.needsRedraw(opts) && !attributeTransitionManager.hasAttribute(attributeName)) {\n        changedAttributes[attributeName] = attribute;\n      }\n    }\n\n    return changedAttributes;\n  }\n\n  getShaderAttributes(attributes, excludeAttributes = {}) {\n    if (!attributes) {\n      attributes = this.getAttributes();\n    }\n\n    const shaderAttributes = {};\n\n    for (const attributeName in attributes) {\n      if (!excludeAttributes[attributeName]) {\n        Object.assign(shaderAttributes, attributes[attributeName].getShaderAttributes());\n      }\n    }\n\n    return shaderAttributes;\n  }\n\n  _add(attributes, extraProps = {}) {\n    for (const attributeName in attributes) {\n      const attribute = attributes[attributeName];\n      this.attributes[attributeName] = this._createAttribute(attributeName, attribute, extraProps);\n    }\n\n    this._mapUpdateTriggersToAttributes();\n  }\n\n  _createAttribute(name, attribute, extraProps) {\n    const props = { ...attribute,\n      id: name,\n      size: attribute.isIndexed && 1 || attribute.size || 1,\n      divisor: extraProps.instanced ? 1 : attribute.divisor || 0\n    };\n    return new _attribute__WEBPACK_IMPORTED_MODULE_6__[\"default\"](this.gl, props);\n  }\n\n  _mapUpdateTriggersToAttributes() {\n    const triggers = {};\n\n    for (const attributeName in this.attributes) {\n      const attribute = this.attributes[attributeName];\n      attribute.getUpdateTriggers().forEach(triggerName => {\n        if (!triggers[triggerName]) {\n          triggers[triggerName] = [];\n        }\n\n        triggers[triggerName].push(attributeName);\n      });\n    }\n\n    this.updateTriggers = triggers;\n  }\n\n  _invalidateTrigger(triggerName, dataRange) {\n    const {\n      attributes,\n      updateTriggers\n    } = this;\n    const invalidatedAttributes = updateTriggers[triggerName];\n\n    if (invalidatedAttributes) {\n      invalidatedAttributes.forEach(name => {\n        const attribute = attributes[name];\n\n        if (attribute) {\n          attribute.setNeedsUpdate(attribute.id, dataRange);\n        }\n      });\n    }\n\n    return invalidatedAttributes;\n  }\n\n  _updateAttribute(opts) {\n    const {\n      attribute,\n      numInstances\n    } = opts;\n    (0,_debug__WEBPACK_IMPORTED_MODULE_4__[\"default\"])(TRACE_ATTRIBUTE_UPDATE_START, attribute);\n\n    if (attribute.constant) {\n      attribute.setConstantValue(attribute.value);\n      return;\n    }\n\n    if (attribute.allocate(numInstances)) {\n      (0,_debug__WEBPACK_IMPORTED_MODULE_4__[\"default\"])(TRACE_ATTRIBUTE_ALLOCATE, attribute, numInstances);\n    }\n\n    const updated = attribute.updateBuffer(opts);\n\n    if (updated) {\n      this.needsRedraw = true;\n      (0,_debug__WEBPACK_IMPORTED_MODULE_4__[\"default\"])(TRACE_ATTRIBUTE_UPDATE_END, attribute, numInstances);\n    }\n  }\n\n}\n//# sourceMappingURL=attribute-manager.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/lib/attribute/attribute-manager.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/lib/attribute/attribute-transition-manager.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/lib/attribute/attribute-transition-manager.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ AttributeTransitionManager)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/engine/dist/esm/transform/transform.js\");\n/* harmony import */ var _transitions_gpu_interpolation_transition__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../transitions/gpu-interpolation-transition */ \"./node_modules/@deck.gl/core/dist/esm/transitions/gpu-interpolation-transition.js\");\n/* harmony import */ var _transitions_gpu_spring_transition__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../transitions/gpu-spring-transition */ \"./node_modules/@deck.gl/core/dist/esm/transitions/gpu-spring-transition.js\");\n/* harmony import */ var _utils_log__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../utils/log */ \"./node_modules/@deck.gl/core/dist/esm/utils/log.js\");\n\n\n\n\n\nconst TRANSITION_TYPES = {\n  interpolation: _transitions_gpu_interpolation_transition__WEBPACK_IMPORTED_MODULE_1__[\"default\"],\n  spring: _transitions_gpu_spring_transition__WEBPACK_IMPORTED_MODULE_2__[\"default\"]\n};\nclass AttributeTransitionManager {\n  constructor(gl, {\n    id,\n    timeline\n  }) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"id\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"isSupported\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"gl\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"timeline\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"transitions\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"needsRedraw\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"numInstances\", void 0);\n\n    this.id = id;\n    this.gl = gl;\n    this.timeline = timeline;\n    this.transitions = {};\n    this.needsRedraw = false;\n    this.numInstances = 1;\n    this.isSupported = _luma_gl_core__WEBPACK_IMPORTED_MODULE_3__[\"default\"].isSupported(gl);\n  }\n\n  finalize() {\n    for (const attributeName in this.transitions) {\n      this._removeTransition(attributeName);\n    }\n  }\n\n  update({\n    attributes,\n    transitions,\n    numInstances\n  }) {\n    this.numInstances = numInstances || 1;\n\n    for (const attributeName in attributes) {\n      const attribute = attributes[attributeName];\n      const settings = attribute.getTransitionSetting(transitions);\n      if (!settings) continue;\n\n      this._updateAttribute(attributeName, attribute, settings);\n    }\n\n    for (const attributeName in this.transitions) {\n      const attribute = attributes[attributeName];\n\n      if (!attribute || !attribute.getTransitionSetting(transitions)) {\n        this._removeTransition(attributeName);\n      }\n    }\n  }\n\n  hasAttribute(attributeName) {\n    const transition = this.transitions[attributeName];\n    return transition && transition.inProgress;\n  }\n\n  getAttributes() {\n    const animatedAttributes = {};\n\n    for (const attributeName in this.transitions) {\n      const transition = this.transitions[attributeName];\n\n      if (transition.inProgress) {\n        animatedAttributes[attributeName] = transition.attributeInTransition;\n      }\n    }\n\n    return animatedAttributes;\n  }\n\n  run() {\n    if (!this.isSupported || this.numInstances === 0) {\n      return false;\n    }\n\n    for (const attributeName in this.transitions) {\n      const updated = this.transitions[attributeName].update();\n\n      if (updated) {\n        this.needsRedraw = true;\n      }\n    }\n\n    const needsRedraw = this.needsRedraw;\n    this.needsRedraw = false;\n    return needsRedraw;\n  }\n\n  _removeTransition(attributeName) {\n    this.transitions[attributeName].cancel();\n    delete this.transitions[attributeName];\n  }\n\n  _updateAttribute(attributeName, attribute, settings) {\n    const transition = this.transitions[attributeName];\n    let isNew = !transition || transition.type !== settings.type;\n\n    if (isNew) {\n      if (!this.isSupported) {\n        _utils_log__WEBPACK_IMPORTED_MODULE_4__[\"default\"].warn(\"WebGL2 not supported by this browser. Transition for \".concat(attributeName, \" is disabled.\"))();\n        return;\n      }\n\n      if (transition) {\n        this._removeTransition(attributeName);\n      }\n\n      const TransitionType = TRANSITION_TYPES[settings.type];\n\n      if (TransitionType) {\n        this.transitions[attributeName] = new TransitionType({\n          attribute,\n          timeline: this.timeline,\n          gl: this.gl\n        });\n      } else {\n        _utils_log__WEBPACK_IMPORTED_MODULE_4__[\"default\"].error(\"unsupported transition type '\".concat(settings.type, \"'\"))();\n        isNew = false;\n      }\n    }\n\n    if (isNew || attribute.needsRedraw()) {\n      this.needsRedraw = true;\n      this.transitions[attributeName].start(settings, this.numInstances);\n    }\n  }\n\n}\n//# sourceMappingURL=attribute-transition-manager.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/lib/attribute/attribute-transition-manager.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/lib/attribute/attribute-transition-utils.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/lib/attribute/attribute-transition-utils.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   cycleBuffers: () => (/* binding */ cycleBuffers),\n/* harmony export */   getAttributeBufferLength: () => (/* binding */ getAttributeBufferLength),\n/* harmony export */   getAttributeTypeFromSize: () => (/* binding */ getAttributeTypeFromSize),\n/* harmony export */   getSourceBufferAttribute: () => (/* binding */ getSourceBufferAttribute),\n/* harmony export */   normalizeTransitionSettings: () => (/* binding */ normalizeTransitionSettings),\n/* harmony export */   padBuffer: () => (/* binding */ padBuffer)\n/* harmony export */ });\n/* harmony import */ var _utils_array_utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../utils/array-utils */ \"./node_modules/@deck.gl/core/dist/esm/utils/array-utils.js\");\n\nconst DEFAULT_TRANSITION_SETTINGS = {\n  interpolation: {\n    duration: 0,\n    easing: t => t\n  },\n  spring: {\n    stiffness: 0.05,\n    damping: 0.5\n  }\n};\nfunction normalizeTransitionSettings(userSettings, layerSettings) {\n  if (!userSettings) {\n    return null;\n  }\n\n  if (Number.isFinite(userSettings)) {\n    userSettings = {\n      type: 'interpolation',\n      duration: userSettings\n    };\n  }\n\n  const type = userSettings.type || 'interpolation';\n  return { ...DEFAULT_TRANSITION_SETTINGS[type],\n    ...layerSettings,\n    ...userSettings,\n    type\n  };\n}\nfunction getSourceBufferAttribute(gl, attribute) {\n  const buffer = attribute.getBuffer();\n\n  if (buffer) {\n    return [buffer, {\n      divisor: 0,\n      size: attribute.size,\n      normalized: attribute.settings.normalized\n    }];\n  }\n\n  return attribute.value;\n}\nfunction getAttributeTypeFromSize(size) {\n  switch (size) {\n    case 1:\n      return 'float';\n\n    case 2:\n      return 'vec2';\n\n    case 3:\n      return 'vec3';\n\n    case 4:\n      return 'vec4';\n\n    default:\n      throw new Error(\"No defined attribute type for size \\\"\".concat(size, \"\\\"\"));\n  }\n}\nfunction cycleBuffers(buffers) {\n  buffers.push(buffers.shift());\n}\nfunction getAttributeBufferLength(attribute, numInstances) {\n  const {\n    doublePrecision,\n    settings,\n    value,\n    size\n  } = attribute;\n  const multiplier = doublePrecision && value instanceof Float64Array ? 2 : 1;\n  return (settings.noAlloc ? value.length : numInstances * size) * multiplier;\n}\nfunction padBuffer({\n  buffer,\n  numInstances,\n  attribute,\n  fromLength,\n  fromStartIndices,\n  getData = x => x\n}) {\n  const precisionMultiplier = attribute.doublePrecision && attribute.value instanceof Float64Array ? 2 : 1;\n  const size = attribute.size * precisionMultiplier;\n  const byteOffset = attribute.byteOffset;\n  const toStartIndices = attribute.startIndices;\n  const hasStartIndices = fromStartIndices && toStartIndices;\n  const toLength = getAttributeBufferLength(attribute, numInstances);\n  const isConstant = attribute.isConstant;\n\n  if (!hasStartIndices && fromLength >= toLength) {\n    return;\n  }\n\n  const toData = isConstant ? attribute.value : attribute.getBuffer().getData({\n    srcByteOffset: byteOffset\n  });\n\n  if (attribute.settings.normalized && !isConstant) {\n    const getter = getData;\n\n    getData = (value, chunk) => attribute.normalizeConstant(getter(value, chunk));\n  }\n\n  const getMissingData = isConstant ? (i, chunk) => getData(toData, chunk) : (i, chunk) => getData(toData.subarray(i, i + size), chunk);\n  const source = buffer.getData({\n    length: fromLength\n  });\n  const data = new Float32Array(toLength);\n  (0,_utils_array_utils__WEBPACK_IMPORTED_MODULE_0__.padArray)({\n    source,\n    target: data,\n    sourceStartIndices: fromStartIndices,\n    targetStartIndices: toStartIndices,\n    size,\n    getData: getMissingData\n  });\n\n  if (buffer.byteLength < data.byteLength + byteOffset) {\n    buffer.reallocate(data.byteLength + byteOffset);\n  }\n\n  buffer.subData({\n    data,\n    offset: byteOffset\n  });\n}\n//# sourceMappingURL=attribute-transition-utils.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/lib/attribute/attribute-transition-utils.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/lib/attribute/attribute.js":
/*!************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/lib/attribute/attribute.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Attribute)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _data_column__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./data-column */ \"./node_modules/@deck.gl/core/dist/esm/lib/attribute/data-column.js\");\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../utils/assert */ \"./node_modules/@deck.gl/core/dist/esm/utils/assert.js\");\n/* harmony import */ var _utils_iterable_utils__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../utils/iterable-utils */ \"./node_modules/@deck.gl/core/dist/esm/utils/iterable-utils.js\");\n/* harmony import */ var _utils_flatten__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../utils/flatten */ \"./node_modules/@deck.gl/core/dist/esm/utils/flatten.js\");\n/* harmony import */ var _utils_range__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../utils/range */ \"./node_modules/@deck.gl/core/dist/esm/utils/range.js\");\n/* harmony import */ var _attribute_transition_utils__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./attribute-transition-utils */ \"./node_modules/@deck.gl/core/dist/esm/lib/attribute/attribute-transition-utils.js\");\n\n\n\n\n\n\n\nclass Attribute extends _data_column__WEBPACK_IMPORTED_MODULE_1__[\"default\"] {\n  constructor(gl, opts) {\n    super(gl, opts, {\n      startIndices: null,\n      lastExternalBuffer: null,\n      binaryValue: null,\n      binaryAccessor: null,\n      needsUpdate: true,\n      needsRedraw: false,\n      updateRanges: _utils_range__WEBPACK_IMPORTED_MODULE_2__.FULL\n    });\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"constant\", false);\n\n    this.settings.update = opts.update || (opts.accessor ? this._autoUpdater : undefined);\n    Object.seal(this.settings);\n    Object.seal(this.state);\n\n    this._validateAttributeUpdaters();\n  }\n\n  get startIndices() {\n    return this.state.startIndices;\n  }\n\n  set startIndices(layout) {\n    this.state.startIndices = layout;\n  }\n\n  needsUpdate() {\n    return this.state.needsUpdate;\n  }\n\n  needsRedraw({\n    clearChangedFlags = false\n  } = {}) {\n    const needsRedraw = this.state.needsRedraw;\n    this.state.needsRedraw = needsRedraw && !clearChangedFlags;\n    return needsRedraw;\n  }\n\n  getUpdateTriggers() {\n    const {\n      accessor\n    } = this.settings;\n    return [this.id].concat(typeof accessor !== 'function' && accessor || []);\n  }\n\n  supportsTransition() {\n    return Boolean(this.settings.transition);\n  }\n\n  getTransitionSetting(opts) {\n    if (!opts || !this.supportsTransition()) {\n      return null;\n    }\n\n    const {\n      accessor\n    } = this.settings;\n    const layerSettings = this.settings.transition;\n    const userSettings = Array.isArray(accessor) ? opts[accessor.find(a => opts[a])] : opts[accessor];\n    return (0,_attribute_transition_utils__WEBPACK_IMPORTED_MODULE_3__.normalizeTransitionSettings)(userSettings, layerSettings);\n  }\n\n  setNeedsUpdate(reason = this.id, dataRange) {\n    this.state.needsUpdate = this.state.needsUpdate || reason;\n    this.setNeedsRedraw(reason);\n\n    if (dataRange) {\n      const {\n        startRow = 0,\n        endRow = Infinity\n      } = dataRange;\n      this.state.updateRanges = _utils_range__WEBPACK_IMPORTED_MODULE_2__.add(this.state.updateRanges, [startRow, endRow]);\n    } else {\n      this.state.updateRanges = _utils_range__WEBPACK_IMPORTED_MODULE_2__.FULL;\n    }\n  }\n\n  clearNeedsUpdate() {\n    this.state.needsUpdate = false;\n    this.state.updateRanges = _utils_range__WEBPACK_IMPORTED_MODULE_2__.EMPTY;\n  }\n\n  setNeedsRedraw(reason = this.id) {\n    this.state.needsRedraw = this.state.needsRedraw || reason;\n  }\n\n  allocate(numInstances) {\n    const {\n      state,\n      settings\n    } = this;\n\n    if (settings.noAlloc) {\n      return false;\n    }\n\n    if (settings.update) {\n      super.allocate(numInstances, state.updateRanges !== _utils_range__WEBPACK_IMPORTED_MODULE_2__.FULL);\n      return true;\n    }\n\n    return false;\n  }\n\n  updateBuffer({\n    numInstances,\n    data,\n    props,\n    context\n  }) {\n    if (!this.needsUpdate()) {\n      return false;\n    }\n\n    const {\n      state: {\n        updateRanges\n      },\n      settings: {\n        update,\n        noAlloc\n      }\n    } = this;\n    let updated = true;\n\n    if (update) {\n      for (const [startRow, endRow] of updateRanges) {\n        update.call(context, this, {\n          data,\n          startRow,\n          endRow,\n          props,\n          numInstances\n        });\n      }\n\n      if (!this.value) {} else if (this.constant || this.buffer.byteLength < this.value.byteLength + this.byteOffset) {\n        this.setData({\n          value: this.value,\n          constant: this.constant\n        });\n        this.constant = false;\n      } else {\n        for (const [startRow, endRow] of updateRanges) {\n          const startOffset = Number.isFinite(startRow) ? this.getVertexOffset(startRow) : 0;\n          const endOffset = Number.isFinite(endRow) ? this.getVertexOffset(endRow) : noAlloc || !Number.isFinite(numInstances) ? this.value.length : numInstances * this.size;\n          super.updateSubBuffer({\n            startOffset,\n            endOffset\n          });\n        }\n      }\n\n      this._checkAttributeArray();\n    } else {\n      updated = false;\n    }\n\n    this.clearNeedsUpdate();\n    this.setNeedsRedraw();\n    return updated;\n  }\n\n  setConstantValue(value) {\n    if (value === undefined || typeof value === 'function') {\n      return false;\n    }\n\n    const hasChanged = this.setData({\n      constant: true,\n      value\n    });\n\n    if (hasChanged) {\n      this.setNeedsRedraw();\n    }\n\n    this.clearNeedsUpdate();\n    return true;\n  }\n\n  setExternalBuffer(buffer) {\n    const {\n      state\n    } = this;\n\n    if (!buffer) {\n      state.lastExternalBuffer = null;\n      return false;\n    }\n\n    this.clearNeedsUpdate();\n\n    if (state.lastExternalBuffer === buffer) {\n      return true;\n    }\n\n    state.lastExternalBuffer = buffer;\n    this.setNeedsRedraw();\n    this.setData(buffer);\n    return true;\n  }\n\n  setBinaryValue(buffer, startIndices = null) {\n    const {\n      state,\n      settings\n    } = this;\n\n    if (!buffer) {\n      state.binaryValue = null;\n      state.binaryAccessor = null;\n      return false;\n    }\n\n    if (settings.noAlloc) {\n      return false;\n    }\n\n    if (state.binaryValue === buffer) {\n      this.clearNeedsUpdate();\n      return true;\n    }\n\n    state.binaryValue = buffer;\n    this.setNeedsRedraw();\n    const needsUpdate = settings.transform || startIndices !== this.startIndices;\n\n    if (needsUpdate) {\n      if (ArrayBuffer.isView(buffer)) {\n        buffer = {\n          value: buffer\n        };\n      }\n\n      const binaryValue = buffer;\n      (0,_utils_assert__WEBPACK_IMPORTED_MODULE_4__[\"default\"])(ArrayBuffer.isView(binaryValue.value), \"invalid \".concat(settings.accessor));\n      const needsNormalize = Boolean(binaryValue.size) && binaryValue.size !== this.size;\n      state.binaryAccessor = (0,_utils_iterable_utils__WEBPACK_IMPORTED_MODULE_5__.getAccessorFromBuffer)(binaryValue.value, {\n        size: binaryValue.size || this.size,\n        stride: binaryValue.stride,\n        offset: binaryValue.offset,\n        startIndices: startIndices,\n        nested: needsNormalize\n      });\n      return false;\n    }\n\n    this.clearNeedsUpdate();\n    this.setData(buffer);\n    return true;\n  }\n\n  getVertexOffset(row) {\n    const {\n      startIndices\n    } = this;\n    const vertexIndex = startIndices ? row < startIndices.length ? startIndices[row] : this.numInstances : row;\n    return vertexIndex * this.size;\n  }\n\n  getShaderAttributes() {\n    const shaderAttributeDefs = this.settings.shaderAttributes || {\n      [this.id]: null\n    };\n    const shaderAttributes = {};\n\n    for (const shaderAttributeName in shaderAttributeDefs) {\n      Object.assign(shaderAttributes, super.getShaderAttributes(shaderAttributeName, shaderAttributeDefs[shaderAttributeName]));\n    }\n\n    return shaderAttributes;\n  }\n\n  _autoUpdater(attribute, {\n    data,\n    startRow,\n    endRow,\n    props,\n    numInstances\n  }) {\n    if (attribute.constant) {\n      return;\n    }\n\n    const {\n      settings,\n      state,\n      value,\n      size,\n      startIndices\n    } = attribute;\n    const {\n      accessor,\n      transform\n    } = settings;\n    const accessorFunc = state.binaryAccessor || (typeof accessor === 'function' ? accessor : props[accessor]);\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_4__[\"default\"])(typeof accessorFunc === 'function', \"accessor \\\"\".concat(accessor, \"\\\" is not a function\"));\n    let i = attribute.getVertexOffset(startRow);\n    const {\n      iterable,\n      objectInfo\n    } = (0,_utils_iterable_utils__WEBPACK_IMPORTED_MODULE_5__.createIterable)(data, startRow, endRow);\n\n    for (const object of iterable) {\n      objectInfo.index++;\n      let objectValue = accessorFunc(object, objectInfo);\n\n      if (transform) {\n        objectValue = transform.call(this, objectValue);\n      }\n\n      if (startIndices) {\n        const numVertices = (objectInfo.index < startIndices.length - 1 ? startIndices[objectInfo.index + 1] : numInstances) - startIndices[objectInfo.index];\n\n        if (objectValue && Array.isArray(objectValue[0])) {\n          let startIndex = i;\n\n          for (const item of objectValue) {\n            attribute._normalizeValue(item, value, startIndex);\n\n            startIndex += size;\n          }\n        } else if (objectValue && objectValue.length > size) {\n          value.set(objectValue, i);\n        } else {\n          attribute._normalizeValue(objectValue, objectInfo.target, 0);\n\n          (0,_utils_flatten__WEBPACK_IMPORTED_MODULE_6__.fillArray)({\n            target: value,\n            source: objectInfo.target,\n            start: i,\n            count: numVertices\n          });\n        }\n\n        i += numVertices * size;\n      } else {\n        attribute._normalizeValue(objectValue, value, i);\n\n        i += size;\n      }\n    }\n  }\n\n  _validateAttributeUpdaters() {\n    const {\n      settings\n    } = this;\n    const hasUpdater = settings.noAlloc || typeof settings.update === 'function';\n\n    if (!hasUpdater) {\n      throw new Error(\"Attribute \".concat(this.id, \" missing update or accessor\"));\n    }\n  }\n\n  _checkAttributeArray() {\n    const {\n      value\n    } = this;\n    const limit = Math.min(4, this.size);\n\n    if (value && value.length >= limit) {\n      let valid = true;\n\n      switch (limit) {\n        case 4:\n          valid = valid && Number.isFinite(value[3]);\n\n        case 3:\n          valid = valid && Number.isFinite(value[2]);\n\n        case 2:\n          valid = valid && Number.isFinite(value[1]);\n\n        case 1:\n          valid = valid && Number.isFinite(value[0]);\n          break;\n\n        default:\n          valid = false;\n      }\n\n      if (!valid) {\n        throw new Error(\"Illegal attribute generated for \".concat(this.id));\n      }\n    }\n  }\n\n}\n//# sourceMappingURL=attribute.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/lib/attribute/attribute.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/lib/attribute/data-column.js":
/*!**************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/lib/attribute/data-column.js ***!
  \**************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ DataColumn)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/webgl/dist/esm/features/features.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/webgl/dist/esm/features/webgl-features-table.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/buffer.js\");\n/* harmony import */ var _shader_attribute__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./shader-attribute */ \"./node_modules/@deck.gl/core/dist/esm/lib/attribute/shader-attribute.js\");\n/* harmony import */ var _gl_utils__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./gl-utils */ \"./node_modules/@deck.gl/core/dist/esm/lib/attribute/gl-utils.js\");\n/* harmony import */ var _utils_typed_array_manager__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../utils/typed-array-manager */ \"./node_modules/@deck.gl/core/dist/esm/utils/typed-array-manager.js\");\n/* harmony import */ var _utils_math_utils__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../../utils/math-utils */ \"./node_modules/@deck.gl/core/dist/esm/utils/math-utils.js\");\n/* harmony import */ var _utils_log__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../utils/log */ \"./node_modules/@deck.gl/core/dist/esm/utils/log.js\");\n\n\n\n\n\n\n\n\nfunction getStride(accessor) {\n  return accessor.stride || accessor.size * accessor.bytesPerElement;\n}\n\nfunction resolveShaderAttribute(baseAccessor, shaderAttributeOptions) {\n  if (shaderAttributeOptions.offset) {\n    _utils_log__WEBPACK_IMPORTED_MODULE_1__[\"default\"].removed('shaderAttribute.offset', 'vertexOffset, elementOffset')();\n  }\n\n  const stride = getStride(baseAccessor);\n  const vertexOffset = shaderAttributeOptions.vertexOffset !== undefined ? shaderAttributeOptions.vertexOffset : baseAccessor.vertexOffset || 0;\n  const elementOffset = shaderAttributeOptions.elementOffset || 0;\n  const offset = vertexOffset * stride + elementOffset * baseAccessor.bytesPerElement + (baseAccessor.offset || 0);\n  return { ...shaderAttributeOptions,\n    offset,\n    stride\n  };\n}\n\nfunction resolveDoublePrecisionShaderAttributes(baseAccessor, shaderAttributeOptions) {\n  const resolvedOptions = resolveShaderAttribute(baseAccessor, shaderAttributeOptions);\n  return {\n    high: resolvedOptions,\n    low: { ...resolvedOptions,\n      offset: resolvedOptions.offset + baseAccessor.size * 4\n    }\n  };\n}\n\nclass DataColumn {\n  constructor(gl, opts, state) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"gl\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"id\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"size\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"settings\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"value\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"doublePrecision\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_buffer\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"state\", void 0);\n\n    this.gl = gl;\n    this.id = opts.id || '';\n    this.size = opts.size || 1;\n    const logicalType = opts.logicalType || opts.type;\n    const doublePrecision = logicalType === 5130;\n    let {\n      defaultValue\n    } = opts;\n    defaultValue = Number.isFinite(defaultValue) ? [defaultValue] : defaultValue || new Array(this.size).fill(0);\n    let bufferType;\n\n    if (doublePrecision) {\n      bufferType = 5126;\n    } else if (!logicalType && opts.isIndexed) {\n      bufferType = gl && (0,_luma_gl_core__WEBPACK_IMPORTED_MODULE_2__.hasFeature)(gl, _luma_gl_core__WEBPACK_IMPORTED_MODULE_3__.FEATURES.ELEMENT_INDEX_UINT32) ? 5125 : 5123;\n    } else {\n      bufferType = logicalType || 5126;\n    }\n\n    let defaultType = (0,_gl_utils__WEBPACK_IMPORTED_MODULE_4__.glArrayFromType)(logicalType || bufferType || 5126);\n    this.doublePrecision = doublePrecision;\n\n    if (doublePrecision && opts.fp64 === false) {\n      defaultType = Float32Array;\n    }\n\n    this.value = null;\n    this.settings = { ...opts,\n      defaultType,\n      defaultValue: defaultValue,\n      logicalType,\n      type: bufferType,\n      size: this.size,\n      bytesPerElement: defaultType.BYTES_PER_ELEMENT\n    };\n    this.state = { ...state,\n      externalBuffer: null,\n      bufferAccessor: this.settings,\n      allocatedValue: null,\n      numInstances: 0,\n      bounds: null,\n      constant: false\n    };\n    this._buffer = null;\n  }\n\n  get isConstant() {\n    return this.state.constant;\n  }\n\n  get buffer() {\n    if (!this._buffer) {\n      const {\n        isIndexed,\n        type\n      } = this.settings;\n      this._buffer = new _luma_gl_core__WEBPACK_IMPORTED_MODULE_5__[\"default\"](this.gl, {\n        id: this.id,\n        target: isIndexed ? 34963 : 34962,\n        accessor: {\n          type\n        }\n      });\n    }\n\n    return this._buffer;\n  }\n\n  get byteOffset() {\n    const accessor = this.getAccessor();\n\n    if (accessor.vertexOffset) {\n      return accessor.vertexOffset * getStride(accessor);\n    }\n\n    return 0;\n  }\n\n  get numInstances() {\n    return this.state.numInstances;\n  }\n\n  set numInstances(n) {\n    this.state.numInstances = n;\n  }\n\n  delete() {\n    if (this._buffer) {\n      this._buffer.delete();\n\n      this._buffer = null;\n    }\n\n    _utils_typed_array_manager__WEBPACK_IMPORTED_MODULE_6__[\"default\"].release(this.state.allocatedValue);\n  }\n\n  getShaderAttributes(id, options) {\n    if (this.doublePrecision) {\n      const shaderAttributes = {};\n      const isBuffer64Bit = this.value instanceof Float64Array;\n      const doubleShaderAttributeDefs = resolveDoublePrecisionShaderAttributes(this.getAccessor(), options || {});\n      shaderAttributes[id] = new _shader_attribute__WEBPACK_IMPORTED_MODULE_7__[\"default\"](this, doubleShaderAttributeDefs.high);\n      shaderAttributes[\"\".concat(id, \"64Low\")] = isBuffer64Bit ? new _shader_attribute__WEBPACK_IMPORTED_MODULE_7__[\"default\"](this, doubleShaderAttributeDefs.low) : new Float32Array(this.size);\n      return shaderAttributes;\n    }\n\n    if (options) {\n      const shaderAttributeDef = resolveShaderAttribute(this.getAccessor(), options);\n      return {\n        [id]: new _shader_attribute__WEBPACK_IMPORTED_MODULE_7__[\"default\"](this, shaderAttributeDef)\n      };\n    }\n\n    return {\n      [id]: this\n    };\n  }\n\n  getBuffer() {\n    if (this.state.constant) {\n      return null;\n    }\n\n    return this.state.externalBuffer || this._buffer;\n  }\n\n  getValue() {\n    if (this.state.constant) {\n      return this.value;\n    }\n\n    return [this.getBuffer(), this.getAccessor()];\n  }\n\n  getAccessor() {\n    return this.state.bufferAccessor;\n  }\n\n  getBounds() {\n    if (this.state.bounds) {\n      return this.state.bounds;\n    }\n\n    let result = null;\n\n    if (this.state.constant && this.value) {\n      const min = Array.from(this.value);\n      result = [min, min];\n    } else {\n      const {\n        value,\n        numInstances,\n        size\n      } = this;\n      const len = numInstances * size;\n\n      if (value && len && value.length >= len) {\n        const min = new Array(size).fill(Infinity);\n        const max = new Array(size).fill(-Infinity);\n\n        for (let i = 0; i < len;) {\n          for (let j = 0; j < size; j++) {\n            const v = value[i++];\n            if (v < min[j]) min[j] = v;\n            if (v > max[j]) max[j] = v;\n          }\n        }\n\n        result = [min, max];\n      }\n    }\n\n    this.state.bounds = result;\n    return result;\n  }\n\n  setData(data) {\n    const {\n      state\n    } = this;\n    let opts;\n\n    if (ArrayBuffer.isView(data)) {\n      opts = {\n        value: data\n      };\n    } else if (data instanceof _luma_gl_core__WEBPACK_IMPORTED_MODULE_5__[\"default\"]) {\n      opts = {\n        buffer: data\n      };\n    } else {\n      opts = data;\n    }\n\n    const accessor = { ...this.settings,\n      ...opts\n    };\n    state.bufferAccessor = accessor;\n    state.bounds = null;\n\n    if (opts.constant) {\n      let value = opts.value;\n      value = this._normalizeValue(value, [], 0);\n\n      if (this.settings.normalized) {\n        value = this.normalizeConstant(value);\n      }\n\n      const hasChanged = !state.constant || !this._areValuesEqual(value, this.value);\n\n      if (!hasChanged) {\n        return false;\n      }\n\n      state.externalBuffer = null;\n      state.constant = true;\n      this.value = value;\n    } else if (opts.buffer) {\n      const buffer = opts.buffer;\n      state.externalBuffer = buffer;\n      state.constant = false;\n      this.value = opts.value || null;\n      const isBuffer64Bit = opts.value instanceof Float64Array;\n      accessor.type = opts.type || buffer.accessor.type;\n      accessor.bytesPerElement = buffer.accessor.BYTES_PER_ELEMENT * (isBuffer64Bit ? 2 : 1);\n      accessor.stride = getStride(accessor);\n    } else if (opts.value) {\n      this._checkExternalBuffer(opts);\n\n      let value = opts.value;\n      state.externalBuffer = null;\n      state.constant = false;\n      this.value = value;\n      accessor.bytesPerElement = value.BYTES_PER_ELEMENT;\n      accessor.stride = getStride(accessor);\n      const {\n        buffer,\n        byteOffset\n      } = this;\n\n      if (this.doublePrecision && value instanceof Float64Array) {\n        value = (0,_utils_math_utils__WEBPACK_IMPORTED_MODULE_8__.toDoublePrecisionArray)(value, accessor);\n      }\n\n      const requiredBufferSize = value.byteLength + byteOffset + accessor.stride * 2;\n\n      if (buffer.byteLength < requiredBufferSize) {\n        buffer.reallocate(requiredBufferSize);\n      }\n\n      buffer.setAccessor(null);\n      buffer.subData({\n        data: value,\n        offset: byteOffset\n      });\n      accessor.type = opts.type || buffer.accessor.type;\n    }\n\n    return true;\n  }\n\n  updateSubBuffer(opts = {}) {\n    this.state.bounds = null;\n    const value = this.value;\n    const {\n      startOffset = 0,\n      endOffset\n    } = opts;\n    this.buffer.subData({\n      data: this.doublePrecision && value instanceof Float64Array ? (0,_utils_math_utils__WEBPACK_IMPORTED_MODULE_8__.toDoublePrecisionArray)(value, {\n        size: this.size,\n        startIndex: startOffset,\n        endIndex: endOffset\n      }) : value.subarray(startOffset, endOffset),\n      offset: startOffset * value.BYTES_PER_ELEMENT + this.byteOffset\n    });\n  }\n\n  allocate(numInstances, copy = false) {\n    const {\n      state\n    } = this;\n    const oldValue = state.allocatedValue;\n    const value = _utils_typed_array_manager__WEBPACK_IMPORTED_MODULE_6__[\"default\"].allocate(oldValue, numInstances + 1, {\n      size: this.size,\n      type: this.settings.defaultType,\n      copy\n    });\n    this.value = value;\n    const {\n      buffer,\n      byteOffset\n    } = this;\n\n    if (buffer.byteLength < value.byteLength + byteOffset) {\n      buffer.reallocate(value.byteLength + byteOffset);\n\n      if (copy && oldValue) {\n        buffer.subData({\n          data: oldValue instanceof Float64Array ? (0,_utils_math_utils__WEBPACK_IMPORTED_MODULE_8__.toDoublePrecisionArray)(oldValue, this) : oldValue,\n          offset: byteOffset\n        });\n      }\n    }\n\n    state.allocatedValue = value;\n    state.constant = false;\n    state.externalBuffer = null;\n    state.bufferAccessor = this.settings;\n    return true;\n  }\n\n  _checkExternalBuffer(opts) {\n    const {\n      value\n    } = opts;\n\n    if (!ArrayBuffer.isView(value)) {\n      throw new Error(\"Attribute \".concat(this.id, \" value is not TypedArray\"));\n    }\n\n    const ArrayType = this.settings.defaultType;\n    let illegalArrayType = false;\n\n    if (this.doublePrecision) {\n      illegalArrayType = value.BYTES_PER_ELEMENT < 4;\n    }\n\n    if (illegalArrayType) {\n      throw new Error(\"Attribute \".concat(this.id, \" does not support \").concat(value.constructor.name));\n    }\n\n    if (!(value instanceof ArrayType) && this.settings.normalized && !('normalized' in opts)) {\n      _utils_log__WEBPACK_IMPORTED_MODULE_1__[\"default\"].warn(\"Attribute \".concat(this.id, \" is normalized\"))();\n    }\n  }\n\n  normalizeConstant(value) {\n    switch (this.settings.type) {\n      case 5120:\n        return new Float32Array(value).map(x => (x + 128) / 255 * 2 - 1);\n\n      case 5122:\n        return new Float32Array(value).map(x => (x + 32768) / 65535 * 2 - 1);\n\n      case 5121:\n        return new Float32Array(value).map(x => x / 255);\n\n      case 5123:\n        return new Float32Array(value).map(x => x / 65535);\n\n      default:\n        return value;\n    }\n  }\n\n  _normalizeValue(value, out, start) {\n    const {\n      defaultValue,\n      size\n    } = this.settings;\n\n    if (Number.isFinite(value)) {\n      out[start] = value;\n      return out;\n    }\n\n    if (!value) {\n      let i = size;\n\n      while (--i >= 0) {\n        out[start + i] = defaultValue[i];\n      }\n\n      return out;\n    }\n\n    switch (size) {\n      case 4:\n        out[start + 3] = Number.isFinite(value[3]) ? value[3] : defaultValue[3];\n\n      case 3:\n        out[start + 2] = Number.isFinite(value[2]) ? value[2] : defaultValue[2];\n\n      case 2:\n        out[start + 1] = Number.isFinite(value[1]) ? value[1] : defaultValue[1];\n\n      case 1:\n        out[start + 0] = Number.isFinite(value[0]) ? value[0] : defaultValue[0];\n        break;\n\n      default:\n        let i = size;\n\n        while (--i >= 0) {\n          out[start + i] = Number.isFinite(value[i]) ? value[i] : defaultValue[i];\n        }\n\n    }\n\n    return out;\n  }\n\n  _areValuesEqual(value1, value2) {\n    if (!value1 || !value2) {\n      return false;\n    }\n\n    const {\n      size\n    } = this;\n\n    for (let i = 0; i < size; i++) {\n      if (value1[i] !== value2[i]) {\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n}\n//# sourceMappingURL=data-column.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/lib/attribute/data-column.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/lib/attribute/gl-utils.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/lib/attribute/gl-utils.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   glArrayFromType: () => (/* binding */ glArrayFromType)\n/* harmony export */ });\nfunction glArrayFromType(glType) {\n  switch (glType) {\n    case 5126:\n      return Float32Array;\n\n    case 5130:\n      return Float64Array;\n\n    case 5123:\n    case 33635:\n    case 32819:\n    case 32820:\n      return Uint16Array;\n\n    case 5125:\n      return Uint32Array;\n\n    case 5121:\n      return Uint8ClampedArray;\n\n    case 5120:\n      return Int8Array;\n\n    case 5122:\n      return Int16Array;\n\n    case 5124:\n      return Int32Array;\n\n    default:\n      throw new Error('Unknown GL type');\n  }\n}\n//# sourceMappingURL=gl-utils.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/lib/attribute/gl-utils.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/lib/attribute/shader-attribute.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/lib/attribute/shader-attribute.js ***!
  \*******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ ShaderAttribute)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n\nclass ShaderAttribute {\n  constructor(dataColumn, opts) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"opts\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"source\", void 0);\n\n    this.opts = opts;\n    this.source = dataColumn;\n  }\n\n  get value() {\n    return this.source.value;\n  }\n\n  getValue() {\n    const buffer = this.source.getBuffer();\n    const accessor = this.getAccessor();\n\n    if (buffer) {\n      return [buffer, accessor];\n    }\n\n    const {\n      value\n    } = this.source;\n    const {\n      size\n    } = accessor;\n    let constantValue = value;\n\n    if (value && value.length !== size) {\n      constantValue = new Float32Array(size);\n      const index = accessor.elementOffset || 0;\n\n      for (let i = 0; i < size; ++i) {\n        constantValue[i] = value[index + i];\n      }\n    }\n\n    return constantValue;\n  }\n\n  getAccessor() {\n    return { ...this.source.getAccessor(),\n      ...this.opts\n    };\n  }\n\n}\n//# sourceMappingURL=shader-attribute.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/lib/attribute/shader-attribute.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/lib/constants.js":
/*!**************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/lib/constants.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   COORDINATE_SYSTEM: () => (/* binding */ COORDINATE_SYSTEM),\n/* harmony export */   EVENTS: () => (/* binding */ EVENTS),\n/* harmony export */   OPERATION: () => (/* binding */ OPERATION),\n/* harmony export */   PROJECTION_MODE: () => (/* binding */ PROJECTION_MODE),\n/* harmony export */   UNIT: () => (/* binding */ UNIT)\n/* harmony export */ });\n/* harmony import */ var _utils_log__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/log */ \"./node_modules/@deck.gl/core/dist/esm/utils/log.js\");\n\nconst COORDINATE_SYSTEM = {\n  DEFAULT: -1,\n  LNGLAT: 1,\n  METER_OFFSETS: 2,\n  LNGLAT_OFFSETS: 3,\n  CARTESIAN: 0\n};\nObject.defineProperty(COORDINATE_SYSTEM, 'IDENTITY', {\n  get: () => {\n    _utils_log__WEBPACK_IMPORTED_MODULE_0__[\"default\"].deprecated('COORDINATE_SYSTEM.IDENTITY', 'COORDINATE_SYSTEM.CARTESIAN')();\n    return 0;\n  }\n});\nconst PROJECTION_MODE = {\n  WEB_MERCATOR: 1,\n  GLOBE: 2,\n  WEB_MERCATOR_AUTO_OFFSET: 4,\n  IDENTITY: 0\n};\nconst UNIT = {\n  common: 0,\n  meters: 1,\n  pixels: 2\n};\nconst EVENTS = {\n  click: {\n    handler: 'onClick'\n  },\n  panstart: {\n    handler: 'onDragStart'\n  },\n  panmove: {\n    handler: 'onDrag'\n  },\n  panend: {\n    handler: 'onDragEnd'\n  }\n};\nconst OPERATION = {\n  DRAW: 'draw',\n  MASK: 'mask',\n  TERRAIN: 'terrain'\n};\n//# sourceMappingURL=constants.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/lib/constants.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/lib/deck-picker.js":
/*!****************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/lib/deck-picker.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ DeckPicker)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/framebuffer.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/texture-2d.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/copy-and-blit.js\");\n/* harmony import */ var _passes_pick_layers_pass__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../passes/pick-layers-pass */ \"./node_modules/@deck.gl/core/dist/esm/passes/pick-layers-pass.js\");\n/* harmony import */ var _picking_query_object__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./picking/query-object */ \"./node_modules/@deck.gl/core/dist/esm/lib/picking/query-object.js\");\n/* harmony import */ var _picking_pick_info__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./picking/pick-info */ \"./node_modules/@deck.gl/core/dist/esm/lib/picking/pick-info.js\");\n\n\n\n\n\nclass DeckPicker {\n  constructor(gl) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"gl\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"pickingFBO\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"depthFBO\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"pickLayersPass\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"layerFilter\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"lastPickedInfo\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_pickable\", true);\n\n    this.gl = gl;\n    this.pickLayersPass = new _passes_pick_layers_pass__WEBPACK_IMPORTED_MODULE_1__[\"default\"](gl);\n    this.lastPickedInfo = {\n      index: -1,\n      layerId: null,\n      info: null\n    };\n  }\n\n  setProps(props) {\n    if ('layerFilter' in props) {\n      this.layerFilter = props.layerFilter;\n    }\n\n    if ('_pickable' in props) {\n      this._pickable = props._pickable;\n    }\n  }\n\n  finalize() {\n    if (this.pickingFBO) {\n      this.pickingFBO.delete();\n    }\n\n    if (this.depthFBO) {\n      this.depthFBO.color.delete();\n      this.depthFBO.delete();\n    }\n  }\n\n  pickObject(opts) {\n    return this._pickClosestObject(opts);\n  }\n\n  pickObjects(opts) {\n    return this._pickVisibleObjects(opts);\n  }\n\n  getLastPickedObject({\n    x,\n    y,\n    layers,\n    viewports\n  }, lastPickedInfo = this.lastPickedInfo.info) {\n    const lastPickedLayerId = lastPickedInfo && lastPickedInfo.layer && lastPickedInfo.layer.id;\n    const lastPickedViewportId = lastPickedInfo && lastPickedInfo.viewport && lastPickedInfo.viewport.id;\n    const layer = lastPickedLayerId ? layers.find(l => l.id === lastPickedLayerId) : null;\n    const viewport = lastPickedViewportId && viewports.find(v => v.id === lastPickedViewportId) || viewports[0];\n    const coordinate = viewport && viewport.unproject([x - viewport.x, y - viewport.y]);\n    const info = {\n      x,\n      y,\n      viewport,\n      coordinate,\n      layer\n    };\n    return { ...lastPickedInfo,\n      ...info\n    };\n  }\n\n  _resizeBuffer() {\n    var _this$pickingFBO, _this$depthFBO;\n\n    const {\n      gl\n    } = this;\n\n    if (!this.pickingFBO) {\n      this.pickingFBO = new _luma_gl_core__WEBPACK_IMPORTED_MODULE_2__[\"default\"](gl);\n\n      if (_luma_gl_core__WEBPACK_IMPORTED_MODULE_2__[\"default\"].isSupported(gl, {\n        colorBufferFloat: true\n      })) {\n        const depthFBO = new _luma_gl_core__WEBPACK_IMPORTED_MODULE_2__[\"default\"](gl);\n        depthFBO.attach({\n          [36064]: new _luma_gl_core__WEBPACK_IMPORTED_MODULE_3__[\"default\"](gl, {\n            format: (0,_luma_gl_core__WEBPACK_IMPORTED_MODULE_4__.isWebGL2)(gl) ? 34836 : 6408,\n            type: 5126\n          })\n        });\n        this.depthFBO = depthFBO;\n      }\n    }\n\n    (_this$pickingFBO = this.pickingFBO) === null || _this$pickingFBO === void 0 ? void 0 : _this$pickingFBO.resize({\n      width: gl.canvas.width,\n      height: gl.canvas.height\n    });\n    (_this$depthFBO = this.depthFBO) === null || _this$depthFBO === void 0 ? void 0 : _this$depthFBO.resize({\n      width: gl.canvas.width,\n      height: gl.canvas.height\n    });\n  }\n\n  _getPickable(layers) {\n    if (this._pickable === false) {\n      return null;\n    }\n\n    const pickableLayers = layers.filter(layer => this.pickLayersPass.shouldDrawLayer(layer) && !layer.isComposite);\n    return pickableLayers.length ? pickableLayers : null;\n  }\n\n  _pickClosestObject({\n    layers,\n    views,\n    viewports,\n    x,\n    y,\n    radius = 0,\n    depth = 1,\n    mode = 'query',\n    unproject3D,\n    onViewportActive,\n    effects\n  }) {\n    const pickableLayers = this._getPickable(layers);\n\n    const pixelRatio = (0,_luma_gl_core__WEBPACK_IMPORTED_MODULE_4__.cssToDeviceRatio)(this.gl);\n\n    if (!pickableLayers) {\n      return {\n        result: [],\n        emptyInfo: (0,_picking_pick_info__WEBPACK_IMPORTED_MODULE_5__.getEmptyPickingInfo)({\n          viewports,\n          x,\n          y,\n          pixelRatio\n        })\n      };\n    }\n\n    this._resizeBuffer();\n\n    const devicePixelRange = (0,_luma_gl_core__WEBPACK_IMPORTED_MODULE_4__.cssToDevicePixels)(this.gl, [x, y], true);\n    const devicePixel = [devicePixelRange.x + Math.floor(devicePixelRange.width / 2), devicePixelRange.y + Math.floor(devicePixelRange.height / 2)];\n    const deviceRadius = Math.round(radius * pixelRatio);\n    const {\n      width,\n      height\n    } = this.pickingFBO;\n\n    const deviceRect = this._getPickingRect({\n      deviceX: devicePixel[0],\n      deviceY: devicePixel[1],\n      deviceRadius,\n      deviceWidth: width,\n      deviceHeight: height\n    });\n\n    const cullRect = {\n      x: x - radius,\n      y: y - radius,\n      width: radius * 2 + 1,\n      height: radius * 2 + 1\n    };\n    let infos;\n    const result = [];\n    const affectedLayers = new Set();\n\n    for (let i = 0; i < depth; i++) {\n      let pickInfo;\n\n      if (deviceRect) {\n        const pickedResult = this._drawAndSample({\n          layers: pickableLayers,\n          views,\n          viewports,\n          onViewportActive,\n          deviceRect,\n          cullRect,\n          effects,\n          pass: \"picking:\".concat(mode)\n        });\n\n        pickInfo = (0,_picking_query_object__WEBPACK_IMPORTED_MODULE_6__.getClosestObject)({ ...pickedResult,\n          deviceX: devicePixel[0],\n          deviceY: devicePixel[1],\n          deviceRadius,\n          deviceRect\n        });\n      } else {\n        pickInfo = {\n          pickedColor: null,\n          pickedObjectIndex: -1\n        };\n      }\n\n      let z;\n\n      if (pickInfo.pickedLayer && unproject3D && this.depthFBO) {\n        const {\n          pickedColors: pickedColors2\n        } = this._drawAndSample({\n          layers: [pickInfo.pickedLayer],\n          views,\n          viewports,\n          onViewportActive,\n          deviceRect: {\n            x: pickInfo.pickedX,\n            y: pickInfo.pickedY,\n            width: 1,\n            height: 1\n          },\n          cullRect,\n          effects,\n          pass: \"picking:\".concat(mode, \":z\")\n        }, true);\n\n        if (pickedColors2[3]) {\n          z = pickedColors2[0];\n        }\n      }\n\n      if (pickInfo.pickedLayer && i + 1 < depth) {\n        affectedLayers.add(pickInfo.pickedLayer);\n        pickInfo.pickedLayer.disablePickingIndex(pickInfo.pickedObjectIndex);\n      }\n\n      infos = (0,_picking_pick_info__WEBPACK_IMPORTED_MODULE_5__.processPickInfo)({\n        pickInfo,\n        lastPickedInfo: this.lastPickedInfo,\n        mode,\n        layers: pickableLayers,\n        viewports,\n        x,\n        y,\n        z,\n        pixelRatio\n      });\n\n      for (const info of infos.values()) {\n        if (info.layer) {\n          result.push(info);\n        }\n      }\n\n      if (!pickInfo.pickedColor) {\n        break;\n      }\n    }\n\n    for (const layer of affectedLayers) {\n      layer.restorePickingColors();\n    }\n\n    return {\n      result,\n      emptyInfo: infos.get(null)\n    };\n  }\n\n  _pickVisibleObjects({\n    layers,\n    views,\n    viewports,\n    x,\n    y,\n    width = 1,\n    height = 1,\n    mode = 'query',\n    maxObjects = null,\n    onViewportActive,\n    effects\n  }) {\n    const pickableLayers = this._getPickable(layers);\n\n    if (!pickableLayers) {\n      return [];\n    }\n\n    this._resizeBuffer();\n\n    const pixelRatio = (0,_luma_gl_core__WEBPACK_IMPORTED_MODULE_4__.cssToDeviceRatio)(this.gl);\n    const leftTop = (0,_luma_gl_core__WEBPACK_IMPORTED_MODULE_4__.cssToDevicePixels)(this.gl, [x, y], true);\n    const deviceLeft = leftTop.x;\n    const deviceTop = leftTop.y + leftTop.height;\n    const rightBottom = (0,_luma_gl_core__WEBPACK_IMPORTED_MODULE_4__.cssToDevicePixels)(this.gl, [x + width, y + height], true);\n    const deviceRight = rightBottom.x + rightBottom.width;\n    const deviceBottom = rightBottom.y;\n    const deviceRect = {\n      x: deviceLeft,\n      y: deviceBottom,\n      width: deviceRight - deviceLeft,\n      height: deviceTop - deviceBottom\n    };\n\n    const pickedResult = this._drawAndSample({\n      layers: pickableLayers,\n      views,\n      viewports,\n      onViewportActive,\n      deviceRect,\n      cullRect: {\n        x,\n        y,\n        width,\n        height\n      },\n      effects,\n      pass: \"picking:\".concat(mode)\n    });\n\n    const pickInfos = (0,_picking_query_object__WEBPACK_IMPORTED_MODULE_6__.getUniqueObjects)(pickedResult);\n    const uniqueInfos = new Map();\n    const isMaxObjects = Number.isFinite(maxObjects);\n\n    for (let i = 0; i < pickInfos.length; i++) {\n      var _info$object;\n\n      if (isMaxObjects && maxObjects && uniqueInfos.size >= maxObjects) {\n        break;\n      }\n\n      const pickInfo = pickInfos[i];\n      let info = {\n        color: pickInfo.pickedColor,\n        layer: null,\n        index: pickInfo.pickedObjectIndex,\n        picked: true,\n        x,\n        y,\n        pixelRatio\n      };\n      info = (0,_picking_pick_info__WEBPACK_IMPORTED_MODULE_5__.getLayerPickingInfo)({\n        layer: pickInfo.pickedLayer,\n        info,\n        mode\n      });\n      const pickedObjectKey = (_info$object = info.object) !== null && _info$object !== void 0 ? _info$object : \"\".concat(info.layer.id, \"[\").concat(info.index, \"]\");\n\n      if (!uniqueInfos.has(pickedObjectKey)) {\n        uniqueInfos.set(pickedObjectKey, info);\n      }\n    }\n\n    return Array.from(uniqueInfos.values());\n  }\n\n  _drawAndSample({\n    layers,\n    views,\n    viewports,\n    onViewportActive,\n    deviceRect,\n    cullRect,\n    effects,\n    pass\n  }, pickZ = false) {\n    const pickingFBO = pickZ ? this.depthFBO : this.pickingFBO;\n    const opts = {\n      layers,\n      layerFilter: this.layerFilter,\n      views,\n      viewports,\n      onViewportActive,\n      pickingFBO,\n      deviceRect,\n      cullRect,\n      effects,\n      pass,\n      pickZ,\n      preRenderStats: {}\n    };\n\n    for (const effect of effects) {\n      if (effect.useInPicking) {\n        opts.preRenderStats[effect.id] = effect.preRender(this.gl, opts);\n      }\n    }\n\n    const {\n      decodePickingColor\n    } = this.pickLayersPass.render(opts);\n    const {\n      x,\n      y,\n      width,\n      height\n    } = deviceRect;\n    const pickedColors = new (pickZ ? Float32Array : Uint8Array)(width * height * 4);\n    (0,_luma_gl_core__WEBPACK_IMPORTED_MODULE_7__.readPixelsToArray)(pickingFBO, {\n      sourceX: x,\n      sourceY: y,\n      sourceWidth: width,\n      sourceHeight: height,\n      target: pickedColors\n    });\n    return {\n      pickedColors,\n      decodePickingColor\n    };\n  }\n\n  _getPickingRect({\n    deviceX,\n    deviceY,\n    deviceRadius,\n    deviceWidth,\n    deviceHeight\n  }) {\n    const x = Math.max(0, deviceX - deviceRadius);\n    const y = Math.max(0, deviceY - deviceRadius);\n    const width = Math.min(deviceWidth, deviceX + deviceRadius + 1) - x;\n    const height = Math.min(deviceHeight, deviceY + deviceRadius + 1) - y;\n\n    if (width <= 0 || height <= 0) {\n      return null;\n    }\n\n    return {\n      x,\n      y,\n      width,\n      height\n    };\n  }\n\n}\n//# sourceMappingURL=deck-picker.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/lib/deck-picker.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/lib/deck-renderer.js":
/*!******************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/lib/deck-renderer.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ DeckRenderer)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _debug__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../debug */ \"./node_modules/@deck.gl/core/dist/esm/debug/index.js\");\n/* harmony import */ var _passes_draw_layers_pass__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../passes/draw-layers-pass */ \"./node_modules/@deck.gl/core/dist/esm/passes/draw-layers-pass.js\");\n/* harmony import */ var _passes_pick_layers_pass__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../passes/pick-layers-pass */ \"./node_modules/@deck.gl/core/dist/esm/passes/pick-layers-pass.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/framebuffer.js\");\n\n\n\n\n\nconst TRACE_RENDER_LAYERS = 'deckRenderer.renderLayers';\nclass DeckRenderer {\n  constructor(gl) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"gl\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"layerFilter\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"drawPickingColors\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"drawLayersPass\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"pickLayersPass\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"renderCount\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_needsRedraw\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"renderBuffers\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"lastPostProcessEffect\", void 0);\n\n    this.gl = gl;\n    this.layerFilter = null;\n    this.drawPickingColors = false;\n    this.drawLayersPass = new _passes_draw_layers_pass__WEBPACK_IMPORTED_MODULE_1__[\"default\"](gl);\n    this.pickLayersPass = new _passes_pick_layers_pass__WEBPACK_IMPORTED_MODULE_2__[\"default\"](gl);\n    this.renderCount = 0;\n    this._needsRedraw = 'Initial render';\n    this.renderBuffers = [];\n    this.lastPostProcessEffect = null;\n  }\n\n  setProps(props) {\n    if (this.layerFilter !== props.layerFilter) {\n      this.layerFilter = props.layerFilter;\n      this._needsRedraw = 'layerFilter changed';\n    }\n\n    if (this.drawPickingColors !== props.drawPickingColors) {\n      this.drawPickingColors = props.drawPickingColors;\n      this._needsRedraw = 'drawPickingColors changed';\n    }\n  }\n\n  renderLayers(opts) {\n    if (!opts.viewports.length) {\n      return;\n    }\n\n    const layerPass = this.drawPickingColors ? this.pickLayersPass : this.drawLayersPass;\n    const renderOpts = {\n      layerFilter: this.layerFilter,\n      isPicking: this.drawPickingColors,\n      ...opts,\n      target: opts.target || _luma_gl_core__WEBPACK_IMPORTED_MODULE_3__[\"default\"].getDefaultFramebuffer(this.gl)\n    };\n\n    if (renderOpts.effects) {\n      this._preRender(renderOpts.effects, renderOpts);\n    }\n\n    const outputBuffer = this.lastPostProcessEffect ? this.renderBuffers[0] : renderOpts.target;\n    const renderStats = layerPass.render({ ...renderOpts,\n      target: outputBuffer\n    });\n\n    if (renderOpts.effects) {\n      this._postRender(renderOpts.effects, renderOpts);\n    }\n\n    this.renderCount++;\n    (0,_debug__WEBPACK_IMPORTED_MODULE_4__[\"default\"])(TRACE_RENDER_LAYERS, this, renderStats, opts);\n  }\n\n  needsRedraw(opts = {\n    clearRedrawFlags: false\n  }) {\n    const redraw = this._needsRedraw;\n\n    if (opts.clearRedrawFlags) {\n      this._needsRedraw = false;\n    }\n\n    return redraw;\n  }\n\n  finalize() {\n    const {\n      renderBuffers\n    } = this;\n\n    for (const buffer of renderBuffers) {\n      buffer.delete();\n    }\n\n    renderBuffers.length = 0;\n  }\n\n  _preRender(effects, opts) {\n    this.lastPostProcessEffect = null;\n    opts.preRenderStats = opts.preRenderStats || {};\n\n    for (const effect of effects) {\n      opts.preRenderStats[effect.id] = effect.preRender(this.gl, opts);\n\n      if (effect.postRender) {\n        this.lastPostProcessEffect = effect.id;\n      }\n    }\n\n    if (this.lastPostProcessEffect) {\n      this._resizeRenderBuffers();\n    }\n  }\n\n  _resizeRenderBuffers() {\n    const {\n      renderBuffers\n    } = this;\n\n    if (renderBuffers.length === 0) {\n      renderBuffers.push(new _luma_gl_core__WEBPACK_IMPORTED_MODULE_3__[\"default\"](this.gl), new _luma_gl_core__WEBPACK_IMPORTED_MODULE_3__[\"default\"](this.gl));\n    }\n\n    for (const buffer of renderBuffers) {\n      buffer.resize();\n    }\n  }\n\n  _postRender(effects, opts) {\n    const {\n      renderBuffers\n    } = this;\n    const params = { ...opts,\n      inputBuffer: renderBuffers[0],\n      swapBuffer: renderBuffers[1],\n      target: null\n    };\n\n    for (const effect of effects) {\n      if (effect.postRender) {\n        if (effect.id === this.lastPostProcessEffect) {\n          params.target = opts.target;\n          effect.postRender(this.gl, params);\n          break;\n        }\n\n        const buffer = effect.postRender(this.gl, params);\n        params.inputBuffer = buffer;\n        params.swapBuffer = buffer === renderBuffers[0] ? renderBuffers[1] : renderBuffers[0];\n      }\n    }\n  }\n\n}\n//# sourceMappingURL=deck-renderer.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/lib/deck-renderer.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/lib/deck.js":
/*!*********************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/lib/deck.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Deck)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _layer_manager__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./layer-manager */ \"./node_modules/@deck.gl/core/dist/esm/lib/layer-manager.js\");\n/* harmony import */ var _view_manager__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./view-manager */ \"./node_modules/@deck.gl/core/dist/esm/lib/view-manager.js\");\n/* harmony import */ var _views_map_view__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../views/map-view */ \"./node_modules/@deck.gl/core/dist/esm/views/map-view.js\");\n/* harmony import */ var _effect_manager__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./effect-manager */ \"./node_modules/@deck.gl/core/dist/esm/lib/effect-manager.js\");\n/* harmony import */ var _deck_renderer__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./deck-renderer */ \"./node_modules/@deck.gl/core/dist/esm/lib/deck-renderer.js\");\n/* harmony import */ var _deck_picker__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./deck-picker */ \"./node_modules/@deck.gl/core/dist/esm/lib/deck-picker.js\");\n/* harmony import */ var _tooltip__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./tooltip */ \"./node_modules/@deck.gl/core/dist/esm/lib/tooltip.js\");\n/* harmony import */ var _utils_log__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/log */ \"./node_modules/@deck.gl/core/dist/esm/utils/log.js\");\n/* harmony import */ var _utils_deep_equal__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../utils/deep-equal */ \"./node_modules/@deck.gl/core/dist/esm/utils/deep-equal.js\");\n/* harmony import */ var _utils_typed_array_manager__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../utils/typed-array-manager */ \"./node_modules/@deck.gl/core/dist/esm/utils/typed-array-manager.js\");\n/* harmony import */ var _init__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ./init */ \"./node_modules/@deck.gl/core/dist/esm/lib/init.js\");\n/* harmony import */ var _probe_gl_env__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! @probe.gl/env */ \"./node_modules/@probe.gl/env/dist/esm/lib/get-browser.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/engine/dist/esm/lib/animation-loop.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/engine/dist/esm/animation/timeline.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/webgl/dist/esm/init.js\");\n/* harmony import */ var _probe_gl_stats__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @probe.gl/stats */ \"./node_modules/@probe.gl/stats/dist/esm/index.js\");\n/* harmony import */ var mjolnir_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! mjolnir.js */ \"./node_modules/mjolnir.js/dist/esm/index.js\");\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../utils/assert */ \"./node_modules/@deck.gl/core/dist/esm/utils/assert.js\");\n/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./constants */ \"./node_modules/@deck.gl/core/dist/esm/lib/constants.js\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfunction noop() {}\n\nconst getCursor = ({\n  isDragging\n}) => isDragging ? 'grabbing' : 'grab';\n\nconst defaultProps = {\n  id: '',\n  width: '100%',\n  height: '100%',\n  style: null,\n  viewState: null,\n  initialViewState: null,\n  pickingRadius: 0,\n  layerFilter: null,\n  glOptions: {},\n  parameters: {},\n  parent: null,\n  gl: null,\n  canvas: null,\n  layers: [],\n  effects: [],\n  views: null,\n  controller: null,\n  useDevicePixels: true,\n  touchAction: 'none',\n  eventRecognizerOptions: {},\n  _framebuffer: null,\n  _animate: false,\n  _pickable: true,\n  _typedArrayManagerProps: {},\n  _customRender: null,\n  onWebGLInitialized: noop,\n  onResize: noop,\n  onViewStateChange: noop,\n  onInteractionStateChange: noop,\n  onBeforeRender: noop,\n  onAfterRender: noop,\n  onLoad: noop,\n  onError: error => _utils_log__WEBPACK_IMPORTED_MODULE_3__[\"default\"].error(error.message, error.cause)(),\n  onHover: null,\n  onClick: null,\n  onDragStart: null,\n  onDrag: null,\n  onDragEnd: null,\n  _onMetrics: null,\n  getCursor,\n  getTooltip: null,\n  debug: false,\n  drawPickingColors: false\n};\nclass Deck {\n  constructor(props) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"props\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"width\", 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"height\", 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"userData\", {});\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"canvas\", null);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"viewManager\", null);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"layerManager\", null);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"effectManager\", null);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"deckRenderer\", null);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"deckPicker\", null);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"eventManager\", null);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"tooltip\", null);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"metrics\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"animationLoop\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"stats\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"viewState\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"cursorState\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_needsRedraw\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_pickRequest\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_lastPointerDownInfo\", null);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_metricsCounter\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_onPointerMove\", event => {\n      const {\n        _pickRequest\n      } = this;\n\n      if (event.type === 'pointerleave') {\n        _pickRequest.x = -1;\n        _pickRequest.y = -1;\n        _pickRequest.radius = 0;\n      } else if (event.leftButton || event.rightButton) {\n        return;\n      } else {\n        const pos = event.offsetCenter;\n\n        if (!pos) {\n          return;\n        }\n\n        _pickRequest.x = pos.x;\n        _pickRequest.y = pos.y;\n        _pickRequest.radius = this.props.pickingRadius;\n      }\n\n      if (this.layerManager) {\n        this.layerManager.context.mousePosition = {\n          x: _pickRequest.x,\n          y: _pickRequest.y\n        };\n      }\n\n      _pickRequest.event = event;\n    });\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_onEvent\", event => {\n      const eventOptions = _constants__WEBPACK_IMPORTED_MODULE_4__.EVENTS[event.type];\n      const pos = event.offsetCenter;\n\n      if (!eventOptions || !pos || !this.layerManager) {\n        return;\n      }\n\n      const layers = this.layerManager.getLayers();\n      const info = this.deckPicker.getLastPickedObject({\n        x: pos.x,\n        y: pos.y,\n        layers,\n        viewports: this.getViewports(pos)\n      }, this._lastPointerDownInfo);\n      const {\n        layer\n      } = info;\n      const layerHandler = layer && (layer[eventOptions.handler] || layer.props[eventOptions.handler]);\n      const rootHandler = this.props[eventOptions.handler];\n      let handled = false;\n\n      if (layerHandler) {\n        handled = layerHandler.call(layer, info, event);\n      }\n\n      if (!handled && rootHandler) {\n        rootHandler(info, event);\n      }\n    });\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_onPointerDown\", event => {\n      const pos = event.offsetCenter;\n\n      const pickedInfo = this._pick('pickObject', 'pickObject Time', {\n        x: pos.x,\n        y: pos.y,\n        radius: this.props.pickingRadius\n      });\n\n      this._lastPointerDownInfo = pickedInfo.result[0] || pickedInfo.emptyInfo;\n    });\n\n    this.props = { ...defaultProps,\n      ...props\n    };\n    props = this.props;\n    this._needsRedraw = 'Initial render';\n    this._pickRequest = {\n      mode: 'hover',\n      x: -1,\n      y: -1,\n      radius: 0,\n      event: null\n    };\n    this.cursorState = {\n      isHovering: false,\n      isDragging: false\n    };\n\n    if (props.viewState && props.initialViewState) {\n      _utils_log__WEBPACK_IMPORTED_MODULE_3__[\"default\"].warn('View state tracking is disabled. Use either `initialViewState` for auto update or `viewState` for manual update.')();\n    }\n\n    if ((0,_probe_gl_env__WEBPACK_IMPORTED_MODULE_5__[\"default\"])() === 'IE') {\n      _utils_log__WEBPACK_IMPORTED_MODULE_3__[\"default\"].warn('IE 11 is not supported')();\n    }\n\n    this.viewState = props.initialViewState;\n\n    if (!props.gl) {\n      if (typeof document !== 'undefined') {\n        this.canvas = this._createCanvas(props);\n      }\n    }\n\n    this.animationLoop = this._createAnimationLoop(props);\n    this.stats = new _probe_gl_stats__WEBPACK_IMPORTED_MODULE_1__.Stats({\n      id: 'deck.gl'\n    });\n    this.metrics = {\n      fps: 0,\n      setPropsTime: 0,\n      updateAttributesTime: 0,\n      framesRedrawn: 0,\n      pickTime: 0,\n      pickCount: 0,\n      gpuTime: 0,\n      gpuTimePerFrame: 0,\n      cpuTime: 0,\n      cpuTimePerFrame: 0,\n      bufferMemory: 0,\n      textureMemory: 0,\n      renderbufferMemory: 0,\n      gpuMemory: 0\n    };\n    this._metricsCounter = 0;\n    this.setProps(props);\n\n    if (props._typedArrayManagerProps) {\n      _utils_typed_array_manager__WEBPACK_IMPORTED_MODULE_6__[\"default\"].setOptions(props._typedArrayManagerProps);\n    }\n\n    this.animationLoop.start();\n  }\n\n  finalize() {\n    var _this$animationLoop, _this$layerManager, _this$viewManager, _this$effectManager, _this$deckRenderer, _this$deckPicker, _this$eventManager, _this$tooltip;\n\n    (_this$animationLoop = this.animationLoop) === null || _this$animationLoop === void 0 ? void 0 : _this$animationLoop.stop();\n    this.animationLoop = null;\n    this._lastPointerDownInfo = null;\n    (_this$layerManager = this.layerManager) === null || _this$layerManager === void 0 ? void 0 : _this$layerManager.finalize();\n    this.layerManager = null;\n    (_this$viewManager = this.viewManager) === null || _this$viewManager === void 0 ? void 0 : _this$viewManager.finalize();\n    this.viewManager = null;\n    (_this$effectManager = this.effectManager) === null || _this$effectManager === void 0 ? void 0 : _this$effectManager.finalize();\n    this.effectManager = null;\n    (_this$deckRenderer = this.deckRenderer) === null || _this$deckRenderer === void 0 ? void 0 : _this$deckRenderer.finalize();\n    this.deckRenderer = null;\n    (_this$deckPicker = this.deckPicker) === null || _this$deckPicker === void 0 ? void 0 : _this$deckPicker.finalize();\n    this.deckPicker = null;\n    (_this$eventManager = this.eventManager) === null || _this$eventManager === void 0 ? void 0 : _this$eventManager.destroy();\n    this.eventManager = null;\n    (_this$tooltip = this.tooltip) === null || _this$tooltip === void 0 ? void 0 : _this$tooltip.remove();\n    this.tooltip = null;\n\n    if (!this.props.canvas && !this.props.gl && this.canvas) {\n      var _this$canvas$parentEl;\n\n      (_this$canvas$parentEl = this.canvas.parentElement) === null || _this$canvas$parentEl === void 0 ? void 0 : _this$canvas$parentEl.removeChild(this.canvas);\n      this.canvas = null;\n    }\n  }\n\n  setProps(props) {\n    this.stats.get('setProps Time').timeStart();\n\n    if ('onLayerHover' in props) {\n      _utils_log__WEBPACK_IMPORTED_MODULE_3__[\"default\"].removed('onLayerHover', 'onHover')();\n    }\n\n    if ('onLayerClick' in props) {\n      _utils_log__WEBPACK_IMPORTED_MODULE_3__[\"default\"].removed('onLayerClick', 'onClick')();\n    }\n\n    if (props.initialViewState && !(0,_utils_deep_equal__WEBPACK_IMPORTED_MODULE_7__.deepEqual)(this.props.initialViewState, props.initialViewState, 3)) {\n      this.viewState = props.initialViewState;\n    }\n\n    Object.assign(this.props, props);\n\n    this._setCanvasSize(this.props);\n\n    const resolvedProps = Object.create(this.props);\n    Object.assign(resolvedProps, {\n      views: this._getViews(),\n      width: this.width,\n      height: this.height,\n      viewState: this._getViewState()\n    });\n    this.animationLoop.setProps(resolvedProps);\n\n    if (this.layerManager) {\n      this.viewManager.setProps(resolvedProps);\n      this.layerManager.activateViewport(this.getViewports()[0]);\n      this.layerManager.setProps(resolvedProps);\n      this.effectManager.setProps(resolvedProps);\n      this.deckRenderer.setProps(resolvedProps);\n      this.deckPicker.setProps(resolvedProps);\n    }\n\n    this.stats.get('setProps Time').timeEnd();\n  }\n\n  needsRedraw(opts = {\n    clearRedrawFlags: false\n  }) {\n    if (!this.layerManager) {\n      return false;\n    }\n\n    if (this.props._animate) {\n      return 'Deck._animate';\n    }\n\n    let redraw = this._needsRedraw;\n\n    if (opts.clearRedrawFlags) {\n      this._needsRedraw = false;\n    }\n\n    const viewManagerNeedsRedraw = this.viewManager.needsRedraw(opts);\n    const layerManagerNeedsRedraw = this.layerManager.needsRedraw(opts);\n    const effectManagerNeedsRedraw = this.effectManager.needsRedraw(opts);\n    const deckRendererNeedsRedraw = this.deckRenderer.needsRedraw(opts);\n    redraw = redraw || viewManagerNeedsRedraw || layerManagerNeedsRedraw || effectManagerNeedsRedraw || deckRendererNeedsRedraw;\n    return redraw;\n  }\n\n  redraw(reason) {\n    if (!this.layerManager) {\n      return;\n    }\n\n    let redrawReason = this.needsRedraw({\n      clearRedrawFlags: true\n    });\n    redrawReason = reason || redrawReason;\n\n    if (!redrawReason) {\n      return;\n    }\n\n    this.stats.get('Redraw Count').incrementCount();\n\n    if (this.props._customRender) {\n      this.props._customRender(redrawReason);\n    } else {\n      this._drawLayers(redrawReason);\n    }\n  }\n\n  get isInitialized() {\n    return this.viewManager !== null;\n  }\n\n  getViews() {\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_8__[\"default\"])(this.viewManager);\n    return this.viewManager.views;\n  }\n\n  getViewports(rect) {\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_8__[\"default\"])(this.viewManager);\n    return this.viewManager.getViewports(rect);\n  }\n\n  getCanvas() {\n    return this.canvas;\n  }\n\n  pickObject(opts) {\n    const infos = this._pick('pickObject', 'pickObject Time', opts).result;\n\n    return infos.length ? infos[0] : null;\n  }\n\n  pickMultipleObjects(opts) {\n    opts.depth = opts.depth || 10;\n    return this._pick('pickObject', 'pickMultipleObjects Time', opts).result;\n  }\n\n  pickObjects(opts) {\n    return this._pick('pickObjects', 'pickObjects Time', opts);\n  }\n\n  _addResources(resources, forceUpdate = false) {\n    for (const id in resources) {\n      this.layerManager.resourceManager.add({\n        resourceId: id,\n        data: resources[id],\n        forceUpdate\n      });\n    }\n  }\n\n  _removeResources(resourceIds) {\n    for (const id of resourceIds) {\n      this.layerManager.resourceManager.remove(id);\n    }\n  }\n\n  _addDefaultEffect(effect) {\n    this.effectManager.addDefaultEffect(effect);\n  }\n\n  _pick(method, statKey, opts) {\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_8__[\"default\"])(this.deckPicker);\n    const {\n      stats\n    } = this;\n    stats.get('Pick Count').incrementCount();\n    stats.get(statKey).timeStart();\n    const infos = this.deckPicker[method]({\n      layers: this.layerManager.getLayers(opts),\n      views: this.viewManager.getViews(),\n      viewports: this.getViewports(opts),\n      onViewportActive: this.layerManager.activateViewport,\n      effects: this.effectManager.getEffects(),\n      ...opts\n    });\n    stats.get(statKey).timeEnd();\n    return infos;\n  }\n\n  _createCanvas(props) {\n    let canvas = props.canvas;\n\n    if (typeof canvas === 'string') {\n      canvas = document.getElementById(canvas);\n      (0,_utils_assert__WEBPACK_IMPORTED_MODULE_8__[\"default\"])(canvas);\n    }\n\n    if (!canvas) {\n      canvas = document.createElement('canvas');\n      canvas.id = props.id || 'deckgl-overlay';\n      const parent = props.parent || document.body;\n      parent.appendChild(canvas);\n    }\n\n    Object.assign(canvas.style, props.style);\n    return canvas;\n  }\n\n  _setCanvasSize(props) {\n    if (!this.canvas) {\n      return;\n    }\n\n    const {\n      width,\n      height\n    } = props;\n\n    if (width || width === 0) {\n      const cssWidth = Number.isFinite(width) ? \"\".concat(width, \"px\") : width;\n      this.canvas.style.width = cssWidth;\n    }\n\n    if (height || height === 0) {\n      var _props$style;\n\n      const cssHeight = Number.isFinite(height) ? \"\".concat(height, \"px\") : height;\n      this.canvas.style.position = ((_props$style = props.style) === null || _props$style === void 0 ? void 0 : _props$style.position) || 'absolute';\n      this.canvas.style.height = cssHeight;\n    }\n  }\n\n  _updateCanvasSize() {\n    var _canvas$clientWidth, _canvas$clientHeight;\n\n    const {\n      canvas\n    } = this;\n\n    if (!canvas) {\n      return;\n    }\n\n    const newWidth = (_canvas$clientWidth = canvas.clientWidth) !== null && _canvas$clientWidth !== void 0 ? _canvas$clientWidth : canvas.width;\n    const newHeight = (_canvas$clientHeight = canvas.clientHeight) !== null && _canvas$clientHeight !== void 0 ? _canvas$clientHeight : canvas.height;\n\n    if (newWidth !== this.width || newHeight !== this.height) {\n      var _this$viewManager2, _this$layerManager2;\n\n      this.width = newWidth;\n      this.height = newHeight;\n      (_this$viewManager2 = this.viewManager) === null || _this$viewManager2 === void 0 ? void 0 : _this$viewManager2.setProps({\n        width: newWidth,\n        height: newHeight\n      });\n      (_this$layerManager2 = this.layerManager) === null || _this$layerManager2 === void 0 ? void 0 : _this$layerManager2.activateViewport(this.getViewports()[0]);\n      this.props.onResize({\n        width: newWidth,\n        height: newHeight\n      });\n    }\n  }\n\n  _createAnimationLoop(props) {\n    const {\n      width,\n      height,\n      gl,\n      glOptions,\n      debug,\n      onError,\n      onBeforeRender,\n      onAfterRender,\n      useDevicePixels\n    } = props;\n    return new _luma_gl_core__WEBPACK_IMPORTED_MODULE_9__[\"default\"]({\n      width,\n      height,\n      useDevicePixels,\n      autoResizeDrawingBuffer: !gl,\n      autoResizeViewport: false,\n      gl,\n      onCreateContext: opts => (0,_luma_gl_core__WEBPACK_IMPORTED_MODULE_10__.createGLContext)({ ...glOptions,\n        ...opts,\n        canvas: this.canvas,\n        debug,\n        onContextLost: () => this._onContextLost()\n      }),\n      onInitialize: context => this._setGLContext(context.gl),\n      onRender: this._onRenderFrame.bind(this),\n      onBeforeRender,\n      onAfterRender,\n      onError\n    });\n  }\n\n  _getViewState() {\n    return this.props.viewState || this.viewState;\n  }\n\n  _getViews() {\n    let views = this.props.views || [new _views_map_view__WEBPACK_IMPORTED_MODULE_11__[\"default\"]({\n      id: 'default-view'\n    })];\n    views = Array.isArray(views) ? views : [views];\n\n    if (views.length && this.props.controller) {\n      views[0].props.controller = this.props.controller;\n    }\n\n    return views;\n  }\n\n  _onContextLost() {\n    const {\n      onError\n    } = this.props;\n\n    if (this.animationLoop && onError) {\n      onError(new Error('WebGL context is lost'));\n    }\n  }\n\n  _pickAndCallback() {\n    const {\n      _pickRequest\n    } = this;\n\n    if (_pickRequest.event) {\n      const {\n        result,\n        emptyInfo\n      } = this._pick('pickObject', 'pickObject Time', _pickRequest);\n\n      this.cursorState.isHovering = result.length > 0;\n      let pickedInfo = emptyInfo;\n      let handled = false;\n\n      for (const info of result) {\n        var _info$layer;\n\n        pickedInfo = info;\n        handled = ((_info$layer = info.layer) === null || _info$layer === void 0 ? void 0 : _info$layer.onHover(info, _pickRequest.event)) || handled;\n      }\n\n      if (!handled && this.props.onHover) {\n        this.props.onHover(pickedInfo, _pickRequest.event);\n      }\n\n      if (this.props.getTooltip && this.tooltip) {\n        const displayInfo = this.props.getTooltip(pickedInfo);\n        this.tooltip.setTooltip(displayInfo, pickedInfo.x, pickedInfo.y);\n      }\n\n      _pickRequest.event = null;\n    }\n  }\n\n  _updateCursor() {\n    const container = this.props.parent || this.canvas;\n\n    if (container) {\n      container.style.cursor = this.props.getCursor(this.cursorState);\n    }\n  }\n\n  _setGLContext(gl) {\n    if (this.layerManager) {\n      return;\n    }\n\n    if (!this.canvas) {\n      this.canvas = gl.canvas;\n      (0,_luma_gl_core__WEBPACK_IMPORTED_MODULE_10__.instrumentGLContext)(gl, {\n        enable: true,\n        copyState: true\n      });\n    }\n\n    this.tooltip = new _tooltip__WEBPACK_IMPORTED_MODULE_12__[\"default\"](this.canvas);\n    (0,_luma_gl_core__WEBPACK_IMPORTED_MODULE_10__.setParameters)(gl, {\n      blend: true,\n      blendFunc: [770, 771, 1, 771],\n      polygonOffsetFill: true,\n      depthTest: true,\n      depthFunc: 515\n    });\n    this.props.onWebGLInitialized(gl);\n    const timeline = new _luma_gl_core__WEBPACK_IMPORTED_MODULE_13__.Timeline();\n    timeline.play();\n    this.animationLoop.attachTimeline(timeline);\n    this.eventManager = new mjolnir_js__WEBPACK_IMPORTED_MODULE_2__.EventManager(this.props.parent || gl.canvas, {\n      touchAction: this.props.touchAction,\n      recognizerOptions: this.props.eventRecognizerOptions,\n      events: {\n        pointerdown: this._onPointerDown,\n        pointermove: this._onPointerMove,\n        pointerleave: this._onPointerMove\n      }\n    });\n\n    for (const eventType in _constants__WEBPACK_IMPORTED_MODULE_4__.EVENTS) {\n      this.eventManager.on(eventType, this._onEvent);\n    }\n\n    this.viewManager = new _view_manager__WEBPACK_IMPORTED_MODULE_14__[\"default\"]({\n      timeline,\n      eventManager: this.eventManager,\n      onViewStateChange: this._onViewStateChange.bind(this),\n      onInteractionStateChange: this._onInteractionStateChange.bind(this),\n      views: this._getViews(),\n      viewState: this._getViewState(),\n      width: this.width,\n      height: this.height\n    });\n    const viewport = this.viewManager.getViewports()[0];\n    this.layerManager = new _layer_manager__WEBPACK_IMPORTED_MODULE_15__[\"default\"](gl, {\n      deck: this,\n      stats: this.stats,\n      viewport,\n      timeline\n    });\n    this.effectManager = new _effect_manager__WEBPACK_IMPORTED_MODULE_16__[\"default\"]();\n    this.deckRenderer = new _deck_renderer__WEBPACK_IMPORTED_MODULE_17__[\"default\"](gl);\n    this.deckPicker = new _deck_picker__WEBPACK_IMPORTED_MODULE_18__[\"default\"](gl);\n    this.setProps(this.props);\n\n    this._updateCanvasSize();\n\n    this.props.onLoad();\n  }\n\n  _drawLayers(redrawReason, renderOptions) {\n    const {\n      gl\n    } = this.layerManager.context;\n    (0,_luma_gl_core__WEBPACK_IMPORTED_MODULE_10__.setParameters)(gl, this.props.parameters);\n    this.props.onBeforeRender({\n      gl\n    });\n    this.deckRenderer.renderLayers({\n      target: this.props._framebuffer,\n      layers: this.layerManager.getLayers(),\n      viewports: this.viewManager.getViewports(),\n      onViewportActive: this.layerManager.activateViewport,\n      views: this.viewManager.getViews(),\n      pass: 'screen',\n      effects: this.effectManager.getEffects(),\n      ...renderOptions\n    });\n    this.props.onAfterRender({\n      gl\n    });\n  }\n\n  _onRenderFrame(animationProps) {\n    this._getFrameStats();\n\n    if (this._metricsCounter++ % 60 === 0) {\n      this._getMetrics();\n\n      this.stats.reset();\n      _utils_log__WEBPACK_IMPORTED_MODULE_3__[\"default\"].table(4, this.metrics)();\n\n      if (this.props._onMetrics) {\n        this.props._onMetrics(this.metrics);\n      }\n    }\n\n    this._updateCanvasSize();\n\n    this._updateCursor();\n\n    if (this.tooltip.isVisible && this.viewManager.needsRedraw()) {\n      this.tooltip.setTooltip(null);\n    }\n\n    this.layerManager.updateLayers();\n\n    this._pickAndCallback();\n\n    this.redraw();\n\n    if (this.viewManager) {\n      this.viewManager.updateViewStates();\n    }\n  }\n\n  _onViewStateChange(params) {\n    const viewState = this.props.onViewStateChange(params) || params.viewState;\n\n    if (this.viewState) {\n      this.viewState = { ...this.viewState,\n        [params.viewId]: viewState\n      };\n\n      if (!this.props.viewState) {\n        if (this.viewManager) {\n          this.viewManager.setProps({\n            viewState: this.viewState\n          });\n        }\n      }\n    }\n  }\n\n  _onInteractionStateChange(interactionState) {\n    this.cursorState.isDragging = interactionState.isDragging || false;\n    this.props.onInteractionStateChange(interactionState);\n  }\n\n  _getFrameStats() {\n    const {\n      stats\n    } = this;\n    stats.get('frameRate').timeEnd();\n    stats.get('frameRate').timeStart();\n    const animationLoopStats = this.animationLoop.stats;\n    stats.get('GPU Time').addTime(animationLoopStats.get('GPU Time').lastTiming);\n    stats.get('CPU Time').addTime(animationLoopStats.get('CPU Time').lastTiming);\n  }\n\n  _getMetrics() {\n    const {\n      metrics,\n      stats\n    } = this;\n    metrics.fps = stats.get('frameRate').getHz();\n    metrics.setPropsTime = stats.get('setProps Time').time;\n    metrics.updateAttributesTime = stats.get('Update Attributes').time;\n    metrics.framesRedrawn = stats.get('Redraw Count').count;\n    metrics.pickTime = stats.get('pickObject Time').time + stats.get('pickMultipleObjects Time').time + stats.get('pickObjects Time').time;\n    metrics.pickCount = stats.get('Pick Count').count;\n    metrics.gpuTime = stats.get('GPU Time').time;\n    metrics.cpuTime = stats.get('CPU Time').time;\n    metrics.gpuTimePerFrame = stats.get('GPU Time').getAverageTime();\n    metrics.cpuTimePerFrame = stats.get('CPU Time').getAverageTime();\n    const memoryStats = _luma_gl_core__WEBPACK_IMPORTED_MODULE_19__.lumaStats.get('Memory Usage');\n    metrics.bufferMemory = memoryStats.get('Buffer Memory').count;\n    metrics.textureMemory = memoryStats.get('Texture Memory').count;\n    metrics.renderbufferMemory = memoryStats.get('Renderbuffer Memory').count;\n    metrics.gpuMemory = memoryStats.get('GPU Memory').count;\n  }\n\n}\n\n(0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(Deck, \"defaultProps\", defaultProps);\n\n(0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(Deck, \"VERSION\", _init__WEBPACK_IMPORTED_MODULE_20__.VERSION);\n//# sourceMappingURL=deck.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/lib/deck.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/lib/effect-manager.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/lib/effect-manager.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ EffectManager)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _utils_deep_equal__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/deep-equal */ \"./node_modules/@deck.gl/core/dist/esm/utils/deep-equal.js\");\n/* harmony import */ var _effects_lighting_lighting_effect__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../effects/lighting/lighting-effect */ \"./node_modules/@deck.gl/core/dist/esm/effects/lighting/lighting-effect.js\");\n\n\n\nconst DEFAULT_LIGHTING_EFFECT = new _effects_lighting_lighting_effect__WEBPACK_IMPORTED_MODULE_1__[\"default\"]();\n\nfunction compareEffects(e1, e2) {\n  var _e1$order, _e2$order;\n\n  const o1 = (_e1$order = e1.order) !== null && _e1$order !== void 0 ? _e1$order : Infinity;\n  const o2 = (_e2$order = e2.order) !== null && _e2$order !== void 0 ? _e2$order : Infinity;\n  return o1 - o2;\n}\n\nclass EffectManager {\n  constructor() {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"effects\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_resolvedEffects\", []);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_defaultEffects\", []);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_needsRedraw\", void 0);\n\n    this.effects = [];\n    this._needsRedraw = 'Initial render';\n\n    this._setEffects([]);\n  }\n\n  addDefaultEffect(effect) {\n    const defaultEffects = this._defaultEffects;\n\n    if (!defaultEffects.find(e => e.id === effect.id)) {\n      const index = defaultEffects.findIndex(e => compareEffects(e, effect) > 0);\n\n      if (index < 0) {\n        defaultEffects.push(effect);\n      } else {\n        defaultEffects.splice(index, 0, effect);\n      }\n\n      this._setEffects(this.effects);\n    }\n  }\n\n  setProps(props) {\n    if ('effects' in props) {\n      if (!(0,_utils_deep_equal__WEBPACK_IMPORTED_MODULE_2__.deepEqual)(props.effects, this.effects, 1)) {\n        this._setEffects(props.effects);\n      }\n    }\n  }\n\n  needsRedraw(opts = {\n    clearRedrawFlags: false\n  }) {\n    const redraw = this._needsRedraw;\n\n    if (opts.clearRedrawFlags) {\n      this._needsRedraw = false;\n    }\n\n    return redraw;\n  }\n\n  getEffects() {\n    return this._resolvedEffects;\n  }\n\n  _setEffects(effects) {\n    const oldEffectsMap = {};\n\n    for (const effect of this.effects) {\n      oldEffectsMap[effect.id] = effect;\n    }\n\n    const nextEffects = [];\n\n    for (const effect of effects) {\n      const oldEffect = oldEffectsMap[effect.id];\n\n      if (oldEffect && oldEffect !== effect) {\n        if (oldEffect.setProps) {\n          oldEffect.setProps(effect.props);\n          nextEffects.push(oldEffect);\n        } else {\n          oldEffect.cleanup();\n          nextEffects.push(effect);\n        }\n      } else {\n        nextEffects.push(effect);\n      }\n\n      delete oldEffectsMap[effect.id];\n    }\n\n    for (const removedEffectId in oldEffectsMap) {\n      oldEffectsMap[removedEffectId].cleanup();\n    }\n\n    this.effects = nextEffects;\n    this._resolvedEffects = nextEffects.concat(this._defaultEffects);\n\n    if (!effects.some(effect => effect instanceof _effects_lighting_lighting_effect__WEBPACK_IMPORTED_MODULE_1__[\"default\"])) {\n      this._resolvedEffects.push(DEFAULT_LIGHTING_EFFECT);\n    }\n\n    this._needsRedraw = 'effects changed';\n  }\n\n  finalize() {\n    for (const effect of this._resolvedEffects) {\n      effect.cleanup();\n    }\n\n    this.effects.length = 0;\n    this._resolvedEffects.length = 0;\n    this._defaultEffects.length = 0;\n  }\n\n}\n//# sourceMappingURL=effect-manager.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/lib/effect-manager.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/lib/init.js":
/*!*********************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/lib/init.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   VERSION: () => (/* binding */ VERSION)\n/* harmony export */ });\n/* harmony import */ var _loaders_gl_core__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @loaders.gl/core */ \"./node_modules/@loaders.gl/core/dist/esm/lib/api/register-loaders.js\");\n/* harmony import */ var _loaders_gl_images__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! @loaders.gl/images */ \"./node_modules/@loaders.gl/images/dist/esm/image-loader.js\");\n/* harmony import */ var _utils_log__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/log */ \"./node_modules/@deck.gl/core/dist/esm/utils/log.js\");\n/* harmony import */ var _debug__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../debug */ \"./node_modules/@deck.gl/core/dist/esm/debug/index.js\");\n/* harmony import */ var _utils_json_loader__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/json-loader */ \"./node_modules/@deck.gl/core/dist/esm/utils/json-loader.js\");\n\n\n\n\n\n\nfunction checkVersion() {\n  const version =  true ? \"8.9.35\" : 0;\n  const existingVersion = globalThis.deck && globalThis.deck.VERSION;\n\n  if (existingVersion && existingVersion !== version) {\n    throw new Error(\"deck.gl - multiple versions detected: \".concat(existingVersion, \" vs \").concat(version));\n  }\n\n  if (!existingVersion) {\n    _utils_log__WEBPACK_IMPORTED_MODULE_0__[\"default\"].log(1, \"deck.gl \".concat(version))();\n    globalThis.deck = { ...globalThis.deck,\n      VERSION: version,\n      version,\n      log: _utils_log__WEBPACK_IMPORTED_MODULE_0__[\"default\"],\n      _registerLoggers: _debug__WEBPACK_IMPORTED_MODULE_1__.register\n    };\n    (0,_loaders_gl_core__WEBPACK_IMPORTED_MODULE_2__.registerLoaders)([_utils_json_loader__WEBPACK_IMPORTED_MODULE_3__[\"default\"], [_loaders_gl_images__WEBPACK_IMPORTED_MODULE_4__.ImageLoader, {\n      imagebitmap: {\n        premultiplyAlpha: 'none'\n      }\n    }]]);\n  }\n\n  return version;\n}\n\nconst VERSION = checkVersion();\n//# sourceMappingURL=init.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/lib/init.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/lib/layer-manager.js":
/*!******************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/lib/layer-manager.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ LayerManager)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/engine/dist/esm/animation/timeline.js\");\n/* harmony import */ var _lifecycle_constants__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../lifecycle/constants */ \"./node_modules/@deck.gl/core/dist/esm/lifecycle/constants.js\");\n/* harmony import */ var _utils_log__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../utils/log */ \"./node_modules/@deck.gl/core/dist/esm/utils/log.js\");\n/* harmony import */ var _debug__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../debug */ \"./node_modules/@deck.gl/core/dist/esm/debug/index.js\");\n/* harmony import */ var _utils_flatten__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../utils/flatten */ \"./node_modules/@deck.gl/core/dist/esm/utils/flatten.js\");\n/* harmony import */ var _probe_gl_stats__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @probe.gl/stats */ \"./node_modules/@probe.gl/stats/dist/esm/index.js\");\n/* harmony import */ var _resource_resource_manager__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./resource/resource-manager */ \"./node_modules/@deck.gl/core/dist/esm/lib/resource/resource-manager.js\");\n/* harmony import */ var _viewports_viewport__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../viewports/viewport */ \"./node_modules/@deck.gl/core/dist/esm/viewports/viewport.js\");\n/* harmony import */ var _shaderlib__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../shaderlib */ \"./node_modules/@deck.gl/core/dist/esm/shaderlib/index.js\");\n\n\n\n\n\n\n\n\n\n\nconst TRACE_SET_LAYERS = 'layerManager.setLayers';\nconst TRACE_ACTIVATE_VIEWPORT = 'layerManager.activateViewport';\nclass LayerManager {\n  constructor(gl, {\n    deck,\n    stats,\n    viewport: _viewport,\n    timeline\n  } = {}) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"layers\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"context\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"resourceManager\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_lastRenderedLayers\", []);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_needsRedraw\", false);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_needsUpdate\", false);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_nextLayers\", null);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_debug\", false);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"activateViewport\", viewport => {\n      (0,_debug__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(TRACE_ACTIVATE_VIEWPORT, this, viewport);\n\n      if (viewport) {\n        this.context.viewport = viewport;\n      }\n    });\n\n    this.layers = [];\n    this.resourceManager = new _resource_resource_manager__WEBPACK_IMPORTED_MODULE_3__[\"default\"]({\n      gl,\n      protocol: 'deck://'\n    });\n    this.context = {\n      mousePosition: null,\n      userData: {},\n      layerManager: this,\n      gl,\n      deck,\n      programManager: gl && (0,_shaderlib__WEBPACK_IMPORTED_MODULE_4__.createProgramManager)(gl),\n      stats: stats || new _probe_gl_stats__WEBPACK_IMPORTED_MODULE_1__.Stats({\n        id: 'deck.gl'\n      }),\n      viewport: _viewport || new _viewports_viewport__WEBPACK_IMPORTED_MODULE_5__[\"default\"]({\n        id: 'DEFAULT-INITIAL-VIEWPORT'\n      }),\n      timeline: timeline || new _luma_gl_core__WEBPACK_IMPORTED_MODULE_6__.Timeline(),\n      resourceManager: this.resourceManager,\n      onError: undefined\n    };\n    Object.seal(this);\n  }\n\n  finalize() {\n    this.resourceManager.finalize();\n\n    for (const layer of this.layers) {\n      this._finalizeLayer(layer);\n    }\n  }\n\n  needsRedraw(opts = {\n    clearRedrawFlags: false\n  }) {\n    let redraw = this._needsRedraw;\n\n    if (opts.clearRedrawFlags) {\n      this._needsRedraw = false;\n    }\n\n    for (const layer of this.layers) {\n      const layerNeedsRedraw = layer.getNeedsRedraw(opts);\n      redraw = redraw || layerNeedsRedraw;\n    }\n\n    return redraw;\n  }\n\n  needsUpdate() {\n    if (this._nextLayers && this._nextLayers !== this._lastRenderedLayers) {\n      return 'layers changed';\n    }\n\n    return this._needsUpdate;\n  }\n\n  setNeedsRedraw(reason) {\n    this._needsRedraw = this._needsRedraw || reason;\n  }\n\n  setNeedsUpdate(reason) {\n    this._needsUpdate = this._needsUpdate || reason;\n  }\n\n  getLayers({\n    layerIds\n  } = {}) {\n    return layerIds ? this.layers.filter(layer => layerIds.find(layerId => layer.id.indexOf(layerId) === 0)) : this.layers;\n  }\n\n  setProps(props) {\n    if ('debug' in props) {\n      this._debug = props.debug;\n    }\n\n    if ('userData' in props) {\n      this.context.userData = props.userData;\n    }\n\n    if ('layers' in props) {\n      this._nextLayers = props.layers;\n    }\n\n    if ('onError' in props) {\n      this.context.onError = props.onError;\n    }\n  }\n\n  setLayers(newLayers, reason) {\n    (0,_debug__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(TRACE_SET_LAYERS, this, reason, newLayers);\n    this._lastRenderedLayers = newLayers;\n    const flatLayers = (0,_utils_flatten__WEBPACK_IMPORTED_MODULE_7__.flatten)(newLayers, Boolean);\n\n    for (const layer of flatLayers) {\n      layer.context = this.context;\n    }\n\n    this._updateLayers(this.layers, flatLayers);\n  }\n\n  updateLayers() {\n    const reason = this.needsUpdate();\n\n    if (reason) {\n      this.setNeedsRedraw(\"updating layers: \".concat(reason));\n      this.setLayers(this._nextLayers || this._lastRenderedLayers, reason);\n    }\n\n    this._nextLayers = null;\n  }\n\n  _handleError(stage, error, layer) {\n    layer.raiseError(error, \"\".concat(stage, \" of \").concat(layer));\n  }\n\n  _updateLayers(oldLayers, newLayers) {\n    const oldLayerMap = {};\n\n    for (const oldLayer of oldLayers) {\n      if (oldLayerMap[oldLayer.id]) {\n        _utils_log__WEBPACK_IMPORTED_MODULE_8__[\"default\"].warn(\"Multiple old layers with same id \".concat(oldLayer.id))();\n      } else {\n        oldLayerMap[oldLayer.id] = oldLayer;\n      }\n    }\n\n    const generatedLayers = [];\n\n    this._updateSublayersRecursively(newLayers, oldLayerMap, generatedLayers);\n\n    this._finalizeOldLayers(oldLayerMap);\n\n    let needsUpdate = false;\n\n    for (const layer of generatedLayers) {\n      if (layer.hasUniformTransition()) {\n        needsUpdate = \"Uniform transition in \".concat(layer);\n        break;\n      }\n    }\n\n    this._needsUpdate = needsUpdate;\n    this.layers = generatedLayers;\n  }\n\n  _updateSublayersRecursively(newLayers, oldLayerMap, generatedLayers) {\n    for (const newLayer of newLayers) {\n      newLayer.context = this.context;\n      const oldLayer = oldLayerMap[newLayer.id];\n\n      if (oldLayer === null) {\n        _utils_log__WEBPACK_IMPORTED_MODULE_8__[\"default\"].warn(\"Multiple new layers with same id \".concat(newLayer.id))();\n      }\n\n      oldLayerMap[newLayer.id] = null;\n      let sublayers = null;\n\n      try {\n        if (this._debug && oldLayer !== newLayer) {\n          newLayer.validateProps();\n        }\n\n        if (!oldLayer) {\n          this._initializeLayer(newLayer);\n        } else {\n          this._transferLayerState(oldLayer, newLayer);\n\n          this._updateLayer(newLayer);\n        }\n\n        generatedLayers.push(newLayer);\n        sublayers = newLayer.isComposite ? newLayer.getSubLayers() : null;\n      } catch (err) {\n        this._handleError('matching', err, newLayer);\n      }\n\n      if (sublayers) {\n        this._updateSublayersRecursively(sublayers, oldLayerMap, generatedLayers);\n      }\n    }\n  }\n\n  _finalizeOldLayers(oldLayerMap) {\n    for (const layerId in oldLayerMap) {\n      const layer = oldLayerMap[layerId];\n\n      if (layer) {\n        this._finalizeLayer(layer);\n      }\n    }\n  }\n\n  _initializeLayer(layer) {\n    try {\n      layer._initialize();\n\n      layer.lifecycle = _lifecycle_constants__WEBPACK_IMPORTED_MODULE_9__.LIFECYCLE.INITIALIZED;\n    } catch (err) {\n      this._handleError('initialization', err, layer);\n    }\n  }\n\n  _transferLayerState(oldLayer, newLayer) {\n    newLayer._transferState(oldLayer);\n\n    newLayer.lifecycle = _lifecycle_constants__WEBPACK_IMPORTED_MODULE_9__.LIFECYCLE.MATCHED;\n\n    if (newLayer !== oldLayer) {\n      oldLayer.lifecycle = _lifecycle_constants__WEBPACK_IMPORTED_MODULE_9__.LIFECYCLE.AWAITING_GC;\n    }\n  }\n\n  _updateLayer(layer) {\n    try {\n      layer._update();\n    } catch (err) {\n      this._handleError('update', err, layer);\n    }\n  }\n\n  _finalizeLayer(layer) {\n    this._needsRedraw = this._needsRedraw || \"finalized \".concat(layer);\n    layer.lifecycle = _lifecycle_constants__WEBPACK_IMPORTED_MODULE_9__.LIFECYCLE.AWAITING_FINALIZATION;\n\n    try {\n      layer._finalize();\n\n      layer.lifecycle = _lifecycle_constants__WEBPACK_IMPORTED_MODULE_9__.LIFECYCLE.FINALIZED;\n    } catch (err) {\n      this._handleError('finalization', err, layer);\n    }\n  }\n\n}\n//# sourceMappingURL=layer-manager.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/lib/layer-manager.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/lib/layer-state.js":
/*!****************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/lib/layer-state.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ LayerState)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _lifecycle_component_state__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../lifecycle/component-state */ \"./node_modules/@deck.gl/core/dist/esm/lifecycle/component-state.js\");\n\n\nclass LayerState extends _lifecycle_component_state__WEBPACK_IMPORTED_MODULE_1__[\"default\"] {\n  constructor({\n    attributeManager,\n    layer\n  }) {\n    super(layer);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"attributeManager\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"needsRedraw\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"needsUpdate\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"subLayers\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"usesPickingColorCache\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"hasPickingBuffer\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"changeFlags\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"viewport\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"uniformTransitions\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"propsInTransition\", void 0);\n\n    this.attributeManager = attributeManager;\n    this.needsRedraw = true;\n    this.needsUpdate = true;\n    this.subLayers = null;\n    this.usesPickingColorCache = false;\n  }\n\n  get layer() {\n    return this.component;\n  }\n\n  _fetch(propName, url) {\n    const layer = this.layer;\n    const fetch = layer === null || layer === void 0 ? void 0 : layer.props.fetch;\n\n    if (fetch) {\n      return fetch(url, {\n        propName,\n        layer\n      });\n    }\n\n    return super._fetch(propName, url);\n  }\n\n  _onResolve(propName, value) {\n    const layer = this.layer;\n\n    if (layer) {\n      const onDataLoad = layer.props.onDataLoad;\n\n      if (propName === 'data' && onDataLoad) {\n        onDataLoad(value, {\n          propName,\n          layer\n        });\n      }\n    }\n  }\n\n  _onError(propName, error) {\n    const layer = this.layer;\n\n    if (layer) {\n      layer.raiseError(error, \"loading \".concat(propName, \" of \").concat(this.layer));\n    }\n  }\n\n}\n//# sourceMappingURL=layer-state.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/lib/layer-state.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/lib/layer.js":
/*!**********************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/lib/layer.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Layer)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./constants */ \"./node_modules/@deck.gl/core/dist/esm/lib/constants.js\");\n/* harmony import */ var _attribute_attribute_manager__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./attribute/attribute-manager */ \"./node_modules/@deck.gl/core/dist/esm/lib/attribute/attribute-manager.js\");\n/* harmony import */ var _uniform_transition_manager__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./uniform-transition-manager */ \"./node_modules/@deck.gl/core/dist/esm/lib/uniform-transition-manager.js\");\n/* harmony import */ var _lifecycle_props__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ../lifecycle/props */ \"./node_modules/@deck.gl/core/dist/esm/lifecycle/props.js\");\n/* harmony import */ var _lifecycle_constants__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../lifecycle/constants */ \"./node_modules/@deck.gl/core/dist/esm/lifecycle/constants.js\");\n/* harmony import */ var _utils_count__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../utils/count */ \"./node_modules/@deck.gl/core/dist/esm/utils/count.js\");\n/* harmony import */ var _utils_log__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../utils/log */ \"./node_modules/@deck.gl/core/dist/esm/utils/log.js\");\n/* harmony import */ var _debug__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../debug */ \"./node_modules/@deck.gl/core/dist/esm/debug/index.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../utils/assert */ \"./node_modules/@deck.gl/core/dist/esm/utils/assert.js\");\n/* harmony import */ var _utils_memoize__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/memoize */ \"./node_modules/@deck.gl/core/dist/esm/utils/memoize.js\");\n/* harmony import */ var _utils_shader__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../utils/shader */ \"./node_modules/@deck.gl/core/dist/esm/utils/shader.js\");\n/* harmony import */ var _shaderlib_project_project_functions__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../shaderlib/project/project-functions */ \"./node_modules/@deck.gl/core/dist/esm/shaderlib/project/project-functions.js\");\n/* harmony import */ var _utils_typed_array_manager__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../utils/typed-array-manager */ \"./node_modules/@deck.gl/core/dist/esm/utils/typed-array-manager.js\");\n/* harmony import */ var _lifecycle_component__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../lifecycle/component */ \"./node_modules/@deck.gl/core/dist/esm/lifecycle/component.js\");\n/* harmony import */ var _layer_state__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./layer-state */ \"./node_modules/@deck.gl/core/dist/esm/lib/layer-state.js\");\n/* harmony import */ var _math_gl_web_mercator__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @math.gl/web-mercator */ \"./node_modules/@math.gl/web-mercator/dist/esm/index.js\");\n/* harmony import */ var _loaders_gl_core__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! @loaders.gl/core */ \"./node_modules/@loaders.gl/core/dist/esm/lib/api/load.js\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nconst TRACE_CHANGE_FLAG = 'layer.changeFlag';\nconst TRACE_INITIALIZE = 'layer.initialize';\nconst TRACE_UPDATE = 'layer.update';\nconst TRACE_FINALIZE = 'layer.finalize';\nconst TRACE_MATCHED = 'layer.matched';\nconst MAX_PICKING_COLOR_CACHE_SIZE = 2 ** 24 - 1;\nconst EMPTY_ARRAY = Object.freeze([]);\nconst areViewportsEqual = (0,_utils_memoize__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(({\n  oldViewport,\n  viewport\n}) => {\n  return oldViewport.equals(viewport);\n});\nlet pickingColorCache = new Uint8ClampedArray(0);\nconst defaultProps = {\n  data: {\n    type: 'data',\n    value: EMPTY_ARRAY,\n    async: true\n  },\n  dataComparator: {\n    type: 'function',\n    value: null,\n    optional: true\n  },\n  _dataDiff: {\n    type: 'function',\n    value: data => data && data.__diff,\n    optional: true\n  },\n  dataTransform: {\n    type: 'function',\n    value: null,\n    optional: true\n  },\n  onDataLoad: {\n    type: 'function',\n    value: null,\n    optional: true\n  },\n  onError: {\n    type: 'function',\n    value: null,\n    optional: true\n  },\n  fetch: {\n    type: 'function',\n    value: (url, {\n      propName,\n      layer,\n      loaders,\n      loadOptions,\n      signal\n    }) => {\n      const {\n        resourceManager\n      } = layer.context;\n      loadOptions = loadOptions || layer.getLoadOptions();\n      loaders = loaders || layer.props.loaders;\n\n      if (signal) {\n        var _loadOptions;\n\n        loadOptions = { ...loadOptions,\n          fetch: { ...((_loadOptions = loadOptions) === null || _loadOptions === void 0 ? void 0 : _loadOptions.fetch),\n            signal\n          }\n        };\n      }\n\n      let inResourceManager = resourceManager.contains(url);\n\n      if (!inResourceManager && !loadOptions) {\n        resourceManager.add({\n          resourceId: url,\n          data: (0,_loaders_gl_core__WEBPACK_IMPORTED_MODULE_3__.load)(url, loaders),\n          persistent: false\n        });\n        inResourceManager = true;\n      }\n\n      if (inResourceManager) {\n        return resourceManager.subscribe({\n          resourceId: url,\n          onChange: data => {\n            var _layer$internalState;\n\n            return (_layer$internalState = layer.internalState) === null || _layer$internalState === void 0 ? void 0 : _layer$internalState.reloadAsyncProp(propName, data);\n          },\n          consumerId: layer.id,\n          requestId: propName\n        });\n      }\n\n      return (0,_loaders_gl_core__WEBPACK_IMPORTED_MODULE_3__.load)(url, loaders, loadOptions);\n    }\n  },\n  updateTriggers: {},\n  visible: true,\n  pickable: false,\n  opacity: {\n    type: 'number',\n    min: 0,\n    max: 1,\n    value: 1\n  },\n  operation: 'draw',\n  onHover: {\n    type: 'function',\n    value: null,\n    optional: true\n  },\n  onClick: {\n    type: 'function',\n    value: null,\n    optional: true\n  },\n  onDragStart: {\n    type: 'function',\n    value: null,\n    optional: true\n  },\n  onDrag: {\n    type: 'function',\n    value: null,\n    optional: true\n  },\n  onDragEnd: {\n    type: 'function',\n    value: null,\n    optional: true\n  },\n  coordinateSystem: _constants__WEBPACK_IMPORTED_MODULE_4__.COORDINATE_SYSTEM.DEFAULT,\n  coordinateOrigin: {\n    type: 'array',\n    value: [0, 0, 0],\n    compare: true\n  },\n  modelMatrix: {\n    type: 'array',\n    value: null,\n    compare: true,\n    optional: true\n  },\n  wrapLongitude: false,\n  positionFormat: 'XYZ',\n  colorFormat: 'RGBA',\n  parameters: {\n    type: 'object',\n    value: {},\n    optional: true,\n    compare: 2\n  },\n  loadOptions: {\n    type: 'object',\n    value: null,\n    optional: true,\n    ignore: true\n  },\n  transitions: null,\n  extensions: [],\n  loaders: {\n    type: 'array',\n    value: [],\n    optional: true,\n    ignore: true\n  },\n  getPolygonOffset: {\n    type: 'function',\n    value: ({\n      layerIndex\n    }) => [0, -layerIndex * 100]\n  },\n  highlightedObjectIndex: null,\n  autoHighlight: false,\n  highlightColor: {\n    type: 'accessor',\n    value: [0, 0, 128, 128]\n  }\n};\nclass Layer extends _lifecycle_component__WEBPACK_IMPORTED_MODULE_5__[\"default\"] {\n  constructor(...args) {\n    super(...args);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"internalState\", null);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"lifecycle\", _lifecycle_constants__WEBPACK_IMPORTED_MODULE_6__.LIFECYCLE.NO_STATE);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"context\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"state\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"parent\", null);\n  }\n\n  static get componentName() {\n    return Object.prototype.hasOwnProperty.call(this, 'layerName') ? this.layerName : '';\n  }\n\n  get root() {\n    let layer = this;\n\n    while (layer.parent) {\n      layer = layer.parent;\n    }\n\n    return layer;\n  }\n\n  toString() {\n    const className = this.constructor.layerName || this.constructor.name;\n    return \"\".concat(className, \"({id: '\").concat(this.props.id, \"'})\");\n  }\n\n  project(xyz) {\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_7__[\"default\"])(this.internalState);\n    const viewport = this.internalState.viewport || this.context.viewport;\n    const worldPosition = (0,_shaderlib_project_project_functions__WEBPACK_IMPORTED_MODULE_8__.getWorldPosition)(xyz, {\n      viewport,\n      modelMatrix: this.props.modelMatrix,\n      coordinateOrigin: this.props.coordinateOrigin,\n      coordinateSystem: this.props.coordinateSystem\n    });\n    const [x, y, z] = (0,_math_gl_web_mercator__WEBPACK_IMPORTED_MODULE_1__.worldToPixels)(worldPosition, viewport.pixelProjectionMatrix);\n    return xyz.length === 2 ? [x, y] : [x, y, z];\n  }\n\n  unproject(xy) {\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_7__[\"default\"])(this.internalState);\n    const viewport = this.internalState.viewport || this.context.viewport;\n    return viewport.unproject(xy);\n  }\n\n  projectPosition(xyz, params) {\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_7__[\"default\"])(this.internalState);\n    const viewport = this.internalState.viewport || this.context.viewport;\n    return (0,_shaderlib_project_project_functions__WEBPACK_IMPORTED_MODULE_8__.projectPosition)(xyz, {\n      viewport,\n      modelMatrix: this.props.modelMatrix,\n      coordinateOrigin: this.props.coordinateOrigin,\n      coordinateSystem: this.props.coordinateSystem,\n      ...params\n    });\n  }\n\n  get isComposite() {\n    return false;\n  }\n\n  setState(partialState) {\n    this.setChangeFlags({\n      stateChanged: true\n    });\n    Object.assign(this.state, partialState);\n    this.setNeedsRedraw();\n  }\n\n  setNeedsRedraw() {\n    if (this.internalState) {\n      this.internalState.needsRedraw = true;\n    }\n  }\n\n  setNeedsUpdate() {\n    if (this.internalState) {\n      this.context.layerManager.setNeedsUpdate(String(this));\n      this.internalState.needsUpdate = true;\n    }\n  }\n\n  get isLoaded() {\n    return this.internalState ? !this.internalState.isAsyncPropLoading() : false;\n  }\n\n  get wrapLongitude() {\n    return this.props.wrapLongitude;\n  }\n\n  isPickable() {\n    return this.props.pickable && this.props.visible;\n  }\n\n  getModels() {\n    return this.state && (this.state.models || this.state.model && [this.state.model]) || [];\n  }\n\n  setModuleParameters(moduleParameters) {\n    for (const model of this.getModels()) {\n      model.updateModuleSettings(moduleParameters);\n    }\n  }\n\n  getAttributeManager() {\n    return this.internalState && this.internalState.attributeManager;\n  }\n\n  getCurrentLayer() {\n    return this.internalState && this.internalState.layer;\n  }\n\n  getLoadOptions() {\n    return this.props.loadOptions;\n  }\n\n  use64bitPositions() {\n    const {\n      coordinateSystem\n    } = this.props;\n    return coordinateSystem === _constants__WEBPACK_IMPORTED_MODULE_4__.COORDINATE_SYSTEM.DEFAULT || coordinateSystem === _constants__WEBPACK_IMPORTED_MODULE_4__.COORDINATE_SYSTEM.LNGLAT || coordinateSystem === _constants__WEBPACK_IMPORTED_MODULE_4__.COORDINATE_SYSTEM.CARTESIAN;\n  }\n\n  onHover(info, pickingEvent) {\n    if (this.props.onHover) {\n      return this.props.onHover(info, pickingEvent) || false;\n    }\n\n    return false;\n  }\n\n  onClick(info, pickingEvent) {\n    if (this.props.onClick) {\n      return this.props.onClick(info, pickingEvent) || false;\n    }\n\n    return false;\n  }\n\n  nullPickingColor() {\n    return [0, 0, 0];\n  }\n\n  encodePickingColor(i, target = []) {\n    target[0] = i + 1 & 255;\n    target[1] = i + 1 >> 8 & 255;\n    target[2] = i + 1 >> 8 >> 8 & 255;\n    return target;\n  }\n\n  decodePickingColor(color) {\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_7__[\"default\"])(color instanceof Uint8Array);\n    const [i1, i2, i3] = color;\n    const index = i1 + i2 * 256 + i3 * 65536 - 1;\n    return index;\n  }\n\n  getNumInstances() {\n    if (Number.isFinite(this.props.numInstances)) {\n      return this.props.numInstances;\n    }\n\n    if (this.state && this.state.numInstances !== undefined) {\n      return this.state.numInstances;\n    }\n\n    return (0,_utils_count__WEBPACK_IMPORTED_MODULE_9__.count)(this.props.data);\n  }\n\n  getStartIndices() {\n    if (this.props.startIndices) {\n      return this.props.startIndices;\n    }\n\n    if (this.state && this.state.startIndices) {\n      return this.state.startIndices;\n    }\n\n    return null;\n  }\n\n  getBounds() {\n    var _this$getAttributeMan;\n\n    return (_this$getAttributeMan = this.getAttributeManager()) === null || _this$getAttributeMan === void 0 ? void 0 : _this$getAttributeMan.getBounds(['positions', 'instancePositions']);\n  }\n\n  getShaders(shaders) {\n    for (const extension of this.props.extensions) {\n      shaders = (0,_utils_shader__WEBPACK_IMPORTED_MODULE_10__.mergeShaders)(shaders, extension.getShaders.call(this, extension));\n    }\n\n    return shaders;\n  }\n\n  shouldUpdateState(params) {\n    return params.changeFlags.propsOrDataChanged;\n  }\n\n  updateState(params) {\n    const attributeManager = this.getAttributeManager();\n    const {\n      dataChanged\n    } = params.changeFlags;\n\n    if (dataChanged && attributeManager) {\n      if (Array.isArray(dataChanged)) {\n        for (const dataRange of dataChanged) {\n          attributeManager.invalidateAll(dataRange);\n        }\n      } else {\n        attributeManager.invalidateAll();\n      }\n    }\n\n    if (attributeManager) {\n      const {\n        props\n      } = params;\n      const hasPickingBuffer = this.internalState.hasPickingBuffer;\n      const needsPickingBuffer = Number.isInteger(props.highlightedObjectIndex) || props.pickable || props.extensions.some(extension => extension.getNeedsPickingBuffer.call(this, extension));\n\n      if (hasPickingBuffer !== needsPickingBuffer) {\n        this.internalState.hasPickingBuffer = needsPickingBuffer;\n        const {\n          pickingColors,\n          instancePickingColors\n        } = attributeManager.attributes;\n        const pickingColorsAttribute = pickingColors || instancePickingColors;\n\n        if (pickingColorsAttribute) {\n          if (needsPickingBuffer && pickingColorsAttribute.constant) {\n            pickingColorsAttribute.constant = false;\n            attributeManager.invalidate(pickingColorsAttribute.id);\n          }\n\n          if (!pickingColorsAttribute.value && !needsPickingBuffer) {\n            pickingColorsAttribute.constant = true;\n            pickingColorsAttribute.value = [0, 0, 0];\n          }\n        }\n      }\n    }\n  }\n\n  finalizeState(context) {\n    for (const model of this.getModels()) {\n      model.delete();\n    }\n\n    const attributeManager = this.getAttributeManager();\n\n    if (attributeManager) {\n      attributeManager.finalize();\n    }\n\n    if (this.context) {\n      this.context.resourceManager.unsubscribe({\n        consumerId: this.id\n      });\n    }\n\n    if (this.internalState) {\n      this.internalState.uniformTransitions.clear();\n      this.internalState.finalize();\n    }\n  }\n\n  draw(opts) {\n    for (const model of this.getModels()) {\n      model.draw(opts);\n    }\n  }\n\n  getPickingInfo({\n    info,\n    mode,\n    sourceLayer\n  }) {\n    const {\n      index\n    } = info;\n\n    if (index >= 0) {\n      if (Array.isArray(this.props.data)) {\n        info.object = this.props.data[index];\n      }\n    }\n\n    return info;\n  }\n\n  raiseError(error, message) {\n    var _this$props$onError, _this$props;\n\n    if (message) {\n      error = new Error(\"\".concat(message, \": \").concat(error.message), {\n        cause: error\n      });\n    }\n\n    if (!((_this$props$onError = (_this$props = this.props).onError) !== null && _this$props$onError !== void 0 && _this$props$onError.call(_this$props, error))) {\n      var _this$context, _this$context$onError;\n\n      (_this$context = this.context) === null || _this$context === void 0 ? void 0 : (_this$context$onError = _this$context.onError) === null || _this$context$onError === void 0 ? void 0 : _this$context$onError.call(_this$context, error, this);\n    }\n  }\n\n  getNeedsRedraw(opts = {\n    clearRedrawFlags: false\n  }) {\n    return this._getNeedsRedraw(opts);\n  }\n\n  needsUpdate() {\n    if (!this.internalState) {\n      return false;\n    }\n\n    return this.internalState.needsUpdate || this.hasUniformTransition() || this.shouldUpdateState(this._getUpdateParams());\n  }\n\n  hasUniformTransition() {\n    var _this$internalState;\n\n    return ((_this$internalState = this.internalState) === null || _this$internalState === void 0 ? void 0 : _this$internalState.uniformTransitions.active) || false;\n  }\n\n  activateViewport(viewport) {\n    if (!this.internalState) {\n      return;\n    }\n\n    const oldViewport = this.internalState.viewport;\n    this.internalState.viewport = viewport;\n\n    if (!oldViewport || !areViewportsEqual({\n      oldViewport,\n      viewport\n    })) {\n      this.setChangeFlags({\n        viewportChanged: true\n      });\n\n      if (this.isComposite) {\n        if (this.needsUpdate()) {\n          this.setNeedsUpdate();\n        }\n      } else {\n        this._update();\n      }\n    }\n  }\n\n  invalidateAttribute(name = 'all') {\n    const attributeManager = this.getAttributeManager();\n\n    if (!attributeManager) {\n      return;\n    }\n\n    if (name === 'all') {\n      attributeManager.invalidateAll();\n    } else {\n      attributeManager.invalidate(name);\n    }\n  }\n\n  updateAttributes(changedAttributes) {\n    for (const model of this.getModels()) {\n      this._setModelAttributes(model, changedAttributes);\n    }\n  }\n\n  _updateAttributes() {\n    const attributeManager = this.getAttributeManager();\n\n    if (!attributeManager) {\n      return;\n    }\n\n    const props = this.props;\n    const numInstances = this.getNumInstances();\n    const startIndices = this.getStartIndices();\n    attributeManager.update({\n      data: props.data,\n      numInstances,\n      startIndices,\n      props,\n      transitions: props.transitions,\n      buffers: props.data.attributes,\n      context: this\n    });\n    const changedAttributes = attributeManager.getChangedAttributes({\n      clearChangedFlags: true\n    });\n    this.updateAttributes(changedAttributes);\n  }\n\n  _updateAttributeTransition() {\n    const attributeManager = this.getAttributeManager();\n\n    if (attributeManager) {\n      attributeManager.updateTransition();\n    }\n  }\n\n  _updateUniformTransition() {\n    const {\n      uniformTransitions\n    } = this.internalState;\n\n    if (uniformTransitions.active) {\n      const propsInTransition = uniformTransitions.update();\n      const props = Object.create(this.props);\n\n      for (const key in propsInTransition) {\n        Object.defineProperty(props, key, {\n          value: propsInTransition[key]\n        });\n      }\n\n      return props;\n    }\n\n    return this.props;\n  }\n\n  calculateInstancePickingColors(attribute, {\n    numInstances\n  }) {\n    if (attribute.constant) {\n      return;\n    }\n\n    const cacheSize = Math.floor(pickingColorCache.length / 3);\n    this.internalState.usesPickingColorCache = true;\n\n    if (cacheSize < numInstances) {\n      if (numInstances > MAX_PICKING_COLOR_CACHE_SIZE) {\n        _utils_log__WEBPACK_IMPORTED_MODULE_11__[\"default\"].warn('Layer has too many data objects. Picking might not be able to distinguish all objects.')();\n      }\n\n      pickingColorCache = _utils_typed_array_manager__WEBPACK_IMPORTED_MODULE_12__[\"default\"].allocate(pickingColorCache, numInstances, {\n        size: 3,\n        copy: true,\n        maxCount: Math.max(numInstances, MAX_PICKING_COLOR_CACHE_SIZE)\n      });\n      const newCacheSize = Math.floor(pickingColorCache.length / 3);\n      const pickingColor = [];\n\n      for (let i = cacheSize; i < newCacheSize; i++) {\n        this.encodePickingColor(i, pickingColor);\n        pickingColorCache[i * 3 + 0] = pickingColor[0];\n        pickingColorCache[i * 3 + 1] = pickingColor[1];\n        pickingColorCache[i * 3 + 2] = pickingColor[2];\n      }\n    }\n\n    attribute.value = pickingColorCache.subarray(0, numInstances * 3);\n  }\n\n  _setModelAttributes(model, changedAttributes) {\n    const attributeManager = this.getAttributeManager();\n    const excludeAttributes = model.userData.excludeAttributes || {};\n    const shaderAttributes = attributeManager.getShaderAttributes(changedAttributes, excludeAttributes);\n    model.setAttributes(shaderAttributes);\n  }\n\n  disablePickingIndex(objectIndex) {\n    const data = this.props.data;\n\n    if (!('attributes' in data)) {\n      this._disablePickingIndex(objectIndex);\n\n      return;\n    }\n\n    const {\n      pickingColors,\n      instancePickingColors\n    } = this.getAttributeManager().attributes;\n    const colors = pickingColors || instancePickingColors;\n    const externalColorAttribute = colors && data.attributes && data.attributes[colors.id];\n\n    if (externalColorAttribute && externalColorAttribute.value) {\n      const values = externalColorAttribute.value;\n      const objectColor = this.encodePickingColor(objectIndex);\n\n      for (let index = 0; index < data.length; index++) {\n        const i = colors.getVertexOffset(index);\n\n        if (values[i] === objectColor[0] && values[i + 1] === objectColor[1] && values[i + 2] === objectColor[2]) {\n          this._disablePickingIndex(index);\n        }\n      }\n    } else {\n      this._disablePickingIndex(objectIndex);\n    }\n  }\n\n  _disablePickingIndex(objectIndex) {\n    const {\n      pickingColors,\n      instancePickingColors\n    } = this.getAttributeManager().attributes;\n    const colors = pickingColors || instancePickingColors;\n\n    if (!colors) {\n      return;\n    }\n\n    const start = colors.getVertexOffset(objectIndex);\n    const end = colors.getVertexOffset(objectIndex + 1);\n    colors.buffer.subData({\n      data: new Uint8Array(end - start),\n      offset: start\n    });\n  }\n\n  restorePickingColors() {\n    const {\n      pickingColors,\n      instancePickingColors\n    } = this.getAttributeManager().attributes;\n    const colors = pickingColors || instancePickingColors;\n\n    if (!colors) {\n      return;\n    }\n\n    if (this.internalState.usesPickingColorCache && colors.value.buffer !== pickingColorCache.buffer) {\n      colors.value = pickingColorCache.subarray(0, colors.value.length);\n    }\n\n    colors.updateSubBuffer({\n      startOffset: 0\n    });\n  }\n\n  _initialize() {\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_7__[\"default\"])(!this.internalState);\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_7__[\"default\"])(Number.isFinite(this.props.coordinateSystem));\n    (0,_debug__WEBPACK_IMPORTED_MODULE_13__[\"default\"])(TRACE_INITIALIZE, this);\n\n    const attributeManager = this._getAttributeManager();\n\n    if (attributeManager) {\n      attributeManager.addInstanced({\n        instancePickingColors: {\n          type: 5121,\n          size: 3,\n          noAlloc: true,\n          update: this.calculateInstancePickingColors\n        }\n      });\n    }\n\n    this.internalState = new _layer_state__WEBPACK_IMPORTED_MODULE_14__[\"default\"]({\n      attributeManager,\n      layer: this\n    });\n\n    this._clearChangeFlags();\n\n    this.state = {};\n    Object.defineProperty(this.state, 'attributeManager', {\n      get: () => {\n        _utils_log__WEBPACK_IMPORTED_MODULE_11__[\"default\"].deprecated('layer.state.attributeManager', 'layer.getAttributeManager()')();\n        return attributeManager;\n      }\n    });\n    this.internalState.uniformTransitions = new _uniform_transition_manager__WEBPACK_IMPORTED_MODULE_15__[\"default\"](this.context.timeline);\n    this.internalState.onAsyncPropUpdated = this._onAsyncPropUpdated.bind(this);\n    this.internalState.setAsyncProps(this.props);\n    this.initializeState(this.context);\n\n    for (const extension of this.props.extensions) {\n      extension.initializeState.call(this, this.context, extension);\n    }\n\n    this.setChangeFlags({\n      dataChanged: 'init',\n      propsChanged: 'init',\n      viewportChanged: true,\n      extensionsChanged: true\n    });\n\n    this._update();\n  }\n\n  _transferState(oldLayer) {\n    (0,_debug__WEBPACK_IMPORTED_MODULE_13__[\"default\"])(TRACE_MATCHED, this, this === oldLayer);\n    const {\n      state,\n      internalState\n    } = oldLayer;\n\n    if (this === oldLayer) {\n      return;\n    }\n\n    this.internalState = internalState;\n    this.state = state;\n    this.internalState.setAsyncProps(this.props);\n\n    this._diffProps(this.props, this.internalState.getOldProps());\n  }\n\n  _update() {\n    const stateNeedsUpdate = this.needsUpdate();\n    (0,_debug__WEBPACK_IMPORTED_MODULE_13__[\"default\"])(TRACE_UPDATE, this, stateNeedsUpdate);\n\n    if (!stateNeedsUpdate) {\n      return;\n    }\n\n    const currentProps = this.props;\n    const context = this.context;\n    const internalState = this.internalState;\n    const currentViewport = context.viewport;\n\n    const propsInTransition = this._updateUniformTransition();\n\n    internalState.propsInTransition = propsInTransition;\n    context.viewport = internalState.viewport || currentViewport;\n    this.props = propsInTransition;\n\n    try {\n      const updateParams = this._getUpdateParams();\n\n      const oldModels = this.getModels();\n\n      if (context.gl) {\n        this.updateState(updateParams);\n      } else {\n        try {\n          this.updateState(updateParams);\n        } catch (error) {}\n      }\n\n      for (const extension of this.props.extensions) {\n        extension.updateState.call(this, updateParams, extension);\n      }\n\n      const modelChanged = this.getModels()[0] !== oldModels[0];\n\n      this._postUpdate(updateParams, modelChanged);\n    } finally {\n      context.viewport = currentViewport;\n      this.props = currentProps;\n\n      this._clearChangeFlags();\n\n      internalState.needsUpdate = false;\n      internalState.resetOldProps();\n    }\n  }\n\n  _finalize() {\n    (0,_debug__WEBPACK_IMPORTED_MODULE_13__[\"default\"])(TRACE_FINALIZE, this);\n    this.finalizeState(this.context);\n\n    for (const extension of this.props.extensions) {\n      extension.finalizeState.call(this, this.context, extension);\n    }\n  }\n\n  _drawLayer({\n    moduleParameters = null,\n    uniforms = {},\n    parameters = {}\n  }) {\n    this._updateAttributeTransition();\n\n    const currentProps = this.props;\n    const context = this.context;\n    this.props = this.internalState.propsInTransition || currentProps;\n    const opacity = this.props.opacity;\n    uniforms.opacity = Math.pow(opacity, 1 / 2.2);\n\n    try {\n      if (moduleParameters) {\n        this.setModuleParameters(moduleParameters);\n      }\n\n      const {\n        getPolygonOffset\n      } = this.props;\n      const offsets = getPolygonOffset && getPolygonOffset(uniforms) || [0, 0];\n      (0,_luma_gl_core__WEBPACK_IMPORTED_MODULE_16__.setParameters)(context.gl, {\n        polygonOffset: offsets\n      });\n      (0,_luma_gl_core__WEBPACK_IMPORTED_MODULE_16__.withParameters)(context.gl, parameters, () => {\n        const opts = {\n          moduleParameters,\n          uniforms,\n          parameters,\n          context\n        };\n\n        for (const extension of this.props.extensions) {\n          extension.draw.call(this, opts, extension);\n        }\n\n        this.draw(opts);\n      });\n    } finally {\n      this.props = currentProps;\n    }\n  }\n\n  getChangeFlags() {\n    var _this$internalState2;\n\n    return (_this$internalState2 = this.internalState) === null || _this$internalState2 === void 0 ? void 0 : _this$internalState2.changeFlags;\n  }\n\n  setChangeFlags(flags) {\n    if (!this.internalState) {\n      return;\n    }\n\n    const {\n      changeFlags\n    } = this.internalState;\n\n    for (const key in flags) {\n      if (flags[key]) {\n        let flagChanged = false;\n\n        switch (key) {\n          case 'dataChanged':\n            const dataChangedReason = flags[key];\n            const prevDataChangedReason = changeFlags[key];\n\n            if (dataChangedReason && Array.isArray(prevDataChangedReason)) {\n              changeFlags.dataChanged = Array.isArray(dataChangedReason) ? prevDataChangedReason.concat(dataChangedReason) : dataChangedReason;\n              flagChanged = true;\n            }\n\n          default:\n            if (!changeFlags[key]) {\n              changeFlags[key] = flags[key];\n              flagChanged = true;\n            }\n\n        }\n\n        if (flagChanged) {\n          (0,_debug__WEBPACK_IMPORTED_MODULE_13__[\"default\"])(TRACE_CHANGE_FLAG, this, key, flags);\n        }\n      }\n    }\n\n    const propsOrDataChanged = Boolean(changeFlags.dataChanged || changeFlags.updateTriggersChanged || changeFlags.propsChanged || changeFlags.extensionsChanged);\n    changeFlags.propsOrDataChanged = propsOrDataChanged;\n    changeFlags.somethingChanged = propsOrDataChanged || changeFlags.viewportChanged || changeFlags.stateChanged;\n  }\n\n  _clearChangeFlags() {\n    this.internalState.changeFlags = {\n      dataChanged: false,\n      propsChanged: false,\n      updateTriggersChanged: false,\n      viewportChanged: false,\n      stateChanged: false,\n      extensionsChanged: false,\n      propsOrDataChanged: false,\n      somethingChanged: false\n    };\n  }\n\n  _diffProps(newProps, oldProps) {\n    const changeFlags = (0,_lifecycle_props__WEBPACK_IMPORTED_MODULE_17__.diffProps)(newProps, oldProps);\n\n    if (changeFlags.updateTriggersChanged) {\n      for (const key in changeFlags.updateTriggersChanged) {\n        if (changeFlags.updateTriggersChanged[key]) {\n          this.invalidateAttribute(key);\n        }\n      }\n    }\n\n    if (changeFlags.transitionsChanged) {\n      for (const key in changeFlags.transitionsChanged) {\n        var _newProps$transitions;\n\n        this.internalState.uniformTransitions.add(key, oldProps[key], newProps[key], (_newProps$transitions = newProps.transitions) === null || _newProps$transitions === void 0 ? void 0 : _newProps$transitions[key]);\n      }\n    }\n\n    return this.setChangeFlags(changeFlags);\n  }\n\n  validateProps() {\n    (0,_lifecycle_props__WEBPACK_IMPORTED_MODULE_17__.validateProps)(this.props);\n  }\n\n  updateAutoHighlight(info) {\n    if (this.props.autoHighlight && !Number.isInteger(this.props.highlightedObjectIndex)) {\n      this._updateAutoHighlight(info);\n    }\n  }\n\n  _updateAutoHighlight(info) {\n    const pickingModuleParameters = {\n      pickingSelectedColor: info.picked ? info.color : null\n    };\n    const {\n      highlightColor\n    } = this.props;\n\n    if (info.picked && typeof highlightColor === 'function') {\n      pickingModuleParameters.pickingHighlightColor = highlightColor(info);\n    }\n\n    this.setModuleParameters(pickingModuleParameters);\n    this.setNeedsRedraw();\n  }\n\n  _getAttributeManager() {\n    const context = this.context;\n    return new _attribute_attribute_manager__WEBPACK_IMPORTED_MODULE_18__[\"default\"](context.gl, {\n      id: this.props.id,\n      stats: context.stats,\n      timeline: context.timeline\n    });\n  }\n\n  _postUpdate(updateParams, forceUpdate) {\n    const {\n      props,\n      oldProps\n    } = updateParams;\n    this.setNeedsRedraw();\n\n    this._updateAttributes();\n\n    const {\n      model\n    } = this.state;\n    model === null || model === void 0 ? void 0 : model.setInstanceCount(this.getNumInstances());\n    const {\n      autoHighlight,\n      highlightedObjectIndex,\n      highlightColor\n    } = props;\n\n    if (forceUpdate || oldProps.autoHighlight !== autoHighlight || oldProps.highlightedObjectIndex !== highlightedObjectIndex || oldProps.highlightColor !== highlightColor) {\n      const parameters = {};\n\n      if (!autoHighlight) {\n        parameters.pickingSelectedColor = null;\n      }\n\n      if (Array.isArray(highlightColor)) {\n        parameters.pickingHighlightColor = highlightColor;\n      }\n\n      if (forceUpdate || highlightedObjectIndex !== oldProps.highlightedObjectIndex) {\n        parameters.pickingSelectedColor = Number.isFinite(highlightedObjectIndex) && highlightedObjectIndex >= 0 ? this.encodePickingColor(highlightedObjectIndex) : null;\n      }\n\n      this.setModuleParameters(parameters);\n    }\n  }\n\n  _getUpdateParams() {\n    return {\n      props: this.props,\n      oldProps: this.internalState.getOldProps(),\n      context: this.context,\n      changeFlags: this.internalState.changeFlags\n    };\n  }\n\n  _getNeedsRedraw(opts) {\n    if (!this.internalState) {\n      return false;\n    }\n\n    let redraw = false;\n    redraw = redraw || this.internalState.needsRedraw && this.id;\n    const attributeManager = this.getAttributeManager();\n    const attributeManagerNeedsRedraw = attributeManager ? attributeManager.getNeedsRedraw(opts) : false;\n    redraw = redraw || attributeManagerNeedsRedraw;\n\n    if (redraw) {\n      for (const extension of this.props.extensions) {\n        extension.onNeedsRedraw.call(this, extension);\n      }\n    }\n\n    this.internalState.needsRedraw = this.internalState.needsRedraw && !opts.clearRedrawFlags;\n    return redraw;\n  }\n\n  _onAsyncPropUpdated() {\n    this._diffProps(this.props, this.internalState.getOldProps());\n\n    this.setNeedsUpdate();\n  }\n\n}\n\n(0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(Layer, \"defaultProps\", defaultProps);\n\n(0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(Layer, \"layerName\", 'Layer');\n//# sourceMappingURL=layer.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/lib/layer.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/lib/picking/pick-info.js":
/*!**********************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/lib/picking/pick-info.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getEmptyPickingInfo: () => (/* binding */ getEmptyPickingInfo),\n/* harmony export */   getLayerPickingInfo: () => (/* binding */ getLayerPickingInfo),\n/* harmony export */   processPickInfo: () => (/* binding */ processPickInfo)\n/* harmony export */ });\nfunction getEmptyPickingInfo({\n  pickInfo,\n  viewports,\n  pixelRatio,\n  x,\n  y,\n  z\n}) {\n  let pickedViewport = viewports[0];\n\n  if (viewports.length > 1) {\n    pickedViewport = getViewportFromCoordinates((pickInfo === null || pickInfo === void 0 ? void 0 : pickInfo.pickedViewports) || viewports, {\n      x,\n      y\n    });\n  }\n\n  let coordinate;\n\n  if (pickedViewport) {\n    const point = [x - pickedViewport.x, y - pickedViewport.y];\n\n    if (z !== undefined) {\n      point[2] = z;\n    }\n\n    coordinate = pickedViewport.unproject(point);\n  }\n\n  return {\n    color: null,\n    layer: null,\n    viewport: pickedViewport,\n    index: -1,\n    picked: false,\n    x,\n    y,\n    pixel: [x, y],\n    coordinate,\n    devicePixel: pickInfo && 'pickedX' in pickInfo ? [pickInfo.pickedX, pickInfo.pickedY] : undefined,\n    pixelRatio\n  };\n}\nfunction processPickInfo(opts) {\n  const {\n    pickInfo,\n    lastPickedInfo,\n    mode,\n    layers\n  } = opts;\n  const {\n    pickedColor,\n    pickedLayer,\n    pickedObjectIndex\n  } = pickInfo;\n  const affectedLayers = pickedLayer ? [pickedLayer] : [];\n\n  if (mode === 'hover') {\n    const lastPickedPixelIndex = lastPickedInfo.index;\n    const lastPickedLayerId = lastPickedInfo.layerId;\n    const pickedLayerId = pickedLayer ? pickedLayer.props.id : null;\n\n    if (pickedLayerId !== lastPickedLayerId || pickedObjectIndex !== lastPickedPixelIndex) {\n      if (pickedLayerId !== lastPickedLayerId) {\n        const lastPickedLayer = layers.find(layer => layer.props.id === lastPickedLayerId);\n\n        if (lastPickedLayer) {\n          affectedLayers.unshift(lastPickedLayer);\n        }\n      }\n\n      lastPickedInfo.layerId = pickedLayerId;\n      lastPickedInfo.index = pickedObjectIndex;\n      lastPickedInfo.info = null;\n    }\n  }\n\n  const baseInfo = getEmptyPickingInfo(opts);\n  const infos = new Map();\n  infos.set(null, baseInfo);\n  affectedLayers.forEach(layer => {\n    let info = { ...baseInfo\n    };\n\n    if (layer === pickedLayer) {\n      info.color = pickedColor;\n      info.index = pickedObjectIndex;\n      info.picked = true;\n    }\n\n    info = getLayerPickingInfo({\n      layer,\n      info,\n      mode\n    });\n    const rootLayer = info.layer;\n\n    if (layer === pickedLayer && mode === 'hover') {\n      lastPickedInfo.info = info;\n    }\n\n    infos.set(rootLayer.id, info);\n\n    if (mode === 'hover') {\n      rootLayer.updateAutoHighlight(info);\n    }\n  });\n  return infos;\n}\nfunction getLayerPickingInfo({\n  layer,\n  info,\n  mode\n}) {\n  while (layer && info) {\n    const sourceLayer = info.layer || null;\n    info.sourceLayer = sourceLayer;\n    info.layer = layer;\n    info = layer.getPickingInfo({\n      info,\n      mode,\n      sourceLayer\n    });\n    layer = layer.parent;\n  }\n\n  return info;\n}\n\nfunction getViewportFromCoordinates(viewports, pixel) {\n  for (let i = viewports.length - 1; i >= 0; i--) {\n    const viewport = viewports[i];\n\n    if (viewport.containsPixel(pixel)) {\n      return viewport;\n    }\n  }\n\n  return viewports[0];\n}\n//# sourceMappingURL=pick-info.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/lib/picking/pick-info.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/lib/picking/query-object.js":
/*!*************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/lib/picking/query-object.js ***!
  \*************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getClosestObject: () => (/* binding */ getClosestObject),\n/* harmony export */   getUniqueObjects: () => (/* binding */ getUniqueObjects)\n/* harmony export */ });\n/* harmony import */ var _utils_log__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../utils/log */ \"./node_modules/@deck.gl/core/dist/esm/utils/log.js\");\n\nconst NO_PICKED_OBJECT = {\n  pickedColor: null,\n  pickedObjectIndex: -1\n};\nfunction getClosestObject({\n  pickedColors,\n  decodePickingColor,\n  deviceX,\n  deviceY,\n  deviceRadius,\n  deviceRect\n}) {\n  const {\n    x,\n    y,\n    width,\n    height\n  } = deviceRect;\n  let minSquareDistanceToCenter = deviceRadius * deviceRadius;\n  let closestPixelIndex = -1;\n  let i = 0;\n\n  for (let row = 0; row < height; row++) {\n    const dy = row + y - deviceY;\n    const dy2 = dy * dy;\n\n    if (dy2 > minSquareDistanceToCenter) {\n      i += 4 * width;\n    } else {\n      for (let col = 0; col < width; col++) {\n        const pickedLayerIndex = pickedColors[i + 3] - 1;\n\n        if (pickedLayerIndex >= 0) {\n          const dx = col + x - deviceX;\n          const d2 = dx * dx + dy2;\n\n          if (d2 <= minSquareDistanceToCenter) {\n            minSquareDistanceToCenter = d2;\n            closestPixelIndex = i;\n          }\n        }\n\n        i += 4;\n      }\n    }\n  }\n\n  if (closestPixelIndex >= 0) {\n    const pickedColor = pickedColors.slice(closestPixelIndex, closestPixelIndex + 4);\n    const pickedObject = decodePickingColor(pickedColor);\n\n    if (pickedObject) {\n      const dy = Math.floor(closestPixelIndex / 4 / width);\n      const dx = closestPixelIndex / 4 - dy * width;\n      return { ...pickedObject,\n        pickedColor,\n        pickedX: x + dx,\n        pickedY: y + dy\n      };\n    }\n\n    _utils_log__WEBPACK_IMPORTED_MODULE_0__[\"default\"].error('Picked non-existent layer. Is picking buffer corrupt?')();\n  }\n\n  return NO_PICKED_OBJECT;\n}\nfunction getUniqueObjects({\n  pickedColors,\n  decodePickingColor\n}) {\n  const uniqueColors = new Map();\n\n  if (pickedColors) {\n    for (let i = 0; i < pickedColors.length; i += 4) {\n      const pickedLayerIndex = pickedColors[i + 3] - 1;\n\n      if (pickedLayerIndex >= 0) {\n        const pickedColor = pickedColors.slice(i, i + 4);\n        const colorKey = pickedColor.join(',');\n\n        if (!uniqueColors.has(colorKey)) {\n          const pickedObject = decodePickingColor(pickedColor);\n\n          if (pickedObject) {\n            uniqueColors.set(colorKey, { ...pickedObject,\n              color: pickedColor\n            });\n          } else {\n            _utils_log__WEBPACK_IMPORTED_MODULE_0__[\"default\"].error('Picked non-existent layer. Is picking buffer corrupt?')();\n          }\n        }\n      }\n    }\n  }\n\n  return Array.from(uniqueColors.values());\n}\n//# sourceMappingURL=query-object.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/lib/picking/query-object.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/lib/resource/resource-manager.js":
/*!******************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/lib/resource/resource-manager.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ ResourceManager)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _resource__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./resource */ \"./node_modules/@deck.gl/core/dist/esm/lib/resource/resource.js\");\n\n\nclass ResourceManager {\n  constructor({\n    gl,\n    protocol\n  }) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"protocol\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_context\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_resources\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_consumers\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_pruneRequest\", void 0);\n\n    this.protocol = protocol || 'resource://';\n    this._context = {\n      gl,\n      resourceManager: this\n    };\n    this._resources = {};\n    this._consumers = {};\n    this._pruneRequest = null;\n  }\n\n  contains(resourceId) {\n    if (resourceId.startsWith(this.protocol)) {\n      return true;\n    }\n\n    return resourceId in this._resources;\n  }\n\n  add({\n    resourceId,\n    data,\n    forceUpdate = false,\n    persistent = true\n  }) {\n    let res = this._resources[resourceId];\n\n    if (res) {\n      res.setData(data, forceUpdate);\n    } else {\n      res = new _resource__WEBPACK_IMPORTED_MODULE_1__[\"default\"](resourceId, data, this._context);\n      this._resources[resourceId] = res;\n    }\n\n    res.persistent = persistent;\n  }\n\n  remove(resourceId) {\n    const res = this._resources[resourceId];\n\n    if (res) {\n      res.delete();\n      delete this._resources[resourceId];\n    }\n  }\n\n  unsubscribe({\n    consumerId\n  }) {\n    const consumer = this._consumers[consumerId];\n\n    if (consumer) {\n      for (const requestId in consumer) {\n        const request = consumer[requestId];\n        const resource = this._resources[request.resourceId];\n\n        if (resource) {\n          resource.unsubscribe(request);\n        }\n      }\n\n      delete this._consumers[consumerId];\n      this.prune();\n    }\n  }\n\n  subscribe({\n    resourceId,\n    onChange,\n    consumerId,\n    requestId = 'default'\n  }) {\n    const {\n      _resources: resources,\n      protocol\n    } = this;\n\n    if (resourceId.startsWith(protocol)) {\n      resourceId = resourceId.replace(protocol, '');\n\n      if (!resources[resourceId]) {\n        this.add({\n          resourceId,\n          data: null,\n          persistent: false\n        });\n      }\n    }\n\n    const res = resources[resourceId];\n\n    this._track(consumerId, requestId, res, onChange);\n\n    if (res) {\n      return res.getData();\n    }\n\n    return undefined;\n  }\n\n  prune() {\n    if (!this._pruneRequest) {\n      this._pruneRequest = setTimeout(() => this._prune(), 0);\n    }\n  }\n\n  finalize() {\n    for (const key in this._resources) {\n      this._resources[key].delete();\n    }\n  }\n\n  _track(consumerId, requestId, resource, onChange) {\n    const consumers = this._consumers;\n    const consumer = consumers[consumerId] = consumers[consumerId] || {};\n    const request = consumer[requestId] || {};\n    const oldResource = request.resourceId && this._resources[request.resourceId];\n\n    if (oldResource) {\n      oldResource.unsubscribe(request);\n      this.prune();\n    }\n\n    if (resource) {\n      consumer[requestId] = request;\n      request.onChange = onChange;\n      request.resourceId = resource.id;\n      resource.subscribe(request);\n    }\n  }\n\n  _prune() {\n    this._pruneRequest = null;\n\n    for (const key of Object.keys(this._resources)) {\n      const res = this._resources[key];\n\n      if (!res.persistent && !res.inUse()) {\n        res.delete();\n        delete this._resources[key];\n      }\n    }\n  }\n\n}\n//# sourceMappingURL=resource-manager.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/lib/resource/resource-manager.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/lib/resource/resource.js":
/*!**********************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/lib/resource/resource.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Resource)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _loaders_gl_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @loaders.gl/core */ \"./node_modules/@loaders.gl/core/dist/esm/lib/api/load.js\");\n\n\nclass Resource {\n  constructor(id, data, context) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"id\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"context\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"isLoaded\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"persistent\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_loadCount\", 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_subscribers\", new Set());\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_data\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_loader\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_error\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_content\", void 0);\n\n    this.id = id;\n    this.context = context;\n    this.setData(data);\n  }\n\n  subscribe(consumer) {\n    this._subscribers.add(consumer);\n  }\n\n  unsubscribe(consumer) {\n    this._subscribers.delete(consumer);\n  }\n\n  inUse() {\n    return this._subscribers.size > 0;\n  }\n\n  delete() {}\n\n  getData() {\n    return this.isLoaded ? this._error ? Promise.reject(this._error) : this._content : this._loader.then(() => this.getData());\n  }\n\n  setData(data, forceUpdate) {\n    if (data === this._data && !forceUpdate) {\n      return;\n    }\n\n    this._data = data;\n    const loadCount = ++this._loadCount;\n    let loader = data;\n\n    if (typeof data === 'string') {\n      loader = (0,_loaders_gl_core__WEBPACK_IMPORTED_MODULE_1__.load)(data);\n    }\n\n    if (loader instanceof Promise) {\n      this.isLoaded = false;\n      this._loader = loader.then(result => {\n        if (this._loadCount === loadCount) {\n          this.isLoaded = true;\n          this._error = undefined;\n          this._content = result;\n        }\n      }).catch(error => {\n        if (this._loadCount === loadCount) {\n          this.isLoaded = true;\n          this._error = error || true;\n        }\n      });\n    } else {\n      this.isLoaded = true;\n      this._error = undefined;\n      this._content = data;\n    }\n\n    for (const subscriber of this._subscribers) {\n      subscriber.onChange(this.getData());\n    }\n  }\n\n}\n//# sourceMappingURL=resource.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/lib/resource/resource.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/lib/tooltip.js":
/*!************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/lib/tooltip.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Tooltip)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n\nconst defaultStyle = {\n  zIndex: '1',\n  position: 'absolute',\n  pointerEvents: 'none',\n  color: '#a0a7b4',\n  backgroundColor: '#29323c',\n  padding: '10px',\n  top: '0',\n  left: '0',\n  display: 'none'\n};\nclass Tooltip {\n  constructor(canvas) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"el\", null);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"isVisible\", false);\n\n    const canvasParent = canvas.parentElement;\n\n    if (canvasParent) {\n      this.el = document.createElement('div');\n      this.el.className = 'deck-tooltip';\n      Object.assign(this.el.style, defaultStyle);\n      canvasParent.appendChild(this.el);\n    }\n  }\n\n  setTooltip(displayInfo, x, y) {\n    const el = this.el;\n\n    if (!el) {\n      return;\n    }\n\n    if (typeof displayInfo === 'string') {\n      el.innerText = displayInfo;\n    } else if (!displayInfo) {\n      this.isVisible = false;\n      el.style.display = 'none';\n      return;\n    } else {\n      if (displayInfo.text) {\n        el.innerText = displayInfo.text;\n      }\n\n      if (displayInfo.html) {\n        el.innerHTML = displayInfo.html;\n      }\n\n      if (displayInfo.className) {\n        el.className = displayInfo.className;\n      }\n    }\n\n    this.isVisible = true;\n    el.style.display = 'block';\n    el.style.transform = \"translate(\".concat(x, \"px, \").concat(y, \"px)\");\n\n    if (displayInfo && typeof displayInfo === 'object' && 'style' in displayInfo) {\n      Object.assign(el.style, displayInfo.style);\n    }\n  }\n\n  remove() {\n    if (this.el) {\n      this.el.remove();\n      this.el = null;\n    }\n  }\n\n}\n//# sourceMappingURL=tooltip.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/lib/tooltip.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/lib/uniform-transition-manager.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/lib/uniform-transition-manager.js ***!
  \*******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ UniformTransitionManager)\n/* harmony export */ });\n/* harmony import */ var _attribute_attribute_transition_utils__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./attribute/attribute-transition-utils */ \"./node_modules/@deck.gl/core/dist/esm/lib/attribute/attribute-transition-utils.js\");\n/* harmony import */ var _transitions_cpu_interpolation_transition__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../transitions/cpu-interpolation-transition */ \"./node_modules/@deck.gl/core/dist/esm/transitions/cpu-interpolation-transition.js\");\n/* harmony import */ var _transitions_cpu_spring_transition__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../transitions/cpu-spring-transition */ \"./node_modules/@deck.gl/core/dist/esm/transitions/cpu-spring-transition.js\");\n/* harmony import */ var _utils_log__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/log */ \"./node_modules/@deck.gl/core/dist/esm/utils/log.js\");\n\n\n\n\nconst TRANSITION_TYPES = {\n  interpolation: _transitions_cpu_interpolation_transition__WEBPACK_IMPORTED_MODULE_0__[\"default\"],\n  spring: _transitions_cpu_spring_transition__WEBPACK_IMPORTED_MODULE_1__[\"default\"]\n};\nclass UniformTransitionManager {\n  constructor(timeline) {\n    this.transitions = new Map();\n    this.timeline = timeline;\n  }\n\n  get active() {\n    return this.transitions.size > 0;\n  }\n\n  add(key, fromValue, toValue, settings) {\n    const {\n      transitions\n    } = this;\n\n    if (transitions.has(key)) {\n      const transition = transitions.get(key);\n      const {\n        value = transition.settings.fromValue\n      } = transition;\n      fromValue = value;\n      this.remove(key);\n    }\n\n    settings = (0,_attribute_attribute_transition_utils__WEBPACK_IMPORTED_MODULE_2__.normalizeTransitionSettings)(settings);\n\n    if (!settings) {\n      return;\n    }\n\n    const TransitionType = TRANSITION_TYPES[settings.type];\n\n    if (!TransitionType) {\n      _utils_log__WEBPACK_IMPORTED_MODULE_3__[\"default\"].error(\"unsupported transition type '\".concat(settings.type, \"'\"))();\n      return;\n    }\n\n    const transition = new TransitionType(this.timeline);\n    transition.start({ ...settings,\n      fromValue,\n      toValue\n    });\n    transitions.set(key, transition);\n  }\n\n  remove(key) {\n    const {\n      transitions\n    } = this;\n\n    if (transitions.has(key)) {\n      transitions.get(key).cancel();\n      transitions.delete(key);\n    }\n  }\n\n  update() {\n    const propsInTransition = {};\n\n    for (const [key, transition] of this.transitions) {\n      transition.update();\n      propsInTransition[key] = transition.value;\n\n      if (!transition.inProgress) {\n        this.remove(key);\n      }\n    }\n\n    return propsInTransition;\n  }\n\n  clear() {\n    for (const key of this.transitions.keys()) {\n      this.remove(key);\n    }\n  }\n\n}\n//# sourceMappingURL=uniform-transition-manager.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/lib/uniform-transition-manager.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/lib/view-manager.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/lib/view-manager.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ ViewManager)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _utils_deep_equal__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/deep-equal */ \"./node_modules/@deck.gl/core/dist/esm/utils/deep-equal.js\");\n/* harmony import */ var _utils_log__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/log */ \"./node_modules/@deck.gl/core/dist/esm/utils/log.js\");\n/* harmony import */ var _utils_flatten__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/flatten */ \"./node_modules/@deck.gl/core/dist/esm/utils/flatten.js\");\n\n\n\n\nclass ViewManager {\n  constructor(props) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"width\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"height\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"views\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"viewState\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"controllers\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"timeline\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_viewports\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_viewportMap\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_isUpdating\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_needsRedraw\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_needsUpdate\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_eventManager\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_eventCallbacks\", void 0);\n\n    this.views = [];\n    this.width = 100;\n    this.height = 100;\n    this.viewState = {};\n    this.controllers = {};\n    this.timeline = props.timeline;\n    this._viewports = [];\n    this._viewportMap = {};\n    this._isUpdating = false;\n    this._needsRedraw = 'First render';\n    this._needsUpdate = 'Initialize';\n    this._eventManager = props.eventManager;\n    this._eventCallbacks = {\n      onViewStateChange: props.onViewStateChange,\n      onInteractionStateChange: props.onInteractionStateChange\n    };\n    Object.seal(this);\n    this.setProps(props);\n  }\n\n  finalize() {\n    for (const key in this.controllers) {\n      const controller = this.controllers[key];\n\n      if (controller) {\n        controller.finalize();\n      }\n    }\n\n    this.controllers = {};\n  }\n\n  needsRedraw(opts = {\n    clearRedrawFlags: false\n  }) {\n    const redraw = this._needsRedraw;\n\n    if (opts.clearRedrawFlags) {\n      this._needsRedraw = false;\n    }\n\n    return redraw;\n  }\n\n  setNeedsUpdate(reason) {\n    this._needsUpdate = this._needsUpdate || reason;\n    this._needsRedraw = this._needsRedraw || reason;\n  }\n\n  updateViewStates() {\n    for (const viewId in this.controllers) {\n      const controller = this.controllers[viewId];\n\n      if (controller) {\n        controller.updateTransition();\n      }\n    }\n  }\n\n  getViewports(rect) {\n    if (rect) {\n      return this._viewports.filter(viewport => viewport.containsPixel(rect));\n    }\n\n    return this._viewports;\n  }\n\n  getViews() {\n    const viewMap = {};\n    this.views.forEach(view => {\n      viewMap[view.id] = view;\n    });\n    return viewMap;\n  }\n\n  getView(viewId) {\n    return this.views.find(view => view.id === viewId);\n  }\n\n  getViewState(viewOrViewId) {\n    const view = typeof viewOrViewId === 'string' ? this.getView(viewOrViewId) : viewOrViewId;\n    const viewState = view && this.viewState[view.getViewStateId()] || this.viewState;\n    return view ? view.filterViewState(viewState) : viewState;\n  }\n\n  getViewport(viewId) {\n    return this._viewportMap[viewId];\n  }\n\n  unproject(xyz, opts) {\n    const viewports = this.getViewports();\n    const pixel = {\n      x: xyz[0],\n      y: xyz[1]\n    };\n\n    for (let i = viewports.length - 1; i >= 0; --i) {\n      const viewport = viewports[i];\n\n      if (viewport.containsPixel(pixel)) {\n        const p = xyz.slice();\n        p[0] -= viewport.x;\n        p[1] -= viewport.y;\n        return viewport.unproject(p, opts);\n      }\n    }\n\n    return null;\n  }\n\n  setProps(props) {\n    if (props.views) {\n      this._setViews(props.views);\n    }\n\n    if (props.viewState) {\n      this._setViewState(props.viewState);\n    }\n\n    if ('width' in props || 'height' in props) {\n      this._setSize(props.width, props.height);\n    }\n\n    if (!this._isUpdating) {\n      this._update();\n    }\n  }\n\n  _update() {\n    this._isUpdating = true;\n\n    if (this._needsUpdate) {\n      this._needsUpdate = false;\n\n      this._rebuildViewports();\n    }\n\n    if (this._needsUpdate) {\n      this._needsUpdate = false;\n\n      this._rebuildViewports();\n    }\n\n    this._isUpdating = false;\n  }\n\n  _setSize(width, height) {\n    if (width !== this.width || height !== this.height) {\n      this.width = width;\n      this.height = height;\n      this.setNeedsUpdate('Size changed');\n    }\n  }\n\n  _setViews(views) {\n    views = (0,_utils_flatten__WEBPACK_IMPORTED_MODULE_1__.flatten)(views, Boolean);\n\n    const viewsChanged = this._diffViews(views, this.views);\n\n    if (viewsChanged) {\n      this.setNeedsUpdate('views changed');\n    }\n\n    this.views = views;\n  }\n\n  _setViewState(viewState) {\n    if (viewState) {\n      const viewStateChanged = !(0,_utils_deep_equal__WEBPACK_IMPORTED_MODULE_2__.deepEqual)(viewState, this.viewState, 3);\n\n      if (viewStateChanged) {\n        this.setNeedsUpdate('viewState changed');\n      }\n\n      this.viewState = viewState;\n    } else {\n      _utils_log__WEBPACK_IMPORTED_MODULE_3__[\"default\"].warn('missing `viewState` or `initialViewState`')();\n    }\n  }\n\n  _onViewStateChange(viewId, event) {\n    if (this._eventCallbacks.onViewStateChange) {\n      this._eventCallbacks.onViewStateChange({ ...event,\n        viewId\n      });\n    }\n  }\n\n  _createController(view, props) {\n    const Controller = props.type;\n    const controller = new Controller({\n      timeline: this.timeline,\n      eventManager: this._eventManager,\n      onViewStateChange: this._onViewStateChange.bind(this, props.id),\n      onStateChange: this._eventCallbacks.onInteractionStateChange,\n      makeViewport: viewState => {\n        var _this$getView;\n\n        return (_this$getView = this.getView(view.id)) === null || _this$getView === void 0 ? void 0 : _this$getView.makeViewport({\n          viewState,\n          width: this.width,\n          height: this.height\n        });\n      }\n    });\n    return controller;\n  }\n\n  _updateController(view, viewState, viewport, controller) {\n    const controllerProps = view.controller;\n\n    if (controllerProps && viewport) {\n      const resolvedProps = { ...viewState,\n        ...controllerProps,\n        id: view.id,\n        x: viewport.x,\n        y: viewport.y,\n        width: viewport.width,\n        height: viewport.height\n      };\n\n      if (!controller || controller.constructor !== controllerProps.type) {\n        controller = this._createController(view, resolvedProps);\n      }\n\n      if (controller) {\n        controller.setProps(resolvedProps);\n      }\n\n      return controller;\n    }\n\n    return null;\n  }\n\n  _rebuildViewports() {\n    const {\n      views\n    } = this;\n    const oldControllers = this.controllers;\n    this._viewports = [];\n    this.controllers = {};\n    let invalidateControllers = false;\n\n    for (let i = views.length; i--;) {\n      const view = views[i];\n      const viewState = this.getViewState(view);\n      const viewport = view.makeViewport({\n        viewState,\n        width: this.width,\n        height: this.height\n      });\n      let oldController = oldControllers[view.id];\n      const hasController = Boolean(view.controller);\n\n      if (hasController && !oldController) {\n        invalidateControllers = true;\n      }\n\n      if ((invalidateControllers || !hasController) && oldController) {\n        oldController.finalize();\n        oldController = null;\n      }\n\n      this.controllers[view.id] = this._updateController(view, viewState, viewport, oldController);\n\n      if (viewport) {\n        this._viewports.unshift(viewport);\n      }\n    }\n\n    for (const id in oldControllers) {\n      const oldController = oldControllers[id];\n\n      if (oldController && !this.controllers[id]) {\n        oldController.finalize();\n      }\n    }\n\n    this._buildViewportMap();\n  }\n\n  _buildViewportMap() {\n    this._viewportMap = {};\n\n    this._viewports.forEach(viewport => {\n      if (viewport.id) {\n        this._viewportMap[viewport.id] = this._viewportMap[viewport.id] || viewport;\n      }\n    });\n  }\n\n  _diffViews(newViews, oldViews) {\n    if (newViews.length !== oldViews.length) {\n      return true;\n    }\n\n    return newViews.some((_, i) => !newViews[i].equals(oldViews[i]));\n  }\n\n}\n//# sourceMappingURL=view-manager.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/lib/view-manager.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/lifecycle/component-state.js":
/*!**************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/lifecycle/component-state.js ***!
  \**************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ ComponentState)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _utils_iterable_utils__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/iterable-utils */ \"./node_modules/@deck.gl/core/dist/esm/utils/iterable-utils.js\");\n/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./constants */ \"./node_modules/@deck.gl/core/dist/esm/lifecycle/constants.js\");\n\n\n\nconst EMPTY_PROPS = Object.freeze({});\nclass ComponentState {\n  constructor(component) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"component\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"onAsyncPropUpdated\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"asyncProps\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"oldProps\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"oldAsyncProps\", void 0);\n\n    this.component = component;\n    this.asyncProps = {};\n\n    this.onAsyncPropUpdated = () => {};\n\n    this.oldProps = null;\n    this.oldAsyncProps = null;\n  }\n\n  finalize() {\n    for (const propName in this.asyncProps) {\n      const asyncProp = this.asyncProps[propName];\n\n      if (asyncProp && asyncProp.type && asyncProp.type.release) {\n        asyncProp.type.release(asyncProp.resolvedValue, asyncProp.type, this.component);\n      }\n    }\n\n    this.asyncProps = {};\n    this.component = null;\n    this.resetOldProps();\n  }\n\n  getOldProps() {\n    return this.oldAsyncProps || this.oldProps || EMPTY_PROPS;\n  }\n\n  resetOldProps() {\n    this.oldAsyncProps = null;\n    this.oldProps = this.component ? this.component.props : null;\n  }\n\n  hasAsyncProp(propName) {\n    return propName in this.asyncProps;\n  }\n\n  getAsyncProp(propName) {\n    const asyncProp = this.asyncProps[propName];\n    return asyncProp && asyncProp.resolvedValue;\n  }\n\n  isAsyncPropLoading(propName) {\n    if (propName) {\n      const asyncProp = this.asyncProps[propName];\n      return Boolean(asyncProp && asyncProp.pendingLoadCount > 0 && asyncProp.pendingLoadCount !== asyncProp.resolvedLoadCount);\n    }\n\n    for (const key in this.asyncProps) {\n      if (this.isAsyncPropLoading(key)) {\n        return true;\n      }\n    }\n\n    return false;\n  }\n\n  reloadAsyncProp(propName, value) {\n    this._watchPromise(propName, Promise.resolve(value));\n  }\n\n  setAsyncProps(props) {\n    this.component = props[_constants__WEBPACK_IMPORTED_MODULE_1__.COMPONENT_SYMBOL] || this.component;\n    const resolvedValues = props[_constants__WEBPACK_IMPORTED_MODULE_1__.ASYNC_RESOLVED_SYMBOL] || {};\n    const originalValues = props[_constants__WEBPACK_IMPORTED_MODULE_1__.ASYNC_ORIGINAL_SYMBOL] || props;\n    const defaultValues = props[_constants__WEBPACK_IMPORTED_MODULE_1__.ASYNC_DEFAULTS_SYMBOL] || {};\n\n    for (const propName in resolvedValues) {\n      const value = resolvedValues[propName];\n\n      this._createAsyncPropData(propName, defaultValues[propName]);\n\n      this._updateAsyncProp(propName, value);\n\n      resolvedValues[propName] = this.getAsyncProp(propName);\n    }\n\n    for (const propName in originalValues) {\n      const value = originalValues[propName];\n\n      this._createAsyncPropData(propName, defaultValues[propName]);\n\n      this._updateAsyncProp(propName, value);\n    }\n  }\n\n  _fetch(propName, url) {\n    return null;\n  }\n\n  _onResolve(propName, value) {}\n\n  _onError(propName, error) {}\n\n  _updateAsyncProp(propName, value) {\n    if (!this._didAsyncInputValueChange(propName, value)) {\n      return;\n    }\n\n    if (typeof value === 'string') {\n      value = this._fetch(propName, value);\n    }\n\n    if (value instanceof Promise) {\n      this._watchPromise(propName, value);\n\n      return;\n    }\n\n    if ((0,_utils_iterable_utils__WEBPACK_IMPORTED_MODULE_2__.isAsyncIterable)(value)) {\n      this._resolveAsyncIterable(propName, value);\n\n      return;\n    }\n\n    this._setPropValue(propName, value);\n  }\n\n  _freezeAsyncOldProps() {\n    if (!this.oldAsyncProps && this.oldProps) {\n      this.oldAsyncProps = Object.create(this.oldProps);\n\n      for (const propName in this.asyncProps) {\n        Object.defineProperty(this.oldAsyncProps, propName, {\n          enumerable: true,\n          value: this.oldProps[propName]\n        });\n      }\n    }\n  }\n\n  _didAsyncInputValueChange(propName, value) {\n    const asyncProp = this.asyncProps[propName];\n\n    if (value === asyncProp.resolvedValue || value === asyncProp.lastValue) {\n      return false;\n    }\n\n    asyncProp.lastValue = value;\n    return true;\n  }\n\n  _setPropValue(propName, value) {\n    this._freezeAsyncOldProps();\n\n    const asyncProp = this.asyncProps[propName];\n\n    if (asyncProp) {\n      value = this._postProcessValue(asyncProp, value);\n      asyncProp.resolvedValue = value;\n      asyncProp.pendingLoadCount++;\n      asyncProp.resolvedLoadCount = asyncProp.pendingLoadCount;\n    }\n  }\n\n  _setAsyncPropValue(propName, value, loadCount) {\n    const asyncProp = this.asyncProps[propName];\n\n    if (asyncProp && loadCount >= asyncProp.resolvedLoadCount && value !== undefined) {\n      this._freezeAsyncOldProps();\n\n      asyncProp.resolvedValue = value;\n      asyncProp.resolvedLoadCount = loadCount;\n      this.onAsyncPropUpdated(propName, value);\n    }\n  }\n\n  _watchPromise(propName, promise) {\n    const asyncProp = this.asyncProps[propName];\n\n    if (asyncProp) {\n      asyncProp.pendingLoadCount++;\n      const loadCount = asyncProp.pendingLoadCount;\n      promise.then(data => {\n        if (!this.component) {\n          return;\n        }\n\n        data = this._postProcessValue(asyncProp, data);\n\n        this._setAsyncPropValue(propName, data, loadCount);\n\n        this._onResolve(propName, data);\n      }).catch(error => {\n        this._onError(propName, error);\n      });\n    }\n  }\n\n  async _resolveAsyncIterable(propName, iterable) {\n    if (propName !== 'data') {\n      this._setPropValue(propName, iterable);\n\n      return;\n    }\n\n    const asyncProp = this.asyncProps[propName];\n\n    if (!asyncProp) {\n      return;\n    }\n\n    asyncProp.pendingLoadCount++;\n    const loadCount = asyncProp.pendingLoadCount;\n    let data = [];\n    let count = 0;\n\n    for await (const chunk of iterable) {\n      if (!this.component) {\n        return;\n      }\n\n      const {\n        dataTransform\n      } = this.component.props;\n\n      if (dataTransform) {\n        data = dataTransform(chunk, data);\n      } else {\n        data = data.concat(chunk);\n      }\n\n      Object.defineProperty(data, '__diff', {\n        enumerable: false,\n        value: [{\n          startRow: count,\n          endRow: data.length\n        }]\n      });\n      count = data.length;\n\n      this._setAsyncPropValue(propName, data, loadCount);\n    }\n\n    this._onResolve(propName, data);\n  }\n\n  _postProcessValue(asyncProp, value) {\n    const propType = asyncProp.type;\n\n    if (propType && this.component) {\n      if (propType.release) {\n        propType.release(asyncProp.resolvedValue, propType, this.component);\n      }\n\n      if (propType.transform) {\n        return propType.transform(value, propType, this.component);\n      }\n    }\n\n    return value;\n  }\n\n  _createAsyncPropData(propName, defaultValue) {\n    const asyncProp = this.asyncProps[propName];\n\n    if (!asyncProp) {\n      const propTypes = this.component && this.component.props[_constants__WEBPACK_IMPORTED_MODULE_1__.PROP_TYPES_SYMBOL];\n      this.asyncProps[propName] = {\n        type: propTypes && propTypes[propName],\n        lastValue: null,\n        resolvedValue: defaultValue,\n        pendingLoadCount: 0,\n        resolvedLoadCount: 0\n      };\n    }\n  }\n\n}\n//# sourceMappingURL=component-state.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/lifecycle/component-state.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/lifecycle/component.js":
/*!********************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/lifecycle/component.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Component)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./constants */ \"./node_modules/@deck.gl/core/dist/esm/lifecycle/constants.js\");\n/* harmony import */ var _create_props__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./create-props */ \"./node_modules/@deck.gl/core/dist/esm/lifecycle/create-props.js\");\n\n\n\nlet counter = 0;\nclass Component {\n  constructor(...propObjects) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"id\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"props\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"count\", void 0);\n\n    this.props = (0,_create_props__WEBPACK_IMPORTED_MODULE_1__.createProps)(this, propObjects);\n    this.id = this.props.id;\n    this.count = counter++;\n  }\n\n  clone(newProps) {\n    const {\n      props\n    } = this;\n    const asyncProps = {};\n\n    for (const key in props[_constants__WEBPACK_IMPORTED_MODULE_2__.ASYNC_DEFAULTS_SYMBOL]) {\n      if (key in props[_constants__WEBPACK_IMPORTED_MODULE_2__.ASYNC_RESOLVED_SYMBOL]) {\n        asyncProps[key] = props[_constants__WEBPACK_IMPORTED_MODULE_2__.ASYNC_RESOLVED_SYMBOL][key];\n      } else if (key in props[_constants__WEBPACK_IMPORTED_MODULE_2__.ASYNC_ORIGINAL_SYMBOL]) {\n        asyncProps[key] = props[_constants__WEBPACK_IMPORTED_MODULE_2__.ASYNC_ORIGINAL_SYMBOL][key];\n      }\n    }\n\n    return new this.constructor({ ...props,\n      ...asyncProps,\n      ...newProps\n    });\n  }\n\n}\n\n(0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(Component, \"componentName\", 'Component');\n\n(0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(Component, \"defaultProps\", {});\n//# sourceMappingURL=component.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/lifecycle/component.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/lifecycle/constants.js":
/*!********************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/lifecycle/constants.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   ASYNC_DEFAULTS_SYMBOL: () => (/* binding */ ASYNC_DEFAULTS_SYMBOL),\n/* harmony export */   ASYNC_ORIGINAL_SYMBOL: () => (/* binding */ ASYNC_ORIGINAL_SYMBOL),\n/* harmony export */   ASYNC_RESOLVED_SYMBOL: () => (/* binding */ ASYNC_RESOLVED_SYMBOL),\n/* harmony export */   COMPONENT_SYMBOL: () => (/* binding */ COMPONENT_SYMBOL),\n/* harmony export */   DEPRECATED_PROPS_SYMBOL: () => (/* binding */ DEPRECATED_PROPS_SYMBOL),\n/* harmony export */   LIFECYCLE: () => (/* binding */ LIFECYCLE),\n/* harmony export */   PROP_TYPES_SYMBOL: () => (/* binding */ PROP_TYPES_SYMBOL)\n/* harmony export */ });\nconst LIFECYCLE = {\n  NO_STATE: 'Awaiting state',\n  MATCHED: 'Matched. State transferred from previous layer',\n  INITIALIZED: 'Initialized',\n  AWAITING_GC: 'Discarded. Awaiting garbage collection',\n  AWAITING_FINALIZATION: 'No longer matched. Awaiting garbage collection',\n  FINALIZED: 'Finalized! Awaiting garbage collection'\n};\nconst COMPONENT_SYMBOL = Symbol.for('component');\nconst PROP_TYPES_SYMBOL = Symbol.for('propTypes');\nconst DEPRECATED_PROPS_SYMBOL = Symbol.for('deprecatedProps');\nconst ASYNC_DEFAULTS_SYMBOL = Symbol.for('asyncPropDefaults');\nconst ASYNC_ORIGINAL_SYMBOL = Symbol.for('asyncPropOriginal');\nconst ASYNC_RESOLVED_SYMBOL = Symbol.for('asyncPropResolved');\n//# sourceMappingURL=constants.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/lifecycle/constants.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/lifecycle/create-props.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/lifecycle/create-props.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   createProps: () => (/* binding */ createProps)\n/* harmony export */ });\n/* harmony import */ var _utils_log__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/log */ \"./node_modules/@deck.gl/core/dist/esm/utils/log.js\");\n/* harmony import */ var _utils_iterable_utils__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/iterable-utils */ \"./node_modules/@deck.gl/core/dist/esm/utils/iterable-utils.js\");\n/* harmony import */ var _prop_types__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./prop-types */ \"./node_modules/@deck.gl/core/dist/esm/lifecycle/prop-types.js\");\n/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./constants */ \"./node_modules/@deck.gl/core/dist/esm/lifecycle/constants.js\");\n\n\n\n\nfunction createProps(component, propObjects) {\n  let extensions;\n\n  for (let i = propObjects.length - 1; i >= 0; i--) {\n    const props = propObjects[i];\n\n    if ('extensions' in props) {\n      extensions = props.extensions;\n    }\n  }\n\n  const propsPrototype = getPropsPrototype(component.constructor, extensions);\n  const propsInstance = Object.create(propsPrototype);\n  propsInstance[_constants__WEBPACK_IMPORTED_MODULE_0__.COMPONENT_SYMBOL] = component;\n  propsInstance[_constants__WEBPACK_IMPORTED_MODULE_0__.ASYNC_ORIGINAL_SYMBOL] = {};\n  propsInstance[_constants__WEBPACK_IMPORTED_MODULE_0__.ASYNC_RESOLVED_SYMBOL] = {};\n\n  for (let i = 0; i < propObjects.length; ++i) {\n    const props = propObjects[i];\n\n    for (const key in props) {\n      propsInstance[key] = props[key];\n    }\n  }\n\n  Object.freeze(propsInstance);\n  return propsInstance;\n}\nconst MergedDefaultPropsCacheKey = '_mergedDefaultProps';\n\nfunction getPropsPrototype(componentClass, extensions) {\n  let cacheKey = MergedDefaultPropsCacheKey;\n\n  if (extensions) {\n    for (const extension of extensions) {\n      const ExtensionClass = extension.constructor;\n\n      if (ExtensionClass) {\n        cacheKey += \":\".concat(ExtensionClass.extensionName || ExtensionClass.name);\n      }\n    }\n  }\n\n  const defaultProps = getOwnProperty(componentClass, cacheKey);\n\n  if (!defaultProps) {\n    return componentClass[cacheKey] = createPropsPrototypeAndTypes(componentClass, extensions || []);\n  }\n\n  return defaultProps;\n}\n\nfunction createPropsPrototypeAndTypes(componentClass, extensions) {\n  const parent = componentClass.prototype;\n\n  if (!parent) {\n    return null;\n  }\n\n  const parentClass = Object.getPrototypeOf(componentClass);\n  const parentDefaultProps = getPropsPrototype(parentClass);\n  const componentDefaultProps = getOwnProperty(componentClass, 'defaultProps') || {};\n  const componentPropDefs = (0,_prop_types__WEBPACK_IMPORTED_MODULE_1__.parsePropTypes)(componentDefaultProps);\n  const defaultProps = Object.assign(Object.create(null), parentDefaultProps, componentPropDefs.defaultProps);\n  const propTypes = Object.assign(Object.create(null), parentDefaultProps === null || parentDefaultProps === void 0 ? void 0 : parentDefaultProps[_constants__WEBPACK_IMPORTED_MODULE_0__.PROP_TYPES_SYMBOL], componentPropDefs.propTypes);\n  const deprecatedProps = Object.assign(Object.create(null), parentDefaultProps === null || parentDefaultProps === void 0 ? void 0 : parentDefaultProps[_constants__WEBPACK_IMPORTED_MODULE_0__.DEPRECATED_PROPS_SYMBOL], componentPropDefs.deprecatedProps);\n\n  for (const extension of extensions) {\n    const extensionDefaultProps = getPropsPrototype(extension.constructor);\n\n    if (extensionDefaultProps) {\n      Object.assign(defaultProps, extensionDefaultProps);\n      Object.assign(propTypes, extensionDefaultProps[_constants__WEBPACK_IMPORTED_MODULE_0__.PROP_TYPES_SYMBOL]);\n      Object.assign(deprecatedProps, extensionDefaultProps[_constants__WEBPACK_IMPORTED_MODULE_0__.DEPRECATED_PROPS_SYMBOL]);\n    }\n  }\n\n  createPropsPrototype(defaultProps, componentClass);\n  addAsyncPropsToPropPrototype(defaultProps, propTypes);\n  addDeprecatedPropsToPropPrototype(defaultProps, deprecatedProps);\n  defaultProps[_constants__WEBPACK_IMPORTED_MODULE_0__.PROP_TYPES_SYMBOL] = propTypes;\n  defaultProps[_constants__WEBPACK_IMPORTED_MODULE_0__.DEPRECATED_PROPS_SYMBOL] = deprecatedProps;\n\n  if (extensions.length === 0 && !hasOwnProperty(componentClass, '_propTypes')) {\n    componentClass._propTypes = propTypes;\n  }\n\n  return defaultProps;\n}\n\nfunction createPropsPrototype(defaultProps, componentClass) {\n  const id = getComponentName(componentClass);\n  Object.defineProperties(defaultProps, {\n    id: {\n      writable: true,\n      value: id\n    }\n  });\n}\n\nfunction addDeprecatedPropsToPropPrototype(defaultProps, deprecatedProps) {\n  for (const propName in deprecatedProps) {\n    Object.defineProperty(defaultProps, propName, {\n      enumerable: false,\n\n      set(newValue) {\n        const nameStr = \"\".concat(this.id, \": \").concat(propName);\n\n        for (const newPropName of deprecatedProps[propName]) {\n          if (!hasOwnProperty(this, newPropName)) {\n            this[newPropName] = newValue;\n          }\n        }\n\n        _utils_log__WEBPACK_IMPORTED_MODULE_2__[\"default\"].deprecated(nameStr, deprecatedProps[propName].join('/'))();\n      }\n\n    });\n  }\n}\n\nfunction addAsyncPropsToPropPrototype(defaultProps, propTypes) {\n  const defaultValues = {};\n  const descriptors = {};\n\n  for (const propName in propTypes) {\n    const propType = propTypes[propName];\n    const {\n      name,\n      value\n    } = propType;\n\n    if (propType.async) {\n      defaultValues[name] = value;\n      descriptors[name] = getDescriptorForAsyncProp(name);\n    }\n  }\n\n  defaultProps[_constants__WEBPACK_IMPORTED_MODULE_0__.ASYNC_DEFAULTS_SYMBOL] = defaultValues;\n  defaultProps[_constants__WEBPACK_IMPORTED_MODULE_0__.ASYNC_ORIGINAL_SYMBOL] = {};\n  Object.defineProperties(defaultProps, descriptors);\n}\n\nfunction getDescriptorForAsyncProp(name) {\n  return {\n    enumerable: true,\n\n    set(newValue) {\n      if (typeof newValue === 'string' || newValue instanceof Promise || (0,_utils_iterable_utils__WEBPACK_IMPORTED_MODULE_3__.isAsyncIterable)(newValue)) {\n        this[_constants__WEBPACK_IMPORTED_MODULE_0__.ASYNC_ORIGINAL_SYMBOL][name] = newValue;\n      } else {\n        this[_constants__WEBPACK_IMPORTED_MODULE_0__.ASYNC_RESOLVED_SYMBOL][name] = newValue;\n      }\n    },\n\n    get() {\n      if (this[_constants__WEBPACK_IMPORTED_MODULE_0__.ASYNC_RESOLVED_SYMBOL]) {\n        if (name in this[_constants__WEBPACK_IMPORTED_MODULE_0__.ASYNC_RESOLVED_SYMBOL]) {\n          const value = this[_constants__WEBPACK_IMPORTED_MODULE_0__.ASYNC_RESOLVED_SYMBOL][name];\n          return value || this[_constants__WEBPACK_IMPORTED_MODULE_0__.ASYNC_DEFAULTS_SYMBOL][name];\n        }\n\n        if (name in this[_constants__WEBPACK_IMPORTED_MODULE_0__.ASYNC_ORIGINAL_SYMBOL]) {\n          const state = this[_constants__WEBPACK_IMPORTED_MODULE_0__.COMPONENT_SYMBOL] && this[_constants__WEBPACK_IMPORTED_MODULE_0__.COMPONENT_SYMBOL].internalState;\n\n          if (state && state.hasAsyncProp(name)) {\n            return state.getAsyncProp(name) || this[_constants__WEBPACK_IMPORTED_MODULE_0__.ASYNC_DEFAULTS_SYMBOL][name];\n          }\n        }\n      }\n\n      return this[_constants__WEBPACK_IMPORTED_MODULE_0__.ASYNC_DEFAULTS_SYMBOL][name];\n    }\n\n  };\n}\n\nfunction hasOwnProperty(object, prop) {\n  return Object.prototype.hasOwnProperty.call(object, prop);\n}\n\nfunction getOwnProperty(object, prop) {\n  return hasOwnProperty(object, prop) && object[prop];\n}\n\nfunction getComponentName(componentClass) {\n  const componentName = componentClass.componentName;\n\n  if (!componentName) {\n    _utils_log__WEBPACK_IMPORTED_MODULE_2__[\"default\"].warn(\"\".concat(componentClass.name, \".componentName not specified\"))();\n  }\n\n  return componentName || componentClass.name;\n}\n//# sourceMappingURL=create-props.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/lifecycle/create-props.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/lifecycle/prop-types.js":
/*!*********************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/lifecycle/prop-types.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   parsePropTypes: () => (/* binding */ parsePropTypes)\n/* harmony export */ });\n/* harmony import */ var _utils_texture__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/texture */ \"./node_modules/@deck.gl/core/dist/esm/utils/texture.js\");\n/* harmony import */ var _utils_deep_equal__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/deep-equal */ \"./node_modules/@deck.gl/core/dist/esm/utils/deep-equal.js\");\n\n\nconst TYPE_DEFINITIONS = {\n  boolean: {\n    validate(value, propType) {\n      return true;\n    },\n\n    equal(value1, value2, propType) {\n      return Boolean(value1) === Boolean(value2);\n    }\n\n  },\n  number: {\n    validate(value, propType) {\n      return Number.isFinite(value) && (!('max' in propType) || value <= propType.max) && (!('min' in propType) || value >= propType.min);\n    }\n\n  },\n  color: {\n    validate(value, propType) {\n      return propType.optional && !value || isArray(value) && (value.length === 3 || value.length === 4);\n    },\n\n    equal(value1, value2, propType) {\n      return (0,_utils_deep_equal__WEBPACK_IMPORTED_MODULE_0__.deepEqual)(value1, value2, 1);\n    }\n\n  },\n  accessor: {\n    validate(value, propType) {\n      const valueType = getTypeOf(value);\n      return valueType === 'function' || valueType === getTypeOf(propType.value);\n    },\n\n    equal(value1, value2, propType) {\n      if (typeof value2 === 'function') {\n        return true;\n      }\n\n      return (0,_utils_deep_equal__WEBPACK_IMPORTED_MODULE_0__.deepEqual)(value1, value2, 1);\n    }\n\n  },\n  array: {\n    validate(value, propType) {\n      return propType.optional && !value || isArray(value);\n    },\n\n    equal(value1, value2, propType) {\n      const {\n        compare\n      } = propType;\n      const depth = Number.isInteger(compare) ? compare : compare ? 1 : 0;\n      return compare ? (0,_utils_deep_equal__WEBPACK_IMPORTED_MODULE_0__.deepEqual)(value1, value2, depth) : value1 === value2;\n    }\n\n  },\n  object: {\n    equal(value1, value2, propType) {\n      if (propType.ignore) {\n        return true;\n      }\n\n      const {\n        compare\n      } = propType;\n      const depth = Number.isInteger(compare) ? compare : compare ? 1 : 0;\n      return compare ? (0,_utils_deep_equal__WEBPACK_IMPORTED_MODULE_0__.deepEqual)(value1, value2, depth) : value1 === value2;\n    }\n\n  },\n  function: {\n    validate(value, propType) {\n      return propType.optional && !value || typeof value === 'function';\n    },\n\n    equal(value1, value2, propType) {\n      const shouldIgnore = !propType.compare && propType.ignore !== false;\n      return shouldIgnore || value1 === value2;\n    }\n\n  },\n  data: {\n    transform: (value, propType, component) => {\n      const {\n        dataTransform\n      } = component.props;\n      return dataTransform && value ? dataTransform(value) : value;\n    }\n  },\n  image: {\n    transform: (value, propType, component) => {\n      const context = component.context;\n\n      if (!context || !context.gl) {\n        return null;\n      }\n\n      return (0,_utils_texture__WEBPACK_IMPORTED_MODULE_1__.createTexture)(component.id, context.gl, value, { ...propType.parameters,\n        ...component.props.textureParameters\n      });\n    },\n    release: (value, propType, component) => {\n      (0,_utils_texture__WEBPACK_IMPORTED_MODULE_1__.destroyTexture)(component.id, value);\n    }\n  }\n};\nfunction parsePropTypes(propDefs) {\n  const propTypes = {};\n  const defaultProps = {};\n  const deprecatedProps = {};\n\n  for (const [propName, propDef] of Object.entries(propDefs)) {\n    const deprecated = propDef === null || propDef === void 0 ? void 0 : propDef.deprecatedFor;\n\n    if (deprecated) {\n      deprecatedProps[propName] = Array.isArray(deprecated) ? deprecated : [deprecated];\n    } else {\n      const propType = parsePropType(propName, propDef);\n      propTypes[propName] = propType;\n      defaultProps[propName] = propType.value;\n    }\n  }\n\n  return {\n    propTypes,\n    defaultProps,\n    deprecatedProps\n  };\n}\n\nfunction parsePropType(name, propDef) {\n  switch (getTypeOf(propDef)) {\n    case 'object':\n      return normalizePropDefinition(name, propDef);\n\n    case 'array':\n      return normalizePropDefinition(name, {\n        type: 'array',\n        value: propDef,\n        compare: false\n      });\n\n    case 'boolean':\n      return normalizePropDefinition(name, {\n        type: 'boolean',\n        value: propDef\n      });\n\n    case 'number':\n      return normalizePropDefinition(name, {\n        type: 'number',\n        value: propDef\n      });\n\n    case 'function':\n      return normalizePropDefinition(name, {\n        type: 'function',\n        value: propDef,\n        compare: true\n      });\n\n    default:\n      return {\n        name,\n        type: 'unknown',\n        value: propDef\n      };\n  }\n}\n\nfunction normalizePropDefinition(name, propDef) {\n  if (!('type' in propDef)) {\n    if (!('value' in propDef)) {\n      return {\n        name,\n        type: 'object',\n        value: propDef\n      };\n    }\n\n    return {\n      name,\n      type: getTypeOf(propDef.value),\n      ...propDef\n    };\n  }\n\n  return {\n    name,\n    ...TYPE_DEFINITIONS[propDef.type],\n    ...propDef\n  };\n}\n\nfunction isArray(value) {\n  return Array.isArray(value) || ArrayBuffer.isView(value);\n}\n\nfunction getTypeOf(value) {\n  if (isArray(value)) {\n    return 'array';\n  }\n\n  if (value === null) {\n    return 'null';\n  }\n\n  return typeof value;\n}\n//# sourceMappingURL=prop-types.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/lifecycle/prop-types.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/lifecycle/props.js":
/*!****************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/lifecycle/props.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   compareProps: () => (/* binding */ compareProps),\n/* harmony export */   diffProps: () => (/* binding */ diffProps),\n/* harmony export */   validateProps: () => (/* binding */ validateProps)\n/* harmony export */ });\n/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./constants */ \"./node_modules/@deck.gl/core/dist/esm/lifecycle/constants.js\");\n\nfunction validateProps(props) {\n  const propTypes = props[_constants__WEBPACK_IMPORTED_MODULE_0__.PROP_TYPES_SYMBOL];\n\n  for (const propName in propTypes) {\n    const propType = propTypes[propName];\n    const {\n      validate\n    } = propType;\n\n    if (validate && !validate(props[propName], propType)) {\n      throw new Error(\"Invalid prop \".concat(propName, \": \").concat(props[propName]));\n    }\n  }\n}\nfunction diffProps(props, oldProps) {\n  const propsChangedReason = compareProps({\n    newProps: props,\n    oldProps,\n    propTypes: props[_constants__WEBPACK_IMPORTED_MODULE_0__.PROP_TYPES_SYMBOL],\n    ignoreProps: {\n      data: null,\n      updateTriggers: null,\n      extensions: null,\n      transitions: null\n    }\n  });\n  const dataChangedReason = diffDataProps(props, oldProps);\n  let updateTriggersChangedReason = false;\n\n  if (!dataChangedReason) {\n    updateTriggersChangedReason = diffUpdateTriggers(props, oldProps);\n  }\n\n  return {\n    dataChanged: dataChangedReason,\n    propsChanged: propsChangedReason,\n    updateTriggersChanged: updateTriggersChangedReason,\n    extensionsChanged: diffExtensions(props, oldProps),\n    transitionsChanged: diffTransitions(props, oldProps)\n  };\n}\n\nfunction diffTransitions(props, oldProps) {\n  if (!props.transitions) {\n    return false;\n  }\n\n  const result = {};\n  const propTypes = props[_constants__WEBPACK_IMPORTED_MODULE_0__.PROP_TYPES_SYMBOL];\n  let changed = false;\n\n  for (const key in props.transitions) {\n    const propType = propTypes[key];\n    const type = propType && propType.type;\n    const isTransitionable = type === 'number' || type === 'color' || type === 'array';\n\n    if (isTransitionable && comparePropValues(props[key], oldProps[key], propType)) {\n      result[key] = true;\n      changed = true;\n    }\n  }\n\n  return changed ? result : false;\n}\n\nfunction compareProps({\n  newProps,\n  oldProps,\n  ignoreProps = {},\n  propTypes = {},\n  triggerName = 'props'\n}) {\n  if (oldProps === newProps) {\n    return false;\n  }\n\n  if (typeof newProps !== 'object' || newProps === null) {\n    return \"\".concat(triggerName, \" changed shallowly\");\n  }\n\n  if (typeof oldProps !== 'object' || oldProps === null) {\n    return \"\".concat(triggerName, \" changed shallowly\");\n  }\n\n  for (const key of Object.keys(newProps)) {\n    if (!(key in ignoreProps)) {\n      if (!(key in oldProps)) {\n        return \"\".concat(triggerName, \".\").concat(key, \" added\");\n      }\n\n      const changed = comparePropValues(newProps[key], oldProps[key], propTypes[key]);\n\n      if (changed) {\n        return \"\".concat(triggerName, \".\").concat(key, \" \").concat(changed);\n      }\n    }\n  }\n\n  for (const key of Object.keys(oldProps)) {\n    if (!(key in ignoreProps)) {\n      if (!(key in newProps)) {\n        return \"\".concat(triggerName, \".\").concat(key, \" dropped\");\n      }\n\n      if (!Object.hasOwnProperty.call(newProps, key)) {\n        const changed = comparePropValues(newProps[key], oldProps[key], propTypes[key]);\n\n        if (changed) {\n          return \"\".concat(triggerName, \".\").concat(key, \" \").concat(changed);\n        }\n      }\n    }\n  }\n\n  return false;\n}\n\nfunction comparePropValues(newProp, oldProp, propType) {\n  let equal = propType && propType.equal;\n\n  if (equal && !equal(newProp, oldProp, propType)) {\n    return 'changed deeply';\n  }\n\n  if (!equal) {\n    equal = newProp && oldProp && newProp.equals;\n\n    if (equal && !equal.call(newProp, oldProp)) {\n      return 'changed deeply';\n    }\n  }\n\n  if (!equal && oldProp !== newProp) {\n    return 'changed shallowly';\n  }\n\n  return null;\n}\n\nfunction diffDataProps(props, oldProps) {\n  if (oldProps === null) {\n    return 'oldProps is null, initial diff';\n  }\n\n  let dataChanged = false;\n  const {\n    dataComparator,\n    _dataDiff\n  } = props;\n\n  if (dataComparator) {\n    if (!dataComparator(props.data, oldProps.data)) {\n      dataChanged = 'Data comparator detected a change';\n    }\n  } else if (props.data !== oldProps.data) {\n    dataChanged = 'A new data container was supplied';\n  }\n\n  if (dataChanged && _dataDiff) {\n    dataChanged = _dataDiff(props.data, oldProps.data) || dataChanged;\n  }\n\n  return dataChanged;\n}\n\nfunction diffUpdateTriggers(props, oldProps) {\n  if (oldProps === null) {\n    return {\n      all: true\n    };\n  }\n\n  if ('all' in props.updateTriggers) {\n    const diffReason = diffUpdateTrigger(props, oldProps, 'all');\n\n    if (diffReason) {\n      return {\n        all: true\n      };\n    }\n  }\n\n  const reason = {};\n  let changed = false;\n\n  for (const triggerName in props.updateTriggers) {\n    if (triggerName !== 'all') {\n      const diffReason = diffUpdateTrigger(props, oldProps, triggerName);\n\n      if (diffReason) {\n        reason[triggerName] = true;\n        changed = true;\n      }\n    }\n  }\n\n  return changed ? reason : false;\n}\n\nfunction diffExtensions(props, oldProps) {\n  if (oldProps === null) {\n    return true;\n  }\n\n  const oldExtensions = oldProps.extensions;\n  const {\n    extensions\n  } = props;\n\n  if (extensions === oldExtensions) {\n    return false;\n  }\n\n  if (!oldExtensions || !extensions) {\n    return true;\n  }\n\n  if (extensions.length !== oldExtensions.length) {\n    return true;\n  }\n\n  for (let i = 0; i < extensions.length; i++) {\n    if (!extensions[i].equals(oldExtensions[i])) {\n      return true;\n    }\n  }\n\n  return false;\n}\n\nfunction diffUpdateTrigger(props, oldProps, triggerName) {\n  let newTriggers = props.updateTriggers[triggerName];\n  newTriggers = newTriggers === undefined || newTriggers === null ? {} : newTriggers;\n  let oldTriggers = oldProps.updateTriggers[triggerName];\n  oldTriggers = oldTriggers === undefined || oldTriggers === null ? {} : oldTriggers;\n  const diffReason = compareProps({\n    oldProps: oldTriggers,\n    newProps: newTriggers,\n    triggerName\n  });\n  return diffReason;\n}\n//# sourceMappingURL=props.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/lifecycle/props.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/passes/draw-layers-pass.js":
/*!************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/passes/draw-layers-pass.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ DrawLayersPass)\n/* harmony export */ });\n/* harmony import */ var _layers_pass__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./layers-pass */ \"./node_modules/@deck.gl/core/dist/esm/passes/layers-pass.js\");\n\nclass DrawLayersPass extends _layers_pass__WEBPACK_IMPORTED_MODULE_0__[\"default\"] {\n  shouldDrawLayer(layer) {\n    const {\n      operation\n    } = layer.props;\n    return operation.includes('draw') || operation.includes('terrain');\n  }\n\n}\n//# sourceMappingURL=draw-layers-pass.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/passes/draw-layers-pass.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/passes/layers-pass.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/passes/layers-pass.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ LayersPass),\n/* harmony export */   layerIndexResolver: () => (/* binding */ layerIndexResolver)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _pass__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./pass */ \"./node_modules/@deck.gl/core/dist/esm/passes/pass.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/clear.js\");\n\n\n\nclass LayersPass extends _pass__WEBPACK_IMPORTED_MODULE_1__[\"default\"] {\n  constructor(...args) {\n    super(...args);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_lastRenderIndex\", -1);\n  }\n\n  render(options) {\n    const gl = this.gl;\n    (0,_luma_gl_core__WEBPACK_IMPORTED_MODULE_2__.setParameters)(gl, {\n      framebuffer: options.target\n    });\n    return this._drawLayers(options);\n  }\n\n  _drawLayers(options) {\n    const {\n      target,\n      moduleParameters,\n      viewports,\n      views,\n      onViewportActive,\n      clearStack = true,\n      clearCanvas = true\n    } = options;\n    options.pass = options.pass || 'unknown';\n    const gl = this.gl;\n\n    if (clearCanvas) {\n      clearGLCanvas(gl, target);\n    }\n\n    if (clearStack) {\n      this._lastRenderIndex = -1;\n    }\n\n    const renderStats = [];\n\n    for (const viewport of viewports) {\n      const view = views && views[viewport.id];\n      onViewportActive === null || onViewportActive === void 0 ? void 0 : onViewportActive(viewport);\n\n      const drawLayerParams = this._getDrawLayerParams(viewport, options);\n\n      const subViewports = viewport.subViewports || [viewport];\n\n      for (const subViewport of subViewports) {\n        const stats = this._drawLayersInViewport(gl, {\n          target,\n          moduleParameters,\n          viewport: subViewport,\n          view,\n          pass: options.pass,\n          layers: options.layers\n        }, drawLayerParams);\n\n        renderStats.push(stats);\n      }\n    }\n\n    return renderStats;\n  }\n\n  _getDrawLayerParams(viewport, {\n    layers,\n    pass,\n    isPicking = false,\n    layerFilter,\n    cullRect,\n    effects,\n    moduleParameters\n  }, evaluateShouldDrawOnly = false) {\n    const drawLayerParams = [];\n    const indexResolver = layerIndexResolver(this._lastRenderIndex + 1);\n    const drawContext = {\n      layer: layers[0],\n      viewport,\n      isPicking,\n      renderPass: pass,\n      cullRect\n    };\n    const layerFilterCache = {};\n\n    for (let layerIndex = 0; layerIndex < layers.length; layerIndex++) {\n      const layer = layers[layerIndex];\n\n      const shouldDrawLayer = this._shouldDrawLayer(layer, drawContext, layerFilter, layerFilterCache);\n\n      const layerParam = {\n        shouldDrawLayer\n      };\n\n      if (shouldDrawLayer && !evaluateShouldDrawOnly) {\n        layerParam.layerRenderIndex = indexResolver(layer, shouldDrawLayer);\n        layerParam.moduleParameters = this._getModuleParameters(layer, effects, pass, moduleParameters);\n        layerParam.layerParameters = this.getLayerParameters(layer, layerIndex, viewport);\n      }\n\n      drawLayerParams[layerIndex] = layerParam;\n    }\n\n    return drawLayerParams;\n  }\n\n  _drawLayersInViewport(gl, {\n    layers,\n    moduleParameters: globalModuleParameters,\n    pass,\n    target,\n    viewport,\n    view\n  }, drawLayerParams) {\n    const glViewport = getGLViewport(gl, {\n      moduleParameters: globalModuleParameters,\n      target,\n      viewport\n    });\n\n    if (view && view.props.clear) {\n      const clearOpts = view.props.clear === true ? {\n        color: true,\n        depth: true\n      } : view.props.clear;\n      (0,_luma_gl_core__WEBPACK_IMPORTED_MODULE_2__.withParameters)(gl, {\n        scissorTest: true,\n        scissor: glViewport\n      }, () => (0,_luma_gl_core__WEBPACK_IMPORTED_MODULE_3__.clear)(gl, clearOpts));\n    }\n\n    const renderStatus = {\n      totalCount: layers.length,\n      visibleCount: 0,\n      compositeCount: 0,\n      pickableCount: 0\n    };\n    (0,_luma_gl_core__WEBPACK_IMPORTED_MODULE_2__.setParameters)(gl, {\n      viewport: glViewport\n    });\n\n    for (let layerIndex = 0; layerIndex < layers.length; layerIndex++) {\n      const layer = layers[layerIndex];\n      const {\n        shouldDrawLayer,\n        layerRenderIndex,\n        moduleParameters,\n        layerParameters\n      } = drawLayerParams[layerIndex];\n\n      if (shouldDrawLayer && layer.props.pickable) {\n        renderStatus.pickableCount++;\n      }\n\n      if (layer.isComposite) {\n        renderStatus.compositeCount++;\n      } else if (shouldDrawLayer) {\n        renderStatus.visibleCount++;\n        this._lastRenderIndex = Math.max(this._lastRenderIndex, layerRenderIndex);\n        moduleParameters.viewport = viewport;\n\n        try {\n          layer._drawLayer({\n            moduleParameters,\n            uniforms: {\n              layerIndex: layerRenderIndex\n            },\n            parameters: layerParameters\n          });\n        } catch (err) {\n          layer.raiseError(err, \"drawing \".concat(layer, \" to \").concat(pass));\n        }\n      }\n    }\n\n    return renderStatus;\n  }\n\n  shouldDrawLayer(layer) {\n    return true;\n  }\n\n  getModuleParameters(layer, effects) {\n    return null;\n  }\n\n  getLayerParameters(layer, layerIndex, viewport) {\n    return layer.props.parameters;\n  }\n\n  _shouldDrawLayer(layer, drawContext, layerFilter, layerFilterCache) {\n    const shouldDrawLayer = layer.props.visible && this.shouldDrawLayer(layer);\n\n    if (!shouldDrawLayer) {\n      return false;\n    }\n\n    drawContext.layer = layer;\n    let parent = layer.parent;\n\n    while (parent) {\n      if (!parent.props.visible || !parent.filterSubLayer(drawContext)) {\n        return false;\n      }\n\n      drawContext.layer = parent;\n      parent = parent.parent;\n    }\n\n    if (layerFilter) {\n      const rootLayerId = drawContext.layer.id;\n\n      if (!(rootLayerId in layerFilterCache)) {\n        layerFilterCache[rootLayerId] = layerFilter(drawContext);\n      }\n\n      if (!layerFilterCache[rootLayerId]) {\n        return false;\n      }\n    }\n\n    layer.activateViewport(drawContext.viewport);\n    return true;\n  }\n\n  _getModuleParameters(layer, effects, pass, overrides) {\n    var _layer$internalState;\n\n    const moduleParameters = Object.assign(Object.create(((_layer$internalState = layer.internalState) === null || _layer$internalState === void 0 ? void 0 : _layer$internalState.propsInTransition) || layer.props), {\n      autoWrapLongitude: layer.wrapLongitude,\n      viewport: layer.context.viewport,\n      mousePosition: layer.context.mousePosition,\n      pickingActive: 0,\n      devicePixelRatio: (0,_luma_gl_core__WEBPACK_IMPORTED_MODULE_2__.cssToDeviceRatio)(this.gl)\n    });\n\n    if (effects) {\n      for (const effect of effects) {\n        var _effect$getModulePara;\n\n        Object.assign(moduleParameters, (_effect$getModulePara = effect.getModuleParameters) === null || _effect$getModulePara === void 0 ? void 0 : _effect$getModulePara.call(effect, layer));\n      }\n    }\n\n    return Object.assign(moduleParameters, this.getModuleParameters(layer, effects), overrides);\n  }\n\n}\nfunction layerIndexResolver(startIndex = 0, layerIndices = {}) {\n  const resolvers = {};\n\n  const resolveLayerIndex = (layer, isDrawn) => {\n    const indexOverride = layer.props._offset;\n    const layerId = layer.id;\n    const parentId = layer.parent && layer.parent.id;\n    let index;\n\n    if (parentId && !(parentId in layerIndices)) {\n      resolveLayerIndex(layer.parent, false);\n    }\n\n    if (parentId in resolvers) {\n      const resolver = resolvers[parentId] = resolvers[parentId] || layerIndexResolver(layerIndices[parentId], layerIndices);\n      index = resolver(layer, isDrawn);\n      resolvers[layerId] = resolver;\n    } else if (Number.isFinite(indexOverride)) {\n      index = indexOverride + (layerIndices[parentId] || 0);\n      resolvers[layerId] = null;\n    } else {\n      index = startIndex;\n    }\n\n    if (isDrawn && index >= startIndex) {\n      startIndex = index + 1;\n    }\n\n    layerIndices[layerId] = index;\n    return index;\n  };\n\n  return resolveLayerIndex;\n}\n\nfunction getGLViewport(gl, {\n  moduleParameters,\n  target,\n  viewport\n}) {\n  const useTarget = target && target.id !== 'default-framebuffer';\n  const pixelRatio = moduleParameters && moduleParameters.devicePixelRatio || (0,_luma_gl_core__WEBPACK_IMPORTED_MODULE_2__.cssToDeviceRatio)(gl);\n  const height = useTarget ? target.height : gl.drawingBufferHeight;\n  const dimensions = viewport;\n  return [dimensions.x * pixelRatio, height - (dimensions.y + dimensions.height) * pixelRatio, dimensions.width * pixelRatio, dimensions.height * pixelRatio];\n}\n\nfunction clearGLCanvas(gl, targetFramebuffer) {\n  const width = targetFramebuffer ? targetFramebuffer.width : gl.drawingBufferWidth;\n  const height = targetFramebuffer ? targetFramebuffer.height : gl.drawingBufferHeight;\n  (0,_luma_gl_core__WEBPACK_IMPORTED_MODULE_2__.setParameters)(gl, {\n    viewport: [0, 0, width, height]\n  });\n  gl.clear(16384 | 256);\n}\n//# sourceMappingURL=layers-pass.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/passes/layers-pass.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/passes/pass.js":
/*!************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/passes/pass.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Pass)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n\nclass Pass {\n  constructor(gl, props = {\n    id: 'pass'\n  }) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"id\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"gl\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"props\", void 0);\n\n    const {\n      id\n    } = props;\n    this.id = id;\n    this.gl = gl;\n    this.props = { ...props\n    };\n  }\n\n  setProps(props) {\n    Object.assign(this.props, props);\n  }\n\n  render(params) {}\n\n  cleanup() {}\n\n}\n//# sourceMappingURL=pass.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/passes/pass.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/passes/pick-layers-pass.js":
/*!************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/passes/pick-layers-pass.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ PickLayersPass)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _layers_pass__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./layers-pass */ \"./node_modules/@deck.gl/core/dist/esm/passes/layers-pass.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n/* harmony import */ var _utils_log__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/log */ \"./node_modules/@deck.gl/core/dist/esm/utils/log.js\");\n\n\n\n\nconst PICKING_PARAMETERS = {\n  blendFunc: [1, 0, 32771, 0],\n  blendEquation: 32774\n};\nclass PickLayersPass extends _layers_pass__WEBPACK_IMPORTED_MODULE_1__[\"default\"] {\n  constructor(...args) {\n    super(...args);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"pickZ\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_colorEncoderState\", null);\n  }\n\n  render(props) {\n    if ('pickingFBO' in props) {\n      return this._drawPickingBuffer(props);\n    }\n\n    return super.render(props);\n  }\n\n  _drawPickingBuffer({\n    layers,\n    layerFilter,\n    views,\n    viewports,\n    onViewportActive,\n    pickingFBO,\n    deviceRect: {\n      x,\n      y,\n      width,\n      height\n    },\n    cullRect,\n    effects,\n    pass = 'picking',\n    pickZ,\n    moduleParameters\n  }) {\n    const gl = this.gl;\n    this.pickZ = pickZ;\n\n    const colorEncoderState = this._resetColorEncoder(pickZ);\n\n    const renderStatus = (0,_luma_gl_core__WEBPACK_IMPORTED_MODULE_2__.withParameters)(gl, {\n      scissorTest: true,\n      scissor: [x, y, width, height],\n      clearColor: [0, 0, 0, 0],\n      depthMask: true,\n      depthTest: true,\n      depthRange: [0, 1],\n      colorMask: [true, true, true, true],\n      ...PICKING_PARAMETERS,\n      blend: !pickZ\n    }, () => super.render({\n      target: pickingFBO,\n      layers,\n      layerFilter,\n      views,\n      viewports,\n      onViewportActive,\n      cullRect,\n      effects: effects === null || effects === void 0 ? void 0 : effects.filter(e => e.useInPicking),\n      pass,\n      isPicking: true,\n      moduleParameters\n    }));\n    this._colorEncoderState = null;\n    const decodePickingColor = colorEncoderState && decodeColor.bind(null, colorEncoderState);\n    return {\n      decodePickingColor,\n      stats: renderStatus\n    };\n  }\n\n  shouldDrawLayer(layer) {\n    const {\n      pickable,\n      operation\n    } = layer.props;\n    return pickable && operation.includes('draw') || operation.includes('terrain') || operation.includes('mask');\n  }\n\n  getModuleParameters() {\n    return {\n      pickingActive: 1,\n      pickingAttribute: this.pickZ,\n      lightSources: {}\n    };\n  }\n\n  getLayerParameters(layer, layerIndex, viewport) {\n    const pickParameters = { ...layer.props.parameters\n    };\n    const {\n      pickable,\n      operation\n    } = layer.props;\n\n    if (!this._colorEncoderState) {\n      pickParameters.blend = false;\n    } else if (pickable && operation.includes('draw')) {\n      Object.assign(pickParameters, PICKING_PARAMETERS);\n      pickParameters.blend = true;\n      pickParameters.blendColor = encodeColor(this._colorEncoderState, layer, viewport);\n    }\n\n    if (operation.includes('terrain')) {\n      pickParameters.blend = false;\n    }\n\n    return pickParameters;\n  }\n\n  _resetColorEncoder(pickZ) {\n    this._colorEncoderState = pickZ ? null : {\n      byLayer: new Map(),\n      byAlpha: []\n    };\n    return this._colorEncoderState;\n  }\n\n}\n\nfunction encodeColor(encoded, layer, viewport) {\n  const {\n    byLayer,\n    byAlpha\n  } = encoded;\n  let a;\n  let entry = byLayer.get(layer);\n\n  if (entry) {\n    entry.viewports.push(viewport);\n    a = entry.a;\n  } else {\n    a = byLayer.size + 1;\n\n    if (a <= 255) {\n      entry = {\n        a,\n        layer,\n        viewports: [viewport]\n      };\n      byLayer.set(layer, entry);\n      byAlpha[a] = entry;\n    } else {\n      _utils_log__WEBPACK_IMPORTED_MODULE_3__[\"default\"].warn('Too many pickable layers, only picking the first 255')();\n      a = 0;\n    }\n  }\n\n  return [0, 0, 0, a / 255];\n}\n\nfunction decodeColor(encoded, pickedColor) {\n  const entry = encoded.byAlpha[pickedColor[3]];\n  return entry && {\n    pickedLayer: entry.layer,\n    pickedViewports: entry.viewports,\n    pickedObjectIndex: entry.layer.decodePickingColor(pickedColor)\n  };\n}\n//# sourceMappingURL=pick-layers-pass.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/passes/pick-layers-pass.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/passes/shadow-pass.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/passes/shadow-pass.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ ShadowPass)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _layers_pass__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./layers-pass */ \"./node_modules/@deck.gl/core/dist/esm/passes/layers-pass.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/texture-2d.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/renderbuffer.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/framebuffer.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n\n\n\nclass ShadowPass extends _layers_pass__WEBPACK_IMPORTED_MODULE_1__[\"default\"] {\n  constructor(gl, props) {\n    super(gl, props);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"shadowMap\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"depthBuffer\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"fbo\", void 0);\n\n    this.shadowMap = new _luma_gl_core__WEBPACK_IMPORTED_MODULE_2__[\"default\"](gl, {\n      width: 1,\n      height: 1,\n      parameters: {\n        [10241]: 9729,\n        [10240]: 9729,\n        [10242]: 33071,\n        [10243]: 33071\n      }\n    });\n    this.depthBuffer = new _luma_gl_core__WEBPACK_IMPORTED_MODULE_3__[\"default\"](gl, {\n      format: 33189,\n      width: 1,\n      height: 1\n    });\n    this.fbo = new _luma_gl_core__WEBPACK_IMPORTED_MODULE_4__[\"default\"](gl, {\n      id: 'shadowmap',\n      width: 1,\n      height: 1,\n      attachments: {\n        [36064]: this.shadowMap,\n        [36096]: this.depthBuffer\n      }\n    });\n  }\n\n  render(params) {\n    const target = this.fbo;\n    (0,_luma_gl_core__WEBPACK_IMPORTED_MODULE_5__.withParameters)(this.gl, {\n      depthRange: [0, 1],\n      depthTest: true,\n      blend: false,\n      clearColor: [1, 1, 1, 1]\n    }, () => {\n      const viewport = params.viewports[0];\n      const pixelRatio = (0,_luma_gl_core__WEBPACK_IMPORTED_MODULE_5__.cssToDeviceRatio)(this.gl);\n      const width = viewport.width * pixelRatio;\n      const height = viewport.height * pixelRatio;\n\n      if (width !== target.width || height !== target.height) {\n        target.resize({\n          width,\n          height\n        });\n      }\n\n      super.render({ ...params,\n        target,\n        pass: 'shadow'\n      });\n    });\n  }\n\n  shouldDrawLayer(layer) {\n    return layer.props.shadowEnabled !== false;\n  }\n\n  getModuleParameters() {\n    return {\n      drawToShadowMap: true\n    };\n  }\n\n  delete() {\n    if (this.fbo) {\n      this.fbo.delete();\n      this.fbo = null;\n    }\n\n    if (this.shadowMap) {\n      this.shadowMap.delete();\n      this.shadowMap = null;\n    }\n\n    if (this.depthBuffer) {\n      this.depthBuffer.delete();\n      this.depthBuffer = null;\n    }\n  }\n\n}\n//# sourceMappingURL=shadow-pass.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/passes/shadow-pass.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/shaderlib/index.js":
/*!****************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/shaderlib/index.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   createProgramManager: () => (/* binding */ createProgramManager),\n/* harmony export */   gouraudLighting: () => (/* reexport safe */ _luma_gl_core__WEBPACK_IMPORTED_MODULE_4__.gouraudLighting),\n/* harmony export */   phongLighting: () => (/* reexport safe */ _luma_gl_core__WEBPACK_IMPORTED_MODULE_4__.phongLighting),\n/* harmony export */   picking: () => (/* reexport safe */ _picking_picking__WEBPACK_IMPORTED_MODULE_2__[\"default\"]),\n/* harmony export */   project: () => (/* reexport safe */ _project_project__WEBPACK_IMPORTED_MODULE_0__[\"default\"]),\n/* harmony export */   project32: () => (/* reexport safe */ _project32_project32__WEBPACK_IMPORTED_MODULE_3__[\"default\"]),\n/* harmony export */   shadow: () => (/* reexport safe */ _shadow_shadow__WEBPACK_IMPORTED_MODULE_5__[\"default\"])\n/* harmony export */ });\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/engine/dist/esm/lib/program-manager.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/shadertools/dist/esm/modules/phong-lighting/phong-lighting.js\");\n/* harmony import */ var _project_project__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./project/project */ \"./node_modules/@deck.gl/core/dist/esm/shaderlib/project/project.js\");\n/* harmony import */ var _project32_project32__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./project32/project32 */ \"./node_modules/@deck.gl/core/dist/esm/shaderlib/project32/project32.js\");\n/* harmony import */ var _shadow_shadow__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./shadow/shadow */ \"./node_modules/@deck.gl/core/dist/esm/shaderlib/shadow/shadow.js\");\n/* harmony import */ var _picking_picking__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./picking/picking */ \"./node_modules/@deck.gl/core/dist/esm/shaderlib/picking/picking.js\");\n\n\n\n\n\n\nconst DEFAULT_MODULES = [_project_project__WEBPACK_IMPORTED_MODULE_0__[\"default\"]];\nconst SHADER_HOOKS = ['vs:DECKGL_FILTER_SIZE(inout vec3 size, VertexGeometry geometry)', 'vs:DECKGL_FILTER_GL_POSITION(inout vec4 position, VertexGeometry geometry)', 'vs:DECKGL_FILTER_COLOR(inout vec4 color, VertexGeometry geometry)', 'fs:DECKGL_FILTER_COLOR(inout vec4 color, FragmentGeometry geometry)'];\nfunction createProgramManager(gl) {\n  const programManager = _luma_gl_core__WEBPACK_IMPORTED_MODULE_1__[\"default\"].getDefaultProgramManager(gl);\n\n  for (const shaderModule of DEFAULT_MODULES) {\n    programManager.addDefaultModule(shaderModule);\n  }\n\n  for (const shaderHook of SHADER_HOOKS) {\n    programManager.addShaderHook(shaderHook);\n  }\n\n  return programManager;\n}\n\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/shaderlib/index.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/shaderlib/misc/geometry.js":
/*!************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/shaderlib/misc/geometry.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nconst defines = '#define SMOOTH_EDGE_RADIUS 0.5';\nconst vs = \"\\n\".concat(defines, \"\\n\\nstruct VertexGeometry {\\n  vec4 position;\\n  vec3 worldPosition;\\n  vec3 worldPositionAlt;\\n  vec3 normal;\\n  vec2 uv;\\n  vec3 pickingColor;\\n} geometry = VertexGeometry(\\n  vec4(0.0, 0.0, 1.0, 0.0),\\n  vec3(0.0),\\n  vec3(0.0),\\n  vec3(0.0),\\n  vec2(0.0),\\n  vec3(0.0)\\n);\\n\");\nconst fs = \"\\n\".concat(defines, \"\\n\\nstruct FragmentGeometry {\\n  vec2 uv;\\n} geometry;\\n\\nfloat smoothedge(float edge, float x) {\\n  return smoothstep(edge - SMOOTH_EDGE_RADIUS, edge + SMOOTH_EDGE_RADIUS, x);\\n}\\n\");\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ({\n  name: 'geometry',\n  vs,\n  fs\n});\n//# sourceMappingURL=geometry.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/shaderlib/misc/geometry.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/shaderlib/picking/picking.js":
/*!**************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/shaderlib/picking/picking.js ***!
  \**************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/shadertools/dist/esm/modules/picking/picking.js\");\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ({\n  inject: {\n    'vs:DECKGL_FILTER_GL_POSITION': \"\\n    // for picking depth values\\n    picking_setPickingAttribute(position.z / position.w);\\n  \",\n    'vs:DECKGL_FILTER_COLOR': \"\\n  picking_setPickingColor(geometry.pickingColor);\\n  \",\n    'fs:#decl': \"\\nuniform bool picking_uAttribute;\\n  \",\n    'fs:DECKGL_FILTER_COLOR': {\n      order: 99,\n      injection: \"\\n  // use highlight color if this fragment belongs to the selected object.\\n  color = picking_filterHighlightColor(color);\\n\\n  // use picking color if rendering to picking FBO.\\n  color = picking_filterPickingColor(color);\\n    \"\n    }\n  },\n  ..._luma_gl_core__WEBPACK_IMPORTED_MODULE_0__.picking\n});\n//# sourceMappingURL=picking.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/shaderlib/picking/picking.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/shaderlib/project/project-functions.js":
/*!************************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/shaderlib/project/project-functions.js ***!
  \************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getWorldPosition: () => (/* binding */ getWorldPosition),\n/* harmony export */   projectPosition: () => (/* binding */ projectPosition)\n/* harmony export */ });\n/* harmony import */ var _lib_constants__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../lib/constants */ \"./node_modules/@deck.gl/core/dist/esm/lib/constants.js\");\n/* harmony import */ var _viewport_uniforms__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./viewport-uniforms */ \"./node_modules/@deck.gl/core/dist/esm/shaderlib/project/viewport-uniforms.js\");\n/* harmony import */ var _viewports_web_mercator_viewport__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../viewports/web-mercator-viewport */ \"./node_modules/@deck.gl/core/dist/esm/viewports/web-mercator-viewport.js\");\n/* harmony import */ var gl_matrix_vec4__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! gl-matrix/vec4 */ \"./node_modules/gl-matrix/esm/vec4.js\");\n/* harmony import */ var gl_matrix_vec3__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! gl-matrix/vec3 */ \"./node_modules/gl-matrix/esm/vec3.js\");\n/* harmony import */ var _math_gl_web_mercator__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @math.gl/web-mercator */ \"./node_modules/@math.gl/web-mercator/dist/esm/index.js\");\n\n\n\n\n\n\nconst DEFAULT_COORDINATE_ORIGIN = [0, 0, 0];\n\nfunction lngLatZToWorldPosition(lngLatZ, viewport, offsetMode = false) {\n  const p = viewport.projectPosition(lngLatZ);\n\n  if (offsetMode && viewport instanceof _viewports_web_mercator_viewport__WEBPACK_IMPORTED_MODULE_1__[\"default\"]) {\n    const [longitude, latitude, z = 0] = lngLatZ;\n    const distanceScales = viewport.getDistanceScales([longitude, latitude]);\n    p[2] = z * distanceScales.unitsPerMeter[2];\n  }\n\n  return p;\n}\n\nfunction normalizeParameters(opts) {\n  const {\n    viewport,\n    modelMatrix,\n    coordinateOrigin\n  } = opts;\n  let {\n    coordinateSystem,\n    fromCoordinateSystem,\n    fromCoordinateOrigin\n  } = opts;\n\n  if (coordinateSystem === _lib_constants__WEBPACK_IMPORTED_MODULE_2__.COORDINATE_SYSTEM.DEFAULT) {\n    coordinateSystem = viewport.isGeospatial ? _lib_constants__WEBPACK_IMPORTED_MODULE_2__.COORDINATE_SYSTEM.LNGLAT : _lib_constants__WEBPACK_IMPORTED_MODULE_2__.COORDINATE_SYSTEM.CARTESIAN;\n  }\n\n  if (fromCoordinateSystem === undefined) {\n    fromCoordinateSystem = coordinateSystem;\n  }\n\n  if (fromCoordinateOrigin === undefined) {\n    fromCoordinateOrigin = coordinateOrigin;\n  }\n\n  return {\n    viewport,\n    coordinateSystem,\n    coordinateOrigin,\n    modelMatrix,\n    fromCoordinateSystem,\n    fromCoordinateOrigin\n  };\n}\n\nfunction getWorldPosition(position, {\n  viewport,\n  modelMatrix,\n  coordinateSystem,\n  coordinateOrigin,\n  offsetMode\n}) {\n  let [x, y, z = 0] = position;\n\n  if (modelMatrix) {\n    [x, y, z] = gl_matrix_vec4__WEBPACK_IMPORTED_MODULE_3__.transformMat4([], [x, y, z, 1.0], modelMatrix);\n  }\n\n  switch (coordinateSystem) {\n    case _lib_constants__WEBPACK_IMPORTED_MODULE_2__.COORDINATE_SYSTEM.LNGLAT:\n      return lngLatZToWorldPosition([x, y, z], viewport, offsetMode);\n\n    case _lib_constants__WEBPACK_IMPORTED_MODULE_2__.COORDINATE_SYSTEM.LNGLAT_OFFSETS:\n      return lngLatZToWorldPosition([x + coordinateOrigin[0], y + coordinateOrigin[1], z + (coordinateOrigin[2] || 0)], viewport, offsetMode);\n\n    case _lib_constants__WEBPACK_IMPORTED_MODULE_2__.COORDINATE_SYSTEM.METER_OFFSETS:\n      return lngLatZToWorldPosition((0,_math_gl_web_mercator__WEBPACK_IMPORTED_MODULE_0__.addMetersToLngLat)(coordinateOrigin, [x, y, z]), viewport, offsetMode);\n\n    case _lib_constants__WEBPACK_IMPORTED_MODULE_2__.COORDINATE_SYSTEM.CARTESIAN:\n    default:\n      return viewport.isGeospatial ? [x + coordinateOrigin[0], y + coordinateOrigin[1], z + coordinateOrigin[2]] : viewport.projectPosition([x, y, z]);\n  }\n}\nfunction projectPosition(position, params) {\n  const {\n    viewport,\n    coordinateSystem,\n    coordinateOrigin,\n    modelMatrix,\n    fromCoordinateSystem,\n    fromCoordinateOrigin\n  } = normalizeParameters(params);\n  const {\n    autoOffset = true\n  } = params;\n  const {\n    geospatialOrigin = DEFAULT_COORDINATE_ORIGIN,\n    shaderCoordinateOrigin = DEFAULT_COORDINATE_ORIGIN,\n    offsetMode = false\n  } = autoOffset ? (0,_viewport_uniforms__WEBPACK_IMPORTED_MODULE_4__.getOffsetOrigin)(viewport, coordinateSystem, coordinateOrigin) : {};\n  const worldPosition = getWorldPosition(position, {\n    viewport,\n    modelMatrix,\n    coordinateSystem: fromCoordinateSystem,\n    coordinateOrigin: fromCoordinateOrigin,\n    offsetMode\n  });\n\n  if (offsetMode) {\n    const positionCommonSpace = viewport.projectPosition(geospatialOrigin || shaderCoordinateOrigin);\n    gl_matrix_vec3__WEBPACK_IMPORTED_MODULE_5__.sub(worldPosition, worldPosition, positionCommonSpace);\n  }\n\n  return worldPosition;\n}\n//# sourceMappingURL=project-functions.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/shaderlib/project/project-functions.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/shaderlib/project/project.glsl.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/shaderlib/project/project.glsl.js ***!
  \*******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _lib_constants__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../lib/constants */ \"./node_modules/@deck.gl/core/dist/esm/lib/constants.js\");\n\nconst COORDINATE_SYSTEM_GLSL_CONSTANTS = Object.keys(_lib_constants__WEBPACK_IMPORTED_MODULE_0__.COORDINATE_SYSTEM).map(key => \"const int COORDINATE_SYSTEM_\".concat(key, \" = \").concat(_lib_constants__WEBPACK_IMPORTED_MODULE_0__.COORDINATE_SYSTEM[key], \";\")).join('');\nconst PROJECTION_MODE_GLSL_CONSTANTS = Object.keys(_lib_constants__WEBPACK_IMPORTED_MODULE_0__.PROJECTION_MODE).map(key => \"const int PROJECTION_MODE_\".concat(key, \" = \").concat(_lib_constants__WEBPACK_IMPORTED_MODULE_0__.PROJECTION_MODE[key], \";\")).join('');\nconst UNIT_GLSL_CONSTANTS = Object.keys(_lib_constants__WEBPACK_IMPORTED_MODULE_0__.UNIT).map(key => \"const int UNIT_\".concat(key.toUpperCase(), \" = \").concat(_lib_constants__WEBPACK_IMPORTED_MODULE_0__.UNIT[key], \";\")).join('');\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (\"\".concat(COORDINATE_SYSTEM_GLSL_CONSTANTS, \"\\n\").concat(PROJECTION_MODE_GLSL_CONSTANTS, \"\\n\").concat(UNIT_GLSL_CONSTANTS, \"\\n\\nuniform int project_uCoordinateSystem;\\nuniform int project_uProjectionMode;\\nuniform float project_uScale;\\nuniform bool project_uWrapLongitude;\\nuniform vec3 project_uCommonUnitsPerMeter;\\nuniform vec3 project_uCommonUnitsPerWorldUnit;\\nuniform vec3 project_uCommonUnitsPerWorldUnit2;\\nuniform vec4 project_uCenter;\\nuniform mat4 project_uModelMatrix;\\nuniform mat4 project_uViewProjectionMatrix;\\nuniform vec2 project_uViewportSize;\\nuniform float project_uDevicePixelRatio;\\nuniform float project_uFocalDistance;\\nuniform vec3 project_uCameraPosition;\\nuniform vec3 project_uCoordinateOrigin;\\nuniform vec3 project_uCommonOrigin;\\nuniform bool project_uPseudoMeters;\\n\\nconst float TILE_SIZE = 512.0;\\nconst float PI = 3.1415926536;\\nconst float WORLD_SCALE = TILE_SIZE / (PI * 2.0);\\nconst vec3 ZERO_64_LOW = vec3(0.0);\\nconst float EARTH_RADIUS = 6370972.0;\\nconst float GLOBE_RADIUS = 256.0;\\nfloat project_size_at_latitude(float lat) {\\n  float y = clamp(lat, -89.9, 89.9);\\n  return 1.0 / cos(radians(y));\\n}\\n\\nfloat project_size() {\\n  if (project_uProjectionMode == PROJECTION_MODE_WEB_MERCATOR &&\\n    project_uCoordinateSystem == COORDINATE_SYSTEM_LNGLAT &&\\n    project_uPseudoMeters == false) {\\n    \\n    if (geometry.position.w == 0.0) {\\n      return project_size_at_latitude(geometry.worldPosition.y);\\n    }\\n  \\n    float y = geometry.position.y / TILE_SIZE * 2.0 - 1.0;\\n    float y2 = y * y;\\n    float y4 = y2 * y2;\\n    float y6 = y4 * y2;\\n    return 1.0 + 4.9348 * y2 + 4.0587 * y4 + 1.5642 * y6;\\n  }\\n  return 1.0;\\n}\\n\\nfloat project_size_at_latitude(float meters, float lat) {\\n  return meters * project_uCommonUnitsPerMeter.z * project_size_at_latitude(lat);\\n}\\nfloat project_size(float meters) {\\n  return meters * project_uCommonUnitsPerMeter.z * project_size();\\n}\\n\\nvec2 project_size(vec2 meters) {\\n  return meters * project_uCommonUnitsPerMeter.xy * project_size();\\n}\\n\\nvec3 project_size(vec3 meters) {\\n  return meters * project_uCommonUnitsPerMeter * project_size();\\n}\\n\\nvec4 project_size(vec4 meters) {\\n  return vec4(meters.xyz * project_uCommonUnitsPerMeter, meters.w);\\n}\\nmat3 project_get_orientation_matrix(vec3 up) {\\n  vec3 uz = normalize(up);\\n  vec3 ux = abs(uz.z) == 1.0 ? vec3(1.0, 0.0, 0.0) : normalize(vec3(uz.y, -uz.x, 0));\\n  vec3 uy = cross(uz, ux);\\n  return mat3(ux, uy, uz);\\n}\\n\\nbool project_needs_rotation(vec3 commonPosition, out mat3 transform) {\\n  if (project_uProjectionMode == PROJECTION_MODE_GLOBE) {\\n    transform = project_get_orientation_matrix(commonPosition);\\n    return true;\\n  }\\n  return false;\\n}\\nvec3 project_normal(vec3 vector) {\\n  vec4 normal_modelspace = project_uModelMatrix * vec4(vector, 0.0);\\n  vec3 n = normalize(normal_modelspace.xyz * project_uCommonUnitsPerMeter);\\n  mat3 rotation;\\n  if (project_needs_rotation(geometry.position.xyz, rotation)) {\\n    n = rotation * n;\\n  }\\n  return n;\\n}\\n\\nvec4 project_offset_(vec4 offset) {\\n  float dy = offset.y;\\n  vec3 commonUnitsPerWorldUnit = project_uCommonUnitsPerWorldUnit + project_uCommonUnitsPerWorldUnit2 * dy;\\n  return vec4(offset.xyz * commonUnitsPerWorldUnit, offset.w);\\n}\\nvec2 project_mercator_(vec2 lnglat) {\\n  float x = lnglat.x;\\n  if (project_uWrapLongitude) {\\n    x = mod(x + 180., 360.0) - 180.;\\n  }\\n  float y = clamp(lnglat.y, -89.9, 89.9);\\n  return vec2(\\n    radians(x) + PI,\\n    PI + log(tan_fp32(PI * 0.25 + radians(y) * 0.5))\\n  ) * WORLD_SCALE;\\n}\\n\\nvec3 project_globe_(vec3 lnglatz) {\\n  float lambda = radians(lnglatz.x);\\n  float phi = radians(lnglatz.y);\\n  float cosPhi = cos(phi);\\n  float D = (lnglatz.z / EARTH_RADIUS + 1.0) * GLOBE_RADIUS;\\n\\n  return vec3(\\n    sin(lambda) * cosPhi,\\n    -cos(lambda) * cosPhi,\\n    sin(phi)\\n  ) * D;\\n}\\nvec4 project_position(vec4 position, vec3 position64Low) {\\n  vec4 position_world = project_uModelMatrix * position;\\n  if (project_uProjectionMode == PROJECTION_MODE_WEB_MERCATOR) {\\n    if (project_uCoordinateSystem == COORDINATE_SYSTEM_LNGLAT) {\\n      return vec4(\\n        project_mercator_(position_world.xy),\\n        project_size_at_latitude(position_world.z, position_world.y),\\n        position_world.w\\n      );\\n    }\\n    if (project_uCoordinateSystem == COORDINATE_SYSTEM_CARTESIAN) {\\n      position_world.xyz += project_uCoordinateOrigin;\\n    }\\n  }\\n  if (project_uProjectionMode == PROJECTION_MODE_GLOBE) {\\n    if (project_uCoordinateSystem == COORDINATE_SYSTEM_LNGLAT) {\\n      return vec4(\\n        project_globe_(position_world.xyz),\\n        position_world.w\\n      );\\n    }\\n  }\\n  if (project_uProjectionMode == PROJECTION_MODE_WEB_MERCATOR_AUTO_OFFSET) {\\n    if (project_uCoordinateSystem == COORDINATE_SYSTEM_LNGLAT) {\\n      if (abs(position_world.y - project_uCoordinateOrigin.y) > 0.25) {\\n        return vec4(\\n          project_mercator_(position_world.xy) - project_uCommonOrigin.xy,\\n          project_size(position_world.z),\\n          position_world.w\\n        );\\n      }\\n    }\\n  }\\n  if (project_uProjectionMode == PROJECTION_MODE_IDENTITY ||\\n    (project_uProjectionMode == PROJECTION_MODE_WEB_MERCATOR_AUTO_OFFSET &&\\n    (project_uCoordinateSystem == COORDINATE_SYSTEM_LNGLAT ||\\n     project_uCoordinateSystem == COORDINATE_SYSTEM_CARTESIAN))) {\\n    position_world.xyz -= project_uCoordinateOrigin;\\n  }\\n  return project_offset_(position_world) + project_offset_(project_uModelMatrix * vec4(position64Low, 0.0));\\n}\\n\\nvec4 project_position(vec4 position) {\\n  return project_position(position, ZERO_64_LOW);\\n}\\n\\nvec3 project_position(vec3 position, vec3 position64Low) {\\n  vec4 projected_position = project_position(vec4(position, 1.0), position64Low);\\n  return projected_position.xyz;\\n}\\n\\nvec3 project_position(vec3 position) {\\n  vec4 projected_position = project_position(vec4(position, 1.0), ZERO_64_LOW);\\n  return projected_position.xyz;\\n}\\n\\nvec2 project_position(vec2 position) {\\n  vec4 projected_position = project_position(vec4(position, 0.0, 1.0), ZERO_64_LOW);\\n  return projected_position.xy;\\n}\\n\\nvec4 project_common_position_to_clipspace(vec4 position, mat4 viewProjectionMatrix, vec4 center) {\\n  return viewProjectionMatrix * position + center;\\n}\\nvec4 project_common_position_to_clipspace(vec4 position) {\\n  return project_common_position_to_clipspace(position, project_uViewProjectionMatrix, project_uCenter);\\n}\\nvec2 project_pixel_size_to_clipspace(vec2 pixels) {\\n  vec2 offset = pixels / project_uViewportSize * project_uDevicePixelRatio * 2.0;\\n  return offset * project_uFocalDistance;\\n}\\n\\nfloat project_size_to_pixel(float meters) {\\n  return project_size(meters) * project_uScale;\\n}\\nfloat project_size_to_pixel(float size, int unit) {\\n  if (unit == UNIT_METERS) return project_size_to_pixel(size);\\n  if (unit == UNIT_COMMON) return size * project_uScale;\\n  return size;\\n}\\nfloat project_pixel_size(float pixels) {\\n  return pixels / project_uScale;\\n}\\nvec2 project_pixel_size(vec2 pixels) {\\n  return pixels / project_uScale;\\n}\\n\"));\n//# sourceMappingURL=project.glsl.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/shaderlib/project/project.glsl.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/shaderlib/project/project.js":
/*!**************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/shaderlib/project/project.js ***!
  \**************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/shadertools/dist/esm/modules/fp32/fp32.js\");\n/* harmony import */ var _misc_geometry__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../misc/geometry */ \"./node_modules/@deck.gl/core/dist/esm/shaderlib/misc/geometry.js\");\n/* harmony import */ var _project_glsl__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./project.glsl */ \"./node_modules/@deck.gl/core/dist/esm/shaderlib/project/project.glsl.js\");\n/* harmony import */ var _viewport_uniforms__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./viewport-uniforms */ \"./node_modules/@deck.gl/core/dist/esm/shaderlib/project/viewport-uniforms.js\");\n\n\n\n\nconst INITIAL_MODULE_OPTIONS = {};\n\nfunction getUniforms(opts = INITIAL_MODULE_OPTIONS) {\n  if ('viewport' in opts) {\n    return (0,_viewport_uniforms__WEBPACK_IMPORTED_MODULE_0__.getUniformsFromViewport)(opts);\n  }\n\n  return {};\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ({\n  name: 'project',\n  dependencies: [_luma_gl_core__WEBPACK_IMPORTED_MODULE_1__.fp32, _misc_geometry__WEBPACK_IMPORTED_MODULE_2__[\"default\"]],\n  vs: _project_glsl__WEBPACK_IMPORTED_MODULE_3__[\"default\"],\n  getUniforms\n});\n//# sourceMappingURL=project.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/shaderlib/project/project.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/shaderlib/project/viewport-uniforms.js":
/*!************************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/shaderlib/project/viewport-uniforms.js ***!
  \************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getOffsetOrigin: () => (/* binding */ getOffsetOrigin),\n/* harmony export */   getUniformsFromViewport: () => (/* binding */ getUniformsFromViewport)\n/* harmony export */ });\n/* harmony import */ var gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! gl-matrix/mat4 */ \"./node_modules/gl-matrix/esm/mat4.js\");\n/* harmony import */ var gl_matrix_vec4__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! gl-matrix/vec4 */ \"./node_modules/gl-matrix/esm/vec4.js\");\n/* harmony import */ var _lib_constants__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../lib/constants */ \"./node_modules/@deck.gl/core/dist/esm/lib/constants.js\");\n/* harmony import */ var _utils_memoize__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../utils/memoize */ \"./node_modules/@deck.gl/core/dist/esm/utils/memoize.js\");\n\n\n\n\nconst ZERO_VECTOR = [0, 0, 0, 0];\nconst VECTOR_TO_POINT_MATRIX = [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0];\nconst IDENTITY_MATRIX = [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1];\nconst DEFAULT_PIXELS_PER_UNIT2 = [0, 0, 0];\nconst DEFAULT_COORDINATE_ORIGIN = [0, 0, 0];\nconst getMemoizedViewportUniforms = (0,_utils_memoize__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(calculateViewportUniforms);\nfunction getOffsetOrigin(viewport, coordinateSystem, coordinateOrigin = DEFAULT_COORDINATE_ORIGIN) {\n  if (coordinateOrigin.length < 3) {\n    coordinateOrigin = [coordinateOrigin[0], coordinateOrigin[1], 0];\n  }\n\n  let shaderCoordinateOrigin = coordinateOrigin;\n  let geospatialOrigin;\n  let offsetMode = true;\n\n  if (coordinateSystem === _lib_constants__WEBPACK_IMPORTED_MODULE_1__.COORDINATE_SYSTEM.LNGLAT_OFFSETS || coordinateSystem === _lib_constants__WEBPACK_IMPORTED_MODULE_1__.COORDINATE_SYSTEM.METER_OFFSETS) {\n    geospatialOrigin = coordinateOrigin;\n  } else {\n    geospatialOrigin = viewport.isGeospatial ? [Math.fround(viewport.longitude), Math.fround(viewport.latitude), 0] : null;\n  }\n\n  switch (viewport.projectionMode) {\n    case _lib_constants__WEBPACK_IMPORTED_MODULE_1__.PROJECTION_MODE.WEB_MERCATOR:\n      if (coordinateSystem === _lib_constants__WEBPACK_IMPORTED_MODULE_1__.COORDINATE_SYSTEM.LNGLAT || coordinateSystem === _lib_constants__WEBPACK_IMPORTED_MODULE_1__.COORDINATE_SYSTEM.CARTESIAN) {\n        geospatialOrigin = [0, 0, 0];\n        offsetMode = false;\n      }\n\n      break;\n\n    case _lib_constants__WEBPACK_IMPORTED_MODULE_1__.PROJECTION_MODE.WEB_MERCATOR_AUTO_OFFSET:\n      if (coordinateSystem === _lib_constants__WEBPACK_IMPORTED_MODULE_1__.COORDINATE_SYSTEM.LNGLAT) {\n        shaderCoordinateOrigin = geospatialOrigin;\n      } else if (coordinateSystem === _lib_constants__WEBPACK_IMPORTED_MODULE_1__.COORDINATE_SYSTEM.CARTESIAN) {\n        shaderCoordinateOrigin = [Math.fround(viewport.center[0]), Math.fround(viewport.center[1]), 0];\n        geospatialOrigin = viewport.unprojectPosition(shaderCoordinateOrigin);\n        shaderCoordinateOrigin[0] -= coordinateOrigin[0];\n        shaderCoordinateOrigin[1] -= coordinateOrigin[1];\n        shaderCoordinateOrigin[2] -= coordinateOrigin[2];\n      }\n\n      break;\n\n    case _lib_constants__WEBPACK_IMPORTED_MODULE_1__.PROJECTION_MODE.IDENTITY:\n      shaderCoordinateOrigin = viewport.position.map(Math.fround);\n      shaderCoordinateOrigin[2] = shaderCoordinateOrigin[2] || 0;\n      break;\n\n    case _lib_constants__WEBPACK_IMPORTED_MODULE_1__.PROJECTION_MODE.GLOBE:\n      offsetMode = false;\n      geospatialOrigin = null;\n      break;\n\n    default:\n      offsetMode = false;\n  }\n\n  return {\n    geospatialOrigin,\n    shaderCoordinateOrigin,\n    offsetMode\n  };\n}\n\nfunction calculateMatrixAndOffset(viewport, coordinateSystem, coordinateOrigin) {\n  const {\n    viewMatrixUncentered,\n    projectionMatrix\n  } = viewport;\n  let {\n    viewMatrix,\n    viewProjectionMatrix\n  } = viewport;\n  let projectionCenter = ZERO_VECTOR;\n  let originCommon = ZERO_VECTOR;\n  let cameraPosCommon = viewport.cameraPosition;\n  const {\n    geospatialOrigin,\n    shaderCoordinateOrigin,\n    offsetMode\n  } = getOffsetOrigin(viewport, coordinateSystem, coordinateOrigin);\n\n  if (offsetMode) {\n    originCommon = viewport.projectPosition(geospatialOrigin || shaderCoordinateOrigin);\n    cameraPosCommon = [cameraPosCommon[0] - originCommon[0], cameraPosCommon[1] - originCommon[1], cameraPosCommon[2] - originCommon[2]];\n    originCommon[3] = 1;\n    projectionCenter = gl_matrix_vec4__WEBPACK_IMPORTED_MODULE_2__.transformMat4([], originCommon, viewProjectionMatrix);\n    viewMatrix = viewMatrixUncentered || viewMatrix;\n    viewProjectionMatrix = gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_3__.multiply([], projectionMatrix, viewMatrix);\n    viewProjectionMatrix = gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_3__.multiply([], viewProjectionMatrix, VECTOR_TO_POINT_MATRIX);\n  }\n\n  return {\n    viewMatrix,\n    viewProjectionMatrix,\n    projectionCenter,\n    originCommon,\n    cameraPosCommon,\n    shaderCoordinateOrigin,\n    geospatialOrigin\n  };\n}\n\nfunction getUniformsFromViewport({\n  viewport,\n  devicePixelRatio = 1,\n  modelMatrix = null,\n  coordinateSystem = _lib_constants__WEBPACK_IMPORTED_MODULE_1__.COORDINATE_SYSTEM.DEFAULT,\n  coordinateOrigin = DEFAULT_COORDINATE_ORIGIN,\n  autoWrapLongitude = false\n}) {\n  if (coordinateSystem === _lib_constants__WEBPACK_IMPORTED_MODULE_1__.COORDINATE_SYSTEM.DEFAULT) {\n    coordinateSystem = viewport.isGeospatial ? _lib_constants__WEBPACK_IMPORTED_MODULE_1__.COORDINATE_SYSTEM.LNGLAT : _lib_constants__WEBPACK_IMPORTED_MODULE_1__.COORDINATE_SYSTEM.CARTESIAN;\n  }\n\n  const uniforms = getMemoizedViewportUniforms({\n    viewport,\n    devicePixelRatio,\n    coordinateSystem,\n    coordinateOrigin\n  });\n  uniforms.project_uWrapLongitude = autoWrapLongitude;\n  uniforms.project_uModelMatrix = modelMatrix || IDENTITY_MATRIX;\n  return uniforms;\n}\n\nfunction calculateViewportUniforms({\n  viewport,\n  devicePixelRatio,\n  coordinateSystem,\n  coordinateOrigin\n}) {\n  const {\n    projectionCenter,\n    viewProjectionMatrix,\n    originCommon,\n    cameraPosCommon,\n    shaderCoordinateOrigin,\n    geospatialOrigin\n  } = calculateMatrixAndOffset(viewport, coordinateSystem, coordinateOrigin);\n  const distanceScales = viewport.getDistanceScales();\n  const viewportSize = [viewport.width * devicePixelRatio, viewport.height * devicePixelRatio];\n  const focalDistance = gl_matrix_vec4__WEBPACK_IMPORTED_MODULE_2__.transformMat4([], [0, 0, -viewport.focalDistance, 1], viewport.projectionMatrix)[3] || 1;\n  const uniforms = {\n    project_uCoordinateSystem: coordinateSystem,\n    project_uProjectionMode: viewport.projectionMode,\n    project_uCoordinateOrigin: shaderCoordinateOrigin,\n    project_uCommonOrigin: originCommon.slice(0, 3),\n    project_uCenter: projectionCenter,\n    project_uPseudoMeters: Boolean(viewport._pseudoMeters),\n    project_uViewportSize: viewportSize,\n    project_uDevicePixelRatio: devicePixelRatio,\n    project_uFocalDistance: focalDistance,\n    project_uCommonUnitsPerMeter: distanceScales.unitsPerMeter,\n    project_uCommonUnitsPerWorldUnit: distanceScales.unitsPerMeter,\n    project_uCommonUnitsPerWorldUnit2: DEFAULT_PIXELS_PER_UNIT2,\n    project_uScale: viewport.scale,\n    project_uWrapLongitude: false,\n    project_uViewProjectionMatrix: viewProjectionMatrix,\n    project_uModelMatrix: IDENTITY_MATRIX,\n    project_uCameraPosition: cameraPosCommon\n  };\n\n  if (geospatialOrigin) {\n    const distanceScalesAtOrigin = viewport.getDistanceScales(geospatialOrigin);\n\n    switch (coordinateSystem) {\n      case _lib_constants__WEBPACK_IMPORTED_MODULE_1__.COORDINATE_SYSTEM.METER_OFFSETS:\n        uniforms.project_uCommonUnitsPerWorldUnit = distanceScalesAtOrigin.unitsPerMeter;\n        uniforms.project_uCommonUnitsPerWorldUnit2 = distanceScalesAtOrigin.unitsPerMeter2;\n        break;\n\n      case _lib_constants__WEBPACK_IMPORTED_MODULE_1__.COORDINATE_SYSTEM.LNGLAT:\n      case _lib_constants__WEBPACK_IMPORTED_MODULE_1__.COORDINATE_SYSTEM.LNGLAT_OFFSETS:\n        if (!viewport._pseudoMeters) {\n          uniforms.project_uCommonUnitsPerMeter = distanceScalesAtOrigin.unitsPerMeter;\n        }\n\n        uniforms.project_uCommonUnitsPerWorldUnit = distanceScalesAtOrigin.unitsPerDegree;\n        uniforms.project_uCommonUnitsPerWorldUnit2 = distanceScalesAtOrigin.unitsPerDegree2;\n        break;\n\n      case _lib_constants__WEBPACK_IMPORTED_MODULE_1__.COORDINATE_SYSTEM.CARTESIAN:\n        uniforms.project_uCommonUnitsPerWorldUnit = [1, 1, distanceScalesAtOrigin.unitsPerMeter[2]];\n        uniforms.project_uCommonUnitsPerWorldUnit2 = [0, 0, distanceScalesAtOrigin.unitsPerMeter2[2]];\n        break;\n\n      default:\n        break;\n    }\n  }\n\n  return uniforms;\n}\n//# sourceMappingURL=viewport-uniforms.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/shaderlib/project/viewport-uniforms.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/shaderlib/project32/project32.js":
/*!******************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/shaderlib/project32/project32.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _project_project__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../project/project */ \"./node_modules/@deck.gl/core/dist/esm/shaderlib/project/project.js\");\n\nconst vs = \"\\nvec4 project_position_to_clipspace(\\n  vec3 position, vec3 position64Low, vec3 offset, out vec4 commonPosition\\n) {\\n  vec3 projectedPosition = project_position(position, position64Low);\\n  mat3 rotation;\\n  if (project_needs_rotation(projectedPosition, rotation)) {\\n    // offset is specified as ENU\\n    // when in globe projection, rotate offset so that the ground alighs with the surface of the globe\\n    offset = rotation * offset;\\n  }\\n  commonPosition = vec4(projectedPosition + offset, 1.0);\\n  return project_common_position_to_clipspace(commonPosition);\\n}\\n\\nvec4 project_position_to_clipspace(\\n  vec3 position, vec3 position64Low, vec3 offset\\n) {\\n  vec4 commonPosition;\\n  return project_position_to_clipspace(position, position64Low, offset, commonPosition);\\n}\\n\";\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ({\n  name: 'project32',\n  dependencies: [_project_project__WEBPACK_IMPORTED_MODULE_0__[\"default\"]],\n  vs\n});\n//# sourceMappingURL=project32.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/shaderlib/project32/project32.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/shaderlib/shadow/shadow.js":
/*!************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/shaderlib/shadow/shadow.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _lib_constants__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../lib/constants */ \"./node_modules/@deck.gl/core/dist/esm/lib/constants.js\");\n/* harmony import */ var _project_project__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../project/project */ \"./node_modules/@deck.gl/core/dist/esm/shaderlib/project/project.js\");\n/* harmony import */ var _math_gl_core__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @math.gl/core */ \"./node_modules/@math.gl/core/dist/esm/classes/matrix4.js\");\n/* harmony import */ var _math_gl_core__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! @math.gl/core */ \"./node_modules/@math.gl/core/dist/esm/classes/vector3.js\");\n/* harmony import */ var _utils_memoize__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../utils/memoize */ \"./node_modules/@deck.gl/core/dist/esm/utils/memoize.js\");\n/* harmony import */ var _math_gl_web_mercator__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @math.gl/web-mercator */ \"./node_modules/@math.gl/web-mercator/dist/esm/index.js\");\n\n\n\n\n\nconst vs = \"\\nconst int max_lights = 2;\\nuniform mat4 shadow_uViewProjectionMatrices[max_lights];\\nuniform vec4 shadow_uProjectCenters[max_lights];\\nuniform bool shadow_uDrawShadowMap;\\nuniform bool shadow_uUseShadowMap;\\nuniform int shadow_uLightId;\\nuniform float shadow_uLightCount;\\n\\nvarying vec3 shadow_vPosition[max_lights];\\n\\nvec4 shadow_setVertexPosition(vec4 position_commonspace) {\\n  if (shadow_uDrawShadowMap) {\\n    return project_common_position_to_clipspace(position_commonspace, shadow_uViewProjectionMatrices[shadow_uLightId], shadow_uProjectCenters[shadow_uLightId]);\\n  }\\n  if (shadow_uUseShadowMap) {\\n    for (int i = 0; i < max_lights; i++) {\\n      if(i < int(shadow_uLightCount)) {\\n        vec4 shadowMap_position = project_common_position_to_clipspace(position_commonspace, shadow_uViewProjectionMatrices[i], shadow_uProjectCenters[i]);\\n        shadow_vPosition[i] = (shadowMap_position.xyz / shadowMap_position.w + 1.0) / 2.0;\\n      }\\n    }\\n  }\\n  return gl_Position;\\n}\\n\";\nconst fs = \"\\nconst int max_lights = 2;\\nuniform bool shadow_uDrawShadowMap;\\nuniform bool shadow_uUseShadowMap;\\nuniform sampler2D shadow_uShadowMap0;\\nuniform sampler2D shadow_uShadowMap1;\\nuniform vec4 shadow_uColor;\\nuniform float shadow_uLightCount;\\n\\nvarying vec3 shadow_vPosition[max_lights];\\n\\nconst vec4 bitPackShift = vec4(1.0, 255.0, 65025.0, 16581375.0);\\nconst vec4 bitUnpackShift = 1.0 / bitPackShift;\\nconst vec4 bitMask = vec4(1.0 / 255.0, 1.0 / 255.0, 1.0 / 255.0,  0.0);\\n\\nfloat shadow_getShadowWeight(vec3 position, sampler2D shadowMap) {\\n  vec4 rgbaDepth = texture2D(shadowMap, position.xy);\\n\\n  float z = dot(rgbaDepth, bitUnpackShift);\\n  return smoothstep(0.001, 0.01, position.z - z);\\n}\\n\\nvec4 shadow_filterShadowColor(vec4 color) {\\n  if (shadow_uDrawShadowMap) {\\n    vec4 rgbaDepth = fract(gl_FragCoord.z * bitPackShift);\\n    rgbaDepth -= rgbaDepth.gbaa * bitMask;\\n    return rgbaDepth;\\n  }\\n  if (shadow_uUseShadowMap) {\\n    float shadowAlpha = 0.0;\\n    shadowAlpha += shadow_getShadowWeight(shadow_vPosition[0], shadow_uShadowMap0);\\n    if(shadow_uLightCount > 1.0) {\\n      shadowAlpha += shadow_getShadowWeight(shadow_vPosition[1], shadow_uShadowMap1);\\n    }\\n    shadowAlpha *= shadow_uColor.a / shadow_uLightCount;\\n    float blendedAlpha = shadowAlpha + color.a * (1.0 - shadowAlpha);\\n\\n    return vec4(\\n      mix(color.rgb, shadow_uColor.rgb, shadowAlpha / blendedAlpha),\\n      blendedAlpha\\n    );\\n  }\\n  return color;\\n}\\n\";\nconst getMemoizedViewportCenterPosition = (0,_utils_memoize__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(getViewportCenterPosition);\nconst getMemoizedViewProjectionMatrices = (0,_utils_memoize__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(getViewProjectionMatrices);\nconst DEFAULT_SHADOW_COLOR = [0, 0, 0, 1.0];\nconst VECTOR_TO_POINT_MATRIX = [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0];\n\nfunction screenToCommonSpace(xyz, pixelUnprojectionMatrix) {\n  const [x, y, z] = xyz;\n  const coord = (0,_math_gl_web_mercator__WEBPACK_IMPORTED_MODULE_0__.pixelsToWorld)([x, y, z], pixelUnprojectionMatrix);\n\n  if (Number.isFinite(z)) {\n    return coord;\n  }\n\n  return [coord[0], coord[1], 0];\n}\n\nfunction getViewportCenterPosition({\n  viewport,\n  center\n}) {\n  return new _math_gl_core__WEBPACK_IMPORTED_MODULE_2__[\"default\"](viewport.viewProjectionMatrix).invert().transform(center);\n}\n\nfunction getViewProjectionMatrices({\n  viewport,\n  shadowMatrices\n}) {\n  const projectionMatrices = [];\n  const pixelUnprojectionMatrix = viewport.pixelUnprojectionMatrix;\n  const farZ = viewport.isGeospatial ? undefined : 1;\n  const corners = [[0, 0, farZ], [viewport.width, 0, farZ], [0, viewport.height, farZ], [viewport.width, viewport.height, farZ], [0, 0, -1], [viewport.width, 0, -1], [0, viewport.height, -1], [viewport.width, viewport.height, -1]].map(pixel => screenToCommonSpace(pixel, pixelUnprojectionMatrix));\n\n  for (const shadowMatrix of shadowMatrices) {\n    const viewMatrix = shadowMatrix.clone().translate(new _math_gl_core__WEBPACK_IMPORTED_MODULE_3__[\"default\"](viewport.center).negate());\n    const positions = corners.map(corner => viewMatrix.transform(corner));\n    const projectionMatrix = new _math_gl_core__WEBPACK_IMPORTED_MODULE_2__[\"default\"]().ortho({\n      left: Math.min(...positions.map(position => position[0])),\n      right: Math.max(...positions.map(position => position[0])),\n      bottom: Math.min(...positions.map(position => position[1])),\n      top: Math.max(...positions.map(position => position[1])),\n      near: Math.min(...positions.map(position => -position[2])),\n      far: Math.max(...positions.map(position => -position[2]))\n    });\n    projectionMatrices.push(projectionMatrix.multiplyRight(shadowMatrix));\n  }\n\n  return projectionMatrices;\n}\n\nfunction createShadowUniforms(opts, context) {\n  const {\n    shadowEnabled = true\n  } = opts;\n\n  if (!shadowEnabled || !opts.shadowMatrices || !opts.shadowMatrices.length) {\n    return {\n      shadow_uDrawShadowMap: false,\n      shadow_uUseShadowMap: false\n    };\n  }\n\n  const uniforms = {\n    shadow_uDrawShadowMap: Boolean(opts.drawToShadowMap),\n    shadow_uUseShadowMap: opts.shadowMaps ? opts.shadowMaps.length > 0 : false,\n    shadow_uColor: opts.shadowColor || DEFAULT_SHADOW_COLOR,\n    shadow_uLightId: opts.shadowLightId || 0,\n    shadow_uLightCount: opts.shadowMatrices.length\n  };\n  const center = getMemoizedViewportCenterPosition({\n    viewport: opts.viewport,\n    center: context.project_uCenter\n  });\n  const projectCenters = [];\n  const viewProjectionMatrices = getMemoizedViewProjectionMatrices({\n    shadowMatrices: opts.shadowMatrices,\n    viewport: opts.viewport\n  }).slice();\n\n  for (let i = 0; i < opts.shadowMatrices.length; i++) {\n    const viewProjectionMatrix = viewProjectionMatrices[i];\n    const viewProjectionMatrixCentered = viewProjectionMatrix.clone().translate(new _math_gl_core__WEBPACK_IMPORTED_MODULE_3__[\"default\"](opts.viewport.center).negate());\n\n    if (context.project_uCoordinateSystem === _lib_constants__WEBPACK_IMPORTED_MODULE_4__.COORDINATE_SYSTEM.LNGLAT && context.project_uProjectionMode === _lib_constants__WEBPACK_IMPORTED_MODULE_4__.PROJECTION_MODE.WEB_MERCATOR) {\n      viewProjectionMatrices[i] = viewProjectionMatrixCentered;\n      projectCenters[i] = center;\n    } else {\n      viewProjectionMatrices[i] = viewProjectionMatrix.clone().multiplyRight(VECTOR_TO_POINT_MATRIX);\n      projectCenters[i] = viewProjectionMatrixCentered.transform(center);\n    }\n  }\n\n  for (let i = 0; i < viewProjectionMatrices.length; i++) {\n    uniforms[\"shadow_uViewProjectionMatrices[\".concat(i, \"]\")] = viewProjectionMatrices[i];\n    uniforms[\"shadow_uProjectCenters[\".concat(i, \"]\")] = projectCenters[i];\n\n    if (opts.shadowMaps && opts.shadowMaps.length > 0) {\n      uniforms[\"shadow_uShadowMap\".concat(i)] = opts.shadowMaps[i];\n    } else {\n      uniforms[\"shadow_uShadowMap\".concat(i)] = opts.dummyShadowMap;\n    }\n  }\n\n  return uniforms;\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ({\n  name: 'shadow',\n  dependencies: [_project_project__WEBPACK_IMPORTED_MODULE_5__[\"default\"]],\n  vs,\n  fs,\n  inject: {\n    'vs:DECKGL_FILTER_GL_POSITION': \"\\n    position = shadow_setVertexPosition(geometry.position);\\n    \",\n    'fs:DECKGL_FILTER_COLOR': \"\\n    color = shadow_filterShadowColor(color);\\n    \"\n  },\n  getUniforms: (opts = {}, context = {}) => {\n    if ('viewport' in opts && (opts.drawToShadowMap || opts.shadowMaps && opts.shadowMaps.length > 0)) {\n      return createShadowUniforms(opts, context);\n    }\n\n    return {};\n  }\n});\n//# sourceMappingURL=shadow.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/shaderlib/shadow/shadow.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/transitions/cpu-interpolation-transition.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/transitions/cpu-interpolation-transition.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ CPUInterpolationTransition)\n/* harmony export */ });\n/* harmony import */ var _math_gl_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @math.gl/core */ \"./node_modules/@math.gl/core/dist/esm/lib/common.js\");\n/* harmony import */ var _transition__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./transition */ \"./node_modules/@deck.gl/core/dist/esm/transitions/transition.js\");\n\n\nclass CPUInterpolationTransition extends _transition__WEBPACK_IMPORTED_MODULE_0__[\"default\"] {\n  get value() {\n    return this._value;\n  }\n\n  _onUpdate() {\n    const {\n      time,\n      settings: {\n        fromValue,\n        toValue,\n        duration,\n        easing\n      }\n    } = this;\n    const t = easing(time / duration);\n    this._value = (0,_math_gl_core__WEBPACK_IMPORTED_MODULE_1__.lerp)(fromValue, toValue, t);\n  }\n\n}\n//# sourceMappingURL=cpu-interpolation-transition.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/transitions/cpu-interpolation-transition.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/transitions/cpu-spring-transition.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/transitions/cpu-spring-transition.js ***!
  \**********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ CPUSpringTransition)\n/* harmony export */ });\n/* harmony import */ var _transition__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./transition */ \"./node_modules/@deck.gl/core/dist/esm/transitions/transition.js\");\n\nconst EPSILON = 1e-5;\n\nfunction updateSpringElement(prev, cur, dest, damping, stiffness) {\n  const velocity = cur - prev;\n  const delta = dest - cur;\n  const spring = delta * stiffness;\n  const damper = -velocity * damping;\n  return spring + damper + velocity + cur;\n}\n\nfunction updateSpring(prev, cur, dest, damping, stiffness) {\n  if (Array.isArray(dest)) {\n    const next = [];\n\n    for (let i = 0; i < dest.length; i++) {\n      next[i] = updateSpringElement(prev[i], cur[i], dest[i], damping, stiffness);\n    }\n\n    return next;\n  }\n\n  return updateSpringElement(prev, cur, dest, damping, stiffness);\n}\n\nfunction distance(value1, value2) {\n  if (Array.isArray(value1)) {\n    let distanceSquare = 0;\n\n    for (let i = 0; i < value1.length; i++) {\n      const d = value1[i] - value2[i];\n      distanceSquare += d * d;\n    }\n\n    return Math.sqrt(distanceSquare);\n  }\n\n  return Math.abs(value1 - value2);\n}\n\nclass CPUSpringTransition extends _transition__WEBPACK_IMPORTED_MODULE_0__[\"default\"] {\n  get value() {\n    return this._currValue;\n  }\n\n  _onUpdate() {\n    const {\n      fromValue,\n      toValue,\n      damping,\n      stiffness\n    } = this.settings;\n    const {\n      _prevValue = fromValue,\n      _currValue = fromValue\n    } = this;\n    let nextValue = updateSpring(_prevValue, _currValue, toValue, damping, stiffness);\n    const delta = distance(nextValue, toValue);\n    const velocity = distance(nextValue, _currValue);\n\n    if (delta < EPSILON && velocity < EPSILON) {\n      nextValue = toValue;\n      this.end();\n    }\n\n    this._prevValue = _currValue;\n    this._currValue = nextValue;\n  }\n\n}\n//# sourceMappingURL=cpu-spring-transition.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/transitions/cpu-spring-transition.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/transitions/gpu-interpolation-transition.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/transitions/gpu-interpolation-transition.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ GPUInterpolationTransition)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/buffer.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/engine/dist/esm/transform/transform.js\");\n/* harmony import */ var _lib_attribute_attribute__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../lib/attribute/attribute */ \"./node_modules/@deck.gl/core/dist/esm/lib/attribute/attribute.js\");\n/* harmony import */ var _lib_attribute_attribute_transition_utils__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../lib/attribute/attribute-transition-utils */ \"./node_modules/@deck.gl/core/dist/esm/lib/attribute/attribute-transition-utils.js\");\n/* harmony import */ var _transition__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./transition */ \"./node_modules/@deck.gl/core/dist/esm/transitions/transition.js\");\n\n\n\n\n\nclass GPUInterpolationTransition {\n  constructor({\n    gl,\n    attribute,\n    timeline\n  }) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"gl\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"type\", 'interpolation');\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"attributeInTransition\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"settings\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"attribute\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"transition\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"currentStartIndices\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"currentLength\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"transform\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"buffers\", void 0);\n\n    this.gl = gl;\n    this.transition = new _transition__WEBPACK_IMPORTED_MODULE_1__[\"default\"](timeline);\n    this.attribute = attribute;\n    this.attributeInTransition = new _lib_attribute_attribute__WEBPACK_IMPORTED_MODULE_2__[\"default\"](gl, attribute.settings);\n    this.currentStartIndices = attribute.startIndices;\n    this.currentLength = 0;\n    this.transform = getTransform(gl, attribute);\n    const bufferOpts = {\n      byteLength: 0,\n      usage: 35050\n    };\n    this.buffers = [new _luma_gl_core__WEBPACK_IMPORTED_MODULE_3__[\"default\"](gl, bufferOpts), new _luma_gl_core__WEBPACK_IMPORTED_MODULE_3__[\"default\"](gl, bufferOpts)];\n  }\n\n  get inProgress() {\n    return this.transition.inProgress;\n  }\n\n  start(transitionSettings, numInstances) {\n    if (transitionSettings.duration <= 0) {\n      this.transition.cancel();\n      return;\n    }\n\n    this.settings = transitionSettings;\n    const {\n      gl,\n      buffers,\n      attribute\n    } = this;\n    (0,_lib_attribute_attribute_transition_utils__WEBPACK_IMPORTED_MODULE_4__.cycleBuffers)(buffers);\n    const padBufferOpts = {\n      numInstances,\n      attribute,\n      fromLength: this.currentLength,\n      fromStartIndices: this.currentStartIndices,\n      getData: transitionSettings.enter\n    };\n\n    for (const buffer of buffers) {\n      (0,_lib_attribute_attribute_transition_utils__WEBPACK_IMPORTED_MODULE_4__.padBuffer)({\n        buffer,\n        ...padBufferOpts\n      });\n    }\n\n    this.currentStartIndices = attribute.startIndices;\n    this.currentLength = (0,_lib_attribute_attribute_transition_utils__WEBPACK_IMPORTED_MODULE_4__.getAttributeBufferLength)(attribute, numInstances);\n    this.attributeInTransition.setData({\n      buffer: buffers[1],\n      value: attribute.value\n    });\n    this.transition.start(transitionSettings);\n    this.transform.update({\n      elementCount: Math.floor(this.currentLength / attribute.size),\n      sourceBuffers: {\n        aFrom: buffers[0],\n        aTo: (0,_lib_attribute_attribute_transition_utils__WEBPACK_IMPORTED_MODULE_4__.getSourceBufferAttribute)(gl, attribute)\n      },\n      feedbackBuffers: {\n        vCurrent: buffers[1]\n      }\n    });\n  }\n\n  update() {\n    const updated = this.transition.update();\n\n    if (updated) {\n      const {\n        duration,\n        easing\n      } = this.settings;\n      const {\n        time\n      } = this.transition;\n      let t = time / duration;\n\n      if (easing) {\n        t = easing(t);\n      }\n\n      this.transform.run({\n        uniforms: {\n          time: t\n        }\n      });\n    }\n\n    return updated;\n  }\n\n  cancel() {\n    this.transition.cancel();\n    this.transform.delete();\n\n    for (const buffer of this.buffers) {\n      buffer.delete();\n    }\n\n    this.buffers.length = 0;\n  }\n\n}\nconst vs = \"\\n#define SHADER_NAME interpolation-transition-vertex-shader\\n\\nuniform float time;\\nattribute ATTRIBUTE_TYPE aFrom;\\nattribute ATTRIBUTE_TYPE aTo;\\nvarying ATTRIBUTE_TYPE vCurrent;\\n\\nvoid main(void) {\\n  vCurrent = mix(aFrom, aTo, time);\\n  gl_Position = vec4(0.0);\\n}\\n\";\n\nfunction getTransform(gl, attribute) {\n  const attributeType = (0,_lib_attribute_attribute_transition_utils__WEBPACK_IMPORTED_MODULE_4__.getAttributeTypeFromSize)(attribute.size);\n  return new _luma_gl_core__WEBPACK_IMPORTED_MODULE_5__[\"default\"](gl, {\n    vs,\n    defines: {\n      ATTRIBUTE_TYPE: attributeType\n    },\n    varyings: ['vCurrent']\n  });\n}\n//# sourceMappingURL=gpu-interpolation-transition.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/transitions/gpu-interpolation-transition.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/transitions/gpu-spring-transition.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/transitions/gpu-spring-transition.js ***!
  \**********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ GPUSpringTransition)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/buffer.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/copy-and-blit.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/engine/dist/esm/transform/transform.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/texture-2d.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/framebuffer.js\");\n/* harmony import */ var _lib_attribute_attribute_transition_utils__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../lib/attribute/attribute-transition-utils */ \"./node_modules/@deck.gl/core/dist/esm/lib/attribute/attribute-transition-utils.js\");\n/* harmony import */ var _lib_attribute_attribute__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../lib/attribute/attribute */ \"./node_modules/@deck.gl/core/dist/esm/lib/attribute/attribute.js\");\n/* harmony import */ var _transition__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./transition */ \"./node_modules/@deck.gl/core/dist/esm/transitions/transition.js\");\n\n\n\n\n\nclass GPUSpringTransition {\n  constructor({\n    gl,\n    attribute,\n    timeline\n  }) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"gl\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"type\", 'spring');\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"attributeInTransition\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"settings\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"attribute\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"transition\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"currentStartIndices\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"currentLength\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"texture\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"framebuffer\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"transform\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"buffers\", void 0);\n\n    this.gl = gl;\n    this.type = 'spring';\n    this.transition = new _transition__WEBPACK_IMPORTED_MODULE_1__[\"default\"](timeline);\n    this.attribute = attribute;\n    this.attributeInTransition = new _lib_attribute_attribute__WEBPACK_IMPORTED_MODULE_2__[\"default\"](gl, { ...attribute.settings,\n      normalized: false\n    });\n    this.currentStartIndices = attribute.startIndices;\n    this.currentLength = 0;\n    this.texture = getTexture(gl);\n    this.framebuffer = getFramebuffer(gl, this.texture);\n    this.transform = getTransform(gl, attribute, this.framebuffer);\n    const bufferOpts = {\n      byteLength: 0,\n      usage: 35050\n    };\n    this.buffers = [new _luma_gl_core__WEBPACK_IMPORTED_MODULE_3__[\"default\"](gl, bufferOpts), new _luma_gl_core__WEBPACK_IMPORTED_MODULE_3__[\"default\"](gl, bufferOpts), new _luma_gl_core__WEBPACK_IMPORTED_MODULE_3__[\"default\"](gl, bufferOpts)];\n  }\n\n  get inProgress() {\n    return this.transition.inProgress;\n  }\n\n  start(transitionSettings, numInstances) {\n    const {\n      gl,\n      buffers,\n      attribute\n    } = this;\n    const padBufferOpts = {\n      numInstances,\n      attribute,\n      fromLength: this.currentLength,\n      fromStartIndices: this.currentStartIndices,\n      getData: transitionSettings.enter\n    };\n\n    for (const buffer of buffers) {\n      (0,_lib_attribute_attribute_transition_utils__WEBPACK_IMPORTED_MODULE_4__.padBuffer)({\n        buffer,\n        ...padBufferOpts\n      });\n    }\n\n    this.settings = transitionSettings;\n    this.currentStartIndices = attribute.startIndices;\n    this.currentLength = (0,_lib_attribute_attribute_transition_utils__WEBPACK_IMPORTED_MODULE_4__.getAttributeBufferLength)(attribute, numInstances);\n    this.attributeInTransition.setData({\n      buffer: buffers[1],\n      value: attribute.value\n    });\n    this.transition.start({ ...transitionSettings,\n      duration: Infinity\n    });\n    this.transform.update({\n      elementCount: Math.floor(this.currentLength / attribute.size),\n      sourceBuffers: {\n        aTo: (0,_lib_attribute_attribute_transition_utils__WEBPACK_IMPORTED_MODULE_4__.getSourceBufferAttribute)(gl, attribute)\n      }\n    });\n  }\n\n  update() {\n    const {\n      buffers,\n      transform,\n      framebuffer,\n      transition\n    } = this;\n    const updated = transition.update();\n\n    if (!updated) {\n      return false;\n    }\n\n    const settings = this.settings;\n    transform.update({\n      sourceBuffers: {\n        aPrev: buffers[0],\n        aCur: buffers[1]\n      },\n      feedbackBuffers: {\n        vNext: buffers[2]\n      }\n    });\n    transform.run({\n      framebuffer,\n      discard: false,\n      clearRenderTarget: true,\n      uniforms: {\n        stiffness: settings.stiffness,\n        damping: settings.damping\n      },\n      parameters: {\n        depthTest: false,\n        blend: true,\n        viewport: [0, 0, 1, 1],\n        blendFunc: [1, 1],\n        blendEquation: [32776, 32776]\n      }\n    });\n    (0,_lib_attribute_attribute_transition_utils__WEBPACK_IMPORTED_MODULE_4__.cycleBuffers)(buffers);\n    this.attributeInTransition.setData({\n      buffer: buffers[1],\n      value: this.attribute.value\n    });\n    const isTransitioning = (0,_luma_gl_core__WEBPACK_IMPORTED_MODULE_5__.readPixelsToArray)(framebuffer)[0] > 0;\n\n    if (!isTransitioning) {\n      transition.end();\n    }\n\n    return true;\n  }\n\n  cancel() {\n    this.transition.cancel();\n    this.transform.delete();\n\n    for (const buffer of this.buffers) {\n      buffer.delete();\n    }\n\n    this.buffers.length = 0;\n    this.texture.delete();\n    this.framebuffer.delete();\n  }\n\n}\n\nfunction getTransform(gl, attribute, framebuffer) {\n  const attributeType = (0,_lib_attribute_attribute_transition_utils__WEBPACK_IMPORTED_MODULE_4__.getAttributeTypeFromSize)(attribute.size);\n  return new _luma_gl_core__WEBPACK_IMPORTED_MODULE_6__[\"default\"](gl, {\n    framebuffer,\n    vs: \"\\n#define SHADER_NAME spring-transition-vertex-shader\\n\\n#define EPSILON 0.00001\\n\\nuniform float stiffness;\\nuniform float damping;\\nattribute ATTRIBUTE_TYPE aPrev;\\nattribute ATTRIBUTE_TYPE aCur;\\nattribute ATTRIBUTE_TYPE aTo;\\nvarying ATTRIBUTE_TYPE vNext;\\nvarying float vIsTransitioningFlag;\\n\\nATTRIBUTE_TYPE getNextValue(ATTRIBUTE_TYPE cur, ATTRIBUTE_TYPE prev, ATTRIBUTE_TYPE dest) {\\n  ATTRIBUTE_TYPE velocity = cur - prev;\\n  ATTRIBUTE_TYPE delta = dest - cur;\\n  ATTRIBUTE_TYPE spring = delta * stiffness;\\n  ATTRIBUTE_TYPE damper = velocity * -1.0 * damping;\\n  return spring + damper + velocity + cur;\\n}\\n\\nvoid main(void) {\\n  bool isTransitioning = length(aCur - aPrev) > EPSILON || length(aTo - aCur) > EPSILON;\\n  vIsTransitioningFlag = isTransitioning ? 1.0 : 0.0;\\n\\n  vNext = getNextValue(aCur, aPrev, aTo);\\n  gl_Position = vec4(0, 0, 0, 1);\\n  gl_PointSize = 100.0;\\n}\\n\",\n    fs: \"\\n#define SHADER_NAME spring-transition-is-transitioning-fragment-shader\\n\\nvarying float vIsTransitioningFlag;\\n\\nvoid main(void) {\\n  if (vIsTransitioningFlag == 0.0) {\\n    discard;\\n  }\\n  gl_FragColor = vec4(1.0);\\n}\",\n    defines: {\n      ATTRIBUTE_TYPE: attributeType\n    },\n    varyings: ['vNext']\n  });\n}\n\nfunction getTexture(gl) {\n  return new _luma_gl_core__WEBPACK_IMPORTED_MODULE_7__[\"default\"](gl, {\n    data: new Uint8Array(4),\n    format: 6408,\n    type: 5121,\n    border: 0,\n    mipmaps: false,\n    dataFormat: 6408,\n    width: 1,\n    height: 1\n  });\n}\n\nfunction getFramebuffer(gl, texture) {\n  return new _luma_gl_core__WEBPACK_IMPORTED_MODULE_8__[\"default\"](gl, {\n    id: 'spring-transition-is-transitioning-framebuffer',\n    width: 1,\n    height: 1,\n    attachments: {\n      [36064]: texture\n    }\n  });\n}\n//# sourceMappingURL=gpu-spring-transition.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/transitions/gpu-spring-transition.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/transitions/linear-interpolator.js":
/*!********************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/transitions/linear-interpolator.js ***!
  \********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ LinearInterpolator)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _transition_interpolator__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./transition-interpolator */ \"./node_modules/@deck.gl/core/dist/esm/transitions/transition-interpolator.js\");\n/* harmony import */ var _math_gl_core__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @math.gl/core */ \"./node_modules/@math.gl/core/dist/esm/lib/common.js\");\n\n\n\nconst DEFAULT_PROPS = ['longitude', 'latitude', 'zoom', 'bearing', 'pitch'];\nconst DEFAULT_REQUIRED_PROPS = ['longitude', 'latitude', 'zoom'];\nclass LinearInterpolator extends _transition_interpolator__WEBPACK_IMPORTED_MODULE_1__[\"default\"] {\n  constructor(opts = {}) {\n    const transitionProps = Array.isArray(opts) ? opts : opts.transitionProps;\n    const normalizedOpts = Array.isArray(opts) ? {} : opts;\n    normalizedOpts.transitionProps = Array.isArray(transitionProps) ? {\n      compare: transitionProps,\n      required: transitionProps\n    } : transitionProps || {\n      compare: DEFAULT_PROPS,\n      required: DEFAULT_REQUIRED_PROPS\n    };\n    super(normalizedOpts.transitionProps);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"opts\", void 0);\n\n    this.opts = normalizedOpts;\n  }\n\n  initializeProps(startProps, endProps) {\n    const result = super.initializeProps(startProps, endProps);\n    const {\n      makeViewport,\n      around\n    } = this.opts;\n\n    if (makeViewport && around) {\n      const startViewport = makeViewport(startProps);\n      const endViewport = makeViewport(endProps);\n      const aroundPosition = startViewport.unproject(around);\n      result.start.around = around;\n      Object.assign(result.end, {\n        around: endViewport.project(aroundPosition),\n        aroundPosition,\n        width: endProps.width,\n        height: endProps.height\n      });\n    }\n\n    return result;\n  }\n\n  interpolateProps(startProps, endProps, t) {\n    const propsInTransition = {};\n\n    for (const key of this._propsToExtract) {\n      propsInTransition[key] = (0,_math_gl_core__WEBPACK_IMPORTED_MODULE_2__.lerp)(startProps[key] || 0, endProps[key] || 0, t);\n    }\n\n    if (endProps.aroundPosition && this.opts.makeViewport) {\n      const viewport = this.opts.makeViewport({ ...endProps,\n        ...propsInTransition\n      });\n      Object.assign(propsInTransition, viewport.panByPosition(endProps.aroundPosition, (0,_math_gl_core__WEBPACK_IMPORTED_MODULE_2__.lerp)(startProps.around, endProps.around, t)));\n    }\n\n    return propsInTransition;\n  }\n\n}\n//# sourceMappingURL=linear-interpolator.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/transitions/linear-interpolator.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/transitions/transition-interpolator.js":
/*!************************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/transitions/transition-interpolator.js ***!
  \************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ TransitionInterpolator)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _math_gl_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @math.gl/core */ \"./node_modules/@math.gl/core/dist/esm/lib/common.js\");\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/assert */ \"./node_modules/@deck.gl/core/dist/esm/utils/assert.js\");\n\n\n\nclass TransitionInterpolator {\n  constructor(opts) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_propsToCompare\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_propsToExtract\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_requiredProps\", void 0);\n\n    const {\n      compare,\n      extract,\n      required\n    } = opts;\n    this._propsToCompare = compare;\n    this._propsToExtract = extract || compare;\n    this._requiredProps = required;\n  }\n\n  arePropsEqual(currentProps, nextProps) {\n    for (const key of this._propsToCompare) {\n      if (!(key in currentProps) || !(key in nextProps) || !(0,_math_gl_core__WEBPACK_IMPORTED_MODULE_1__.equals)(currentProps[key], nextProps[key])) {\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n  initializeProps(startProps, endProps) {\n    const startViewStateProps = {};\n    const endViewStateProps = {};\n\n    for (const key of this._propsToExtract) {\n      if (key in startProps || key in endProps) {\n        startViewStateProps[key] = startProps[key];\n        endViewStateProps[key] = endProps[key];\n      }\n    }\n\n    this._checkRequiredProps(startViewStateProps);\n\n    this._checkRequiredProps(endViewStateProps);\n\n    return {\n      start: startViewStateProps,\n      end: endViewStateProps\n    };\n  }\n\n  getDuration(startProps, endProps) {\n    return endProps.transitionDuration;\n  }\n\n  _checkRequiredProps(props) {\n    if (!this._requiredProps) {\n      return;\n    }\n\n    this._requiredProps.forEach(propName => {\n      const value = props[propName];\n      (0,_utils_assert__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(Number.isFinite(value) || Array.isArray(value), \"\".concat(propName, \" is required for transition\"));\n    });\n  }\n\n}\n//# sourceMappingURL=transition-interpolator.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/transitions/transition-interpolator.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/transitions/transition.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/transitions/transition.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Transition)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n\nclass Transition {\n  constructor(timeline) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_inProgress\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_handle\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_timeline\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"time\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"settings\", void 0);\n\n    this._inProgress = false;\n    this._handle = null;\n    this._timeline = timeline;\n    this.time = 0;\n    this.settings = {\n      duration: 0\n    };\n  }\n\n  get inProgress() {\n    return this._inProgress;\n  }\n\n  start(settings) {\n    var _this$settings$onStar, _this$settings;\n\n    this.cancel();\n    this.settings = settings;\n    this._inProgress = true;\n    (_this$settings$onStar = (_this$settings = this.settings).onStart) === null || _this$settings$onStar === void 0 ? void 0 : _this$settings$onStar.call(_this$settings, this);\n  }\n\n  end() {\n    if (this._inProgress) {\n      var _this$settings$onEnd, _this$settings2;\n\n      this._timeline.removeChannel(this._handle);\n\n      this._handle = null;\n      this._inProgress = false;\n      (_this$settings$onEnd = (_this$settings2 = this.settings).onEnd) === null || _this$settings$onEnd === void 0 ? void 0 : _this$settings$onEnd.call(_this$settings2, this);\n    }\n  }\n\n  cancel() {\n    if (this._inProgress) {\n      var _this$settings$onInte, _this$settings3;\n\n      (_this$settings$onInte = (_this$settings3 = this.settings).onInterrupt) === null || _this$settings$onInte === void 0 ? void 0 : _this$settings$onInte.call(_this$settings3, this);\n\n      this._timeline.removeChannel(this._handle);\n\n      this._handle = null;\n      this._inProgress = false;\n    }\n  }\n\n  update() {\n    var _this$settings$onUpda, _this$settings4;\n\n    if (!this._inProgress) {\n      return false;\n    }\n\n    if (this._handle === null) {\n      const {\n        _timeline: timeline,\n        settings\n      } = this;\n      this._handle = timeline.addChannel({\n        delay: timeline.getTime(),\n        duration: settings.duration\n      });\n    }\n\n    this.time = this._timeline.getTime(this._handle);\n\n    this._onUpdate();\n\n    (_this$settings$onUpda = (_this$settings4 = this.settings).onUpdate) === null || _this$settings$onUpda === void 0 ? void 0 : _this$settings$onUpda.call(_this$settings4, this);\n\n    if (this._timeline.isFinished(this._handle)) {\n      this.end();\n    }\n\n    return true;\n  }\n\n  _onUpdate() {}\n\n}\n//# sourceMappingURL=transition.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/transitions/transition.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/utils/array-utils.js":
/*!******************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/utils/array-utils.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   padArray: () => (/* binding */ padArray)\n/* harmony export */ });\nfunction padArrayChunk(options) {\n  const {\n    source,\n    target,\n    start = 0,\n    size,\n    getData\n  } = options;\n  const end = options.end || target.length;\n  const sourceLength = source.length;\n  const targetLength = end - start;\n\n  if (sourceLength > targetLength) {\n    target.set(source.subarray(0, targetLength), start);\n    return;\n  }\n\n  target.set(source, start);\n\n  if (!getData) {\n    return;\n  }\n\n  let i = sourceLength;\n\n  while (i < targetLength) {\n    const datum = getData(i, source);\n\n    for (let j = 0; j < size; j++) {\n      target[start + i] = datum[j] || 0;\n      i++;\n    }\n  }\n}\n\nfunction padArray({\n  source,\n  target,\n  size,\n  getData,\n  sourceStartIndices,\n  targetStartIndices\n}) {\n  if (!Array.isArray(targetStartIndices)) {\n    padArrayChunk({\n      source,\n      target,\n      size,\n      getData\n    });\n    return target;\n  }\n\n  let sourceIndex = 0;\n  let targetIndex = 0;\n\n  const getChunkData = getData && ((i, chunk) => getData(i + targetIndex, chunk));\n\n  const n = Math.min(sourceStartIndices.length, targetStartIndices.length);\n\n  for (let i = 1; i < n; i++) {\n    const nextSourceIndex = sourceStartIndices[i] * size;\n    const nextTargetIndex = targetStartIndices[i] * size;\n    padArrayChunk({\n      source: source.subarray(sourceIndex, nextSourceIndex),\n      target,\n      start: targetIndex,\n      end: nextTargetIndex,\n      size,\n      getData: getChunkData\n    });\n    sourceIndex = nextSourceIndex;\n    targetIndex = nextTargetIndex;\n  }\n\n  if (targetIndex < target.length) {\n    padArrayChunk({\n      source: [],\n      target,\n      start: targetIndex,\n      size,\n      getData: getChunkData\n    });\n  }\n\n  return target;\n}\n//# sourceMappingURL=array-utils.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/utils/array-utils.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/utils/assert.js":
/*!*************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/utils/assert.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ assert)\n/* harmony export */ });\nfunction assert(condition, message) {\n  if (!condition) {\n    throw new Error(message || 'deck.gl: assertion failed.');\n  }\n}\n//# sourceMappingURL=assert.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/utils/assert.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/utils/count.js":
/*!************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/utils/count.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   count: () => (/* binding */ count)\n/* harmony export */ });\nconst ERR_NOT_OBJECT = 'count(): argument not an object';\nconst ERR_NOT_CONTAINER = 'count(): argument not a container';\nfunction count(container) {\n  if (!isObject(container)) {\n    throw new Error(ERR_NOT_OBJECT);\n  }\n\n  if (typeof container.count === 'function') {\n    return container.count();\n  }\n\n  if (Number.isFinite(container.size)) {\n    return container.size;\n  }\n\n  if (Number.isFinite(container.length)) {\n    return container.length;\n  }\n\n  if (isPlainObject(container)) {\n    return Object.keys(container).length;\n  }\n\n  throw new Error(ERR_NOT_CONTAINER);\n}\n\nfunction isPlainObject(value) {\n  return value !== null && typeof value === 'object' && value.constructor === Object;\n}\n\nfunction isObject(value) {\n  return value !== null && typeof value === 'object';\n}\n//# sourceMappingURL=count.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/utils/count.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/utils/deep-equal.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/utils/deep-equal.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   deepEqual: () => (/* binding */ deepEqual)\n/* harmony export */ });\nfunction deepEqual(a, b, depth) {\n  if (a === b) {\n    return true;\n  }\n\n  if (!depth || !a || !b) {\n    return false;\n  }\n\n  if (Array.isArray(a)) {\n    if (!Array.isArray(b) || a.length !== b.length) {\n      return false;\n    }\n\n    for (let i = 0; i < a.length; i++) {\n      if (!deepEqual(a[i], b[i], depth - 1)) {\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n  if (Array.isArray(b)) {\n    return false;\n  }\n\n  if (typeof a === 'object' && typeof b === 'object') {\n    const aKeys = Object.keys(a);\n    const bKeys = Object.keys(b);\n\n    if (aKeys.length !== bKeys.length) {\n      return false;\n    }\n\n    for (const key of aKeys) {\n      if (!b.hasOwnProperty(key)) {\n        return false;\n      }\n\n      if (!deepEqual(a[key], b[key], depth - 1)) {\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n  return false;\n}\n//# sourceMappingURL=deep-equal.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/utils/deep-equal.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/utils/flatten.js":
/*!**************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/utils/flatten.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   fillArray: () => (/* binding */ fillArray),\n/* harmony export */   flatten: () => (/* binding */ flatten)\n/* harmony export */ });\nfunction flatten(array, filter = () => true) {\n  if (!Array.isArray(array)) {\n    return filter(array) ? [array] : [];\n  }\n\n  return flattenArray(array, filter, []);\n}\n\nfunction flattenArray(array, filter, result) {\n  let index = -1;\n\n  while (++index < array.length) {\n    const value = array[index];\n\n    if (Array.isArray(value)) {\n      flattenArray(value, filter, result);\n    } else if (filter(value)) {\n      result.push(value);\n    }\n  }\n\n  return result;\n}\n\nfunction fillArray({\n  target,\n  source,\n  start = 0,\n  count = 1\n}) {\n  const length = source.length;\n  const total = count * length;\n  let copied = 0;\n\n  for (let i = start; copied < length; copied++) {\n    target[i++] = source[copied];\n  }\n\n  while (copied < total) {\n    if (copied < total - copied) {\n      target.copyWithin(start + copied, start, start + copied);\n      copied *= 2;\n    } else {\n      target.copyWithin(start + copied, start, start + total - copied);\n      copied = total;\n    }\n  }\n\n  return target;\n}\n//# sourceMappingURL=flatten.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/utils/flatten.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/utils/iterable-utils.js":
/*!*********************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/utils/iterable-utils.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   createIterable: () => (/* binding */ createIterable),\n/* harmony export */   getAccessorFromBuffer: () => (/* binding */ getAccessorFromBuffer),\n/* harmony export */   isAsyncIterable: () => (/* binding */ isAsyncIterable)\n/* harmony export */ });\nconst EMPTY_ARRAY = [];\nconst placeholderArray = [];\nfunction createIterable(data, startRow = 0, endRow = Infinity) {\n  let iterable = EMPTY_ARRAY;\n  const objectInfo = {\n    index: -1,\n    data,\n    target: []\n  };\n\n  if (!data) {\n    iterable = EMPTY_ARRAY;\n  } else if (typeof data[Symbol.iterator] === 'function') {\n    iterable = data;\n  } else if (data.length > 0) {\n    placeholderArray.length = data.length;\n    iterable = placeholderArray;\n  }\n\n  if (startRow > 0 || Number.isFinite(endRow)) {\n    iterable = (Array.isArray(iterable) ? iterable : Array.from(iterable)).slice(startRow, endRow);\n    objectInfo.index = startRow - 1;\n  }\n\n  return {\n    iterable,\n    objectInfo\n  };\n}\nfunction isAsyncIterable(data) {\n  return data && data[Symbol.asyncIterator];\n}\nfunction getAccessorFromBuffer(typedArray, options) {\n  const {\n    size,\n    stride,\n    offset,\n    startIndices,\n    nested\n  } = options;\n  const bytesPerElement = typedArray.BYTES_PER_ELEMENT;\n  const elementStride = stride ? stride / bytesPerElement : size;\n  const elementOffset = offset ? offset / bytesPerElement : 0;\n  const vertexCount = Math.floor((typedArray.length - elementOffset) / elementStride);\n  return (_, {\n    index,\n    target\n  }) => {\n    if (!startIndices) {\n      const sourceIndex = index * elementStride + elementOffset;\n\n      for (let j = 0; j < size; j++) {\n        target[j] = typedArray[sourceIndex + j];\n      }\n\n      return target;\n    }\n\n    const startIndex = startIndices[index];\n    const endIndex = startIndices[index + 1] || vertexCount;\n    let result;\n\n    if (nested) {\n      result = new Array(endIndex - startIndex);\n\n      for (let i = startIndex; i < endIndex; i++) {\n        const sourceIndex = i * elementStride + elementOffset;\n        target = new Array(size);\n\n        for (let j = 0; j < size; j++) {\n          target[j] = typedArray[sourceIndex + j];\n        }\n\n        result[i - startIndex] = target;\n      }\n    } else if (elementStride === size) {\n      result = typedArray.subarray(startIndex * size + elementOffset, endIndex * size + elementOffset);\n    } else {\n      result = new typedArray.constructor((endIndex - startIndex) * size);\n      let targetIndex = 0;\n\n      for (let i = startIndex; i < endIndex; i++) {\n        const sourceIndex = i * elementStride + elementOffset;\n\n        for (let j = 0; j < size; j++) {\n          result[targetIndex++] = typedArray[sourceIndex + j];\n        }\n      }\n    }\n\n    return result;\n  };\n}\n//# sourceMappingURL=iterable-utils.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/utils/iterable-utils.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/utils/json-loader.js":
/*!******************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/utils/json-loader.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nfunction isJSON(text) {\n  const firstChar = text[0];\n  const lastChar = text[text.length - 1];\n  return firstChar === '{' && lastChar === '}' || firstChar === '[' && lastChar === ']';\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ({\n  id: 'JSON',\n  name: 'JSON',\n  module: '',\n  version: '',\n  options: {},\n  extensions: ['json', 'geojson'],\n  mimeTypes: ['application/json', 'application/geo+json'],\n  testText: isJSON,\n  parseTextSync: JSON.parse\n});\n//# sourceMappingURL=json-loader.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/utils/json-loader.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/utils/log.js":
/*!**********************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/utils/log.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _probe_gl_log__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @probe.gl/log */ \"./node_modules/@probe.gl/log/dist/esm/log.js\");\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (new _probe_gl_log__WEBPACK_IMPORTED_MODULE_0__.Log({\n  id: 'deck'\n}));\n//# sourceMappingURL=log.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/utils/log.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/utils/math-utils.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/utils/math-utils.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   createMat4: () => (/* binding */ createMat4),\n/* harmony export */   fp64LowPart: () => (/* binding */ fp64LowPart),\n/* harmony export */   getCameraPosition: () => (/* binding */ getCameraPosition),\n/* harmony export */   getFrustumPlanes: () => (/* binding */ getFrustumPlanes),\n/* harmony export */   mergeBounds: () => (/* binding */ mergeBounds),\n/* harmony export */   mod: () => (/* binding */ mod),\n/* harmony export */   toDoublePrecisionArray: () => (/* binding */ toDoublePrecisionArray)\n/* harmony export */ });\n/* harmony import */ var _typed_array_manager__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./typed-array-manager */ \"./node_modules/@deck.gl/core/dist/esm/utils/typed-array-manager.js\");\n/* harmony import */ var _math_gl_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @math.gl/core */ \"./node_modules/@math.gl/core/dist/esm/classes/vector3.js\");\n\n\nfunction createMat4() {\n  return [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1];\n}\nfunction mod(value, divisor) {\n  const modulus = value % divisor;\n  return modulus < 0 ? divisor + modulus : modulus;\n}\nfunction getCameraPosition(viewMatrixInverse) {\n  return [viewMatrixInverse[12], viewMatrixInverse[13], viewMatrixInverse[14]];\n}\nfunction getFrustumPlanes(viewProjectionMatrix) {\n  return {\n    left: getFrustumPlane(viewProjectionMatrix[3] + viewProjectionMatrix[0], viewProjectionMatrix[7] + viewProjectionMatrix[4], viewProjectionMatrix[11] + viewProjectionMatrix[8], viewProjectionMatrix[15] + viewProjectionMatrix[12]),\n    right: getFrustumPlane(viewProjectionMatrix[3] - viewProjectionMatrix[0], viewProjectionMatrix[7] - viewProjectionMatrix[4], viewProjectionMatrix[11] - viewProjectionMatrix[8], viewProjectionMatrix[15] - viewProjectionMatrix[12]),\n    bottom: getFrustumPlane(viewProjectionMatrix[3] + viewProjectionMatrix[1], viewProjectionMatrix[7] + viewProjectionMatrix[5], viewProjectionMatrix[11] + viewProjectionMatrix[9], viewProjectionMatrix[15] + viewProjectionMatrix[13]),\n    top: getFrustumPlane(viewProjectionMatrix[3] - viewProjectionMatrix[1], viewProjectionMatrix[7] - viewProjectionMatrix[5], viewProjectionMatrix[11] - viewProjectionMatrix[9], viewProjectionMatrix[15] - viewProjectionMatrix[13]),\n    near: getFrustumPlane(viewProjectionMatrix[3] + viewProjectionMatrix[2], viewProjectionMatrix[7] + viewProjectionMatrix[6], viewProjectionMatrix[11] + viewProjectionMatrix[10], viewProjectionMatrix[15] + viewProjectionMatrix[14]),\n    far: getFrustumPlane(viewProjectionMatrix[3] - viewProjectionMatrix[2], viewProjectionMatrix[7] - viewProjectionMatrix[6], viewProjectionMatrix[11] - viewProjectionMatrix[10], viewProjectionMatrix[15] - viewProjectionMatrix[14])\n  };\n}\nconst scratchVector = new _math_gl_core__WEBPACK_IMPORTED_MODULE_0__[\"default\"]();\n\nfunction getFrustumPlane(a, b, c, d) {\n  scratchVector.set(a, b, c);\n  const L = scratchVector.len();\n  return {\n    distance: d / L,\n    normal: new _math_gl_core__WEBPACK_IMPORTED_MODULE_0__[\"default\"](-a / L, -b / L, -c / L)\n  };\n}\n\nfunction fp64LowPart(x) {\n  return x - Math.fround(x);\n}\nlet scratchArray;\nfunction toDoublePrecisionArray(typedArray, options) {\n  const {\n    size = 1,\n    startIndex = 0\n  } = options;\n  const endIndex = options.endIndex !== undefined ? options.endIndex : typedArray.length;\n  const count = (endIndex - startIndex) / size;\n  scratchArray = _typed_array_manager__WEBPACK_IMPORTED_MODULE_1__[\"default\"].allocate(scratchArray, count, {\n    type: Float32Array,\n    size: size * 2\n  });\n  let sourceIndex = startIndex;\n  let targetIndex = 0;\n\n  while (sourceIndex < endIndex) {\n    for (let j = 0; j < size; j++) {\n      const value = typedArray[sourceIndex++];\n      scratchArray[targetIndex + j] = value;\n      scratchArray[targetIndex + j + size] = fp64LowPart(value);\n    }\n\n    targetIndex += size * 2;\n  }\n\n  return scratchArray.subarray(0, count * size * 2);\n}\nfunction mergeBounds(boundsList) {\n  let mergedBounds = null;\n  let isMerged = false;\n\n  for (const bounds of boundsList) {\n    if (!bounds) continue;\n\n    if (!mergedBounds) {\n      mergedBounds = bounds;\n    } else {\n      if (!isMerged) {\n        mergedBounds = [[mergedBounds[0][0], mergedBounds[0][1]], [mergedBounds[1][0], mergedBounds[1][1]]];\n        isMerged = true;\n      }\n\n      mergedBounds[0][0] = Math.min(mergedBounds[0][0], bounds[0][0]);\n      mergedBounds[0][1] = Math.min(mergedBounds[0][1], bounds[0][1]);\n      mergedBounds[1][0] = Math.max(mergedBounds[1][0], bounds[1][0]);\n      mergedBounds[1][1] = Math.max(mergedBounds[1][1], bounds[1][1]);\n    }\n  }\n\n  return mergedBounds;\n}\n//# sourceMappingURL=math-utils.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/utils/math-utils.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/utils/memoize.js":
/*!**************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/utils/memoize.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ memoize)\n/* harmony export */ });\nfunction isEqual(a, b) {\n  if (a === b) {\n    return true;\n  }\n\n  if (Array.isArray(a)) {\n    const len = a.length;\n\n    if (!b || b.length !== len) {\n      return false;\n    }\n\n    for (let i = 0; i < len; i++) {\n      if (a[i] !== b[i]) {\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n  return false;\n}\n\nfunction memoize(compute) {\n  let cachedArgs = {};\n  let cachedResult;\n  return args => {\n    for (const key in args) {\n      if (!isEqual(args[key], cachedArgs[key])) {\n        cachedResult = compute(args);\n        cachedArgs = args;\n        break;\n      }\n    }\n\n    return cachedResult;\n  };\n}\n//# sourceMappingURL=memoize.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/utils/memoize.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/utils/positions.js":
/*!****************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/utils/positions.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getPosition: () => (/* binding */ getPosition),\n/* harmony export */   parsePosition: () => (/* binding */ parsePosition)\n/* harmony export */ });\nconst PERCENT_OR_PIXELS_REGEX = /([0-9]+\\.?[0-9]*)(%|px)/;\nfunction parsePosition(value) {\n  switch (typeof value) {\n    case 'number':\n      return {\n        position: value,\n        relative: false\n      };\n\n    case 'string':\n      const match = PERCENT_OR_PIXELS_REGEX.exec(value);\n\n      if (match && match.length >= 3) {\n        const relative = match[2] === '%';\n        const position = parseFloat(match[1]);\n        return {\n          position: relative ? position / 100 : position,\n          relative\n        };\n      }\n\n    default:\n      throw new Error(\"Could not parse position string \".concat(value));\n  }\n}\nfunction getPosition(position, extent) {\n  return position.relative ? Math.round(position.position * extent) : position.position;\n}\n//# sourceMappingURL=positions.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/utils/positions.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/utils/range.js":
/*!************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/utils/range.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   EMPTY: () => (/* binding */ EMPTY),\n/* harmony export */   FULL: () => (/* binding */ FULL),\n/* harmony export */   add: () => (/* binding */ add)\n/* harmony export */ });\nconst EMPTY = [];\nconst FULL = [[0, Infinity]];\nfunction add(rangeList, range) {\n  if (rangeList === FULL) {\n    return rangeList;\n  }\n\n  if (range[0] < 0) {\n    range[0] = 0;\n  }\n\n  if (range[0] >= range[1]) {\n    return rangeList;\n  }\n\n  const newRangeList = [];\n  const len = rangeList.length;\n  let insertPosition = 0;\n\n  for (let i = 0; i < len; i++) {\n    const range0 = rangeList[i];\n\n    if (range0[1] < range[0]) {\n      newRangeList.push(range0);\n      insertPosition = i + 1;\n    } else if (range0[0] > range[1]) {\n      newRangeList.push(range0);\n    } else {\n      range = [Math.min(range0[0], range[0]), Math.max(range0[1], range[1])];\n    }\n  }\n\n  newRangeList.splice(insertPosition, 0, range);\n  return newRangeList;\n}\n//# sourceMappingURL=range.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/utils/range.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/utils/shader.js":
/*!*************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/utils/shader.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   mergeShaders: () => (/* binding */ mergeShaders)\n/* harmony export */ });\nfunction mergeShaders(target, source) {\n  if (!source) {\n    return target;\n  }\n\n  const result = { ...target,\n    ...source\n  };\n\n  if ('defines' in source) {\n    result.defines = { ...target.defines,\n      ...source.defines\n    };\n  }\n\n  if ('modules' in source) {\n    result.modules = (target.modules || []).concat(source.modules);\n\n    if (source.modules.some(module => module.name === 'project64')) {\n      const index = result.modules.findIndex(module => module.name === 'project32');\n\n      if (index >= 0) {\n        result.modules.splice(index, 1);\n      }\n    }\n  }\n\n  if ('inject' in source) {\n    if (!target.inject) {\n      result.inject = source.inject;\n    } else {\n      const mergedInjection = { ...target.inject\n      };\n\n      for (const key in source.inject) {\n        mergedInjection[key] = (mergedInjection[key] || '') + source.inject[key];\n      }\n\n      result.inject = mergedInjection;\n    }\n  }\n\n  return result;\n}\n//# sourceMappingURL=shader.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/utils/shader.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/utils/texture.js":
/*!**************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/utils/texture.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   createTexture: () => (/* binding */ createTexture),\n/* harmony export */   destroyTexture: () => (/* binding */ destroyTexture)\n/* harmony export */ });\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/texture-2d.js\");\n\nconst DEFAULT_TEXTURE_PARAMETERS = {\n  [10241]: 9987,\n  [10240]: 9729,\n  [10242]: 33071,\n  [10243]: 33071\n};\nconst internalTextures = {};\nfunction createTexture(owner, gl, image, parameters) {\n  if (image instanceof _luma_gl_core__WEBPACK_IMPORTED_MODULE_0__[\"default\"]) {\n    return image;\n  } else if (image.constructor && image.constructor.name !== 'Object') {\n    image = {\n      data: image\n    };\n  }\n\n  let specialTextureParameters = null;\n\n  if (image.compressed) {\n    specialTextureParameters = {\n      [10241]: image.data.length > 1 ? 9985 : 9729\n    };\n  }\n\n  const texture = new _luma_gl_core__WEBPACK_IMPORTED_MODULE_0__[\"default\"](gl, { ...image,\n    parameters: { ...DEFAULT_TEXTURE_PARAMETERS,\n      ...specialTextureParameters,\n      ...parameters\n    }\n  });\n  internalTextures[texture.id] = owner;\n  return texture;\n}\nfunction destroyTexture(owner, texture) {\n  if (!texture || !(texture instanceof _luma_gl_core__WEBPACK_IMPORTED_MODULE_0__[\"default\"])) {\n    return;\n  }\n\n  if (internalTextures[texture.id] === owner) {\n    texture.delete();\n    delete internalTextures[texture.id];\n  }\n}\n//# sourceMappingURL=texture.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/utils/texture.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/utils/typed-array-manager.js":
/*!**************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/utils/typed-array-manager.js ***!
  \**************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   TypedArrayManager: () => (/* binding */ TypedArrayManager),\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n\nclass TypedArrayManager {\n  constructor(options = {}) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_pool\", []);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"opts\", {\n      overAlloc: 2,\n      poolSize: 100\n    });\n\n    this.setOptions(options);\n  }\n\n  setOptions(options) {\n    Object.assign(this.opts, options);\n  }\n\n  allocate(typedArray, count, {\n    size = 1,\n    type,\n    padding = 0,\n    copy = false,\n    initialize = false,\n    maxCount\n  }) {\n    const Type = type || typedArray && typedArray.constructor || Float32Array;\n    const newSize = count * size + padding;\n\n    if (ArrayBuffer.isView(typedArray)) {\n      if (newSize <= typedArray.length) {\n        return typedArray;\n      }\n\n      if (newSize * typedArray.BYTES_PER_ELEMENT <= typedArray.buffer.byteLength) {\n        return new Type(typedArray.buffer, 0, newSize);\n      }\n    }\n\n    let maxSize = Infinity;\n\n    if (maxCount) {\n      maxSize = maxCount * size + padding;\n    }\n\n    const newArray = this._allocate(Type, newSize, initialize, maxSize);\n\n    if (typedArray && copy) {\n      newArray.set(typedArray);\n    } else if (!initialize) {\n      newArray.fill(0, 0, 4);\n    }\n\n    this._release(typedArray);\n\n    return newArray;\n  }\n\n  release(typedArray) {\n    this._release(typedArray);\n  }\n\n  _allocate(Type, size, initialize, maxSize) {\n    let sizeToAllocate = Math.max(Math.ceil(size * this.opts.overAlloc), 1);\n\n    if (sizeToAllocate > maxSize) {\n      sizeToAllocate = maxSize;\n    }\n\n    const pool = this._pool;\n    const byteLength = Type.BYTES_PER_ELEMENT * sizeToAllocate;\n    const i = pool.findIndex(b => b.byteLength >= byteLength);\n\n    if (i >= 0) {\n      const array = new Type(pool.splice(i, 1)[0], 0, sizeToAllocate);\n\n      if (initialize) {\n        array.fill(0);\n      }\n\n      return array;\n    }\n\n    return new Type(sizeToAllocate);\n  }\n\n  _release(typedArray) {\n    if (!ArrayBuffer.isView(typedArray)) {\n      return;\n    }\n\n    const pool = this._pool;\n    const {\n      buffer\n    } = typedArray;\n    const {\n      byteLength\n    } = buffer;\n    const i = pool.findIndex(b => b.byteLength >= byteLength);\n\n    if (i < 0) {\n      pool.push(buffer);\n    } else if (i > 0 || pool.length < this.opts.poolSize) {\n      pool.splice(i, 0, buffer);\n    }\n\n    if (pool.length > this.opts.poolSize) {\n      pool.shift();\n    }\n  }\n\n}\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (new TypedArrayManager());\n//# sourceMappingURL=typed-array-manager.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/utils/typed-array-manager.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/viewports/viewport.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/viewports/viewport.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Viewport)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _utils_log__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../utils/log */ \"./node_modules/@deck.gl/core/dist/esm/utils/log.js\");\n/* harmony import */ var _utils_math_utils__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/math-utils */ \"./node_modules/@deck.gl/core/dist/esm/utils/math-utils.js\");\n/* harmony import */ var _math_gl_core__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! @math.gl/core */ \"./node_modules/@math.gl/core/dist/esm/classes/matrix4.js\");\n/* harmony import */ var _math_gl_core__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! @math.gl/core */ \"./node_modules/@math.gl/core/dist/esm/lib/common.js\");\n/* harmony import */ var _math_gl_core__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! @math.gl/core */ \"./node_modules/@math.gl/core/dist/esm/classes/vector3.js\");\n/* harmony import */ var gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! gl-matrix/mat4 */ \"./node_modules/gl-matrix/esm/mat4.js\");\n/* harmony import */ var _math_gl_web_mercator__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @math.gl/web-mercator */ \"./node_modules/@math.gl/web-mercator/dist/esm/index.js\");\n/* harmony import */ var _lib_constants__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../lib/constants */ \"./node_modules/@deck.gl/core/dist/esm/lib/constants.js\");\n\n\n\n\n\n\n\nconst DEGREES_TO_RADIANS = Math.PI / 180;\nconst IDENTITY = (0,_utils_math_utils__WEBPACK_IMPORTED_MODULE_2__.createMat4)();\nconst ZERO_VECTOR = [0, 0, 0];\nconst DEFAULT_DISTANCE_SCALES = {\n  unitsPerMeter: [1, 1, 1],\n  metersPerUnit: [1, 1, 1]\n};\n\nfunction createProjectionMatrix({\n  width,\n  height,\n  orthographic,\n  fovyRadians,\n  focalDistance,\n  padding,\n  near,\n  far\n}) {\n  const aspect = width / height;\n  const matrix = orthographic ? new _math_gl_core__WEBPACK_IMPORTED_MODULE_3__[\"default\"]().orthographic({\n    fovy: fovyRadians,\n    aspect,\n    focalDistance,\n    near,\n    far\n  }) : new _math_gl_core__WEBPACK_IMPORTED_MODULE_3__[\"default\"]().perspective({\n    fovy: fovyRadians,\n    aspect,\n    near,\n    far\n  });\n\n  if (padding) {\n    const {\n      left = 0,\n      right = 0,\n      top = 0,\n      bottom = 0\n    } = padding;\n    const offsetX = (0,_math_gl_core__WEBPACK_IMPORTED_MODULE_4__.clamp)((left + width - right) / 2, 0, width) - width / 2;\n    const offsetY = (0,_math_gl_core__WEBPACK_IMPORTED_MODULE_4__.clamp)((top + height - bottom) / 2, 0, height) - height / 2;\n    matrix[8] -= offsetX * 2 / width;\n    matrix[9] += offsetY * 2 / height;\n  }\n\n  return matrix;\n}\n\nclass Viewport {\n  constructor(opts = {}) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"id\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"x\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"y\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"width\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"height\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"padding\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"isGeospatial\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"zoom\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"focalDistance\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"position\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"modelMatrix\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"distanceScales\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"scale\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"center\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"cameraPosition\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"projectionMatrix\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"viewMatrix\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"viewMatrixUncentered\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"viewMatrixInverse\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"viewProjectionMatrix\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"pixelProjectionMatrix\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"pixelUnprojectionMatrix\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"resolution\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_frustumPlanes\", {});\n\n    this.id = opts.id || this.constructor.displayName || 'viewport';\n    this.x = opts.x || 0;\n    this.y = opts.y || 0;\n    this.width = opts.width || 1;\n    this.height = opts.height || 1;\n    this.zoom = opts.zoom || 0;\n    this.padding = opts.padding;\n    this.distanceScales = opts.distanceScales || DEFAULT_DISTANCE_SCALES;\n    this.focalDistance = opts.focalDistance || 1;\n    this.position = opts.position || ZERO_VECTOR;\n    this.modelMatrix = opts.modelMatrix || null;\n    const {\n      longitude,\n      latitude\n    } = opts;\n    this.isGeospatial = Number.isFinite(latitude) && Number.isFinite(longitude);\n\n    this._initProps(opts);\n\n    this._initMatrices(opts);\n\n    this.equals = this.equals.bind(this);\n    this.project = this.project.bind(this);\n    this.unproject = this.unproject.bind(this);\n    this.projectPosition = this.projectPosition.bind(this);\n    this.unprojectPosition = this.unprojectPosition.bind(this);\n    this.projectFlat = this.projectFlat.bind(this);\n    this.unprojectFlat = this.unprojectFlat.bind(this);\n  }\n\n  get subViewports() {\n    return null;\n  }\n\n  get metersPerPixel() {\n    return this.distanceScales.metersPerUnit[2] / this.scale;\n  }\n\n  get projectionMode() {\n    if (this.isGeospatial) {\n      return this.zoom < 12 ? _lib_constants__WEBPACK_IMPORTED_MODULE_5__.PROJECTION_MODE.WEB_MERCATOR : _lib_constants__WEBPACK_IMPORTED_MODULE_5__.PROJECTION_MODE.WEB_MERCATOR_AUTO_OFFSET;\n    }\n\n    return _lib_constants__WEBPACK_IMPORTED_MODULE_5__.PROJECTION_MODE.IDENTITY;\n  }\n\n  equals(viewport) {\n    if (!(viewport instanceof Viewport)) {\n      return false;\n    }\n\n    if (this === viewport) {\n      return true;\n    }\n\n    return viewport.width === this.width && viewport.height === this.height && viewport.scale === this.scale && (0,_math_gl_core__WEBPACK_IMPORTED_MODULE_4__.equals)(viewport.projectionMatrix, this.projectionMatrix) && (0,_math_gl_core__WEBPACK_IMPORTED_MODULE_4__.equals)(viewport.viewMatrix, this.viewMatrix);\n  }\n\n  project(xyz, {\n    topLeft = true\n  } = {}) {\n    const worldPosition = this.projectPosition(xyz);\n    const coord = (0,_math_gl_web_mercator__WEBPACK_IMPORTED_MODULE_1__.worldToPixels)(worldPosition, this.pixelProjectionMatrix);\n    const [x, y] = coord;\n    const y2 = topLeft ? y : this.height - y;\n    return xyz.length === 2 ? [x, y2] : [x, y2, coord[2]];\n  }\n\n  unproject(xyz, {\n    topLeft = true,\n    targetZ\n  } = {}) {\n    const [x, y, z] = xyz;\n    const y2 = topLeft ? y : this.height - y;\n    const targetZWorld = targetZ && targetZ * this.distanceScales.unitsPerMeter[2];\n    const coord = (0,_math_gl_web_mercator__WEBPACK_IMPORTED_MODULE_1__.pixelsToWorld)([x, y2, z], this.pixelUnprojectionMatrix, targetZWorld);\n    const [X, Y, Z] = this.unprojectPosition(coord);\n\n    if (Number.isFinite(z)) {\n      return [X, Y, Z];\n    }\n\n    return Number.isFinite(targetZ) ? [X, Y, targetZ] : [X, Y];\n  }\n\n  projectPosition(xyz) {\n    const [X, Y] = this.projectFlat(xyz);\n    const Z = (xyz[2] || 0) * this.distanceScales.unitsPerMeter[2];\n    return [X, Y, Z];\n  }\n\n  unprojectPosition(xyz) {\n    const [X, Y] = this.unprojectFlat(xyz);\n    const Z = (xyz[2] || 0) * this.distanceScales.metersPerUnit[2];\n    return [X, Y, Z];\n  }\n\n  projectFlat(xyz) {\n    if (this.isGeospatial) {\n      const result = (0,_math_gl_web_mercator__WEBPACK_IMPORTED_MODULE_1__.lngLatToWorld)(xyz);\n      result[1] = (0,_math_gl_core__WEBPACK_IMPORTED_MODULE_4__.clamp)(result[1], -318, 830);\n      return result;\n    }\n\n    return xyz;\n  }\n\n  unprojectFlat(xyz) {\n    if (this.isGeospatial) {\n      return (0,_math_gl_web_mercator__WEBPACK_IMPORTED_MODULE_1__.worldToLngLat)(xyz);\n    }\n\n    return xyz;\n  }\n\n  getBounds(options = {}) {\n    const unprojectOption = {\n      targetZ: options.z || 0\n    };\n    const topLeft = this.unproject([0, 0], unprojectOption);\n    const topRight = this.unproject([this.width, 0], unprojectOption);\n    const bottomLeft = this.unproject([0, this.height], unprojectOption);\n    const bottomRight = this.unproject([this.width, this.height], unprojectOption);\n    return [Math.min(topLeft[0], topRight[0], bottomLeft[0], bottomRight[0]), Math.min(topLeft[1], topRight[1], bottomLeft[1], bottomRight[1]), Math.max(topLeft[0], topRight[0], bottomLeft[0], bottomRight[0]), Math.max(topLeft[1], topRight[1], bottomLeft[1], bottomRight[1])];\n  }\n\n  getDistanceScales(coordinateOrigin) {\n    if (coordinateOrigin) {\n      return (0,_math_gl_web_mercator__WEBPACK_IMPORTED_MODULE_1__.getDistanceScales)({\n        longitude: coordinateOrigin[0],\n        latitude: coordinateOrigin[1],\n        highPrecision: true\n      });\n    }\n\n    return this.distanceScales;\n  }\n\n  containsPixel({\n    x,\n    y,\n    width = 1,\n    height = 1\n  }) {\n    return x < this.x + this.width && this.x < x + width && y < this.y + this.height && this.y < y + height;\n  }\n\n  getFrustumPlanes() {\n    if (this._frustumPlanes.near) {\n      return this._frustumPlanes;\n    }\n\n    Object.assign(this._frustumPlanes, (0,_utils_math_utils__WEBPACK_IMPORTED_MODULE_2__.getFrustumPlanes)(this.viewProjectionMatrix));\n    return this._frustumPlanes;\n  }\n\n  panByPosition(coords, pixel) {\n    return null;\n  }\n\n  _initProps(opts) {\n    const longitude = opts.longitude;\n    const latitude = opts.latitude;\n\n    if (this.isGeospatial) {\n      if (!Number.isFinite(opts.zoom)) {\n        this.zoom = (0,_math_gl_web_mercator__WEBPACK_IMPORTED_MODULE_1__.getMeterZoom)({\n          latitude\n        }) + Math.log2(this.focalDistance);\n      }\n\n      this.distanceScales = opts.distanceScales || (0,_math_gl_web_mercator__WEBPACK_IMPORTED_MODULE_1__.getDistanceScales)({\n        latitude,\n        longitude\n      });\n    }\n\n    const scale = Math.pow(2, this.zoom);\n    this.scale = scale;\n    const {\n      position,\n      modelMatrix\n    } = opts;\n    let meterOffset = ZERO_VECTOR;\n\n    if (position) {\n      meterOffset = modelMatrix ? new _math_gl_core__WEBPACK_IMPORTED_MODULE_3__[\"default\"](modelMatrix).transformAsVector(position, []) : position;\n    }\n\n    if (this.isGeospatial) {\n      const center = this.projectPosition([longitude, latitude, 0]);\n      this.center = new _math_gl_core__WEBPACK_IMPORTED_MODULE_6__[\"default\"](meterOffset).scale(this.distanceScales.unitsPerMeter).add(center);\n    } else {\n      this.center = this.projectPosition(meterOffset);\n    }\n  }\n\n  _initMatrices(opts) {\n    const {\n      viewMatrix = IDENTITY,\n      projectionMatrix = null,\n      orthographic = false,\n      fovyRadians,\n      fovy = 75,\n      near = 0.1,\n      far = 1000,\n      padding = null,\n      focalDistance = 1\n    } = opts;\n    this.viewMatrixUncentered = viewMatrix;\n    this.viewMatrix = new _math_gl_core__WEBPACK_IMPORTED_MODULE_3__[\"default\"]().multiplyRight(viewMatrix).translate(new _math_gl_core__WEBPACK_IMPORTED_MODULE_6__[\"default\"](this.center).negate());\n    this.projectionMatrix = projectionMatrix || createProjectionMatrix({\n      width: this.width,\n      height: this.height,\n      orthographic,\n      fovyRadians: fovyRadians || fovy * DEGREES_TO_RADIANS,\n      focalDistance,\n      padding,\n      near,\n      far\n    });\n    const vpm = (0,_utils_math_utils__WEBPACK_IMPORTED_MODULE_2__.createMat4)();\n    gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_7__.multiply(vpm, vpm, this.projectionMatrix);\n    gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_7__.multiply(vpm, vpm, this.viewMatrix);\n    this.viewProjectionMatrix = vpm;\n    this.viewMatrixInverse = gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_7__.invert([], this.viewMatrix) || this.viewMatrix;\n    this.cameraPosition = (0,_utils_math_utils__WEBPACK_IMPORTED_MODULE_2__.getCameraPosition)(this.viewMatrixInverse);\n    const viewportMatrix = (0,_utils_math_utils__WEBPACK_IMPORTED_MODULE_2__.createMat4)();\n    const pixelProjectionMatrix = (0,_utils_math_utils__WEBPACK_IMPORTED_MODULE_2__.createMat4)();\n    gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_7__.scale(viewportMatrix, viewportMatrix, [this.width / 2, -this.height / 2, 1]);\n    gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_7__.translate(viewportMatrix, viewportMatrix, [1, -1, 0]);\n    gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_7__.multiply(pixelProjectionMatrix, viewportMatrix, this.viewProjectionMatrix);\n    this.pixelProjectionMatrix = pixelProjectionMatrix;\n    this.pixelUnprojectionMatrix = gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_7__.invert((0,_utils_math_utils__WEBPACK_IMPORTED_MODULE_2__.createMat4)(), this.pixelProjectionMatrix);\n\n    if (!this.pixelUnprojectionMatrix) {\n      _utils_log__WEBPACK_IMPORTED_MODULE_8__[\"default\"].warn('Pixel project matrix not invertible')();\n    }\n  }\n\n}\n\n(0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(Viewport, \"displayName\", 'Viewport');\n//# sourceMappingURL=viewport.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/viewports/viewport.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/viewports/web-mercator-viewport.js":
/*!********************************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/viewports/web-mercator-viewport.js ***!
  \********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ WebMercatorViewport)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _viewport__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./viewport */ \"./node_modules/@deck.gl/core/dist/esm/viewports/viewport.js\");\n/* harmony import */ var _math_gl_web_mercator__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @math.gl/web-mercator */ \"./node_modules/@math.gl/web-mercator/dist/esm/index.js\");\n/* harmony import */ var gl_matrix_vec2__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! gl-matrix/vec2 */ \"./node_modules/gl-matrix/esm/vec2.js\");\n/* harmony import */ var _math_gl_core__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! @math.gl/core */ \"./node_modules/@math.gl/core/dist/esm/lib/common.js\");\n/* harmony import */ var _math_gl_core__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! @math.gl/core */ \"./node_modules/@math.gl/core/dist/esm/classes/matrix4.js\");\n\n\n\n\n\nclass WebMercatorViewport extends _viewport__WEBPACK_IMPORTED_MODULE_2__[\"default\"] {\n  constructor(opts = {}) {\n    const {\n      latitude = 0,\n      longitude = 0,\n      zoom = 0,\n      pitch = 0,\n      bearing = 0,\n      nearZMultiplier = 0.1,\n      farZMultiplier = 1.01,\n      nearZ,\n      farZ,\n      orthographic = false,\n      projectionMatrix,\n      repeat = false,\n      worldOffset = 0,\n      position,\n      padding,\n      legacyMeterSizes = false\n    } = opts;\n    let {\n      width,\n      height,\n      altitude = 1.5\n    } = opts;\n    const scale = Math.pow(2, zoom);\n    width = width || 1;\n    height = height || 1;\n    let fovy;\n    let projectionParameters = null;\n\n    if (projectionMatrix) {\n      altitude = projectionMatrix[5] / 2;\n      fovy = (0,_math_gl_web_mercator__WEBPACK_IMPORTED_MODULE_1__.altitudeToFovy)(altitude);\n    } else {\n      if (opts.fovy) {\n        fovy = opts.fovy;\n        altitude = (0,_math_gl_web_mercator__WEBPACK_IMPORTED_MODULE_1__.fovyToAltitude)(fovy);\n      } else {\n        fovy = (0,_math_gl_web_mercator__WEBPACK_IMPORTED_MODULE_1__.altitudeToFovy)(altitude);\n      }\n\n      let offset;\n\n      if (padding) {\n        const {\n          top = 0,\n          bottom = 0\n        } = padding;\n        offset = [0, (0,_math_gl_core__WEBPACK_IMPORTED_MODULE_3__.clamp)((top + height - bottom) / 2, 0, height) - height / 2];\n      }\n\n      projectionParameters = (0,_math_gl_web_mercator__WEBPACK_IMPORTED_MODULE_1__.getProjectionParameters)({\n        width,\n        height,\n        scale,\n        center: position && [0, 0, position[2] * (0,_math_gl_web_mercator__WEBPACK_IMPORTED_MODULE_1__.unitsPerMeter)(latitude)],\n        offset,\n        pitch,\n        fovy,\n        nearZMultiplier,\n        farZMultiplier\n      });\n\n      if (Number.isFinite(nearZ)) {\n        projectionParameters.near = nearZ;\n      }\n\n      if (Number.isFinite(farZ)) {\n        projectionParameters.far = farZ;\n      }\n    }\n\n    let viewMatrixUncentered = (0,_math_gl_web_mercator__WEBPACK_IMPORTED_MODULE_1__.getViewMatrix)({\n      height,\n      pitch,\n      bearing,\n      scale,\n      altitude\n    });\n\n    if (worldOffset) {\n      const viewOffset = new _math_gl_core__WEBPACK_IMPORTED_MODULE_4__[\"default\"]().translate([512 * worldOffset, 0, 0]);\n      viewMatrixUncentered = viewOffset.multiplyLeft(viewMatrixUncentered);\n    }\n\n    super({ ...opts,\n      width,\n      height,\n      viewMatrix: viewMatrixUncentered,\n      longitude,\n      latitude,\n      zoom,\n      ...projectionParameters,\n      fovy,\n      focalDistance: altitude\n    });\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"longitude\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"latitude\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"pitch\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"bearing\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"altitude\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"fovy\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"orthographic\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_subViewports\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_pseudoMeters\", void 0);\n\n    this.latitude = latitude;\n    this.longitude = longitude;\n    this.zoom = zoom;\n    this.pitch = pitch;\n    this.bearing = bearing;\n    this.altitude = altitude;\n    this.fovy = fovy;\n    this.orthographic = orthographic;\n    this._subViewports = repeat ? [] : null;\n    this._pseudoMeters = legacyMeterSizes;\n    Object.freeze(this);\n  }\n\n  get subViewports() {\n    if (this._subViewports && !this._subViewports.length) {\n      const bounds = this.getBounds();\n      const minOffset = Math.floor((bounds[0] + 180) / 360);\n      const maxOffset = Math.ceil((bounds[2] - 180) / 360);\n\n      for (let x = minOffset; x <= maxOffset; x++) {\n        const offsetViewport = x ? new WebMercatorViewport({ ...this,\n          worldOffset: x\n        }) : this;\n\n        this._subViewports.push(offsetViewport);\n      }\n    }\n\n    return this._subViewports;\n  }\n\n  projectPosition(xyz) {\n    if (this._pseudoMeters) {\n      return super.projectPosition(xyz);\n    }\n\n    const [X, Y] = this.projectFlat(xyz);\n    const Z = (xyz[2] || 0) * (0,_math_gl_web_mercator__WEBPACK_IMPORTED_MODULE_1__.unitsPerMeter)(xyz[1]);\n    return [X, Y, Z];\n  }\n\n  unprojectPosition(xyz) {\n    if (this._pseudoMeters) {\n      return super.unprojectPosition(xyz);\n    }\n\n    const [X, Y] = this.unprojectFlat(xyz);\n    const Z = (xyz[2] || 0) / (0,_math_gl_web_mercator__WEBPACK_IMPORTED_MODULE_1__.unitsPerMeter)(Y);\n    return [X, Y, Z];\n  }\n\n  addMetersToLngLat(lngLatZ, xyz) {\n    return (0,_math_gl_web_mercator__WEBPACK_IMPORTED_MODULE_1__.addMetersToLngLat)(lngLatZ, xyz);\n  }\n\n  panByPosition(coords, pixel) {\n    const fromLocation = (0,_math_gl_web_mercator__WEBPACK_IMPORTED_MODULE_1__.pixelsToWorld)(pixel, this.pixelUnprojectionMatrix);\n    const toLocation = this.projectFlat(coords);\n    const translate = gl_matrix_vec2__WEBPACK_IMPORTED_MODULE_5__.add([], toLocation, gl_matrix_vec2__WEBPACK_IMPORTED_MODULE_5__.negate([], fromLocation));\n    const newCenter = gl_matrix_vec2__WEBPACK_IMPORTED_MODULE_5__.add([], this.center, translate);\n    const [longitude, latitude] = this.unprojectFlat(newCenter);\n    return {\n      longitude,\n      latitude\n    };\n  }\n\n  getBounds(options = {}) {\n    const corners = (0,_math_gl_web_mercator__WEBPACK_IMPORTED_MODULE_1__.getBounds)(this, options.z || 0);\n    return [Math.min(corners[0][0], corners[1][0], corners[2][0], corners[3][0]), Math.min(corners[0][1], corners[1][1], corners[2][1], corners[3][1]), Math.max(corners[0][0], corners[1][0], corners[2][0], corners[3][0]), Math.max(corners[0][1], corners[1][1], corners[2][1], corners[3][1])];\n  }\n\n  fitBounds(bounds, options = {}) {\n    const {\n      width,\n      height\n    } = this;\n    const {\n      longitude,\n      latitude,\n      zoom\n    } = (0,_math_gl_web_mercator__WEBPACK_IMPORTED_MODULE_1__.fitBounds)({\n      width,\n      height,\n      bounds,\n      ...options\n    });\n    return new WebMercatorViewport({\n      width,\n      height,\n      longitude,\n      latitude,\n      zoom\n    });\n  }\n\n}\n\n(0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(WebMercatorViewport, \"displayName\", 'WebMercatorViewport');\n//# sourceMappingURL=web-mercator-viewport.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/viewports/web-mercator-viewport.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/views/map-view.js":
/*!***************************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/views/map-view.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ MapView)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _view__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./view */ \"./node_modules/@deck.gl/core/dist/esm/views/view.js\");\n/* harmony import */ var _viewports_web_mercator_viewport__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../viewports/web-mercator-viewport */ \"./node_modules/@deck.gl/core/dist/esm/viewports/web-mercator-viewport.js\");\n/* harmony import */ var _controllers_map_controller__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../controllers/map-controller */ \"./node_modules/@deck.gl/core/dist/esm/controllers/map-controller.js\");\n\n\n\n\nclass MapView extends _view__WEBPACK_IMPORTED_MODULE_1__[\"default\"] {\n  get ViewportType() {\n    return _viewports_web_mercator_viewport__WEBPACK_IMPORTED_MODULE_2__[\"default\"];\n  }\n\n  get ControllerType() {\n    return _controllers_map_controller__WEBPACK_IMPORTED_MODULE_3__[\"default\"];\n  }\n\n}\n\n(0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(MapView, \"displayName\", 'MapView');\n//# sourceMappingURL=map-view.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/views/map-view.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/core/dist/esm/views/view.js":
/*!***********************************************************!*\
  !*** ./node_modules/@deck.gl/core/dist/esm/views/view.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ View)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _viewports_viewport__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../viewports/viewport */ \"./node_modules/@deck.gl/core/dist/esm/viewports/viewport.js\");\n/* harmony import */ var _utils_positions__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/positions */ \"./node_modules/@deck.gl/core/dist/esm/utils/positions.js\");\n/* harmony import */ var _utils_deep_equal__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../utils/deep-equal */ \"./node_modules/@deck.gl/core/dist/esm/utils/deep-equal.js\");\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/assert */ \"./node_modules/@deck.gl/core/dist/esm/utils/assert.js\");\n\n\n\n\n\nclass View {\n  constructor(props) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"id\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"viewportInstance\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_x\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_y\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_width\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_height\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_padding\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"props\", void 0);\n\n    const {\n      id,\n      x = 0,\n      y = 0,\n      width = '100%',\n      height = '100%',\n      padding = null,\n      viewportInstance\n    } = props || {};\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(!viewportInstance || viewportInstance instanceof _viewports_viewport__WEBPACK_IMPORTED_MODULE_2__[\"default\"]);\n    this.viewportInstance = viewportInstance;\n    this.id = id || this.constructor.displayName || 'view';\n    this.props = { ...props,\n      id: this.id\n    };\n    this._x = (0,_utils_positions__WEBPACK_IMPORTED_MODULE_3__.parsePosition)(x);\n    this._y = (0,_utils_positions__WEBPACK_IMPORTED_MODULE_3__.parsePosition)(y);\n    this._width = (0,_utils_positions__WEBPACK_IMPORTED_MODULE_3__.parsePosition)(width);\n    this._height = (0,_utils_positions__WEBPACK_IMPORTED_MODULE_3__.parsePosition)(height);\n    this._padding = padding && {\n      left: (0,_utils_positions__WEBPACK_IMPORTED_MODULE_3__.parsePosition)(padding.left || 0),\n      right: (0,_utils_positions__WEBPACK_IMPORTED_MODULE_3__.parsePosition)(padding.right || 0),\n      top: (0,_utils_positions__WEBPACK_IMPORTED_MODULE_3__.parsePosition)(padding.top || 0),\n      bottom: (0,_utils_positions__WEBPACK_IMPORTED_MODULE_3__.parsePosition)(padding.bottom || 0)\n    };\n    this.equals = this.equals.bind(this);\n    Object.seal(this);\n  }\n\n  equals(view) {\n    if (this === view) {\n      return true;\n    }\n\n    if (this.viewportInstance) {\n      return view.viewportInstance ? this.viewportInstance.equals(view.viewportInstance) : false;\n    }\n\n    return this.ViewportType === view.ViewportType && (0,_utils_deep_equal__WEBPACK_IMPORTED_MODULE_4__.deepEqual)(this.props, view.props, 2);\n  }\n\n  makeViewport({\n    width,\n    height,\n    viewState\n  }) {\n    if (this.viewportInstance) {\n      return this.viewportInstance;\n    }\n\n    viewState = this.filterViewState(viewState);\n    const viewportDimensions = this.getDimensions({\n      width,\n      height\n    });\n\n    if (!viewportDimensions.height || !viewportDimensions.width) {\n      return null;\n    }\n\n    return new this.ViewportType({ ...viewState,\n      ...this.props,\n      ...viewportDimensions\n    });\n  }\n\n  getViewStateId() {\n    const {\n      viewState\n    } = this.props;\n\n    if (typeof viewState === 'string') {\n      return viewState;\n    }\n\n    return (viewState === null || viewState === void 0 ? void 0 : viewState.id) || this.id;\n  }\n\n  filterViewState(viewState) {\n    if (this.props.viewState && typeof this.props.viewState === 'object') {\n      if (!this.props.viewState.id) {\n        return this.props.viewState;\n      }\n\n      const newViewState = { ...viewState\n      };\n\n      for (const key in this.props.viewState) {\n        if (key !== 'id') {\n          newViewState[key] = this.props.viewState[key];\n        }\n      }\n\n      return newViewState;\n    }\n\n    return viewState;\n  }\n\n  getDimensions({\n    width,\n    height\n  }) {\n    const dimensions = {\n      x: (0,_utils_positions__WEBPACK_IMPORTED_MODULE_3__.getPosition)(this._x, width),\n      y: (0,_utils_positions__WEBPACK_IMPORTED_MODULE_3__.getPosition)(this._y, height),\n      width: (0,_utils_positions__WEBPACK_IMPORTED_MODULE_3__.getPosition)(this._width, width),\n      height: (0,_utils_positions__WEBPACK_IMPORTED_MODULE_3__.getPosition)(this._height, height)\n    };\n\n    if (this._padding) {\n      dimensions.padding = {\n        left: (0,_utils_positions__WEBPACK_IMPORTED_MODULE_3__.getPosition)(this._padding.left, width),\n        top: (0,_utils_positions__WEBPACK_IMPORTED_MODULE_3__.getPosition)(this._padding.top, height),\n        right: (0,_utils_positions__WEBPACK_IMPORTED_MODULE_3__.getPosition)(this._padding.right, width),\n        bottom: (0,_utils_positions__WEBPACK_IMPORTED_MODULE_3__.getPosition)(this._padding.bottom, height)\n      };\n    }\n\n    return dimensions;\n  }\n\n  get controller() {\n    const opts = this.props.controller;\n\n    if (!opts) {\n      return null;\n    }\n\n    if (opts === true) {\n      return {\n        type: this.ControllerType\n      };\n    }\n\n    if (typeof opts === 'function') {\n      return {\n        type: opts\n      };\n    }\n\n    return {\n      type: this.ControllerType,\n      ...opts\n    };\n  }\n\n}\n//# sourceMappingURL=view.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/core/dist/esm/views/view.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/layers/dist/esm/scatterplot-layer/scatterplot-layer-fragment.glsl.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/@deck.gl/layers/dist/esm/scatterplot-layer/scatterplot-layer-fragment.glsl.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (\"#define SHADER_NAME scatterplot-layer-fragment-shader\\n\\nprecision highp float;\\n\\nuniform bool filled;\\nuniform float stroked;\\nuniform bool antialiasing;\\n\\nvarying vec4 vFillColor;\\nvarying vec4 vLineColor;\\nvarying vec2 unitPosition;\\nvarying float innerUnitRadius;\\nvarying float outerRadiusPixels;\\n\\nvoid main(void) {\\n  geometry.uv = unitPosition;\\n\\n  float distToCenter = length(unitPosition) * outerRadiusPixels;\\n  float inCircle = antialiasing ? \\n    smoothedge(distToCenter, outerRadiusPixels) : \\n    step(distToCenter, outerRadiusPixels);\\n\\n  if (inCircle == 0.0) {\\n    discard;\\n  }\\n\\n  if (stroked > 0.5) {\\n    float isLine = antialiasing ? \\n      smoothedge(innerUnitRadius * outerRadiusPixels, distToCenter) :\\n      step(innerUnitRadius * outerRadiusPixels, distToCenter);\\n\\n    if (filled) {\\n      gl_FragColor = mix(vFillColor, vLineColor, isLine);\\n    } else {\\n      if (isLine == 0.0) {\\n        discard;\\n      }\\n      gl_FragColor = vec4(vLineColor.rgb, vLineColor.a * isLine);\\n    }\\n  } else if (!filled) {\\n    discard;\\n  } else {\\n    gl_FragColor = vFillColor;\\n  }\\n\\n  gl_FragColor.a *= inCircle;\\n  DECKGL_FILTER_COLOR(gl_FragColor, geometry);\\n}\\n\");\n//# sourceMappingURL=scatterplot-layer-fragment.glsl.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/layers/dist/esm/scatterplot-layer/scatterplot-layer-fragment.glsl.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/layers/dist/esm/scatterplot-layer/scatterplot-layer-vertex.glsl.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/@deck.gl/layers/dist/esm/scatterplot-layer/scatterplot-layer-vertex.glsl.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (\"#define SHADER_NAME scatterplot-layer-vertex-shader\\n\\nattribute vec3 positions;\\n\\nattribute vec3 instancePositions;\\nattribute vec3 instancePositions64Low;\\nattribute float instanceRadius;\\nattribute float instanceLineWidths;\\nattribute vec4 instanceFillColors;\\nattribute vec4 instanceLineColors;\\nattribute vec3 instancePickingColors;\\n\\nuniform float opacity;\\nuniform float radiusScale;\\nuniform float radiusMinPixels;\\nuniform float radiusMaxPixels;\\nuniform float lineWidthScale;\\nuniform float lineWidthMinPixels;\\nuniform float lineWidthMaxPixels;\\nuniform float stroked;\\nuniform bool filled;\\nuniform bool antialiasing;\\nuniform bool billboard;\\nuniform int radiusUnits;\\nuniform int lineWidthUnits;\\n\\nvarying vec4 vFillColor;\\nvarying vec4 vLineColor;\\nvarying vec2 unitPosition;\\nvarying float innerUnitRadius;\\nvarying float outerRadiusPixels;\\n\\n\\nvoid main(void) {\\n  geometry.worldPosition = instancePositions;\\n  outerRadiusPixels = clamp(\\n    project_size_to_pixel(radiusScale * instanceRadius, radiusUnits),\\n    radiusMinPixels, radiusMaxPixels\\n  );\\n  float lineWidthPixels = clamp(\\n    project_size_to_pixel(lineWidthScale * instanceLineWidths, lineWidthUnits),\\n    lineWidthMinPixels, lineWidthMaxPixels\\n  );\\n  outerRadiusPixels += stroked * lineWidthPixels / 2.0;\\n  float edgePadding = antialiasing ? (outerRadiusPixels + SMOOTH_EDGE_RADIUS) / outerRadiusPixels : 1.0;\\n  unitPosition = edgePadding * positions.xy;\\n  geometry.uv = unitPosition;\\n  geometry.pickingColor = instancePickingColors;\\n\\n  innerUnitRadius = 1.0 - stroked * lineWidthPixels / outerRadiusPixels;\\n  \\n  if (billboard) {\\n    gl_Position = project_position_to_clipspace(instancePositions, instancePositions64Low, vec3(0.0), geometry.position);\\n    DECKGL_FILTER_GL_POSITION(gl_Position, geometry);\\n    vec3 offset = edgePadding * positions * outerRadiusPixels;\\n    DECKGL_FILTER_SIZE(offset, geometry);\\n    gl_Position.xy += project_pixel_size_to_clipspace(offset.xy);\\n  } else {\\n    vec3 offset = edgePadding * positions * project_pixel_size(outerRadiusPixels);\\n    DECKGL_FILTER_SIZE(offset, geometry);\\n    gl_Position = project_position_to_clipspace(instancePositions, instancePositions64Low, offset, geometry.position);\\n    DECKGL_FILTER_GL_POSITION(gl_Position, geometry);\\n  }\\n  vFillColor = vec4(instanceFillColors.rgb, instanceFillColors.a * opacity);\\n  DECKGL_FILTER_COLOR(vFillColor, geometry);\\n  vLineColor = vec4(instanceLineColors.rgb, instanceLineColors.a * opacity);\\n  DECKGL_FILTER_COLOR(vLineColor, geometry);\\n}\\n\");\n//# sourceMappingURL=scatterplot-layer-vertex.glsl.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/layers/dist/esm/scatterplot-layer/scatterplot-layer-vertex.glsl.js?");

/***/ }),

/***/ "./node_modules/@deck.gl/layers/dist/esm/scatterplot-layer/scatterplot-layer.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/@deck.gl/layers/dist/esm/scatterplot-layer/scatterplot-layer.js ***!
  \**************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ ScatterplotLayer)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _deck_gl_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @deck.gl/core */ \"./node_modules/@deck.gl/core/dist/esm/lib/layer.js\");\n/* harmony import */ var _deck_gl_core__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! @deck.gl/core */ \"./node_modules/@deck.gl/core/dist/esm/shaderlib/project32/project32.js\");\n/* harmony import */ var _deck_gl_core__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! @deck.gl/core */ \"./node_modules/@deck.gl/core/dist/esm/shaderlib/picking/picking.js\");\n/* harmony import */ var _deck_gl_core__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! @deck.gl/core */ \"./node_modules/@deck.gl/core/dist/esm/lib/constants.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/engine/dist/esm/lib/model.js\");\n/* harmony import */ var _luma_gl_core__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! @luma.gl/core */ \"./node_modules/@luma.gl/engine/dist/esm/geometry/geometry.js\");\n/* harmony import */ var _scatterplot_layer_vertex_glsl__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./scatterplot-layer-vertex.glsl */ \"./node_modules/@deck.gl/layers/dist/esm/scatterplot-layer/scatterplot-layer-vertex.glsl.js\");\n/* harmony import */ var _scatterplot_layer_fragment_glsl__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./scatterplot-layer-fragment.glsl */ \"./node_modules/@deck.gl/layers/dist/esm/scatterplot-layer/scatterplot-layer-fragment.glsl.js\");\n\n\n\n\n\nconst DEFAULT_COLOR = [0, 0, 0, 255];\nconst defaultProps = {\n  radiusUnits: 'meters',\n  radiusScale: {\n    type: 'number',\n    min: 0,\n    value: 1\n  },\n  radiusMinPixels: {\n    type: 'number',\n    min: 0,\n    value: 0\n  },\n  radiusMaxPixels: {\n    type: 'number',\n    min: 0,\n    value: Number.MAX_SAFE_INTEGER\n  },\n  lineWidthUnits: 'meters',\n  lineWidthScale: {\n    type: 'number',\n    min: 0,\n    value: 1\n  },\n  lineWidthMinPixels: {\n    type: 'number',\n    min: 0,\n    value: 0\n  },\n  lineWidthMaxPixels: {\n    type: 'number',\n    min: 0,\n    value: Number.MAX_SAFE_INTEGER\n  },\n  stroked: false,\n  filled: true,\n  billboard: false,\n  antialiasing: true,\n  getPosition: {\n    type: 'accessor',\n    value: x => x.position\n  },\n  getRadius: {\n    type: 'accessor',\n    value: 1\n  },\n  getFillColor: {\n    type: 'accessor',\n    value: DEFAULT_COLOR\n  },\n  getLineColor: {\n    type: 'accessor',\n    value: DEFAULT_COLOR\n  },\n  getLineWidth: {\n    type: 'accessor',\n    value: 1\n  },\n  strokeWidth: {\n    deprecatedFor: 'getLineWidth'\n  },\n  outline: {\n    deprecatedFor: 'stroked'\n  },\n  getColor: {\n    deprecatedFor: ['getFillColor', 'getLineColor']\n  }\n};\nclass ScatterplotLayer extends _deck_gl_core__WEBPACK_IMPORTED_MODULE_1__[\"default\"] {\n  getShaders() {\n    return super.getShaders({\n      vs: _scatterplot_layer_vertex_glsl__WEBPACK_IMPORTED_MODULE_2__[\"default\"],\n      fs: _scatterplot_layer_fragment_glsl__WEBPACK_IMPORTED_MODULE_3__[\"default\"],\n      modules: [_deck_gl_core__WEBPACK_IMPORTED_MODULE_4__[\"default\"], _deck_gl_core__WEBPACK_IMPORTED_MODULE_5__[\"default\"]]\n    });\n  }\n\n  initializeState() {\n    this.getAttributeManager().addInstanced({\n      instancePositions: {\n        size: 3,\n        type: 5130,\n        fp64: this.use64bitPositions(),\n        transition: true,\n        accessor: 'getPosition'\n      },\n      instanceRadius: {\n        size: 1,\n        transition: true,\n        accessor: 'getRadius',\n        defaultValue: 1\n      },\n      instanceFillColors: {\n        size: this.props.colorFormat.length,\n        transition: true,\n        normalized: true,\n        type: 5121,\n        accessor: 'getFillColor',\n        defaultValue: [0, 0, 0, 255]\n      },\n      instanceLineColors: {\n        size: this.props.colorFormat.length,\n        transition: true,\n        normalized: true,\n        type: 5121,\n        accessor: 'getLineColor',\n        defaultValue: [0, 0, 0, 255]\n      },\n      instanceLineWidths: {\n        size: 1,\n        transition: true,\n        accessor: 'getLineWidth',\n        defaultValue: 1\n      }\n    });\n  }\n\n  updateState(params) {\n    super.updateState(params);\n\n    if (params.changeFlags.extensionsChanged) {\n      var _this$state$model;\n\n      const {\n        gl\n      } = this.context;\n      (_this$state$model = this.state.model) === null || _this$state$model === void 0 ? void 0 : _this$state$model.delete();\n      this.state.model = this._getModel(gl);\n      this.getAttributeManager().invalidateAll();\n    }\n  }\n\n  draw({\n    uniforms\n  }) {\n    const {\n      radiusUnits,\n      radiusScale,\n      radiusMinPixels,\n      radiusMaxPixels,\n      stroked,\n      filled,\n      billboard,\n      antialiasing,\n      lineWidthUnits,\n      lineWidthScale,\n      lineWidthMinPixels,\n      lineWidthMaxPixels\n    } = this.props;\n    this.state.model.setUniforms(uniforms).setUniforms({\n      stroked: stroked ? 1 : 0,\n      filled,\n      billboard,\n      antialiasing,\n      radiusUnits: _deck_gl_core__WEBPACK_IMPORTED_MODULE_6__.UNIT[radiusUnits],\n      radiusScale,\n      radiusMinPixels,\n      radiusMaxPixels,\n      lineWidthUnits: _deck_gl_core__WEBPACK_IMPORTED_MODULE_6__.UNIT[lineWidthUnits],\n      lineWidthScale,\n      lineWidthMinPixels,\n      lineWidthMaxPixels\n    }).draw();\n  }\n\n  _getModel(gl) {\n    const positions = [-1, -1, 0, 1, -1, 0, 1, 1, 0, -1, 1, 0];\n    return new _luma_gl_core__WEBPACK_IMPORTED_MODULE_7__[\"default\"](gl, { ...this.getShaders(),\n      id: this.props.id,\n      geometry: new _luma_gl_core__WEBPACK_IMPORTED_MODULE_8__[\"default\"]({\n        drawMode: 6,\n        vertexCount: 4,\n        attributes: {\n          positions: {\n            size: 3,\n            value: new Float32Array(positions)\n          }\n        }\n      }),\n      isInstanced: true\n    });\n  }\n\n}\n\n(0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(ScatterplotLayer, \"defaultProps\", defaultProps);\n\n(0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(ScatterplotLayer, \"layerName\", 'ScatterplotLayer');\n//# sourceMappingURL=scatterplot-layer.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@deck.gl/layers/dist/esm/scatterplot-layer/scatterplot-layer.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/core/dist/esm/iterators/make-iterator/make-array-buffer-iterator.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/@loaders.gl/core/dist/esm/iterators/make-iterator/make-array-buffer-iterator.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   makeArrayBufferIterator: () => (/* binding */ makeArrayBufferIterator)\n/* harmony export */ });\nconst DEFAULT_CHUNK_SIZE = 256 * 1024;\nfunction makeArrayBufferIterator(arrayBuffer) {\n  let options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  return function* () {\n    const {\n      chunkSize = DEFAULT_CHUNK_SIZE\n    } = options;\n    let byteOffset = 0;\n    while (byteOffset < arrayBuffer.byteLength) {\n      const chunkByteLength = Math.min(arrayBuffer.byteLength - byteOffset, chunkSize);\n      const chunk = new ArrayBuffer(chunkByteLength);\n      const sourceArray = new Uint8Array(arrayBuffer, byteOffset, chunkByteLength);\n      const chunkArray = new Uint8Array(chunk);\n      chunkArray.set(sourceArray);\n      byteOffset += chunkByteLength;\n      yield chunk;\n    }\n  }();\n}\n//# sourceMappingURL=make-array-buffer-iterator.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/core/dist/esm/iterators/make-iterator/make-array-buffer-iterator.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/core/dist/esm/iterators/make-iterator/make-blob-iterator.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/@loaders.gl/core/dist/esm/iterators/make-iterator/make-blob-iterator.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   makeBlobIterator: () => (/* binding */ makeBlobIterator)\n/* harmony export */ });\nconst DEFAULT_CHUNK_SIZE = 1024 * 1024;\nasync function* makeBlobIterator(blob, options) {\n  const chunkSize = (options === null || options === void 0 ? void 0 : options.chunkSize) || DEFAULT_CHUNK_SIZE;\n  let offset = 0;\n  while (offset < blob.size) {\n    const end = offset + chunkSize;\n    const chunk = await blob.slice(offset, end).arrayBuffer();\n    offset = end;\n    yield chunk;\n  }\n}\n//# sourceMappingURL=make-blob-iterator.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/core/dist/esm/iterators/make-iterator/make-blob-iterator.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/core/dist/esm/iterators/make-iterator/make-iterator.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/@loaders.gl/core/dist/esm/iterators/make-iterator/make-iterator.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   makeIterator: () => (/* binding */ makeIterator)\n/* harmony export */ });\n/* harmony import */ var _make_string_iterator__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./make-string-iterator */ \"./node_modules/@loaders.gl/core/dist/esm/iterators/make-iterator/make-string-iterator.js\");\n/* harmony import */ var _make_array_buffer_iterator__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./make-array-buffer-iterator */ \"./node_modules/@loaders.gl/core/dist/esm/iterators/make-iterator/make-array-buffer-iterator.js\");\n/* harmony import */ var _make_blob_iterator__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./make-blob-iterator */ \"./node_modules/@loaders.gl/core/dist/esm/iterators/make-iterator/make-blob-iterator.js\");\n/* harmony import */ var _make_stream_iterator__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./make-stream-iterator */ \"./node_modules/@loaders.gl/core/dist/esm/iterators/make-iterator/make-stream-iterator.js\");\n/* harmony import */ var _javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../javascript-utils/is-type */ \"./node_modules/@loaders.gl/core/dist/esm/javascript-utils/is-type.js\");\n\n\n\n\n\nfunction makeIterator(data, options) {\n  if (typeof data === 'string') {\n    return (0,_make_string_iterator__WEBPACK_IMPORTED_MODULE_0__.makeStringIterator)(data, options);\n  }\n  if (data instanceof ArrayBuffer) {\n    return (0,_make_array_buffer_iterator__WEBPACK_IMPORTED_MODULE_1__.makeArrayBufferIterator)(data, options);\n  }\n  if ((0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_2__.isBlob)(data)) {\n    return (0,_make_blob_iterator__WEBPACK_IMPORTED_MODULE_3__.makeBlobIterator)(data, options);\n  }\n  if ((0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_2__.isReadableStream)(data)) {\n    return (0,_make_stream_iterator__WEBPACK_IMPORTED_MODULE_4__.makeStreamIterator)(data, options);\n  }\n  if ((0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_2__.isResponse)(data)) {\n    const response = data;\n    return (0,_make_stream_iterator__WEBPACK_IMPORTED_MODULE_4__.makeStreamIterator)(response.body, options);\n  }\n  throw new Error('makeIterator');\n}\n//# sourceMappingURL=make-iterator.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/core/dist/esm/iterators/make-iterator/make-iterator.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/core/dist/esm/iterators/make-iterator/make-stream-iterator.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/@loaders.gl/core/dist/esm/iterators/make-iterator/make-stream-iterator.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   makeStreamIterator: () => (/* binding */ makeStreamIterator)\n/* harmony export */ });\n/* harmony import */ var _loaders_gl_loader_utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @loaders.gl/loader-utils */ \"./node_modules/@loaders.gl/loader-utils/dist/esm/lib/env-utils/globals.js\");\n/* harmony import */ var _loaders_gl_loader_utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @loaders.gl/loader-utils */ \"./node_modules/@loaders.gl/loader-utils/dist/esm/lib/binary-utils/memory-conversion-utils.js\");\n\nfunction makeStreamIterator(stream, options) {\n  return _loaders_gl_loader_utils__WEBPACK_IMPORTED_MODULE_0__.isBrowser ? makeBrowserStreamIterator(stream, options) : makeNodeStreamIterator(stream, options);\n}\nasync function* makeBrowserStreamIterator(stream, options) {\n  const reader = stream.getReader();\n  let nextBatchPromise;\n  try {\n    while (true) {\n      const currentBatchPromise = nextBatchPromise || reader.read();\n      if (options !== null && options !== void 0 && options._streamReadAhead) {\n        nextBatchPromise = reader.read();\n      }\n      const {\n        done,\n        value\n      } = await currentBatchPromise;\n      if (done) {\n        return;\n      }\n      yield (0,_loaders_gl_loader_utils__WEBPACK_IMPORTED_MODULE_1__.toArrayBuffer)(value);\n    }\n  } catch (error) {\n    reader.releaseLock();\n  }\n}\nasync function* makeNodeStreamIterator(stream, options) {\n  for await (const chunk of stream) {\n    yield (0,_loaders_gl_loader_utils__WEBPACK_IMPORTED_MODULE_1__.toArrayBuffer)(chunk);\n  }\n}\n//# sourceMappingURL=make-stream-iterator.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/core/dist/esm/iterators/make-iterator/make-stream-iterator.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/core/dist/esm/iterators/make-iterator/make-string-iterator.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/@loaders.gl/core/dist/esm/iterators/make-iterator/make-string-iterator.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   makeStringIterator: () => (/* binding */ makeStringIterator)\n/* harmony export */ });\nconst DEFAULT_CHUNK_SIZE = 256 * 1024;\nfunction* makeStringIterator(string, options) {\n  const chunkSize = (options === null || options === void 0 ? void 0 : options.chunkSize) || DEFAULT_CHUNK_SIZE;\n  let offset = 0;\n  const textEncoder = new TextEncoder();\n  while (offset < string.length) {\n    const chunkLength = Math.min(string.length - offset, chunkSize);\n    const chunk = string.slice(offset, offset + chunkLength);\n    offset += chunkLength;\n    yield textEncoder.encode(chunk);\n  }\n}\n//# sourceMappingURL=make-string-iterator.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/core/dist/esm/iterators/make-iterator/make-string-iterator.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/core/dist/esm/javascript-utils/is-type.js":
/*!****************************************************************************!*\
  !*** ./node_modules/@loaders.gl/core/dist/esm/javascript-utils/is-type.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   isAsyncIterable: () => (/* binding */ isAsyncIterable),\n/* harmony export */   isBlob: () => (/* binding */ isBlob),\n/* harmony export */   isBuffer: () => (/* binding */ isBuffer),\n/* harmony export */   isFile: () => (/* binding */ isFile),\n/* harmony export */   isIterable: () => (/* binding */ isIterable),\n/* harmony export */   isIterator: () => (/* binding */ isIterator),\n/* harmony export */   isObject: () => (/* binding */ isObject),\n/* harmony export */   isPromise: () => (/* binding */ isPromise),\n/* harmony export */   isPureObject: () => (/* binding */ isPureObject),\n/* harmony export */   isReadableDOMStream: () => (/* binding */ isReadableDOMStream),\n/* harmony export */   isReadableNodeStream: () => (/* binding */ isReadableNodeStream),\n/* harmony export */   isReadableStream: () => (/* binding */ isReadableStream),\n/* harmony export */   isResponse: () => (/* binding */ isResponse),\n/* harmony export */   isWritableDOMStream: () => (/* binding */ isWritableDOMStream),\n/* harmony export */   isWritableNodeStream: () => (/* binding */ isWritableNodeStream),\n/* harmony export */   isWritableStream: () => (/* binding */ isWritableStream)\n/* harmony export */ });\nconst isBoolean = x => typeof x === 'boolean';\nconst isFunction = x => typeof x === 'function';\nconst isObject = x => x !== null && typeof x === 'object';\nconst isPureObject = x => isObject(x) && x.constructor === {}.constructor;\nconst isPromise = x => isObject(x) && isFunction(x.then);\nconst isIterable = x => x && typeof x[Symbol.iterator] === 'function';\nconst isAsyncIterable = x => x && typeof x[Symbol.asyncIterator] === 'function';\nconst isIterator = x => x && isFunction(x.next);\nconst isResponse = x => typeof Response !== 'undefined' && x instanceof Response || x && x.arrayBuffer && x.text && x.json;\nconst isFile = x => typeof File !== 'undefined' && x instanceof File;\nconst isBlob = x => typeof Blob !== 'undefined' && x instanceof Blob;\nconst isBuffer = x => x && typeof x === 'object' && x.isBuffer;\nconst isWritableDOMStream = x => isObject(x) && isFunction(x.abort) && isFunction(x.getWriter);\nconst isReadableDOMStream = x => typeof ReadableStream !== 'undefined' && x instanceof ReadableStream || isObject(x) && isFunction(x.tee) && isFunction(x.cancel) && isFunction(x.getReader);\nconst isWritableNodeStream = x => isObject(x) && isFunction(x.end) && isFunction(x.write) && isBoolean(x.writable);\nconst isReadableNodeStream = x => isObject(x) && isFunction(x.read) && isFunction(x.pipe) && isBoolean(x.readable);\nconst isReadableStream = x => isReadableDOMStream(x) || isReadableNodeStream(x);\nconst isWritableStream = x => isWritableDOMStream(x) || isWritableNodeStream(x);\n//# sourceMappingURL=is-type.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/core/dist/esm/javascript-utils/is-type.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/core/dist/esm/lib/api/load.js":
/*!****************************************************************!*\
  !*** ./node_modules/@loaders.gl/core/dist/esm/lib/api/load.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   load: () => (/* binding */ load)\n/* harmony export */ });\n/* harmony import */ var _javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../javascript-utils/is-type */ \"./node_modules/@loaders.gl/core/dist/esm/javascript-utils/is-type.js\");\n/* harmony import */ var _loader_utils_normalize_loader__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../loader-utils/normalize-loader */ \"./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/normalize-loader.js\");\n/* harmony import */ var _loader_utils_get_fetch_function__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../loader-utils/get-fetch-function */ \"./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/get-fetch-function.js\");\n/* harmony import */ var _parse__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./parse */ \"./node_modules/@loaders.gl/core/dist/esm/lib/api/parse.js\");\n\n\n\n\nasync function load(url, loaders, options, context) {\n  if (!Array.isArray(loaders) && !(0,_loader_utils_normalize_loader__WEBPACK_IMPORTED_MODULE_0__.isLoaderObject)(loaders)) {\n    context = undefined;\n    options = loaders;\n    loaders = undefined;\n  }\n  const fetch = (0,_loader_utils_get_fetch_function__WEBPACK_IMPORTED_MODULE_1__.getFetchFunction)(options);\n  let data = url;\n  if (typeof url === 'string') {\n    data = await fetch(url);\n  }\n  if ((0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_2__.isBlob)(url)) {\n    data = await fetch(url);\n  }\n  return await (0,_parse__WEBPACK_IMPORTED_MODULE_3__.parse)(data, loaders, options);\n}\n//# sourceMappingURL=load.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/core/dist/esm/lib/api/load.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/core/dist/esm/lib/api/parse.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@loaders.gl/core/dist/esm/lib/api/parse.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   parse: () => (/* binding */ parse)\n/* harmony export */ });\n/* harmony import */ var _loaders_gl_worker_utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @loaders.gl/worker-utils */ \"./node_modules/@loaders.gl/worker-utils/dist/esm/lib/env-utils/assert.js\");\n/* harmony import */ var _loaders_gl_worker_utils__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! @loaders.gl/worker-utils */ \"./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-api/validate-worker-version.js\");\n/* harmony import */ var _loaders_gl_loader_utils__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! @loaders.gl/loader-utils */ \"./node_modules/@loaders.gl/loader-utils/dist/esm/lib/worker-loader-utils/parse-with-worker.js\");\n/* harmony import */ var _loader_utils_normalize_loader__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../loader-utils/normalize-loader */ \"./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/normalize-loader.js\");\n/* harmony import */ var _javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../../javascript-utils/is-type */ \"./node_modules/@loaders.gl/core/dist/esm/javascript-utils/is-type.js\");\n/* harmony import */ var _loader_utils_option_utils__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../loader-utils/option-utils */ \"./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/option-utils.js\");\n/* harmony import */ var _loader_utils_get_data__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../loader-utils/get-data */ \"./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/get-data.js\");\n/* harmony import */ var _loader_utils_loader_context__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../loader-utils/loader-context */ \"./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/loader-context.js\");\n/* harmony import */ var _utils_resource_utils__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/resource-utils */ \"./node_modules/@loaders.gl/core/dist/esm/lib/utils/resource-utils.js\");\n/* harmony import */ var _select_loader__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./select-loader */ \"./node_modules/@loaders.gl/core/dist/esm/lib/api/select-loader.js\");\n\n\n\n\n\n\n\n\n\nasync function parse(data, loaders, options, context) {\n  (0,_loaders_gl_worker_utils__WEBPACK_IMPORTED_MODULE_0__.assert)(!context || typeof context === 'object');\n  if (loaders && !Array.isArray(loaders) && !(0,_loader_utils_normalize_loader__WEBPACK_IMPORTED_MODULE_1__.isLoaderObject)(loaders)) {\n    context = undefined;\n    options = loaders;\n    loaders = undefined;\n  }\n  data = await data;\n  options = options || {};\n  const url = (0,_utils_resource_utils__WEBPACK_IMPORTED_MODULE_2__.getResourceUrl)(data);\n  const typedLoaders = loaders;\n  const candidateLoaders = (0,_loader_utils_loader_context__WEBPACK_IMPORTED_MODULE_3__.getLoadersFromContext)(typedLoaders, context);\n  const loader = await (0,_select_loader__WEBPACK_IMPORTED_MODULE_4__.selectLoader)(data, candidateLoaders, options);\n  if (!loader) {\n    return null;\n  }\n  options = (0,_loader_utils_option_utils__WEBPACK_IMPORTED_MODULE_5__.normalizeOptions)(options, loader, candidateLoaders, url);\n  context = (0,_loader_utils_loader_context__WEBPACK_IMPORTED_MODULE_3__.getLoaderContext)({\n    url,\n    parse,\n    loaders: candidateLoaders\n  }, options, context || null);\n  return await parseWithLoader(loader, data, options, context);\n}\nasync function parseWithLoader(loader, data, options, context) {\n  (0,_loaders_gl_worker_utils__WEBPACK_IMPORTED_MODULE_6__.validateWorkerVersion)(loader);\n  if ((0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_7__.isResponse)(data)) {\n    const response = data;\n    const {\n      ok,\n      redirected,\n      status,\n      statusText,\n      type,\n      url\n    } = response;\n    const headers = Object.fromEntries(response.headers.entries());\n    context.response = {\n      headers,\n      ok,\n      redirected,\n      status,\n      statusText,\n      type,\n      url\n    };\n  }\n  data = await (0,_loader_utils_get_data__WEBPACK_IMPORTED_MODULE_8__.getArrayBufferOrStringFromData)(data, loader, options);\n  if (loader.parseTextSync && typeof data === 'string') {\n    options.dataType = 'text';\n    return loader.parseTextSync(data, options, context, loader);\n  }\n  if ((0,_loaders_gl_loader_utils__WEBPACK_IMPORTED_MODULE_9__.canParseWithWorker)(loader, options)) {\n    return await (0,_loaders_gl_loader_utils__WEBPACK_IMPORTED_MODULE_9__.parseWithWorker)(loader, data, options, context, parse);\n  }\n  if (loader.parseText && typeof data === 'string') {\n    return await loader.parseText(data, options, context, loader);\n  }\n  if (loader.parse) {\n    return await loader.parse(data, options, context, loader);\n  }\n  (0,_loaders_gl_worker_utils__WEBPACK_IMPORTED_MODULE_0__.assert)(!loader.parseSync);\n  throw new Error(\"\".concat(loader.id, \" loader - no parser found and worker is disabled\"));\n}\n//# sourceMappingURL=parse.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/core/dist/esm/lib/api/parse.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/core/dist/esm/lib/api/register-loaders.js":
/*!****************************************************************************!*\
  !*** ./node_modules/@loaders.gl/core/dist/esm/lib/api/register-loaders.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   _unregisterLoaders: () => (/* binding */ _unregisterLoaders),\n/* harmony export */   getRegisteredLoaders: () => (/* binding */ getRegisteredLoaders),\n/* harmony export */   registerLoaders: () => (/* binding */ registerLoaders)\n/* harmony export */ });\n/* harmony import */ var _loader_utils_normalize_loader__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../loader-utils/normalize-loader */ \"./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/normalize-loader.js\");\n/* harmony import */ var _loader_utils_option_utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../loader-utils/option-utils */ \"./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/option-utils.js\");\n\n\nconst getGlobalLoaderRegistry = () => {\n  const state = (0,_loader_utils_option_utils__WEBPACK_IMPORTED_MODULE_0__.getGlobalLoaderState)();\n  state.loaderRegistry = state.loaderRegistry || [];\n  return state.loaderRegistry;\n};\nfunction registerLoaders(loaders) {\n  const loaderRegistry = getGlobalLoaderRegistry();\n  loaders = Array.isArray(loaders) ? loaders : [loaders];\n  for (const loader of loaders) {\n    const normalizedLoader = (0,_loader_utils_normalize_loader__WEBPACK_IMPORTED_MODULE_1__.normalizeLoader)(loader);\n    if (!loaderRegistry.find(registeredLoader => normalizedLoader === registeredLoader)) {\n      loaderRegistry.unshift(normalizedLoader);\n    }\n  }\n}\nfunction getRegisteredLoaders() {\n  return getGlobalLoaderRegistry();\n}\nfunction _unregisterLoaders() {\n  const state = (0,_loader_utils_option_utils__WEBPACK_IMPORTED_MODULE_0__.getGlobalLoaderState)();\n  state.loaderRegistry = [];\n}\n//# sourceMappingURL=register-loaders.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/core/dist/esm/lib/api/register-loaders.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/core/dist/esm/lib/api/select-loader.js":
/*!*************************************************************************!*\
  !*** ./node_modules/@loaders.gl/core/dist/esm/lib/api/select-loader.js ***!
  \*************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   selectLoader: () => (/* binding */ selectLoader),\n/* harmony export */   selectLoaderSync: () => (/* binding */ selectLoaderSync)\n/* harmony export */ });\n/* harmony import */ var _loaders_gl_loader_utils__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! @loaders.gl/loader-utils */ \"./node_modules/@loaders.gl/loader-utils/dist/esm/lib/path-utils/path.js\");\n/* harmony import */ var _loaders_gl_loader_utils__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! @loaders.gl/loader-utils */ \"./node_modules/@loaders.gl/loader-utils/dist/esm/lib/binary-utils/array-buffer-utils.js\");\n/* harmony import */ var _loader_utils_normalize_loader__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../loader-utils/normalize-loader */ \"./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/normalize-loader.js\");\n/* harmony import */ var _utils_log__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../utils/log */ \"./node_modules/@loaders.gl/core/dist/esm/lib/utils/log.js\");\n/* harmony import */ var _utils_resource_utils__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/resource-utils */ \"./node_modules/@loaders.gl/core/dist/esm/lib/utils/resource-utils.js\");\n/* harmony import */ var _register_loaders__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./register-loaders */ \"./node_modules/@loaders.gl/core/dist/esm/lib/api/register-loaders.js\");\n/* harmony import */ var _javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../javascript-utils/is-type */ \"./node_modules/@loaders.gl/core/dist/esm/javascript-utils/is-type.js\");\n/* harmony import */ var _utils_url_utils__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../utils/url-utils */ \"./node_modules/@loaders.gl/core/dist/esm/lib/utils/url-utils.js\");\n\n\n\n\n\n\n\nconst EXT_PATTERN = /\\.([^.]+)$/;\nasync function selectLoader(data) {\n  let loaders = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : [];\n  let options = arguments.length > 2 ? arguments[2] : undefined;\n  let context = arguments.length > 3 ? arguments[3] : undefined;\n  if (!validHTTPResponse(data)) {\n    return null;\n  }\n  let loader = selectLoaderSync(data, loaders, {\n    ...options,\n    nothrow: true\n  }, context);\n  if (loader) {\n    return loader;\n  }\n  if ((0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_0__.isBlob)(data)) {\n    data = await data.slice(0, 10).arrayBuffer();\n    loader = selectLoaderSync(data, loaders, options, context);\n  }\n  if (!loader && !(options !== null && options !== void 0 && options.nothrow)) {\n    throw new Error(getNoValidLoaderMessage(data));\n  }\n  return loader;\n}\nfunction selectLoaderSync(data) {\n  let loaders = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : [];\n  let options = arguments.length > 2 ? arguments[2] : undefined;\n  let context = arguments.length > 3 ? arguments[3] : undefined;\n  if (!validHTTPResponse(data)) {\n    return null;\n  }\n  if (loaders && !Array.isArray(loaders)) {\n    return (0,_loader_utils_normalize_loader__WEBPACK_IMPORTED_MODULE_1__.normalizeLoader)(loaders);\n  }\n  let candidateLoaders = [];\n  if (loaders) {\n    candidateLoaders = candidateLoaders.concat(loaders);\n  }\n  if (!(options !== null && options !== void 0 && options.ignoreRegisteredLoaders)) {\n    candidateLoaders.push(...(0,_register_loaders__WEBPACK_IMPORTED_MODULE_2__.getRegisteredLoaders)());\n  }\n  normalizeLoaders(candidateLoaders);\n  const loader = selectLoaderInternal(data, candidateLoaders, options, context);\n  if (!loader && !(options !== null && options !== void 0 && options.nothrow)) {\n    throw new Error(getNoValidLoaderMessage(data));\n  }\n  return loader;\n}\nfunction selectLoaderInternal(data, loaders, options, context) {\n  const url = (0,_utils_resource_utils__WEBPACK_IMPORTED_MODULE_3__.getResourceUrl)(data);\n  const type = (0,_utils_resource_utils__WEBPACK_IMPORTED_MODULE_3__.getResourceMIMEType)(data);\n  const testUrl = (0,_utils_url_utils__WEBPACK_IMPORTED_MODULE_4__.stripQueryString)(url) || (context === null || context === void 0 ? void 0 : context.url);\n  let loader = null;\n  let reason = '';\n  if (options !== null && options !== void 0 && options.mimeType) {\n    loader = findLoaderByMIMEType(loaders, options === null || options === void 0 ? void 0 : options.mimeType);\n    reason = \"match forced by supplied MIME type \".concat(options === null || options === void 0 ? void 0 : options.mimeType);\n  }\n  loader = loader || findLoaderByUrl(loaders, testUrl);\n  reason = reason || (loader ? \"matched url \".concat(testUrl) : '');\n  loader = loader || findLoaderByMIMEType(loaders, type);\n  reason = reason || (loader ? \"matched MIME type \".concat(type) : '');\n  loader = loader || findLoaderByInitialBytes(loaders, data);\n  reason = reason || (loader ? \"matched initial data \".concat(getFirstCharacters(data)) : '');\n  loader = loader || findLoaderByMIMEType(loaders, options === null || options === void 0 ? void 0 : options.fallbackMimeType);\n  reason = reason || (loader ? \"matched fallback MIME type \".concat(type) : '');\n  if (reason) {\n    var _loader;\n    _utils_log__WEBPACK_IMPORTED_MODULE_5__.log.log(1, \"selectLoader selected \".concat((_loader = loader) === null || _loader === void 0 ? void 0 : _loader.name, \": \").concat(reason, \".\"));\n  }\n  return loader;\n}\nfunction validHTTPResponse(data) {\n  if (data instanceof Response) {\n    if (data.status === 204) {\n      return false;\n    }\n  }\n  return true;\n}\nfunction getNoValidLoaderMessage(data) {\n  const url = (0,_utils_resource_utils__WEBPACK_IMPORTED_MODULE_3__.getResourceUrl)(data);\n  const type = (0,_utils_resource_utils__WEBPACK_IMPORTED_MODULE_3__.getResourceMIMEType)(data);\n  let message = 'No valid loader found (';\n  message += url ? \"\".concat(_loaders_gl_loader_utils__WEBPACK_IMPORTED_MODULE_6__.filename(url), \", \") : 'no url provided, ';\n  message += \"MIME type: \".concat(type ? \"\\\"\".concat(type, \"\\\"\") : 'not provided', \", \");\n  const firstCharacters = data ? getFirstCharacters(data) : '';\n  message += firstCharacters ? \" first bytes: \\\"\".concat(firstCharacters, \"\\\"\") : 'first bytes: not available';\n  message += ')';\n  return message;\n}\nfunction normalizeLoaders(loaders) {\n  for (const loader of loaders) {\n    (0,_loader_utils_normalize_loader__WEBPACK_IMPORTED_MODULE_1__.normalizeLoader)(loader);\n  }\n}\nfunction findLoaderByUrl(loaders, url) {\n  const match = url && EXT_PATTERN.exec(url);\n  const extension = match && match[1];\n  return extension ? findLoaderByExtension(loaders, extension) : null;\n}\nfunction findLoaderByExtension(loaders, extension) {\n  extension = extension.toLowerCase();\n  for (const loader of loaders) {\n    for (const loaderExtension of loader.extensions) {\n      if (loaderExtension.toLowerCase() === extension) {\n        return loader;\n      }\n    }\n  }\n  return null;\n}\nfunction findLoaderByMIMEType(loaders, mimeType) {\n  for (const loader of loaders) {\n    if (loader.mimeTypes && loader.mimeTypes.includes(mimeType)) {\n      return loader;\n    }\n    if (mimeType === \"application/x.\".concat(loader.id)) {\n      return loader;\n    }\n  }\n  return null;\n}\nfunction findLoaderByInitialBytes(loaders, data) {\n  if (!data) {\n    return null;\n  }\n  for (const loader of loaders) {\n    if (typeof data === 'string') {\n      if (testDataAgainstText(data, loader)) {\n        return loader;\n      }\n    } else if (ArrayBuffer.isView(data)) {\n      if (testDataAgainstBinary(data.buffer, data.byteOffset, loader)) {\n        return loader;\n      }\n    } else if (data instanceof ArrayBuffer) {\n      const byteOffset = 0;\n      if (testDataAgainstBinary(data, byteOffset, loader)) {\n        return loader;\n      }\n    }\n  }\n  return null;\n}\nfunction testDataAgainstText(data, loader) {\n  if (loader.testText) {\n    return loader.testText(data);\n  }\n  const tests = Array.isArray(loader.tests) ? loader.tests : [loader.tests];\n  return tests.some(test => data.startsWith(test));\n}\nfunction testDataAgainstBinary(data, byteOffset, loader) {\n  const tests = Array.isArray(loader.tests) ? loader.tests : [loader.tests];\n  return tests.some(test => testBinary(data, byteOffset, loader, test));\n}\nfunction testBinary(data, byteOffset, loader, test) {\n  if (test instanceof ArrayBuffer) {\n    return (0,_loaders_gl_loader_utils__WEBPACK_IMPORTED_MODULE_7__.compareArrayBuffers)(test, data, test.byteLength);\n  }\n  switch (typeof test) {\n    case 'function':\n      return test(data, loader);\n    case 'string':\n      const magic = getMagicString(data, byteOffset, test.length);\n      return test === magic;\n    default:\n      return false;\n  }\n}\nfunction getFirstCharacters(data) {\n  let length = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 5;\n  if (typeof data === 'string') {\n    return data.slice(0, length);\n  } else if (ArrayBuffer.isView(data)) {\n    return getMagicString(data.buffer, data.byteOffset, length);\n  } else if (data instanceof ArrayBuffer) {\n    const byteOffset = 0;\n    return getMagicString(data, byteOffset, length);\n  }\n  return '';\n}\nfunction getMagicString(arrayBuffer, byteOffset, length) {\n  if (arrayBuffer.byteLength < byteOffset + length) {\n    return '';\n  }\n  const dataView = new DataView(arrayBuffer);\n  let magic = '';\n  for (let i = 0; i < length; i++) {\n    magic += String.fromCharCode(dataView.getUint8(byteOffset + i));\n  }\n  return magic;\n}\n//# sourceMappingURL=select-loader.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/core/dist/esm/lib/api/select-loader.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/core/dist/esm/lib/fetch/fetch-file.js":
/*!************************************************************************!*\
  !*** ./node_modules/@loaders.gl/core/dist/esm/lib/fetch/fetch-file.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   fetchFile: () => (/* binding */ fetchFile)\n/* harmony export */ });\n/* harmony import */ var _loaders_gl_loader_utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @loaders.gl/loader-utils */ \"./node_modules/@loaders.gl/loader-utils/dist/esm/lib/path-utils/file-aliases.js\");\n/* harmony import */ var _utils_response_utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/response-utils */ \"./node_modules/@loaders.gl/core/dist/esm/lib/utils/response-utils.js\");\n\n\nasync function fetchFile(url, options) {\n  if (typeof url === 'string') {\n    url = (0,_loaders_gl_loader_utils__WEBPACK_IMPORTED_MODULE_0__.resolvePath)(url);\n    let fetchOptions = options;\n    if (options !== null && options !== void 0 && options.fetch && typeof (options === null || options === void 0 ? void 0 : options.fetch) !== 'function') {\n      fetchOptions = options.fetch;\n    }\n    return await fetch(url, fetchOptions);\n  }\n  return await (0,_utils_response_utils__WEBPACK_IMPORTED_MODULE_1__.makeResponse)(url);\n}\n//# sourceMappingURL=fetch-file.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/core/dist/esm/lib/fetch/fetch-file.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/get-data.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/get-data.js ***!
  \*****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getArrayBufferOrStringFromData: () => (/* binding */ getArrayBufferOrStringFromData),\n/* harmony export */   getArrayBufferOrStringFromDataSync: () => (/* binding */ getArrayBufferOrStringFromDataSync),\n/* harmony export */   getAsyncIterableFromData: () => (/* binding */ getAsyncIterableFromData),\n/* harmony export */   getReadableStream: () => (/* binding */ getReadableStream)\n/* harmony export */ });\n/* harmony import */ var _loaders_gl_loader_utils__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! @loaders.gl/loader-utils */ \"./node_modules/@loaders.gl/loader-utils/dist/esm/lib/iterators/async-iteration.js\");\n/* harmony import */ var _javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../javascript-utils/is-type */ \"./node_modules/@loaders.gl/core/dist/esm/javascript-utils/is-type.js\");\n/* harmony import */ var _iterators_make_iterator_make_iterator__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../iterators/make-iterator/make-iterator */ \"./node_modules/@loaders.gl/core/dist/esm/iterators/make-iterator/make-iterator.js\");\n/* harmony import */ var _utils_response_utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/response-utils */ \"./node_modules/@loaders.gl/core/dist/esm/lib/utils/response-utils.js\");\n\n\n\n\nconst ERR_DATA = 'Cannot convert supplied data type';\nfunction getArrayBufferOrStringFromDataSync(data, loader, options) {\n  if (loader.text && typeof data === 'string') {\n    return data;\n  }\n  if ((0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_0__.isBuffer)(data)) {\n    data = data.buffer;\n  }\n  if (data instanceof ArrayBuffer) {\n    const arrayBuffer = data;\n    if (loader.text && !loader.binary) {\n      const textDecoder = new TextDecoder('utf8');\n      return textDecoder.decode(arrayBuffer);\n    }\n    return arrayBuffer;\n  }\n  if (ArrayBuffer.isView(data)) {\n    if (loader.text && !loader.binary) {\n      const textDecoder = new TextDecoder('utf8');\n      return textDecoder.decode(data);\n    }\n    let arrayBuffer = data.buffer;\n    const byteLength = data.byteLength || data.length;\n    if (data.byteOffset !== 0 || byteLength !== arrayBuffer.byteLength) {\n      arrayBuffer = arrayBuffer.slice(data.byteOffset, data.byteOffset + byteLength);\n    }\n    return arrayBuffer;\n  }\n  throw new Error(ERR_DATA);\n}\nasync function getArrayBufferOrStringFromData(data, loader, options) {\n  const isArrayBuffer = data instanceof ArrayBuffer || ArrayBuffer.isView(data);\n  if (typeof data === 'string' || isArrayBuffer) {\n    return getArrayBufferOrStringFromDataSync(data, loader, options);\n  }\n  if ((0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_0__.isBlob)(data)) {\n    data = await (0,_utils_response_utils__WEBPACK_IMPORTED_MODULE_1__.makeResponse)(data);\n  }\n  if ((0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_0__.isResponse)(data)) {\n    const response = data;\n    await (0,_utils_response_utils__WEBPACK_IMPORTED_MODULE_1__.checkResponse)(response);\n    return loader.binary ? await response.arrayBuffer() : await response.text();\n  }\n  if ((0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_0__.isReadableStream)(data)) {\n    data = (0,_iterators_make_iterator_make_iterator__WEBPACK_IMPORTED_MODULE_2__.makeIterator)(data, options);\n  }\n  if ((0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_0__.isIterable)(data) || (0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_0__.isAsyncIterable)(data)) {\n    return (0,_loaders_gl_loader_utils__WEBPACK_IMPORTED_MODULE_3__.concatenateArrayBuffersAsync)(data);\n  }\n  throw new Error(ERR_DATA);\n}\nasync function getAsyncIterableFromData(data, options) {\n  if ((0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_0__.isIterator)(data)) {\n    return data;\n  }\n  if ((0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_0__.isResponse)(data)) {\n    const response = data;\n    await (0,_utils_response_utils__WEBPACK_IMPORTED_MODULE_1__.checkResponse)(response);\n    const body = await response.body;\n    return (0,_iterators_make_iterator_make_iterator__WEBPACK_IMPORTED_MODULE_2__.makeIterator)(body, options);\n  }\n  if ((0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_0__.isBlob)(data) || (0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_0__.isReadableStream)(data)) {\n    return (0,_iterators_make_iterator_make_iterator__WEBPACK_IMPORTED_MODULE_2__.makeIterator)(data, options);\n  }\n  if ((0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_0__.isAsyncIterable)(data)) {\n    return data[Symbol.asyncIterator]();\n  }\n  return getIterableFromData(data);\n}\nasync function getReadableStream(data) {\n  if ((0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_0__.isReadableStream)(data)) {\n    return data;\n  }\n  if ((0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_0__.isResponse)(data)) {\n    return data.body;\n  }\n  const response = await (0,_utils_response_utils__WEBPACK_IMPORTED_MODULE_1__.makeResponse)(data);\n  return response.body;\n}\nfunction getIterableFromData(data) {\n  if (ArrayBuffer.isView(data)) {\n    return function* oneChunk() {\n      yield data.buffer;\n    }();\n  }\n  if (data instanceof ArrayBuffer) {\n    return function* oneChunk() {\n      yield data;\n    }();\n  }\n  if ((0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_0__.isIterator)(data)) {\n    return data;\n  }\n  if ((0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_0__.isIterable)(data)) {\n    return data[Symbol.iterator]();\n  }\n  throw new Error(ERR_DATA);\n}\n//# sourceMappingURL=get-data.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/get-data.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/get-fetch-function.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/get-fetch-function.js ***!
  \***************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getFetchFunction: () => (/* binding */ getFetchFunction)\n/* harmony export */ });\n/* harmony import */ var _javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../javascript-utils/is-type */ \"./node_modules/@loaders.gl/core/dist/esm/javascript-utils/is-type.js\");\n/* harmony import */ var _fetch_fetch_file__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../fetch/fetch-file */ \"./node_modules/@loaders.gl/core/dist/esm/lib/fetch/fetch-file.js\");\n/* harmony import */ var _option_utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./option-utils */ \"./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/option-utils.js\");\n\n\n\nfunction getFetchFunction(options, context) {\n  const globalOptions = (0,_option_utils__WEBPACK_IMPORTED_MODULE_0__.getGlobalLoaderOptions)();\n  const fetchOptions = options || globalOptions;\n  if (typeof fetchOptions.fetch === 'function') {\n    return fetchOptions.fetch;\n  }\n  if ((0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_1__.isObject)(fetchOptions.fetch)) {\n    return url => (0,_fetch_fetch_file__WEBPACK_IMPORTED_MODULE_2__.fetchFile)(url, fetchOptions);\n  }\n  if (context !== null && context !== void 0 && context.fetch) {\n    return context === null || context === void 0 ? void 0 : context.fetch;\n  }\n  return _fetch_fetch_file__WEBPACK_IMPORTED_MODULE_2__.fetchFile;\n}\n//# sourceMappingURL=get-fetch-function.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/get-fetch-function.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/loader-context.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/loader-context.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getLoaderContext: () => (/* binding */ getLoaderContext),\n/* harmony export */   getLoadersFromContext: () => (/* binding */ getLoadersFromContext)\n/* harmony export */ });\n/* harmony import */ var _get_fetch_function__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./get-fetch-function */ \"./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/get-fetch-function.js\");\n/* harmony import */ var _utils_url_utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/url-utils */ \"./node_modules/@loaders.gl/core/dist/esm/lib/utils/url-utils.js\");\n/* harmony import */ var _loaders_gl_loader_utils__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @loaders.gl/loader-utils */ \"./node_modules/@loaders.gl/loader-utils/dist/esm/lib/path-utils/path.js\");\n\n\n\nfunction getLoaderContext(context, options, parentContext) {\n  if (parentContext) {\n    return parentContext;\n  }\n  const newContext = {\n    fetch: (0,_get_fetch_function__WEBPACK_IMPORTED_MODULE_0__.getFetchFunction)(options, context),\n    ...context\n  };\n  if (newContext.url) {\n    const baseUrl = (0,_utils_url_utils__WEBPACK_IMPORTED_MODULE_1__.stripQueryString)(newContext.url);\n    newContext.baseUrl = baseUrl;\n    newContext.queryString = (0,_utils_url_utils__WEBPACK_IMPORTED_MODULE_1__.extractQueryString)(newContext.url);\n    newContext.filename = _loaders_gl_loader_utils__WEBPACK_IMPORTED_MODULE_2__.filename(baseUrl);\n    newContext.baseUrl = _loaders_gl_loader_utils__WEBPACK_IMPORTED_MODULE_2__.dirname(baseUrl);\n  }\n  if (!Array.isArray(newContext.loaders)) {\n    newContext.loaders = null;\n  }\n  return newContext;\n}\nfunction getLoadersFromContext(loaders, context) {\n  if (!context && loaders && !Array.isArray(loaders)) {\n    return loaders;\n  }\n  let candidateLoaders;\n  if (loaders) {\n    candidateLoaders = Array.isArray(loaders) ? loaders : [loaders];\n  }\n  if (context && context.loaders) {\n    const contextLoaders = Array.isArray(context.loaders) ? context.loaders : [context.loaders];\n    candidateLoaders = candidateLoaders ? [...candidateLoaders, ...contextLoaders] : contextLoaders;\n  }\n  return candidateLoaders && candidateLoaders.length ? candidateLoaders : null;\n}\n//# sourceMappingURL=loader-context.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/loader-context.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/loggers.js":
/*!****************************************************************************!*\
  !*** ./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/loggers.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   ConsoleLog: () => (/* binding */ ConsoleLog),\n/* harmony export */   NullLog: () => (/* binding */ NullLog),\n/* harmony export */   probeLog: () => (/* binding */ probeLog)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _probe_gl_log__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @probe.gl/log */ \"./node_modules/@probe.gl/log/dist/esm/log.js\");\n\n\nconst probeLog = new _probe_gl_log__WEBPACK_IMPORTED_MODULE_1__.Log({\n  id: 'loaders.gl'\n});\nclass NullLog {\n  log() {\n    return () => {};\n  }\n  info() {\n    return () => {};\n  }\n  warn() {\n    return () => {};\n  }\n  error() {\n    return () => {};\n  }\n}\nclass ConsoleLog {\n  constructor() {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"console\", void 0);\n    this.console = console;\n  }\n  log() {\n    for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\n      args[_key] = arguments[_key];\n    }\n    return this.console.log.bind(this.console, ...args);\n  }\n  info() {\n    for (var _len2 = arguments.length, args = new Array(_len2), _key2 = 0; _key2 < _len2; _key2++) {\n      args[_key2] = arguments[_key2];\n    }\n    return this.console.info.bind(this.console, ...args);\n  }\n  warn() {\n    for (var _len3 = arguments.length, args = new Array(_len3), _key3 = 0; _key3 < _len3; _key3++) {\n      args[_key3] = arguments[_key3];\n    }\n    return this.console.warn.bind(this.console, ...args);\n  }\n  error() {\n    for (var _len4 = arguments.length, args = new Array(_len4), _key4 = 0; _key4 < _len4; _key4++) {\n      args[_key4] = arguments[_key4];\n    }\n    return this.console.error.bind(this.console, ...args);\n  }\n}\n//# sourceMappingURL=loggers.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/loggers.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/normalize-loader.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/normalize-loader.js ***!
  \*************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   isLoaderObject: () => (/* binding */ isLoaderObject),\n/* harmony export */   normalizeLoader: () => (/* binding */ normalizeLoader)\n/* harmony export */ });\n/* harmony import */ var _loaders_gl_loader_utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @loaders.gl/loader-utils */ \"./node_modules/@loaders.gl/loader-utils/dist/esm/lib/env-utils/assert.js\");\n\nfunction isLoaderObject(loader) {\n  var _loader;\n  if (!loader) {\n    return false;\n  }\n  if (Array.isArray(loader)) {\n    loader = loader[0];\n  }\n  const hasExtensions = Array.isArray((_loader = loader) === null || _loader === void 0 ? void 0 : _loader.extensions);\n  return hasExtensions;\n}\nfunction normalizeLoader(loader) {\n  var _loader2, _loader3;\n  (0,_loaders_gl_loader_utils__WEBPACK_IMPORTED_MODULE_0__.assert)(loader, 'null loader');\n  (0,_loaders_gl_loader_utils__WEBPACK_IMPORTED_MODULE_0__.assert)(isLoaderObject(loader), 'invalid loader');\n  let options;\n  if (Array.isArray(loader)) {\n    options = loader[1];\n    loader = loader[0];\n    loader = {\n      ...loader,\n      options: {\n        ...loader.options,\n        ...options\n      }\n    };\n  }\n  if ((_loader2 = loader) !== null && _loader2 !== void 0 && _loader2.parseTextSync || (_loader3 = loader) !== null && _loader3 !== void 0 && _loader3.parseText) {\n    loader.text = true;\n  }\n  if (!loader.text) {\n    loader.binary = true;\n  }\n  return loader;\n}\n//# sourceMappingURL=normalize-loader.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/normalize-loader.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/option-defaults.js":
/*!************************************************************************************!*\
  !*** ./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/option-defaults.js ***!
  \************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   DEFAULT_LOADER_OPTIONS: () => (/* binding */ DEFAULT_LOADER_OPTIONS),\n/* harmony export */   REMOVED_LOADER_OPTIONS: () => (/* binding */ REMOVED_LOADER_OPTIONS)\n/* harmony export */ });\n/* harmony import */ var _loaders_gl_loader_utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @loaders.gl/loader-utils */ \"./node_modules/@loaders.gl/loader-utils/dist/esm/lib/env-utils/globals.js\");\n/* harmony import */ var _loggers__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./loggers */ \"./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/loggers.js\");\n\n\nconst DEFAULT_LOADER_OPTIONS = {\n  fetch: null,\n  mimeType: undefined,\n  nothrow: false,\n  log: new _loggers__WEBPACK_IMPORTED_MODULE_0__.ConsoleLog(),\n  CDN: 'https://unpkg.com/@loaders.gl',\n  worker: true,\n  maxConcurrency: 3,\n  maxMobileConcurrency: 1,\n  reuseWorkers: _loaders_gl_loader_utils__WEBPACK_IMPORTED_MODULE_1__.isBrowser,\n  _nodeWorkers: false,\n  _workerType: '',\n  limit: 0,\n  _limitMB: 0,\n  batchSize: 'auto',\n  batchDebounceMs: 0,\n  metadata: false,\n  transforms: []\n};\nconst REMOVED_LOADER_OPTIONS = {\n  throws: 'nothrow',\n  dataType: '(no longer used)',\n  uri: 'baseUri',\n  method: 'fetch.method',\n  headers: 'fetch.headers',\n  body: 'fetch.body',\n  mode: 'fetch.mode',\n  credentials: 'fetch.credentials',\n  cache: 'fetch.cache',\n  redirect: 'fetch.redirect',\n  referrer: 'fetch.referrer',\n  referrerPolicy: 'fetch.referrerPolicy',\n  integrity: 'fetch.integrity',\n  keepalive: 'fetch.keepalive',\n  signal: 'fetch.signal'\n};\n//# sourceMappingURL=option-defaults.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/option-defaults.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/option-utils.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/option-utils.js ***!
  \*********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getGlobalLoaderOptions: () => (/* binding */ getGlobalLoaderOptions),\n/* harmony export */   getGlobalLoaderState: () => (/* binding */ getGlobalLoaderState),\n/* harmony export */   normalizeOptions: () => (/* binding */ normalizeOptions),\n/* harmony export */   setGlobalOptions: () => (/* binding */ setGlobalOptions)\n/* harmony export */ });\n/* harmony import */ var _javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../javascript-utils/is-type */ \"./node_modules/@loaders.gl/core/dist/esm/javascript-utils/is-type.js\");\n/* harmony import */ var _loggers__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./loggers */ \"./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/loggers.js\");\n/* harmony import */ var _option_defaults__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./option-defaults */ \"./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/option-defaults.js\");\n\n\n\nfunction getGlobalLoaderState() {\n  globalThis.loaders = globalThis.loaders || {};\n  const {\n    loaders\n  } = globalThis;\n  loaders._state = loaders._state || {};\n  return loaders._state;\n}\nconst getGlobalLoaderOptions = () => {\n  const state = getGlobalLoaderState();\n  state.globalOptions = state.globalOptions || {\n    ..._option_defaults__WEBPACK_IMPORTED_MODULE_0__.DEFAULT_LOADER_OPTIONS\n  };\n  return state.globalOptions;\n};\nfunction setGlobalOptions(options) {\n  const state = getGlobalLoaderState();\n  const globalOptions = getGlobalLoaderOptions();\n  state.globalOptions = normalizeOptionsInternal(globalOptions, options);\n}\nfunction normalizeOptions(options, loader, loaders, url) {\n  loaders = loaders || [];\n  loaders = Array.isArray(loaders) ? loaders : [loaders];\n  validateOptions(options, loaders);\n  return normalizeOptionsInternal(loader, options, url);\n}\nfunction validateOptions(options, loaders) {\n  validateOptionsObject(options, null, _option_defaults__WEBPACK_IMPORTED_MODULE_0__.DEFAULT_LOADER_OPTIONS, _option_defaults__WEBPACK_IMPORTED_MODULE_0__.REMOVED_LOADER_OPTIONS, loaders);\n  for (const loader of loaders) {\n    const idOptions = options && options[loader.id] || {};\n    const loaderOptions = loader.options && loader.options[loader.id] || {};\n    const deprecatedOptions = loader.deprecatedOptions && loader.deprecatedOptions[loader.id] || {};\n    validateOptionsObject(idOptions, loader.id, loaderOptions, deprecatedOptions, loaders);\n  }\n}\nfunction validateOptionsObject(options, id, defaultOptions, deprecatedOptions, loaders) {\n  const loaderName = id || 'Top level';\n  const prefix = id ? \"\".concat(id, \".\") : '';\n  for (const key in options) {\n    const isSubOptions = !id && (0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_1__.isObject)(options[key]);\n    const isBaseUriOption = key === 'baseUri' && !id;\n    const isWorkerUrlOption = key === 'workerUrl' && id;\n    if (!(key in defaultOptions) && !isBaseUriOption && !isWorkerUrlOption) {\n      if (key in deprecatedOptions) {\n        _loggers__WEBPACK_IMPORTED_MODULE_2__.probeLog.warn(\"\".concat(loaderName, \" loader option '\").concat(prefix).concat(key, \"' no longer supported, use '\").concat(deprecatedOptions[key], \"'\"))();\n      } else if (!isSubOptions) {\n        const suggestion = findSimilarOption(key, loaders);\n        _loggers__WEBPACK_IMPORTED_MODULE_2__.probeLog.warn(\"\".concat(loaderName, \" loader option '\").concat(prefix).concat(key, \"' not recognized. \").concat(suggestion))();\n      }\n    }\n  }\n}\nfunction findSimilarOption(optionKey, loaders) {\n  const lowerCaseOptionKey = optionKey.toLowerCase();\n  let bestSuggestion = '';\n  for (const loader of loaders) {\n    for (const key in loader.options) {\n      if (optionKey === key) {\n        return \"Did you mean '\".concat(loader.id, \".\").concat(key, \"'?\");\n      }\n      const lowerCaseKey = key.toLowerCase();\n      const isPartialMatch = lowerCaseOptionKey.startsWith(lowerCaseKey) || lowerCaseKey.startsWith(lowerCaseOptionKey);\n      if (isPartialMatch) {\n        bestSuggestion = bestSuggestion || \"Did you mean '\".concat(loader.id, \".\").concat(key, \"'?\");\n      }\n    }\n  }\n  return bestSuggestion;\n}\nfunction normalizeOptionsInternal(loader, options, url) {\n  const loaderDefaultOptions = loader.options || {};\n  const mergedOptions = {\n    ...loaderDefaultOptions\n  };\n  addUrlOptions(mergedOptions, url);\n  if (mergedOptions.log === null) {\n    mergedOptions.log = new _loggers__WEBPACK_IMPORTED_MODULE_2__.NullLog();\n  }\n  mergeNestedFields(mergedOptions, getGlobalLoaderOptions());\n  mergeNestedFields(mergedOptions, options);\n  return mergedOptions;\n}\nfunction mergeNestedFields(mergedOptions, options) {\n  for (const key in options) {\n    if (key in options) {\n      const value = options[key];\n      if ((0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_1__.isPureObject)(value) && (0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_1__.isPureObject)(mergedOptions[key])) {\n        mergedOptions[key] = {\n          ...mergedOptions[key],\n          ...options[key]\n        };\n      } else {\n        mergedOptions[key] = options[key];\n      }\n    }\n  }\n}\nfunction addUrlOptions(options, url) {\n  if (url && !('baseUri' in options)) {\n    options.baseUri = url;\n  }\n}\n//# sourceMappingURL=option-utils.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/core/dist/esm/lib/loader-utils/option-utils.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/core/dist/esm/lib/utils/log.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@loaders.gl/core/dist/esm/lib/utils/log.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   log: () => (/* binding */ log)\n/* harmony export */ });\n/* harmony import */ var _probe_gl_log__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @probe.gl/log */ \"./node_modules/@probe.gl/log/dist/esm/log.js\");\n\nconst log = new _probe_gl_log__WEBPACK_IMPORTED_MODULE_0__.Log({\n  id: 'loaders.gl'\n});\n//# sourceMappingURL=log.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/core/dist/esm/lib/utils/log.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/core/dist/esm/lib/utils/mime-type-utils.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/@loaders.gl/core/dist/esm/lib/utils/mime-type-utils.js ***!
  \*****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   parseMIMEType: () => (/* binding */ parseMIMEType),\n/* harmony export */   parseMIMETypeFromURL: () => (/* binding */ parseMIMETypeFromURL)\n/* harmony export */ });\nconst DATA_URL_PATTERN = /^data:([-\\w.]+\\/[-\\w.+]+)(;|,)/;\nconst MIME_TYPE_PATTERN = /^([-\\w.]+\\/[-\\w.+]+)/;\nfunction parseMIMEType(mimeString) {\n  const matches = MIME_TYPE_PATTERN.exec(mimeString);\n  if (matches) {\n    return matches[1];\n  }\n  return mimeString;\n}\nfunction parseMIMETypeFromURL(url) {\n  const matches = DATA_URL_PATTERN.exec(url);\n  if (matches) {\n    return matches[1];\n  }\n  return '';\n}\n//# sourceMappingURL=mime-type-utils.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/core/dist/esm/lib/utils/mime-type-utils.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/core/dist/esm/lib/utils/resource-utils.js":
/*!****************************************************************************!*\
  !*** ./node_modules/@loaders.gl/core/dist/esm/lib/utils/resource-utils.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getResourceContentLength: () => (/* binding */ getResourceContentLength),\n/* harmony export */   getResourceMIMEType: () => (/* binding */ getResourceMIMEType),\n/* harmony export */   getResourceUrl: () => (/* binding */ getResourceUrl)\n/* harmony export */ });\n/* harmony import */ var _javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../javascript-utils/is-type */ \"./node_modules/@loaders.gl/core/dist/esm/javascript-utils/is-type.js\");\n/* harmony import */ var _mime_type_utils__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./mime-type-utils */ \"./node_modules/@loaders.gl/core/dist/esm/lib/utils/mime-type-utils.js\");\n/* harmony import */ var _url_utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./url-utils */ \"./node_modules/@loaders.gl/core/dist/esm/lib/utils/url-utils.js\");\n\n\n\nfunction getResourceUrl(resource) {\n  if ((0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_0__.isResponse)(resource)) {\n    const response = resource;\n    return response.url;\n  }\n  if ((0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_0__.isBlob)(resource)) {\n    const blob = resource;\n    return blob.name || '';\n  }\n  if (typeof resource === 'string') {\n    return resource;\n  }\n  return '';\n}\nfunction getResourceMIMEType(resource) {\n  if ((0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_0__.isResponse)(resource)) {\n    const response = resource;\n    const contentTypeHeader = response.headers.get('content-type') || '';\n    const noQueryUrl = (0,_url_utils__WEBPACK_IMPORTED_MODULE_1__.stripQueryString)(response.url);\n    return (0,_mime_type_utils__WEBPACK_IMPORTED_MODULE_2__.parseMIMEType)(contentTypeHeader) || (0,_mime_type_utils__WEBPACK_IMPORTED_MODULE_2__.parseMIMETypeFromURL)(noQueryUrl);\n  }\n  if ((0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_0__.isBlob)(resource)) {\n    const blob = resource;\n    return blob.type || '';\n  }\n  if (typeof resource === 'string') {\n    return (0,_mime_type_utils__WEBPACK_IMPORTED_MODULE_2__.parseMIMETypeFromURL)(resource);\n  }\n  return '';\n}\nfunction getResourceContentLength(resource) {\n  if ((0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_0__.isResponse)(resource)) {\n    const response = resource;\n    return response.headers['content-length'] || -1;\n  }\n  if ((0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_0__.isBlob)(resource)) {\n    const blob = resource;\n    return blob.size;\n  }\n  if (typeof resource === 'string') {\n    return resource.length;\n  }\n  if (resource instanceof ArrayBuffer) {\n    return resource.byteLength;\n  }\n  if (ArrayBuffer.isView(resource)) {\n    return resource.byteLength;\n  }\n  return -1;\n}\n//# sourceMappingURL=resource-utils.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/core/dist/esm/lib/utils/resource-utils.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/core/dist/esm/lib/utils/response-utils.js":
/*!****************************************************************************!*\
  !*** ./node_modules/@loaders.gl/core/dist/esm/lib/utils/response-utils.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   checkResponse: () => (/* binding */ checkResponse),\n/* harmony export */   checkResponseSync: () => (/* binding */ checkResponseSync),\n/* harmony export */   makeResponse: () => (/* binding */ makeResponse)\n/* harmony export */ });\n/* harmony import */ var _javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../javascript-utils/is-type */ \"./node_modules/@loaders.gl/core/dist/esm/javascript-utils/is-type.js\");\n/* harmony import */ var _resource_utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./resource-utils */ \"./node_modules/@loaders.gl/core/dist/esm/lib/utils/resource-utils.js\");\n\n\nasync function makeResponse(resource) {\n  if ((0,_javascript_utils_is_type__WEBPACK_IMPORTED_MODULE_0__.isResponse)(resource)) {\n    return resource;\n  }\n  const headers = {};\n  const contentLength = (0,_resource_utils__WEBPACK_IMPORTED_MODULE_1__.getResourceContentLength)(resource);\n  if (contentLength >= 0) {\n    headers['content-length'] = String(contentLength);\n  }\n  const url = (0,_resource_utils__WEBPACK_IMPORTED_MODULE_1__.getResourceUrl)(resource);\n  const type = (0,_resource_utils__WEBPACK_IMPORTED_MODULE_1__.getResourceMIMEType)(resource);\n  if (type) {\n    headers['content-type'] = type;\n  }\n  const initialDataUrl = await getInitialDataUrl(resource);\n  if (initialDataUrl) {\n    headers['x-first-bytes'] = initialDataUrl;\n  }\n  if (typeof resource === 'string') {\n    resource = new TextEncoder().encode(resource);\n  }\n  const response = new Response(resource, {\n    headers\n  });\n  Object.defineProperty(response, 'url', {\n    value: url\n  });\n  return response;\n}\nasync function checkResponse(response) {\n  if (!response.ok) {\n    const message = await getResponseError(response);\n    throw new Error(message);\n  }\n}\nfunction checkResponseSync(response) {\n  if (!response.ok) {\n    let message = \"\".concat(response.status, \" \").concat(response.statusText);\n    message = message.length > 60 ? \"\".concat(message.slice(0, 60), \"...\") : message;\n    throw new Error(message);\n  }\n}\nasync function getResponseError(response) {\n  let message = \"Failed to fetch resource \".concat(response.url, \" (\").concat(response.status, \"): \");\n  try {\n    const contentType = response.headers.get('Content-Type');\n    let text = response.statusText;\n    if (contentType.includes('application/json')) {\n      text += \" \".concat(await response.text());\n    }\n    message += text;\n    message = message.length > 60 ? \"\".concat(message.slice(0, 60), \"...\") : message;\n  } catch (error) {}\n  return message;\n}\nasync function getInitialDataUrl(resource) {\n  const INITIAL_DATA_LENGTH = 5;\n  if (typeof resource === 'string') {\n    return \"data:,\".concat(resource.slice(0, INITIAL_DATA_LENGTH));\n  }\n  if (resource instanceof Blob) {\n    const blobSlice = resource.slice(0, 5);\n    return await new Promise(resolve => {\n      const reader = new FileReader();\n      reader.onload = event => {\n        var _event$target;\n        return resolve(event === null || event === void 0 ? void 0 : (_event$target = event.target) === null || _event$target === void 0 ? void 0 : _event$target.result);\n      };\n      reader.readAsDataURL(blobSlice);\n    });\n  }\n  if (resource instanceof ArrayBuffer) {\n    const slice = resource.slice(0, INITIAL_DATA_LENGTH);\n    const base64 = arrayBufferToBase64(slice);\n    return \"data:base64,\".concat(base64);\n  }\n  return null;\n}\nfunction arrayBufferToBase64(buffer) {\n  let binary = '';\n  const bytes = new Uint8Array(buffer);\n  for (let i = 0; i < bytes.byteLength; i++) {\n    binary += String.fromCharCode(bytes[i]);\n  }\n  return btoa(binary);\n}\n//# sourceMappingURL=response-utils.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/core/dist/esm/lib/utils/response-utils.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/core/dist/esm/lib/utils/url-utils.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@loaders.gl/core/dist/esm/lib/utils/url-utils.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   extractQueryString: () => (/* binding */ extractQueryString),\n/* harmony export */   stripQueryString: () => (/* binding */ stripQueryString)\n/* harmony export */ });\nconst QUERY_STRING_PATTERN = /\\?.*/;\nfunction extractQueryString(url) {\n  const matches = url.match(QUERY_STRING_PATTERN);\n  return matches && matches[0];\n}\nfunction stripQueryString(url) {\n  return url.replace(QUERY_STRING_PATTERN, '');\n}\n//# sourceMappingURL=url-utils.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/core/dist/esm/lib/utils/url-utils.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/images/dist/esm/image-loader.js":
/*!******************************************************************!*\
  !*** ./node_modules/@loaders.gl/images/dist/esm/image-loader.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   ImageLoader: () => (/* binding */ ImageLoader),\n/* harmony export */   _typecheckImageLoader: () => (/* binding */ _typecheckImageLoader)\n/* harmony export */ });\n/* harmony import */ var _lib_utils_version__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./lib/utils/version */ \"./node_modules/@loaders.gl/images/dist/esm/lib/utils/version.js\");\n/* harmony import */ var _lib_parsers_parse_image__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./lib/parsers/parse-image */ \"./node_modules/@loaders.gl/images/dist/esm/lib/parsers/parse-image.js\");\n/* harmony import */ var _lib_category_api_binary_image_api__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./lib/category-api/binary-image-api */ \"./node_modules/@loaders.gl/images/dist/esm/lib/category-api/binary-image-api.js\");\n\n\n\nconst EXTENSIONS = ['png', 'jpg', 'jpeg', 'gif', 'webp', 'bmp', 'ico', 'svg', 'avif'];\nconst MIME_TYPES = ['image/png', 'image/jpeg', 'image/gif', 'image/webp', 'image/avif', 'image/bmp', 'image/vnd.microsoft.icon', 'image/svg+xml'];\nconst DEFAULT_IMAGE_LOADER_OPTIONS = {\n  image: {\n    type: 'auto',\n    decode: true\n  }\n};\nconst ImageLoader = {\n  id: 'image',\n  module: 'images',\n  name: 'Images',\n  version: _lib_utils_version__WEBPACK_IMPORTED_MODULE_0__.VERSION,\n  mimeTypes: MIME_TYPES,\n  extensions: EXTENSIONS,\n  parse: _lib_parsers_parse_image__WEBPACK_IMPORTED_MODULE_1__.parseImage,\n  tests: [arrayBuffer => Boolean((0,_lib_category_api_binary_image_api__WEBPACK_IMPORTED_MODULE_2__.getBinaryImageMetadata)(new DataView(arrayBuffer)))],\n  options: DEFAULT_IMAGE_LOADER_OPTIONS\n};\nconst _typecheckImageLoader = ImageLoader;\n//# sourceMappingURL=image-loader.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/images/dist/esm/image-loader.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/images/dist/esm/lib/category-api/binary-image-api.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/@loaders.gl/images/dist/esm/lib/category-api/binary-image-api.js ***!
  \***************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getBinaryImageMetadata: () => (/* binding */ getBinaryImageMetadata),\n/* harmony export */   getBmpMetadata: () => (/* binding */ getBmpMetadata)\n/* harmony export */ });\n/* harmony import */ var _parse_isobmff_binary__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./parse-isobmff-binary */ \"./node_modules/@loaders.gl/images/dist/esm/lib/category-api/parse-isobmff-binary.js\");\n\nconst BIG_ENDIAN = false;\nconst LITTLE_ENDIAN = true;\nfunction getBinaryImageMetadata(binaryData) {\n  const dataView = toDataView(binaryData);\n  return getPngMetadata(dataView) || getJpegMetadata(dataView) || getGifMetadata(dataView) || getBmpMetadata(dataView) || getISOBMFFMetadata(dataView);\n}\nfunction getISOBMFFMetadata(binaryData) {\n  const buffer = new Uint8Array(binaryData instanceof DataView ? binaryData.buffer : binaryData);\n  const mediaType = (0,_parse_isobmff_binary__WEBPACK_IMPORTED_MODULE_0__.getISOBMFFMediaType)(buffer);\n  if (!mediaType) {\n    return null;\n  }\n  return {\n    mimeType: mediaType.mimeType,\n    width: 0,\n    height: 0\n  };\n}\nfunction getPngMetadata(binaryData) {\n  const dataView = toDataView(binaryData);\n  const isPng = dataView.byteLength >= 24 && dataView.getUint32(0, BIG_ENDIAN) === 0x89504e47;\n  if (!isPng) {\n    return null;\n  }\n  return {\n    mimeType: 'image/png',\n    width: dataView.getUint32(16, BIG_ENDIAN),\n    height: dataView.getUint32(20, BIG_ENDIAN)\n  };\n}\nfunction getGifMetadata(binaryData) {\n  const dataView = toDataView(binaryData);\n  const isGif = dataView.byteLength >= 10 && dataView.getUint32(0, BIG_ENDIAN) === 0x47494638;\n  if (!isGif) {\n    return null;\n  }\n  return {\n    mimeType: 'image/gif',\n    width: dataView.getUint16(6, LITTLE_ENDIAN),\n    height: dataView.getUint16(8, LITTLE_ENDIAN)\n  };\n}\nfunction getBmpMetadata(binaryData) {\n  const dataView = toDataView(binaryData);\n  const isBmp = dataView.byteLength >= 14 && dataView.getUint16(0, BIG_ENDIAN) === 0x424d && dataView.getUint32(2, LITTLE_ENDIAN) === dataView.byteLength;\n  if (!isBmp) {\n    return null;\n  }\n  return {\n    mimeType: 'image/bmp',\n    width: dataView.getUint32(18, LITTLE_ENDIAN),\n    height: dataView.getUint32(22, LITTLE_ENDIAN)\n  };\n}\nfunction getJpegMetadata(binaryData) {\n  const dataView = toDataView(binaryData);\n  const isJpeg = dataView.byteLength >= 3 && dataView.getUint16(0, BIG_ENDIAN) === 0xffd8 && dataView.getUint8(2) === 0xff;\n  if (!isJpeg) {\n    return null;\n  }\n  const {\n    tableMarkers,\n    sofMarkers\n  } = getJpegMarkers();\n  let i = 2;\n  while (i + 9 < dataView.byteLength) {\n    const marker = dataView.getUint16(i, BIG_ENDIAN);\n    if (sofMarkers.has(marker)) {\n      return {\n        mimeType: 'image/jpeg',\n        height: dataView.getUint16(i + 5, BIG_ENDIAN),\n        width: dataView.getUint16(i + 7, BIG_ENDIAN)\n      };\n    }\n    if (!tableMarkers.has(marker)) {\n      return null;\n    }\n    i += 2;\n    i += dataView.getUint16(i, BIG_ENDIAN);\n  }\n  return null;\n}\nfunction getJpegMarkers() {\n  const tableMarkers = new Set([0xffdb, 0xffc4, 0xffcc, 0xffdd, 0xfffe]);\n  for (let i = 0xffe0; i < 0xfff0; ++i) {\n    tableMarkers.add(i);\n  }\n  const sofMarkers = new Set([0xffc0, 0xffc1, 0xffc2, 0xffc3, 0xffc5, 0xffc6, 0xffc7, 0xffc9, 0xffca, 0xffcb, 0xffcd, 0xffce, 0xffcf, 0xffde]);\n  return {\n    tableMarkers,\n    sofMarkers\n  };\n}\nfunction toDataView(data) {\n  if (data instanceof DataView) {\n    return data;\n  }\n  if (ArrayBuffer.isView(data)) {\n    return new DataView(data.buffer);\n  }\n  if (data instanceof ArrayBuffer) {\n    return new DataView(data);\n  }\n  throw new Error('toDataView');\n}\n//# sourceMappingURL=binary-image-api.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/images/dist/esm/lib/category-api/binary-image-api.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/images/dist/esm/lib/category-api/image-type.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/@loaders.gl/images/dist/esm/lib/category-api/image-type.js ***!
  \*********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getDefaultImageType: () => (/* binding */ getDefaultImageType),\n/* harmony export */   isImageTypeSupported: () => (/* binding */ isImageTypeSupported)\n/* harmony export */ });\n/* harmony import */ var _loaders_gl_loader_utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @loaders.gl/loader-utils */ \"./node_modules/@loaders.gl/loader-utils/dist/esm/lib/env-utils/globals.js\");\n\nconst {\n  _parseImageNode\n} = globalThis;\nconst IMAGE_SUPPORTED = typeof Image !== 'undefined';\nconst IMAGE_BITMAP_SUPPORTED = typeof ImageBitmap !== 'undefined';\nconst NODE_IMAGE_SUPPORTED = Boolean(_parseImageNode);\nconst DATA_SUPPORTED = _loaders_gl_loader_utils__WEBPACK_IMPORTED_MODULE_0__.isBrowser ? true : NODE_IMAGE_SUPPORTED;\nfunction isImageTypeSupported(type) {\n  switch (type) {\n    case 'auto':\n      return IMAGE_BITMAP_SUPPORTED || IMAGE_SUPPORTED || DATA_SUPPORTED;\n    case 'imagebitmap':\n      return IMAGE_BITMAP_SUPPORTED;\n    case 'image':\n      return IMAGE_SUPPORTED;\n    case 'data':\n      return DATA_SUPPORTED;\n    default:\n      throw new Error(\"@loaders.gl/images: image \".concat(type, \" not supported in this environment\"));\n  }\n}\nfunction getDefaultImageType() {\n  if (IMAGE_BITMAP_SUPPORTED) {\n    return 'imagebitmap';\n  }\n  if (IMAGE_SUPPORTED) {\n    return 'image';\n  }\n  if (DATA_SUPPORTED) {\n    return 'data';\n  }\n  throw new Error('Install \\'@loaders.gl/polyfills\\' to parse images under Node.js');\n}\n//# sourceMappingURL=image-type.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/images/dist/esm/lib/category-api/image-type.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/images/dist/esm/lib/category-api/parse-isobmff-binary.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/@loaders.gl/images/dist/esm/lib/category-api/parse-isobmff-binary.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   decodeMajorBrand: () => (/* binding */ decodeMajorBrand),\n/* harmony export */   getISOBMFFMediaType: () => (/* binding */ getISOBMFFMediaType)\n/* harmony export */ });\nfunction getISOBMFFMediaType(buffer) {\n  if (!checkString(buffer, 'ftyp', 4)) {\n    return null;\n  }\n  if ((buffer[8] & 0x60) === 0x00) {\n    return null;\n  }\n  return decodeMajorBrand(buffer);\n}\nfunction decodeMajorBrand(buffer) {\n  const brandMajor = getUTF8String(buffer, 8, 12).replace('\\0', ' ').trim();\n  switch (brandMajor) {\n    case 'avif':\n    case 'avis':\n      return {\n        extension: 'avif',\n        mimeType: 'image/avif'\n      };\n    default:\n      return null;\n  }\n}\nfunction getUTF8String(array, start, end) {\n  return String.fromCharCode(...array.slice(start, end));\n}\nfunction stringToBytes(string) {\n  return [...string].map(character => character.charCodeAt(0));\n}\nfunction checkString(buffer, header) {\n  let offset = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n  const headerBytes = stringToBytes(header);\n  for (let i = 0; i < headerBytes.length; ++i) {\n    if (headerBytes[i] !== buffer[i + offset]) {\n      return false;\n    }\n  }\n  return true;\n}\n//# sourceMappingURL=parse-isobmff-binary.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/images/dist/esm/lib/category-api/parse-isobmff-binary.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/images/dist/esm/lib/category-api/parsed-image-api.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/@loaders.gl/images/dist/esm/lib/category-api/parsed-image-api.js ***!
  \***************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   deleteImage: () => (/* binding */ deleteImage),\n/* harmony export */   getImageData: () => (/* binding */ getImageData),\n/* harmony export */   getImageSize: () => (/* binding */ getImageSize),\n/* harmony export */   getImageType: () => (/* binding */ getImageType),\n/* harmony export */   isImage: () => (/* binding */ isImage)\n/* harmony export */ });\nfunction isImage(image) {\n  return Boolean(getImageTypeOrNull(image));\n}\nfunction deleteImage(image) {\n  switch (getImageType(image)) {\n    case 'imagebitmap':\n      image.close();\n      break;\n    default:\n  }\n}\nfunction getImageType(image) {\n  const format = getImageTypeOrNull(image);\n  if (!format) {\n    throw new Error('Not an image');\n  }\n  return format;\n}\nfunction getImageSize(image) {\n  return getImageData(image);\n}\nfunction getImageData(image) {\n  switch (getImageType(image)) {\n    case 'data':\n      return image;\n    case 'image':\n    case 'imagebitmap':\n      const canvas = document.createElement('canvas');\n      const context = canvas.getContext('2d');\n      if (!context) {\n        throw new Error('getImageData');\n      }\n      canvas.width = image.width;\n      canvas.height = image.height;\n      context.drawImage(image, 0, 0);\n      return context.getImageData(0, 0, image.width, image.height);\n    default:\n      throw new Error('getImageData');\n  }\n}\nfunction getImageTypeOrNull(image) {\n  if (typeof ImageBitmap !== 'undefined' && image instanceof ImageBitmap) {\n    return 'imagebitmap';\n  }\n  if (typeof Image !== 'undefined' && image instanceof Image) {\n    return 'image';\n  }\n  if (image && typeof image === 'object' && image.data && image.width && image.height) {\n    return 'data';\n  }\n  return null;\n}\n//# sourceMappingURL=parsed-image-api.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/images/dist/esm/lib/category-api/parsed-image-api.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/images/dist/esm/lib/parsers/parse-image.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/@loaders.gl/images/dist/esm/lib/parsers/parse-image.js ***!
  \*****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   parseImage: () => (/* binding */ parseImage)\n/* harmony export */ });\n/* harmony import */ var _loaders_gl_loader_utils__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! @loaders.gl/loader-utils */ \"./node_modules/@loaders.gl/loader-utils/dist/esm/lib/env-utils/assert.js\");\n/* harmony import */ var _category_api_image_type__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../category-api/image-type */ \"./node_modules/@loaders.gl/images/dist/esm/lib/category-api/image-type.js\");\n/* harmony import */ var _category_api_parsed_image_api__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../category-api/parsed-image-api */ \"./node_modules/@loaders.gl/images/dist/esm/lib/category-api/parsed-image-api.js\");\n/* harmony import */ var _parse_to_image__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./parse-to-image */ \"./node_modules/@loaders.gl/images/dist/esm/lib/parsers/parse-to-image.js\");\n/* harmony import */ var _parse_to_image_bitmap__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./parse-to-image-bitmap */ \"./node_modules/@loaders.gl/images/dist/esm/lib/parsers/parse-to-image-bitmap.js\");\n/* harmony import */ var _parse_to_node_image__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./parse-to-node-image */ \"./node_modules/@loaders.gl/images/dist/esm/lib/parsers/parse-to-node-image.js\");\n\n\n\n\n\n\nasync function parseImage(arrayBuffer, options, context) {\n  options = options || {};\n  const imageOptions = options.image || {};\n  const imageType = imageOptions.type || 'auto';\n  const {\n    url\n  } = context || {};\n  const loadType = getLoadableImageType(imageType);\n  let image;\n  switch (loadType) {\n    case 'imagebitmap':\n      image = await (0,_parse_to_image_bitmap__WEBPACK_IMPORTED_MODULE_0__.parseToImageBitmap)(arrayBuffer, options, url);\n      break;\n    case 'image':\n      image = await (0,_parse_to_image__WEBPACK_IMPORTED_MODULE_1__.parseToImage)(arrayBuffer, options, url);\n      break;\n    case 'data':\n      image = await (0,_parse_to_node_image__WEBPACK_IMPORTED_MODULE_2__.parseToNodeImage)(arrayBuffer, options);\n      break;\n    default:\n      (0,_loaders_gl_loader_utils__WEBPACK_IMPORTED_MODULE_3__.assert)(false);\n  }\n  if (imageType === 'data') {\n    image = (0,_category_api_parsed_image_api__WEBPACK_IMPORTED_MODULE_4__.getImageData)(image);\n  }\n  return image;\n}\nfunction getLoadableImageType(type) {\n  switch (type) {\n    case 'auto':\n    case 'data':\n      return (0,_category_api_image_type__WEBPACK_IMPORTED_MODULE_5__.getDefaultImageType)();\n    default:\n      (0,_category_api_image_type__WEBPACK_IMPORTED_MODULE_5__.isImageTypeSupported)(type);\n      return type;\n  }\n}\n//# sourceMappingURL=parse-image.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/images/dist/esm/lib/parsers/parse-image.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/images/dist/esm/lib/parsers/parse-to-image-bitmap.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/@loaders.gl/images/dist/esm/lib/parsers/parse-to-image-bitmap.js ***!
  \***************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   parseToImageBitmap: () => (/* binding */ parseToImageBitmap)\n/* harmony export */ });\n/* harmony import */ var _svg_utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./svg-utils */ \"./node_modules/@loaders.gl/images/dist/esm/lib/parsers/svg-utils.js\");\n/* harmony import */ var _parse_to_image__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./parse-to-image */ \"./node_modules/@loaders.gl/images/dist/esm/lib/parsers/parse-to-image.js\");\n\n\nconst EMPTY_OBJECT = {};\nlet imagebitmapOptionsSupported = true;\nasync function parseToImageBitmap(arrayBuffer, options, url) {\n  let blob;\n  if ((0,_svg_utils__WEBPACK_IMPORTED_MODULE_0__.isSVG)(url)) {\n    const image = await (0,_parse_to_image__WEBPACK_IMPORTED_MODULE_1__.parseToImage)(arrayBuffer, options, url);\n    blob = image;\n  } else {\n    blob = (0,_svg_utils__WEBPACK_IMPORTED_MODULE_0__.getBlob)(arrayBuffer, url);\n  }\n  const imagebitmapOptions = options && options.imagebitmap;\n  return await safeCreateImageBitmap(blob, imagebitmapOptions);\n}\nasync function safeCreateImageBitmap(blob) {\n  let imagebitmapOptions = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n  if (isEmptyObject(imagebitmapOptions) || !imagebitmapOptionsSupported) {\n    imagebitmapOptions = null;\n  }\n  if (imagebitmapOptions) {\n    try {\n      return await createImageBitmap(blob, imagebitmapOptions);\n    } catch (error) {\n      console.warn(error);\n      imagebitmapOptionsSupported = false;\n    }\n  }\n  return await createImageBitmap(blob);\n}\nfunction isEmptyObject(object) {\n  for (const key in object || EMPTY_OBJECT) {\n    return false;\n  }\n  return true;\n}\n//# sourceMappingURL=parse-to-image-bitmap.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/images/dist/esm/lib/parsers/parse-to-image-bitmap.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/images/dist/esm/lib/parsers/parse-to-image.js":
/*!********************************************************************************!*\
  !*** ./node_modules/@loaders.gl/images/dist/esm/lib/parsers/parse-to-image.js ***!
  \********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   loadToImage: () => (/* binding */ loadToImage),\n/* harmony export */   parseToImage: () => (/* binding */ parseToImage)\n/* harmony export */ });\n/* harmony import */ var _svg_utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./svg-utils */ \"./node_modules/@loaders.gl/images/dist/esm/lib/parsers/svg-utils.js\");\n\nasync function parseToImage(arrayBuffer, options, url) {\n  const blobOrDataUrl = (0,_svg_utils__WEBPACK_IMPORTED_MODULE_0__.getBlobOrSVGDataUrl)(arrayBuffer, url);\n  const URL = self.URL || self.webkitURL;\n  const objectUrl = typeof blobOrDataUrl !== 'string' && URL.createObjectURL(blobOrDataUrl);\n  try {\n    return await loadToImage(objectUrl || blobOrDataUrl, options);\n  } finally {\n    if (objectUrl) {\n      URL.revokeObjectURL(objectUrl);\n    }\n  }\n}\nasync function loadToImage(url, options) {\n  const image = new Image();\n  image.src = url;\n  if (options.image && options.image.decode && image.decode) {\n    await image.decode();\n    return image;\n  }\n  return await new Promise((resolve, reject) => {\n    try {\n      image.onload = () => resolve(image);\n      image.onerror = err => reject(new Error(\"Could not load image \".concat(url, \": \").concat(err)));\n    } catch (error) {\n      reject(error);\n    }\n  });\n}\n//# sourceMappingURL=parse-to-image.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/images/dist/esm/lib/parsers/parse-to-image.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/images/dist/esm/lib/parsers/parse-to-node-image.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/@loaders.gl/images/dist/esm/lib/parsers/parse-to-node-image.js ***!
  \*************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   parseToNodeImage: () => (/* binding */ parseToNodeImage)\n/* harmony export */ });\n/* harmony import */ var _loaders_gl_loader_utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @loaders.gl/loader-utils */ \"./node_modules/@loaders.gl/loader-utils/dist/esm/lib/env-utils/assert.js\");\n/* harmony import */ var _category_api_binary_image_api__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../category-api/binary-image-api */ \"./node_modules/@loaders.gl/images/dist/esm/lib/category-api/binary-image-api.js\");\n\n\nasync function parseToNodeImage(arrayBuffer, options) {\n  const {\n    mimeType\n  } = (0,_category_api_binary_image_api__WEBPACK_IMPORTED_MODULE_0__.getBinaryImageMetadata)(arrayBuffer) || {};\n  const _parseImageNode = globalThis._parseImageNode;\n  (0,_loaders_gl_loader_utils__WEBPACK_IMPORTED_MODULE_1__.assert)(_parseImageNode);\n  return await _parseImageNode(arrayBuffer, mimeType);\n}\n//# sourceMappingURL=parse-to-node-image.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/images/dist/esm/lib/parsers/parse-to-node-image.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/images/dist/esm/lib/parsers/svg-utils.js":
/*!***************************************************************************!*\
  !*** ./node_modules/@loaders.gl/images/dist/esm/lib/parsers/svg-utils.js ***!
  \***************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getBlob: () => (/* binding */ getBlob),\n/* harmony export */   getBlobOrSVGDataUrl: () => (/* binding */ getBlobOrSVGDataUrl),\n/* harmony export */   isSVG: () => (/* binding */ isSVG)\n/* harmony export */ });\nconst SVG_DATA_URL_PATTERN = /^data:image\\/svg\\+xml/;\nconst SVG_URL_PATTERN = /\\.svg((\\?|#).*)?$/;\nfunction isSVG(url) {\n  return url && (SVG_DATA_URL_PATTERN.test(url) || SVG_URL_PATTERN.test(url));\n}\nfunction getBlobOrSVGDataUrl(arrayBuffer, url) {\n  if (isSVG(url)) {\n    const textDecoder = new TextDecoder();\n    let xmlText = textDecoder.decode(arrayBuffer);\n    try {\n      if (typeof unescape === 'function' && typeof encodeURIComponent === 'function') {\n        xmlText = unescape(encodeURIComponent(xmlText));\n      }\n    } catch (error) {\n      throw new Error(error.message);\n    }\n    const src = \"data:image/svg+xml;base64,\".concat(btoa(xmlText));\n    return src;\n  }\n  return getBlob(arrayBuffer, url);\n}\nfunction getBlob(arrayBuffer, url) {\n  if (isSVG(url)) {\n    throw new Error('SVG cannot be parsed directly to imagebitmap');\n  }\n  return new Blob([new Uint8Array(arrayBuffer)]);\n}\n//# sourceMappingURL=svg-utils.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/images/dist/esm/lib/parsers/svg-utils.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/images/dist/esm/lib/utils/version.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@loaders.gl/images/dist/esm/lib/utils/version.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   VERSION: () => (/* binding */ VERSION)\n/* harmony export */ });\nconst VERSION =  true ? \"3.4.15\" : 0;\n//# sourceMappingURL=version.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/images/dist/esm/lib/utils/version.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/loader-utils/dist/esm/lib/binary-utils/array-buffer-utils.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/@loaders.gl/loader-utils/dist/esm/lib/binary-utils/array-buffer-utils.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   compareArrayBuffers: () => (/* binding */ compareArrayBuffers),\n/* harmony export */   concatenateArrayBuffers: () => (/* binding */ concatenateArrayBuffers),\n/* harmony export */   concatenateTypedArrays: () => (/* binding */ concatenateTypedArrays),\n/* harmony export */   sliceArrayBuffer: () => (/* binding */ sliceArrayBuffer)\n/* harmony export */ });\nfunction compareArrayBuffers(arrayBuffer1, arrayBuffer2, byteLength) {\n  byteLength = byteLength || arrayBuffer1.byteLength;\n  if (arrayBuffer1.byteLength < byteLength || arrayBuffer2.byteLength < byteLength) {\n    return false;\n  }\n  const array1 = new Uint8Array(arrayBuffer1);\n  const array2 = new Uint8Array(arrayBuffer2);\n  for (let i = 0; i < array1.length; ++i) {\n    if (array1[i] !== array2[i]) {\n      return false;\n    }\n  }\n  return true;\n}\nfunction concatenateArrayBuffers() {\n  for (var _len = arguments.length, sources = new Array(_len), _key = 0; _key < _len; _key++) {\n    sources[_key] = arguments[_key];\n  }\n  const sourceArrays = sources.map(source2 => source2 instanceof ArrayBuffer ? new Uint8Array(source2) : source2);\n  const byteLength = sourceArrays.reduce((length, typedArray) => length + typedArray.byteLength, 0);\n  const result = new Uint8Array(byteLength);\n  let offset = 0;\n  for (const sourceArray of sourceArrays) {\n    result.set(sourceArray, offset);\n    offset += sourceArray.byteLength;\n  }\n  return result.buffer;\n}\nfunction concatenateTypedArrays() {\n  for (var _len2 = arguments.length, typedArrays = new Array(_len2), _key2 = 0; _key2 < _len2; _key2++) {\n    typedArrays[_key2] = arguments[_key2];\n  }\n  const arrays = typedArrays;\n  const TypedArrayConstructor = arrays && arrays.length > 1 && arrays[0].constructor || null;\n  if (!TypedArrayConstructor) {\n    throw new Error('\"concatenateTypedArrays\" - incorrect quantity of arguments or arguments have incompatible data types');\n  }\n  const sumLength = arrays.reduce((acc, value) => acc + value.length, 0);\n  const result = new TypedArrayConstructor(sumLength);\n  let offset = 0;\n  for (const array of arrays) {\n    result.set(array, offset);\n    offset += array.length;\n  }\n  return result;\n}\nfunction sliceArrayBuffer(arrayBuffer, byteOffset, byteLength) {\n  const subArray = byteLength !== undefined ? new Uint8Array(arrayBuffer).subarray(byteOffset, byteOffset + byteLength) : new Uint8Array(arrayBuffer).subarray(byteOffset);\n  const arrayCopy = new Uint8Array(subArray);\n  return arrayCopy.buffer;\n}\n//# sourceMappingURL=array-buffer-utils.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/loader-utils/dist/esm/lib/binary-utils/array-buffer-utils.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/loader-utils/dist/esm/lib/binary-utils/memory-conversion-utils.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/@loaders.gl/loader-utils/dist/esm/lib/binary-utils/memory-conversion-utils.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   isBuffer: () => (/* binding */ isBuffer),\n/* harmony export */   toArrayBuffer: () => (/* binding */ toArrayBuffer),\n/* harmony export */   toBuffer: () => (/* binding */ toBuffer)\n/* harmony export */ });\n/* harmony import */ var _node_buffer__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../node/buffer */ \"./node_modules/@loaders.gl/loader-utils/dist/esm/lib/node/buffer.browser.js\");\n\nfunction isBuffer(value) {\n  return value && typeof value === 'object' && value.isBuffer;\n}\nfunction toBuffer(data) {\n  return _node_buffer__WEBPACK_IMPORTED_MODULE_0__.toBuffer ? _node_buffer__WEBPACK_IMPORTED_MODULE_0__.toBuffer(data) : data;\n}\nfunction toArrayBuffer(data) {\n  if (isBuffer(data)) {\n    return _node_buffer__WEBPACK_IMPORTED_MODULE_0__.toArrayBuffer(data);\n  }\n  if (data instanceof ArrayBuffer) {\n    return data;\n  }\n  if (ArrayBuffer.isView(data)) {\n    if (data.byteOffset === 0 && data.byteLength === data.buffer.byteLength) {\n      return data.buffer;\n    }\n    return data.buffer.slice(data.byteOffset, data.byteOffset + data.byteLength);\n  }\n  if (typeof data === 'string') {\n    const text = data;\n    const uint8Array = new TextEncoder().encode(text);\n    return uint8Array.buffer;\n  }\n  if (data && typeof data === 'object' && data._toArrayBuffer) {\n    return data._toArrayBuffer();\n  }\n  throw new Error('toArrayBuffer');\n}\n//# sourceMappingURL=memory-conversion-utils.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/loader-utils/dist/esm/lib/binary-utils/memory-conversion-utils.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/loader-utils/dist/esm/lib/env-utils/assert.js":
/*!********************************************************************************!*\
  !*** ./node_modules/@loaders.gl/loader-utils/dist/esm/lib/env-utils/assert.js ***!
  \********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   assert: () => (/* binding */ assert)\n/* harmony export */ });\nfunction assert(condition, message) {\n  if (!condition) {\n    throw new Error(message || 'loader assertion failed.');\n  }\n}\n//# sourceMappingURL=assert.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/loader-utils/dist/esm/lib/env-utils/assert.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/loader-utils/dist/esm/lib/env-utils/globals.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/@loaders.gl/loader-utils/dist/esm/lib/env-utils/globals.js ***!
  \*********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   document: () => (/* binding */ document_),\n/* harmony export */   global: () => (/* binding */ global_),\n/* harmony export */   isBrowser: () => (/* binding */ isBrowser),\n/* harmony export */   isWorker: () => (/* binding */ isWorker),\n/* harmony export */   nodeVersion: () => (/* binding */ nodeVersion),\n/* harmony export */   self: () => (/* binding */ self_),\n/* harmony export */   window: () => (/* binding */ window_)\n/* harmony export */ });\nconst globals = {\n  self: typeof self !== 'undefined' && self,\n  window: typeof window !== 'undefined' && window,\n  global: typeof __webpack_require__.g !== 'undefined' && __webpack_require__.g,\n  document: typeof document !== 'undefined' && document\n};\nconst self_ = globals.self || globals.window || globals.global || {};\nconst window_ = globals.window || globals.self || globals.global || {};\nconst global_ = globals.global || globals.self || globals.window || {};\nconst document_ = globals.document || {};\n\nconst isBrowser = Boolean(typeof process !== 'object' || String(process) !== '[object process]' || process.browser);\nconst isWorker = typeof importScripts === 'function';\nconst matches = typeof process !== 'undefined' && process.version && /v([0-9]*)/.exec(process.version);\nconst nodeVersion = matches && parseFloat(matches[1]) || 0;\n//# sourceMappingURL=globals.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/loader-utils/dist/esm/lib/env-utils/globals.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/loader-utils/dist/esm/lib/iterators/async-iteration.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/@loaders.gl/loader-utils/dist/esm/lib/iterators/async-iteration.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   concatenateArrayBuffersAsync: () => (/* binding */ concatenateArrayBuffersAsync),\n/* harmony export */   concatenateStringsAsync: () => (/* binding */ concatenateStringsAsync),\n/* harmony export */   forEach: () => (/* binding */ forEach)\n/* harmony export */ });\n/* harmony import */ var _binary_utils_array_buffer_utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../binary-utils/array-buffer-utils */ \"./node_modules/@loaders.gl/loader-utils/dist/esm/lib/binary-utils/array-buffer-utils.js\");\n\nasync function forEach(iterator, visitor) {\n  while (true) {\n    const {\n      done,\n      value\n    } = await iterator.next();\n    if (done) {\n      iterator.return();\n      return;\n    }\n    const cancel = visitor(value);\n    if (cancel) {\n      return;\n    }\n  }\n}\nasync function concatenateArrayBuffersAsync(asyncIterator) {\n  const arrayBuffers = [];\n  for await (const chunk of asyncIterator) {\n    arrayBuffers.push(chunk);\n  }\n  return (0,_binary_utils_array_buffer_utils__WEBPACK_IMPORTED_MODULE_0__.concatenateArrayBuffers)(...arrayBuffers);\n}\nasync function concatenateStringsAsync(asyncIterator) {\n  const strings = [];\n  for await (const chunk of asyncIterator) {\n    strings.push(chunk);\n  }\n  return strings.join('');\n}\n//# sourceMappingURL=async-iteration.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/loader-utils/dist/esm/lib/iterators/async-iteration.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/loader-utils/dist/esm/lib/node/buffer.browser.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/@loaders.gl/loader-utils/dist/esm/lib/node/buffer.browser.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   toArrayBuffer: () => (/* binding */ toArrayBuffer),\n/* harmony export */   toBuffer: () => (/* binding */ toBuffer)\n/* harmony export */ });\nfunction toArrayBuffer(buffer) {\n  return buffer;\n}\nfunction toBuffer(binaryData) {\n  throw new Error('Buffer not supported in browser');\n}\n//# sourceMappingURL=buffer.browser.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/loader-utils/dist/esm/lib/node/buffer.browser.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/loader-utils/dist/esm/lib/path-utils/file-aliases.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/@loaders.gl/loader-utils/dist/esm/lib/path-utils/file-aliases.js ***!
  \***************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   addAliases: () => (/* binding */ addAliases),\n/* harmony export */   getPathPrefix: () => (/* binding */ getPathPrefix),\n/* harmony export */   resolvePath: () => (/* binding */ resolvePath),\n/* harmony export */   setPathPrefix: () => (/* binding */ setPathPrefix)\n/* harmony export */ });\nlet pathPrefix = '';\nconst fileAliases = {};\nfunction setPathPrefix(prefix) {\n  pathPrefix = prefix;\n}\nfunction getPathPrefix() {\n  return pathPrefix;\n}\nfunction addAliases(aliases) {\n  Object.assign(fileAliases, aliases);\n}\nfunction resolvePath(filename) {\n  for (const alias in fileAliases) {\n    if (filename.startsWith(alias)) {\n      const replacement = fileAliases[alias];\n      filename = filename.replace(alias, replacement);\n    }\n  }\n  if (!filename.startsWith('http://') && !filename.startsWith('https://')) {\n    filename = \"\".concat(pathPrefix).concat(filename);\n  }\n  return filename;\n}\n//# sourceMappingURL=file-aliases.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/loader-utils/dist/esm/lib/path-utils/file-aliases.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/loader-utils/dist/esm/lib/path-utils/get-cwd.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/@loaders.gl/loader-utils/dist/esm/lib/path-utils/get-cwd.js ***!
  \**********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getCWD: () => (/* binding */ getCWD)\n/* harmony export */ });\nfunction getCWD() {\n  var _window$location;\n  if (typeof process !== 'undefined' && typeof process.cwd !== 'undefined') {\n    return process.cwd();\n  }\n  const pathname = (_window$location = window.location) === null || _window$location === void 0 ? void 0 : _window$location.pathname;\n  return (pathname === null || pathname === void 0 ? void 0 : pathname.slice(0, pathname.lastIndexOf('/') + 1)) || '';\n}\n//# sourceMappingURL=get-cwd.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/loader-utils/dist/esm/lib/path-utils/get-cwd.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/loader-utils/dist/esm/lib/path-utils/path.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/@loaders.gl/loader-utils/dist/esm/lib/path-utils/path.js ***!
  \*******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   dirname: () => (/* binding */ dirname),\n/* harmony export */   filename: () => (/* binding */ filename),\n/* harmony export */   join: () => (/* binding */ join),\n/* harmony export */   resolve: () => (/* binding */ resolve)\n/* harmony export */ });\n/* harmony import */ var _get_cwd__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./get-cwd */ \"./node_modules/@loaders.gl/loader-utils/dist/esm/lib/path-utils/get-cwd.js\");\n\nfunction filename(url) {\n  const slashIndex = url ? url.lastIndexOf('/') : -1;\n  return slashIndex >= 0 ? url.substr(slashIndex + 1) : '';\n}\nfunction dirname(url) {\n  const slashIndex = url ? url.lastIndexOf('/') : -1;\n  return slashIndex >= 0 ? url.substr(0, slashIndex) : '';\n}\nfunction join() {\n  for (var _len = arguments.length, parts = new Array(_len), _key = 0; _key < _len; _key++) {\n    parts[_key] = arguments[_key];\n  }\n  const separator = '/';\n  parts = parts.map((part, index) => {\n    if (index) {\n      part = part.replace(new RegExp(\"^\".concat(separator)), '');\n    }\n    if (index !== parts.length - 1) {\n      part = part.replace(new RegExp(\"\".concat(separator, \"$\")), '');\n    }\n    return part;\n  });\n  return parts.join(separator);\n}\nfunction resolve() {\n  const paths = [];\n  for (let _i = 0; _i < arguments.length; _i++) {\n    paths[_i] = _i < 0 || arguments.length <= _i ? undefined : arguments[_i];\n  }\n  let resolvedPath = '';\n  let resolvedAbsolute = false;\n  let cwd;\n  for (let i = paths.length - 1; i >= -1 && !resolvedAbsolute; i--) {\n    let path;\n    if (i >= 0) {\n      path = paths[i];\n    } else {\n      if (cwd === undefined) {\n        cwd = (0,_get_cwd__WEBPACK_IMPORTED_MODULE_0__.getCWD)();\n      }\n      path = cwd;\n    }\n    if (path.length === 0) {\n      continue;\n    }\n    resolvedPath = \"\".concat(path, \"/\").concat(resolvedPath);\n    resolvedAbsolute = path.charCodeAt(0) === SLASH;\n  }\n  resolvedPath = normalizeStringPosix(resolvedPath, !resolvedAbsolute);\n  if (resolvedAbsolute) {\n    return \"/\".concat(resolvedPath);\n  } else if (resolvedPath.length > 0) {\n    return resolvedPath;\n  }\n  return '.';\n}\nconst SLASH = 47;\nconst DOT = 46;\nfunction normalizeStringPosix(path, allowAboveRoot) {\n  let res = '';\n  let lastSlash = -1;\n  let dots = 0;\n  let code;\n  let isAboveRoot = false;\n  for (let i = 0; i <= path.length; ++i) {\n    if (i < path.length) {\n      code = path.charCodeAt(i);\n    } else if (code === SLASH) {\n      break;\n    } else {\n      code = SLASH;\n    }\n    if (code === SLASH) {\n      if (lastSlash === i - 1 || dots === 1) {} else if (lastSlash !== i - 1 && dots === 2) {\n        if (res.length < 2 || !isAboveRoot || res.charCodeAt(res.length - 1) !== DOT || res.charCodeAt(res.length - 2) !== DOT) {\n          if (res.length > 2) {\n            const start = res.length - 1;\n            let j = start;\n            for (; j >= 0; --j) {\n              if (res.charCodeAt(j) === SLASH) {\n                break;\n              }\n            }\n            if (j !== start) {\n              res = j === -1 ? '' : res.slice(0, j);\n              lastSlash = i;\n              dots = 0;\n              isAboveRoot = false;\n              continue;\n            }\n          } else if (res.length === 2 || res.length === 1) {\n            res = '';\n            lastSlash = i;\n            dots = 0;\n            isAboveRoot = false;\n            continue;\n          }\n        }\n        if (allowAboveRoot) {\n          if (res.length > 0) {\n            res += '/..';\n          } else {\n            res = '..';\n          }\n          isAboveRoot = true;\n        }\n      } else {\n        const slice = path.slice(lastSlash + 1, i);\n        if (res.length > 0) {\n          res += \"/\".concat(slice);\n        } else {\n          res = slice;\n        }\n        isAboveRoot = false;\n      }\n      lastSlash = i;\n      dots = 0;\n    } else if (code === DOT && dots !== -1) {\n      ++dots;\n    } else {\n      dots = -1;\n    }\n  }\n  return res;\n}\n//# sourceMappingURL=path.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/loader-utils/dist/esm/lib/path-utils/path.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/loader-utils/dist/esm/lib/worker-loader-utils/parse-with-worker.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/@loaders.gl/loader-utils/dist/esm/lib/worker-loader-utils/parse-with-worker.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   canParseWithWorker: () => (/* binding */ canParseWithWorker),\n/* harmony export */   parseWithWorker: () => (/* binding */ parseWithWorker)\n/* harmony export */ });\n/* harmony import */ var _loaders_gl_worker_utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @loaders.gl/worker-utils */ \"./node_modules/@loaders.gl/worker-utils/dist/esm/lib/env-utils/globals.js\");\n/* harmony import */ var _loaders_gl_worker_utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @loaders.gl/worker-utils */ \"./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-farm/worker-farm.js\");\n/* harmony import */ var _loaders_gl_worker_utils__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @loaders.gl/worker-utils */ \"./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-api/get-worker-url.js\");\n\n\nfunction canParseWithWorker(loader, options) {\n  if (!_loaders_gl_worker_utils__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isSupported()) {\n    return false;\n  }\n  if (!_loaders_gl_worker_utils__WEBPACK_IMPORTED_MODULE_1__.isBrowser && !(options !== null && options !== void 0 && options._nodeWorkers)) {\n    return false;\n  }\n  return loader.worker && (options === null || options === void 0 ? void 0 : options.worker);\n}\nasync function parseWithWorker(loader, data, options, context, parseOnMainThread) {\n  const name = loader.id;\n  const url = (0,_loaders_gl_worker_utils__WEBPACK_IMPORTED_MODULE_2__.getWorkerURL)(loader, options);\n  const workerFarm = _loaders_gl_worker_utils__WEBPACK_IMPORTED_MODULE_0__[\"default\"].getWorkerFarm(options);\n  const workerPool = workerFarm.getWorkerPool({\n    name,\n    url\n  });\n  options = JSON.parse(JSON.stringify(options));\n  context = JSON.parse(JSON.stringify(context || {}));\n  const job = await workerPool.startJob('process-on-worker', onMessage.bind(null, parseOnMainThread));\n  job.postMessage('process', {\n    input: data,\n    options,\n    context\n  });\n  const result = await job.result;\n  return await result.result;\n}\nasync function onMessage(parseOnMainThread, job, type, payload) {\n  switch (type) {\n    case 'done':\n      job.done(payload);\n      break;\n    case 'error':\n      job.error(new Error(payload.error));\n      break;\n    case 'process':\n      const {\n        id,\n        input,\n        options\n      } = payload;\n      try {\n        const result = await parseOnMainThread(input, options);\n        job.postMessage('done', {\n          id,\n          result\n        });\n      } catch (error) {\n        const message = error instanceof Error ? error.message : 'unknown error';\n        job.postMessage('error', {\n          id,\n          error: message\n        });\n      }\n      break;\n    default:\n      console.warn(\"parse-with-worker unknown message \".concat(type));\n  }\n}\n//# sourceMappingURL=parse-with-worker.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/loader-utils/dist/esm/lib/worker-loader-utils/parse-with-worker.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/worker-utils/dist/esm/lib/env-utils/assert.js":
/*!********************************************************************************!*\
  !*** ./node_modules/@loaders.gl/worker-utils/dist/esm/lib/env-utils/assert.js ***!
  \********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   assert: () => (/* binding */ assert)\n/* harmony export */ });\nfunction assert(condition, message) {\n  if (!condition) {\n    throw new Error(message || 'loaders.gl assertion failed.');\n  }\n}\n//# sourceMappingURL=assert.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/worker-utils/dist/esm/lib/env-utils/assert.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/worker-utils/dist/esm/lib/env-utils/globals.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/@loaders.gl/worker-utils/dist/esm/lib/env-utils/globals.js ***!
  \*********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   document: () => (/* binding */ document_),\n/* harmony export */   global: () => (/* binding */ global_),\n/* harmony export */   isBrowser: () => (/* binding */ isBrowser),\n/* harmony export */   isMobile: () => (/* binding */ isMobile),\n/* harmony export */   isWorker: () => (/* binding */ isWorker),\n/* harmony export */   nodeVersion: () => (/* binding */ nodeVersion),\n/* harmony export */   self: () => (/* binding */ self_),\n/* harmony export */   window: () => (/* binding */ window_)\n/* harmony export */ });\nconst globals = {\n  self: typeof self !== 'undefined' && self,\n  window: typeof window !== 'undefined' && window,\n  global: typeof __webpack_require__.g !== 'undefined' && __webpack_require__.g,\n  document: typeof document !== 'undefined' && document\n};\nconst self_ = globals.self || globals.window || globals.global || {};\nconst window_ = globals.window || globals.self || globals.global || {};\nconst global_ = globals.global || globals.self || globals.window || {};\nconst document_ = globals.document || {};\n\nconst isBrowser = typeof process !== 'object' || String(process) !== '[object process]' || process.browser;\nconst isWorker = typeof importScripts === 'function';\nconst isMobile = typeof window !== 'undefined' && typeof window.orientation !== 'undefined';\nconst matches = typeof process !== 'undefined' && process.version && /v([0-9]*)/.exec(process.version);\nconst nodeVersion = matches && parseFloat(matches[1]) || 0;\n//# sourceMappingURL=globals.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/worker-utils/dist/esm/lib/env-utils/globals.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/worker-utils/dist/esm/lib/env-utils/version.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/@loaders.gl/worker-utils/dist/esm/lib/env-utils/version.js ***!
  \*********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   VERSION: () => (/* binding */ VERSION)\n/* harmony export */ });\nconst DEFAULT_VERSION = 'latest';\nconst VERSION =  true ? \"3.4.15\" : 0;\nif (false) {}\n//# sourceMappingURL=version.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/worker-utils/dist/esm/lib/env-utils/version.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/worker-utils/dist/esm/lib/node/worker_threads-browser.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/@loaders.gl/worker-utils/dist/esm/lib/node/worker_threads-browser.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   NodeWorker: () => (/* binding */ Worker),\n/* harmony export */   NodeWorkerType: () => (/* binding */ Worker),\n/* harmony export */   Worker: () => (/* binding */ Worker),\n/* harmony export */   parentPort: () => (/* binding */ parentPort)\n/* harmony export */ });\nclass Worker {\n  terminate() {}\n}\n\n\nconst parentPort = null;\n//# sourceMappingURL=worker_threads-browser.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/worker-utils/dist/esm/lib/node/worker_threads-browser.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-api/get-worker-url.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-api/get-worker-url.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getWorkerName: () => (/* binding */ getWorkerName),\n/* harmony export */   getWorkerURL: () => (/* binding */ getWorkerURL)\n/* harmony export */ });\n/* harmony import */ var _env_utils_assert__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../env-utils/assert */ \"./node_modules/@loaders.gl/worker-utils/dist/esm/lib/env-utils/assert.js\");\n\n\nconst NPM_TAG = 'latest';\nconst VERSION =  true ? \"3.4.15\" : 0;\nfunction getWorkerName(worker) {\n  const warning = worker.version !== VERSION ? \" (worker-utils@\".concat(VERSION, \")\") : '';\n  return \"\".concat(worker.name, \"@\").concat(worker.version).concat(warning);\n}\nfunction getWorkerURL(worker) {\n  let options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  const workerOptions = options[worker.id] || {};\n  const workerFile = \"\".concat(worker.id, \"-worker.js\");\n  let url = workerOptions.workerUrl;\n  if (!url && worker.id === 'compression') {\n    url = options.workerUrl;\n  }\n  if (options._workerType === 'test') {\n    url = \"modules/\".concat(worker.module, \"/dist/\").concat(workerFile);\n  }\n  if (!url) {\n    let version = worker.version;\n    if (version === 'latest') {\n      version = NPM_TAG;\n    }\n    const versionTag = version ? \"@\".concat(version) : '';\n    url = \"https://unpkg.com/@loaders.gl/\".concat(worker.module).concat(versionTag, \"/dist/\").concat(workerFile);\n  }\n  (0,_env_utils_assert__WEBPACK_IMPORTED_MODULE_0__.assert)(url);\n  return url;\n}\n//# sourceMappingURL=get-worker-url.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-api/get-worker-url.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-api/validate-worker-version.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-api/validate-worker-version.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   validateWorkerVersion: () => (/* binding */ validateWorkerVersion)\n/* harmony export */ });\n/* harmony import */ var _env_utils_assert__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../env-utils/assert */ \"./node_modules/@loaders.gl/worker-utils/dist/esm/lib/env-utils/assert.js\");\n/* harmony import */ var _env_utils_version__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../env-utils/version */ \"./node_modules/@loaders.gl/worker-utils/dist/esm/lib/env-utils/version.js\");\n\n\nfunction validateWorkerVersion(worker) {\n  let coreVersion = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : _env_utils_version__WEBPACK_IMPORTED_MODULE_0__.VERSION;\n  (0,_env_utils_assert__WEBPACK_IMPORTED_MODULE_1__.assert)(worker, 'no worker provided');\n  const workerVersion = worker.version;\n  if (!coreVersion || !workerVersion) {\n    return false;\n  }\n  return true;\n}\nfunction parseVersion(version) {\n  const parts = version.split('.').map(Number);\n  return {\n    major: parts[0],\n    minor: parts[1]\n  };\n}\n//# sourceMappingURL=validate-worker-version.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-api/validate-worker-version.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-farm/worker-farm.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-farm/worker-farm.js ***!
  \***************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ WorkerFarm)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _worker_pool__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./worker-pool */ \"./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-farm/worker-pool.js\");\n/* harmony import */ var _worker_thread__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./worker-thread */ \"./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-farm/worker-thread.js\");\n\n\n\nconst DEFAULT_PROPS = {\n  maxConcurrency: 3,\n  maxMobileConcurrency: 1,\n  reuseWorkers: true,\n  onDebug: () => {}\n};\nclass WorkerFarm {\n  static isSupported() {\n    return _worker_thread__WEBPACK_IMPORTED_MODULE_1__[\"default\"].isSupported();\n  }\n  static getWorkerFarm() {\n    let props = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    WorkerFarm._workerFarm = WorkerFarm._workerFarm || new WorkerFarm({});\n    WorkerFarm._workerFarm.setProps(props);\n    return WorkerFarm._workerFarm;\n  }\n  constructor(props) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"props\", void 0);\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"workerPools\", new Map());\n    this.props = {\n      ...DEFAULT_PROPS\n    };\n    this.setProps(props);\n    this.workerPools = new Map();\n  }\n  destroy() {\n    for (const workerPool of this.workerPools.values()) {\n      workerPool.destroy();\n    }\n    this.workerPools = new Map();\n  }\n  setProps(props) {\n    this.props = {\n      ...this.props,\n      ...props\n    };\n    for (const workerPool of this.workerPools.values()) {\n      workerPool.setProps(this._getWorkerPoolProps());\n    }\n  }\n  getWorkerPool(options) {\n    const {\n      name,\n      source,\n      url\n    } = options;\n    let workerPool = this.workerPools.get(name);\n    if (!workerPool) {\n      workerPool = new _worker_pool__WEBPACK_IMPORTED_MODULE_2__[\"default\"]({\n        name,\n        source,\n        url\n      });\n      workerPool.setProps(this._getWorkerPoolProps());\n      this.workerPools.set(name, workerPool);\n    }\n    return workerPool;\n  }\n  _getWorkerPoolProps() {\n    return {\n      maxConcurrency: this.props.maxConcurrency,\n      maxMobileConcurrency: this.props.maxMobileConcurrency,\n      reuseWorkers: this.props.reuseWorkers,\n      onDebug: this.props.onDebug\n    };\n  }\n}\n(0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(WorkerFarm, \"_workerFarm\", void 0);\n//# sourceMappingURL=worker-farm.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-farm/worker-farm.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-farm/worker-job.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-farm/worker-job.js ***!
  \**************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ WorkerJob)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _env_utils_assert__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../env-utils/assert */ \"./node_modules/@loaders.gl/worker-utils/dist/esm/lib/env-utils/assert.js\");\n\n\nclass WorkerJob {\n  constructor(jobName, workerThread) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"name\", void 0);\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"workerThread\", void 0);\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"isRunning\", true);\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"result\", void 0);\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_resolve\", () => {});\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_reject\", () => {});\n    this.name = jobName;\n    this.workerThread = workerThread;\n    this.result = new Promise((resolve, reject) => {\n      this._resolve = resolve;\n      this._reject = reject;\n    });\n  }\n  postMessage(type, payload) {\n    this.workerThread.postMessage({\n      source: 'loaders.gl',\n      type,\n      payload\n    });\n  }\n  done(value) {\n    (0,_env_utils_assert__WEBPACK_IMPORTED_MODULE_1__.assert)(this.isRunning);\n    this.isRunning = false;\n    this._resolve(value);\n  }\n  error(error) {\n    (0,_env_utils_assert__WEBPACK_IMPORTED_MODULE_1__.assert)(this.isRunning);\n    this.isRunning = false;\n    this._reject(error);\n  }\n}\n//# sourceMappingURL=worker-job.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-farm/worker-job.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-farm/worker-pool.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-farm/worker-pool.js ***!
  \***************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ WorkerPool)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _env_utils_globals__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../env-utils/globals */ \"./node_modules/@loaders.gl/worker-utils/dist/esm/lib/env-utils/globals.js\");\n/* harmony import */ var _worker_thread__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./worker-thread */ \"./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-farm/worker-thread.js\");\n/* harmony import */ var _worker_job__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./worker-job */ \"./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-farm/worker-job.js\");\n\n\n\n\nclass WorkerPool {\n  static isSupported() {\n    return _worker_thread__WEBPACK_IMPORTED_MODULE_1__[\"default\"].isSupported();\n  }\n  constructor(props) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"name\", 'unnamed');\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"source\", void 0);\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"url\", void 0);\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"maxConcurrency\", 1);\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"maxMobileConcurrency\", 1);\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"onDebug\", () => {});\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"reuseWorkers\", true);\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"props\", {});\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"jobQueue\", []);\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"idleQueue\", []);\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"count\", 0);\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"isDestroyed\", false);\n    this.source = props.source;\n    this.url = props.url;\n    this.setProps(props);\n  }\n  destroy() {\n    this.idleQueue.forEach(worker => worker.destroy());\n    this.isDestroyed = true;\n  }\n  setProps(props) {\n    this.props = {\n      ...this.props,\n      ...props\n    };\n    if (props.name !== undefined) {\n      this.name = props.name;\n    }\n    if (props.maxConcurrency !== undefined) {\n      this.maxConcurrency = props.maxConcurrency;\n    }\n    if (props.maxMobileConcurrency !== undefined) {\n      this.maxMobileConcurrency = props.maxMobileConcurrency;\n    }\n    if (props.reuseWorkers !== undefined) {\n      this.reuseWorkers = props.reuseWorkers;\n    }\n    if (props.onDebug !== undefined) {\n      this.onDebug = props.onDebug;\n    }\n  }\n  async startJob(name) {\n    let onMessage = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : (job, type, data) => job.done(data);\n    let onError = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : (job, error) => job.error(error);\n    const startPromise = new Promise(onStart => {\n      this.jobQueue.push({\n        name,\n        onMessage,\n        onError,\n        onStart\n      });\n      return this;\n    });\n    this._startQueuedJob();\n    return await startPromise;\n  }\n  async _startQueuedJob() {\n    if (!this.jobQueue.length) {\n      return;\n    }\n    const workerThread = this._getAvailableWorker();\n    if (!workerThread) {\n      return;\n    }\n    const queuedJob = this.jobQueue.shift();\n    if (queuedJob) {\n      this.onDebug({\n        message: 'Starting job',\n        name: queuedJob.name,\n        workerThread,\n        backlog: this.jobQueue.length\n      });\n      const job = new _worker_job__WEBPACK_IMPORTED_MODULE_2__[\"default\"](queuedJob.name, workerThread);\n      workerThread.onMessage = data => queuedJob.onMessage(job, data.type, data.payload);\n      workerThread.onError = error => queuedJob.onError(job, error);\n      queuedJob.onStart(job);\n      try {\n        await job.result;\n      } finally {\n        this.returnWorkerToQueue(workerThread);\n      }\n    }\n  }\n  returnWorkerToQueue(worker) {\n    const shouldDestroyWorker = this.isDestroyed || !this.reuseWorkers || this.count > this._getMaxConcurrency();\n    if (shouldDestroyWorker) {\n      worker.destroy();\n      this.count--;\n    } else {\n      this.idleQueue.push(worker);\n    }\n    if (!this.isDestroyed) {\n      this._startQueuedJob();\n    }\n  }\n  _getAvailableWorker() {\n    if (this.idleQueue.length > 0) {\n      return this.idleQueue.shift() || null;\n    }\n    if (this.count < this._getMaxConcurrency()) {\n      this.count++;\n      const name = \"\".concat(this.name.toLowerCase(), \" (#\").concat(this.count, \" of \").concat(this.maxConcurrency, \")\");\n      return new _worker_thread__WEBPACK_IMPORTED_MODULE_1__[\"default\"]({\n        name,\n        source: this.source,\n        url: this.url\n      });\n    }\n    return null;\n  }\n  _getMaxConcurrency() {\n    return _env_utils_globals__WEBPACK_IMPORTED_MODULE_3__.isMobile ? this.maxMobileConcurrency : this.maxConcurrency;\n  }\n}\n//# sourceMappingURL=worker-pool.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-farm/worker-pool.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-farm/worker-thread.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-farm/worker-thread.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ WorkerThread)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _node_worker_threads__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../node/worker_threads */ \"./node_modules/@loaders.gl/worker-utils/dist/esm/lib/node/worker_threads-browser.js\");\n/* harmony import */ var _env_utils_globals__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../env-utils/globals */ \"./node_modules/@loaders.gl/worker-utils/dist/esm/lib/env-utils/globals.js\");\n/* harmony import */ var _env_utils_assert__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../env-utils/assert */ \"./node_modules/@loaders.gl/worker-utils/dist/esm/lib/env-utils/assert.js\");\n/* harmony import */ var _worker_utils_get_loadable_worker_url__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../worker-utils/get-loadable-worker-url */ \"./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-utils/get-loadable-worker-url.js\");\n/* harmony import */ var _worker_utils_get_transfer_list__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../worker-utils/get-transfer-list */ \"./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-utils/get-transfer-list.js\");\n\n\n\n\n\n\nconst NOOP = () => {};\nclass WorkerThread {\n  static isSupported() {\n    return typeof Worker !== 'undefined' && _env_utils_globals__WEBPACK_IMPORTED_MODULE_1__.isBrowser || typeof _node_worker_threads__WEBPACK_IMPORTED_MODULE_2__.NodeWorker !== 'undefined' && !_env_utils_globals__WEBPACK_IMPORTED_MODULE_1__.isBrowser;\n  }\n  constructor(props) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"name\", void 0);\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"source\", void 0);\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"url\", void 0);\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"terminated\", false);\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"worker\", void 0);\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"onMessage\", void 0);\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"onError\", void 0);\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_loadableURL\", '');\n    const {\n      name,\n      source,\n      url\n    } = props;\n    (0,_env_utils_assert__WEBPACK_IMPORTED_MODULE_3__.assert)(source || url);\n    this.name = name;\n    this.source = source;\n    this.url = url;\n    this.onMessage = NOOP;\n    this.onError = error => console.log(error);\n    this.worker = _env_utils_globals__WEBPACK_IMPORTED_MODULE_1__.isBrowser ? this._createBrowserWorker() : this._createNodeWorker();\n  }\n  destroy() {\n    this.onMessage = NOOP;\n    this.onError = NOOP;\n    this.worker.terminate();\n    this.terminated = true;\n  }\n  get isRunning() {\n    return Boolean(this.onMessage);\n  }\n  postMessage(data, transferList) {\n    transferList = transferList || (0,_worker_utils_get_transfer_list__WEBPACK_IMPORTED_MODULE_4__.getTransferList)(data);\n    this.worker.postMessage(data, transferList);\n  }\n  _getErrorFromErrorEvent(event) {\n    let message = 'Failed to load ';\n    message += \"worker \".concat(this.name, \" from \").concat(this.url, \". \");\n    if (event.message) {\n      message += \"\".concat(event.message, \" in \");\n    }\n    if (event.lineno) {\n      message += \":\".concat(event.lineno, \":\").concat(event.colno);\n    }\n    return new Error(message);\n  }\n  _createBrowserWorker() {\n    this._loadableURL = (0,_worker_utils_get_loadable_worker_url__WEBPACK_IMPORTED_MODULE_5__.getLoadableWorkerURL)({\n      source: this.source,\n      url: this.url\n    });\n    const worker = new Worker(this._loadableURL, {\n      name: this.name\n    });\n    worker.onmessage = event => {\n      if (!event.data) {\n        this.onError(new Error('No data received'));\n      } else {\n        this.onMessage(event.data);\n      }\n    };\n    worker.onerror = error => {\n      this.onError(this._getErrorFromErrorEvent(error));\n      this.terminated = true;\n    };\n    worker.onmessageerror = event => console.error(event);\n    return worker;\n  }\n  _createNodeWorker() {\n    let worker;\n    if (this.url) {\n      const absolute = this.url.includes(':/') || this.url.startsWith('/');\n      const url = absolute ? this.url : \"./\".concat(this.url);\n      worker = new _node_worker_threads__WEBPACK_IMPORTED_MODULE_2__.NodeWorker(url, {\n        eval: false\n      });\n    } else if (this.source) {\n      worker = new _node_worker_threads__WEBPACK_IMPORTED_MODULE_2__.NodeWorker(this.source, {\n        eval: true\n      });\n    } else {\n      throw new Error('no worker');\n    }\n    worker.on('message', data => {\n      this.onMessage(data);\n    });\n    worker.on('error', error => {\n      this.onError(error);\n    });\n    worker.on('exit', code => {});\n    return worker;\n  }\n}\n//# sourceMappingURL=worker-thread.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-farm/worker-thread.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-utils/get-loadable-worker-url.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-utils/get-loadable-worker-url.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getLoadableWorkerURL: () => (/* binding */ getLoadableWorkerURL)\n/* harmony export */ });\n/* harmony import */ var _env_utils_assert__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../env-utils/assert */ \"./node_modules/@loaders.gl/worker-utils/dist/esm/lib/env-utils/assert.js\");\n\nconst workerURLCache = new Map();\nfunction getLoadableWorkerURL(props) {\n  (0,_env_utils_assert__WEBPACK_IMPORTED_MODULE_0__.assert)(props.source && !props.url || !props.source && props.url);\n  let workerURL = workerURLCache.get(props.source || props.url);\n  if (!workerURL) {\n    if (props.url) {\n      workerURL = getLoadableWorkerURLFromURL(props.url);\n      workerURLCache.set(props.url, workerURL);\n    }\n    if (props.source) {\n      workerURL = getLoadableWorkerURLFromSource(props.source);\n      workerURLCache.set(props.source, workerURL);\n    }\n  }\n  (0,_env_utils_assert__WEBPACK_IMPORTED_MODULE_0__.assert)(workerURL);\n  return workerURL;\n}\nfunction getLoadableWorkerURLFromURL(url) {\n  if (!url.startsWith('http')) {\n    return url;\n  }\n  const workerSource = buildScriptSource(url);\n  return getLoadableWorkerURLFromSource(workerSource);\n}\nfunction getLoadableWorkerURLFromSource(workerSource) {\n  const blob = new Blob([workerSource], {\n    type: 'application/javascript'\n  });\n  return URL.createObjectURL(blob);\n}\nfunction buildScriptSource(workerUrl) {\n  return \"try {\\n  importScripts('\".concat(workerUrl, \"');\\n} catch (error) {\\n  console.error(error);\\n  throw error;\\n}\");\n}\n//# sourceMappingURL=get-loadable-worker-url.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-utils/get-loadable-worker-url.js?");

/***/ }),

/***/ "./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-utils/get-transfer-list.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-utils/get-transfer-list.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getTransferList: () => (/* binding */ getTransferList),\n/* harmony export */   getTransferListForWriter: () => (/* binding */ getTransferListForWriter)\n/* harmony export */ });\nfunction getTransferList(object) {\n  let recursive = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : true;\n  let transfers = arguments.length > 2 ? arguments[2] : undefined;\n  const transfersSet = transfers || new Set();\n  if (!object) {} else if (isTransferable(object)) {\n    transfersSet.add(object);\n  } else if (isTransferable(object.buffer)) {\n    transfersSet.add(object.buffer);\n  } else if (ArrayBuffer.isView(object)) {} else if (recursive && typeof object === 'object') {\n    for (const key in object) {\n      getTransferList(object[key], recursive, transfersSet);\n    }\n  }\n  return transfers === undefined ? Array.from(transfersSet) : [];\n}\nfunction isTransferable(object) {\n  if (!object) {\n    return false;\n  }\n  if (object instanceof ArrayBuffer) {\n    return true;\n  }\n  if (typeof MessagePort !== 'undefined' && object instanceof MessagePort) {\n    return true;\n  }\n  if (typeof ImageBitmap !== 'undefined' && object instanceof ImageBitmap) {\n    return true;\n  }\n  if (typeof OffscreenCanvas !== 'undefined' && object instanceof OffscreenCanvas) {\n    return true;\n  }\n  return false;\n}\nfunction getTransferListForWriter(object) {\n  if (object === null) {\n    return {};\n  }\n  const clone = Object.assign({}, object);\n  Object.keys(clone).forEach(key => {\n    if (typeof object[key] === 'object' && !ArrayBuffer.isView(object[key]) && !(object[key] instanceof Array)) {\n      clone[key] = getTransferListForWriter(object[key]);\n    } else if (typeof clone[key] === 'function' || clone[key] instanceof RegExp) {\n      clone[key] = {};\n    } else {\n      clone[key] = object[key];\n    }\n  });\n  return clone;\n}\n//# sourceMappingURL=get-transfer-list.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@loaders.gl/worker-utils/dist/esm/lib/worker-utils/get-transfer-list.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/engine/dist/esm/animation/timeline.js":
/*!*********************************************************************!*\
  !*** ./node_modules/@luma.gl/engine/dist/esm/animation/timeline.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Timeline: () => (/* binding */ Timeline)\n/* harmony export */ });\nlet channelHandles = 1;\nlet animationHandles = 1;\nclass Timeline {\n  constructor() {\n    this.time = 0;\n    this.channels = new Map();\n    this.animations = new Map();\n    this.playing = false;\n    this.lastEngineTime = -1;\n  }\n\n  addChannel(props) {\n    const {\n      delay = 0,\n      duration = Number.POSITIVE_INFINITY,\n      rate = 1,\n      repeat = 1\n    } = props;\n    const handle = channelHandles++;\n    const channel = {\n      time: 0,\n      delay,\n      duration,\n      rate,\n      repeat\n    };\n\n    this._setChannelTime(channel, this.time);\n\n    this.channels.set(handle, channel);\n    return handle;\n  }\n\n  removeChannel(handle) {\n    this.channels.delete(handle);\n\n    for (const [animationHandle, animation] of this.animations) {\n      if (animation.channel === handle) {\n        this.detachAnimation(animationHandle);\n      }\n    }\n  }\n\n  isFinished(handle) {\n    const channel = this.channels.get(handle);\n\n    if (channel === undefined) {\n      return false;\n    }\n\n    return this.time >= channel.delay + channel.duration * channel.repeat;\n  }\n\n  getTime(handle) {\n    if (handle === undefined) {\n      return this.time;\n    }\n\n    const channel = this.channels.get(handle);\n\n    if (channel === undefined) {\n      return -1;\n    }\n\n    return channel.time;\n  }\n\n  setTime(time) {\n    this.time = Math.max(0, time);\n    const channels = this.channels.values();\n\n    for (const channel of channels) {\n      this._setChannelTime(channel, this.time);\n    }\n\n    const animations = this.animations.values();\n\n    for (const animationData of animations) {\n      const {\n        animation,\n        channel\n      } = animationData;\n      animation.setTime(this.getTime(channel));\n    }\n  }\n\n  play() {\n    this.playing = true;\n  }\n\n  pause() {\n    this.playing = false;\n    this.lastEngineTime = -1;\n  }\n\n  reset() {\n    this.setTime(0);\n  }\n\n  attachAnimation(animation, channelHandle) {\n    const animationHandle = animationHandles++;\n    this.animations.set(animationHandle, {\n      animation,\n      channel: channelHandle\n    });\n    animation.setTime(this.getTime(channelHandle));\n    return animationHandle;\n  }\n\n  detachAnimation(handle) {\n    this.animations.delete(handle);\n  }\n\n  update(engineTime) {\n    if (this.playing) {\n      if (this.lastEngineTime === -1) {\n        this.lastEngineTime = engineTime;\n      }\n\n      this.setTime(this.time + (engineTime - this.lastEngineTime));\n      this.lastEngineTime = engineTime;\n    }\n  }\n\n  _setChannelTime(channel, time) {\n    const offsetTime = time - channel.delay;\n    const totalDuration = channel.duration * channel.repeat;\n\n    if (offsetTime >= totalDuration) {\n      channel.time = channel.duration * channel.rate;\n    } else {\n      channel.time = Math.max(0, offsetTime) % channel.duration;\n      channel.time *= channel.rate;\n    }\n  }\n\n}\n//# sourceMappingURL=timeline.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/engine/dist/esm/animation/timeline.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/engine/dist/esm/geometry/geometry.js":
/*!********************************************************************!*\
  !*** ./node_modules/@luma.gl/engine/dist/esm/geometry/geometry.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   DRAW_MODE: () => (/* binding */ DRAW_MODE),\n/* harmony export */   \"default\": () => (/* binding */ Geometry)\n/* harmony export */ });\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/utils.js\");\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js\");\n\nconst DRAW_MODE = {\n  POINTS: 0x0000,\n  LINES: 0x0001,\n  LINE_LOOP: 0x0002,\n  LINE_STRIP: 0x0003,\n  TRIANGLES: 0x0004,\n  TRIANGLE_STRIP: 0x0005,\n  TRIANGLE_FAN: 0x0006\n};\nclass Geometry {\n  static get DRAW_MODE() {\n    return DRAW_MODE;\n  }\n\n  constructor() {\n    let props = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    const {\n      id = (0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_0__.uid)('geometry'),\n      drawMode = DRAW_MODE.TRIANGLES,\n      attributes = {},\n      indices = null,\n      vertexCount = null\n    } = props;\n    this.id = id;\n    this.drawMode = drawMode | 0;\n    this.attributes = {};\n    this.userData = {};\n\n    this._setAttributes(attributes, indices);\n\n    this.vertexCount = vertexCount || this._calculateVertexCount(this.attributes, this.indices);\n  }\n\n  get mode() {\n    return this.drawMode;\n  }\n\n  getVertexCount() {\n    return this.vertexCount;\n  }\n\n  getAttributes() {\n    return this.indices ? {\n      indices: this.indices,\n      ...this.attributes\n    } : this.attributes;\n  }\n\n  _print(attributeName) {\n    return \"Geometry \".concat(this.id, \" attribute \").concat(attributeName);\n  }\n\n  _setAttributes(attributes, indices) {\n    if (indices) {\n      this.indices = ArrayBuffer.isView(indices) ? {\n        value: indices,\n        size: 1\n      } : indices;\n    }\n\n    for (const attributeName in attributes) {\n      let attribute = attributes[attributeName];\n      attribute = ArrayBuffer.isView(attribute) ? {\n        value: attribute\n      } : attribute;\n      (0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_1__.assert)(ArrayBuffer.isView(attribute.value), \"\".concat(this._print(attributeName), \": must be typed array or object with value as typed array\"));\n\n      if ((attributeName === 'POSITION' || attributeName === 'positions') && !attribute.size) {\n        attribute.size = 3;\n      }\n\n      if (attributeName === 'indices') {\n        (0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_1__.assert)(!this.indices);\n        this.indices = attribute;\n      } else {\n        this.attributes[attributeName] = attribute;\n      }\n    }\n\n    if (this.indices && this.indices.isIndexed !== undefined) {\n      this.indices = Object.assign({}, this.indices);\n      delete this.indices.isIndexed;\n    }\n\n    return this;\n  }\n\n  _calculateVertexCount(attributes, indices) {\n    if (indices) {\n      return indices.value.length;\n    }\n\n    let vertexCount = Infinity;\n\n    for (const attributeName in attributes) {\n      const attribute = attributes[attributeName];\n      const {\n        value,\n        size,\n        constant\n      } = attribute;\n\n      if (!constant && value && size >= 1) {\n        vertexCount = Math.min(vertexCount, value.length / size);\n      }\n    }\n\n    (0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_1__.assert)(Number.isFinite(vertexCount));\n    return vertexCount;\n  }\n\n}\n//# sourceMappingURL=geometry.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/engine/dist/esm/geometry/geometry.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/engine/dist/esm/lib/animation-loop.js":
/*!*********************************************************************!*\
  !*** ./node_modules/@luma.gl/engine/dist/esm/lib/animation-loop.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ AnimationLoop)\n/* harmony export */ });\n/* harmony import */ var _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/init.js\");\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js\");\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/query.js\");\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/request-animation-frame.js\");\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/framebuffer.js\");\n/* harmony import */ var _probe_gl_env__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @probe.gl/env */ \"./node_modules/@probe.gl/env/dist/esm/lib/is-browser.js\");\n\n\n\nconst isPage = (0,_probe_gl_env__WEBPACK_IMPORTED_MODULE_1__[\"default\"])() && typeof document !== 'undefined';\nlet statIdCounter = 0;\nclass AnimationLoop {\n  constructor() {\n    let props = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    const {\n      onCreateContext = opts => (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.createGLContext)(opts),\n      onAddHTML = null,\n      onInitialize = () => {},\n      onRender = () => {},\n      onFinalize = () => {},\n      onError,\n      gl = null,\n      glOptions = {},\n      debug = false,\n      createFramebuffer = false,\n      autoResizeViewport = true,\n      autoResizeDrawingBuffer = true,\n      stats = _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_2__.lumaStats.get(\"animation-loop-\".concat(statIdCounter++))\n    } = props;\n    let {\n      useDevicePixels = true\n    } = props;\n\n    if ('useDevicePixelRatio' in props) {\n      _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.deprecated('useDevicePixelRatio', 'useDevicePixels')();\n      useDevicePixels = props.useDevicePixelRatio;\n    }\n\n    this.props = {\n      onCreateContext,\n      onAddHTML,\n      onInitialize,\n      onRender,\n      onFinalize,\n      onError,\n      gl,\n      glOptions,\n      debug,\n      createFramebuffer\n    };\n    this.gl = gl;\n    this.needsRedraw = null;\n    this.timeline = null;\n    this.stats = stats;\n    this.cpuTime = this.stats.get('CPU Time');\n    this.gpuTime = this.stats.get('GPU Time');\n    this.frameRate = this.stats.get('Frame Rate');\n    this._initialized = false;\n    this._running = false;\n    this._animationFrameId = null;\n    this._nextFramePromise = null;\n    this._resolveNextFrame = null;\n    this._cpuStartTime = 0;\n    this.setProps({\n      autoResizeViewport,\n      autoResizeDrawingBuffer,\n      useDevicePixels\n    });\n    this.start = this.start.bind(this);\n    this.stop = this.stop.bind(this);\n    this._pageLoadPromise = null;\n    this._onMousemove = this._onMousemove.bind(this);\n    this._onMouseleave = this._onMouseleave.bind(this);\n  }\n\n  delete() {\n    this.stop();\n\n    this._setDisplay(null);\n  }\n\n  setNeedsRedraw(reason) {\n    (0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_3__.assert)(typeof reason === 'string');\n    this.needsRedraw = this.needsRedraw || reason;\n    return this;\n  }\n\n  setProps(props) {\n    if ('autoResizeViewport' in props) {\n      this.autoResizeViewport = props.autoResizeViewport;\n    }\n\n    if ('autoResizeDrawingBuffer' in props) {\n      this.autoResizeDrawingBuffer = props.autoResizeDrawingBuffer;\n    }\n\n    if ('useDevicePixels' in props) {\n      this.useDevicePixels = props.useDevicePixels;\n    }\n\n    return this;\n  }\n\n  start() {\n    let opts = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n\n    if (this._running) {\n      return this;\n    }\n\n    this._running = true;\n\n    const startPromise = this._getPageLoadPromise().then(() => {\n      if (!this._running || this._initialized) {\n        return null;\n      }\n\n      this._createWebGLContext(opts);\n\n      this._createFramebuffer();\n\n      this._startEventHandling();\n\n      this._initializeCallbackData();\n\n      this._updateCallbackData();\n\n      this._resizeCanvasDrawingBuffer();\n\n      this._resizeViewport();\n\n      this._gpuTimeQuery = _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_4__[\"default\"].isSupported(this.gl, ['timers']) ? new _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_4__[\"default\"](this.gl) : null;\n      this._initialized = true;\n      return this.onInitialize(this.animationProps);\n    }).then(appContext => {\n      if (this._running) {\n        this._addCallbackData(appContext || {});\n\n        if (appContext !== false) {\n          this._startLoop();\n        }\n      }\n    });\n\n    if (this.props.onError) {\n      startPromise.catch(this.props.onError);\n    }\n\n    return this;\n  }\n\n  redraw() {\n    if (this.isContextLost()) {\n      return this;\n    }\n\n    this._beginTimers();\n\n    this._setupFrame();\n\n    this._updateCallbackData();\n\n    this._renderFrame(this.animationProps);\n\n    this._clearNeedsRedraw();\n\n    if (this.offScreen && this.gl.commit) {\n      this.gl.commit();\n    }\n\n    if (this._resolveNextFrame) {\n      this._resolveNextFrame(this);\n\n      this._nextFramePromise = null;\n      this._resolveNextFrame = null;\n    }\n\n    this._endTimers();\n\n    return this;\n  }\n\n  stop() {\n    if (this._running) {\n      this._finalizeCallbackData();\n\n      this._cancelAnimationFrame(this._animationFrameId);\n\n      this._nextFramePromise = null;\n      this._resolveNextFrame = null;\n      this._animationFrameId = null;\n      this._running = false;\n    }\n\n    return this;\n  }\n\n  attachTimeline(timeline) {\n    this.timeline = timeline;\n    return this.timeline;\n  }\n\n  detachTimeline() {\n    this.timeline = null;\n  }\n\n  waitForRender() {\n    this.setNeedsRedraw('waitForRender');\n\n    if (!this._nextFramePromise) {\n      this._nextFramePromise = new Promise(resolve => {\n        this._resolveNextFrame = resolve;\n      });\n    }\n\n    return this._nextFramePromise;\n  }\n\n  async toDataURL() {\n    this.setNeedsRedraw('toDataURL');\n    await this.waitForRender();\n    return this.gl.canvas.toDataURL();\n  }\n\n  isContextLost() {\n    return this.gl.isContextLost();\n  }\n\n  onCreateContext() {\n    return this.props.onCreateContext(...arguments);\n  }\n\n  onInitialize() {\n    return this.props.onInitialize(...arguments);\n  }\n\n  onRender() {\n    return this.props.onRender(...arguments);\n  }\n\n  onFinalize() {\n    return this.props.onFinalize(...arguments);\n  }\n\n  getHTMLControlValue(id) {\n    let defaultValue = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;\n    const element = document.getElementById(id);\n    return element ? Number(element.value) : defaultValue;\n  }\n\n  setViewParameters() {\n    _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.removed('AnimationLoop.setViewParameters', 'AnimationLoop.setProps')();\n    return this;\n  }\n\n  _startLoop() {\n    const renderFrame = () => {\n      if (!this._running) {\n        return;\n      }\n\n      this.redraw();\n      this._animationFrameId = this._requestAnimationFrame(renderFrame);\n    };\n\n    this._cancelAnimationFrame(this._animationFrameId);\n\n    this._animationFrameId = this._requestAnimationFrame(renderFrame);\n  }\n\n  _getPageLoadPromise() {\n    if (!this._pageLoadPromise) {\n      this._pageLoadPromise = isPage ? new Promise((resolve, reject) => {\n        if (isPage && document.readyState === 'complete') {\n          resolve(document);\n          return;\n        }\n\n        window.addEventListener('load', () => {\n          resolve(document);\n        });\n      }) : Promise.resolve({});\n    }\n\n    return this._pageLoadPromise;\n  }\n\n  _setDisplay(display) {\n    if (this.display) {\n      this.display.delete();\n      this.display.animationLoop = null;\n    }\n\n    if (display) {\n      display.animationLoop = this;\n    }\n\n    this.display = display;\n  }\n\n  _cancelAnimationFrame(animationFrameId) {\n    if (this.display && this.display.cancelAnimationFrame) {\n      return this.display.cancelAnimationFrame(animationFrameId);\n    }\n\n    return (0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_5__.cancelAnimationFrame)(animationFrameId);\n  }\n\n  _requestAnimationFrame(renderFrameCallback) {\n    if (this._running) {\n      if (this.display && this.display.requestAnimationFrame) {\n        return this.display.requestAnimationFrame(renderFrameCallback);\n      }\n\n      return (0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_5__.requestAnimationFrame)(renderFrameCallback);\n    }\n\n    return undefined;\n  }\n\n  _renderFrame() {\n    if (this.display) {\n      this.display._renderFrame(...arguments);\n\n      return;\n    }\n\n    this.onRender(...arguments);\n  }\n\n  _clearNeedsRedraw() {\n    this.needsRedraw = null;\n  }\n\n  _setupFrame() {\n    this._resizeCanvasDrawingBuffer();\n\n    this._resizeViewport();\n\n    this._resizeFramebuffer();\n  }\n\n  _initializeCallbackData() {\n    this.animationProps = {\n      gl: this.gl,\n      stop: this.stop,\n      canvas: this.gl.canvas,\n      framebuffer: this.framebuffer,\n      useDevicePixels: this.useDevicePixels,\n      needsRedraw: null,\n      startTime: Date.now(),\n      engineTime: 0,\n      tick: 0,\n      tock: 0,\n      time: 0,\n      _timeline: this.timeline,\n      _loop: this,\n      _animationLoop: this,\n      _mousePosition: null\n    };\n  }\n\n  _updateCallbackData() {\n    const {\n      width,\n      height,\n      aspect\n    } = this._getSizeAndAspect();\n\n    if (width !== this.animationProps.width || height !== this.animationProps.height) {\n      this.setNeedsRedraw('drawing buffer resized');\n    }\n\n    if (aspect !== this.animationProps.aspect) {\n      this.setNeedsRedraw('drawing buffer aspect changed');\n    }\n\n    this.animationProps.width = width;\n    this.animationProps.height = height;\n    this.animationProps.aspect = aspect;\n    this.animationProps.needsRedraw = this.needsRedraw;\n    this.animationProps.engineTime = Date.now() - this.animationProps.startTime;\n\n    if (this.timeline) {\n      this.timeline.update(this.animationProps.engineTime);\n    }\n\n    this.animationProps.tick = Math.floor(this.animationProps.time / 1000 * 60);\n    this.animationProps.tock++;\n    this.animationProps.time = this.timeline ? this.timeline.getTime() : this.animationProps.engineTime;\n    this.animationProps._offScreen = this.offScreen;\n  }\n\n  _finalizeCallbackData() {\n    this.onFinalize(this.animationProps);\n  }\n\n  _addCallbackData(appContext) {\n    if (typeof appContext === 'object' && appContext !== null) {\n      this.animationProps = Object.assign({}, this.animationProps, appContext);\n    }\n  }\n\n  _createWebGLContext(opts) {\n    this.offScreen = opts.canvas && typeof OffscreenCanvas !== 'undefined' && opts.canvas instanceof OffscreenCanvas;\n    opts = Object.assign({}, opts, this.props.glOptions);\n    this.gl = this.props.gl ? (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.instrumentGLContext)(this.props.gl, opts) : this.onCreateContext(opts);\n\n    if (!(0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.isWebGL)(this.gl)) {\n      throw new Error('AnimationLoop.onCreateContext - illegal context returned');\n    }\n\n    (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.resetParameters)(this.gl);\n\n    this._createInfoDiv();\n  }\n\n  _createInfoDiv() {\n    if (this.gl.canvas && this.props.onAddHTML) {\n      const wrapperDiv = document.createElement('div');\n      document.body.appendChild(wrapperDiv);\n      wrapperDiv.style.position = 'relative';\n      const div = document.createElement('div');\n      div.style.position = 'absolute';\n      div.style.left = '10px';\n      div.style.bottom = '10px';\n      div.style.width = '300px';\n      div.style.background = 'white';\n      wrapperDiv.appendChild(this.gl.canvas);\n      wrapperDiv.appendChild(div);\n      const html = this.props.onAddHTML(div);\n\n      if (html) {\n        div.innerHTML = html;\n      }\n    }\n  }\n\n  _getSizeAndAspect() {\n    const width = this.gl.drawingBufferWidth;\n    const height = this.gl.drawingBufferHeight;\n    let aspect = 1;\n    const {\n      canvas\n    } = this.gl;\n\n    if (canvas && canvas.clientHeight) {\n      aspect = canvas.clientWidth / canvas.clientHeight;\n    } else if (width > 0 && height > 0) {\n      aspect = width / height;\n    }\n\n    return {\n      width,\n      height,\n      aspect\n    };\n  }\n\n  _resizeViewport() {\n    if (this.autoResizeViewport) {\n      this.gl.viewport(0, 0, this.gl.drawingBufferWidth, this.gl.drawingBufferHeight);\n    }\n  }\n\n  _resizeCanvasDrawingBuffer() {\n    if (this.autoResizeDrawingBuffer) {\n      (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.resizeGLContext)(this.gl, {\n        useDevicePixels: this.useDevicePixels\n      });\n    }\n  }\n\n  _createFramebuffer() {\n    if (this.props.createFramebuffer) {\n      this.framebuffer = new _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_6__[\"default\"](this.gl);\n    }\n  }\n\n  _resizeFramebuffer() {\n    if (this.framebuffer) {\n      this.framebuffer.resize({\n        width: this.gl.drawingBufferWidth,\n        height: this.gl.drawingBufferHeight\n      });\n    }\n  }\n\n  _beginTimers() {\n    this.frameRate.timeEnd();\n    this.frameRate.timeStart();\n\n    if (this._gpuTimeQuery && this._gpuTimeQuery.isResultAvailable() && !this._gpuTimeQuery.isTimerDisjoint()) {\n      this.stats.get('GPU Time').addTime(this._gpuTimeQuery.getTimerMilliseconds());\n    }\n\n    if (this._gpuTimeQuery) {\n      this._gpuTimeQuery.beginTimeElapsedQuery();\n    }\n\n    this.cpuTime.timeStart();\n  }\n\n  _endTimers() {\n    this.cpuTime.timeEnd();\n\n    if (this._gpuTimeQuery) {\n      this._gpuTimeQuery.end();\n    }\n  }\n\n  _startEventHandling() {\n    const {\n      canvas\n    } = this.gl;\n\n    if (canvas) {\n      canvas.addEventListener('mousemove', this._onMousemove);\n      canvas.addEventListener('mouseleave', this._onMouseleave);\n    }\n  }\n\n  _onMousemove(e) {\n    this.animationProps._mousePosition = [e.offsetX, e.offsetY];\n  }\n\n  _onMouseleave(e) {\n    this.animationProps._mousePosition = null;\n  }\n\n}\n//# sourceMappingURL=animation-loop.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/engine/dist/esm/lib/animation-loop.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/engine/dist/esm/lib/model-utils.js":
/*!******************************************************************!*\
  !*** ./node_modules/@luma.gl/engine/dist/esm/lib/model-utils.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getBuffersFromGeometry: () => (/* binding */ getBuffersFromGeometry),\n/* harmony export */   inferAttributeAccessor: () => (/* binding */ inferAttributeAccessor)\n/* harmony export */ });\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/buffer.js\");\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js\");\n\nconst GLTF_TO_LUMA_ATTRIBUTE_MAP = {\n  POSITION: 'positions',\n  NORMAL: 'normals',\n  COLOR_0: 'colors',\n  TEXCOORD_0: 'texCoords',\n  TEXCOORD_1: 'texCoords1',\n  TEXCOORD_2: 'texCoords2'\n};\nfunction getBuffersFromGeometry(gl, geometry, options) {\n  const buffers = {};\n  let indices = geometry.indices;\n\n  for (const name in geometry.attributes) {\n    const attribute = geometry.attributes[name];\n    const remappedName = mapAttributeName(name, options);\n\n    if (name === 'indices') {\n      indices = attribute;\n    } else if (attribute.constant) {\n      buffers[remappedName] = attribute.value;\n    } else {\n      const typedArray = attribute.value;\n      const accessor = { ...attribute\n      };\n      delete accessor.value;\n      buffers[remappedName] = [new _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_0__[\"default\"](gl, typedArray), accessor];\n      inferAttributeAccessor(name, accessor);\n    }\n  }\n\n  if (indices) {\n    const data = indices.value || indices;\n    (0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_1__.assert)(data instanceof Uint16Array || data instanceof Uint32Array, 'attribute array for \"indices\" must be of integer type');\n    const accessor = {\n      size: 1,\n      isIndexed: indices.isIndexed === undefined ? true : indices.isIndexed\n    };\n    buffers.indices = [new _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_0__[\"default\"](gl, {\n      data,\n      target: 34963\n    }), accessor];\n  }\n\n  return buffers;\n}\n\nfunction mapAttributeName(name, options) {\n  const {\n    attributeMap = GLTF_TO_LUMA_ATTRIBUTE_MAP\n  } = options || {};\n  return attributeMap && attributeMap[name] || name;\n}\n\nfunction inferAttributeAccessor(attributeName, attribute) {\n  let category;\n\n  switch (attributeName) {\n    case 'texCoords':\n    case 'texCoord1':\n    case 'texCoord2':\n    case 'texCoord3':\n      category = 'uvs';\n      break;\n\n    case 'vertices':\n    case 'positions':\n    case 'normals':\n    case 'pickingColors':\n      category = 'vectors';\n      break;\n\n    default:\n  }\n\n  switch (category) {\n    case 'vectors':\n      attribute.size = attribute.size || 3;\n      break;\n\n    case 'uvs':\n      attribute.size = attribute.size || 2;\n      break;\n\n    default:\n  }\n\n  (0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_1__.assert)(Number.isFinite(attribute.size), \"attribute \".concat(attributeName, \" needs size\"));\n}\n//# sourceMappingURL=model-utils.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/engine/dist/esm/lib/model-utils.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/engine/dist/esm/lib/model.js":
/*!************************************************************!*\
  !*** ./node_modules/@luma.gl/engine/dist/esm/lib/model.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Model)\n/* harmony export */ });\n/* harmony import */ var _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n/* harmony import */ var _program_manager__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./program-manager */ \"./node_modules/@luma.gl/engine/dist/esm/lib/program-manager.js\");\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/utils.js\");\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js\");\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/clear.js\");\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/program.js\");\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/vertex-array.js\");\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/buffer.js\");\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/transform-feedback.js\");\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/debug/debug-vertex-array.js\");\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/debug/debug-uniforms.js\");\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/debug/debug-program-configuration.js\");\n/* harmony import */ var _model_utils__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./model-utils */ \"./node_modules/@luma.gl/engine/dist/esm/lib/model-utils.js\");\n\n\n\n\n\nconst LOG_DRAW_PRIORITY = 2;\nconst LOG_DRAW_TIMEOUT = 10000;\nconst ERR_MODEL_PARAMS = 'Model needs drawMode and vertexCount';\n\nconst NOOP = () => {};\n\nconst DRAW_PARAMS = {};\nclass Model {\n  constructor(gl) {\n    let props = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    const {\n      id = (0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_1__.uid)('model')\n    } = props;\n    (0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_2__.assert)((0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.isWebGL)(gl));\n    this.id = id;\n    this.gl = gl;\n    this.id = props.id || (0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_1__.uid)('Model');\n    this.lastLogTime = 0;\n    this.animated = false;\n    this.initialize(props);\n  }\n\n  initialize(props) {\n    this.props = {};\n    this.programManager = props.programManager || _program_manager__WEBPACK_IMPORTED_MODULE_3__[\"default\"].getDefaultProgramManager(this.gl);\n    this._programManagerState = -1;\n    this._managedProgram = false;\n    const {\n      program = null,\n      vs,\n      fs,\n      modules,\n      defines,\n      inject,\n      varyings,\n      bufferMode,\n      transpileToGLSL100\n    } = props;\n    this.programProps = {\n      program,\n      vs,\n      fs,\n      modules,\n      defines,\n      inject,\n      varyings,\n      bufferMode,\n      transpileToGLSL100\n    };\n    this.program = null;\n    this.vertexArray = null;\n    this._programDirty = true;\n    this.userData = {};\n    this.needsRedraw = true;\n    this._attributes = {};\n    this.attributes = {};\n    this.uniforms = {};\n    this.pickable = true;\n\n    this._checkProgram();\n\n    this.setUniforms(Object.assign({}, this.getModuleUniforms(props.moduleSettings)));\n    this.drawMode = props.drawMode !== undefined ? props.drawMode : 4;\n    this.vertexCount = props.vertexCount || 0;\n    this.geometryBuffers = {};\n    this.isInstanced = props.isInstanced || props.instanced || props.instanceCount > 0;\n\n    this._setModelProps(props);\n\n    this.geometry = {};\n    (0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_2__.assert)(this.drawMode !== undefined && Number.isFinite(this.vertexCount), ERR_MODEL_PARAMS);\n  }\n\n  setProps(props) {\n    this._setModelProps(props);\n  }\n\n  delete() {\n    for (const key in this._attributes) {\n      if (this._attributes[key] !== this.attributes[key]) {\n        this._attributes[key].delete();\n      }\n    }\n\n    if (this._managedProgram) {\n      this.programManager.release(this.program);\n      this._managedProgram = false;\n    }\n\n    this.vertexArray.delete();\n\n    this._deleteGeometryBuffers();\n  }\n\n  getDrawMode() {\n    return this.drawMode;\n  }\n\n  getVertexCount() {\n    return this.vertexCount;\n  }\n\n  getInstanceCount() {\n    return this.instanceCount;\n  }\n\n  getAttributes() {\n    return this.attributes;\n  }\n\n  getProgram() {\n    return this.program;\n  }\n\n  setProgram(props) {\n    const {\n      program,\n      vs,\n      fs,\n      modules,\n      defines,\n      inject,\n      varyings,\n      bufferMode,\n      transpileToGLSL100\n    } = props;\n    this.programProps = {\n      program,\n      vs,\n      fs,\n      modules,\n      defines,\n      inject,\n      varyings,\n      bufferMode,\n      transpileToGLSL100\n    };\n    this._programDirty = true;\n  }\n\n  getUniforms() {\n    return this.uniforms;\n  }\n\n  setDrawMode(drawMode) {\n    this.drawMode = drawMode;\n    return this;\n  }\n\n  setVertexCount(vertexCount) {\n    (0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_2__.assert)(Number.isFinite(vertexCount));\n    this.vertexCount = vertexCount;\n    return this;\n  }\n\n  setInstanceCount(instanceCount) {\n    (0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_2__.assert)(Number.isFinite(instanceCount));\n    this.instanceCount = instanceCount;\n    return this;\n  }\n\n  setGeometry(geometry) {\n    this.drawMode = geometry.drawMode;\n    this.vertexCount = geometry.getVertexCount();\n\n    this._deleteGeometryBuffers();\n\n    this.geometryBuffers = (0,_model_utils__WEBPACK_IMPORTED_MODULE_4__.getBuffersFromGeometry)(this.gl, geometry);\n    this.vertexArray.setAttributes(this.geometryBuffers);\n    return this;\n  }\n\n  setAttributes() {\n    let attributes = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n\n    if ((0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_1__.isObjectEmpty)(attributes)) {\n      return this;\n    }\n\n    const normalizedAttributes = {};\n\n    for (const name in attributes) {\n      const attribute = attributes[name];\n      normalizedAttributes[name] = attribute.getValue ? attribute.getValue() : attribute;\n    }\n\n    this.vertexArray.setAttributes(normalizedAttributes);\n    return this;\n  }\n\n  setUniforms() {\n    let uniforms = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    Object.assign(this.uniforms, uniforms);\n    return this;\n  }\n\n  getModuleUniforms(opts) {\n    this._checkProgram();\n\n    const getUniforms = this.programManager.getUniforms(this.program);\n\n    if (getUniforms) {\n      return getUniforms(opts);\n    }\n\n    return {};\n  }\n\n  updateModuleSettings(opts) {\n    const uniforms = this.getModuleUniforms(opts || {});\n    return this.setUniforms(uniforms);\n  }\n\n  clear(opts) {\n    (0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_5__.clear)(this.program.gl, opts);\n    return this;\n  }\n\n  draw() {\n    let opts = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n\n    this._checkProgram();\n\n    const {\n      moduleSettings = null,\n      framebuffer,\n      uniforms = {},\n      attributes = {},\n      transformFeedback = this.transformFeedback,\n      parameters = {},\n      vertexArray = this.vertexArray\n    } = opts;\n    this.setAttributes(attributes);\n    this.updateModuleSettings(moduleSettings);\n    this.setUniforms(uniforms);\n    let logPriority;\n\n    if (_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.priority >= LOG_DRAW_PRIORITY) {\n      logPriority = this._logDrawCallStart(LOG_DRAW_PRIORITY);\n    }\n\n    const drawParams = this.vertexArray.getDrawParams();\n    const {\n      isIndexed = drawParams.isIndexed,\n      indexType = drawParams.indexType,\n      indexOffset = drawParams.indexOffset,\n      vertexArrayInstanced = drawParams.isInstanced\n    } = this.props;\n\n    if (vertexArrayInstanced && !this.isInstanced) {\n      _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.warn('Found instanced attributes on non-instanced model', this.id)();\n    }\n\n    const {\n      isInstanced,\n      instanceCount\n    } = this;\n    const {\n      onBeforeRender = NOOP,\n      onAfterRender = NOOP\n    } = this.props;\n    onBeforeRender();\n    this.program.setUniforms(this.uniforms);\n    const didDraw = this.program.draw(Object.assign(DRAW_PARAMS, opts, {\n      logPriority,\n      uniforms: null,\n      framebuffer,\n      parameters,\n      drawMode: this.getDrawMode(),\n      vertexCount: this.getVertexCount(),\n      vertexArray,\n      transformFeedback,\n      isIndexed,\n      indexType,\n      isInstanced,\n      instanceCount,\n      offset: isIndexed ? indexOffset : 0\n    }));\n    onAfterRender();\n\n    if (_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.priority >= LOG_DRAW_PRIORITY) {\n      this._logDrawCallEnd(logPriority, vertexArray, framebuffer);\n    }\n\n    return didDraw;\n  }\n\n  transform() {\n    let opts = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    const {\n      discard = true,\n      feedbackBuffers,\n      unbindModels = []\n    } = opts;\n    let {\n      parameters\n    } = opts;\n\n    if (feedbackBuffers) {\n      this._setFeedbackBuffers(feedbackBuffers);\n    }\n\n    if (discard) {\n      parameters = Object.assign({}, parameters, {\n        [35977]: discard\n      });\n    }\n\n    unbindModels.forEach(model => model.vertexArray.unbindBuffers());\n\n    try {\n      this.draw(Object.assign({}, opts, {\n        parameters\n      }));\n    } finally {\n      unbindModels.forEach(model => model.vertexArray.bindBuffers());\n    }\n\n    return this;\n  }\n\n  render() {\n    let uniforms = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.warn('Model.render() is deprecated. Use Model.setUniforms() and Model.draw()')();\n    return this.setUniforms(uniforms).draw();\n  }\n\n  _setModelProps(props) {\n    Object.assign(this.props, props);\n\n    if ('uniforms' in props) {\n      this.setUniforms(props.uniforms);\n    }\n\n    if ('pickable' in props) {\n      this.pickable = props.pickable;\n    }\n\n    if ('instanceCount' in props) {\n      this.instanceCount = props.instanceCount;\n    }\n\n    if ('geometry' in props) {\n      this.setGeometry(props.geometry);\n    }\n\n    if ('attributes' in props) {\n      this.setAttributes(props.attributes);\n    }\n\n    if ('_feedbackBuffers' in props) {\n      this._setFeedbackBuffers(props._feedbackBuffers);\n    }\n  }\n\n  _checkProgram() {\n    const needsUpdate = this._programDirty || this.programManager.stateHash !== this._programManagerState;\n\n    if (!needsUpdate) {\n      return;\n    }\n\n    let {\n      program\n    } = this.programProps;\n\n    if (program) {\n      this._managedProgram = false;\n    } else {\n      const {\n        vs,\n        fs,\n        modules,\n        inject,\n        defines,\n        varyings,\n        bufferMode,\n        transpileToGLSL100\n      } = this.programProps;\n      program = this.programManager.get({\n        vs,\n        fs,\n        modules,\n        inject,\n        defines,\n        varyings,\n        bufferMode,\n        transpileToGLSL100\n      });\n\n      if (this.program && this._managedProgram) {\n        this.programManager.release(this.program);\n      }\n\n      this._programManagerState = this.programManager.stateHash;\n      this._managedProgram = true;\n    }\n\n    (0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_2__.assert)(program instanceof _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_6__[\"default\"], 'Model needs a program');\n    this._programDirty = false;\n\n    if (program === this.program) {\n      return;\n    }\n\n    this.program = program;\n\n    if (this.vertexArray) {\n      this.vertexArray.setProps({\n        program: this.program,\n        attributes: this.vertexArray.attributes\n      });\n    } else {\n      this.vertexArray = new _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_7__[\"default\"](this.gl, {\n        program: this.program\n      });\n    }\n\n    this.setUniforms(Object.assign({}, this.getModuleUniforms()));\n  }\n\n  _deleteGeometryBuffers() {\n    for (const name in this.geometryBuffers) {\n      const buffer = this.geometryBuffers[name][0] || this.geometryBuffers[name];\n\n      if (buffer instanceof _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_8__[\"default\"]) {\n        buffer.delete();\n      }\n    }\n  }\n\n  _setAnimationProps(animationProps) {\n    if (this.animated) {\n      (0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_2__.assert)(animationProps, 'Model.draw(): animated uniforms but no animationProps');\n    }\n  }\n\n  _setFeedbackBuffers() {\n    let feedbackBuffers = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n\n    if ((0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_1__.isObjectEmpty)(feedbackBuffers)) {\n      return this;\n    }\n\n    const {\n      gl\n    } = this.program;\n    this.transformFeedback = this.transformFeedback || new _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_9__[\"default\"](gl, {\n      program: this.program\n    });\n    this.transformFeedback.setBuffers(feedbackBuffers);\n    return this;\n  }\n\n  _logDrawCallStart(logLevel) {\n    const logDrawTimeout = logLevel > 3 ? 0 : LOG_DRAW_TIMEOUT;\n\n    if (Date.now() - this.lastLogTime < logDrawTimeout) {\n      return undefined;\n    }\n\n    this.lastLogTime = Date.now();\n    _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.group(LOG_DRAW_PRIORITY, \">>> DRAWING MODEL \".concat(this.id), {\n      collapsed: _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.level <= 2\n    })();\n    return logLevel;\n  }\n\n  _logDrawCallEnd(logLevel, vertexArray, uniforms, framebuffer) {\n    if (logLevel === undefined) {\n      return;\n    }\n\n    const attributeTable = (0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_10__.getDebugTableForVertexArray)({\n      vertexArray,\n      header: \"\".concat(this.id, \" attributes\"),\n      attributes: this._attributes\n    });\n    const {\n      table: uniformTable,\n      unusedTable,\n      unusedCount\n    } = (0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_11__.getDebugTableForUniforms)({\n      header: \"\".concat(this.id, \" uniforms\"),\n      program: this.program,\n      uniforms: Object.assign({}, this.program.uniforms, uniforms)\n    });\n    const {\n      table: missingTable,\n      count: missingCount\n    } = (0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_11__.getDebugTableForUniforms)({\n      header: \"\".concat(this.id, \" uniforms\"),\n      program: this.program,\n      uniforms: Object.assign({}, this.program.uniforms, uniforms),\n      undefinedOnly: true\n    });\n\n    if (missingCount > 0) {\n      _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.log('MISSING UNIFORMS', Object.keys(missingTable))();\n    }\n\n    if (unusedCount > 0) {\n      _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.log('UNUSED UNIFORMS', Object.keys(unusedTable))();\n    }\n\n    const configTable = (0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_12__.getDebugTableForProgramConfiguration)(this.vertexArray.configuration);\n    _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.table(logLevel, attributeTable)();\n    _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.table(logLevel, uniformTable)();\n    _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.table(logLevel + 1, configTable)();\n\n    if (framebuffer) {\n      framebuffer.log({\n        logLevel: LOG_DRAW_PRIORITY,\n        message: \"Rendered to \".concat(framebuffer.id)\n      });\n    }\n\n    _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.groupEnd(LOG_DRAW_PRIORITY)();\n  }\n\n}\n//# sourceMappingURL=model.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/engine/dist/esm/lib/model.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/engine/dist/esm/lib/program-manager.js":
/*!**********************************************************************!*\
  !*** ./node_modules/@luma.gl/engine/dist/esm/lib/program-manager.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ ProgramManager)\n/* harmony export */ });\n/* harmony import */ var _luma_gl_shadertools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/shadertools */ \"./node_modules/@luma.gl/shadertools/dist/esm/lib/assemble-shaders.js\");\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/program.js\");\n\n\nclass ProgramManager {\n  static getDefaultProgramManager(gl) {\n    gl.luma = gl.luma || {};\n    gl.luma.defaultProgramManager = gl.luma.defaultProgramManager || new ProgramManager(gl);\n    return gl.luma.defaultProgramManager;\n  }\n\n  constructor(gl) {\n    this.gl = gl;\n    this._programCache = {};\n    this._getUniforms = {};\n    this._registeredModules = {};\n    this._hookFunctions = [];\n    this._defaultModules = [];\n    this._hashes = {};\n    this._hashCounter = 0;\n    this.stateHash = 0;\n    this._useCounts = {};\n  }\n\n  addDefaultModule(module) {\n    if (!this._defaultModules.find(m => m.name === module.name)) {\n      this._defaultModules.push(module);\n    }\n\n    this.stateHash++;\n  }\n\n  removeDefaultModule(module) {\n    const moduleName = typeof module === 'string' ? module : module.name;\n    this._defaultModules = this._defaultModules.filter(m => m.name !== moduleName);\n    this.stateHash++;\n  }\n\n  addShaderHook(hook, opts) {\n    if (opts) {\n      hook = Object.assign(opts, {\n        hook\n      });\n    }\n\n    this._hookFunctions.push(hook);\n\n    this.stateHash++;\n  }\n\n  get() {\n    let props = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    const {\n      vs = '',\n      fs = '',\n      defines = {},\n      inject = {},\n      varyings = [],\n      bufferMode = 0x8c8d,\n      transpileToGLSL100 = false\n    } = props;\n\n    const modules = this._getModuleList(props.modules);\n\n    const vsHash = this._getHash(vs);\n\n    const fsHash = this._getHash(fs);\n\n    const moduleHashes = modules.map(m => this._getHash(m.name)).sort();\n    const varyingHashes = varyings.map(v => this._getHash(v));\n    const defineKeys = Object.keys(defines).sort();\n    const injectKeys = Object.keys(inject).sort();\n    const defineHashes = [];\n    const injectHashes = [];\n\n    for (const key of defineKeys) {\n      defineHashes.push(this._getHash(key));\n      defineHashes.push(this._getHash(defines[key]));\n    }\n\n    for (const key of injectKeys) {\n      injectHashes.push(this._getHash(key));\n      injectHashes.push(this._getHash(inject[key]));\n    }\n\n    const hash = \"\".concat(vsHash, \"/\").concat(fsHash, \"D\").concat(defineHashes.join('/'), \"M\").concat(moduleHashes.join('/'), \"I\").concat(injectHashes.join('/'), \"V\").concat(varyingHashes.join('/'), \"H\").concat(this.stateHash, \"B\").concat(bufferMode).concat(transpileToGLSL100 ? 'T' : '');\n\n    if (!this._programCache[hash]) {\n      const assembled = (0,_luma_gl_shadertools__WEBPACK_IMPORTED_MODULE_0__.assembleShaders)(this.gl, {\n        vs,\n        fs,\n        modules,\n        inject,\n        defines,\n        hookFunctions: this._hookFunctions,\n        transpileToGLSL100\n      });\n      this._programCache[hash] = new _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_1__[\"default\"](this.gl, {\n        hash,\n        vs: assembled.vs,\n        fs: assembled.fs,\n        varyings,\n        bufferMode\n      });\n\n      this._getUniforms[hash] = assembled.getUniforms || (x => {});\n\n      this._useCounts[hash] = 0;\n    }\n\n    this._useCounts[hash]++;\n    return this._programCache[hash];\n  }\n\n  getUniforms(program) {\n    return this._getUniforms[program.hash] || null;\n  }\n\n  release(program) {\n    const hash = program.hash;\n    this._useCounts[hash]--;\n\n    if (this._useCounts[hash] === 0) {\n      this._programCache[hash].delete();\n\n      delete this._programCache[hash];\n      delete this._getUniforms[hash];\n      delete this._useCounts[hash];\n    }\n  }\n\n  _getHash(key) {\n    if (this._hashes[key] === undefined) {\n      this._hashes[key] = this._hashCounter++;\n    }\n\n    return this._hashes[key];\n  }\n\n  _getModuleList() {\n    let appModules = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : [];\n    const modules = new Array(this._defaultModules.length + appModules.length);\n    const seen = {};\n    let count = 0;\n\n    for (let i = 0, len = this._defaultModules.length; i < len; ++i) {\n      const module = this._defaultModules[i];\n      const name = module.name;\n      modules[count++] = module;\n      seen[name] = true;\n    }\n\n    for (let i = 0, len = appModules.length; i < len; ++i) {\n      const module = appModules[i];\n      const name = module.name;\n\n      if (!seen[name]) {\n        modules[count++] = module;\n        seen[name] = true;\n      }\n    }\n\n    modules.length = count;\n    return modules;\n  }\n\n}\n//# sourceMappingURL=program-manager.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/engine/dist/esm/lib/program-manager.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/engine/dist/esm/transform/buffer-transform.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/@luma.gl/engine/dist/esm/transform/buffer-transform.js ***!
  \*****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ BufferTransform)\n/* harmony export */ });\n/* harmony import */ var _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/gltools */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/buffer.js\");\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/transform-feedback.js\");\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js\");\n\n\n\nclass BufferTransform {\n  constructor(gl) {\n    let props = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    this.gl = gl;\n    this.currentIndex = 0;\n    this.feedbackMap = {};\n    this.varyings = null;\n    this.bindings = [];\n    this.resources = {};\n\n    this._initialize(props);\n\n    Object.seal(this);\n  }\n\n  setupResources(opts) {\n    for (const binding of this.bindings) {\n      this._setupTransformFeedback(binding, opts);\n    }\n  }\n\n  updateModelProps() {\n    let props = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    const {\n      varyings\n    } = this;\n\n    if (varyings.length > 0) {\n      props = Object.assign({}, props, {\n        varyings\n      });\n    }\n\n    return props;\n  }\n\n  getDrawOptions() {\n    let opts = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    const binding = this.bindings[this.currentIndex];\n    const {\n      sourceBuffers,\n      transformFeedback\n    } = binding;\n    const attributes = Object.assign({}, sourceBuffers, opts.attributes);\n    return {\n      attributes,\n      transformFeedback\n    };\n  }\n\n  swap() {\n    if (this.feedbackMap) {\n      this.currentIndex = this._getNextIndex();\n      return true;\n    }\n\n    return false;\n  }\n\n  update() {\n    let opts = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n\n    this._setupBuffers(opts);\n  }\n\n  getBuffer(varyingName) {\n    const {\n      feedbackBuffers\n    } = this.bindings[this.currentIndex];\n    const bufferOrParams = varyingName ? feedbackBuffers[varyingName] : null;\n\n    if (!bufferOrParams) {\n      return null;\n    }\n\n    return bufferOrParams instanceof _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_1__[\"default\"] ? bufferOrParams : bufferOrParams.buffer;\n  }\n\n  getData() {\n    let options = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    const {\n      varyingName\n    } = options;\n    const buffer = this.getBuffer(varyingName);\n\n    if (buffer) {\n      return buffer.getData();\n    }\n\n    return null;\n  }\n\n  delete() {\n    for (const name in this.resources) {\n      this.resources[name].delete();\n    }\n  }\n\n  _initialize() {\n    let props = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n\n    this._setupBuffers(props);\n\n    this.varyings = props.varyings || Object.keys(this.bindings[this.currentIndex].feedbackBuffers);\n\n    if (this.varyings.length > 0) {\n      (0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_2__.assert)((0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.isWebGL2)(this.gl));\n    }\n  }\n\n  _getFeedbackBuffers(props) {\n    const {\n      sourceBuffers = {}\n    } = props;\n    const feedbackBuffers = {};\n\n    if (this.bindings[this.currentIndex]) {\n      Object.assign(feedbackBuffers, this.bindings[this.currentIndex].feedbackBuffers);\n    }\n\n    if (this.feedbackMap) {\n      for (const sourceName in this.feedbackMap) {\n        const feedbackName = this.feedbackMap[sourceName];\n\n        if (sourceName in sourceBuffers) {\n          feedbackBuffers[feedbackName] = sourceName;\n        }\n      }\n    }\n\n    Object.assign(feedbackBuffers, props.feedbackBuffers);\n\n    for (const bufferName in feedbackBuffers) {\n      const bufferOrRef = feedbackBuffers[bufferName];\n\n      if (typeof bufferOrRef === 'string') {\n        const sourceBuffer = sourceBuffers[bufferOrRef];\n        const {\n          byteLength,\n          usage,\n          accessor\n        } = sourceBuffer;\n        feedbackBuffers[bufferName] = this._createNewBuffer(bufferName, {\n          byteLength,\n          usage,\n          accessor\n        });\n      }\n    }\n\n    return feedbackBuffers;\n  }\n\n  _setupBuffers() {\n    let props = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    const {\n      sourceBuffers = null\n    } = props;\n    Object.assign(this.feedbackMap, props.feedbackMap);\n\n    const feedbackBuffers = this._getFeedbackBuffers(props);\n\n    this._updateBindings({\n      sourceBuffers,\n      feedbackBuffers\n    });\n  }\n\n  _setupTransformFeedback(binding, _ref) {\n    let {\n      model\n    } = _ref;\n    const {\n      program\n    } = model;\n    binding.transformFeedback = new _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_3__[\"default\"](this.gl, {\n      program,\n      buffers: binding.feedbackBuffers\n    });\n  }\n\n  _updateBindings(opts) {\n    this.bindings[this.currentIndex] = this._updateBinding(this.bindings[this.currentIndex], opts);\n\n    if (this.feedbackMap) {\n      const {\n        sourceBuffers,\n        feedbackBuffers\n      } = this._swapBuffers(this.bindings[this.currentIndex]);\n\n      const nextIndex = this._getNextIndex();\n\n      this.bindings[nextIndex] = this._updateBinding(this.bindings[nextIndex], {\n        sourceBuffers,\n        feedbackBuffers\n      });\n    }\n  }\n\n  _updateBinding(binding, opts) {\n    if (!binding) {\n      return {\n        sourceBuffers: Object.assign({}, opts.sourceBuffers),\n        feedbackBuffers: Object.assign({}, opts.feedbackBuffers)\n      };\n    }\n\n    Object.assign(binding.sourceBuffers, opts.sourceBuffers);\n    Object.assign(binding.feedbackBuffers, opts.feedbackBuffers);\n\n    if (binding.transformFeedback) {\n      binding.transformFeedback.setBuffers(binding.feedbackBuffers);\n    }\n\n    return binding;\n  }\n\n  _swapBuffers(opts) {\n    if (!this.feedbackMap) {\n      return null;\n    }\n\n    const sourceBuffers = Object.assign({}, opts.sourceBuffers);\n    const feedbackBuffers = Object.assign({}, opts.feedbackBuffers);\n\n    for (const srcName in this.feedbackMap) {\n      const dstName = this.feedbackMap[srcName];\n      sourceBuffers[srcName] = opts.feedbackBuffers[dstName];\n      feedbackBuffers[dstName] = opts.sourceBuffers[srcName];\n      (0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_2__.assert)(feedbackBuffers[dstName] instanceof _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_1__[\"default\"]);\n    }\n\n    return {\n      sourceBuffers,\n      feedbackBuffers\n    };\n  }\n\n  _createNewBuffer(name, opts) {\n    const buffer = new _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_1__[\"default\"](this.gl, opts);\n\n    if (this.resources[name]) {\n      this.resources[name].delete();\n    }\n\n    this.resources[name] = buffer;\n    return buffer;\n  }\n\n  _getNextIndex() {\n    return (this.currentIndex + 1) % 2;\n  }\n\n}\n//# sourceMappingURL=buffer-transform.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/engine/dist/esm/transform/buffer-transform.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/engine/dist/esm/transform/texture-transform.js":
/*!******************************************************************************!*\
  !*** ./node_modules/@luma.gl/engine/dist/esm/transform/texture-transform.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ TextureTransform)\n/* harmony export */ });\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/copy-and-blit.js\");\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/texture-2d.js\");\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/buffer.js\");\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/framebuffer.js\");\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/texture-utils.js\");\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/glsl-utils/get-shader-version.js\");\n/* harmony import */ var _luma_gl_shadertools__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @luma.gl/shadertools */ \"./node_modules/@luma.gl/shadertools/dist/esm/utils/shader-utils.js\");\n/* harmony import */ var _luma_gl_shadertools__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! @luma.gl/shadertools */ \"./node_modules/@luma.gl/shadertools/dist/esm/lib/inject-shader.js\");\n/* harmony import */ var _luma_gl_shadertools__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! @luma.gl/shadertools */ \"./node_modules/@luma.gl/shadertools/dist/esm/modules/transform/transform.js\");\n/* harmony import */ var _transform_shader_utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./transform-shader-utils */ \"./node_modules/@luma.gl/engine/dist/esm/transform/transform-shader-utils.js\");\n\n\n\nconst SRC_TEX_PARAMETER_OVERRIDES = {\n  [10241]: 9728,\n  [10240]: 9728,\n  [10242]: 33071,\n  [10243]: 33071\n};\nconst FS_OUTPUT_VARIABLE = 'transform_output';\nclass TextureTransform {\n  constructor(gl) {\n    let props = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    this.gl = gl;\n    this.id = this.currentIndex = 0;\n    this._swapTexture = null;\n    this.targetTextureVarying = null;\n    this.targetTextureType = null;\n    this.samplerTextureMap = null;\n    this.bindings = [];\n    this.resources = {};\n\n    this._initialize(props);\n\n    Object.seal(this);\n  }\n\n  updateModelProps() {\n    let props = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n\n    const updatedModelProps = this._processVertexShader(props);\n\n    return Object.assign({}, props, updatedModelProps);\n  }\n\n  getDrawOptions() {\n    let opts = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    const {\n      sourceBuffers,\n      sourceTextures,\n      framebuffer,\n      targetTexture\n    } = this.bindings[this.currentIndex];\n    const attributes = Object.assign({}, sourceBuffers, opts.attributes);\n    const uniforms = Object.assign({}, opts.uniforms);\n    const parameters = Object.assign({}, opts.parameters);\n    let discard = opts.discard;\n\n    if (this.hasSourceTextures || this.hasTargetTexture) {\n      attributes.transform_elementID = this.elementIDBuffer;\n\n      for (const sampler in this.samplerTextureMap) {\n        const textureName = this.samplerTextureMap[sampler];\n        uniforms[sampler] = sourceTextures[textureName];\n      }\n\n      this._setSourceTextureParameters();\n\n      const sizeUniforms = (0,_transform_shader_utils__WEBPACK_IMPORTED_MODULE_0__.getSizeUniforms)({\n        sourceTextureMap: sourceTextures,\n        targetTextureVarying: this.targetTextureVarying,\n        targetTexture\n      });\n      Object.assign(uniforms, sizeUniforms);\n    }\n\n    if (this.hasTargetTexture) {\n      discard = false;\n      parameters.viewport = [0, 0, framebuffer.width, framebuffer.height];\n    }\n\n    return {\n      attributes,\n      framebuffer,\n      uniforms,\n      discard,\n      parameters\n    };\n  }\n\n  swap() {\n    if (this._swapTexture) {\n      this.currentIndex = this._getNextIndex();\n      return true;\n    }\n\n    return false;\n  }\n\n  update() {\n    let opts = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n\n    this._setupTextures(opts);\n  }\n\n  getTargetTexture() {\n    const {\n      targetTexture\n    } = this.bindings[this.currentIndex];\n    return targetTexture;\n  }\n\n  getData() {\n    let {\n      packed = false\n    } = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    const {\n      framebuffer\n    } = this.bindings[this.currentIndex];\n    const pixels = (0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_1__.readPixelsToArray)(framebuffer);\n\n    if (!packed) {\n      return pixels;\n    }\n\n    const ArrayType = pixels.constructor;\n    const channelCount = (0,_luma_gl_shadertools__WEBPACK_IMPORTED_MODULE_2__.typeToChannelCount)(this.targetTextureType);\n    const packedPixels = new ArrayType(pixels.length * channelCount / 4);\n    let packCount = 0;\n\n    for (let i = 0; i < pixels.length; i += 4) {\n      for (let j = 0; j < channelCount; j++) {\n        packedPixels[packCount++] = pixels[i + j];\n      }\n    }\n\n    return packedPixels;\n  }\n\n  getFramebuffer() {\n    const currentResources = this.bindings[this.currentIndex];\n    return currentResources.framebuffer;\n  }\n\n  delete() {\n    if (this.ownTexture) {\n      this.ownTexture.delete();\n    }\n\n    if (this.elementIDBuffer) {\n      this.elementIDBuffer.delete();\n    }\n  }\n\n  _initialize() {\n    let props = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    const {\n      _targetTextureVarying,\n      _swapTexture\n    } = props;\n    this._swapTexture = _swapTexture;\n    this.targetTextureVarying = _targetTextureVarying;\n    this.hasTargetTexture = _targetTextureVarying;\n\n    this._setupTextures(props);\n  }\n\n  _createTargetTexture(props) {\n    const {\n      sourceTextures,\n      textureOrReference\n    } = props;\n\n    if (textureOrReference instanceof _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_3__[\"default\"]) {\n      return textureOrReference;\n    }\n\n    const refTexture = sourceTextures[textureOrReference];\n\n    if (!refTexture) {\n      return null;\n    }\n\n    this._targetRefTexName = textureOrReference;\n    return this._createNewTexture(refTexture);\n  }\n\n  _setupTextures() {\n    let props = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    const {\n      sourceBuffers,\n      _sourceTextures = {},\n      _targetTexture\n    } = props;\n\n    const targetTexture = this._createTargetTexture({\n      sourceTextures: _sourceTextures,\n      textureOrReference: _targetTexture\n    });\n\n    this.hasSourceTextures = this.hasSourceTextures || _sourceTextures && Object.keys(_sourceTextures).length > 0;\n\n    this._updateBindings({\n      sourceBuffers,\n      sourceTextures: _sourceTextures,\n      targetTexture\n    });\n\n    if ('elementCount' in props) {\n      this._updateElementIDBuffer(props.elementCount);\n    }\n  }\n\n  _updateElementIDBuffer(elementCount) {\n    if (typeof elementCount !== 'number' || this.elementCount >= elementCount) {\n      return;\n    }\n\n    const elementIds = new Float32Array(elementCount);\n    elementIds.forEach((_, index, array) => {\n      array[index] = index;\n    });\n\n    if (!this.elementIDBuffer) {\n      this.elementIDBuffer = new _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_4__[\"default\"](this.gl, {\n        data: elementIds,\n        accessor: {\n          size: 1\n        }\n      });\n    } else {\n      this.elementIDBuffer.setData({\n        data: elementIds\n      });\n    }\n\n    this.elementCount = elementCount;\n  }\n\n  _updateBindings(opts) {\n    this.bindings[this.currentIndex] = this._updateBinding(this.bindings[this.currentIndex], opts);\n\n    if (this._swapTexture) {\n      const {\n        sourceTextures,\n        targetTexture\n      } = this._swapTextures(this.bindings[this.currentIndex]);\n\n      const nextIndex = this._getNextIndex();\n\n      this.bindings[nextIndex] = this._updateBinding(this.bindings[nextIndex], {\n        sourceTextures,\n        targetTexture\n      });\n    }\n  }\n\n  _updateBinding(binding, opts) {\n    const {\n      sourceBuffers,\n      sourceTextures,\n      targetTexture\n    } = opts;\n\n    if (!binding) {\n      binding = {\n        sourceBuffers: {},\n        sourceTextures: {},\n        targetTexture: null\n      };\n    }\n\n    Object.assign(binding.sourceTextures, sourceTextures);\n    Object.assign(binding.sourceBuffers, sourceBuffers);\n\n    if (targetTexture) {\n      binding.targetTexture = targetTexture;\n      const {\n        width,\n        height\n      } = targetTexture;\n      const {\n        framebuffer\n      } = binding;\n\n      if (framebuffer) {\n        framebuffer.update({\n          attachments: {\n            [36064]: targetTexture\n          },\n          resizeAttachments: false\n        });\n        framebuffer.resize({\n          width,\n          height\n        });\n      } else {\n        binding.framebuffer = new _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_5__[\"default\"](this.gl, {\n          id: \"transform-framebuffer\",\n          width,\n          height,\n          attachments: {\n            [36064]: targetTexture\n          }\n        });\n      }\n    }\n\n    return binding;\n  }\n\n  _setSourceTextureParameters() {\n    const index = this.currentIndex;\n    const {\n      sourceTextures\n    } = this.bindings[index];\n\n    for (const name in sourceTextures) {\n      sourceTextures[name].setParameters(SRC_TEX_PARAMETER_OVERRIDES);\n    }\n  }\n\n  _swapTextures(opts) {\n    if (!this._swapTexture) {\n      return null;\n    }\n\n    const sourceTextures = Object.assign({}, opts.sourceTextures);\n    sourceTextures[this._swapTexture] = opts.targetTexture;\n    const targetTexture = opts.sourceTextures[this._swapTexture];\n    return {\n      sourceTextures,\n      targetTexture\n    };\n  }\n\n  _createNewTexture(refTexture) {\n    const texture = (0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_6__.cloneTextureFrom)(refTexture, {\n      parameters: {\n        [10241]: 9728,\n        [10240]: 9728,\n        [10242]: 33071,\n        [10243]: 33071\n      },\n      pixelStore: {\n        [37440]: false\n      }\n    });\n\n    if (this.ownTexture) {\n      this.ownTexture.delete();\n    }\n\n    this.ownTexture = texture;\n    return texture;\n  }\n\n  _getNextIndex() {\n    return (this.currentIndex + 1) % 2;\n  }\n\n  _processVertexShader() {\n    let props = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    const {\n      sourceTextures,\n      targetTexture\n    } = this.bindings[this.currentIndex];\n    const {\n      vs,\n      uniforms,\n      targetTextureType,\n      inject,\n      samplerTextureMap\n    } = (0,_transform_shader_utils__WEBPACK_IMPORTED_MODULE_0__.updateForTextures)({\n      vs: props.vs,\n      sourceTextureMap: sourceTextures,\n      targetTextureVarying: this.targetTextureVarying,\n      targetTexture\n    });\n    const combinedInject = (0,_luma_gl_shadertools__WEBPACK_IMPORTED_MODULE_7__.combineInjects)([props.inject || {}, inject]);\n    this.targetTextureType = targetTextureType;\n    this.samplerTextureMap = samplerTextureMap;\n    const fs = props._fs || (0,_luma_gl_shadertools__WEBPACK_IMPORTED_MODULE_2__.getPassthroughFS)({\n      version: (0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_8__[\"default\"])(vs),\n      input: this.targetTextureVarying,\n      inputType: targetTextureType,\n      output: FS_OUTPUT_VARIABLE\n    });\n    const modules = this.hasSourceTextures || this.targetTextureVarying ? [_luma_gl_shadertools__WEBPACK_IMPORTED_MODULE_9__.transform].concat(props.modules || []) : props.modules;\n    return {\n      vs,\n      fs,\n      modules,\n      uniforms,\n      inject: combinedInject\n    };\n  }\n\n}\n//# sourceMappingURL=texture-transform.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/engine/dist/esm/transform/texture-transform.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/engine/dist/esm/transform/transform-shader-utils.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/@luma.gl/engine/dist/esm/transform/transform-shader-utils.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getSizeUniforms: () => (/* binding */ getSizeUniforms),\n/* harmony export */   getVaryingType: () => (/* binding */ getVaryingType),\n/* harmony export */   processAttributeDefinition: () => (/* binding */ processAttributeDefinition),\n/* harmony export */   updateForTextures: () => (/* binding */ updateForTextures)\n/* harmony export */ });\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js\");\n/* harmony import */ var _luma_gl_shadertools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/shadertools */ \"./node_modules/@luma.gl/shadertools/dist/esm/lib/inject-shader.js\");\n/* harmony import */ var _luma_gl_shadertools__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @luma.gl/shadertools */ \"./node_modules/@luma.gl/shadertools/dist/esm/utils/shader-utils.js\");\n\n\nconst SAMPLER_UNIFORM_PREFIX = 'transform_uSampler_';\nconst SIZE_UNIFORM_PREFIX = 'transform_uSize_';\nconst VS_POS_VARIABLE = 'transform_position';\nfunction updateForTextures(_ref) {\n  let {\n    vs,\n    sourceTextureMap,\n    targetTextureVarying,\n    targetTexture\n  } = _ref;\n  const texAttributeNames = Object.keys(sourceTextureMap);\n  let sourceCount = texAttributeNames.length;\n  let targetTextureType = null;\n  const samplerTextureMap = {};\n  let updatedVs = vs;\n  let finalInject = {};\n\n  if (sourceCount > 0 || targetTextureVarying) {\n    const vsLines = updatedVs.split('\\n');\n    const updateVsLines = vsLines.slice();\n    vsLines.forEach((line, index, lines) => {\n      if (sourceCount > 0) {\n        const updated = processAttributeDefinition(line, sourceTextureMap);\n\n        if (updated) {\n          const {\n            updatedLine,\n            inject\n          } = updated;\n          updateVsLines[index] = updatedLine;\n          finalInject = (0,_luma_gl_shadertools__WEBPACK_IMPORTED_MODULE_0__.combineInjects)([finalInject, inject]);\n          Object.assign(samplerTextureMap, updated.samplerTextureMap);\n          sourceCount--;\n        }\n      }\n\n      if (targetTextureVarying && !targetTextureType) {\n        targetTextureType = getVaryingType(line, targetTextureVarying);\n      }\n    });\n\n    if (targetTextureVarying) {\n      (0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_1__.assert)(targetTexture);\n      const sizeName = \"\".concat(SIZE_UNIFORM_PREFIX).concat(targetTextureVarying);\n      const uniformDeclaration = \"uniform vec2 \".concat(sizeName, \";\\n\");\n      const posInstructions = \"     vec2 \".concat(VS_POS_VARIABLE, \" = transform_getPos(\").concat(sizeName, \");\\n     gl_Position = vec4(\").concat(VS_POS_VARIABLE, \", 0, 1.);\\n\");\n      const inject = {\n        'vs:#decl': uniformDeclaration,\n        'vs:#main-start': posInstructions\n      };\n      finalInject = (0,_luma_gl_shadertools__WEBPACK_IMPORTED_MODULE_0__.combineInjects)([finalInject, inject]);\n    }\n\n    updatedVs = updateVsLines.join('\\n');\n  }\n\n  return {\n    vs: updatedVs,\n    targetTextureType,\n    inject: finalInject,\n    samplerTextureMap\n  };\n}\nfunction getSizeUniforms(_ref2) {\n  let {\n    sourceTextureMap,\n    targetTextureVarying,\n    targetTexture\n  } = _ref2;\n  const uniforms = {};\n  let width;\n  let height;\n\n  if (targetTextureVarying) {\n    ({\n      width,\n      height\n    } = targetTexture);\n    uniforms[\"\".concat(SIZE_UNIFORM_PREFIX).concat(targetTextureVarying)] = [width, height];\n  }\n\n  for (const textureName in sourceTextureMap) {\n    ({\n      width,\n      height\n    } = sourceTextureMap[textureName]);\n    uniforms[\"\".concat(SIZE_UNIFORM_PREFIX).concat(textureName)] = [width, height];\n  }\n\n  return uniforms;\n}\n\nfunction getAttributeDefinition(line) {\n  return (0,_luma_gl_shadertools__WEBPACK_IMPORTED_MODULE_2__.getQualifierDetails)(line, ['attribute', 'in']);\n}\n\nfunction getSamplerDeclerations(textureName) {\n  const samplerName = \"\".concat(SAMPLER_UNIFORM_PREFIX).concat(textureName);\n  const sizeName = \"\".concat(SIZE_UNIFORM_PREFIX).concat(textureName);\n  const uniformDeclerations = \"  uniform sampler2D \".concat(samplerName, \";\\n  uniform vec2 \").concat(sizeName, \";\");\n  return {\n    samplerName,\n    sizeName,\n    uniformDeclerations\n  };\n}\n\nfunction getVaryingType(line, varying) {\n  const qualaiferDetails = (0,_luma_gl_shadertools__WEBPACK_IMPORTED_MODULE_2__.getQualifierDetails)(line, ['varying', 'out']);\n\n  if (!qualaiferDetails) {\n    return null;\n  }\n\n  return qualaiferDetails.name === varying ? qualaiferDetails.type : null;\n}\nfunction processAttributeDefinition(line, textureMap) {\n  const samplerTextureMap = {};\n  const attributeData = getAttributeDefinition(line);\n\n  if (!attributeData) {\n    return null;\n  }\n\n  const {\n    type,\n    name\n  } = attributeData;\n\n  if (name && textureMap[name]) {\n    const updatedLine = \"// \".concat(line, \" => Replaced by Transform with a sampler\");\n    const {\n      samplerName,\n      sizeName,\n      uniformDeclerations\n    } = getSamplerDeclerations(name);\n    const channels = (0,_luma_gl_shadertools__WEBPACK_IMPORTED_MODULE_2__.typeToChannelSuffix)(type);\n    const sampleInstruction = \"  \".concat(type, \" \").concat(name, \" = transform_getInput(\").concat(samplerName, \", \").concat(sizeName, \").\").concat(channels, \";\\n\");\n    samplerTextureMap[samplerName] = name;\n    const inject = {\n      'vs:#decl': uniformDeclerations,\n      'vs:#main-start': sampleInstruction\n    };\n    return {\n      updatedLine,\n      inject,\n      samplerTextureMap\n    };\n  }\n\n  return null;\n}\n//# sourceMappingURL=transform-shader-utils.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/engine/dist/esm/transform/transform-shader-utils.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/engine/dist/esm/transform/transform.js":
/*!**********************************************************************!*\
  !*** ./node_modules/@luma.gl/engine/dist/esm/transform/transform.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Transform)\n/* harmony export */ });\n/* harmony import */ var _luma_gl_shadertools__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! @luma.gl/shadertools */ \"./node_modules/@luma.gl/shadertools/dist/esm/utils/shader-utils.js\");\n/* harmony import */ var _buffer_transform__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./buffer-transform */ \"./node_modules/@luma.gl/engine/dist/esm/transform/buffer-transform.js\");\n/* harmony import */ var _texture_transform__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./texture-transform */ \"./node_modules/@luma.gl/engine/dist/esm/transform/texture-transform.js\");\n/* harmony import */ var _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/gltools */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js\");\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/glsl-utils/get-shader-version.js\");\n/* harmony import */ var _luma_gl_webgl__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! @luma.gl/webgl */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/utils.js\");\n/* harmony import */ var _lib_model__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../lib/model */ \"./node_modules/@luma.gl/engine/dist/esm/lib/model.js\");\n\n\n\n\n\n\nclass Transform {\n  static isSupported(gl) {\n    return (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.isWebGL2)(gl);\n  }\n\n  constructor(gl) {\n    let props = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    this.gl = gl;\n    this.model = null;\n    this.elementCount = 0;\n    this.bufferTransform = null;\n    this.textureTransform = null;\n    this.elementIDBuffer = null;\n\n    this._initialize(props);\n\n    Object.seal(this);\n  }\n\n  delete() {\n    const {\n      model,\n      bufferTransform,\n      textureTransform\n    } = this;\n\n    if (model) {\n      model.delete();\n    }\n\n    if (bufferTransform) {\n      bufferTransform.delete();\n    }\n\n    if (textureTransform) {\n      textureTransform.delete();\n    }\n  }\n\n  run() {\n    let opts = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    const {\n      clearRenderTarget = true\n    } = opts;\n\n    const updatedOpts = this._updateDrawOptions(opts);\n\n    if (clearRenderTarget && updatedOpts.framebuffer) {\n      updatedOpts.framebuffer.clear({\n        color: true\n      });\n    }\n\n    this.model.transform(updatedOpts);\n  }\n\n  swap() {\n    let swapped = false;\n    const resourceTransforms = [this.bufferTransform, this.textureTransform].filter(Boolean);\n\n    for (const resourceTransform of resourceTransforms) {\n      swapped = swapped || resourceTransform.swap();\n    }\n\n    (0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_1__.assert)(swapped, 'Nothing to swap');\n  }\n\n  getBuffer() {\n    let varyingName = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : null;\n    return this.bufferTransform && this.bufferTransform.getBuffer(varyingName);\n  }\n\n  getData() {\n    let opts = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    const resourceTransforms = [this.bufferTransform, this.textureTransform].filter(Boolean);\n\n    for (const resourceTransform of resourceTransforms) {\n      const data = resourceTransform.getData(opts);\n\n      if (data) {\n        return data;\n      }\n    }\n\n    return null;\n  }\n\n  getFramebuffer() {\n    return this.textureTransform && this.textureTransform.getFramebuffer();\n  }\n\n  update() {\n    let opts = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n\n    if ('elementCount' in opts) {\n      this.model.setVertexCount(opts.elementCount);\n    }\n\n    const resourceTransforms = [this.bufferTransform, this.textureTransform].filter(Boolean);\n\n    for (const resourceTransform of resourceTransforms) {\n      resourceTransform.update(opts);\n    }\n  }\n\n  _initialize() {\n    let props = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    const {\n      gl\n    } = this;\n\n    this._buildResourceTransforms(gl, props);\n\n    props = this._updateModelProps(props);\n    this.model = new _lib_model__WEBPACK_IMPORTED_MODULE_2__[\"default\"](gl, Object.assign({}, props, {\n      fs: props.fs || (0,_luma_gl_shadertools__WEBPACK_IMPORTED_MODULE_3__.getPassthroughFS)({\n        version: (0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_4__[\"default\"])(props.vs)\n      }),\n      id: props.id || 'transform-model',\n      drawMode: props.drawMode || 0,\n      vertexCount: props.elementCount\n    }));\n    this.bufferTransform && this.bufferTransform.setupResources({\n      model: this.model\n    });\n  }\n\n  _updateModelProps(props) {\n    let updatedProps = Object.assign({}, props);\n    const resourceTransforms = [this.bufferTransform, this.textureTransform].filter(Boolean);\n\n    for (const resourceTransform of resourceTransforms) {\n      updatedProps = resourceTransform.updateModelProps(updatedProps);\n    }\n\n    return updatedProps;\n  }\n\n  _buildResourceTransforms(gl, props) {\n    if (canCreateBufferTransform(props)) {\n      this.bufferTransform = new _buffer_transform__WEBPACK_IMPORTED_MODULE_5__[\"default\"](gl, props);\n    }\n\n    if (canCreateTextureTransform(props)) {\n      this.textureTransform = new _texture_transform__WEBPACK_IMPORTED_MODULE_6__[\"default\"](gl, props);\n    }\n\n    (0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_1__.assert)(this.bufferTransform || this.textureTransform, 'must provide source/feedback buffers or source/target textures');\n  }\n\n  _updateDrawOptions(opts) {\n    let updatedOpts = Object.assign({}, opts);\n    const resourceTransforms = [this.bufferTransform, this.textureTransform].filter(Boolean);\n\n    for (const resourceTransform of resourceTransforms) {\n      updatedOpts = Object.assign(updatedOpts, resourceTransform.getDrawOptions(updatedOpts));\n    }\n\n    return updatedOpts;\n  }\n\n}\n\nfunction canCreateBufferTransform(props) {\n  if (!(0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_7__.isObjectEmpty)(props.feedbackBuffers) || !(0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_7__.isObjectEmpty)(props.feedbackMap) || props.varyings && props.varyings.length > 0) {\n    return true;\n  }\n\n  return false;\n}\n\nfunction canCreateTextureTransform(props) {\n  if (!(0,_luma_gl_webgl__WEBPACK_IMPORTED_MODULE_7__.isObjectEmpty)(props._sourceTextures) || props._targetTexture || props._targetTextureVarying) {\n    return true;\n  }\n\n  return false;\n}\n//# sourceMappingURL=transform.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/engine/dist/esm/transform/transform.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/gltools/dist/esm/context/context.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@luma.gl/gltools/dist/esm/context/context.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   createGLContext: () => (/* binding */ createGLContext),\n/* harmony export */   getContextDebugInfo: () => (/* binding */ getContextDebugInfo),\n/* harmony export */   instrumentGLContext: () => (/* binding */ instrumentGLContext),\n/* harmony export */   resizeGLContext: () => (/* binding */ resizeGLContext)\n/* harmony export */ });\n/* harmony import */ var _probe_gl_env__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! @probe.gl/env */ \"./node_modules/@probe.gl/env/dist/esm/lib/is-browser.js\");\n/* harmony import */ var _state_tracker_track_context_state__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../state-tracker/track-context-state */ \"./node_modules/@luma.gl/gltools/dist/esm/state-tracker/track-context-state.js\");\n/* harmony import */ var _utils_log__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/log */ \"./node_modules/@luma.gl/gltools/dist/esm/utils/log.js\");\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/assert */ \"./node_modules/@luma.gl/gltools/dist/esm/utils/assert.js\");\n/* harmony import */ var _utils_device_pixels__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/device-pixels */ \"./node_modules/@luma.gl/gltools/dist/esm/utils/device-pixels.js\");\n/* harmony import */ var _utils_webgl_checks__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../utils/webgl-checks */ \"./node_modules/@luma.gl/gltools/dist/esm/utils/webgl-checks.js\");\n\n\n\n\n\n\nconst isBrowser = (0,_probe_gl_env__WEBPACK_IMPORTED_MODULE_5__[\"default\"])();\nconst isPage = isBrowser && typeof document !== 'undefined';\nconst CONTEXT_DEFAULTS = {\n  webgl2: true,\n  webgl1: true,\n  throwOnError: true,\n  manageState: true,\n  canvas: null,\n  debug: false,\n  width: 800,\n  height: 600\n};\nfunction createGLContext() {\n  let options = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n  (0,_utils_assert__WEBPACK_IMPORTED_MODULE_2__.assert)(isBrowser, \"createGLContext only available in the browser.\\nCreate your own headless context or use 'createHeadlessContext' from @luma.gl/test-utils\");\n  options = Object.assign({}, CONTEXT_DEFAULTS, options);\n  const {\n    width,\n    height\n  } = options;\n\n  function onError(message) {\n    if (options.throwOnError) {\n      throw new Error(message);\n    }\n\n    console.error(message);\n    return null;\n  }\n\n  options.onError = onError;\n  let gl;\n  const {\n    canvas\n  } = options;\n  const targetCanvas = getCanvas({\n    canvas,\n    width,\n    height,\n    onError\n  });\n  gl = createBrowserContext(targetCanvas, options);\n\n  if (!gl) {\n    return null;\n  }\n\n  gl = instrumentGLContext(gl, options);\n  logInfo(gl);\n  return gl;\n}\nfunction instrumentGLContext(gl) {\n  let options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n\n  if (!gl || gl._instrumented) {\n    return gl;\n  }\n\n  gl._version = gl._version || getVersion(gl);\n  gl.luma = gl.luma || {};\n  gl.luma.canvasSizeInfo = gl.luma.canvasSizeInfo || {};\n  options = Object.assign({}, CONTEXT_DEFAULTS, options);\n  const {\n    manageState,\n    debug\n  } = options;\n\n  if (manageState) {\n    (0,_state_tracker_track_context_state__WEBPACK_IMPORTED_MODULE_0__.trackContextState)(gl, {\n      copyState: false,\n      log: function () {\n        for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\n          args[_key] = arguments[_key];\n        }\n\n        return _utils_log__WEBPACK_IMPORTED_MODULE_1__.log.log(1, ...args)();\n      }\n    });\n  }\n\n  if (isBrowser && debug) {\n    if (!globalThis.makeDebugContext) {\n      _utils_log__WEBPACK_IMPORTED_MODULE_1__.log.warn('WebGL debug mode not activated. import \"@luma.gl/debug\" to enable.')();\n    } else {\n      gl = globalThis.makeDebugContext(gl, options);\n      _utils_log__WEBPACK_IMPORTED_MODULE_1__.log.level = Math.max(_utils_log__WEBPACK_IMPORTED_MODULE_1__.log.level, 1);\n    }\n  }\n\n  gl._instrumented = true;\n  return gl;\n}\nfunction getContextDebugInfo(gl) {\n  const vendorMasked = gl.getParameter(7936);\n  const rendererMasked = gl.getParameter(7937);\n  const ext = gl.getExtension('WEBGL_debug_renderer_info');\n  const vendorUnmasked = ext && gl.getParameter(ext.UNMASKED_VENDOR_WEBGL || 7936);\n  const rendererUnmasked = ext && gl.getParameter(ext.UNMASKED_RENDERER_WEBGL || 7937);\n  return {\n    vendor: vendorUnmasked || vendorMasked,\n    renderer: rendererUnmasked || rendererMasked,\n    vendorMasked,\n    rendererMasked,\n    version: gl.getParameter(7938),\n    shadingLanguageVersion: gl.getParameter(35724)\n  };\n}\nfunction resizeGLContext(gl) {\n  let options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n\n  if (gl.canvas) {\n    const devicePixelRatio = (0,_utils_device_pixels__WEBPACK_IMPORTED_MODULE_3__.getDevicePixelRatio)(options.useDevicePixels);\n    setDevicePixelRatio(gl, devicePixelRatio, options);\n    return;\n  }\n\n  const ext = gl.getExtension('STACKGL_resize_drawingbuffer');\n\n  if (ext && \"width\" in options && \"height\" in options) {\n    ext.resize(options.width, options.height);\n  }\n}\n\nfunction createBrowserContext(canvas, options) {\n  const {\n    onError\n  } = options;\n  let errorMessage = null;\n\n  const onCreateError = error => errorMessage = error.statusMessage || errorMessage;\n\n  canvas.addEventListener('webglcontextcreationerror', onCreateError, false);\n  const {\n    webgl1 = true,\n    webgl2 = true\n  } = options;\n  let gl = null;\n\n  if (webgl2) {\n    gl = gl || canvas.getContext('webgl2', options);\n    gl = gl || canvas.getContext('experimental-webgl2', options);\n  }\n\n  if (webgl1) {\n    gl = gl || canvas.getContext('webgl', options);\n    gl = gl || canvas.getContext('experimental-webgl', options);\n  }\n\n  canvas.removeEventListener('webglcontextcreationerror', onCreateError, false);\n\n  if (!gl) {\n    return onError(\"Failed to create \".concat(webgl2 && !webgl1 ? 'WebGL2' : 'WebGL', \" context: \").concat(errorMessage || 'Unknown error'));\n  }\n\n  if (options.onContextLost) {\n    canvas.addEventListener('webglcontextlost', options.onContextLost, false);\n  }\n\n  if (options.onContextRestored) {\n    canvas.addEventListener('webglcontextrestored', options.onContextRestored, false);\n  }\n\n  return gl;\n}\n\nfunction getCanvas(_ref) {\n  let {\n    canvas,\n    width = 800,\n    height = 600,\n    onError\n  } = _ref;\n  let targetCanvas;\n\n  if (typeof canvas === 'string') {\n    const isPageLoaded = isPage && document.readyState === 'complete';\n\n    if (!isPageLoaded) {\n      onError(\"createGLContext called on canvas '\".concat(canvas, \"' before page was loaded\"));\n    }\n\n    targetCanvas = document.getElementById(canvas);\n  } else if (canvas) {\n    targetCanvas = canvas;\n  } else {\n    targetCanvas = document.createElement('canvas');\n    targetCanvas.id = 'lumagl-canvas';\n    targetCanvas.style.width = Number.isFinite(width) ? \"\".concat(width, \"px\") : '100%';\n    targetCanvas.style.height = Number.isFinite(height) ? \"\".concat(height, \"px\") : '100%';\n    document.body.insertBefore(targetCanvas, document.body.firstChild);\n  }\n\n  return targetCanvas;\n}\n\nfunction logInfo(gl) {\n  const webGL = (0,_utils_webgl_checks__WEBPACK_IMPORTED_MODULE_4__.isWebGL2)(gl) ? 'WebGL2' : 'WebGL1';\n  const info = getContextDebugInfo(gl);\n  const driver = info ? \"(\".concat(info.vendor, \",\").concat(info.renderer, \")\") : '';\n  const debug = gl.debug ? ' debug' : '';\n  _utils_log__WEBPACK_IMPORTED_MODULE_1__.log.info(1, \"\".concat(webGL).concat(debug, \" context \").concat(driver))();\n}\n\nfunction getVersion(gl) {\n  if (typeof WebGL2RenderingContext !== 'undefined' && gl instanceof WebGL2RenderingContext) {\n    return 2;\n  }\n\n  return 1;\n}\n\nfunction setDevicePixelRatio(gl, devicePixelRatio, options) {\n  let clientWidth = 'width' in options ? options.width : gl.canvas.clientWidth;\n  let clientHeight = 'height' in options ? options.height : gl.canvas.clientHeight;\n\n  if (!clientWidth || !clientHeight) {\n    _utils_log__WEBPACK_IMPORTED_MODULE_1__.log.log(1, 'Canvas clientWidth/clientHeight is 0')();\n    devicePixelRatio = 1;\n    clientWidth = gl.canvas.width || 1;\n    clientHeight = gl.canvas.height || 1;\n  }\n\n  gl.luma = gl.luma || {};\n  gl.luma.canvasSizeInfo = gl.luma.canvasSizeInfo || {};\n  const cachedSize = gl.luma.canvasSizeInfo;\n\n  if (cachedSize.clientWidth !== clientWidth || cachedSize.clientHeight !== clientHeight || cachedSize.devicePixelRatio !== devicePixelRatio) {\n    let clampedPixelRatio = devicePixelRatio;\n    const canvasWidth = Math.floor(clientWidth * clampedPixelRatio);\n    const canvasHeight = Math.floor(clientHeight * clampedPixelRatio);\n    gl.canvas.width = canvasWidth;\n    gl.canvas.height = canvasHeight;\n\n    if (gl.drawingBufferWidth !== canvasWidth || gl.drawingBufferHeight !== canvasHeight) {\n      _utils_log__WEBPACK_IMPORTED_MODULE_1__.log.warn(\"Device pixel ratio clamped\")();\n      clampedPixelRatio = Math.min(gl.drawingBufferWidth / clientWidth, gl.drawingBufferHeight / clientHeight);\n      gl.canvas.width = Math.floor(clientWidth * clampedPixelRatio);\n      gl.canvas.height = Math.floor(clientHeight * clampedPixelRatio);\n    }\n\n    Object.assign(gl.luma.canvasSizeInfo, {\n      clientWidth,\n      clientHeight,\n      devicePixelRatio\n    });\n  }\n}\n//# sourceMappingURL=context.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/gltools/dist/esm/context/context.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/gltools/dist/esm/index.js":
/*!*********************************************************!*\
  !*** ./node_modules/@luma.gl/gltools/dist/esm/index.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   assertWebGL2Context: () => (/* reexport safe */ _utils_webgl_checks__WEBPACK_IMPORTED_MODULE_1__.assertWebGL2Context),\n/* harmony export */   assertWebGLContext: () => (/* reexport safe */ _utils_webgl_checks__WEBPACK_IMPORTED_MODULE_1__.assertWebGLContext),\n/* harmony export */   createGLContext: () => (/* reexport safe */ _context_context__WEBPACK_IMPORTED_MODULE_5__.createGLContext),\n/* harmony export */   cssToDevicePixels: () => (/* reexport safe */ _utils_device_pixels__WEBPACK_IMPORTED_MODULE_6__.cssToDevicePixels),\n/* harmony export */   cssToDeviceRatio: () => (/* reexport safe */ _utils_device_pixels__WEBPACK_IMPORTED_MODULE_6__.cssToDeviceRatio),\n/* harmony export */   getContextDebugInfo: () => (/* reexport safe */ _context_context__WEBPACK_IMPORTED_MODULE_5__.getContextDebugInfo),\n/* harmony export */   getParameters: () => (/* reexport safe */ _state_tracker_unified_parameter_api__WEBPACK_IMPORTED_MODULE_3__.getParameters),\n/* harmony export */   getWebGL2Context: () => (/* reexport safe */ _utils_webgl_checks__WEBPACK_IMPORTED_MODULE_1__.getWebGL2Context),\n/* harmony export */   instrumentGLContext: () => (/* reexport safe */ _context_context__WEBPACK_IMPORTED_MODULE_5__.instrumentGLContext),\n/* harmony export */   isWebGL: () => (/* reexport safe */ _utils_webgl_checks__WEBPACK_IMPORTED_MODULE_1__.isWebGL),\n/* harmony export */   isWebGL2: () => (/* reexport safe */ _utils_webgl_checks__WEBPACK_IMPORTED_MODULE_1__.isWebGL2),\n/* harmony export */   log: () => (/* reexport safe */ _utils_log__WEBPACK_IMPORTED_MODULE_0__.log),\n/* harmony export */   polyfillContext: () => (/* reexport safe */ _polyfill_polyfill_context__WEBPACK_IMPORTED_MODULE_2__.polyfillContext),\n/* harmony export */   popContextState: () => (/* reexport safe */ _state_tracker_track_context_state__WEBPACK_IMPORTED_MODULE_4__.popContextState),\n/* harmony export */   pushContextState: () => (/* reexport safe */ _state_tracker_track_context_state__WEBPACK_IMPORTED_MODULE_4__.pushContextState),\n/* harmony export */   resetParameters: () => (/* reexport safe */ _state_tracker_unified_parameter_api__WEBPACK_IMPORTED_MODULE_3__.resetParameters),\n/* harmony export */   resizeGLContext: () => (/* reexport safe */ _context_context__WEBPACK_IMPORTED_MODULE_5__.resizeGLContext),\n/* harmony export */   setParameters: () => (/* reexport safe */ _state_tracker_unified_parameter_api__WEBPACK_IMPORTED_MODULE_3__.setParameters),\n/* harmony export */   trackContextState: () => (/* reexport safe */ _state_tracker_track_context_state__WEBPACK_IMPORTED_MODULE_4__.trackContextState),\n/* harmony export */   withParameters: () => (/* reexport safe */ _state_tracker_unified_parameter_api__WEBPACK_IMPORTED_MODULE_3__.withParameters)\n/* harmony export */ });\n/* harmony import */ var _utils_log__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./utils/log */ \"./node_modules/@luma.gl/gltools/dist/esm/utils/log.js\");\n/* harmony import */ var _utils_webgl_checks__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./utils/webgl-checks */ \"./node_modules/@luma.gl/gltools/dist/esm/utils/webgl-checks.js\");\n/* harmony import */ var _polyfill_polyfill_context__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./polyfill/polyfill-context */ \"./node_modules/@luma.gl/gltools/dist/esm/polyfill/polyfill-context.js\");\n/* harmony import */ var _state_tracker_unified_parameter_api__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./state-tracker/unified-parameter-api */ \"./node_modules/@luma.gl/gltools/dist/esm/state-tracker/unified-parameter-api.js\");\n/* harmony import */ var _state_tracker_track_context_state__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./state-tracker/track-context-state */ \"./node_modules/@luma.gl/gltools/dist/esm/state-tracker/track-context-state.js\");\n/* harmony import */ var _context_context__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./context/context */ \"./node_modules/@luma.gl/gltools/dist/esm/context/context.js\");\n/* harmony import */ var _utils_device_pixels__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./utils/device-pixels */ \"./node_modules/@luma.gl/gltools/dist/esm/utils/device-pixels.js\");\n\n\n\n\n\n\n\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/gltools/dist/esm/index.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/gltools/dist/esm/polyfill/get-parameter-polyfill.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/@luma.gl/gltools/dist/esm/polyfill/get-parameter-polyfill.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getParameterPolyfill: () => (/* binding */ getParameterPolyfill)\n/* harmony export */ });\n/* harmony import */ var _utils_webgl_checks__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/webgl-checks */ \"./node_modules/@luma.gl/gltools/dist/esm/utils/webgl-checks.js\");\n\nconst OES_element_index = 'OES_element_index';\nconst WEBGL_draw_buffers = 'WEBGL_draw_buffers';\nconst EXT_disjoint_timer_query = 'EXT_disjoint_timer_query';\nconst EXT_disjoint_timer_query_webgl2 = 'EXT_disjoint_timer_query_webgl2';\nconst EXT_texture_filter_anisotropic = 'EXT_texture_filter_anisotropic';\nconst WEBGL_debug_renderer_info = 'WEBGL_debug_renderer_info';\nconst GL_FRAGMENT_SHADER_DERIVATIVE_HINT = 0x8b8b;\nconst GL_DONT_CARE = 0x1100;\nconst GL_GPU_DISJOINT_EXT = 0x8fbb;\nconst GL_MAX_TEXTURE_MAX_ANISOTROPY_EXT = 0x84ff;\nconst GL_UNMASKED_VENDOR_WEBGL = 0x9245;\nconst GL_UNMASKED_RENDERER_WEBGL = 0x9246;\n\nconst getWebGL2ValueOrZero = gl => !(0,_utils_webgl_checks__WEBPACK_IMPORTED_MODULE_0__.isWebGL2)(gl) ? 0 : undefined;\n\nconst WEBGL_PARAMETERS = {\n  [3074]: gl => !(0,_utils_webgl_checks__WEBPACK_IMPORTED_MODULE_0__.isWebGL2)(gl) ? 36064 : undefined,\n  [GL_FRAGMENT_SHADER_DERIVATIVE_HINT]: gl => !(0,_utils_webgl_checks__WEBPACK_IMPORTED_MODULE_0__.isWebGL2)(gl) ? GL_DONT_CARE : undefined,\n  [35977]: getWebGL2ValueOrZero,\n  [32937]: getWebGL2ValueOrZero,\n  [GL_GPU_DISJOINT_EXT]: (gl, getParameter) => {\n    const ext = (0,_utils_webgl_checks__WEBPACK_IMPORTED_MODULE_0__.isWebGL2)(gl) ? gl.getExtension(EXT_disjoint_timer_query_webgl2) : gl.getExtension(EXT_disjoint_timer_query);\n    return ext && ext.GPU_DISJOINT_EXT ? getParameter(ext.GPU_DISJOINT_EXT) : 0;\n  },\n  [GL_UNMASKED_VENDOR_WEBGL]: (gl, getParameter) => {\n    const ext = gl.getExtension(WEBGL_debug_renderer_info);\n    return getParameter(ext && ext.UNMASKED_VENDOR_WEBGL || 7936);\n  },\n  [GL_UNMASKED_RENDERER_WEBGL]: (gl, getParameter) => {\n    const ext = gl.getExtension(WEBGL_debug_renderer_info);\n    return getParameter(ext && ext.UNMASKED_RENDERER_WEBGL || 7937);\n  },\n  [GL_MAX_TEXTURE_MAX_ANISOTROPY_EXT]: (gl, getParameter) => {\n    const ext = gl.luma.extensions[EXT_texture_filter_anisotropic];\n    return ext ? getParameter(ext.MAX_TEXTURE_MAX_ANISOTROPY_EXT) : 1.0;\n  },\n  [32883]: getWebGL2ValueOrZero,\n  [35071]: getWebGL2ValueOrZero,\n  [37447]: getWebGL2ValueOrZero,\n  [36063]: (gl, getParameter) => {\n    if (!(0,_utils_webgl_checks__WEBPACK_IMPORTED_MODULE_0__.isWebGL2)(gl)) {\n      const ext = gl.getExtension(WEBGL_draw_buffers);\n      return ext ? getParameter(ext.MAX_COLOR_ATTACHMENTS_WEBGL) : 0;\n    }\n\n    return undefined;\n  },\n  [35379]: getWebGL2ValueOrZero,\n  [35374]: getWebGL2ValueOrZero,\n  [35377]: getWebGL2ValueOrZero,\n  [34852]: gl => {\n    if (!(0,_utils_webgl_checks__WEBPACK_IMPORTED_MODULE_0__.isWebGL2)(gl)) {\n      const ext = gl.getExtension(WEBGL_draw_buffers);\n      return ext ? ext.MAX_DRAW_BUFFERS_WEBGL : 0;\n    }\n\n    return undefined;\n  },\n  [36203]: gl => gl.getExtension(OES_element_index) ? 2147483647 : 65535,\n  [33001]: gl => gl.getExtension(OES_element_index) ? 16777216 : 65535,\n  [33000]: gl => 16777216,\n  [37157]: getWebGL2ValueOrZero,\n  [35373]: getWebGL2ValueOrZero,\n  [35657]: getWebGL2ValueOrZero,\n  [36183]: getWebGL2ValueOrZero,\n  [37137]: getWebGL2ValueOrZero,\n  [34045]: getWebGL2ValueOrZero,\n  [35978]: getWebGL2ValueOrZero,\n  [35979]: getWebGL2ValueOrZero,\n  [35968]: getWebGL2ValueOrZero,\n  [35376]: getWebGL2ValueOrZero,\n  [35375]: getWebGL2ValueOrZero,\n  [35659]: getWebGL2ValueOrZero,\n  [37154]: getWebGL2ValueOrZero,\n  [35371]: getWebGL2ValueOrZero,\n  [35658]: getWebGL2ValueOrZero,\n  [35076]: getWebGL2ValueOrZero,\n  [35077]: getWebGL2ValueOrZero,\n  [35380]: getWebGL2ValueOrZero\n};\nfunction getParameterPolyfill(gl, originalGetParameter, pname) {\n  const limit = WEBGL_PARAMETERS[pname];\n  const value = typeof limit === 'function' ? limit(gl, originalGetParameter, pname) : limit;\n  const result = value !== undefined ? value : originalGetParameter(pname);\n  return result;\n}\n//# sourceMappingURL=get-parameter-polyfill.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/gltools/dist/esm/polyfill/get-parameter-polyfill.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/gltools/dist/esm/polyfill/polyfill-context.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/@luma.gl/gltools/dist/esm/polyfill/polyfill-context.js ***!
  \*****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   polyfillContext: () => (/* binding */ polyfillContext)\n/* harmony export */ });\n/* harmony import */ var _polyfill_vertex_array_object__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./polyfill-vertex-array-object */ \"./node_modules/@luma.gl/gltools/dist/esm/polyfill/polyfill-vertex-array-object.js\");\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/assert */ \"./node_modules/@luma.gl/gltools/dist/esm/utils/assert.js\");\n/* harmony import */ var _polyfill_table__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./polyfill-table */ \"./node_modules/@luma.gl/gltools/dist/esm/polyfill/polyfill-table.js\");\n\n\n\nfunction polyfillContext(gl) {\n  gl.luma = gl.luma || {};\n  const {\n    luma\n  } = gl;\n\n  if (!luma.polyfilled) {\n    (0,_polyfill_vertex_array_object__WEBPACK_IMPORTED_MODULE_0__.polyfillVertexArrayObject)(gl);\n    initializeExtensions(gl);\n    installPolyfills(gl, _polyfill_table__WEBPACK_IMPORTED_MODULE_2__.WEBGL2_CONTEXT_POLYFILLS);\n    installOverrides(gl, {\n      target: luma,\n      target2: gl\n    });\n    luma.polyfilled = true;\n  }\n\n  return gl;\n}\nglobalThis.polyfillContext = polyfillContext;\n\nfunction initializeExtensions(gl) {\n  gl.luma.extensions = {};\n  const EXTENSIONS = gl.getSupportedExtensions() || [];\n\n  for (const extension of EXTENSIONS) {\n    gl.luma[extension] = gl.getExtension(extension);\n  }\n}\n\nfunction installOverrides(gl, _ref) {\n  let {\n    target,\n    target2\n  } = _ref;\n  Object.keys(_polyfill_table__WEBPACK_IMPORTED_MODULE_2__.WEBGL2_CONTEXT_OVERRIDES).forEach(key => {\n    if (typeof _polyfill_table__WEBPACK_IMPORTED_MODULE_2__.WEBGL2_CONTEXT_OVERRIDES[key] === 'function') {\n      const originalFunc = gl[key] ? gl[key].bind(gl) : () => {};\n      const polyfill = _polyfill_table__WEBPACK_IMPORTED_MODULE_2__.WEBGL2_CONTEXT_OVERRIDES[key].bind(null, gl, originalFunc);\n      target[key] = polyfill;\n      target2[key] = polyfill;\n    }\n  });\n}\n\nfunction installPolyfills(gl, polyfills) {\n  for (const extension of Object.getOwnPropertyNames(polyfills)) {\n    if (extension !== 'overrides') {\n      polyfillExtension(gl, {\n        extension,\n        target: gl.luma,\n        target2: gl\n      });\n    }\n  }\n}\n\nfunction polyfillExtension(gl, _ref2) {\n  let {\n    extension,\n    target,\n    target2\n  } = _ref2;\n  const defaults = _polyfill_table__WEBPACK_IMPORTED_MODULE_2__.WEBGL2_CONTEXT_POLYFILLS[extension];\n  (0,_utils_assert__WEBPACK_IMPORTED_MODULE_1__.assert)(defaults);\n  const {\n    meta = {}\n  } = defaults;\n  const {\n    suffix = ''\n  } = meta;\n  const ext = gl.getExtension(extension);\n\n  for (const key of Object.keys(defaults)) {\n    const extKey = \"\".concat(key).concat(suffix);\n    let polyfill = null;\n\n    if (key === 'meta') {} else if (typeof gl[key] === 'function') {} else if (ext && typeof ext[extKey] === 'function') {\n      polyfill = function () {\n        return ext[extKey](...arguments);\n      };\n    } else if (typeof defaults[key] === 'function') {\n      polyfill = defaults[key].bind(target);\n    }\n\n    if (polyfill) {\n      target[key] = polyfill;\n      target2[key] = polyfill;\n    }\n  }\n}\n//# sourceMappingURL=polyfill-context.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/gltools/dist/esm/polyfill/polyfill-context.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/gltools/dist/esm/polyfill/polyfill-table.js":
/*!***************************************************************************!*\
  !*** ./node_modules/@luma.gl/gltools/dist/esm/polyfill/polyfill-table.js ***!
  \***************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   WEBGL2_CONTEXT_OVERRIDES: () => (/* binding */ WEBGL2_CONTEXT_OVERRIDES),\n/* harmony export */   WEBGL2_CONTEXT_POLYFILLS: () => (/* binding */ WEBGL2_CONTEXT_POLYFILLS)\n/* harmony export */ });\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/assert */ \"./node_modules/@luma.gl/gltools/dist/esm/utils/assert.js\");\n/* harmony import */ var _utils_webgl_checks__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/webgl-checks */ \"./node_modules/@luma.gl/gltools/dist/esm/utils/webgl-checks.js\");\n/* harmony import */ var _get_parameter_polyfill__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./get-parameter-polyfill */ \"./node_modules/@luma.gl/gltools/dist/esm/polyfill/get-parameter-polyfill.js\");\n\n\n\nconst OES_vertex_array_object = 'OES_vertex_array_object';\nconst ANGLE_instanced_arrays = 'ANGLE_instanced_arrays';\nconst WEBGL_draw_buffers = 'WEBGL_draw_buffers';\nconst EXT_disjoint_timer_query = 'EXT_disjoint_timer_query';\nconst EXT_texture_filter_anisotropic = 'EXT_texture_filter_anisotropic';\nconst ERR_VAO_NOT_SUPPORTED = 'VertexArray requires WebGL2 or OES_vertex_array_object extension';\n\nfunction getExtensionData(gl, extension) {\n  return {\n    webgl2: (0,_utils_webgl_checks__WEBPACK_IMPORTED_MODULE_1__.isWebGL2)(gl),\n    ext: gl.getExtension(extension)\n  };\n}\n\nconst WEBGL2_CONTEXT_POLYFILLS = {\n  [OES_vertex_array_object]: {\n    meta: {\n      suffix: 'OES'\n    },\n    createVertexArray: () => {\n      (0,_utils_assert__WEBPACK_IMPORTED_MODULE_0__.assert)(false, ERR_VAO_NOT_SUPPORTED);\n    },\n    deleteVertexArray: () => {},\n    bindVertexArray: () => {},\n    isVertexArray: () => false\n  },\n  [ANGLE_instanced_arrays]: {\n    meta: {\n      suffix: 'ANGLE'\n    },\n\n    vertexAttribDivisor(location, divisor) {\n      (0,_utils_assert__WEBPACK_IMPORTED_MODULE_0__.assert)(divisor === 0, 'WebGL instanced rendering not supported');\n    },\n\n    drawElementsInstanced: () => {},\n    drawArraysInstanced: () => {}\n  },\n  [WEBGL_draw_buffers]: {\n    meta: {\n      suffix: 'WEBGL'\n    },\n    drawBuffers: () => {\n      (0,_utils_assert__WEBPACK_IMPORTED_MODULE_0__.assert)(false);\n    }\n  },\n  [EXT_disjoint_timer_query]: {\n    meta: {\n      suffix: 'EXT'\n    },\n    createQuery: () => {\n      (0,_utils_assert__WEBPACK_IMPORTED_MODULE_0__.assert)(false);\n    },\n    deleteQuery: () => {\n      (0,_utils_assert__WEBPACK_IMPORTED_MODULE_0__.assert)(false);\n    },\n    beginQuery: () => {\n      (0,_utils_assert__WEBPACK_IMPORTED_MODULE_0__.assert)(false);\n    },\n    endQuery: () => {},\n\n    getQuery(handle, pname) {\n      return this.getQueryObject(handle, pname);\n    },\n\n    getQueryParameter(handle, pname) {\n      return this.getQueryObject(handle, pname);\n    },\n\n    getQueryObject: () => {}\n  }\n};\nconst WEBGL2_CONTEXT_OVERRIDES = {\n  readBuffer: (gl, originalFunc, attachment) => {\n    if ((0,_utils_webgl_checks__WEBPACK_IMPORTED_MODULE_1__.isWebGL2)(gl)) {\n      originalFunc(attachment);\n    } else {}\n  },\n  getVertexAttrib: (gl, originalFunc, location, pname) => {\n    const {\n      webgl2,\n      ext\n    } = getExtensionData(gl, ANGLE_instanced_arrays);\n    let result;\n\n    switch (pname) {\n      case 35069:\n        result = !webgl2 ? false : undefined;\n        break;\n\n      case 35070:\n        result = !webgl2 && !ext ? 0 : undefined;\n        break;\n\n      default:\n    }\n\n    return result !== undefined ? result : originalFunc(location, pname);\n  },\n  getProgramParameter: (gl, originalFunc, program, pname) => {\n    if (!(0,_utils_webgl_checks__WEBPACK_IMPORTED_MODULE_1__.isWebGL2)(gl)) {\n      switch (pname) {\n        case 35967:\n          return 35981;\n\n        case 35971:\n          return 0;\n\n        case 35382:\n          return 0;\n\n        default:\n      }\n    }\n\n    return originalFunc(program, pname);\n  },\n  getInternalformatParameter: (gl, originalFunc, target, format, pname) => {\n    if (!(0,_utils_webgl_checks__WEBPACK_IMPORTED_MODULE_1__.isWebGL2)(gl)) {\n      switch (pname) {\n        case 32937:\n          return new Int32Array([0]);\n\n        default:\n      }\n    }\n\n    return gl.getInternalformatParameter(target, format, pname);\n  },\n\n  getTexParameter(gl, originalFunc, target, pname) {\n    switch (pname) {\n      case 34046:\n        const {\n          extensions\n        } = gl.luma;\n        const ext = extensions[EXT_texture_filter_anisotropic];\n        pname = ext && ext.TEXTURE_MAX_ANISOTROPY_EXT || 34046;\n        break;\n\n      default:\n    }\n\n    return originalFunc(target, pname);\n  },\n\n  getParameter: _get_parameter_polyfill__WEBPACK_IMPORTED_MODULE_2__.getParameterPolyfill,\n\n  hint(gl, originalFunc, pname, value) {\n    return originalFunc(pname, value);\n  }\n\n};\n//# sourceMappingURL=polyfill-table.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/gltools/dist/esm/polyfill/polyfill-table.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/gltools/dist/esm/polyfill/polyfill-vertex-array-object.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/@luma.gl/gltools/dist/esm/polyfill/polyfill-vertex-array-object.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   polyfillVertexArrayObject: () => (/* binding */ polyfillVertexArrayObject)\n/* harmony export */ });\nconst glErrorShadow = {};\n\nfunction error(msg) {\n  if (globalThis.console && globalThis.console.error) {\n    globalThis.console.error(msg);\n  }\n}\n\nfunction log(msg) {\n  if (globalThis.console && globalThis.console.log) {\n    globalThis.console.log(msg);\n  }\n}\n\nfunction synthesizeGLError(err, opt_msg) {\n  glErrorShadow[err] = true;\n\n  if (opt_msg !== undefined) {\n    error(opt_msg);\n  }\n}\n\nfunction wrapGLError(gl) {\n  const f = gl.getError;\n\n  gl.getError = function getError() {\n    let err;\n\n    do {\n      err = f.apply(gl);\n\n      if (err !== 0) {\n        glErrorShadow[err] = true;\n      }\n    } while (err !== 0);\n\n    for (err in glErrorShadow) {\n      if (glErrorShadow[err]) {\n        delete glErrorShadow[err];\n        return parseInt(err, 10);\n      }\n    }\n\n    return 0;\n  };\n}\n\nconst WebGLVertexArrayObjectOES = function WebGLVertexArrayObjectOES(ext) {\n  const gl = ext.gl;\n  this.ext = ext;\n  this.isAlive = true;\n  this.hasBeenBound = false;\n  this.elementArrayBuffer = null;\n  this.attribs = new Array(ext.maxVertexAttribs);\n\n  for (let n = 0; n < this.attribs.length; n++) {\n    const attrib = new WebGLVertexArrayObjectOES.VertexAttrib(gl);\n    this.attribs[n] = attrib;\n  }\n\n  this.maxAttrib = 0;\n};\n\nWebGLVertexArrayObjectOES.VertexAttrib = function VertexAttrib(gl) {\n  this.enabled = false;\n  this.buffer = null;\n  this.size = 4;\n  this.type = 5126;\n  this.normalized = false;\n  this.stride = 16;\n  this.offset = 0;\n  this.cached = '';\n  this.recache();\n};\n\nWebGLVertexArrayObjectOES.VertexAttrib.prototype.recache = function recache() {\n  this.cached = [this.size, this.type, this.normalized, this.stride, this.offset].join(':');\n};\n\nconst OESVertexArrayObject = function OESVertexArrayObject(gl) {\n  const self = this;\n  this.gl = gl;\n  wrapGLError(gl);\n  const original = this.original = {\n    getParameter: gl.getParameter,\n    enableVertexAttribArray: gl.enableVertexAttribArray,\n    disableVertexAttribArray: gl.disableVertexAttribArray,\n    bindBuffer: gl.bindBuffer,\n    getVertexAttrib: gl.getVertexAttrib,\n    vertexAttribPointer: gl.vertexAttribPointer\n  };\n\n  gl.getParameter = function getParameter(pname) {\n    if (pname === self.VERTEX_ARRAY_BINDING_OES) {\n      if (self.currentVertexArrayObject === self.defaultVertexArrayObject) {\n        return null;\n      }\n\n      return self.currentVertexArrayObject;\n    }\n\n    return original.getParameter.apply(this, arguments);\n  };\n\n  gl.enableVertexAttribArray = function enableVertexAttribArray(index) {\n    const vao = self.currentVertexArrayObject;\n    vao.maxAttrib = Math.max(vao.maxAttrib, index);\n    const attrib = vao.attribs[index];\n    attrib.enabled = true;\n    return original.enableVertexAttribArray.apply(this, arguments);\n  };\n\n  gl.disableVertexAttribArray = function disableVertexAttribArray(index) {\n    const vao = self.currentVertexArrayObject;\n    vao.maxAttrib = Math.max(vao.maxAttrib, index);\n    const attrib = vao.attribs[index];\n    attrib.enabled = false;\n    return original.disableVertexAttribArray.apply(this, arguments);\n  };\n\n  gl.bindBuffer = function bindBuffer(target, buffer) {\n    switch (target) {\n      case 34962:\n        self.currentArrayBuffer = buffer;\n        break;\n\n      case 34963:\n        self.currentVertexArrayObject.elementArrayBuffer = buffer;\n        break;\n\n      default:\n    }\n\n    return original.bindBuffer.apply(this, arguments);\n  };\n\n  gl.getVertexAttrib = function getVertexAttrib(index, pname) {\n    const vao = self.currentVertexArrayObject;\n    const attrib = vao.attribs[index];\n\n    switch (pname) {\n      case 34975:\n        return attrib.buffer;\n\n      case 34338:\n        return attrib.enabled;\n\n      case 34339:\n        return attrib.size;\n\n      case 34340:\n        return attrib.stride;\n\n      case 34341:\n        return attrib.type;\n\n      case 34922:\n        return attrib.normalized;\n\n      default:\n        return original.getVertexAttrib.apply(this, arguments);\n    }\n  };\n\n  gl.vertexAttribPointer = function vertexAttribPointer(indx, size, type, normalized, stride, offset) {\n    const vao = self.currentVertexArrayObject;\n    vao.maxAttrib = Math.max(vao.maxAttrib, indx);\n    const attrib = vao.attribs[indx];\n    attrib.buffer = self.currentArrayBuffer;\n    attrib.size = size;\n    attrib.type = type;\n    attrib.normalized = normalized;\n    attrib.stride = stride;\n    attrib.offset = offset;\n    attrib.recache();\n    return original.vertexAttribPointer.apply(this, arguments);\n  };\n\n  if (gl.instrumentExtension) {\n    gl.instrumentExtension(this, 'OES_vertex_array_object');\n  }\n\n  if (gl.canvas) {\n    gl.canvas.addEventListener('webglcontextrestored', () => {\n      log('OESVertexArrayObject emulation library context restored');\n      self.reset_();\n    }, true);\n  }\n\n  this.reset_();\n};\n\nOESVertexArrayObject.prototype.VERTEX_ARRAY_BINDING_OES = 0x85b5;\n\nOESVertexArrayObject.prototype.reset_ = function reset_() {\n  const contextWasLost = this.vertexArrayObjects !== undefined;\n\n  if (contextWasLost) {\n    for (let ii = 0; ii < this.vertexArrayObjects.length; ++ii) {\n      this.vertexArrayObjects.isAlive = false;\n    }\n  }\n\n  const gl = this.gl;\n  this.maxVertexAttribs = gl.getParameter(34921);\n  this.defaultVertexArrayObject = new WebGLVertexArrayObjectOES(this);\n  this.currentVertexArrayObject = null;\n  this.currentArrayBuffer = null;\n  this.vertexArrayObjects = [this.defaultVertexArrayObject];\n  this.bindVertexArrayOES(null);\n};\n\nOESVertexArrayObject.prototype.createVertexArrayOES = function createVertexArrayOES() {\n  const arrayObject = new WebGLVertexArrayObjectOES(this);\n  this.vertexArrayObjects.push(arrayObject);\n  return arrayObject;\n};\n\nOESVertexArrayObject.prototype.deleteVertexArrayOES = function deleteVertexArrayOES(arrayObject) {\n  arrayObject.isAlive = false;\n  this.vertexArrayObjects.splice(this.vertexArrayObjects.indexOf(arrayObject), 1);\n\n  if (this.currentVertexArrayObject === arrayObject) {\n    this.bindVertexArrayOES(null);\n  }\n};\n\nOESVertexArrayObject.prototype.isVertexArrayOES = function isVertexArrayOES(arrayObject) {\n  if (arrayObject && arrayObject instanceof WebGLVertexArrayObjectOES) {\n    if (arrayObject.hasBeenBound && arrayObject.ext === this) {\n      return true;\n    }\n  }\n\n  return false;\n};\n\nOESVertexArrayObject.prototype.bindVertexArrayOES = function bindVertexArrayOES(arrayObject) {\n  const gl = this.gl;\n\n  if (arrayObject && !arrayObject.isAlive) {\n    synthesizeGLError(1282, 'bindVertexArrayOES: attempt to bind deleted arrayObject');\n    return;\n  }\n\n  const original = this.original;\n  const oldVAO = this.currentVertexArrayObject;\n  this.currentVertexArrayObject = arrayObject || this.defaultVertexArrayObject;\n  this.currentVertexArrayObject.hasBeenBound = true;\n  const newVAO = this.currentVertexArrayObject;\n\n  if (oldVAO === newVAO) {\n    return;\n  }\n\n  if (!oldVAO || newVAO.elementArrayBuffer !== oldVAO.elementArrayBuffer) {\n    original.bindBuffer.call(gl, 34963, newVAO.elementArrayBuffer);\n  }\n\n  let currentBinding = this.currentArrayBuffer;\n  const maxAttrib = Math.max(oldVAO ? oldVAO.maxAttrib : 0, newVAO.maxAttrib);\n\n  for (let n = 0; n <= maxAttrib; n++) {\n    const attrib = newVAO.attribs[n];\n    const oldAttrib = oldVAO ? oldVAO.attribs[n] : null;\n\n    if (!oldVAO || attrib.enabled !== oldAttrib.enabled) {\n      if (attrib.enabled) {\n        original.enableVertexAttribArray.call(gl, n);\n      } else {\n        original.disableVertexAttribArray.call(gl, n);\n      }\n    }\n\n    if (attrib.enabled) {\n      let bufferChanged = false;\n\n      if (!oldVAO || attrib.buffer !== oldAttrib.buffer) {\n        if (currentBinding !== attrib.buffer) {\n          original.bindBuffer.call(gl, 34962, attrib.buffer);\n          currentBinding = attrib.buffer;\n        }\n\n        bufferChanged = true;\n      }\n\n      if (bufferChanged || attrib.cached !== oldAttrib.cached) {\n        original.vertexAttribPointer.call(gl, n, attrib.size, attrib.type, attrib.normalized, attrib.stride, attrib.offset);\n      }\n    }\n  }\n\n  if (this.currentArrayBuffer !== currentBinding) {\n    original.bindBuffer.call(gl, 34962, this.currentArrayBuffer);\n  }\n};\n\nfunction polyfillVertexArrayObject(gl) {\n  if (typeof gl.createVertexArray === 'function') {\n    return;\n  }\n\n  const original_getSupportedExtensions = gl.getSupportedExtensions;\n\n  gl.getSupportedExtensions = function getSupportedExtensions() {\n    const list = original_getSupportedExtensions.call(this) || [];\n\n    if (list.indexOf('OES_vertex_array_object') < 0) {\n      list.push('OES_vertex_array_object');\n    }\n\n    return list;\n  };\n\n  const original_getExtension = gl.getExtension;\n\n  gl.getExtension = function getExtension(name) {\n    const ext = original_getExtension.call(this, name);\n\n    if (ext) {\n      return ext;\n    }\n\n    if (name !== 'OES_vertex_array_object') {\n      return null;\n    }\n\n    if (!gl.__OESVertexArrayObject) {\n      this.__OESVertexArrayObject = new OESVertexArrayObject(this);\n    }\n\n    return this.__OESVertexArrayObject;\n  };\n}\n//# sourceMappingURL=polyfill-vertex-array-object.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/gltools/dist/esm/polyfill/polyfill-vertex-array-object.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/gltools/dist/esm/state-tracker/track-context-state.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/@luma.gl/gltools/dist/esm/state-tracker/track-context-state.js ***!
  \*************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   popContextState: () => (/* binding */ popContextState),\n/* harmony export */   pushContextState: () => (/* binding */ pushContextState),\n/* harmony export */   trackContextState: () => (/* binding */ trackContextState)\n/* harmony export */ });\n/* harmony import */ var _webgl_parameter_tables__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./webgl-parameter-tables */ \"./node_modules/@luma.gl/gltools/dist/esm/state-tracker/webgl-parameter-tables.js\");\n/* harmony import */ var _unified_parameter_api__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./unified-parameter-api */ \"./node_modules/@luma.gl/gltools/dist/esm/state-tracker/unified-parameter-api.js\");\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/assert */ \"./node_modules/@luma.gl/gltools/dist/esm/utils/assert.js\");\n/* harmony import */ var _utils_utils__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/utils */ \"./node_modules/@luma.gl/gltools/dist/esm/utils/utils.js\");\n\n\n\n\n\nfunction installGetterOverride(gl, functionName) {\n  const originalGetterFunc = gl[functionName].bind(gl);\n\n  gl[functionName] = function get() {\n    const pname = arguments.length <= 0 ? undefined : arguments[0];\n\n    if (!(pname in gl.state.cache)) {\n      return originalGetterFunc(...arguments);\n    }\n\n    return gl.state.enable ? gl.state.cache[pname] : originalGetterFunc(...arguments);\n  };\n\n  Object.defineProperty(gl[functionName], 'name', {\n    value: \"\".concat(functionName, \"-from-cache\"),\n    configurable: false\n  });\n}\n\nfunction installSetterSpy(gl, functionName, setter) {\n  const originalSetterFunc = gl[functionName].bind(gl);\n\n  gl[functionName] = function set() {\n    for (var _len = arguments.length, params = new Array(_len), _key = 0; _key < _len; _key++) {\n      params[_key] = arguments[_key];\n    }\n\n    const {\n      valueChanged,\n      oldValue\n    } = setter(gl.state._updateCache, ...params);\n\n    if (valueChanged) {\n      originalSetterFunc(...params);\n    }\n\n    return oldValue;\n  };\n\n  Object.defineProperty(gl[functionName], 'name', {\n    value: \"\".concat(functionName, \"-to-cache\"),\n    configurable: false\n  });\n}\n\nfunction installProgramSpy(gl) {\n  const originalUseProgram = gl.useProgram.bind(gl);\n\n  gl.useProgram = function useProgramLuma(handle) {\n    if (gl.state.program !== handle) {\n      originalUseProgram(handle);\n      gl.state.program = handle;\n    }\n  };\n}\n\nclass GLState {\n  constructor(gl) {\n    let {\n      copyState = false,\n      log = () => {}\n    } = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    this.gl = gl;\n    this.program = null;\n    this.stateStack = [];\n    this.enable = true;\n    this.cache = copyState ? (0,_unified_parameter_api__WEBPACK_IMPORTED_MODULE_1__.getParameters)(gl) : Object.assign({}, _webgl_parameter_tables__WEBPACK_IMPORTED_MODULE_0__.GL_PARAMETER_DEFAULTS);\n    this.log = log;\n    this._updateCache = this._updateCache.bind(this);\n    Object.seal(this);\n  }\n\n  push() {\n    let values = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    this.stateStack.push({});\n  }\n\n  pop() {\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_2__.assert)(this.stateStack.length > 0);\n    const oldValues = this.stateStack[this.stateStack.length - 1];\n    (0,_unified_parameter_api__WEBPACK_IMPORTED_MODULE_1__.setParameters)(this.gl, oldValues);\n    this.stateStack.pop();\n  }\n\n  _updateCache(values) {\n    let valueChanged = false;\n    let oldValue;\n    const oldValues = this.stateStack.length > 0 && this.stateStack[this.stateStack.length - 1];\n\n    for (const key in values) {\n      (0,_utils_assert__WEBPACK_IMPORTED_MODULE_2__.assert)(key !== undefined);\n      const value = values[key];\n      const cached = this.cache[key];\n\n      if (!(0,_utils_utils__WEBPACK_IMPORTED_MODULE_3__.deepArrayEqual)(value, cached)) {\n        valueChanged = true;\n        oldValue = cached;\n\n        if (oldValues && !(key in oldValues)) {\n          oldValues[key] = cached;\n        }\n\n        this.cache[key] = value;\n      }\n    }\n\n    return {\n      valueChanged,\n      oldValue\n    };\n  }\n\n}\n\nfunction trackContextState(gl) {\n  let options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  const {\n    enable = true,\n    copyState\n  } = options;\n  (0,_utils_assert__WEBPACK_IMPORTED_MODULE_2__.assert)(copyState !== undefined);\n\n  if (!gl.state) {\n    const {\n      polyfillContext\n    } = globalThis;\n\n    if (polyfillContext) {\n      polyfillContext(gl);\n    }\n\n    gl.state = new GLState(gl, {\n      copyState\n    });\n    installProgramSpy(gl);\n\n    for (const key in _webgl_parameter_tables__WEBPACK_IMPORTED_MODULE_0__.GL_HOOKED_SETTERS) {\n      const setter = _webgl_parameter_tables__WEBPACK_IMPORTED_MODULE_0__.GL_HOOKED_SETTERS[key];\n      installSetterSpy(gl, key, setter);\n    }\n\n    installGetterOverride(gl, 'getParameter');\n    installGetterOverride(gl, 'isEnabled');\n  }\n\n  gl.state.enable = enable;\n  return gl;\n}\nfunction pushContextState(gl) {\n  if (!gl.state) {\n    trackContextState(gl, {\n      copyState: false\n    });\n  }\n\n  gl.state.push();\n}\nfunction popContextState(gl) {\n  (0,_utils_assert__WEBPACK_IMPORTED_MODULE_2__.assert)(gl.state);\n  gl.state.pop();\n}\n//# sourceMappingURL=track-context-state.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/gltools/dist/esm/state-tracker/track-context-state.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/gltools/dist/esm/state-tracker/unified-parameter-api.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/@luma.gl/gltools/dist/esm/state-tracker/unified-parameter-api.js ***!
  \***************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getParameters: () => (/* binding */ getParameters),\n/* harmony export */   resetParameters: () => (/* binding */ resetParameters),\n/* harmony export */   setParameters: () => (/* binding */ setParameters),\n/* harmony export */   withParameters: () => (/* binding */ withParameters)\n/* harmony export */ });\n/* harmony import */ var _webgl_parameter_tables__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./webgl-parameter-tables */ \"./node_modules/@luma.gl/gltools/dist/esm/state-tracker/webgl-parameter-tables.js\");\n/* harmony import */ var _track_context_state__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./track-context-state */ \"./node_modules/@luma.gl/gltools/dist/esm/state-tracker/track-context-state.js\");\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/assert */ \"./node_modules/@luma.gl/gltools/dist/esm/utils/assert.js\");\n/* harmony import */ var _utils_webgl_checks__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/webgl-checks */ \"./node_modules/@luma.gl/gltools/dist/esm/utils/webgl-checks.js\");\n/* harmony import */ var _utils_utils__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../utils/utils */ \"./node_modules/@luma.gl/gltools/dist/esm/utils/utils.js\");\n\n\n\n\n\nfunction setParameters(gl, values) {\n  (0,_utils_assert__WEBPACK_IMPORTED_MODULE_2__.assert)((0,_utils_webgl_checks__WEBPACK_IMPORTED_MODULE_3__.isWebGL)(gl), 'setParameters requires a WebGL context');\n\n  if ((0,_utils_utils__WEBPACK_IMPORTED_MODULE_4__.isObjectEmpty)(values)) {\n    return;\n  }\n\n  const compositeSetters = {};\n\n  for (const key in values) {\n    const glConstant = Number(key);\n    const setter = _webgl_parameter_tables__WEBPACK_IMPORTED_MODULE_0__.GL_PARAMETER_SETTERS[key];\n\n    if (setter) {\n      if (typeof setter === 'string') {\n        compositeSetters[setter] = true;\n      } else {\n        setter(gl, values[key], glConstant);\n      }\n    }\n  }\n\n  const cache = gl.state && gl.state.cache;\n\n  if (cache) {\n    for (const key in compositeSetters) {\n      const compositeSetter = _webgl_parameter_tables__WEBPACK_IMPORTED_MODULE_0__.GL_COMPOSITE_PARAMETER_SETTERS[key];\n      compositeSetter(gl, values, cache);\n    }\n  }\n}\nfunction getParameters(gl, parameters) {\n  parameters = parameters || _webgl_parameter_tables__WEBPACK_IMPORTED_MODULE_0__.GL_PARAMETER_DEFAULTS;\n\n  if (typeof parameters === 'number') {\n    const key = parameters;\n    const getter = _webgl_parameter_tables__WEBPACK_IMPORTED_MODULE_0__.GL_PARAMETER_GETTERS[key];\n    return getter ? getter(gl, key) : gl.getParameter(key);\n  }\n\n  const parameterKeys = Array.isArray(parameters) ? parameters : Object.keys(parameters);\n  const state = {};\n\n  for (const key of parameterKeys) {\n    const getter = _webgl_parameter_tables__WEBPACK_IMPORTED_MODULE_0__.GL_PARAMETER_GETTERS[key];\n    state[key] = getter ? getter(gl, Number(key)) : gl.getParameter(Number(key));\n  }\n\n  return state;\n}\nfunction resetParameters(gl) {\n  setParameters(gl, _webgl_parameter_tables__WEBPACK_IMPORTED_MODULE_0__.GL_PARAMETER_DEFAULTS);\n}\nfunction withParameters(gl, parameters, func) {\n  if ((0,_utils_utils__WEBPACK_IMPORTED_MODULE_4__.isObjectEmpty)(parameters)) {\n    return func(gl);\n  }\n\n  const {\n    nocatch = true\n  } = parameters;\n  (0,_track_context_state__WEBPACK_IMPORTED_MODULE_1__.pushContextState)(gl);\n  setParameters(gl, parameters);\n  let value;\n\n  if (nocatch) {\n    value = func(gl);\n    (0,_track_context_state__WEBPACK_IMPORTED_MODULE_1__.popContextState)(gl);\n  } else {\n    try {\n      value = func(gl);\n    } finally {\n      (0,_track_context_state__WEBPACK_IMPORTED_MODULE_1__.popContextState)(gl);\n    }\n  }\n\n  return value;\n}\n//# sourceMappingURL=unified-parameter-api.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/gltools/dist/esm/state-tracker/unified-parameter-api.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/gltools/dist/esm/state-tracker/webgl-parameter-tables.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/@luma.gl/gltools/dist/esm/state-tracker/webgl-parameter-tables.js ***!
  \****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   GL_COMPOSITE_PARAMETER_SETTERS: () => (/* binding */ GL_COMPOSITE_PARAMETER_SETTERS),\n/* harmony export */   GL_HOOKED_SETTERS: () => (/* binding */ GL_HOOKED_SETTERS),\n/* harmony export */   GL_PARAMETER_DEFAULTS: () => (/* binding */ GL_PARAMETER_DEFAULTS),\n/* harmony export */   GL_PARAMETER_GETTERS: () => (/* binding */ GL_PARAMETER_GETTERS),\n/* harmony export */   GL_PARAMETER_SETTERS: () => (/* binding */ GL_PARAMETER_SETTERS)\n/* harmony export */ });\n/* harmony import */ var _utils_webgl_checks__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/webgl-checks */ \"./node_modules/@luma.gl/gltools/dist/esm/utils/webgl-checks.js\");\n\nconst GL_PARAMETER_DEFAULTS = {\n  [3042]: false,\n  [32773]: new Float32Array([0, 0, 0, 0]),\n  [32777]: 32774,\n  [34877]: 32774,\n  [32969]: 1,\n  [32968]: 0,\n  [32971]: 1,\n  [32970]: 0,\n  [3106]: new Float32Array([0, 0, 0, 0]),\n  [3107]: [true, true, true, true],\n  [2884]: false,\n  [2885]: 1029,\n  [2929]: false,\n  [2931]: 1,\n  [2932]: 513,\n  [2928]: new Float32Array([0, 1]),\n  [2930]: true,\n  [3024]: true,\n  [36006]: null,\n  [2886]: 2305,\n  [33170]: 4352,\n  [2849]: 1,\n  [32823]: false,\n  [32824]: 0,\n  [10752]: 0,\n  [32938]: 1.0,\n  [32939]: false,\n  [3089]: false,\n  [3088]: new Int32Array([0, 0, 1024, 1024]),\n  [2960]: false,\n  [2961]: 0,\n  [2968]: 0xffffffff,\n  [36005]: 0xffffffff,\n  [2962]: 519,\n  [2967]: 0,\n  [2963]: 0xffffffff,\n  [34816]: 519,\n  [36003]: 0,\n  [36004]: 0xffffffff,\n  [2964]: 7680,\n  [2965]: 7680,\n  [2966]: 7680,\n  [34817]: 7680,\n  [34818]: 7680,\n  [34819]: 7680,\n  [2978]: [0, 0, 1024, 1024],\n  [3333]: 4,\n  [3317]: 4,\n  [37440]: false,\n  [37441]: false,\n  [37443]: 37444,\n  [35723]: 4352,\n  [36010]: null,\n  [35977]: false,\n  [3330]: 0,\n  [3332]: 0,\n  [3331]: 0,\n  [3314]: 0,\n  [32878]: 0,\n  [3316]: 0,\n  [3315]: 0,\n  [32877]: 0\n};\n\nconst enable = (gl, value, key) => value ? gl.enable(key) : gl.disable(key);\n\nconst hint = (gl, value, key) => gl.hint(key, value);\n\nconst pixelStorei = (gl, value, key) => gl.pixelStorei(key, value);\n\nconst drawFramebuffer = (gl, value) => {\n  const target = (0,_utils_webgl_checks__WEBPACK_IMPORTED_MODULE_0__.isWebGL2)(gl) ? 36009 : 36160;\n  return gl.bindFramebuffer(target, value);\n};\n\nconst readFramebuffer = (gl, value) => {\n  return gl.bindFramebuffer(36008, value);\n};\n\nfunction isArray(array) {\n  return Array.isArray(array) || ArrayBuffer.isView(array);\n}\n\nconst GL_PARAMETER_SETTERS = {\n  [3042]: enable,\n  [32773]: (gl, value) => gl.blendColor(...value),\n  [32777]: 'blendEquation',\n  [34877]: 'blendEquation',\n  [32969]: 'blendFunc',\n  [32968]: 'blendFunc',\n  [32971]: 'blendFunc',\n  [32970]: 'blendFunc',\n  [3106]: (gl, value) => gl.clearColor(...value),\n  [3107]: (gl, value) => gl.colorMask(...value),\n  [2884]: enable,\n  [2885]: (gl, value) => gl.cullFace(value),\n  [2929]: enable,\n  [2931]: (gl, value) => gl.clearDepth(value),\n  [2932]: (gl, value) => gl.depthFunc(value),\n  [2928]: (gl, value) => gl.depthRange(...value),\n  [2930]: (gl, value) => gl.depthMask(value),\n  [3024]: enable,\n  [35723]: hint,\n  [36006]: drawFramebuffer,\n  [2886]: (gl, value) => gl.frontFace(value),\n  [33170]: hint,\n  [2849]: (gl, value) => gl.lineWidth(value),\n  [32823]: enable,\n  [32824]: 'polygonOffset',\n  [10752]: 'polygonOffset',\n  [35977]: enable,\n  [32938]: 'sampleCoverage',\n  [32939]: 'sampleCoverage',\n  [3089]: enable,\n  [3088]: (gl, value) => gl.scissor(...value),\n  [2960]: enable,\n  [2961]: (gl, value) => gl.clearStencil(value),\n  [2968]: (gl, value) => gl.stencilMaskSeparate(1028, value),\n  [36005]: (gl, value) => gl.stencilMaskSeparate(1029, value),\n  [2962]: 'stencilFuncFront',\n  [2967]: 'stencilFuncFront',\n  [2963]: 'stencilFuncFront',\n  [34816]: 'stencilFuncBack',\n  [36003]: 'stencilFuncBack',\n  [36004]: 'stencilFuncBack',\n  [2964]: 'stencilOpFront',\n  [2965]: 'stencilOpFront',\n  [2966]: 'stencilOpFront',\n  [34817]: 'stencilOpBack',\n  [34818]: 'stencilOpBack',\n  [34819]: 'stencilOpBack',\n  [2978]: (gl, value) => gl.viewport(...value),\n  [3333]: pixelStorei,\n  [3317]: pixelStorei,\n  [37440]: pixelStorei,\n  [37441]: pixelStorei,\n  [37443]: pixelStorei,\n  [3330]: pixelStorei,\n  [3332]: pixelStorei,\n  [3331]: pixelStorei,\n  [36010]: readFramebuffer,\n  [3314]: pixelStorei,\n  [32878]: pixelStorei,\n  [3316]: pixelStorei,\n  [3315]: pixelStorei,\n  [32877]: pixelStorei,\n  framebuffer: (gl, framebuffer) => {\n    const handle = framebuffer && 'handle' in framebuffer ? framebuffer.handle : framebuffer;\n    return gl.bindFramebuffer(36160, handle);\n  },\n  blend: (gl, value) => value ? gl.enable(3042) : gl.disable(3042),\n  blendColor: (gl, value) => gl.blendColor(...value),\n  blendEquation: (gl, args) => {\n    args = isArray(args) ? args : [args, args];\n    gl.blendEquationSeparate(...args);\n  },\n  blendFunc: (gl, args) => {\n    args = isArray(args) && args.length === 2 ? [...args, ...args] : args;\n    gl.blendFuncSeparate(...args);\n  },\n  clearColor: (gl, value) => gl.clearColor(...value),\n  clearDepth: (gl, value) => gl.clearDepth(value),\n  clearStencil: (gl, value) => gl.clearStencil(value),\n  colorMask: (gl, value) => gl.colorMask(...value),\n  cull: (gl, value) => value ? gl.enable(2884) : gl.disable(2884),\n  cullFace: (gl, value) => gl.cullFace(value),\n  depthTest: (gl, value) => value ? gl.enable(2929) : gl.disable(2929),\n  depthFunc: (gl, value) => gl.depthFunc(value),\n  depthMask: (gl, value) => gl.depthMask(value),\n  depthRange: (gl, value) => gl.depthRange(...value),\n  dither: (gl, value) => value ? gl.enable(3024) : gl.disable(3024),\n  derivativeHint: (gl, value) => {\n    gl.hint(35723, value);\n  },\n  frontFace: (gl, value) => gl.frontFace(value),\n  mipmapHint: (gl, value) => gl.hint(33170, value),\n  lineWidth: (gl, value) => gl.lineWidth(value),\n  polygonOffsetFill: (gl, value) => value ? gl.enable(32823) : gl.disable(32823),\n  polygonOffset: (gl, value) => gl.polygonOffset(...value),\n  sampleCoverage: (gl, value) => gl.sampleCoverage(...value),\n  scissorTest: (gl, value) => value ? gl.enable(3089) : gl.disable(3089),\n  scissor: (gl, value) => gl.scissor(...value),\n  stencilTest: (gl, value) => value ? gl.enable(2960) : gl.disable(2960),\n  stencilMask: (gl, value) => {\n    value = isArray(value) ? value : [value, value];\n    const [mask, backMask] = value;\n    gl.stencilMaskSeparate(1028, mask);\n    gl.stencilMaskSeparate(1029, backMask);\n  },\n  stencilFunc: (gl, args) => {\n    args = isArray(args) && args.length === 3 ? [...args, ...args] : args;\n    const [func, ref, mask, backFunc, backRef, backMask] = args;\n    gl.stencilFuncSeparate(1028, func, ref, mask);\n    gl.stencilFuncSeparate(1029, backFunc, backRef, backMask);\n  },\n  stencilOp: (gl, args) => {\n    args = isArray(args) && args.length === 3 ? [...args, ...args] : args;\n    const [sfail, dpfail, dppass, backSfail, backDpfail, backDppass] = args;\n    gl.stencilOpSeparate(1028, sfail, dpfail, dppass);\n    gl.stencilOpSeparate(1029, backSfail, backDpfail, backDppass);\n  },\n  viewport: (gl, value) => gl.viewport(...value)\n};\n\nfunction getValue(glEnum, values, cache) {\n  return values[glEnum] !== undefined ? values[glEnum] : cache[glEnum];\n}\n\nconst GL_COMPOSITE_PARAMETER_SETTERS = {\n  blendEquation: (gl, values, cache) => gl.blendEquationSeparate(getValue(32777, values, cache), getValue(34877, values, cache)),\n  blendFunc: (gl, values, cache) => gl.blendFuncSeparate(getValue(32969, values, cache), getValue(32968, values, cache), getValue(32971, values, cache), getValue(32970, values, cache)),\n  polygonOffset: (gl, values, cache) => gl.polygonOffset(getValue(32824, values, cache), getValue(10752, values, cache)),\n  sampleCoverage: (gl, values, cache) => gl.sampleCoverage(getValue(32938, values, cache), getValue(32939, values, cache)),\n  stencilFuncFront: (gl, values, cache) => gl.stencilFuncSeparate(1028, getValue(2962, values, cache), getValue(2967, values, cache), getValue(2963, values, cache)),\n  stencilFuncBack: (gl, values, cache) => gl.stencilFuncSeparate(1029, getValue(34816, values, cache), getValue(36003, values, cache), getValue(36004, values, cache)),\n  stencilOpFront: (gl, values, cache) => gl.stencilOpSeparate(1028, getValue(2964, values, cache), getValue(2965, values, cache), getValue(2966, values, cache)),\n  stencilOpBack: (gl, values, cache) => gl.stencilOpSeparate(1029, getValue(34817, values, cache), getValue(34818, values, cache), getValue(34819, values, cache))\n};\nconst GL_HOOKED_SETTERS = {\n  enable: (update, capability) => update({\n    [capability]: true\n  }),\n  disable: (update, capability) => update({\n    [capability]: false\n  }),\n  pixelStorei: (update, pname, value) => update({\n    [pname]: value\n  }),\n  hint: (update, pname, hint) => update({\n    [pname]: hint\n  }),\n  bindFramebuffer: (update, target, framebuffer) => {\n    switch (target) {\n      case 36160:\n        return update({\n          [36006]: framebuffer,\n          [36010]: framebuffer\n        });\n\n      case 36009:\n        return update({\n          [36006]: framebuffer\n        });\n\n      case 36008:\n        return update({\n          [36010]: framebuffer\n        });\n\n      default:\n        return null;\n    }\n  },\n  blendColor: (update, r, g, b, a) => update({\n    [32773]: new Float32Array([r, g, b, a])\n  }),\n  blendEquation: (update, mode) => update({\n    [32777]: mode,\n    [34877]: mode\n  }),\n  blendEquationSeparate: (update, modeRGB, modeAlpha) => update({\n    [32777]: modeRGB,\n    [34877]: modeAlpha\n  }),\n  blendFunc: (update, src, dst) => update({\n    [32969]: src,\n    [32968]: dst,\n    [32971]: src,\n    [32970]: dst\n  }),\n  blendFuncSeparate: (update, srcRGB, dstRGB, srcAlpha, dstAlpha) => update({\n    [32969]: srcRGB,\n    [32968]: dstRGB,\n    [32971]: srcAlpha,\n    [32970]: dstAlpha\n  }),\n  clearColor: (update, r, g, b, a) => update({\n    [3106]: new Float32Array([r, g, b, a])\n  }),\n  clearDepth: (update, depth) => update({\n    [2931]: depth\n  }),\n  clearStencil: (update, s) => update({\n    [2961]: s\n  }),\n  colorMask: (update, r, g, b, a) => update({\n    [3107]: [r, g, b, a]\n  }),\n  cullFace: (update, mode) => update({\n    [2885]: mode\n  }),\n  depthFunc: (update, func) => update({\n    [2932]: func\n  }),\n  depthRange: (update, zNear, zFar) => update({\n    [2928]: new Float32Array([zNear, zFar])\n  }),\n  depthMask: (update, mask) => update({\n    [2930]: mask\n  }),\n  frontFace: (update, face) => update({\n    [2886]: face\n  }),\n  lineWidth: (update, width) => update({\n    [2849]: width\n  }),\n  polygonOffset: (update, factor, units) => update({\n    [32824]: factor,\n    [10752]: units\n  }),\n  sampleCoverage: (update, value, invert) => update({\n    [32938]: value,\n    [32939]: invert\n  }),\n  scissor: (update, x, y, width, height) => update({\n    [3088]: new Int32Array([x, y, width, height])\n  }),\n  stencilMask: (update, mask) => update({\n    [2968]: mask,\n    [36005]: mask\n  }),\n  stencilMaskSeparate: (update, face, mask) => update({\n    [face === 1028 ? 2968 : 36005]: mask\n  }),\n  stencilFunc: (update, func, ref, mask) => update({\n    [2962]: func,\n    [2967]: ref,\n    [2963]: mask,\n    [34816]: func,\n    [36003]: ref,\n    [36004]: mask\n  }),\n  stencilFuncSeparate: (update, face, func, ref, mask) => update({\n    [face === 1028 ? 2962 : 34816]: func,\n    [face === 1028 ? 2967 : 36003]: ref,\n    [face === 1028 ? 2963 : 36004]: mask\n  }),\n  stencilOp: (update, fail, zfail, zpass) => update({\n    [2964]: fail,\n    [2965]: zfail,\n    [2966]: zpass,\n    [34817]: fail,\n    [34818]: zfail,\n    [34819]: zpass\n  }),\n  stencilOpSeparate: (update, face, fail, zfail, zpass) => update({\n    [face === 1028 ? 2964 : 34817]: fail,\n    [face === 1028 ? 2965 : 34818]: zfail,\n    [face === 1028 ? 2966 : 34819]: zpass\n  }),\n  viewport: (update, x, y, width, height) => update({\n    [2978]: [x, y, width, height]\n  })\n};\n\nconst isEnabled = (gl, key) => gl.isEnabled(key);\n\nconst GL_PARAMETER_GETTERS = {\n  [3042]: isEnabled,\n  [2884]: isEnabled,\n  [2929]: isEnabled,\n  [3024]: isEnabled,\n  [32823]: isEnabled,\n  [32926]: isEnabled,\n  [32928]: isEnabled,\n  [3089]: isEnabled,\n  [2960]: isEnabled,\n  [35977]: isEnabled\n};\n//# sourceMappingURL=webgl-parameter-tables.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/gltools/dist/esm/state-tracker/webgl-parameter-tables.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/gltools/dist/esm/utils/assert.js":
/*!****************************************************************!*\
  !*** ./node_modules/@luma.gl/gltools/dist/esm/utils/assert.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   assert: () => (/* binding */ assert)\n/* harmony export */ });\nfunction assert(condition, message) {\n  if (!condition) {\n    throw new Error(message || 'luma.gl: assertion failed.');\n  }\n}\n//# sourceMappingURL=assert.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/gltools/dist/esm/utils/assert.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/gltools/dist/esm/utils/device-pixels.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@luma.gl/gltools/dist/esm/utils/device-pixels.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   cssToDevicePixels: () => (/* binding */ cssToDevicePixels),\n/* harmony export */   cssToDeviceRatio: () => (/* binding */ cssToDeviceRatio),\n/* harmony export */   getDevicePixelRatio: () => (/* binding */ getDevicePixelRatio)\n/* harmony export */ });\nfunction cssToDeviceRatio(gl) {\n  const {\n    luma\n  } = gl;\n\n  if (gl.canvas && luma) {\n    const cachedSize = luma.canvasSizeInfo;\n    const clientWidth = 'clientWidth' in cachedSize ? cachedSize.clientWidth : gl.canvas.clientWidth;\n    return clientWidth ? gl.drawingBufferWidth / clientWidth : 1;\n  }\n\n  return 1;\n}\nfunction cssToDevicePixels(gl, cssPixel) {\n  let yInvert = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : true;\n  const ratio = cssToDeviceRatio(gl);\n  const width = gl.drawingBufferWidth;\n  const height = gl.drawingBufferHeight;\n  return scalePixels(cssPixel, ratio, width, height, yInvert);\n}\nfunction getDevicePixelRatio(useDevicePixels) {\n  const windowRatio = typeof window === 'undefined' ? 1 : window.devicePixelRatio || 1;\n\n  if (Number.isFinite(useDevicePixels)) {\n    return useDevicePixels <= 0 ? 1 : useDevicePixels;\n  }\n\n  return useDevicePixels ? windowRatio : 1;\n}\n\nfunction scalePixels(pixel, ratio, width, height, yInvert) {\n  const x = scaleX(pixel[0], ratio, width);\n  let y = scaleY(pixel[1], ratio, height, yInvert);\n  let t = scaleX(pixel[0] + 1, ratio, width);\n  const xHigh = t === width - 1 ? t : t - 1;\n  t = scaleY(pixel[1] + 1, ratio, height, yInvert);\n  let yHigh;\n\n  if (yInvert) {\n    t = t === 0 ? t : t + 1;\n    yHigh = y;\n    y = t;\n  } else {\n    yHigh = t === height - 1 ? t : t - 1;\n  }\n\n  return {\n    x,\n    y,\n    width: Math.max(xHigh - x + 1, 1),\n    height: Math.max(yHigh - y + 1, 1)\n  };\n}\n\nfunction scaleX(x, ratio, width) {\n  const r = Math.min(Math.round(x * ratio), width - 1);\n  return r;\n}\n\nfunction scaleY(y, ratio, height, yInvert) {\n  return yInvert ? Math.max(0, height - 1 - Math.round(y * ratio)) : Math.min(Math.round(y * ratio), height - 1);\n}\n//# sourceMappingURL=device-pixels.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/gltools/dist/esm/utils/device-pixels.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/gltools/dist/esm/utils/log.js":
/*!*************************************************************!*\
  !*** ./node_modules/@luma.gl/gltools/dist/esm/utils/log.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   log: () => (/* binding */ log)\n/* harmony export */ });\n/* harmony import */ var _probe_gl_log__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @probe.gl/log */ \"./node_modules/@probe.gl/log/dist/esm/log.js\");\n\nconst log = new _probe_gl_log__WEBPACK_IMPORTED_MODULE_0__.Log({\n  id: 'luma.gl'\n});\n//# sourceMappingURL=log.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/gltools/dist/esm/utils/log.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/gltools/dist/esm/utils/utils.js":
/*!***************************************************************!*\
  !*** ./node_modules/@luma.gl/gltools/dist/esm/utils/utils.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   deepArrayEqual: () => (/* binding */ deepArrayEqual),\n/* harmony export */   isObjectEmpty: () => (/* binding */ isObjectEmpty)\n/* harmony export */ });\nfunction isObjectEmpty(object) {\n  for (const key in object) {\n    return false;\n  }\n\n  return true;\n}\nfunction deepArrayEqual(x, y) {\n  if (x === y) {\n    return true;\n  }\n\n  const isArrayX = Array.isArray(x) || ArrayBuffer.isView(x);\n  const isArrayY = Array.isArray(y) || ArrayBuffer.isView(y);\n\n  if (isArrayX && isArrayY && x.length === y.length) {\n    for (let i = 0; i < x.length; ++i) {\n      if (x[i] !== y[i]) {\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n  return false;\n}\n//# sourceMappingURL=utils.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/gltools/dist/esm/utils/utils.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/gltools/dist/esm/utils/webgl-checks.js":
/*!**********************************************************************!*\
  !*** ./node_modules/@luma.gl/gltools/dist/esm/utils/webgl-checks.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   ERR_WEBGL: () => (/* binding */ ERR_WEBGL),\n/* harmony export */   ERR_WEBGL2: () => (/* binding */ ERR_WEBGL2),\n/* harmony export */   assertWebGL2Context: () => (/* binding */ assertWebGL2Context),\n/* harmony export */   assertWebGLContext: () => (/* binding */ assertWebGLContext),\n/* harmony export */   getWebGL2Context: () => (/* binding */ getWebGL2Context),\n/* harmony export */   isWebGL: () => (/* binding */ isWebGL),\n/* harmony export */   isWebGL2: () => (/* binding */ isWebGL2)\n/* harmony export */ });\n/* harmony import */ var _assert__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./assert */ \"./node_modules/@luma.gl/gltools/dist/esm/utils/assert.js\");\n\nconst ERR_CONTEXT = 'Invalid WebGLRenderingContext';\nconst ERR_WEBGL = ERR_CONTEXT;\nconst ERR_WEBGL2 = 'Requires WebGL2';\nfunction isWebGL(gl) {\n  if (typeof WebGLRenderingContext !== 'undefined' && gl instanceof WebGLRenderingContext) {\n    return true;\n  }\n\n  if (typeof WebGL2RenderingContext !== 'undefined' && gl instanceof WebGL2RenderingContext) {\n    return true;\n  }\n\n  return Boolean(gl && Number.isFinite(gl._version));\n}\nfunction isWebGL2(gl) {\n  if (typeof WebGL2RenderingContext !== 'undefined' && gl instanceof WebGL2RenderingContext) {\n    return true;\n  }\n\n  return Boolean(gl && gl._version === 2);\n}\nfunction getWebGL2Context(gl) {\n  return isWebGL2(gl) ? gl : null;\n}\nfunction assertWebGLContext(gl) {\n  (0,_assert__WEBPACK_IMPORTED_MODULE_0__.assert)(isWebGL(gl), ERR_CONTEXT);\n  return gl;\n}\nfunction assertWebGL2Context(gl) {\n  (0,_assert__WEBPACK_IMPORTED_MODULE_0__.assert)(isWebGL2(gl), ERR_WEBGL2);\n  return gl;\n}\n//# sourceMappingURL=webgl-checks.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/gltools/dist/esm/utils/webgl-checks.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/shadertools/dist/esm/lib/assemble-shaders.js":
/*!****************************************************************************!*\
  !*** ./node_modules/@luma.gl/shadertools/dist/esm/lib/assemble-shaders.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   assembleShaders: () => (/* binding */ assembleShaders)\n/* harmony export */ });\n/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./constants */ \"./node_modules/@luma.gl/shadertools/dist/esm/lib/constants.js\");\n/* harmony import */ var _resolve_modules__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./resolve-modules */ \"./node_modules/@luma.gl/shadertools/dist/esm/lib/resolve-modules.js\");\n/* harmony import */ var _platform_defines__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./platform-defines */ \"./node_modules/@luma.gl/shadertools/dist/esm/lib/platform-defines.js\");\n/* harmony import */ var _inject_shader__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./inject-shader */ \"./node_modules/@luma.gl/shadertools/dist/esm/lib/inject-shader.js\");\n/* harmony import */ var _transpile_shader__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./transpile-shader */ \"./node_modules/@luma.gl/shadertools/dist/esm/lib/transpile-shader.js\");\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils */ \"./node_modules/@luma.gl/shadertools/dist/esm/utils/assert.js\");\n\n\n\n\n\n\nconst INJECT_SHADER_DECLARATIONS = \"\\n\\n\".concat(_inject_shader__WEBPACK_IMPORTED_MODULE_0__.DECLARATION_INJECT_MARKER, \"\\n\\n\");\nconst SHADER_TYPE = {\n  [_constants__WEBPACK_IMPORTED_MODULE_1__.VERTEX_SHADER]: 'vertex',\n  [_constants__WEBPACK_IMPORTED_MODULE_1__.FRAGMENT_SHADER]: 'fragment'\n};\nconst FRAGMENT_SHADER_PROLOGUE = \"precision highp float;\\n\\n\";\nfunction assembleShaders(gl, opts) {\n  const {\n    vs,\n    fs\n  } = opts;\n  const modules = (0,_resolve_modules__WEBPACK_IMPORTED_MODULE_2__.resolveModules)(opts.modules || []);\n  return {\n    gl,\n    vs: assembleShader(gl, Object.assign({}, opts, {\n      source: vs,\n      type: _constants__WEBPACK_IMPORTED_MODULE_1__.VERTEX_SHADER,\n      modules\n    })),\n    fs: assembleShader(gl, Object.assign({}, opts, {\n      source: fs,\n      type: _constants__WEBPACK_IMPORTED_MODULE_1__.FRAGMENT_SHADER,\n      modules\n    })),\n    getUniforms: assembleGetUniforms(modules)\n  };\n}\n\nfunction assembleShader(gl, _ref) {\n  let {\n    id,\n    source,\n    type,\n    modules,\n    defines = {},\n    hookFunctions = [],\n    inject = {},\n    transpileToGLSL100 = false,\n    prologue = true,\n    log\n  } = _ref;\n  (0,_utils__WEBPACK_IMPORTED_MODULE_3__[\"default\"])(typeof source === 'string', 'shader source must be a string');\n  const isVertex = type === _constants__WEBPACK_IMPORTED_MODULE_1__.VERTEX_SHADER;\n  const sourceLines = source.split('\\n');\n  let glslVersion = 100;\n  let versionLine = '';\n  let coreSource = source;\n\n  if (sourceLines[0].indexOf('#version ') === 0) {\n    glslVersion = 300;\n    versionLine = sourceLines[0];\n    coreSource = sourceLines.slice(1).join('\\n');\n  } else {\n    versionLine = \"#version \".concat(glslVersion);\n  }\n\n  const allDefines = {};\n  modules.forEach(module => {\n    Object.assign(allDefines, module.getDefines());\n  });\n  Object.assign(allDefines, defines);\n  let assembledSource = prologue ? \"\".concat(versionLine, \"\\n\").concat(getShaderName({\n    id,\n    source,\n    type\n  }), \"\\n\").concat(getShaderType({\n    type\n  }), \"\\n\").concat((0,_platform_defines__WEBPACK_IMPORTED_MODULE_4__.getPlatformShaderDefines)(gl), \"\\n\").concat((0,_platform_defines__WEBPACK_IMPORTED_MODULE_4__.getVersionDefines)(gl, glslVersion, !isVertex), \"\\n\").concat(getApplicationDefines(allDefines), \"\\n\").concat(isVertex ? '' : FRAGMENT_SHADER_PROLOGUE, \"\\n\") : \"\".concat(versionLine, \"\\n\");\n  const hookFunctionMap = normalizeHookFunctions(hookFunctions);\n  const hookInjections = {};\n  const declInjections = {};\n  const mainInjections = {};\n\n  for (const key in inject) {\n    const injection = typeof inject[key] === 'string' ? {\n      injection: inject[key],\n      order: 0\n    } : inject[key];\n    const match = key.match(/^(v|f)s:(#)?([\\w-]+)$/);\n\n    if (match) {\n      const hash = match[2];\n      const name = match[3];\n\n      if (hash) {\n        if (name === 'decl') {\n          declInjections[key] = [injection];\n        } else {\n          mainInjections[key] = [injection];\n        }\n      } else {\n        hookInjections[key] = [injection];\n      }\n    } else {\n      mainInjections[key] = [injection];\n    }\n  }\n\n  for (const module of modules) {\n    if (log) {\n      module.checkDeprecations(coreSource, log);\n    }\n\n    const moduleSource = module.getModuleSource(type, glslVersion);\n    assembledSource += moduleSource;\n    const injections = module.injections[type];\n\n    for (const key in injections) {\n      const match = key.match(/^(v|f)s:#([\\w-]+)$/);\n\n      if (match) {\n        const name = match[2];\n        const injectionType = name === 'decl' ? declInjections : mainInjections;\n        injectionType[key] = injectionType[key] || [];\n        injectionType[key].push(injections[key]);\n      } else {\n        hookInjections[key] = hookInjections[key] || [];\n        hookInjections[key].push(injections[key]);\n      }\n    }\n  }\n\n  assembledSource += INJECT_SHADER_DECLARATIONS;\n  assembledSource = (0,_inject_shader__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(assembledSource, type, declInjections);\n  assembledSource += getHookFunctions(hookFunctionMap[type], hookInjections);\n  assembledSource += coreSource;\n  assembledSource = (0,_inject_shader__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(assembledSource, type, mainInjections);\n  assembledSource = (0,_transpile_shader__WEBPACK_IMPORTED_MODULE_5__[\"default\"])(assembledSource, transpileToGLSL100 ? 100 : glslVersion, isVertex);\n  return assembledSource;\n}\n\nfunction assembleGetUniforms(modules) {\n  return function getUniforms(opts) {\n    const uniforms = {};\n\n    for (const module of modules) {\n      const moduleUniforms = module.getUniforms(opts, uniforms);\n      Object.assign(uniforms, moduleUniforms);\n    }\n\n    return uniforms;\n  };\n}\n\nfunction getShaderType(_ref2) {\n  let {\n    type\n  } = _ref2;\n  return \"\\n#define SHADER_TYPE_\".concat(SHADER_TYPE[type].toUpperCase(), \"\\n\");\n}\n\nfunction getShaderName(_ref3) {\n  let {\n    id,\n    source,\n    type\n  } = _ref3;\n  const injectShaderName = id && typeof id === 'string' && source.indexOf('SHADER_NAME') === -1;\n  return injectShaderName ? \"\\n#define SHADER_NAME \".concat(id, \"_\").concat(SHADER_TYPE[type], \"\\n\\n\") : '';\n}\n\nfunction getApplicationDefines() {\n  let defines = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n  let count = 0;\n  let sourceText = '';\n\n  for (const define in defines) {\n    if (count === 0) {\n      sourceText += '\\n// APPLICATION DEFINES\\n';\n    }\n\n    count++;\n    const value = defines[define];\n\n    if (value || Number.isFinite(value)) {\n      sourceText += \"#define \".concat(define.toUpperCase(), \" \").concat(defines[define], \"\\n\");\n    }\n  }\n\n  if (count === 0) {\n    sourceText += '\\n';\n  }\n\n  return sourceText;\n}\n\nfunction getHookFunctions(hookFunctions, hookInjections) {\n  let result = '';\n\n  for (const hookName in hookFunctions) {\n    const hookFunction = hookFunctions[hookName];\n    result += \"void \".concat(hookFunction.signature, \" {\\n\");\n\n    if (hookFunction.header) {\n      result += \"  \".concat(hookFunction.header);\n    }\n\n    if (hookInjections[hookName]) {\n      const injections = hookInjections[hookName];\n      injections.sort((a, b) => a.order - b.order);\n\n      for (const injection of injections) {\n        result += \"  \".concat(injection.injection, \"\\n\");\n      }\n    }\n\n    if (hookFunction.footer) {\n      result += \"  \".concat(hookFunction.footer);\n    }\n\n    result += '}\\n';\n  }\n\n  return result;\n}\n\nfunction normalizeHookFunctions(hookFunctions) {\n  const result = {\n    vs: {},\n    fs: {}\n  };\n  hookFunctions.forEach(hook => {\n    let opts;\n\n    if (typeof hook !== 'string') {\n      opts = hook;\n      hook = opts.hook;\n    } else {\n      opts = {};\n    }\n\n    hook = hook.trim();\n    const [stage, signature] = hook.split(':');\n    const name = hook.replace(/\\(.+/, '');\n    result[stage][name] = Object.assign(opts, {\n      signature\n    });\n  });\n  return result;\n}\n//# sourceMappingURL=assemble-shaders.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/shadertools/dist/esm/lib/assemble-shaders.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/shadertools/dist/esm/lib/constants.js":
/*!*********************************************************************!*\
  !*** ./node_modules/@luma.gl/shadertools/dist/esm/lib/constants.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   FRAGMENT_SHADER: () => (/* binding */ FRAGMENT_SHADER),\n/* harmony export */   VERTEX_SHADER: () => (/* binding */ VERTEX_SHADER)\n/* harmony export */ });\nconst VERTEX_SHADER = 'vs';\nconst FRAGMENT_SHADER = 'fs';\n//# sourceMappingURL=constants.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/shadertools/dist/esm/lib/constants.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/shadertools/dist/esm/lib/filters/prop-types.js":
/*!******************************************************************************!*\
  !*** ./node_modules/@luma.gl/shadertools/dist/esm/lib/filters/prop-types.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   parsePropTypes: () => (/* binding */ parsePropTypes)\n/* harmony export */ });\nconst TYPE_DEFINITIONS = {\n  number: {\n    validate(value, propType) {\n      return Number.isFinite(value) && (!('max' in propType) || value <= propType.max) && (!('min' in propType) || value >= propType.min);\n    }\n\n  },\n  array: {\n    validate(value, propType) {\n      return Array.isArray(value) || ArrayBuffer.isView(value);\n    }\n\n  }\n};\nfunction parsePropTypes(propDefs) {\n  const propTypes = {};\n\n  for (const propName in propDefs) {\n    const propDef = propDefs[propName];\n    const propType = parsePropType(propDef);\n    propTypes[propName] = propType;\n  }\n\n  return propTypes;\n}\n\nfunction parsePropType(propDef) {\n  let type = getTypeOf(propDef);\n\n  if (type === 'object') {\n    if (!propDef) {\n      return {\n        type: 'object',\n        value: null\n      };\n    }\n\n    if ('type' in propDef) {\n      return Object.assign({}, propDef, TYPE_DEFINITIONS[propDef.type]);\n    }\n\n    if (!('value' in propDef)) {\n      return {\n        type: 'object',\n        value: propDef\n      };\n    }\n\n    type = getTypeOf(propDef.value);\n    return Object.assign({\n      type\n    }, propDef, TYPE_DEFINITIONS[type]);\n  }\n\n  return Object.assign({\n    type,\n    value: propDef\n  }, TYPE_DEFINITIONS[type]);\n}\n\nfunction getTypeOf(value) {\n  if (Array.isArray(value) || ArrayBuffer.isView(value)) {\n    return 'array';\n  }\n\n  return typeof value;\n}\n//# sourceMappingURL=prop-types.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/shadertools/dist/esm/lib/filters/prop-types.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/shadertools/dist/esm/lib/inject-shader.js":
/*!*************************************************************************!*\
  !*** ./node_modules/@luma.gl/shadertools/dist/esm/lib/inject-shader.js ***!
  \*************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   DECLARATION_INJECT_MARKER: () => (/* binding */ DECLARATION_INJECT_MARKER),\n/* harmony export */   combineInjects: () => (/* binding */ combineInjects),\n/* harmony export */   \"default\": () => (/* binding */ injectShader)\n/* harmony export */ });\n/* harmony import */ var _modules_module_injectors__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../modules/module-injectors */ \"./node_modules/@luma.gl/shadertools/dist/esm/modules/module-injectors.js\");\n/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./constants */ \"./node_modules/@luma.gl/shadertools/dist/esm/lib/constants.js\");\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils */ \"./node_modules/@luma.gl/shadertools/dist/esm/utils/assert.js\");\n\n\n\nconst MODULE_INJECTORS = {\n  [_constants__WEBPACK_IMPORTED_MODULE_0__.VERTEX_SHADER]: _modules_module_injectors__WEBPACK_IMPORTED_MODULE_1__.MODULE_INJECTORS_VS,\n  [_constants__WEBPACK_IMPORTED_MODULE_0__.FRAGMENT_SHADER]: _modules_module_injectors__WEBPACK_IMPORTED_MODULE_1__.MODULE_INJECTORS_FS\n};\nconst DECLARATION_INJECT_MARKER = '__LUMA_INJECT_DECLARATIONS__';\nconst REGEX_START_OF_MAIN = /void\\s+main\\s*\\([^)]*\\)\\s*\\{\\n?/;\nconst REGEX_END_OF_MAIN = /}\\n?[^{}]*$/;\nconst fragments = [];\nfunction injectShader(source, type, inject) {\n  let injectStandardStubs = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : false;\n  const isVertex = type === _constants__WEBPACK_IMPORTED_MODULE_0__.VERTEX_SHADER;\n\n  for (const key in inject) {\n    const fragmentData = inject[key];\n    fragmentData.sort((a, b) => a.order - b.order);\n    fragments.length = fragmentData.length;\n\n    for (let i = 0, len = fragmentData.length; i < len; ++i) {\n      fragments[i] = fragmentData[i].injection;\n    }\n\n    const fragmentString = \"\".concat(fragments.join('\\n'), \"\\n\");\n\n    switch (key) {\n      case 'vs:#decl':\n        if (isVertex) {\n          source = source.replace(DECLARATION_INJECT_MARKER, fragmentString);\n        }\n\n        break;\n\n      case 'vs:#main-start':\n        if (isVertex) {\n          source = source.replace(REGEX_START_OF_MAIN, match => match + fragmentString);\n        }\n\n        break;\n\n      case 'vs:#main-end':\n        if (isVertex) {\n          source = source.replace(REGEX_END_OF_MAIN, match => fragmentString + match);\n        }\n\n        break;\n\n      case 'fs:#decl':\n        if (!isVertex) {\n          source = source.replace(DECLARATION_INJECT_MARKER, fragmentString);\n        }\n\n        break;\n\n      case 'fs:#main-start':\n        if (!isVertex) {\n          source = source.replace(REGEX_START_OF_MAIN, match => match + fragmentString);\n        }\n\n        break;\n\n      case 'fs:#main-end':\n        if (!isVertex) {\n          source = source.replace(REGEX_END_OF_MAIN, match => fragmentString + match);\n        }\n\n        break;\n\n      default:\n        source = source.replace(key, match => match + fragmentString);\n    }\n  }\n\n  source = source.replace(DECLARATION_INJECT_MARKER, '');\n\n  if (injectStandardStubs) {\n    source = source.replace(/\\}\\s*$/, match => match + MODULE_INJECTORS[type]);\n  }\n\n  return source;\n}\nfunction combineInjects(injects) {\n  const result = {};\n  (0,_utils__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(Array.isArray(injects) && injects.length > 1);\n  injects.forEach(inject => {\n    for (const key in inject) {\n      result[key] = result[key] ? \"\".concat(result[key], \"\\n\").concat(inject[key]) : inject[key];\n    }\n  });\n  return result;\n}\n//# sourceMappingURL=inject-shader.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/shadertools/dist/esm/lib/inject-shader.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/shadertools/dist/esm/lib/platform-defines.js":
/*!****************************************************************************!*\
  !*** ./node_modules/@luma.gl/shadertools/dist/esm/lib/platform-defines.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getPlatformShaderDefines: () => (/* binding */ getPlatformShaderDefines),\n/* harmony export */   getVersionDefines: () => (/* binding */ getVersionDefines)\n/* harmony export */ });\n/* harmony import */ var _utils_webgl_info__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/webgl-info */ \"./node_modules/@luma.gl/shadertools/dist/esm/utils/webgl-info.js\");\n\nfunction getPlatformShaderDefines(gl) {\n  const debugInfo = (0,_utils_webgl_info__WEBPACK_IMPORTED_MODULE_0__.getContextInfo)(gl);\n\n  switch (debugInfo.gpuVendor.toLowerCase()) {\n    case 'nvidia':\n      return \"#define NVIDIA_GPU\\n// Nvidia optimizes away the calculation necessary for emulated fp64\\n#define LUMA_FP64_CODE_ELIMINATION_WORKAROUND 1\\n\";\n\n    case 'intel':\n      return \"#define INTEL_GPU\\n// Intel optimizes away the calculation necessary for emulated fp64\\n#define LUMA_FP64_CODE_ELIMINATION_WORKAROUND 1\\n// Intel's built-in 'tan' function doesn't have acceptable precision\\n#define LUMA_FP32_TAN_PRECISION_WORKAROUND 1\\n// Intel GPU doesn't have full 32 bits precision in same cases, causes overflow\\n#define LUMA_FP64_HIGH_BITS_OVERFLOW_WORKAROUND 1\\n\";\n\n    case 'amd':\n      return \"#define AMD_GPU\\n\";\n\n    default:\n      return \"#define DEFAULT_GPU\\n// Prevent driver from optimizing away the calculation necessary for emulated fp64\\n#define LUMA_FP64_CODE_ELIMINATION_WORKAROUND 1\\n// Intel's built-in 'tan' function doesn't have acceptable precision\\n#define LUMA_FP32_TAN_PRECISION_WORKAROUND 1\\n// Intel GPU doesn't have full 32 bits precision in same cases, causes overflow\\n#define LUMA_FP64_HIGH_BITS_OVERFLOW_WORKAROUND 1\\n\";\n  }\n}\nfunction getVersionDefines(gl, glslVersion, isFragment) {\n  let versionDefines = \"#if (__VERSION__ > 120)\\n\\n# define FEATURE_GLSL_DERIVATIVES\\n# define FEATURE_GLSL_DRAW_BUFFERS\\n# define FEATURE_GLSL_FRAG_DEPTH\\n# define FEATURE_GLSL_TEXTURE_LOD\\n\\n// DEPRECATED FLAGS, remove in v9\\n# define FRAG_DEPTH\\n# define DERIVATIVES\\n# define DRAW_BUFFERS\\n# define TEXTURE_LOD\\n\\n#endif // __VERSION\\n\";\n\n  if ((0,_utils_webgl_info__WEBPACK_IMPORTED_MODULE_0__.hasFeatures)(gl, _utils_webgl_info__WEBPACK_IMPORTED_MODULE_0__.FEATURES.GLSL_FRAG_DEPTH)) {\n    versionDefines += \"\\n// FRAG_DEPTH => gl_FragDepth is available\\n#ifdef GL_EXT_frag_depth\\n#extension GL_EXT_frag_depth : enable\\n# define FEATURE_GLSL_FRAG_DEPTH\\n# define FRAG_DEPTH\\n# define gl_FragDepth gl_FragDepthEXT\\n#endif\\n\";\n  }\n\n  if ((0,_utils_webgl_info__WEBPACK_IMPORTED_MODULE_0__.hasFeatures)(gl, _utils_webgl_info__WEBPACK_IMPORTED_MODULE_0__.FEATURES.GLSL_DERIVATIVES) && (0,_utils_webgl_info__WEBPACK_IMPORTED_MODULE_0__.canCompileGLGSExtension)(gl, _utils_webgl_info__WEBPACK_IMPORTED_MODULE_0__.FEATURES.GLSL_DERIVATIVES)) {\n    versionDefines += \"\\n// DERIVATIVES => dxdF, dxdY and fwidth are available\\n#ifdef GL_OES_standard_derivatives\\n#extension GL_OES_standard_derivatives : enable\\n# define FEATURE_GLSL_DERIVATIVES\\n# define DERIVATIVES\\n#endif\\n\";\n  }\n\n  if ((0,_utils_webgl_info__WEBPACK_IMPORTED_MODULE_0__.hasFeatures)(gl, _utils_webgl_info__WEBPACK_IMPORTED_MODULE_0__.FEATURES.GLSL_FRAG_DATA) && (0,_utils_webgl_info__WEBPACK_IMPORTED_MODULE_0__.canCompileGLGSExtension)(gl, _utils_webgl_info__WEBPACK_IMPORTED_MODULE_0__.FEATURES.GLSL_FRAG_DATA, {\n    behavior: 'require'\n  })) {\n    versionDefines += \"\\n// DRAW_BUFFERS => gl_FragData[] is available\\n#ifdef GL_EXT_draw_buffers\\n#extension GL_EXT_draw_buffers : require\\n#define FEATURE_GLSL_DRAW_BUFFERS\\n#define DRAW_BUFFERS\\n#endif\\n\";\n  }\n\n  if ((0,_utils_webgl_info__WEBPACK_IMPORTED_MODULE_0__.hasFeatures)(gl, _utils_webgl_info__WEBPACK_IMPORTED_MODULE_0__.FEATURES.GLSL_TEXTURE_LOD)) {\n    versionDefines += \"// TEXTURE_LOD => texture2DLod etc are available\\n#ifdef GL_EXT_shader_texture_lod\\n#extension GL_EXT_shader_texture_lod : enable\\n\\n# define FEATURE_GLSL_TEXTURE_LOD\\n# define TEXTURE_LOD\\n\\n#endif\\n\";\n  }\n\n  return versionDefines;\n}\n//# sourceMappingURL=platform-defines.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/shadertools/dist/esm/lib/platform-defines.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/shadertools/dist/esm/lib/resolve-modules.js":
/*!***************************************************************************!*\
  !*** ./node_modules/@luma.gl/shadertools/dist/esm/lib/resolve-modules.js ***!
  \***************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   TEST_EXPORTS: () => (/* binding */ TEST_EXPORTS),\n/* harmony export */   resolveModules: () => (/* binding */ resolveModules)\n/* harmony export */ });\n/* harmony import */ var _shader_module__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./shader-module */ \"./node_modules/@luma.gl/shadertools/dist/esm/lib/shader-module.js\");\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils */ \"./node_modules/@luma.gl/shadertools/dist/esm/utils/assert.js\");\n\n\nfunction resolveModules(modules) {\n  return getShaderDependencies(instantiateModules(modules));\n}\n\nfunction getShaderDependencies(modules) {\n  const moduleMap = {};\n  const moduleDepth = {};\n  getDependencyGraph({\n    modules,\n    level: 0,\n    moduleMap,\n    moduleDepth\n  });\n  return Object.keys(moduleDepth).sort((a, b) => moduleDepth[b] - moduleDepth[a]).map(name => moduleMap[name]);\n}\n\nfunction getDependencyGraph(_ref) {\n  let {\n    modules,\n    level,\n    moduleMap,\n    moduleDepth\n  } = _ref;\n\n  if (level >= 5) {\n    throw new Error('Possible loop in shader dependency graph');\n  }\n\n  for (const module of modules) {\n    moduleMap[module.name] = module;\n\n    if (moduleDepth[module.name] === undefined || moduleDepth[module.name] < level) {\n      moduleDepth[module.name] = level;\n    }\n  }\n\n  for (const module of modules) {\n    if (module.dependencies) {\n      getDependencyGraph({\n        modules: module.dependencies,\n        level: level + 1,\n        moduleMap,\n        moduleDepth\n      });\n    }\n  }\n}\n\nfunction instantiateModules(modules, seen) {\n  return modules.map(module => {\n    if (module instanceof _shader_module__WEBPACK_IMPORTED_MODULE_0__[\"default\"]) {\n      return module;\n    }\n\n    (0,_utils__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(typeof module !== 'string', \"Shader module use by name is deprecated. Import shader module '\".concat(module, \"' and use it directly.\"));\n    (0,_utils__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(module.name, 'shader module has no name');\n    module = new _shader_module__WEBPACK_IMPORTED_MODULE_0__[\"default\"](module);\n    module.dependencies = instantiateModules(module.dependencies);\n    return module;\n  });\n}\n\nconst TEST_EXPORTS = {\n  getShaderDependencies,\n  getDependencyGraph\n};\n//# sourceMappingURL=resolve-modules.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/shadertools/dist/esm/lib/resolve-modules.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/shadertools/dist/esm/lib/shader-module.js":
/*!*************************************************************************!*\
  !*** ./node_modules/@luma.gl/shadertools/dist/esm/lib/shader-module.js ***!
  \*************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ ShaderModule),\n/* harmony export */   normalizeShaderModule: () => (/* binding */ normalizeShaderModule)\n/* harmony export */ });\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils */ \"./node_modules/@luma.gl/shadertools/dist/esm/utils/assert.js\");\n/* harmony import */ var _filters_prop_types__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./filters/prop-types */ \"./node_modules/@luma.gl/shadertools/dist/esm/lib/filters/prop-types.js\");\n\n\nconst VERTEX_SHADER = 'vs';\nconst FRAGMENT_SHADER = 'fs';\nclass ShaderModule {\n  constructor(_ref) {\n    let {\n      name,\n      vs,\n      fs,\n      dependencies = [],\n      uniforms,\n      getUniforms,\n      deprecations = [],\n      defines = {},\n      inject = {},\n      vertexShader,\n      fragmentShader\n    } = _ref;\n    (0,_utils__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(typeof name === 'string');\n    this.name = name;\n    this.vs = vs || vertexShader;\n    this.fs = fs || fragmentShader;\n    this.getModuleUniforms = getUniforms;\n    this.dependencies = dependencies;\n    this.deprecations = this._parseDeprecationDefinitions(deprecations);\n    this.defines = defines;\n    this.injections = normalizeInjections(inject);\n\n    if (uniforms) {\n      this.uniforms = (0,_filters_prop_types__WEBPACK_IMPORTED_MODULE_1__.parsePropTypes)(uniforms);\n    }\n  }\n\n  getModuleSource(type) {\n    let moduleSource;\n\n    switch (type) {\n      case VERTEX_SHADER:\n        moduleSource = this.vs || '';\n        break;\n\n      case FRAGMENT_SHADER:\n        moduleSource = this.fs || '';\n        break;\n\n      default:\n        (0,_utils__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(false);\n    }\n\n    return \"#define MODULE_\".concat(this.name.toUpperCase().replace(/[^0-9a-z]/gi, '_'), \"\\n\").concat(moduleSource, \"// END MODULE_\").concat(this.name, \"\\n\\n\");\n  }\n\n  getUniforms(opts, uniforms) {\n    if (this.getModuleUniforms) {\n      return this.getModuleUniforms(opts, uniforms);\n    }\n\n    if (this.uniforms) {\n      return this._defaultGetUniforms(opts);\n    }\n\n    return {};\n  }\n\n  getDefines() {\n    return this.defines;\n  }\n\n  checkDeprecations(shaderSource, log) {\n    this.deprecations.forEach(def => {\n      if (def.regex.test(shaderSource)) {\n        if (def.deprecated) {\n          log.deprecated(def.old, def.new)();\n        } else {\n          log.removed(def.old, def.new)();\n        }\n      }\n    });\n  }\n\n  _parseDeprecationDefinitions(deprecations) {\n    deprecations.forEach(def => {\n      switch (def.type) {\n        case 'function':\n          def.regex = new RegExp(\"\\\\b\".concat(def.old, \"\\\\(\"));\n          break;\n\n        default:\n          def.regex = new RegExp(\"\".concat(def.type, \" \").concat(def.old, \";\"));\n      }\n    });\n    return deprecations;\n  }\n\n  _defaultGetUniforms() {\n    let opts = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    const uniforms = {};\n    const propTypes = this.uniforms;\n\n    for (const key in propTypes) {\n      const propDef = propTypes[key];\n\n      if (key in opts && !propDef.private) {\n        if (propDef.validate) {\n          (0,_utils__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(propDef.validate(opts[key], propDef), \"\".concat(this.name, \": invalid \").concat(key));\n        }\n\n        uniforms[key] = opts[key];\n      } else {\n        uniforms[key] = propDef.value;\n      }\n    }\n\n    return uniforms;\n  }\n\n}\nfunction normalizeShaderModule(module) {\n  if (!module.normalized) {\n    module.normalized = true;\n\n    if (module.uniforms && !module.getUniforms) {\n      const shaderModule = new ShaderModule(module);\n      module.getUniforms = shaderModule.getUniforms.bind(shaderModule);\n    }\n  }\n\n  return module;\n}\n\nfunction normalizeInjections(injections) {\n  const result = {\n    vs: {},\n    fs: {}\n  };\n\n  for (const hook in injections) {\n    let injection = injections[hook];\n    const stage = hook.slice(0, 2);\n\n    if (typeof injection === 'string') {\n      injection = {\n        order: 0,\n        injection\n      };\n    }\n\n    result[stage][hook] = injection;\n  }\n\n  return result;\n}\n//# sourceMappingURL=shader-module.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/shadertools/dist/esm/lib/shader-module.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/shadertools/dist/esm/lib/transpile-shader.js":
/*!****************************************************************************!*\
  !*** ./node_modules/@luma.gl/shadertools/dist/esm/lib/transpile-shader.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ transpileShader)\n/* harmony export */ });\nfunction testVariable(qualifier) {\n  return new RegExp(\"\\\\b\".concat(qualifier, \"[ \\\\t]+(\\\\w+[ \\\\t]+\\\\w+(\\\\[\\\\w+\\\\])?;)\"), 'g');\n}\n\nconst ES300_REPLACEMENTS = [[/^(#version[ \\t]+(100|300[ \\t]+es))?[ \\t]*\\n/, '#version 300 es\\n'], [/\\btexture(2D|2DProj|Cube)Lod(EXT)?\\(/g, 'textureLod('], [/\\btexture(2D|2DProj|Cube)(EXT)?\\(/g, 'texture(']];\nconst ES300_VERTEX_REPLACEMENTS = [...ES300_REPLACEMENTS, [testVariable('attribute'), 'in $1'], [testVariable('varying'), 'out $1']];\nconst ES300_FRAGMENT_REPLACEMENTS = [...ES300_REPLACEMENTS, [testVariable('varying'), 'in $1']];\nconst ES100_REPLACEMENTS = [[/^#version[ \\t]+300[ \\t]+es/, '#version 100'], [/\\btexture(2D|2DProj|Cube)Lod\\(/g, 'texture$1LodEXT('], [/\\btexture\\(/g, 'texture2D('], [/\\btextureLod\\(/g, 'texture2DLodEXT(']];\nconst ES100_VERTEX_REPLACEMENTS = [...ES100_REPLACEMENTS, [testVariable('in'), 'attribute $1'], [testVariable('out'), 'varying $1']];\nconst ES100_FRAGMENT_REPLACEMENTS = [...ES100_REPLACEMENTS, [testVariable('in'), 'varying $1']];\nconst ES100_FRAGMENT_OUTPUT_NAME = 'gl_FragColor';\nconst ES300_FRAGMENT_OUTPUT_REGEX = /\\bout[ \\t]+vec4[ \\t]+(\\w+)[ \\t]*;\\n?/;\nconst REGEX_START_OF_MAIN = /void\\s+main\\s*\\([^)]*\\)\\s*\\{\\n?/;\nfunction transpileShader(source, targetGLSLVersion, isVertex) {\n  switch (targetGLSLVersion) {\n    case 300:\n      return isVertex ? convertShader(source, ES300_VERTEX_REPLACEMENTS) : convertFragmentShaderTo300(source);\n\n    case 100:\n      return isVertex ? convertShader(source, ES100_VERTEX_REPLACEMENTS) : convertFragmentShaderTo100(source);\n\n    default:\n      throw new Error(\"unknown GLSL version \".concat(targetGLSLVersion));\n  }\n}\n\nfunction convertShader(source, replacements) {\n  for (const [pattern, replacement] of replacements) {\n    source = source.replace(pattern, replacement);\n  }\n\n  return source;\n}\n\nfunction convertFragmentShaderTo300(source) {\n  source = convertShader(source, ES300_FRAGMENT_REPLACEMENTS);\n  const outputMatch = source.match(ES300_FRAGMENT_OUTPUT_REGEX);\n\n  if (outputMatch) {\n    const outputName = outputMatch[1];\n    source = source.replace(new RegExp(\"\\\\b\".concat(ES100_FRAGMENT_OUTPUT_NAME, \"\\\\b\"), 'g'), outputName);\n  } else {\n    const outputName = 'fragmentColor';\n    source = source.replace(REGEX_START_OF_MAIN, match => \"out vec4 \".concat(outputName, \";\\n\").concat(match)).replace(new RegExp(\"\\\\b\".concat(ES100_FRAGMENT_OUTPUT_NAME, \"\\\\b\"), 'g'), outputName);\n  }\n\n  return source;\n}\n\nfunction convertFragmentShaderTo100(source) {\n  source = convertShader(source, ES100_FRAGMENT_REPLACEMENTS);\n  const outputMatch = source.match(ES300_FRAGMENT_OUTPUT_REGEX);\n\n  if (outputMatch) {\n    const outputName = outputMatch[1];\n    source = source.replace(ES300_FRAGMENT_OUTPUT_REGEX, '').replace(new RegExp(\"\\\\b\".concat(outputName, \"\\\\b\"), 'g'), ES100_FRAGMENT_OUTPUT_NAME);\n  }\n\n  return source;\n}\n//# sourceMappingURL=transpile-shader.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/shadertools/dist/esm/lib/transpile-shader.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/shadertools/dist/esm/modules/fp32/fp32.js":
/*!*************************************************************************!*\
  !*** ./node_modules/@luma.gl/shadertools/dist/esm/modules/fp32/fp32.js ***!
  \*************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   fp32: () => (/* binding */ fp32)\n/* harmony export */ });\nconst fp32shader = \"#ifdef LUMA_FP32_TAN_PRECISION_WORKAROUND\\nconst float TWO_PI = 6.2831854820251465;\\nconst float PI_2 = 1.5707963705062866;\\nconst float PI_16 = 0.1963495463132858;\\n\\nconst float SIN_TABLE_0 = 0.19509032368659973;\\nconst float SIN_TABLE_1 = 0.3826834261417389;\\nconst float SIN_TABLE_2 = 0.5555702447891235;\\nconst float SIN_TABLE_3 = 0.7071067690849304;\\n\\nconst float COS_TABLE_0 = 0.9807852506637573;\\nconst float COS_TABLE_1 = 0.9238795042037964;\\nconst float COS_TABLE_2 = 0.8314695954322815;\\nconst float COS_TABLE_3 = 0.7071067690849304;\\n\\nconst float INVERSE_FACTORIAL_3 = 1.666666716337204e-01;\\nconst float INVERSE_FACTORIAL_5 = 8.333333767950535e-03;\\nconst float INVERSE_FACTORIAL_7 = 1.9841270113829523e-04;\\nconst float INVERSE_FACTORIAL_9 = 2.75573188446287533e-06;\\n\\nfloat sin_taylor_fp32(float a) {\\n  float r, s, t, x;\\n\\n  if (a == 0.0) {\\n    return 0.0;\\n  }\\n\\n  x = -a * a;\\n  s = a;\\n  r = a;\\n\\n  r = r * x;\\n  t = r * INVERSE_FACTORIAL_3;\\n  s = s + t;\\n\\n  r = r * x;\\n  t = r * INVERSE_FACTORIAL_5;\\n  s = s + t;\\n\\n  r = r * x;\\n  t = r * INVERSE_FACTORIAL_7;\\n  s = s + t;\\n\\n  r = r * x;\\n  t = r * INVERSE_FACTORIAL_9;\\n  s = s + t;\\n\\n  return s;\\n}\\n\\nvoid sincos_taylor_fp32(float a, out float sin_t, out float cos_t) {\\n  if (a == 0.0) {\\n    sin_t = 0.0;\\n    cos_t = 1.0;\\n  }\\n  sin_t = sin_taylor_fp32(a);\\n  cos_t = sqrt(1.0 - sin_t * sin_t);\\n}\\n\\nfloat tan_taylor_fp32(float a) {\\n    float sin_a;\\n    float cos_a;\\n\\n    if (a == 0.0) {\\n        return 0.0;\\n    }\\n    float z = floor(a / TWO_PI);\\n    float r = a - TWO_PI * z;\\n\\n    float t;\\n    float q = floor(r / PI_2 + 0.5);\\n    int j = int(q);\\n\\n    if (j < -2 || j > 2) {\\n        return 1.0 / 0.0;\\n    }\\n\\n    t = r - PI_2 * q;\\n\\n    q = floor(t / PI_16 + 0.5);\\n    int k = int(q);\\n    int abs_k = int(abs(float(k)));\\n\\n    if (abs_k > 4) {\\n        return 1.0 / 0.0;\\n    } else {\\n        t = t - PI_16 * q;\\n    }\\n\\n    float u = 0.0;\\n    float v = 0.0;\\n\\n    float sin_t, cos_t;\\n    float s, c;\\n    sincos_taylor_fp32(t, sin_t, cos_t);\\n\\n    if (k == 0) {\\n        s = sin_t;\\n        c = cos_t;\\n    } else {\\n        if (abs(float(abs_k) - 1.0) < 0.5) {\\n            u = COS_TABLE_0;\\n            v = SIN_TABLE_0;\\n        } else if (abs(float(abs_k) - 2.0) < 0.5) {\\n            u = COS_TABLE_1;\\n            v = SIN_TABLE_1;\\n        } else if (abs(float(abs_k) - 3.0) < 0.5) {\\n            u = COS_TABLE_2;\\n            v = SIN_TABLE_2;\\n        } else if (abs(float(abs_k) - 4.0) < 0.5) {\\n            u = COS_TABLE_3;\\n            v = SIN_TABLE_3;\\n        }\\n        if (k > 0) {\\n            s = u * sin_t + v * cos_t;\\n            c = u * cos_t - v * sin_t;\\n        } else {\\n            s = u * sin_t - v * cos_t;\\n            c = u * cos_t + v * sin_t;\\n        }\\n    }\\n\\n    if (j == 0) {\\n        sin_a = s;\\n        cos_a = c;\\n    } else if (j == 1) {\\n        sin_a = c;\\n        cos_a = -s;\\n    } else if (j == -1) {\\n        sin_a = -c;\\n        cos_a = s;\\n    } else {\\n        sin_a = -s;\\n        cos_a = -c;\\n    }\\n    return sin_a / cos_a;\\n}\\n#endif\\n\\nfloat tan_fp32(float a) {\\n#ifdef LUMA_FP32_TAN_PRECISION_WORKAROUND\\n  return tan_taylor_fp32(a);\\n#else\\n  return tan(a);\\n#endif\\n}\\n\";\nconst fp32 = {\n  name: 'fp32',\n  vs: fp32shader,\n  fs: null\n};\n//# sourceMappingURL=fp32.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/shadertools/dist/esm/modules/fp32/fp32.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/shadertools/dist/esm/modules/lights/lights.glsl.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/@luma.gl/shadertools/dist/esm/modules/lights/lights.glsl.js ***!
  \**********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (\"#if (defined(SHADER_TYPE_FRAGMENT) && defined(LIGHTING_FRAGMENT)) || (defined(SHADER_TYPE_VERTEX) && defined(LIGHTING_VERTEX))\\n\\nstruct AmbientLight {\\n vec3 color;\\n};\\n\\nstruct PointLight {\\n vec3 color;\\n vec3 position;\\n vec3 attenuation;\\n};\\n\\nstruct DirectionalLight {\\n  vec3 color;\\n  vec3 direction;\\n};\\n\\nuniform AmbientLight lighting_uAmbientLight;\\nuniform PointLight lighting_uPointLight[MAX_LIGHTS];\\nuniform DirectionalLight lighting_uDirectionalLight[MAX_LIGHTS];\\nuniform int lighting_uPointLightCount;\\nuniform int lighting_uDirectionalLightCount;\\n\\nuniform bool lighting_uEnabled;\\n\\nfloat getPointLightAttenuation(PointLight pointLight, float distance) {\\n  return pointLight.attenuation.x\\n       + pointLight.attenuation.y * distance\\n       + pointLight.attenuation.z * distance * distance;\\n}\\n\\n#endif\\n\");\n//# sourceMappingURL=lights.glsl.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/shadertools/dist/esm/modules/lights/lights.glsl.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/shadertools/dist/esm/modules/lights/lights.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/@luma.gl/shadertools/dist/esm/modules/lights/lights.js ***!
  \*****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   lights: () => (/* binding */ lights)\n/* harmony export */ });\n/* harmony import */ var _lights_glsl__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./lights.glsl */ \"./node_modules/@luma.gl/shadertools/dist/esm/modules/lights/lights.glsl.js\");\n\nconst INITIAL_MODULE_OPTIONS = {\n  lightSources: {}\n};\n\nfunction convertColor() {\n  let {\n    color = [0, 0, 0],\n    intensity = 1.0\n  } = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n  return color.map(component => component * intensity / 255.0);\n}\n\nfunction getLightSourceUniforms(_ref) {\n  let {\n    ambientLight,\n    pointLights = [],\n    directionalLights = []\n  } = _ref;\n  const lightSourceUniforms = {};\n\n  if (ambientLight) {\n    lightSourceUniforms['lighting_uAmbientLight.color'] = convertColor(ambientLight);\n  } else {\n    lightSourceUniforms['lighting_uAmbientLight.color'] = [0, 0, 0];\n  }\n\n  pointLights.forEach((pointLight, index) => {\n    lightSourceUniforms[\"lighting_uPointLight[\".concat(index, \"].color\")] = convertColor(pointLight);\n    lightSourceUniforms[\"lighting_uPointLight[\".concat(index, \"].position\")] = pointLight.position;\n    lightSourceUniforms[\"lighting_uPointLight[\".concat(index, \"].attenuation\")] = pointLight.attenuation || [1, 0, 0];\n  });\n  lightSourceUniforms.lighting_uPointLightCount = pointLights.length;\n  directionalLights.forEach((directionalLight, index) => {\n    lightSourceUniforms[\"lighting_uDirectionalLight[\".concat(index, \"].color\")] = convertColor(directionalLight);\n    lightSourceUniforms[\"lighting_uDirectionalLight[\".concat(index, \"].direction\")] = directionalLight.direction;\n  });\n  lightSourceUniforms.lighting_uDirectionalLightCount = directionalLights.length;\n  return lightSourceUniforms;\n}\n\nfunction getUniforms() {\n  let opts = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : INITIAL_MODULE_OPTIONS;\n\n  if ('lightSources' in opts) {\n    const {\n      ambientLight,\n      pointLights,\n      directionalLights\n    } = opts.lightSources || {};\n    const hasLights = ambientLight || pointLights && pointLights.length > 0 || directionalLights && directionalLights.length > 0;\n\n    if (!hasLights) {\n      return {\n        lighting_uEnabled: false\n      };\n    }\n\n    return Object.assign({}, getLightSourceUniforms({\n      ambientLight,\n      pointLights,\n      directionalLights\n    }), {\n      lighting_uEnabled: true\n    });\n  }\n\n  if ('lights' in opts) {\n    const lightSources = {\n      pointLights: [],\n      directionalLights: []\n    };\n\n    for (const light of opts.lights || []) {\n      switch (light.type) {\n        case 'ambient':\n          lightSources.ambientLight = light;\n          break;\n\n        case 'directional':\n          lightSources.directionalLights.push(light);\n          break;\n\n        case 'point':\n          lightSources.pointLights.push(light);\n          break;\n\n        default:\n      }\n    }\n\n    return getUniforms({\n      lightSources\n    });\n  }\n\n  return {};\n}\n\nconst lights = {\n  name: 'lights',\n  vs: _lights_glsl__WEBPACK_IMPORTED_MODULE_0__[\"default\"],\n  fs: _lights_glsl__WEBPACK_IMPORTED_MODULE_0__[\"default\"],\n  getUniforms,\n  defines: {\n    MAX_LIGHTS: 3\n  }\n};\n//# sourceMappingURL=lights.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/shadertools/dist/esm/modules/lights/lights.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/shadertools/dist/esm/modules/module-injectors.js":
/*!********************************************************************************!*\
  !*** ./node_modules/@luma.gl/shadertools/dist/esm/modules/module-injectors.js ***!
  \********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   MODULE_INJECTORS_FS: () => (/* binding */ MODULE_INJECTORS_FS),\n/* harmony export */   MODULE_INJECTORS_VS: () => (/* binding */ MODULE_INJECTORS_VS)\n/* harmony export */ });\nconst MODULE_INJECTORS_VS = \"#ifdef MODULE_LOGDEPTH\\n  logdepth_adjustPosition(gl_Position);\\n#endif\\n\";\nconst MODULE_INJECTORS_FS = \"#ifdef MODULE_MATERIAL\\n  gl_FragColor = material_filterColor(gl_FragColor);\\n#endif\\n\\n#ifdef MODULE_LIGHTING\\n  gl_FragColor = lighting_filterColor(gl_FragColor);\\n#endif\\n\\n#ifdef MODULE_FOG\\n  gl_FragColor = fog_filterColor(gl_FragColor);\\n#endif\\n\\n#ifdef MODULE_PICKING\\n  gl_FragColor = picking_filterHighlightColor(gl_FragColor);\\n  gl_FragColor = picking_filterPickingColor(gl_FragColor);\\n#endif\\n\\n#ifdef MODULE_LOGDEPTH\\n  logdepth_setFragDepth();\\n#endif\\n\";\n//# sourceMappingURL=module-injectors.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/shadertools/dist/esm/modules/module-injectors.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/shadertools/dist/esm/modules/phong-lighting/phong-lighting.glsl.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/@luma.gl/shadertools/dist/esm/modules/phong-lighting/phong-lighting.glsl.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (\"\\nuniform float lighting_uAmbient;\\nuniform float lighting_uDiffuse;\\nuniform float lighting_uShininess;\\nuniform vec3  lighting_uSpecularColor;\\n\\nvec3 lighting_getLightColor(vec3 surfaceColor, vec3 light_direction, vec3 view_direction, vec3 normal_worldspace, vec3 color) {\\n    vec3 halfway_direction = normalize(light_direction + view_direction);\\n    float lambertian = dot(light_direction, normal_worldspace);\\n    float specular = 0.0;\\n    if (lambertian > 0.0) {\\n      float specular_angle = max(dot(normal_worldspace, halfway_direction), 0.0);\\n      specular = pow(specular_angle, lighting_uShininess);\\n    }\\n    lambertian = max(lambertian, 0.0);\\n    return (lambertian * lighting_uDiffuse * surfaceColor + specular * lighting_uSpecularColor) * color;\\n}\\n\\nvec3 lighting_getLightColor(vec3 surfaceColor, vec3 cameraPosition, vec3 position_worldspace, vec3 normal_worldspace) {\\n  vec3 lightColor = surfaceColor;\\n\\n  if (lighting_uEnabled) {\\n    vec3 view_direction = normalize(cameraPosition - position_worldspace);\\n    lightColor = lighting_uAmbient * surfaceColor * lighting_uAmbientLight.color;\\n\\n    for (int i = 0; i < MAX_LIGHTS; i++) {\\n      if (i >= lighting_uPointLightCount) {\\n        break;\\n      }\\n      PointLight pointLight = lighting_uPointLight[i];\\n      vec3 light_position_worldspace = pointLight.position;\\n      vec3 light_direction = normalize(light_position_worldspace - position_worldspace);\\n      lightColor += lighting_getLightColor(surfaceColor, light_direction, view_direction, normal_worldspace, pointLight.color);\\n    }\\n\\n    for (int i = 0; i < MAX_LIGHTS; i++) {\\n      if (i >= lighting_uDirectionalLightCount) {\\n        break;\\n      }\\n      DirectionalLight directionalLight = lighting_uDirectionalLight[i];\\n      lightColor += lighting_getLightColor(surfaceColor, -directionalLight.direction, view_direction, normal_worldspace, directionalLight.color);\\n    }\\n  }\\n  return lightColor;\\n}\\n\\nvec3 lighting_getSpecularLightColor(vec3 cameraPosition, vec3 position_worldspace, vec3 normal_worldspace) {\\n  vec3 lightColor = vec3(0, 0, 0);\\n  vec3 surfaceColor = vec3(0, 0, 0);\\n\\n  if (lighting_uEnabled) {\\n    vec3 view_direction = normalize(cameraPosition - position_worldspace);\\n\\n    for (int i = 0; i < MAX_LIGHTS; i++) {\\n      if (i >= lighting_uPointLightCount) {\\n        break;\\n      }\\n      PointLight pointLight = lighting_uPointLight[i];\\n      vec3 light_position_worldspace = pointLight.position;\\n      vec3 light_direction = normalize(light_position_worldspace - position_worldspace);\\n      lightColor += lighting_getLightColor(surfaceColor, light_direction, view_direction, normal_worldspace, pointLight.color);\\n    }\\n\\n    for (int i = 0; i < MAX_LIGHTS; i++) {\\n      if (i >= lighting_uDirectionalLightCount) {\\n        break;\\n      }\\n      DirectionalLight directionalLight = lighting_uDirectionalLight[i];\\n      lightColor += lighting_getLightColor(surfaceColor, -directionalLight.direction, view_direction, normal_worldspace, directionalLight.color);\\n    }\\n  }\\n  return lightColor;\\n}\\n\");\n//# sourceMappingURL=phong-lighting.glsl.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/shadertools/dist/esm/modules/phong-lighting/phong-lighting.glsl.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/shadertools/dist/esm/modules/phong-lighting/phong-lighting.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/@luma.gl/shadertools/dist/esm/modules/phong-lighting/phong-lighting.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   gouraudLighting: () => (/* binding */ gouraudLighting),\n/* harmony export */   phongLighting: () => (/* binding */ phongLighting)\n/* harmony export */ });\n/* harmony import */ var _lights_lights__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../lights/lights */ \"./node_modules/@luma.gl/shadertools/dist/esm/modules/lights/lights.js\");\n/* harmony import */ var _phong_lighting_glsl__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./phong-lighting.glsl */ \"./node_modules/@luma.gl/shadertools/dist/esm/modules/phong-lighting/phong-lighting.glsl.js\");\n\n\nconst INITIAL_MODULE_OPTIONS = {};\n\nfunction getMaterialUniforms(material) {\n  const {\n    ambient = 0.35,\n    diffuse = 0.6,\n    shininess = 32,\n    specularColor = [30, 30, 30]\n  } = material;\n  return {\n    lighting_uAmbient: ambient,\n    lighting_uDiffuse: diffuse,\n    lighting_uShininess: shininess,\n    lighting_uSpecularColor: specularColor.map(x => x / 255)\n  };\n}\n\nfunction getUniforms() {\n  let opts = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : INITIAL_MODULE_OPTIONS;\n\n  if (!('material' in opts)) {\n    return {};\n  }\n\n  const {\n    material\n  } = opts;\n\n  if (!material) {\n    return {\n      lighting_uEnabled: false\n    };\n  }\n\n  return getMaterialUniforms(material);\n}\n\nconst gouraudLighting = {\n  name: 'gouraud-lighting',\n  dependencies: [_lights_lights__WEBPACK_IMPORTED_MODULE_0__.lights],\n  vs: _phong_lighting_glsl__WEBPACK_IMPORTED_MODULE_1__[\"default\"],\n  defines: {\n    LIGHTING_VERTEX: 1\n  },\n  getUniforms\n};\nconst phongLighting = {\n  name: 'phong-lighting',\n  dependencies: [_lights_lights__WEBPACK_IMPORTED_MODULE_0__.lights],\n  fs: _phong_lighting_glsl__WEBPACK_IMPORTED_MODULE_1__[\"default\"],\n  defines: {\n    LIGHTING_FRAGMENT: 1\n  },\n  getUniforms\n};\n//# sourceMappingURL=phong-lighting.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/shadertools/dist/esm/modules/phong-lighting/phong-lighting.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/shadertools/dist/esm/modules/picking/picking.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/@luma.gl/shadertools/dist/esm/modules/picking/picking.js ***!
  \*******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   picking: () => (/* binding */ picking)\n/* harmony export */ });\nconst DEFAULT_HIGHLIGHT_COLOR = new Uint8Array([0, 255, 255, 255]);\nconst DEFAULT_MODULE_OPTIONS = {\n  pickingSelectedColor: null,\n  pickingHighlightColor: DEFAULT_HIGHLIGHT_COLOR,\n  pickingActive: false,\n  pickingAttribute: false\n};\n\nfunction getUniforms() {\n  let opts = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : DEFAULT_MODULE_OPTIONS;\n  const uniforms = {};\n\n  if (opts.pickingSelectedColor !== undefined) {\n    if (!opts.pickingSelectedColor) {\n      uniforms.picking_uSelectedColorValid = 0;\n    } else {\n      const selectedColor = opts.pickingSelectedColor.slice(0, 3);\n      uniforms.picking_uSelectedColorValid = 1;\n      uniforms.picking_uSelectedColor = selectedColor;\n    }\n  }\n\n  if (opts.pickingHighlightColor) {\n    const color = Array.from(opts.pickingHighlightColor, x => x / 255);\n\n    if (!Number.isFinite(color[3])) {\n      color[3] = 1;\n    }\n\n    uniforms.picking_uHighlightColor = color;\n  }\n\n  if (opts.pickingActive !== undefined) {\n    uniforms.picking_uActive = Boolean(opts.pickingActive);\n    uniforms.picking_uAttribute = Boolean(opts.pickingAttribute);\n  }\n\n  return uniforms;\n}\n\nconst vs = \"uniform bool picking_uActive;\\nuniform bool picking_uAttribute;\\nuniform vec3 picking_uSelectedColor;\\nuniform bool picking_uSelectedColorValid;\\n\\nout vec4 picking_vRGBcolor_Avalid;\\n\\nconst float COLOR_SCALE = 1. / 255.;\\n\\nbool picking_isColorValid(vec3 color) {\\n  return dot(color, vec3(1.0)) > 0.001;\\n}\\n\\nbool isVertexPicked(vec3 vertexColor) {\\n  return\\n    picking_uSelectedColorValid &&\\n    !picking_isColorValid(abs(vertexColor - picking_uSelectedColor));\\n}\\n\\nvoid picking_setPickingColor(vec3 pickingColor) {\\n  if (picking_uActive) {\\n    picking_vRGBcolor_Avalid.a = float(picking_isColorValid(pickingColor));\\n\\n    if (!picking_uAttribute) {\\n      picking_vRGBcolor_Avalid.rgb = pickingColor * COLOR_SCALE;\\n    }\\n  } else {\\n    picking_vRGBcolor_Avalid.a = float(isVertexPicked(pickingColor));\\n  }\\n}\\n\\nvoid picking_setPickingAttribute(float value) {\\n  if (picking_uAttribute) {\\n    picking_vRGBcolor_Avalid.r = value;\\n  }\\n}\\nvoid picking_setPickingAttribute(vec2 value) {\\n  if (picking_uAttribute) {\\n    picking_vRGBcolor_Avalid.rg = value;\\n  }\\n}\\nvoid picking_setPickingAttribute(vec3 value) {\\n  if (picking_uAttribute) {\\n    picking_vRGBcolor_Avalid.rgb = value;\\n  }\\n}\\n\";\nconst fs = \"uniform bool picking_uActive;\\nuniform vec3 picking_uSelectedColor;\\nuniform vec4 picking_uHighlightColor;\\n\\nin vec4 picking_vRGBcolor_Avalid;\\nvec4 picking_filterHighlightColor(vec4 color) {\\n  if (picking_uActive) {\\n    return color;\\n  }\\n  bool selected = bool(picking_vRGBcolor_Avalid.a);\\n\\n  if (selected) {\\n    float highLightAlpha = picking_uHighlightColor.a;\\n    float blendedAlpha = highLightAlpha + color.a * (1.0 - highLightAlpha);\\n    float highLightRatio = highLightAlpha / blendedAlpha;\\n\\n    vec3 blendedRGB = mix(color.rgb, picking_uHighlightColor.rgb, highLightRatio);\\n    return vec4(blendedRGB, blendedAlpha);\\n  } else {\\n    return color;\\n  }\\n}\\nvec4 picking_filterPickingColor(vec4 color) {\\n  if (picking_uActive) {\\n    if (picking_vRGBcolor_Avalid.a == 0.0) {\\n      discard;\\n    }\\n    return picking_vRGBcolor_Avalid;\\n  }\\n  return color;\\n}\\nvec4 picking_filterColor(vec4 color) {\\n  vec4 highightColor = picking_filterHighlightColor(color);\\n  return picking_filterPickingColor(highightColor);\\n}\\n\\n\";\nconst picking = {\n  name: 'picking',\n  vs,\n  fs,\n  getUniforms\n};\n//# sourceMappingURL=picking.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/shadertools/dist/esm/modules/picking/picking.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/shadertools/dist/esm/modules/transform/transform.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/@luma.gl/shadertools/dist/esm/modules/transform/transform.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   transform: () => (/* binding */ transform)\n/* harmony export */ });\nconst vs = \"attribute float transform_elementID;\\nvec2 transform_getPixelSizeHalf(vec2 size) {\\n  return vec2(1.) / (2. * size);\\n}\\n\\nvec2 transform_getPixelIndices(vec2 texSize, vec2 pixelSizeHalf) {\\n  float yIndex = floor((transform_elementID / texSize[0]) + pixelSizeHalf[1]);\\n  float xIndex = transform_elementID - (yIndex * texSize[0]);\\n  return vec2(xIndex, yIndex);\\n}\\nvec2 transform_getTexCoord(vec2 size) {\\n  vec2 pixelSizeHalf = transform_getPixelSizeHalf(size);\\n  vec2 indices = transform_getPixelIndices(size, pixelSizeHalf);\\n  vec2 coord = indices / size + pixelSizeHalf;\\n  return coord;\\n}\\nvec2 transform_getPos(vec2 size) {\\n  vec2 texCoord = transform_getTexCoord(size);\\n  vec2 pos = (texCoord * (2.0, 2.0)) - (1., 1.);\\n  return pos;\\n}\\nvec4 transform_getInput(sampler2D texSampler, vec2 size) {\\n  vec2 texCoord = transform_getTexCoord(size);\\n  vec4 textureColor = texture2D(texSampler, texCoord);\\n  return textureColor;\\n}\\n\";\nconst transform = {\n  name: 'transform',\n  vs,\n  fs: null\n};\n//# sourceMappingURL=transform.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/shadertools/dist/esm/modules/transform/transform.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/shadertools/dist/esm/utils/assert.js":
/*!********************************************************************!*\
  !*** ./node_modules/@luma.gl/shadertools/dist/esm/utils/assert.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ assert)\n/* harmony export */ });\nfunction assert(condition, message) {\n  if (!condition) {\n    throw new Error(message || 'shadertools: assertion failed.');\n  }\n}\n//# sourceMappingURL=assert.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/shadertools/dist/esm/utils/assert.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/shadertools/dist/esm/utils/is-old-ie.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@luma.gl/shadertools/dist/esm/utils/is-old-ie.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ isOldIE)\n/* harmony export */ });\nfunction isOldIE() {\n  let opts = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n  const navigator = typeof window !== 'undefined' ? window.navigator || {} : {};\n  const userAgent = opts.userAgent || navigator.userAgent || '';\n  const isMSIE = userAgent.indexOf('MSIE ') !== -1;\n  const isTrident = userAgent.indexOf('Trident/') !== -1;\n  return isMSIE || isTrident;\n}\n//# sourceMappingURL=is-old-ie.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/shadertools/dist/esm/utils/is-old-ie.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/shadertools/dist/esm/utils/shader-utils.js":
/*!**************************************************************************!*\
  !*** ./node_modules/@luma.gl/shadertools/dist/esm/utils/shader-utils.js ***!
  \**************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   convertToVec4: () => (/* binding */ convertToVec4),\n/* harmony export */   getPassthroughFS: () => (/* binding */ getPassthroughFS),\n/* harmony export */   getQualifierDetails: () => (/* binding */ getQualifierDetails),\n/* harmony export */   typeToChannelCount: () => (/* binding */ typeToChannelCount),\n/* harmony export */   typeToChannelSuffix: () => (/* binding */ typeToChannelSuffix)\n/* harmony export */ });\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils */ \"./node_modules/@luma.gl/shadertools/dist/esm/utils/assert.js\");\n\nconst FS100 = \"void main() {gl_FragColor = vec4(0);}\";\nconst FS_GLES = \"out vec4 transform_output;\\nvoid main() {\\n  transform_output = vec4(0);\\n}\";\nconst FS300 = \"#version 300 es\\n\".concat(FS_GLES);\nfunction getQualifierDetails(line, qualifiers) {\n  qualifiers = Array.isArray(qualifiers) ? qualifiers : [qualifiers];\n  const words = line.replace(/^\\s+/, '').split(/\\s+/);\n  const [qualifier, type, definition] = words;\n\n  if (!qualifiers.includes(qualifier) || !type || !definition) {\n    return null;\n  }\n\n  const name = definition.split(';')[0];\n  return {\n    qualifier,\n    type,\n    name\n  };\n}\nfunction getPassthroughFS() {\n  let options = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n  const {\n    version = 100,\n    input,\n    inputType,\n    output\n  } = options;\n\n  if (!input) {\n    if (version === 300) {\n      return FS300;\n    } else if (version > 300) {\n      return \"#version \".concat(version, \"\\n\").concat(FS_GLES);\n    }\n\n    return FS100;\n  }\n\n  const outputValue = convertToVec4(input, inputType);\n\n  if (version >= 300) {\n    return \"#version \".concat(version, \" \").concat(version === 300 ? 'es' : '', \"\\nin \").concat(inputType, \" \").concat(input, \";\\nout vec4 \").concat(output, \";\\nvoid main() {\\n  \").concat(output, \" = \").concat(outputValue, \";\\n}\");\n  }\n\n  return \"varying \".concat(inputType, \" \").concat(input, \";\\nvoid main() {\\n  gl_FragColor = \").concat(outputValue, \";\\n}\");\n}\nfunction typeToChannelSuffix(type) {\n  switch (type) {\n    case 'float':\n      return 'x';\n\n    case 'vec2':\n      return 'xy';\n\n    case 'vec3':\n      return 'xyz';\n\n    case 'vec4':\n      return 'xyzw';\n\n    default:\n      (0,_utils__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(false);\n      return null;\n  }\n}\nfunction typeToChannelCount(type) {\n  switch (type) {\n    case 'float':\n      return 1;\n\n    case 'vec2':\n      return 2;\n\n    case 'vec3':\n      return 3;\n\n    case 'vec4':\n      return 4;\n\n    default:\n      (0,_utils__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(false);\n      return null;\n  }\n}\nfunction convertToVec4(variable, type) {\n  switch (type) {\n    case 'float':\n      return \"vec4(\".concat(variable, \", 0.0, 0.0, 1.0)\");\n\n    case 'vec2':\n      return \"vec4(\".concat(variable, \", 0.0, 1.0)\");\n\n    case 'vec3':\n      return \"vec4(\".concat(variable, \", 1.0)\");\n\n    case 'vec4':\n      return variable;\n\n    default:\n      (0,_utils__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(false);\n      return null;\n  }\n}\n//# sourceMappingURL=shader-utils.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/shadertools/dist/esm/utils/shader-utils.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/shadertools/dist/esm/utils/webgl-info.js":
/*!************************************************************************!*\
  !*** ./node_modules/@luma.gl/shadertools/dist/esm/utils/webgl-info.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   FEATURES: () => (/* binding */ FEATURES),\n/* harmony export */   canCompileGLGSExtension: () => (/* binding */ canCompileGLGSExtension),\n/* harmony export */   getContextInfo: () => (/* binding */ getContextInfo),\n/* harmony export */   hasFeatures: () => (/* binding */ hasFeatures)\n/* harmony export */ });\n/* harmony import */ var _is_old_ie__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./is-old-ie */ \"./node_modules/@luma.gl/shadertools/dist/esm/utils/is-old-ie.js\");\n/* harmony import */ var _assert__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./assert */ \"./node_modules/@luma.gl/shadertools/dist/esm/utils/assert.js\");\n\n\nconst GL_VENDOR = 0x1f00;\nconst GL_RENDERER = 0x1f01;\nconst GL_VERSION = 0x1f02;\nconst GL_SHADING_LANGUAGE_VERSION = 0x8b8c;\nconst WEBGL_FEATURES = {\n  GLSL_FRAG_DATA: ['WEBGL_draw_buffers', true],\n  GLSL_FRAG_DEPTH: ['EXT_frag_depth', true],\n  GLSL_DERIVATIVES: ['OES_standard_derivatives', true],\n  GLSL_TEXTURE_LOD: ['EXT_shader_texture_lod', true]\n};\nconst FEATURES = {};\nObject.keys(WEBGL_FEATURES).forEach(key => {\n  FEATURES[key] = key;\n});\n\n\nfunction isWebGL2(gl) {\n  if (typeof WebGL2RenderingContext !== 'undefined' && gl instanceof WebGL2RenderingContext) {\n    return true;\n  }\n\n  return Boolean(gl && gl._version === 2);\n}\n\nfunction getContextInfo(gl) {\n  const info = gl.getExtension('WEBGL_debug_renderer_info');\n  const vendor = gl.getParameter(info && info.UNMASKED_VENDOR_WEBGL || GL_VENDOR);\n  const renderer = gl.getParameter(info && info.UNMASKED_RENDERER_WEBGL || GL_RENDERER);\n  const gpuVendor = identifyGPUVendor(vendor, renderer);\n  const gpuInfo = {\n    gpuVendor,\n    vendor,\n    renderer,\n    version: gl.getParameter(GL_VERSION),\n    shadingLanguageVersion: gl.getParameter(GL_SHADING_LANGUAGE_VERSION)\n  };\n  return gpuInfo;\n}\n\nfunction identifyGPUVendor(vendor, renderer) {\n  if (vendor.match(/NVIDIA/i) || renderer.match(/NVIDIA/i)) {\n    return 'NVIDIA';\n  }\n\n  if (vendor.match(/INTEL/i) || renderer.match(/INTEL/i)) {\n    return 'INTEL';\n  }\n\n  if (vendor.match(/AMD/i) || renderer.match(/AMD/i) || vendor.match(/ATI/i) || renderer.match(/ATI/i)) {\n    return 'AMD';\n  }\n\n  return 'UNKNOWN GPU';\n}\n\nconst compiledGlslExtensions = {};\nfunction canCompileGLGSExtension(gl, cap) {\n  let opts = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n  const feature = WEBGL_FEATURES[cap];\n  (0,_assert__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(feature, cap);\n\n  if (!(0,_is_old_ie__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(opts)) {\n    return true;\n  }\n\n  if (cap in compiledGlslExtensions) {\n    return compiledGlslExtensions[cap];\n  }\n\n  const extensionName = feature[0];\n  const behavior = opts.behavior || 'enable';\n  const source = \"#extension GL_\".concat(extensionName, \" : \").concat(behavior, \"\\nvoid main(void) {}\");\n  const shader = gl.createShader(35633);\n  gl.shaderSource(shader, source);\n  gl.compileShader(shader);\n  const canCompile = gl.getShaderParameter(shader, 35713);\n  gl.deleteShader(shader);\n  compiledGlslExtensions[cap] = canCompile;\n  return canCompile;\n}\n\nfunction getFeature(gl, cap) {\n  const feature = WEBGL_FEATURES[cap];\n  (0,_assert__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(feature, cap);\n  const extensionName = isWebGL2(gl) ? feature[1] || feature[0] : feature[0];\n  const value = typeof extensionName === 'string' ? Boolean(gl.getExtension(extensionName)) : extensionName;\n  (0,_assert__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(value === false || value === true);\n  return value;\n}\n\nfunction hasFeatures(gl, features) {\n  features = Array.isArray(features) ? features : [features];\n  return features.every(feature => getFeature(gl, feature));\n}\n//# sourceMappingURL=webgl-info.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/shadertools/dist/esm/utils/webgl-info.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/classes/accessor.js":
/*!******************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/classes/accessor.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   DEFAULT_ACCESSOR_VALUES: () => (/* binding */ DEFAULT_ACCESSOR_VALUES),\n/* harmony export */   \"default\": () => (/* binding */ Accessor)\n/* harmony export */ });\n/* harmony import */ var _webgl_utils_typed_array_utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../webgl-utils/typed-array-utils */ \"./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/typed-array-utils.js\");\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/assert */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js\");\n/* harmony import */ var _utils_check_props__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/check-props */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/check-props.js\");\n\n\n\nconst DEFAULT_ACCESSOR_VALUES = {\n  offset: 0,\n  stride: 0,\n  type: 5126,\n  size: 1,\n  divisor: 0,\n  normalized: false,\n  integer: false\n};\nconst PROP_CHECKS = {\n  deprecatedProps: {\n    instanced: 'divisor',\n    isInstanced: 'divisor'\n  }\n};\nclass Accessor {\n  static getBytesPerElement(accessor) {\n    const ArrayType = (0,_webgl_utils_typed_array_utils__WEBPACK_IMPORTED_MODULE_0__.getTypedArrayFromGLType)(accessor.type || 5126);\n    return ArrayType.BYTES_PER_ELEMENT;\n  }\n\n  static getBytesPerVertex(accessor) {\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_1__.assert)(accessor.size);\n    const ArrayType = (0,_webgl_utils_typed_array_utils__WEBPACK_IMPORTED_MODULE_0__.getTypedArrayFromGLType)(accessor.type || 5126);\n    return ArrayType.BYTES_PER_ELEMENT * accessor.size;\n  }\n\n  static resolve() {\n    for (var _len = arguments.length, accessors = new Array(_len), _key = 0; _key < _len; _key++) {\n      accessors[_key] = arguments[_key];\n    }\n\n    return new Accessor(...[DEFAULT_ACCESSOR_VALUES, ...accessors]);\n  }\n\n  constructor() {\n    for (var _len2 = arguments.length, accessors = new Array(_len2), _key2 = 0; _key2 < _len2; _key2++) {\n      accessors[_key2] = arguments[_key2];\n    }\n\n    accessors.forEach(accessor => this._assign(accessor));\n    Object.freeze(this);\n  }\n\n  toString() {\n    return JSON.stringify(this);\n  }\n\n  get BYTES_PER_ELEMENT() {\n    return Accessor.getBytesPerElement(this);\n  }\n\n  get BYTES_PER_VERTEX() {\n    return Accessor.getBytesPerVertex(this);\n  }\n\n  _assign() {\n    let props = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    props = (0,_utils_check_props__WEBPACK_IMPORTED_MODULE_2__.checkProps)('Accessor', props, PROP_CHECKS);\n\n    if (props.type !== undefined) {\n      this.type = props.type;\n\n      if (props.type === 5124 || props.type === 5125) {\n        this.integer = true;\n      }\n    }\n\n    if (props.size !== undefined) {\n      this.size = props.size;\n    }\n\n    if (props.offset !== undefined) {\n      this.offset = props.offset;\n    }\n\n    if (props.stride !== undefined) {\n      this.stride = props.stride;\n    }\n\n    if (props.normalized !== undefined) {\n      this.normalized = props.normalized;\n    }\n\n    if (props.integer !== undefined) {\n      this.integer = props.integer;\n    }\n\n    if (props.divisor !== undefined) {\n      this.divisor = props.divisor;\n    }\n\n    if (props.buffer !== undefined) {\n      this.buffer = props.buffer;\n    }\n\n    if (props.index !== undefined) {\n      if (typeof props.index === 'boolean') {\n        this.index = props.index ? 1 : 0;\n      } else {\n        this.index = props.index;\n      }\n    }\n\n    if (props.instanced !== undefined) {\n      this.divisor = props.instanced ? 1 : 0;\n    }\n\n    if (props.isInstanced !== undefined) {\n      this.divisor = props.isInstanced ? 1 : 0;\n    }\n\n    return this;\n  }\n\n}\n\n//# sourceMappingURL=accessor.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/classes/accessor.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/classes/buffer.js":
/*!****************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/classes/buffer.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Buffer)\n/* harmony export */ });\n/* harmony import */ var _resource__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./resource */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/resource.js\");\n/* harmony import */ var _accessor__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./accessor */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/accessor.js\");\n/* harmony import */ var _webgl_utils_typed_array_utils__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../webgl-utils/typed-array-utils */ \"./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/typed-array-utils.js\");\n/* harmony import */ var _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/gltools */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../utils/assert */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js\");\n/* harmony import */ var _utils_check_props__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/check-props */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/check-props.js\");\n\n\n\n\n\n\nconst DEBUG_DATA_LENGTH = 10;\nconst DEPRECATED_PROPS = {\n  offset: 'accessor.offset',\n  stride: 'accessor.stride',\n  type: 'accessor.type',\n  size: 'accessor.size',\n  divisor: 'accessor.divisor',\n  normalized: 'accessor.normalized',\n  integer: 'accessor.integer',\n  instanced: 'accessor.divisor',\n  isInstanced: 'accessor.divisor'\n};\nconst PROP_CHECKS_INITIALIZE = {\n  removedProps: {},\n  replacedProps: {\n    bytes: 'byteLength'\n  },\n  deprecatedProps: DEPRECATED_PROPS\n};\nconst PROP_CHECKS_SET_PROPS = {\n  removedProps: DEPRECATED_PROPS\n};\nclass Buffer extends _resource__WEBPACK_IMPORTED_MODULE_1__[\"default\"] {\n  get [Symbol.toStringTag]() {\n    return 'Buffer';\n  }\n\n  constructor(gl) {\n    let props = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    super(gl, props);\n    this.stubRemovedMethods('Buffer', 'v6.0', ['layout', 'setLayout', 'getIndexedParameter']);\n    this.target = props.target || (this.gl.webgl2 ? 36662 : 34962);\n    this.initialize(props);\n    Object.seal(this);\n  }\n\n  getElementCount() {\n    let accessor = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : this.accessor;\n    return Math.round(this.byteLength / _accessor__WEBPACK_IMPORTED_MODULE_2__[\"default\"].getBytesPerElement(accessor));\n  }\n\n  getVertexCount() {\n    let accessor = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : this.accessor;\n    return Math.round(this.byteLength / _accessor__WEBPACK_IMPORTED_MODULE_2__[\"default\"].getBytesPerVertex(accessor));\n  }\n\n  initialize() {\n    let props = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n\n    if (ArrayBuffer.isView(props)) {\n      props = {\n        data: props\n      };\n    }\n\n    if (Number.isFinite(props)) {\n      props = {\n        byteLength: props\n      };\n    }\n\n    props = (0,_utils_check_props__WEBPACK_IMPORTED_MODULE_3__.checkProps)('Buffer', props, PROP_CHECKS_INITIALIZE);\n    this.usage = props.usage || 35044;\n    this.debugData = null;\n    this.setAccessor(Object.assign({}, props, props.accessor));\n\n    if (props.data) {\n      this._setData(props.data, props.offset, props.byteLength);\n    } else {\n      this._setByteLength(props.byteLength || 0);\n    }\n\n    return this;\n  }\n\n  setProps(props) {\n    props = (0,_utils_check_props__WEBPACK_IMPORTED_MODULE_3__.checkProps)('Buffer', props, PROP_CHECKS_SET_PROPS);\n\n    if ('accessor' in props) {\n      this.setAccessor(props.accessor);\n    }\n\n    return this;\n  }\n\n  setAccessor(accessor) {\n    accessor = Object.assign({}, accessor);\n    delete accessor.buffer;\n    this.accessor = new _accessor__WEBPACK_IMPORTED_MODULE_2__[\"default\"](accessor);\n    return this;\n  }\n\n  reallocate(byteLength) {\n    if (byteLength > this.byteLength) {\n      this._setByteLength(byteLength);\n\n      return true;\n    }\n\n    this.bytesUsed = byteLength;\n    return false;\n  }\n\n  setData(props) {\n    return this.initialize(props);\n  }\n\n  subData(props) {\n    if (ArrayBuffer.isView(props)) {\n      props = {\n        data: props\n      };\n    }\n\n    const {\n      data,\n      offset = 0,\n      srcOffset = 0\n    } = props;\n    const byteLength = props.byteLength || props.length;\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_4__.assert)(data);\n    const target = this.gl.webgl2 ? 36663 : this.target;\n    this.gl.bindBuffer(target, this.handle);\n\n    if (srcOffset !== 0 || byteLength !== undefined) {\n      (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.assertWebGL2Context)(this.gl);\n      this.gl.bufferSubData(this.target, offset, data, srcOffset, byteLength);\n    } else {\n      this.gl.bufferSubData(target, offset, data);\n    }\n\n    this.gl.bindBuffer(target, null);\n    this.debugData = null;\n\n    this._inferType(data);\n\n    return this;\n  }\n\n  copyData(_ref) {\n    let {\n      sourceBuffer,\n      readOffset = 0,\n      writeOffset = 0,\n      size\n    } = _ref;\n    const {\n      gl\n    } = this;\n    (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.assertWebGL2Context)(gl);\n    gl.bindBuffer(36662, sourceBuffer.handle);\n    gl.bindBuffer(36663, this.handle);\n    gl.copyBufferSubData(36662, 36663, readOffset, writeOffset, size);\n    gl.bindBuffer(36662, null);\n    gl.bindBuffer(36663, null);\n    this.debugData = null;\n    return this;\n  }\n\n  getData() {\n    let {\n      dstData = null,\n      srcByteOffset = 0,\n      dstOffset = 0,\n      length = 0\n    } = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.assertWebGL2Context)(this.gl);\n    const ArrayType = (0,_webgl_utils_typed_array_utils__WEBPACK_IMPORTED_MODULE_5__.getTypedArrayFromGLType)(this.accessor.type || 5126, {\n      clamped: false\n    });\n\n    const sourceAvailableElementCount = this._getAvailableElementCount(srcByteOffset);\n\n    const dstElementOffset = dstOffset;\n    let dstAvailableElementCount;\n    let dstElementCount;\n\n    if (dstData) {\n      dstElementCount = dstData.length;\n      dstAvailableElementCount = dstElementCount - dstElementOffset;\n    } else {\n      dstAvailableElementCount = Math.min(sourceAvailableElementCount, length || sourceAvailableElementCount);\n      dstElementCount = dstElementOffset + dstAvailableElementCount;\n    }\n\n    const copyElementCount = Math.min(sourceAvailableElementCount, dstAvailableElementCount);\n    length = length || copyElementCount;\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_4__.assert)(length <= copyElementCount);\n    dstData = dstData || new ArrayType(dstElementCount);\n    this.gl.bindBuffer(36662, this.handle);\n    this.gl.getBufferSubData(36662, srcByteOffset, dstData, dstOffset, length);\n    this.gl.bindBuffer(36662, null);\n    return dstData;\n  }\n\n  bind() {\n    let {\n      target = this.target,\n      index = this.accessor && this.accessor.index,\n      offset = 0,\n      size\n    } = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n\n    if (target === 35345 || target === 35982) {\n      if (size !== undefined) {\n        this.gl.bindBufferRange(target, index, this.handle, offset, size);\n      } else {\n        (0,_utils_assert__WEBPACK_IMPORTED_MODULE_4__.assert)(offset === 0);\n        this.gl.bindBufferBase(target, index, this.handle);\n      }\n    } else {\n      this.gl.bindBuffer(target, this.handle);\n    }\n\n    return this;\n  }\n\n  unbind() {\n    let {\n      target = this.target,\n      index = this.accessor && this.accessor.index\n    } = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    const isIndexedBuffer = target === 35345 || target === 35982;\n\n    if (isIndexedBuffer) {\n      this.gl.bindBufferBase(target, index, null);\n    } else {\n      this.gl.bindBuffer(target, null);\n    }\n\n    return this;\n  }\n\n  getDebugData() {\n    if (!this.debugData) {\n      this.debugData = this.getData({\n        length: Math.min(DEBUG_DATA_LENGTH, this.byteLength)\n      });\n      return {\n        data: this.debugData,\n        changed: true\n      };\n    }\n\n    return {\n      data: this.debugData,\n      changed: false\n    };\n  }\n\n  invalidateDebugData() {\n    this.debugData = null;\n  }\n\n  _setData(data) {\n    let offset = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n    let byteLength = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : data.byteLength + offset;\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_4__.assert)(ArrayBuffer.isView(data));\n\n    this._trackDeallocatedMemory();\n\n    const target = this._getTarget();\n\n    this.gl.bindBuffer(target, this.handle);\n    this.gl.bufferData(target, byteLength, this.usage);\n    this.gl.bufferSubData(target, offset, data);\n    this.gl.bindBuffer(target, null);\n    this.debugData = data.slice(0, DEBUG_DATA_LENGTH);\n    this.bytesUsed = byteLength;\n\n    this._trackAllocatedMemory(byteLength);\n\n    const type = (0,_webgl_utils_typed_array_utils__WEBPACK_IMPORTED_MODULE_5__.getGLTypeFromTypedArray)(data);\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_4__.assert)(type);\n    this.setAccessor(new _accessor__WEBPACK_IMPORTED_MODULE_2__[\"default\"](this.accessor, {\n      type\n    }));\n    return this;\n  }\n\n  _setByteLength(byteLength) {\n    let usage = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : this.usage;\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_4__.assert)(byteLength >= 0);\n\n    this._trackDeallocatedMemory();\n\n    let data = byteLength;\n\n    if (byteLength === 0) {\n      data = new Float32Array(0);\n    }\n\n    const target = this._getTarget();\n\n    this.gl.bindBuffer(target, this.handle);\n    this.gl.bufferData(target, data, usage);\n    this.gl.bindBuffer(target, null);\n    this.usage = usage;\n    this.debugData = null;\n    this.bytesUsed = byteLength;\n\n    this._trackAllocatedMemory(byteLength);\n\n    return this;\n  }\n\n  _getTarget() {\n    return this.gl.webgl2 ? 36663 : this.target;\n  }\n\n  _getAvailableElementCount(srcByteOffset) {\n    const ArrayType = (0,_webgl_utils_typed_array_utils__WEBPACK_IMPORTED_MODULE_5__.getTypedArrayFromGLType)(this.accessor.type || 5126, {\n      clamped: false\n    });\n    const sourceElementOffset = srcByteOffset / ArrayType.BYTES_PER_ELEMENT;\n    return this.getElementCount() - sourceElementOffset;\n  }\n\n  _inferType(data) {\n    if (!this.accessor.type) {\n      this.setAccessor(new _accessor__WEBPACK_IMPORTED_MODULE_2__[\"default\"](this.accessor, {\n        type: (0,_webgl_utils_typed_array_utils__WEBPACK_IMPORTED_MODULE_5__.getGLTypeFromTypedArray)(data)\n      }));\n    }\n  }\n\n  _createHandle() {\n    return this.gl.createBuffer();\n  }\n\n  _deleteHandle() {\n    this.gl.deleteBuffer(this.handle);\n\n    this._trackDeallocatedMemory();\n  }\n\n  _getParameter(pname) {\n    this.gl.bindBuffer(this.target, this.handle);\n    const value = this.gl.getBufferParameter(this.target, pname);\n    this.gl.bindBuffer(this.target, null);\n    return value;\n  }\n\n  get type() {\n    _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.deprecated('Buffer.type', 'Buffer.accessor.type')();\n    return this.accessor.type;\n  }\n\n  get bytes() {\n    _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.deprecated('Buffer.bytes', 'Buffer.byteLength')();\n    return this.byteLength;\n  }\n\n  setByteLength(byteLength) {\n    _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.deprecated('setByteLength', 'reallocate')();\n    return this.reallocate(byteLength);\n  }\n\n  updateAccessor(opts) {\n    _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.deprecated('updateAccessor(...)', 'setAccessor(new Accessor(buffer.accessor, ...)')();\n    this.accessor = new _accessor__WEBPACK_IMPORTED_MODULE_2__[\"default\"](this.accessor, opts);\n    return this;\n  }\n\n}\n//# sourceMappingURL=buffer.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/classes/buffer.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/classes/clear.js":
/*!***************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/classes/clear.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   clear: () => (/* binding */ clear),\n/* harmony export */   clearBuffer: () => (/* binding */ clearBuffer)\n/* harmony export */ });\n/* harmony import */ var _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/gltools */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/assert */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js\");\n\n\nconst GL_DEPTH_BUFFER_BIT = 0x00000100;\nconst GL_STENCIL_BUFFER_BIT = 0x00000400;\nconst GL_COLOR_BUFFER_BIT = 0x00004000;\nconst GL_COLOR = 0x1800;\nconst GL_DEPTH = 0x1801;\nconst GL_STENCIL = 0x1802;\nconst GL_DEPTH_STENCIL = 0x84f9;\nconst ERR_ARGUMENTS = 'clear: bad arguments';\nfunction clear(gl) {\n  let {\n    framebuffer = null,\n    color = null,\n    depth = null,\n    stencil = null\n  } = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  const parameters = {};\n\n  if (framebuffer) {\n    parameters.framebuffer = framebuffer;\n  }\n\n  let clearFlags = 0;\n\n  if (color) {\n    clearFlags |= GL_COLOR_BUFFER_BIT;\n\n    if (color !== true) {\n      parameters.clearColor = color;\n    }\n  }\n\n  if (depth) {\n    clearFlags |= GL_DEPTH_BUFFER_BIT;\n\n    if (depth !== true) {\n      parameters.clearDepth = depth;\n    }\n  }\n\n  if (stencil) {\n    clearFlags |= GL_STENCIL_BUFFER_BIT;\n\n    if (depth !== true) {\n      parameters.clearStencil = depth;\n    }\n  }\n\n  (0,_utils_assert__WEBPACK_IMPORTED_MODULE_1__.assert)(clearFlags !== 0, ERR_ARGUMENTS);\n  (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.withParameters)(gl, parameters, () => {\n    gl.clear(clearFlags);\n  });\n}\nfunction clearBuffer(gl) {\n  let {\n    framebuffer = null,\n    buffer = GL_COLOR,\n    drawBuffer = 0,\n    value = [0, 0, 0, 0]\n  } = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.assertWebGL2Context)(gl);\n  (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.withParameters)(gl, {\n    framebuffer\n  }, () => {\n    switch (buffer) {\n      case GL_COLOR:\n        switch (value.constructor) {\n          case Int32Array:\n            gl.clearBufferiv(buffer, drawBuffer, value);\n            break;\n\n          case Uint32Array:\n            gl.clearBufferuiv(buffer, drawBuffer, value);\n            break;\n\n          case Float32Array:\n          default:\n            gl.clearBufferfv(buffer, drawBuffer, value);\n        }\n\n        break;\n\n      case GL_DEPTH:\n        gl.clearBufferfv(GL_DEPTH, 0, [value]);\n        break;\n\n      case GL_STENCIL:\n        gl.clearBufferiv(GL_STENCIL, 0, [value]);\n        break;\n\n      case GL_DEPTH_STENCIL:\n        const [depth, stencil] = value;\n        gl.clearBufferfi(GL_DEPTH_STENCIL, 0, depth, stencil);\n        break;\n\n      default:\n        (0,_utils_assert__WEBPACK_IMPORTED_MODULE_1__.assert)(false, ERR_ARGUMENTS);\n    }\n  });\n}\n//# sourceMappingURL=clear.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/classes/clear.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/classes/copy-and-blit.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/classes/copy-and-blit.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   blit: () => (/* binding */ blit),\n/* harmony export */   copyToDataUrl: () => (/* binding */ copyToDataUrl),\n/* harmony export */   copyToImage: () => (/* binding */ copyToImage),\n/* harmony export */   copyToTexture: () => (/* binding */ copyToTexture),\n/* harmony export */   readPixelsToArray: () => (/* binding */ readPixelsToArray),\n/* harmony export */   readPixelsToBuffer: () => (/* binding */ readPixelsToBuffer)\n/* harmony export */ });\n/* harmony import */ var _buffer__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./buffer */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/buffer.js\");\n/* harmony import */ var _framebuffer__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./framebuffer */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/framebuffer.js\");\n/* harmony import */ var _texture__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./texture */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/texture.js\");\n/* harmony import */ var _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/gltools */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n/* harmony import */ var _webgl_utils_typed_array_utils__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../webgl-utils/typed-array-utils */ \"./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/typed-array-utils.js\");\n/* harmony import */ var _webgl_utils_format_utils__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../webgl-utils/format-utils */ \"./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/format-utils.js\");\n/* harmony import */ var _webgl_utils_texture_utils__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../webgl-utils/texture-utils */ \"./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/texture-utils.js\");\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/assert */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js\");\n\n\n\n\n\n\n\n\n\nfunction readPixelsToArray(source) {\n  let options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  const {\n    sourceX = 0,\n    sourceY = 0,\n    sourceFormat = 6408\n  } = options;\n  let {\n    sourceAttachment = 36064,\n    target = null,\n    sourceWidth,\n    sourceHeight,\n    sourceType\n  } = options;\n  const {\n    framebuffer,\n    deleteFramebuffer\n  } = getFramebuffer(source);\n  (0,_utils_assert__WEBPACK_IMPORTED_MODULE_1__.assert)(framebuffer);\n  const {\n    gl,\n    handle,\n    attachments\n  } = framebuffer;\n  sourceWidth = sourceWidth || framebuffer.width;\n  sourceHeight = sourceHeight || framebuffer.height;\n\n  if (sourceAttachment === 36064 && handle === null) {\n    sourceAttachment = 1028;\n  }\n\n  (0,_utils_assert__WEBPACK_IMPORTED_MODULE_1__.assert)(attachments[sourceAttachment]);\n  sourceType = sourceType || attachments[sourceAttachment].type;\n  target = getPixelArray(target, sourceType, sourceFormat, sourceWidth, sourceHeight);\n  sourceType = sourceType || (0,_webgl_utils_typed_array_utils__WEBPACK_IMPORTED_MODULE_2__.getGLTypeFromTypedArray)(target);\n  const prevHandle = gl.bindFramebuffer(36160, handle);\n  gl.readPixels(sourceX, sourceY, sourceWidth, sourceHeight, sourceFormat, sourceType, target);\n  gl.bindFramebuffer(36160, prevHandle || null);\n\n  if (deleteFramebuffer) {\n    framebuffer.delete();\n  }\n\n  return target;\n}\nfunction readPixelsToBuffer(source, _ref) {\n  let {\n    sourceX = 0,\n    sourceY = 0,\n    sourceFormat = 6408,\n    target = null,\n    targetByteOffset = 0,\n    sourceWidth,\n    sourceHeight,\n    sourceType\n  } = _ref;\n  const {\n    framebuffer,\n    deleteFramebuffer\n  } = getFramebuffer(source);\n  (0,_utils_assert__WEBPACK_IMPORTED_MODULE_1__.assert)(framebuffer);\n  sourceWidth = sourceWidth || framebuffer.width;\n  sourceHeight = sourceHeight || framebuffer.height;\n  const gl2 = (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.assertWebGL2Context)(framebuffer.gl);\n  sourceType = sourceType || (target ? target.type : 5121);\n\n  if (!target) {\n    const components = (0,_webgl_utils_format_utils__WEBPACK_IMPORTED_MODULE_3__.glFormatToComponents)(sourceFormat);\n    const byteCount = (0,_webgl_utils_format_utils__WEBPACK_IMPORTED_MODULE_3__.glTypeToBytes)(sourceType);\n    const byteLength = targetByteOffset + sourceWidth * sourceHeight * components * byteCount;\n    target = new _buffer__WEBPACK_IMPORTED_MODULE_4__[\"default\"](gl2, {\n      byteLength,\n      accessor: {\n        type: sourceType,\n        size: components\n      }\n    });\n  }\n\n  target.bind({\n    target: 35051\n  });\n  (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.withParameters)(gl2, {\n    framebuffer\n  }, () => {\n    gl2.readPixels(sourceX, sourceY, sourceWidth, sourceHeight, sourceFormat, sourceType, targetByteOffset);\n  });\n  target.unbind({\n    target: 35051\n  });\n\n  if (deleteFramebuffer) {\n    framebuffer.delete();\n  }\n\n  return target;\n}\nfunction copyToDataUrl(source) {\n  let {\n    sourceAttachment = 36064,\n    targetMaxHeight = Number.MAX_SAFE_INTEGER\n  } = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  let data = readPixelsToArray(source, {\n    sourceAttachment\n  });\n  let {\n    width,\n    height\n  } = source;\n\n  while (height > targetMaxHeight) {\n    ({\n      data,\n      width,\n      height\n    } = (0,_webgl_utils_typed_array_utils__WEBPACK_IMPORTED_MODULE_2__.scalePixels)({\n      data,\n      width,\n      height\n    }));\n  }\n\n  (0,_webgl_utils_typed_array_utils__WEBPACK_IMPORTED_MODULE_2__.flipRows)({\n    data,\n    width,\n    height\n  });\n  const canvas = document.createElement('canvas');\n  canvas.width = width;\n  canvas.height = height;\n  const context = canvas.getContext('2d');\n  const imageData = context.createImageData(width, height);\n  imageData.data.set(data);\n  context.putImageData(imageData, 0, 0);\n  return canvas.toDataURL();\n}\nfunction copyToImage(source) {\n  let {\n    sourceAttachment = 36064,\n    targetImage = null\n  } = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  const dataUrl = copyToDataUrl(source, {\n    sourceAttachment\n  });\n  targetImage = targetImage || new Image();\n  targetImage.src = dataUrl;\n  return targetImage;\n}\nfunction copyToTexture(source, target) {\n  let options = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n  const {\n    sourceX = 0,\n    sourceY = 0,\n    targetMipmaplevel = 0,\n    targetInternalFormat = 6408\n  } = options;\n  let {\n    targetX,\n    targetY,\n    targetZ,\n    width,\n    height\n  } = options;\n  const {\n    framebuffer,\n    deleteFramebuffer\n  } = getFramebuffer(source);\n  (0,_utils_assert__WEBPACK_IMPORTED_MODULE_1__.assert)(framebuffer);\n  const {\n    gl,\n    handle\n  } = framebuffer;\n  const isSubCopy = typeof targetX !== 'undefined' || typeof targetY !== 'undefined' || typeof targetZ !== 'undefined';\n  targetX = targetX || 0;\n  targetY = targetY || 0;\n  targetZ = targetZ || 0;\n  const prevHandle = gl.bindFramebuffer(36160, handle);\n  (0,_utils_assert__WEBPACK_IMPORTED_MODULE_1__.assert)(target);\n  let texture = null;\n\n  if (target instanceof _texture__WEBPACK_IMPORTED_MODULE_5__[\"default\"]) {\n    texture = target;\n    width = Number.isFinite(width) ? width : texture.width;\n    height = Number.isFinite(height) ? height : texture.height;\n    texture.bind(0);\n    target = texture.target;\n  }\n\n  if (!isSubCopy) {\n    gl.copyTexImage2D(target, targetMipmaplevel, targetInternalFormat, sourceX, sourceY, width, height, 0);\n  } else {\n    switch (target) {\n      case 3553:\n      case 34067:\n        gl.copyTexSubImage2D(target, targetMipmaplevel, targetX, targetY, sourceX, sourceY, width, height);\n        break;\n\n      case 35866:\n      case 32879:\n        const gl2 = (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.assertWebGL2Context)(gl);\n        gl2.copyTexSubImage3D(target, targetMipmaplevel, targetX, targetY, targetZ, sourceX, sourceY, width, height);\n        break;\n\n      default:\n    }\n  }\n\n  if (texture) {\n    texture.unbind();\n  }\n\n  gl.bindFramebuffer(36160, prevHandle || null);\n\n  if (deleteFramebuffer) {\n    framebuffer.delete();\n  }\n\n  return texture;\n}\nfunction blit(source, target) {\n  let options = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n  const {\n    sourceX0 = 0,\n    sourceY0 = 0,\n    targetX0 = 0,\n    targetY0 = 0,\n    color = true,\n    depth = false,\n    stencil = false,\n    filter = 9728\n  } = options;\n  let {\n    sourceX1,\n    sourceY1,\n    targetX1,\n    targetY1,\n    sourceAttachment = 36064,\n    mask = 0\n  } = options;\n  const {\n    framebuffer: srcFramebuffer,\n    deleteFramebuffer: deleteSrcFramebuffer\n  } = getFramebuffer(source);\n  const {\n    framebuffer: dstFramebuffer,\n    deleteFramebuffer: deleteDstFramebuffer\n  } = getFramebuffer(target);\n  (0,_utils_assert__WEBPACK_IMPORTED_MODULE_1__.assert)(srcFramebuffer);\n  (0,_utils_assert__WEBPACK_IMPORTED_MODULE_1__.assert)(dstFramebuffer);\n  const {\n    gl,\n    handle,\n    width,\n    height,\n    readBuffer\n  } = dstFramebuffer;\n  const gl2 = (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.assertWebGL2Context)(gl);\n\n  if (!srcFramebuffer.handle && sourceAttachment === 36064) {\n    sourceAttachment = 1028;\n  }\n\n  if (color) {\n    mask |= 16384;\n  }\n\n  if (depth) {\n    mask |= 256;\n  }\n\n  if (stencil) {\n    mask |= 1024;\n  }\n\n  if (deleteSrcFramebuffer || deleteDstFramebuffer) {\n    if (mask & (256 | 1024)) {\n      mask = 16384;\n      _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.warn('Blitting from or into a Texture object, forcing mask to GL.COLOR_BUFFER_BIT')();\n    }\n  }\n\n  (0,_utils_assert__WEBPACK_IMPORTED_MODULE_1__.assert)(mask);\n  sourceX1 = sourceX1 === undefined ? srcFramebuffer.width : sourceX1;\n  sourceY1 = sourceY1 === undefined ? srcFramebuffer.height : sourceY1;\n  targetX1 = targetX1 === undefined ? width : targetX1;\n  targetY1 = targetY1 === undefined ? height : targetY1;\n  const prevDrawHandle = gl.bindFramebuffer(36009, handle);\n  const prevReadHandle = gl.bindFramebuffer(36008, srcFramebuffer.handle);\n  gl2.readBuffer(sourceAttachment);\n  gl2.blitFramebuffer(sourceX0, sourceY0, sourceX1, sourceY1, targetX0, targetY0, targetX1, targetY1, mask, filter);\n  gl2.readBuffer(readBuffer);\n  gl2.bindFramebuffer(36008, prevReadHandle || null);\n  gl2.bindFramebuffer(36009, prevDrawHandle || null);\n\n  if (deleteSrcFramebuffer) {\n    srcFramebuffer.delete();\n  }\n\n  if (deleteDstFramebuffer) {\n    dstFramebuffer.delete();\n  }\n\n  return dstFramebuffer;\n}\n\nfunction getFramebuffer(source) {\n  if (!(source instanceof _framebuffer__WEBPACK_IMPORTED_MODULE_6__[\"default\"])) {\n    return {\n      framebuffer: (0,_webgl_utils_texture_utils__WEBPACK_IMPORTED_MODULE_7__.toFramebuffer)(source),\n      deleteFramebuffer: true\n    };\n  }\n\n  return {\n    framebuffer: source,\n    deleteFramebuffer: false\n  };\n}\n\nfunction getPixelArray(pixelArray, type, format, width, height) {\n  if (pixelArray) {\n    return pixelArray;\n  }\n\n  type = type || 5121;\n  const ArrayType = (0,_webgl_utils_typed_array_utils__WEBPACK_IMPORTED_MODULE_2__.getTypedArrayFromGLType)(type, {\n    clamped: false\n  });\n  const components = (0,_webgl_utils_format_utils__WEBPACK_IMPORTED_MODULE_3__.glFormatToComponents)(format);\n  return new ArrayType(width * height * components);\n}\n//# sourceMappingURL=copy-and-blit.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/classes/copy-and-blit.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/classes/framebuffer.js":
/*!*********************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/classes/framebuffer.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   FRAMEBUFFER_ATTACHMENT_PARAMETERS: () => (/* binding */ FRAMEBUFFER_ATTACHMENT_PARAMETERS),\n/* harmony export */   \"default\": () => (/* binding */ Framebuffer)\n/* harmony export */ });\n/* harmony import */ var _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/gltools */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n/* harmony import */ var _resource__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./resource */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/resource.js\");\n/* harmony import */ var _texture_2d__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./texture-2d */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/texture-2d.js\");\n/* harmony import */ var _renderbuffer__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./renderbuffer */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/renderbuffer.js\");\n/* harmony import */ var _clear__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./clear */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/clear.js\");\n/* harmony import */ var _copy_and_blit_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./copy-and-blit.js */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/copy-and-blit.js\");\n/* harmony import */ var _features__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../features */ \"./node_modules/@luma.gl/webgl/dist/esm/features/features.js\");\n/* harmony import */ var _webgl_utils_constants_to_keys__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../webgl-utils/constants-to-keys */ \"./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/constants-to-keys.js\");\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/assert */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js\");\n\n\n\n\n\n\n\n\n\nconst ERR_MULTIPLE_RENDERTARGETS = 'Multiple render targets not supported';\nclass Framebuffer extends _resource__WEBPACK_IMPORTED_MODULE_1__[\"default\"] {\n  get [Symbol.toStringTag]() {\n    return 'Framebuffer';\n  }\n\n  static isSupported(gl) {\n    let options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    const {\n      colorBufferFloat,\n      colorBufferHalfFloat\n    } = options;\n    let supported = true;\n\n    if (colorBufferFloat) {\n      supported = Boolean(gl.getExtension('EXT_color_buffer_float') || gl.getExtension('WEBGL_color_buffer_float') || gl.getExtension('OES_texture_float'));\n    }\n\n    if (colorBufferHalfFloat) {\n      supported = supported && Boolean(gl.getExtension('EXT_color_buffer_float') || gl.getExtension('EXT_color_buffer_half_float'));\n    }\n\n    return supported;\n  }\n\n  static getDefaultFramebuffer(gl) {\n    gl.luma = gl.luma || {};\n    gl.luma.defaultFramebuffer = gl.luma.defaultFramebuffer || new Framebuffer(gl, {\n      id: 'default-framebuffer',\n      handle: null,\n      attachments: {}\n    });\n    return gl.luma.defaultFramebuffer;\n  }\n\n  get MAX_COLOR_ATTACHMENTS() {\n    const gl2 = (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.assertWebGL2Context)(this.gl);\n    return gl2.getParameter(gl2.MAX_COLOR_ATTACHMENTS);\n  }\n\n  get MAX_DRAW_BUFFERS() {\n    const gl2 = (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.assertWebGL2Context)(this.gl);\n    return gl2.getParameter(gl2.MAX_DRAW_BUFFERS);\n  }\n\n  constructor(gl) {\n    let opts = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    super(gl, opts);\n    this.width = null;\n    this.height = null;\n    this.attachments = {};\n    this.readBuffer = 36064;\n    this.drawBuffers = [36064];\n    this.ownResources = [];\n    this.initialize(opts);\n    Object.seal(this);\n  }\n\n  get color() {\n    return this.attachments[36064] || null;\n  }\n\n  get texture() {\n    return this.attachments[36064] || null;\n  }\n\n  get depth() {\n    return this.attachments[36096] || this.attachments[33306] || null;\n  }\n\n  get stencil() {\n    return this.attachments[36128] || this.attachments[33306] || null;\n  }\n\n  initialize(_ref) {\n    let {\n      width = 1,\n      height = 1,\n      attachments = null,\n      color = true,\n      depth = true,\n      stencil = false,\n      check = true,\n      readBuffer = undefined,\n      drawBuffers = undefined\n    } = _ref;\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_2__.assert)(width >= 0 && height >= 0, 'Width and height need to be integers');\n    this.width = width;\n    this.height = height;\n\n    if (attachments) {\n      for (const attachment in attachments) {\n        const target = attachments[attachment];\n        const object = Array.isArray(target) ? target[0] : target;\n        object.resize({\n          width,\n          height\n        });\n      }\n    } else {\n      attachments = this._createDefaultAttachments(color, depth, stencil, width, height);\n    }\n\n    this.update({\n      clearAttachments: true,\n      attachments,\n      readBuffer,\n      drawBuffers\n    });\n\n    if (attachments && check) {\n      this.checkStatus();\n    }\n  }\n\n  delete() {\n    for (const resource of this.ownResources) {\n      resource.delete();\n    }\n\n    super.delete();\n    return this;\n  }\n\n  update(_ref2) {\n    let {\n      attachments = {},\n      readBuffer,\n      drawBuffers,\n      clearAttachments = false,\n      resizeAttachments = true\n    } = _ref2;\n    this.attach(attachments, {\n      clearAttachments,\n      resizeAttachments\n    });\n    const {\n      gl\n    } = this;\n    const prevHandle = gl.bindFramebuffer(36160, this.handle);\n\n    if (readBuffer) {\n      this._setReadBuffer(readBuffer);\n    }\n\n    if (drawBuffers) {\n      this._setDrawBuffers(drawBuffers);\n    }\n\n    gl.bindFramebuffer(36160, prevHandle || null);\n    return this;\n  }\n\n  resize() {\n    let options = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    let {\n      width,\n      height\n    } = options;\n\n    if (this.handle === null) {\n      (0,_utils_assert__WEBPACK_IMPORTED_MODULE_2__.assert)(width === undefined && height === undefined);\n      this.width = this.gl.drawingBufferWidth;\n      this.height = this.gl.drawingBufferHeight;\n      return this;\n    }\n\n    if (width === undefined) {\n      width = this.gl.drawingBufferWidth;\n    }\n\n    if (height === undefined) {\n      height = this.gl.drawingBufferHeight;\n    }\n\n    if (width !== this.width && height !== this.height) {\n      _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.log(2, \"Resizing framebuffer \".concat(this.id, \" to \").concat(width, \"x\").concat(height))();\n    }\n\n    for (const attachmentPoint in this.attachments) {\n      this.attachments[attachmentPoint].resize({\n        width,\n        height\n      });\n    }\n\n    this.width = width;\n    this.height = height;\n    return this;\n  }\n\n  attach(attachments) {\n    let {\n      clearAttachments = false,\n      resizeAttachments = true\n    } = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    const newAttachments = {};\n\n    if (clearAttachments) {\n      Object.keys(this.attachments).forEach(key => {\n        newAttachments[key] = null;\n      });\n    }\n\n    Object.assign(newAttachments, attachments);\n    const prevHandle = this.gl.bindFramebuffer(36160, this.handle);\n\n    for (const key in newAttachments) {\n      (0,_utils_assert__WEBPACK_IMPORTED_MODULE_2__.assert)(key !== undefined, 'Misspelled framebuffer binding point?');\n      const attachment = Number(key);\n      const descriptor = newAttachments[attachment];\n      let object = descriptor;\n\n      if (!object) {\n        this._unattach(attachment);\n      } else if (object instanceof _renderbuffer__WEBPACK_IMPORTED_MODULE_3__[\"default\"]) {\n        this._attachRenderbuffer({\n          attachment,\n          renderbuffer: object\n        });\n      } else if (Array.isArray(descriptor)) {\n        const [texture, layer = 0, level = 0] = descriptor;\n        object = texture;\n\n        this._attachTexture({\n          attachment,\n          texture,\n          layer,\n          level\n        });\n      } else {\n        this._attachTexture({\n          attachment,\n          texture: object,\n          layer: 0,\n          level: 0\n        });\n      }\n\n      if (resizeAttachments && object) {\n        object.resize({\n          width: this.width,\n          height: this.height\n        });\n      }\n    }\n\n    this.gl.bindFramebuffer(36160, prevHandle || null);\n    Object.assign(this.attachments, attachments);\n    Object.keys(this.attachments).filter(key => !this.attachments[key]).forEach(key => {\n      delete this.attachments[key];\n    });\n  }\n\n  checkStatus() {\n    const {\n      gl\n    } = this;\n    const status = this.getStatus();\n\n    if (status !== 36053) {\n      throw new Error(_getFrameBufferStatus(status));\n    }\n\n    return this;\n  }\n\n  getStatus() {\n    const {\n      gl\n    } = this;\n    const prevHandle = gl.bindFramebuffer(36160, this.handle);\n    const status = gl.checkFramebufferStatus(36160);\n    gl.bindFramebuffer(36160, prevHandle || null);\n    return status;\n  }\n\n  clear() {\n    let options = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    const {\n      color,\n      depth,\n      stencil,\n      drawBuffers = []\n    } = options;\n    const prevHandle = this.gl.bindFramebuffer(36160, this.handle);\n\n    if (color || depth || stencil) {\n      (0,_clear__WEBPACK_IMPORTED_MODULE_4__.clear)(this.gl, {\n        color,\n        depth,\n        stencil\n      });\n    }\n\n    drawBuffers.forEach((value, drawBuffer) => {\n      (0,_clear__WEBPACK_IMPORTED_MODULE_4__.clearBuffer)(this.gl, {\n        drawBuffer,\n        value\n      });\n    });\n    this.gl.bindFramebuffer(36160, prevHandle || null);\n    return this;\n  }\n\n  readPixels() {\n    let opts = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.error('Framebuffer.readPixels() is no logner supported, use readPixelsToArray(framebuffer)')();\n    return null;\n  }\n\n  readPixelsToBuffer() {\n    let opts = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.error('Framebuffer.readPixelsToBuffer()is no logner supported, use readPixelsToBuffer(framebuffer)')();\n    return null;\n  }\n\n  copyToDataUrl() {\n    let opts = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.error('Framebuffer.copyToDataUrl() is no logner supported, use copyToDataUrl(framebuffer)')();\n    return null;\n  }\n\n  copyToImage() {\n    let opts = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.error('Framebuffer.copyToImage() is no logner supported, use copyToImage(framebuffer)')();\n    return null;\n  }\n\n  copyToTexture() {\n    let opts = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.error('Framebuffer.copyToTexture({...}) is no logner supported, use copyToTexture(source, target, opts})')();\n    return null;\n  }\n\n  blit() {\n    let opts = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.error('Framebuffer.blit({...}) is no logner supported, use blit(source, target, opts)')();\n    return null;\n  }\n\n  invalidate(_ref3) {\n    let {\n      attachments = [],\n      x = 0,\n      y = 0,\n      width,\n      height\n    } = _ref3;\n    const gl2 = (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.assertWebGL2Context)(this.gl);\n    const prevHandle = gl2.bindFramebuffer(36008, this.handle);\n    const invalidateAll = x === 0 && y === 0 && width === undefined && height === undefined;\n\n    if (invalidateAll) {\n      gl2.invalidateFramebuffer(36008, attachments);\n    } else {\n      gl2.invalidateFramebuffer(36008, attachments, x, y, width, height);\n    }\n\n    gl2.bindFramebuffer(36008, prevHandle);\n    return this;\n  }\n\n  getAttachmentParameter(attachment, pname, keys) {\n    let value = this._getAttachmentParameterFallback(pname);\n\n    if (value === null) {\n      this.gl.bindFramebuffer(36160, this.handle);\n      value = this.gl.getFramebufferAttachmentParameter(36160, attachment, pname);\n      this.gl.bindFramebuffer(36160, null);\n    }\n\n    if (keys && value > 1000) {\n      value = (0,_webgl_utils_constants_to_keys__WEBPACK_IMPORTED_MODULE_5__.getKey)(this.gl, value);\n    }\n\n    return value;\n  }\n\n  getAttachmentParameters() {\n    let attachment = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 36064;\n    let keys = arguments.length > 1 ? arguments[1] : undefined;\n    let parameters = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : this.constructor.ATTACHMENT_PARAMETERS || [];\n    const values = {};\n\n    for (const pname of parameters) {\n      const key = keys ? (0,_webgl_utils_constants_to_keys__WEBPACK_IMPORTED_MODULE_5__.getKey)(this.gl, pname) : pname;\n      values[key] = this.getAttachmentParameter(attachment, pname, keys);\n    }\n\n    return values;\n  }\n\n  getParameters() {\n    let keys = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : true;\n    const attachments = Object.keys(this.attachments);\n    const parameters = {};\n\n    for (const attachmentName of attachments) {\n      const attachment = Number(attachmentName);\n      const key = keys ? (0,_webgl_utils_constants_to_keys__WEBPACK_IMPORTED_MODULE_5__.getKey)(this.gl, attachment) : attachment;\n      parameters[key] = this.getAttachmentParameters(attachment, keys);\n    }\n\n    return parameters;\n  }\n\n  show() {\n    if (typeof window !== 'undefined') {\n      window.open((0,_copy_and_blit_js__WEBPACK_IMPORTED_MODULE_6__.copyToDataUrl)(this), 'luma-debug-texture');\n    }\n\n    return this;\n  }\n\n  log() {\n    let logLevel = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;\n    let message = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : '';\n\n    if (logLevel > _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.level || typeof window === 'undefined') {\n      return this;\n    }\n\n    message = message || \"Framebuffer \".concat(this.id);\n    const image = (0,_copy_and_blit_js__WEBPACK_IMPORTED_MODULE_6__.copyToDataUrl)(this, {\n      targetMaxHeight: 100\n    });\n    _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.image({\n      logLevel,\n      message,\n      image\n    }, message)();\n    return this;\n  }\n\n  bind() {\n    let {\n      target = 36160\n    } = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    this.gl.bindFramebuffer(target, this.handle);\n    return this;\n  }\n\n  unbind() {\n    let {\n      target = 36160\n    } = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    this.gl.bindFramebuffer(target, null);\n    return this;\n  }\n\n  _createDefaultAttachments(color, depth, stencil, width, height) {\n    let defaultAttachments = null;\n\n    if (color) {\n      defaultAttachments = defaultAttachments || {};\n      defaultAttachments[36064] = new _texture_2d__WEBPACK_IMPORTED_MODULE_7__[\"default\"](this.gl, {\n        id: \"\".concat(this.id, \"-color0\"),\n        pixels: null,\n        format: 6408,\n        type: 5121,\n        width,\n        height,\n        mipmaps: false,\n        parameters: {\n          [10241]: 9729,\n          [10240]: 9729,\n          [10242]: 33071,\n          [10243]: 33071\n        }\n      });\n      this.ownResources.push(defaultAttachments[36064]);\n    }\n\n    if (depth && stencil) {\n      defaultAttachments = defaultAttachments || {};\n      defaultAttachments[33306] = new _renderbuffer__WEBPACK_IMPORTED_MODULE_3__[\"default\"](this.gl, {\n        id: \"\".concat(this.id, \"-depth-stencil\"),\n        format: 35056,\n        width,\n        height: 111\n      });\n      this.ownResources.push(defaultAttachments[33306]);\n    } else if (depth) {\n      defaultAttachments = defaultAttachments || {};\n      defaultAttachments[36096] = new _renderbuffer__WEBPACK_IMPORTED_MODULE_3__[\"default\"](this.gl, {\n        id: \"\".concat(this.id, \"-depth\"),\n        format: 33189,\n        width,\n        height\n      });\n      this.ownResources.push(defaultAttachments[36096]);\n    } else if (stencil) {\n      (0,_utils_assert__WEBPACK_IMPORTED_MODULE_2__.assert)(false);\n    }\n\n    return defaultAttachments;\n  }\n\n  _unattach(attachment) {\n    const oldAttachment = this.attachments[attachment];\n\n    if (!oldAttachment) {\n      return;\n    }\n\n    if (oldAttachment instanceof _renderbuffer__WEBPACK_IMPORTED_MODULE_3__[\"default\"]) {\n      this.gl.framebufferRenderbuffer(36160, attachment, 36161, null);\n    } else {\n      this.gl.framebufferTexture2D(36160, attachment, 3553, null, 0);\n    }\n\n    delete this.attachments[attachment];\n  }\n\n  _attachRenderbuffer(_ref4) {\n    let {\n      attachment = 36064,\n      renderbuffer\n    } = _ref4;\n    const {\n      gl\n    } = this;\n    gl.framebufferRenderbuffer(36160, attachment, 36161, renderbuffer.handle);\n    this.attachments[attachment] = renderbuffer;\n  }\n\n  _attachTexture(_ref5) {\n    let {\n      attachment = 36064,\n      texture,\n      layer,\n      level\n    } = _ref5;\n    const {\n      gl\n    } = this;\n    gl.bindTexture(texture.target, texture.handle);\n\n    switch (texture.target) {\n      case 35866:\n      case 32879:\n        const gl2 = (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.assertWebGL2Context)(gl);\n        gl2.framebufferTextureLayer(36160, attachment, texture.target, level, layer);\n        break;\n\n      case 34067:\n        const face = mapIndexToCubeMapFace(layer);\n        gl.framebufferTexture2D(36160, attachment, face, texture.handle, level);\n        break;\n\n      case 3553:\n        gl.framebufferTexture2D(36160, attachment, 3553, texture.handle, level);\n        break;\n\n      default:\n        (0,_utils_assert__WEBPACK_IMPORTED_MODULE_2__.assert)(false, 'Illegal texture type');\n    }\n\n    gl.bindTexture(texture.target, null);\n    this.attachments[attachment] = texture;\n  }\n\n  _setReadBuffer(readBuffer) {\n    const gl2 = (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.getWebGL2Context)(this.gl);\n\n    if (gl2) {\n      gl2.readBuffer(readBuffer);\n    } else {\n      (0,_utils_assert__WEBPACK_IMPORTED_MODULE_2__.assert)(readBuffer === 36064 || readBuffer === 1029, ERR_MULTIPLE_RENDERTARGETS);\n    }\n\n    this.readBuffer = readBuffer;\n  }\n\n  _setDrawBuffers(drawBuffers) {\n    const {\n      gl\n    } = this;\n    const gl2 = (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.assertWebGL2Context)(gl);\n\n    if (gl2) {\n      gl2.drawBuffers(drawBuffers);\n    } else {\n      const ext = gl.getExtension('WEBGL_draw_buffers');\n\n      if (ext) {\n        ext.drawBuffersWEBGL(drawBuffers);\n      } else {\n        (0,_utils_assert__WEBPACK_IMPORTED_MODULE_2__.assert)(drawBuffers.length === 1 && (drawBuffers[0] === 36064 || drawBuffers[0] === 1029), ERR_MULTIPLE_RENDERTARGETS);\n      }\n    }\n\n    this.drawBuffers = drawBuffers;\n  }\n\n  _getAttachmentParameterFallback(pname) {\n    const caps = (0,_features__WEBPACK_IMPORTED_MODULE_8__.getFeatures)(this.gl);\n\n    switch (pname) {\n      case 36052:\n        return !caps.WEBGL2 ? 0 : null;\n\n      case 33298:\n      case 33299:\n      case 33300:\n      case 33301:\n      case 33302:\n      case 33303:\n        return !caps.WEBGL2 ? 8 : null;\n\n      case 33297:\n        return !caps.WEBGL2 ? 5125 : null;\n\n      case 33296:\n        return !caps.WEBGL2 && !caps.EXT_sRGB ? 9729 : null;\n\n      default:\n        return null;\n    }\n  }\n\n  _createHandle() {\n    return this.gl.createFramebuffer();\n  }\n\n  _deleteHandle() {\n    this.gl.deleteFramebuffer(this.handle);\n  }\n\n  _bindHandle(handle) {\n    return this.gl.bindFramebuffer(36160, handle);\n  }\n\n}\n\nfunction mapIndexToCubeMapFace(layer) {\n  return layer < 34069 ? layer + 34069 : layer;\n}\n\nfunction _getFrameBufferStatus(status) {\n  const STATUS = Framebuffer.STATUS || {};\n  return STATUS[status] || \"Framebuffer error \".concat(status);\n}\n\nconst FRAMEBUFFER_ATTACHMENT_PARAMETERS = [36049, 36048, 33296, 33298, 33299, 33300, 33301, 33302, 33303];\nFramebuffer.ATTACHMENT_PARAMETERS = FRAMEBUFFER_ATTACHMENT_PARAMETERS;\n//# sourceMappingURL=framebuffer.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/classes/framebuffer.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/classes/program-configuration.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/classes/program-configuration.js ***!
  \*******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ ProgramConfiguration)\n/* harmony export */ });\n/* harmony import */ var _accessor__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./accessor */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/accessor.js\");\n/* harmony import */ var _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/gltools */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n/* harmony import */ var _webgl_utils_attribute_utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../webgl-utils/attribute-utils */ \"./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/attribute-utils.js\");\n\n\n\nclass ProgramConfiguration {\n  constructor(program) {\n    this.id = program.id;\n    this.attributeInfos = [];\n    this.attributeInfosByName = {};\n    this.attributeInfosByLocation = [];\n    this.varyingInfos = [];\n    this.varyingInfosByName = {};\n    Object.seal(this);\n\n    this._readAttributesFromProgram(program);\n\n    this._readVaryingsFromProgram(program);\n  }\n\n  getAttributeInfo(locationOrName) {\n    const location = Number(locationOrName);\n\n    if (Number.isFinite(location)) {\n      return this.attributeInfosByLocation[location];\n    }\n\n    return this.attributeInfosByName[locationOrName] || null;\n  }\n\n  getAttributeLocation(locationOrName) {\n    const attributeInfo = this.getAttributeInfo(locationOrName);\n    return attributeInfo ? attributeInfo.location : -1;\n  }\n\n  getAttributeAccessor(locationOrName) {\n    const attributeInfo = this.getAttributeInfo(locationOrName);\n    return attributeInfo ? attributeInfo.accessor : null;\n  }\n\n  getVaryingInfo(locationOrName) {\n    const location = Number(locationOrName);\n\n    if (Number.isFinite(location)) {\n      return this.varyingInfos[location];\n    }\n\n    return this.varyingInfosByName[locationOrName] || null;\n  }\n\n  getVaryingIndex(locationOrName) {\n    const varying = this.getVaryingInfo();\n    return varying ? varying.location : -1;\n  }\n\n  getVaryingAccessor(locationOrName) {\n    const varying = this.getVaryingInfo();\n    return varying ? varying.accessor : null;\n  }\n\n  _readAttributesFromProgram(program) {\n    const {\n      gl\n    } = program;\n    const count = gl.getProgramParameter(program.handle, 35721);\n\n    for (let index = 0; index < count; index++) {\n      const {\n        name,\n        type,\n        size\n      } = gl.getActiveAttrib(program.handle, index);\n      const location = gl.getAttribLocation(program.handle, name);\n\n      if (location >= 0) {\n        this._addAttribute(location, name, type, size);\n      }\n    }\n\n    this.attributeInfos.sort((a, b) => a.location - b.location);\n  }\n\n  _readVaryingsFromProgram(program) {\n    const {\n      gl\n    } = program;\n\n    if (!(0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.isWebGL2)(gl)) {\n      return;\n    }\n\n    const count = gl.getProgramParameter(program.handle, 35971);\n\n    for (let location = 0; location < count; location++) {\n      const {\n        name,\n        type,\n        size\n      } = gl.getTransformFeedbackVarying(program.handle, location);\n\n      this._addVarying(location, name, type, size);\n    }\n\n    this.varyingInfos.sort((a, b) => a.location - b.location);\n  }\n\n  _addAttribute(location, name, compositeType, size) {\n    const {\n      type,\n      components\n    } = (0,_webgl_utils_attribute_utils__WEBPACK_IMPORTED_MODULE_1__.decomposeCompositeGLType)(compositeType);\n    const accessor = {\n      type,\n      size: size * components\n    };\n\n    this._inferProperties(location, name, accessor);\n\n    const attributeInfo = {\n      location,\n      name,\n      accessor: new _accessor__WEBPACK_IMPORTED_MODULE_2__[\"default\"](accessor)\n    };\n    this.attributeInfos.push(attributeInfo);\n    this.attributeInfosByLocation[location] = attributeInfo;\n    this.attributeInfosByName[attributeInfo.name] = attributeInfo;\n  }\n\n  _inferProperties(location, name, accessor) {\n    if (/instance/i.test(name)) {\n      accessor.divisor = 1;\n    }\n  }\n\n  _addVarying(location, name, compositeType, size) {\n    const {\n      type,\n      components\n    } = (0,_webgl_utils_attribute_utils__WEBPACK_IMPORTED_MODULE_1__.decomposeCompositeGLType)(compositeType);\n    const accessor = new _accessor__WEBPACK_IMPORTED_MODULE_2__[\"default\"]({\n      type,\n      size: size * components\n    });\n    const varying = {\n      location,\n      name,\n      accessor\n    };\n    this.varyingInfos.push(varying);\n    this.varyingInfosByName[varying.name] = varying;\n  }\n\n}\n//# sourceMappingURL=program-configuration.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/classes/program-configuration.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/classes/program.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/classes/program.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Program)\n/* harmony export */ });\n/* harmony import */ var _resource__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./resource */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/resource.js\");\n/* harmony import */ var _texture__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./texture */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/texture.js\");\n/* harmony import */ var _framebuffer__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./framebuffer */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/framebuffer.js\");\n/* harmony import */ var _uniforms__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./uniforms */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/uniforms.js\");\n/* harmony import */ var _shader__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./shader */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/shader.js\");\n/* harmony import */ var _program_configuration__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./program-configuration */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/program-configuration.js\");\n/* harmony import */ var _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/gltools */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n/* harmony import */ var _webgl_utils_constants_to_keys__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../webgl-utils/constants-to-keys */ \"./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/constants-to-keys.js\");\n/* harmony import */ var _webgl_utils_attribute_utils__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../webgl-utils/attribute-utils */ \"./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/attribute-utils.js\");\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/assert */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js\");\n/* harmony import */ var _utils_utils__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../utils/utils */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/utils.js\");\n\n\n\n\n\n\n\n\n\n\n\n\nconst LOG_PROGRAM_PERF_PRIORITY = 4;\nconst GL_SEPARATE_ATTRIBS = 0x8c8d;\nconst V6_DEPRECATED_METHODS = ['setVertexArray', 'setAttributes', 'setBuffers', 'unsetBuffers', 'use', 'getUniformCount', 'getUniformInfo', 'getUniformLocation', 'getUniformValue', 'getVarying', 'getFragDataLocation', 'getAttachedShaders', 'getAttributeCount', 'getAttributeLocation', 'getAttributeInfo'];\nclass Program extends _resource__WEBPACK_IMPORTED_MODULE_1__[\"default\"] {\n  get [Symbol.toStringTag]() {\n    return 'Program';\n  }\n\n  constructor(gl) {\n    let props = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    super(gl, props);\n    this.stubRemovedMethods('Program', 'v6.0', V6_DEPRECATED_METHODS);\n    this._isCached = false;\n    this.initialize(props);\n    Object.seal(this);\n\n    this._setId(props.id);\n  }\n\n  initialize() {\n    let props = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    const {\n      hash,\n      vs,\n      fs,\n      varyings,\n      bufferMode = GL_SEPARATE_ATTRIBS\n    } = props;\n    this.hash = hash || '';\n    this.vs = typeof vs === 'string' ? new _shader__WEBPACK_IMPORTED_MODULE_2__.VertexShader(this.gl, {\n      id: \"\".concat(props.id, \"-vs\"),\n      source: vs\n    }) : vs;\n    this.fs = typeof fs === 'string' ? new _shader__WEBPACK_IMPORTED_MODULE_2__.FragmentShader(this.gl, {\n      id: \"\".concat(props.id, \"-fs\"),\n      source: fs\n    }) : fs;\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_3__.assert)(this.vs instanceof _shader__WEBPACK_IMPORTED_MODULE_2__.VertexShader);\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_3__.assert)(this.fs instanceof _shader__WEBPACK_IMPORTED_MODULE_2__.FragmentShader);\n    this.uniforms = {};\n    this._textureUniforms = {};\n\n    if (varyings && varyings.length > 0) {\n      (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.assertWebGL2Context)(this.gl);\n      this.varyings = varyings;\n      this.gl2.transformFeedbackVaryings(this.handle, varyings, bufferMode);\n    }\n\n    this._compileAndLink();\n\n    this._readUniformLocationsFromLinkedProgram();\n\n    this.configuration = new _program_configuration__WEBPACK_IMPORTED_MODULE_4__[\"default\"](this);\n    return this.setProps(props);\n  }\n\n  delete() {\n    let options = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n\n    if (this._isCached) {\n      return this;\n    }\n\n    return super.delete(options);\n  }\n\n  setProps(props) {\n    if ('uniforms' in props) {\n      this.setUniforms(props.uniforms);\n    }\n\n    return this;\n  }\n\n  draw(_ref) {\n    let {\n      logPriority,\n      drawMode = 4,\n      vertexCount,\n      offset = 0,\n      start,\n      end,\n      isIndexed = false,\n      indexType = 5123,\n      instanceCount = 0,\n      isInstanced = instanceCount > 0,\n      vertexArray = null,\n      transformFeedback,\n      framebuffer,\n      parameters = {},\n      uniforms,\n      samplers\n    } = _ref;\n\n    if (uniforms || samplers) {\n      _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.deprecated('Program.draw({uniforms})', 'Program.setUniforms(uniforms)')();\n      this.setUniforms(uniforms || {});\n    }\n\n    if (_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.priority >= logPriority) {\n      const fb = framebuffer ? framebuffer.id : 'default';\n      const message = \"mode=\".concat((0,_webgl_utils_constants_to_keys__WEBPACK_IMPORTED_MODULE_5__.getKey)(this.gl, drawMode), \" verts=\").concat(vertexCount, \" \") + \"instances=\".concat(instanceCount, \" indexType=\").concat((0,_webgl_utils_constants_to_keys__WEBPACK_IMPORTED_MODULE_5__.getKey)(this.gl, indexType), \" \") + \"isInstanced=\".concat(isInstanced, \" isIndexed=\").concat(isIndexed, \" \") + \"Framebuffer=\".concat(fb);\n      _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.log(logPriority, message)();\n    }\n\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_3__.assert)(vertexArray);\n    this.gl.useProgram(this.handle);\n\n    if (!this._areTexturesRenderable() || vertexCount === 0 || isInstanced && instanceCount === 0) {\n      return false;\n    }\n\n    vertexArray.bindForDraw(vertexCount, instanceCount, () => {\n      if (framebuffer !== undefined) {\n        parameters = Object.assign({}, parameters, {\n          framebuffer\n        });\n      }\n\n      if (transformFeedback) {\n        const primitiveMode = (0,_webgl_utils_attribute_utils__WEBPACK_IMPORTED_MODULE_6__.getPrimitiveDrawMode)(drawMode);\n        transformFeedback.begin(primitiveMode);\n      }\n\n      this._bindTextures();\n\n      (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.withParameters)(this.gl, parameters, () => {\n        if (isIndexed && isInstanced) {\n          this.gl2.drawElementsInstanced(drawMode, vertexCount, indexType, offset, instanceCount);\n        } else if (isIndexed && (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.isWebGL2)(this.gl) && !isNaN(start) && !isNaN(end)) {\n          this.gl2.drawRangeElements(drawMode, start, end, vertexCount, indexType, offset);\n        } else if (isIndexed) {\n          this.gl.drawElements(drawMode, vertexCount, indexType, offset);\n        } else if (isInstanced) {\n          this.gl2.drawArraysInstanced(drawMode, offset, vertexCount, instanceCount);\n        } else {\n          this.gl.drawArrays(drawMode, offset, vertexCount);\n        }\n      });\n\n      if (transformFeedback) {\n        transformFeedback.end();\n      }\n    });\n    return true;\n  }\n\n  setUniforms() {\n    let uniforms = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n\n    if (_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.priority >= 2) {\n      (0,_uniforms__WEBPACK_IMPORTED_MODULE_7__.checkUniformValues)(uniforms, this.id, this._uniformSetters);\n    }\n\n    this.gl.useProgram(this.handle);\n\n    for (const uniformName in uniforms) {\n      const uniform = uniforms[uniformName];\n      const uniformSetter = this._uniformSetters[uniformName];\n\n      if (uniformSetter) {\n        let value = uniform;\n        let textureUpdate = false;\n\n        if (value instanceof _framebuffer__WEBPACK_IMPORTED_MODULE_8__[\"default\"]) {\n          value = value.texture;\n        }\n\n        if (value instanceof _texture__WEBPACK_IMPORTED_MODULE_9__[\"default\"]) {\n          textureUpdate = this.uniforms[uniformName] !== uniform;\n\n          if (textureUpdate) {\n            if (uniformSetter.textureIndex === undefined) {\n              uniformSetter.textureIndex = this._textureIndexCounter++;\n            }\n\n            const texture = value;\n            const {\n              textureIndex\n            } = uniformSetter;\n            texture.bind(textureIndex);\n            value = textureIndex;\n            this._textureUniforms[uniformName] = texture;\n          } else {\n            value = uniformSetter.textureIndex;\n          }\n        } else if (this._textureUniforms[uniformName]) {\n          delete this._textureUniforms[uniformName];\n        }\n\n        if (uniformSetter(value) || textureUpdate) {\n          (0,_uniforms__WEBPACK_IMPORTED_MODULE_7__.copyUniform)(this.uniforms, uniformName, uniform);\n        }\n      }\n    }\n\n    return this;\n  }\n\n  _areTexturesRenderable() {\n    let texturesRenderable = true;\n\n    for (const uniformName in this._textureUniforms) {\n      const texture = this._textureUniforms[uniformName];\n      texture.update();\n      texturesRenderable = texturesRenderable && texture.loaded;\n    }\n\n    return texturesRenderable;\n  }\n\n  _bindTextures() {\n    for (const uniformName in this._textureUniforms) {\n      const textureIndex = this._uniformSetters[uniformName].textureIndex;\n\n      this._textureUniforms[uniformName].bind(textureIndex);\n    }\n  }\n\n  _createHandle() {\n    return this.gl.createProgram();\n  }\n\n  _deleteHandle() {\n    this.gl.deleteProgram(this.handle);\n  }\n\n  _getOptionsFromHandle(handle) {\n    const shaderHandles = this.gl.getAttachedShaders(handle);\n    const opts = {};\n\n    for (const shaderHandle of shaderHandles) {\n      const type = this.gl.getShaderParameter(this.handle, 35663);\n\n      switch (type) {\n        case 35633:\n          opts.vs = new _shader__WEBPACK_IMPORTED_MODULE_2__.VertexShader({\n            handle: shaderHandle\n          });\n          break;\n\n        case 35632:\n          opts.fs = new _shader__WEBPACK_IMPORTED_MODULE_2__.FragmentShader({\n            handle: shaderHandle\n          });\n          break;\n\n        default:\n      }\n    }\n\n    return opts;\n  }\n\n  _getParameter(pname) {\n    return this.gl.getProgramParameter(this.handle, pname);\n  }\n\n  _setId(id) {\n    if (!id) {\n      const programName = this._getName();\n\n      this.id = (0,_utils_utils__WEBPACK_IMPORTED_MODULE_10__.uid)(programName);\n    }\n  }\n\n  _getName() {\n    let programName = this.vs.getName() || this.fs.getName();\n    programName = programName.replace(/shader/i, '');\n    programName = programName ? \"\".concat(programName, \"-program\") : 'program';\n    return programName;\n  }\n\n  _compileAndLink() {\n    const {\n      gl\n    } = this;\n    gl.attachShader(this.handle, this.vs.handle);\n    gl.attachShader(this.handle, this.fs.handle);\n    _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.time(LOG_PROGRAM_PERF_PRIORITY, \"linkProgram for \".concat(this._getName()))();\n    gl.linkProgram(this.handle);\n    _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.timeEnd(LOG_PROGRAM_PERF_PRIORITY, \"linkProgram for \".concat(this._getName()))();\n\n    if (gl.debug || _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.level > 0) {\n      const linked = gl.getProgramParameter(this.handle, 35714);\n\n      if (!linked) {\n        throw new Error(\"Error linking: \".concat(gl.getProgramInfoLog(this.handle)));\n      }\n\n      gl.validateProgram(this.handle);\n      const validated = gl.getProgramParameter(this.handle, 35715);\n\n      if (!validated) {\n        throw new Error(\"Error validating: \".concat(gl.getProgramInfoLog(this.handle)));\n      }\n    }\n  }\n\n  _readUniformLocationsFromLinkedProgram() {\n    const {\n      gl\n    } = this;\n    this._uniformSetters = {};\n    this._uniformCount = this._getParameter(35718);\n\n    for (let i = 0; i < this._uniformCount; i++) {\n      const info = this.gl.getActiveUniform(this.handle, i);\n      const {\n        name\n      } = (0,_uniforms__WEBPACK_IMPORTED_MODULE_7__.parseUniformName)(info.name);\n      let location = gl.getUniformLocation(this.handle, name);\n      this._uniformSetters[name] = (0,_uniforms__WEBPACK_IMPORTED_MODULE_7__.getUniformSetter)(gl, location, info);\n\n      if (info.size > 1) {\n        for (let l = 0; l < info.size; l++) {\n          location = gl.getUniformLocation(this.handle, \"\".concat(name, \"[\").concat(l, \"]\"));\n          this._uniformSetters[\"\".concat(name, \"[\").concat(l, \"]\")] = (0,_uniforms__WEBPACK_IMPORTED_MODULE_7__.getUniformSetter)(gl, location, info);\n        }\n      }\n    }\n\n    this._textureIndexCounter = 0;\n  }\n\n  getActiveUniforms(uniformIndices, pname) {\n    return this.gl2.getActiveUniforms(this.handle, uniformIndices, pname);\n  }\n\n  getUniformBlockIndex(blockName) {\n    return this.gl2.getUniformBlockIndex(this.handle, blockName);\n  }\n\n  getActiveUniformBlockParameter(blockIndex, pname) {\n    return this.gl2.getActiveUniformBlockParameter(this.handle, blockIndex, pname);\n  }\n\n  uniformBlockBinding(blockIndex, blockBinding) {\n    this.gl2.uniformBlockBinding(this.handle, blockIndex, blockBinding);\n  }\n\n}\n//# sourceMappingURL=program.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/classes/program.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/classes/query.js":
/*!***************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/classes/query.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Query)\n/* harmony export */ });\n/* harmony import */ var _resource__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./resource */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/resource.js\");\n/* harmony import */ var _features__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../features */ \"./node_modules/@luma.gl/webgl/dist/esm/features/features.js\");\n/* harmony import */ var _features__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../features */ \"./node_modules/@luma.gl/webgl/dist/esm/features/webgl-features-table.js\");\n/* harmony import */ var _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/gltools */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../utils/assert */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js\");\n\n\n\n\nconst GL_QUERY_RESULT = 0x8866;\nconst GL_QUERY_RESULT_AVAILABLE = 0x8867;\nconst GL_TIME_ELAPSED_EXT = 0x88bf;\nconst GL_GPU_DISJOINT_EXT = 0x8fbb;\nconst GL_TRANSFORM_FEEDBACK_PRIMITIVES_WRITTEN = 0x8c88;\nconst GL_ANY_SAMPLES_PASSED = 0x8c2f;\nconst GL_ANY_SAMPLES_PASSED_CONSERVATIVE = 0x8d6a;\nclass Query extends _resource__WEBPACK_IMPORTED_MODULE_1__[\"default\"] {\n  get [Symbol.toStringTag]() {\n    return 'Query';\n  }\n\n  static isSupported(gl) {\n    let opts = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : [];\n    const webgl2 = (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.isWebGL2)(gl);\n    const hasTimerQuery = (0,_features__WEBPACK_IMPORTED_MODULE_2__.hasFeatures)(gl, _features__WEBPACK_IMPORTED_MODULE_3__.FEATURES.TIMER_QUERY);\n    let supported = webgl2 || hasTimerQuery;\n\n    for (const key of opts) {\n      switch (key) {\n        case 'queries':\n          supported = supported && webgl2;\n          break;\n\n        case 'timers':\n          supported = supported && hasTimerQuery;\n          break;\n\n        default:\n          (0,_utils_assert__WEBPACK_IMPORTED_MODULE_4__.assert)(false);\n      }\n    }\n\n    return supported;\n  }\n\n  constructor(gl) {\n    let opts = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    super(gl, opts);\n    this.target = null;\n    this._queryPending = false;\n    this._pollingPromise = null;\n    Object.seal(this);\n  }\n\n  beginTimeElapsedQuery() {\n    return this.begin(GL_TIME_ELAPSED_EXT);\n  }\n\n  beginOcclusionQuery() {\n    let {\n      conservative = false\n    } = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    return this.begin(conservative ? GL_ANY_SAMPLES_PASSED_CONSERVATIVE : GL_ANY_SAMPLES_PASSED);\n  }\n\n  beginTransformFeedbackQuery() {\n    return this.begin(GL_TRANSFORM_FEEDBACK_PRIMITIVES_WRITTEN);\n  }\n\n  begin(target) {\n    if (this._queryPending) {\n      return this;\n    }\n\n    this.target = target;\n    this.gl2.beginQuery(this.target, this.handle);\n    return this;\n  }\n\n  end() {\n    if (this._queryPending) {\n      return this;\n    }\n\n    if (this.target) {\n      this.gl2.endQuery(this.target);\n      this.target = null;\n      this._queryPending = true;\n    }\n\n    return this;\n  }\n\n  isResultAvailable() {\n    if (!this._queryPending) {\n      return false;\n    }\n\n    const resultAvailable = this.gl2.getQueryParameter(this.handle, GL_QUERY_RESULT_AVAILABLE);\n\n    if (resultAvailable) {\n      this._queryPending = false;\n    }\n\n    return resultAvailable;\n  }\n\n  isTimerDisjoint() {\n    return this.gl2.getParameter(GL_GPU_DISJOINT_EXT);\n  }\n\n  getResult() {\n    return this.gl2.getQueryParameter(this.handle, GL_QUERY_RESULT);\n  }\n\n  getTimerMilliseconds() {\n    return this.getResult() / 1e6;\n  }\n\n  createPoll() {\n    let limit = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : Number.POSITIVE_INFINITY;\n\n    if (this._pollingPromise) {\n      return this._pollingPromise;\n    }\n\n    let counter = 0;\n    this._pollingPromise = new Promise((resolve, reject) => {\n      const poll = () => {\n        if (this.isResultAvailable()) {\n          resolve(this.getResult());\n          this._pollingPromise = null;\n        } else if (counter++ > limit) {\n          reject('Timed out');\n          this._pollingPromise = null;\n        } else {\n          requestAnimationFrame(poll);\n        }\n      };\n\n      requestAnimationFrame(poll);\n    });\n    return this._pollingPromise;\n  }\n\n  _createHandle() {\n    return Query.isSupported(this.gl) ? this.gl2.createQuery() : null;\n  }\n\n  _deleteHandle() {\n    this.gl2.deleteQuery(this.handle);\n  }\n\n}\n//# sourceMappingURL=query.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/classes/query.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/classes/renderbuffer-formats.js":
/*!******************************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/classes/renderbuffer-formats.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nconst EXT_FLOAT_WEBGL2 = 'EXT_color_buffer_float';\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ({\n  [33189]: {\n    bpp: 2\n  },\n  [33190]: {\n    gl2: true,\n    bpp: 3\n  },\n  [36012]: {\n    gl2: true,\n    bpp: 4\n  },\n  [36168]: {\n    bpp: 1\n  },\n  [34041]: {\n    bpp: 4\n  },\n  [35056]: {\n    gl2: true,\n    bpp: 4\n  },\n  [36013]: {\n    gl2: true,\n    bpp: 5\n  },\n  [32854]: {\n    bpp: 2\n  },\n  [36194]: {\n    bpp: 2\n  },\n  [32855]: {\n    bpp: 2\n  },\n  [33321]: {\n    gl2: true,\n    bpp: 1\n  },\n  [33330]: {\n    gl2: true,\n    bpp: 1\n  },\n  [33329]: {\n    gl2: true,\n    bpp: 1\n  },\n  [33332]: {\n    gl2: true,\n    bpp: 2\n  },\n  [33331]: {\n    gl2: true,\n    bpp: 2\n  },\n  [33334]: {\n    gl2: true,\n    bpp: 4\n  },\n  [33333]: {\n    gl2: true,\n    bpp: 4\n  },\n  [33323]: {\n    gl2: true,\n    bpp: 2\n  },\n  [33336]: {\n    gl2: true,\n    bpp: 2\n  },\n  [33335]: {\n    gl2: true,\n    bpp: 2\n  },\n  [33338]: {\n    gl2: true,\n    bpp: 4\n  },\n  [33337]: {\n    gl2: true,\n    bpp: 4\n  },\n  [33340]: {\n    gl2: true,\n    bpp: 8\n  },\n  [33339]: {\n    gl2: true,\n    bpp: 8\n  },\n  [32849]: {\n    gl2: true,\n    bpp: 3\n  },\n  [32856]: {\n    gl2: true,\n    bpp: 4\n  },\n  [32857]: {\n    gl2: true,\n    bpp: 4\n  },\n  [36220]: {\n    gl2: true,\n    bpp: 4\n  },\n  [36238]: {\n    gl2: true,\n    bpp: 4\n  },\n  [36975]: {\n    gl2: true,\n    bpp: 4\n  },\n  [36214]: {\n    gl2: true,\n    bpp: 8\n  },\n  [36232]: {\n    gl2: true,\n    bpp: 8\n  },\n  [36226]: {\n    gl2: true,\n    bpp: 16\n  },\n  [36208]: {\n    gl2: true,\n    bpp: 16\n  },\n  [33325]: {\n    gl2: EXT_FLOAT_WEBGL2,\n    bpp: 2\n  },\n  [33327]: {\n    gl2: EXT_FLOAT_WEBGL2,\n    bpp: 4\n  },\n  [34842]: {\n    gl2: EXT_FLOAT_WEBGL2,\n    bpp: 8\n  },\n  [33326]: {\n    gl2: EXT_FLOAT_WEBGL2,\n    bpp: 4\n  },\n  [33328]: {\n    gl2: EXT_FLOAT_WEBGL2,\n    bpp: 8\n  },\n  [34836]: {\n    gl2: EXT_FLOAT_WEBGL2,\n    bpp: 16\n  },\n  [35898]: {\n    gl2: EXT_FLOAT_WEBGL2,\n    bpp: 4\n  }\n});\n//# sourceMappingURL=renderbuffer-formats.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/classes/renderbuffer-formats.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/classes/renderbuffer.js":
/*!**********************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/classes/renderbuffer.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Renderbuffer)\n/* harmony export */ });\n/* harmony import */ var _resource__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./resource */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/resource.js\");\n/* harmony import */ var _renderbuffer_formats__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./renderbuffer-formats */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/renderbuffer-formats.js\");\n/* harmony import */ var _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/gltools */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/assert */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js\");\n\n\n\n\n\nfunction isFormatSupported(gl, format, formats) {\n  const info = formats[format];\n\n  if (!info) {\n    return false;\n  }\n\n  const value = (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.isWebGL2)(gl) ? info.gl2 || info.gl1 : info.gl1;\n\n  if (typeof value === 'string') {\n    return gl.getExtension(value);\n  }\n\n  return value;\n}\n\nclass Renderbuffer extends _resource__WEBPACK_IMPORTED_MODULE_1__[\"default\"] {\n  get [Symbol.toStringTag]() {\n    return 'Renderbuffer';\n  }\n\n  static isSupported(gl) {\n    let {\n      format\n    } = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {\n      format: null\n    };\n    return !format || isFormatSupported(gl, format, _renderbuffer_formats__WEBPACK_IMPORTED_MODULE_2__[\"default\"]);\n  }\n\n  static getSamplesForFormat(gl, _ref) {\n    let {\n      format\n    } = _ref;\n    return gl.getInternalformatParameter(36161, format, 32937);\n  }\n\n  constructor(gl) {\n    let opts = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    super(gl, opts);\n    this.initialize(opts);\n    Object.seal(this);\n  }\n\n  initialize(_ref2) {\n    let {\n      format,\n      width = 1,\n      height = 1,\n      samples = 0\n    } = _ref2;\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_3__.assert)(format, 'Needs format');\n\n    this._trackDeallocatedMemory();\n\n    this.gl.bindRenderbuffer(36161, this.handle);\n\n    if (samples !== 0 && (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.isWebGL2)(this.gl)) {\n      this.gl.renderbufferStorageMultisample(36161, samples, format, width, height);\n    } else {\n      this.gl.renderbufferStorage(36161, format, width, height);\n    }\n\n    this.format = format;\n    this.width = width;\n    this.height = height;\n    this.samples = samples;\n\n    this._trackAllocatedMemory(this.width * this.height * (this.samples || 1) * _renderbuffer_formats__WEBPACK_IMPORTED_MODULE_2__[\"default\"][this.format].bpp);\n\n    return this;\n  }\n\n  resize(_ref3) {\n    let {\n      width,\n      height\n    } = _ref3;\n\n    if (width !== this.width || height !== this.height) {\n      return this.initialize({\n        width,\n        height,\n        format: this.format,\n        samples: this.samples\n      });\n    }\n\n    return this;\n  }\n\n  _createHandle() {\n    return this.gl.createRenderbuffer();\n  }\n\n  _deleteHandle() {\n    this.gl.deleteRenderbuffer(this.handle);\n\n    this._trackDeallocatedMemory();\n  }\n\n  _bindHandle(handle) {\n    this.gl.bindRenderbuffer(36161, handle);\n  }\n\n  _syncHandle(handle) {\n    this.format = this.getParameter(36164);\n    this.width = this.getParameter(36162);\n    this.height = this.getParameter(36163);\n    this.samples = this.getParameter(36011);\n  }\n\n  _getParameter(pname) {\n    this.gl.bindRenderbuffer(36161, this.handle);\n    const value = this.gl.getRenderbufferParameter(36161, pname);\n    return value;\n  }\n\n}\n//# sourceMappingURL=renderbuffer.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/classes/renderbuffer.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/classes/resource.js":
/*!******************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/classes/resource.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Resource)\n/* harmony export */ });\n/* harmony import */ var _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/gltools */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n/* harmony import */ var _init__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../init */ \"./node_modules/@luma.gl/webgl/dist/esm/init.js\");\n/* harmony import */ var _webgl_utils_constants_to_keys__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../webgl-utils/constants-to-keys */ \"./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/constants-to-keys.js\");\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/assert */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js\");\n/* harmony import */ var _utils_utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/utils */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/utils.js\");\n/* harmony import */ var _utils_stub_methods__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../utils/stub-methods */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/stub-methods.js\");\n\n\n\n\n\n\nconst ERR_RESOURCE_METHOD_UNDEFINED = 'Resource subclass must define virtual methods';\nclass Resource {\n  get [Symbol.toStringTag]() {\n    return 'Resource';\n  }\n\n  constructor(gl) {\n    let opts = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.assertWebGLContext)(gl);\n    const {\n      id,\n      userData = {}\n    } = opts;\n    this.gl = gl;\n    this.gl2 = gl;\n    this.id = id || (0,_utils_utils__WEBPACK_IMPORTED_MODULE_1__.uid)(this[Symbol.toStringTag]);\n    this.userData = userData;\n    this._bound = false;\n    this._handle = opts.handle;\n\n    if (this._handle === undefined) {\n      this._handle = this._createHandle();\n    }\n\n    this.byteLength = 0;\n\n    this._addStats();\n  }\n\n  toString() {\n    return \"\".concat(this[Symbol.toStringTag] || this.constructor.name, \"(\").concat(this.id, \")\");\n  }\n\n  get handle() {\n    return this._handle;\n  }\n\n  delete() {\n    let {\n      deleteChildren = false\n    } = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n\n    const children = this._handle && this._deleteHandle(this._handle);\n\n    if (this._handle) {\n      this._removeStats();\n    }\n\n    this._handle = null;\n\n    if (children && deleteChildren) {\n      children.filter(Boolean).forEach(child => child.delete());\n    }\n\n    return this;\n  }\n\n  bind() {\n    let funcOrHandle = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : this.handle;\n\n    if (typeof funcOrHandle !== 'function') {\n      this._bindHandle(funcOrHandle);\n\n      return this;\n    }\n\n    let value;\n\n    if (!this._bound) {\n      this._bindHandle(this.handle);\n\n      this._bound = true;\n      value = funcOrHandle();\n      this._bound = false;\n\n      this._bindHandle(null);\n    } else {\n      value = funcOrHandle();\n    }\n\n    return value;\n  }\n\n  unbind() {\n    this.bind(null);\n  }\n\n  getParameter(pname) {\n    let opts = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    pname = (0,_webgl_utils_constants_to_keys__WEBPACK_IMPORTED_MODULE_2__.getKeyValue)(this.gl, pname);\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_3__.assert)(pname);\n    const parameters = this.constructor.PARAMETERS || {};\n    const parameter = parameters[pname];\n\n    if (parameter) {\n      const isWebgl2 = (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.isWebGL2)(this.gl);\n      const parameterAvailable = (!('webgl2' in parameter) || isWebgl2) && (!('extension' in parameter) || this.gl.getExtension(parameter.extension));\n\n      if (!parameterAvailable) {\n        const webgl1Default = parameter.webgl1;\n        const webgl2Default = 'webgl2' in parameter ? parameter.webgl2 : parameter.webgl1;\n        const defaultValue = isWebgl2 ? webgl2Default : webgl1Default;\n        return defaultValue;\n      }\n    }\n\n    return this._getParameter(pname, opts);\n  }\n\n  getParameters() {\n    let options = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    const {\n      parameters,\n      keys\n    } = options;\n    const PARAMETERS = this.constructor.PARAMETERS || {};\n    const isWebgl2 = (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.isWebGL2)(this.gl);\n    const values = {};\n    const parameterKeys = parameters || Object.keys(PARAMETERS);\n\n    for (const pname of parameterKeys) {\n      const parameter = PARAMETERS[pname];\n      const parameterAvailable = parameter && (!('webgl2' in parameter) || isWebgl2) && (!('extension' in parameter) || this.gl.getExtension(parameter.extension));\n\n      if (parameterAvailable) {\n        const key = keys ? (0,_webgl_utils_constants_to_keys__WEBPACK_IMPORTED_MODULE_2__.getKey)(this.gl, pname) : pname;\n        values[key] = this.getParameter(pname, options);\n\n        if (keys && parameter.type === 'GLenum') {\n          values[key] = (0,_webgl_utils_constants_to_keys__WEBPACK_IMPORTED_MODULE_2__.getKey)(this.gl, values[key]);\n        }\n      }\n    }\n\n    return values;\n  }\n\n  setParameter(pname, value) {\n    pname = (0,_webgl_utils_constants_to_keys__WEBPACK_IMPORTED_MODULE_2__.getKeyValue)(this.gl, pname);\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_3__.assert)(pname);\n    const parameters = this.constructor.PARAMETERS || {};\n    const parameter = parameters[pname];\n\n    if (parameter) {\n      const isWebgl2 = (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.isWebGL2)(this.gl);\n      const parameterAvailable = (!('webgl2' in parameter) || isWebgl2) && (!('extension' in parameter) || this.gl.getExtension(parameter.extension));\n\n      if (!parameterAvailable) {\n        throw new Error('Parameter not available on this platform');\n      }\n\n      if (parameter.type === 'GLenum') {\n        value = (0,_webgl_utils_constants_to_keys__WEBPACK_IMPORTED_MODULE_2__.getKeyValue)(value);\n      }\n    }\n\n    this._setParameter(pname, value);\n\n    return this;\n  }\n\n  setParameters(parameters) {\n    for (const pname in parameters) {\n      this.setParameter(pname, parameters[pname]);\n    }\n\n    return this;\n  }\n\n  stubRemovedMethods(className, version, methodNames) {\n    return (0,_utils_stub_methods__WEBPACK_IMPORTED_MODULE_4__.stubRemovedMethods)(this, className, version, methodNames);\n  }\n\n  initialize(opts) {}\n\n  _createHandle() {\n    throw new Error(ERR_RESOURCE_METHOD_UNDEFINED);\n  }\n\n  _deleteHandle() {\n    throw new Error(ERR_RESOURCE_METHOD_UNDEFINED);\n  }\n\n  _bindHandle(handle) {\n    throw new Error(ERR_RESOURCE_METHOD_UNDEFINED);\n  }\n\n  _getOptsFromHandle() {\n    throw new Error(ERR_RESOURCE_METHOD_UNDEFINED);\n  }\n\n  _getParameter(pname, opts) {\n    throw new Error(ERR_RESOURCE_METHOD_UNDEFINED);\n  }\n\n  _setParameter(pname, value) {\n    throw new Error(ERR_RESOURCE_METHOD_UNDEFINED);\n  }\n\n  _context() {\n    this.gl.luma = this.gl.luma || {};\n    return this.gl.luma;\n  }\n\n  _addStats() {\n    const name = this[Symbol.toStringTag];\n    const stats = _init__WEBPACK_IMPORTED_MODULE_5__.lumaStats.get('Resource Counts');\n    stats.get('Resources Created').incrementCount();\n    stats.get(\"\".concat(name, \"s Created\")).incrementCount();\n    stats.get(\"\".concat(name, \"s Active\")).incrementCount();\n  }\n\n  _removeStats() {\n    const name = this[Symbol.toStringTag];\n    const stats = _init__WEBPACK_IMPORTED_MODULE_5__.lumaStats.get('Resource Counts');\n    stats.get(\"\".concat(name, \"s Active\")).decrementCount();\n  }\n\n  _trackAllocatedMemory(bytes) {\n    let name = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : this[Symbol.toStringTag];\n\n    this._trackAllocatedMemoryForContext(bytes, name);\n\n    this._trackAllocatedMemoryForContext(bytes, name, this.gl.canvas && this.gl.canvas.id);\n\n    this.byteLength = bytes;\n  }\n\n  _trackAllocatedMemoryForContext(bytes) {\n    let name = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : this[Symbol.toStringTag];\n    let id = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : '';\n    const stats = _init__WEBPACK_IMPORTED_MODULE_5__.lumaStats.get(\"Memory Usage\".concat(id));\n    stats.get('GPU Memory').addCount(bytes);\n    stats.get(\"\".concat(name, \" Memory\")).addCount(bytes);\n  }\n\n  _trackDeallocatedMemory() {\n    let name = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : this[Symbol.toStringTag];\n\n    this._trackDeallocatedMemoryForContext(name);\n\n    this._trackDeallocatedMemoryForContext(name, this.gl.canvas && this.gl.canvas.id);\n\n    this.byteLength = 0;\n  }\n\n  _trackDeallocatedMemoryForContext() {\n    let name = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : this[Symbol.toStringTag];\n    let id = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : '';\n    const stats = _init__WEBPACK_IMPORTED_MODULE_5__.lumaStats.get(\"Memory Usage\".concat(id));\n    stats.get('GPU Memory').subtractCount(this.byteLength);\n    stats.get(\"\".concat(name, \" Memory\")).subtractCount(this.byteLength);\n  }\n\n}\n//# sourceMappingURL=resource.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/classes/resource.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/classes/shader.js":
/*!****************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/classes/shader.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   FragmentShader: () => (/* binding */ FragmentShader),\n/* harmony export */   Shader: () => (/* binding */ Shader),\n/* harmony export */   VertexShader: () => (/* binding */ VertexShader)\n/* harmony export */ });\n/* harmony import */ var _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/gltools */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n/* harmony import */ var _glsl_utils__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../glsl-utils */ \"./node_modules/@luma.gl/webgl/dist/esm/glsl-utils/get-shader-name.js\");\n/* harmony import */ var _glsl_utils__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../glsl-utils */ \"./node_modules/@luma.gl/webgl/dist/esm/glsl-utils/format-glsl-error.js\");\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/assert */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js\");\n/* harmony import */ var _utils_utils__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../utils/utils */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/utils.js\");\n/* harmony import */ var _resource__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./resource */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/resource.js\");\n\n\n\n\n\nconst ERR_SOURCE = 'Shader: GLSL source code must be a JavaScript string';\nclass Shader extends _resource__WEBPACK_IMPORTED_MODULE_1__[\"default\"] {\n  get [Symbol.toStringTag]() {\n    return 'Shader';\n  }\n\n  static getTypeName(shaderType) {\n    switch (shaderType) {\n      case 35633:\n        return 'vertex-shader';\n\n      case 35632:\n        return 'fragment-shader';\n\n      default:\n        (0,_utils_assert__WEBPACK_IMPORTED_MODULE_2__.assert)(false);\n        return 'unknown';\n    }\n  }\n\n  constructor(gl, props) {\n    (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.assertWebGLContext)(gl);\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_2__.assert)(typeof props.source === 'string', ERR_SOURCE);\n    const id = (0,_glsl_utils__WEBPACK_IMPORTED_MODULE_3__[\"default\"])(props.source, null) || props.id || (0,_utils_utils__WEBPACK_IMPORTED_MODULE_4__.uid)(\"unnamed \".concat(Shader.getTypeName(props.shaderType)));\n    super(gl, {\n      id\n    });\n    this.shaderType = props.shaderType;\n    this.source = props.source;\n    this.initialize(props);\n  }\n\n  initialize(_ref) {\n    let {\n      source\n    } = _ref;\n    const shaderName = (0,_glsl_utils__WEBPACK_IMPORTED_MODULE_3__[\"default\"])(source, null);\n\n    if (shaderName) {\n      this.id = (0,_utils_utils__WEBPACK_IMPORTED_MODULE_4__.uid)(shaderName);\n    }\n\n    this._compile(source);\n  }\n\n  getParameter(pname) {\n    return this.gl.getShaderParameter(this.handle, pname);\n  }\n\n  toString() {\n    return \"\".concat(Shader.getTypeName(this.shaderType), \":\").concat(this.id);\n  }\n\n  getName() {\n    return (0,_glsl_utils__WEBPACK_IMPORTED_MODULE_3__[\"default\"])(this.source) || 'unnamed-shader';\n  }\n\n  getSource() {\n    return this.gl.getShaderSource(this.handle);\n  }\n\n  getTranslatedSource() {\n    const extension = this.gl.getExtension('WEBGL_debug_shaders');\n    return extension ? extension.getTranslatedShaderSource(this.handle) : 'No translated source available. WEBGL_debug_shaders not implemented';\n  }\n\n  _compile() {\n    let source = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : this.source;\n\n    if (!source.startsWith('#version ')) {\n      source = \"#version 100\\n\".concat(source);\n    }\n\n    this.source = source;\n    this.gl.shaderSource(this.handle, this.source);\n    this.gl.compileShader(this.handle);\n    const compileStatus = this.getParameter(35713);\n\n    if (!compileStatus) {\n      const infoLog = this.gl.getShaderInfoLog(this.handle);\n      const {\n        shaderName,\n        errors,\n        warnings\n      } = (0,_glsl_utils__WEBPACK_IMPORTED_MODULE_5__.parseGLSLCompilerError)(infoLog, this.source, this.shaderType, this.id);\n      _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.error(\"GLSL compilation errors in \".concat(shaderName, \"\\n\").concat(errors))();\n      _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.warn(\"GLSL compilation warnings in \".concat(shaderName, \"\\n\").concat(warnings))();\n      throw new Error(\"GLSL compilation errors in \".concat(shaderName));\n    }\n  }\n\n  _deleteHandle() {\n    this.gl.deleteShader(this.handle);\n  }\n\n  _getOptsFromHandle() {\n    return {\n      type: this.getParameter(35663),\n      source: this.getSource()\n    };\n  }\n\n}\nclass VertexShader extends Shader {\n  get [Symbol.toStringTag]() {\n    return 'VertexShader';\n  }\n\n  constructor(gl, props) {\n    if (typeof props === 'string') {\n      props = {\n        source: props\n      };\n    }\n\n    super(gl, Object.assign({}, props, {\n      shaderType: 35633\n    }));\n  }\n\n  _createHandle() {\n    return this.gl.createShader(35633);\n  }\n\n}\nclass FragmentShader extends Shader {\n  get [Symbol.toStringTag]() {\n    return 'FragmentShader';\n  }\n\n  constructor(gl, props) {\n    if (typeof props === 'string') {\n      props = {\n        source: props\n      };\n    }\n\n    super(gl, Object.assign({}, props, {\n      shaderType: 35632\n    }));\n  }\n\n  _createHandle() {\n    return this.gl.createShader(35632);\n  }\n\n}\n//# sourceMappingURL=shader.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/classes/shader.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/classes/texture-2d.js":
/*!********************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/classes/texture-2d.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Texture2D)\n/* harmony export */ });\n/* harmony import */ var _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/gltools */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n/* harmony import */ var _texture__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./texture */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/texture.js\");\n/* harmony import */ var _utils_load_file__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/load-file */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/load-file.js\");\n\n\n\nclass Texture2D extends _texture__WEBPACK_IMPORTED_MODULE_1__[\"default\"] {\n  get [Symbol.toStringTag]() {\n    return 'Texture2D';\n  }\n\n  static isSupported(gl, opts) {\n    return _texture__WEBPACK_IMPORTED_MODULE_1__[\"default\"].isSupported(gl, opts);\n  }\n\n  constructor(gl) {\n    let props = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.assertWebGLContext)(gl);\n\n    if (props instanceof Promise || typeof props === 'string') {\n      props = {\n        data: props\n      };\n    }\n\n    if (typeof props.data === 'string') {\n      props = Object.assign({}, props, {\n        data: (0,_utils_load_file__WEBPACK_IMPORTED_MODULE_2__.loadImage)(props.data)\n      });\n    }\n\n    super(gl, Object.assign({}, props, {\n      target: 3553\n    }));\n    this.initialize(props);\n    Object.seal(this);\n  }\n\n}\n//# sourceMappingURL=texture-2d.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/classes/texture-2d.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/classes/texture-3d.js":
/*!********************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/classes/texture-3d.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Texture3D)\n/* harmony export */ });\n/* harmony import */ var _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/gltools */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n/* harmony import */ var _texture__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./texture */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/texture.js\");\n/* harmony import */ var _texture_formats__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./texture-formats */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/texture-formats.js\");\n/* harmony import */ var _buffer__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./buffer */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/buffer.js\");\n\n\n\n\nclass Texture3D extends _texture__WEBPACK_IMPORTED_MODULE_1__[\"default\"] {\n  get [Symbol.toStringTag]() {\n    return 'Texture3D';\n  }\n\n  static isSupported(gl) {\n    return (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.isWebGL2)(gl);\n  }\n\n  constructor(gl) {\n    let props = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.assertWebGL2Context)(gl);\n    props = Object.assign({\n      depth: 1\n    }, props, {\n      target: 32879,\n      unpackFlipY: false\n    });\n    super(gl, props);\n    this.initialize(props);\n    Object.seal(this);\n  }\n\n  setImageData(_ref) {\n    let {\n      level = 0,\n      dataFormat = 6408,\n      width,\n      height,\n      depth = 1,\n      border = 0,\n      format,\n      type = 5121,\n      offset = 0,\n      data,\n      parameters = {}\n    } = _ref;\n\n    this._trackDeallocatedMemory('Texture');\n\n    this.gl.bindTexture(this.target, this.handle);\n    (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.withParameters)(this.gl, parameters, () => {\n      if (ArrayBuffer.isView(data)) {\n        this.gl.texImage3D(this.target, level, dataFormat, width, height, depth, border, format, type, data);\n      }\n\n      if (data instanceof _buffer__WEBPACK_IMPORTED_MODULE_2__[\"default\"]) {\n        this.gl.bindBuffer(35052, data.handle);\n        this.gl.texImage3D(this.target, level, dataFormat, width, height, depth, border, format, type, offset);\n      }\n    });\n\n    if (data && data.byteLength) {\n      this._trackAllocatedMemory(data.byteLength, 'Texture');\n    } else {\n      const channels = _texture_formats__WEBPACK_IMPORTED_MODULE_3__.DATA_FORMAT_CHANNELS[this.dataFormat] || 4;\n      const channelSize = _texture_formats__WEBPACK_IMPORTED_MODULE_3__.TYPE_SIZES[this.type] || 1;\n\n      this._trackAllocatedMemory(this.width * this.height * this.depth * channels * channelSize, 'Texture');\n    }\n\n    this.loaded = true;\n    return this;\n  }\n\n}\n//# sourceMappingURL=texture-3d.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/classes/texture-3d.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/classes/texture-cube.js":
/*!**********************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/classes/texture-cube.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ TextureCube)\n/* harmony export */ });\n/* harmony import */ var _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/gltools */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n/* harmony import */ var _texture__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./texture */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/texture.js\");\n\n\nconst FACES = [34069, 34070, 34071, 34072, 34073, 34074];\nclass TextureCube extends _texture__WEBPACK_IMPORTED_MODULE_1__[\"default\"] {\n  get [Symbol.toStringTag]() {\n    return 'TextureCube';\n  }\n\n  constructor(gl) {\n    let props = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.assertWebGLContext)(gl);\n    super(gl, Object.assign({}, props, {\n      target: 34067\n    }));\n    this.initialize(props);\n    Object.seal(this);\n  }\n\n  initialize() {\n    let props = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    const {\n      mipmaps = true,\n      parameters = {}\n    } = props;\n    this.opts = props;\n    this.setCubeMapImageData(props).then(() => {\n      this.loaded = true;\n\n      if (mipmaps) {\n        this.generateMipmap(props);\n      }\n\n      this.setParameters(parameters);\n    });\n    return this;\n  }\n\n  subImage(_ref) {\n    let {\n      face,\n      data,\n      x = 0,\n      y = 0,\n      mipmapLevel = 0\n    } = _ref;\n    return this._subImage({\n      target: face,\n      data,\n      x,\n      y,\n      mipmapLevel\n    });\n  }\n\n  async setCubeMapImageData(_ref2) {\n    let {\n      width,\n      height,\n      pixels,\n      data,\n      border = 0,\n      format = 6408,\n      type = 5121\n    } = _ref2;\n    const {\n      gl\n    } = this;\n    const imageDataMap = pixels || data;\n    const resolvedFaces = await Promise.all(FACES.map(face => {\n      const facePixels = imageDataMap[face];\n      return Promise.all(Array.isArray(facePixels) ? facePixels : [facePixels]);\n    }));\n    this.bind();\n    FACES.forEach((face, index) => {\n      if (resolvedFaces[index].length > 1 && this.opts.mipmaps !== false) {\n        _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.warn(\"\".concat(this.id, \" has mipmap and multiple LODs.\"))();\n      }\n\n      resolvedFaces[index].forEach((image, lodLevel) => {\n        if (width && height) {\n          gl.texImage2D(face, lodLevel, format, width, height, border, format, type, image);\n        } else {\n          gl.texImage2D(face, lodLevel, format, format, type, image);\n        }\n      });\n    });\n    this.unbind();\n  }\n\n  setImageDataForFace(options) {\n    const {\n      face,\n      width,\n      height,\n      pixels,\n      data,\n      border = 0,\n      format = 6408,\n      type = 5121\n    } = options;\n    const {\n      gl\n    } = this;\n    const imageData = pixels || data;\n    this.bind();\n\n    if (imageData instanceof Promise) {\n      imageData.then(resolvedImageData => this.setImageDataForFace(Object.assign({}, options, {\n        face,\n        data: resolvedImageData,\n        pixels: resolvedImageData\n      })));\n    } else if (this.width || this.height) {\n      gl.texImage2D(face, 0, format, width, height, border, format, type, imageData);\n    } else {\n      gl.texImage2D(face, 0, format, format, type, imageData);\n    }\n\n    return this;\n  }\n\n}\nTextureCube.FACES = FACES;\n//# sourceMappingURL=texture-cube.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/classes/texture-cube.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/classes/texture-formats.js":
/*!*************************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/classes/texture-formats.js ***!
  \*************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   DATA_FORMAT_CHANNELS: () => (/* binding */ DATA_FORMAT_CHANNELS),\n/* harmony export */   TEXTURE_FORMATS: () => (/* binding */ TEXTURE_FORMATS),\n/* harmony export */   TYPE_SIZES: () => (/* binding */ TYPE_SIZES),\n/* harmony export */   isFormatSupported: () => (/* binding */ isFormatSupported),\n/* harmony export */   isLinearFilteringSupported: () => (/* binding */ isLinearFilteringSupported)\n/* harmony export */ });\n/* harmony import */ var _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/gltools */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n\nconst TEXTURE_FORMATS = {\n  [6407]: {\n    dataFormat: 6407,\n    types: [5121, 33635]\n  },\n  [6408]: {\n    dataFormat: 6408,\n    types: [5121, 32819, 32820]\n  },\n  [6406]: {\n    dataFormat: 6406,\n    types: [5121]\n  },\n  [6409]: {\n    dataFormat: 6409,\n    types: [5121]\n  },\n  [6410]: {\n    dataFormat: 6410,\n    types: [5121]\n  },\n  [33326]: {\n    dataFormat: 6403,\n    types: [5126],\n    gl2: true\n  },\n  [33328]: {\n    dataFormat: 33319,\n    types: [5126],\n    gl2: true\n  },\n  [34837]: {\n    dataFormat: 6407,\n    types: [5126],\n    gl2: true\n  },\n  [34836]: {\n    dataFormat: 6408,\n    types: [5126],\n    gl2: true\n  }\n};\nconst DATA_FORMAT_CHANNELS = {\n  [6403]: 1,\n  [36244]: 1,\n  [33319]: 2,\n  [33320]: 2,\n  [6407]: 3,\n  [36248]: 3,\n  [6408]: 4,\n  [36249]: 4,\n  [6402]: 1,\n  [34041]: 1,\n  [6406]: 1,\n  [6409]: 1,\n  [6410]: 2\n};\nconst TYPE_SIZES = {\n  [5126]: 4,\n  [5125]: 4,\n  [5124]: 4,\n  [5123]: 2,\n  [5122]: 2,\n  [5131]: 2,\n  [5120]: 1,\n  [5121]: 1\n};\nfunction isFormatSupported(gl, format) {\n  const info = TEXTURE_FORMATS[format];\n\n  if (!info) {\n    return false;\n  }\n\n  if (info.gl1 === undefined && info.gl2 === undefined) {\n    return true;\n  }\n\n  const value = (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.isWebGL2)(gl) ? info.gl2 || info.gl1 : info.gl1;\n  return typeof value === 'string' ? gl.getExtension(value) : value;\n}\nfunction isLinearFilteringSupported(gl, format) {\n  const info = TEXTURE_FORMATS[format];\n\n  switch (info && info.types[0]) {\n    case 5126:\n      return gl.getExtension('OES_texture_float_linear');\n\n    case 5131:\n      return gl.getExtension('OES_texture_half_float_linear');\n\n    default:\n      return true;\n  }\n}\n//# sourceMappingURL=texture-formats.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/classes/texture-formats.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/classes/texture.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/classes/texture.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Texture)\n/* harmony export */ });\n/* harmony import */ var _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/gltools */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n/* harmony import */ var _resource__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./resource */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/resource.js\");\n/* harmony import */ var _buffer__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./buffer */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/buffer.js\");\n/* harmony import */ var _texture_formats__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./texture-formats */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/texture-formats.js\");\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../utils/assert */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js\");\n/* harmony import */ var _utils_utils__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/utils */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/utils.js\");\n\n\n\n\n\n\nconst NPOT_MIN_FILTERS = [9729, 9728];\n\nconst WebGLBuffer = globalThis.WebGLBuffer || function WebGLBuffer() {};\n\nclass Texture extends _resource__WEBPACK_IMPORTED_MODULE_1__[\"default\"] {\n  get [Symbol.toStringTag]() {\n    return 'Texture';\n  }\n\n  static isSupported(gl) {\n    let opts = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    const {\n      format,\n      linearFiltering\n    } = opts;\n    let supported = true;\n\n    if (format) {\n      supported = supported && (0,_texture_formats__WEBPACK_IMPORTED_MODULE_2__.isFormatSupported)(gl, format);\n      supported = supported && (!linearFiltering || (0,_texture_formats__WEBPACK_IMPORTED_MODULE_2__.isLinearFilteringSupported)(gl, format));\n    }\n\n    return supported;\n  }\n\n  constructor(gl, props) {\n    const {\n      id = (0,_utils_utils__WEBPACK_IMPORTED_MODULE_3__.uid)('texture'),\n      handle,\n      target\n    } = props;\n    super(gl, {\n      id,\n      handle\n    });\n    this.target = target;\n    this.textureUnit = undefined;\n    this.loaded = false;\n    this.width = undefined;\n    this.height = undefined;\n    this.depth = undefined;\n    this.format = undefined;\n    this.type = undefined;\n    this.dataFormat = undefined;\n    this.border = undefined;\n    this.textureUnit = undefined;\n    this.mipmaps = undefined;\n  }\n\n  toString() {\n    return \"Texture(\".concat(this.id, \",\").concat(this.width, \"x\").concat(this.height, \")\");\n  }\n\n  initialize() {\n    let props = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    let data = props.data;\n\n    if (data instanceof Promise) {\n      data.then(resolvedImageData => this.initialize(Object.assign({}, props, {\n        pixels: resolvedImageData,\n        data: resolvedImageData\n      })));\n      return this;\n    }\n\n    const isVideo = typeof HTMLVideoElement !== 'undefined' && data instanceof HTMLVideoElement;\n\n    if (isVideo && data.readyState < HTMLVideoElement.HAVE_METADATA) {\n      this._video = null;\n      data.addEventListener('loadeddata', () => this.initialize(props));\n      return this;\n    }\n\n    const {\n      pixels = null,\n      format = 6408,\n      border = 0,\n      recreate = false,\n      parameters = {},\n      pixelStore = {},\n      textureUnit = undefined\n    } = props;\n\n    if (!data) {\n      data = pixels;\n    }\n\n    let {\n      width,\n      height,\n      dataFormat,\n      type,\n      compressed = false,\n      mipmaps = true\n    } = props;\n    const {\n      depth = 0\n    } = props;\n    ({\n      width,\n      height,\n      compressed,\n      dataFormat,\n      type\n    } = this._deduceParameters({\n      format,\n      type,\n      dataFormat,\n      compressed,\n      data,\n      width,\n      height\n    }));\n    this.width = width;\n    this.height = height;\n    this.depth = depth;\n    this.format = format;\n    this.type = type;\n    this.dataFormat = dataFormat;\n    this.border = border;\n    this.textureUnit = textureUnit;\n\n    if (Number.isFinite(this.textureUnit)) {\n      this.gl.activeTexture(33984 + this.textureUnit);\n      this.gl.bindTexture(this.target, this.handle);\n    }\n\n    if (mipmaps && this._isNPOT()) {\n      _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.warn(\"texture: \".concat(this, \" is Non-Power-Of-Two, disabling mipmaping\"))();\n      mipmaps = false;\n\n      this._updateForNPOT(parameters);\n    }\n\n    this.mipmaps = mipmaps;\n    this.setImageData({\n      data,\n      width,\n      height,\n      depth,\n      format,\n      type,\n      dataFormat,\n      border,\n      mipmaps,\n      parameters: pixelStore,\n      compressed\n    });\n\n    if (mipmaps) {\n      this.generateMipmap();\n    }\n\n    this.setParameters(parameters);\n\n    if (recreate) {\n      this.data = data;\n    }\n\n    if (isVideo) {\n      this._video = {\n        video: data,\n        parameters,\n        lastTime: data.readyState >= HTMLVideoElement.HAVE_CURRENT_DATA ? data.currentTime : -1\n      };\n    }\n\n    return this;\n  }\n\n  update() {\n    if (this._video) {\n      const {\n        video,\n        parameters,\n        lastTime\n      } = this._video;\n\n      if (lastTime === video.currentTime || video.readyState < HTMLVideoElement.HAVE_CURRENT_DATA) {\n        return;\n      }\n\n      this.setSubImageData({\n        data: video,\n        parameters\n      });\n\n      if (this.mipmaps) {\n        this.generateMipmap();\n      }\n\n      this._video.lastTime = video.currentTime;\n    }\n  }\n\n  resize(_ref) {\n    let {\n      height,\n      width,\n      mipmaps = false\n    } = _ref;\n\n    if (width !== this.width || height !== this.height) {\n      return this.initialize({\n        width,\n        height,\n        format: this.format,\n        type: this.type,\n        dataFormat: this.dataFormat,\n        border: this.border,\n        mipmaps\n      });\n    }\n\n    return this;\n  }\n\n  generateMipmap() {\n    let params = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n\n    if (this._isNPOT()) {\n      _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.warn(\"texture: \".concat(this, \" is Non-Power-Of-Two, disabling mipmaping\"))();\n      return this;\n    }\n\n    this.mipmaps = true;\n    this.gl.bindTexture(this.target, this.handle);\n    (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.withParameters)(this.gl, params, () => {\n      this.gl.generateMipmap(this.target);\n    });\n    this.gl.bindTexture(this.target, null);\n    return this;\n  }\n\n  setImageData(options) {\n    this._trackDeallocatedMemory('Texture');\n\n    const {\n      target = this.target,\n      pixels = null,\n      level = 0,\n      format = this.format,\n      border = this.border,\n      offset = 0,\n      parameters = {}\n    } = options;\n    let {\n      data = null,\n      type = this.type,\n      width = this.width,\n      height = this.height,\n      dataFormat = this.dataFormat,\n      compressed = false\n    } = options;\n\n    if (!data) {\n      data = pixels;\n    }\n\n    ({\n      type,\n      dataFormat,\n      compressed,\n      width,\n      height\n    } = this._deduceParameters({\n      format,\n      type,\n      dataFormat,\n      compressed,\n      data,\n      width,\n      height\n    }));\n    const {\n      gl\n    } = this;\n    gl.bindTexture(this.target, this.handle);\n    let dataType = null;\n    ({\n      data,\n      dataType\n    } = this._getDataType({\n      data,\n      compressed\n    }));\n    let gl2;\n    let compressedTextureSize = 0;\n    (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.withParameters)(this.gl, parameters, () => {\n      switch (dataType) {\n        case 'null':\n          gl.texImage2D(target, level, format, width, height, border, dataFormat, type, data);\n          break;\n\n        case 'typed-array':\n          gl.texImage2D(target, level, format, width, height, border, dataFormat, type, data, offset);\n          break;\n\n        case 'buffer':\n          gl2 = (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.assertWebGL2Context)(gl);\n          gl2.bindBuffer(35052, data.handle || data);\n          gl2.texImage2D(target, level, format, width, height, border, dataFormat, type, offset);\n          gl2.bindBuffer(35052, null);\n          break;\n\n        case 'browser-object':\n          if ((0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.isWebGL2)(gl)) {\n            gl.texImage2D(target, level, format, width, height, border, dataFormat, type, data);\n          } else {\n            gl.texImage2D(target, level, format, dataFormat, type, data);\n          }\n\n          break;\n\n        case 'compressed':\n          for (const [levelIndex, levelData] of data.entries()) {\n            gl.compressedTexImage2D(target, levelIndex, levelData.format, levelData.width, levelData.height, border, levelData.data);\n            compressedTextureSize += levelData.levelSize;\n          }\n\n          break;\n\n        default:\n          (0,_utils_assert__WEBPACK_IMPORTED_MODULE_4__.assert)(false, 'Unknown image data type');\n      }\n    });\n\n    if (dataType === 'compressed') {\n      this._trackAllocatedMemory(compressedTextureSize, 'Texture');\n    } else if (data && data.byteLength) {\n      this._trackAllocatedMemory(data.byteLength, 'Texture');\n    } else {\n      const channels = _texture_formats__WEBPACK_IMPORTED_MODULE_2__.DATA_FORMAT_CHANNELS[this.dataFormat] || 4;\n      const channelSize = _texture_formats__WEBPACK_IMPORTED_MODULE_2__.TYPE_SIZES[this.type] || 1;\n\n      this._trackAllocatedMemory(this.width * this.height * channels * channelSize, 'Texture');\n    }\n\n    this.loaded = true;\n    return this;\n  }\n\n  setSubImageData(_ref2) {\n    let {\n      target = this.target,\n      pixels = null,\n      data = null,\n      x = 0,\n      y = 0,\n      width = this.width,\n      height = this.height,\n      level = 0,\n      format = this.format,\n      type = this.type,\n      dataFormat = this.dataFormat,\n      compressed = false,\n      offset = 0,\n      border = this.border,\n      parameters = {}\n    } = _ref2;\n    ({\n      type,\n      dataFormat,\n      compressed,\n      width,\n      height\n    } = this._deduceParameters({\n      format,\n      type,\n      dataFormat,\n      compressed,\n      data,\n      width,\n      height\n    }));\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_4__.assert)(this.depth === 0, 'texSubImage not supported for 3D textures');\n\n    if (!data) {\n      data = pixels;\n    }\n\n    if (data && data.data) {\n      const ndarray = data;\n      data = ndarray.data;\n      width = ndarray.shape[0];\n      height = ndarray.shape[1];\n    }\n\n    if (data instanceof _buffer__WEBPACK_IMPORTED_MODULE_5__[\"default\"]) {\n      data = data.handle;\n    }\n\n    this.gl.bindTexture(this.target, this.handle);\n    (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.withParameters)(this.gl, parameters, () => {\n      if (compressed) {\n        this.gl.compressedTexSubImage2D(target, level, x, y, width, height, format, data);\n      } else if (data === null) {\n        this.gl.texSubImage2D(target, level, x, y, width, height, dataFormat, type, null);\n      } else if (ArrayBuffer.isView(data)) {\n        this.gl.texSubImage2D(target, level, x, y, width, height, dataFormat, type, data, offset);\n      } else if (data instanceof WebGLBuffer) {\n        const gl2 = (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.assertWebGL2Context)(this.gl);\n        gl2.bindBuffer(35052, data);\n        gl2.texSubImage2D(target, level, x, y, width, height, dataFormat, type, offset);\n        gl2.bindBuffer(35052, null);\n      } else if ((0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.isWebGL2)(this.gl)) {\n        const gl2 = (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.assertWebGL2Context)(this.gl);\n        gl2.texSubImage2D(target, level, x, y, width, height, dataFormat, type, data);\n      } else {\n        this.gl.texSubImage2D(target, level, x, y, dataFormat, type, data);\n      }\n    });\n    this.gl.bindTexture(this.target, null);\n  }\n\n  copyFramebuffer() {\n    let opts = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.error('Texture.copyFramebuffer({...}) is no logner supported, use copyToTexture(source, target, opts})')();\n    return null;\n  }\n\n  getActiveUnit() {\n    return this.gl.getParameter(34016) - 33984;\n  }\n\n  bind() {\n    let textureUnit = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : this.textureUnit;\n    const {\n      gl\n    } = this;\n\n    if (textureUnit !== undefined) {\n      this.textureUnit = textureUnit;\n      gl.activeTexture(33984 + textureUnit);\n    }\n\n    gl.bindTexture(this.target, this.handle);\n    return textureUnit;\n  }\n\n  unbind() {\n    let textureUnit = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : this.textureUnit;\n    const {\n      gl\n    } = this;\n\n    if (textureUnit !== undefined) {\n      this.textureUnit = textureUnit;\n      gl.activeTexture(33984 + textureUnit);\n    }\n\n    gl.bindTexture(this.target, null);\n    return textureUnit;\n  }\n\n  _getDataType(_ref3) {\n    let {\n      data,\n      compressed = false\n    } = _ref3;\n\n    if (compressed) {\n      return {\n        data,\n        dataType: 'compressed'\n      };\n    }\n\n    if (data === null) {\n      return {\n        data,\n        dataType: 'null'\n      };\n    }\n\n    if (ArrayBuffer.isView(data)) {\n      return {\n        data,\n        dataType: 'typed-array'\n      };\n    }\n\n    if (data instanceof _buffer__WEBPACK_IMPORTED_MODULE_5__[\"default\"]) {\n      return {\n        data: data.handle,\n        dataType: 'buffer'\n      };\n    }\n\n    if (data instanceof WebGLBuffer) {\n      return {\n        data,\n        dataType: 'buffer'\n      };\n    }\n\n    return {\n      data,\n      dataType: 'browser-object'\n    };\n  }\n\n  _deduceParameters(opts) {\n    const {\n      format,\n      data\n    } = opts;\n    let {\n      width,\n      height,\n      dataFormat,\n      type,\n      compressed\n    } = opts;\n    const textureFormat = _texture_formats__WEBPACK_IMPORTED_MODULE_2__.TEXTURE_FORMATS[format];\n    dataFormat = dataFormat || textureFormat && textureFormat.dataFormat;\n    type = type || textureFormat && textureFormat.types[0];\n    compressed = compressed || textureFormat && textureFormat.compressed;\n    ({\n      width,\n      height\n    } = this._deduceImageSize(data, width, height));\n    return {\n      dataFormat,\n      type,\n      compressed,\n      width,\n      height,\n      format,\n      data\n    };\n  }\n\n  _deduceImageSize(data, width, height) {\n    let size;\n\n    if (typeof ImageData !== 'undefined' && data instanceof ImageData) {\n      size = {\n        width: data.width,\n        height: data.height\n      };\n    } else if (typeof HTMLImageElement !== 'undefined' && data instanceof HTMLImageElement) {\n      size = {\n        width: data.naturalWidth,\n        height: data.naturalHeight\n      };\n    } else if (typeof HTMLCanvasElement !== 'undefined' && data instanceof HTMLCanvasElement) {\n      size = {\n        width: data.width,\n        height: data.height\n      };\n    } else if (typeof ImageBitmap !== 'undefined' && data instanceof ImageBitmap) {\n      size = {\n        width: data.width,\n        height: data.height\n      };\n    } else if (typeof HTMLVideoElement !== 'undefined' && data instanceof HTMLVideoElement) {\n      size = {\n        width: data.videoWidth,\n        height: data.videoHeight\n      };\n    } else if (!data) {\n      size = {\n        width: width >= 0 ? width : 1,\n        height: height >= 0 ? height : 1\n      };\n    } else {\n      size = {\n        width,\n        height\n      };\n    }\n\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_4__.assert)(size, 'Could not deduced texture size');\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_4__.assert)(width === undefined || size.width === width, 'Deduced texture width does not match supplied width');\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_4__.assert)(height === undefined || size.height === height, 'Deduced texture height does not match supplied height');\n    return size;\n  }\n\n  _createHandle() {\n    return this.gl.createTexture();\n  }\n\n  _deleteHandle() {\n    this.gl.deleteTexture(this.handle);\n\n    this._trackDeallocatedMemory('Texture');\n  }\n\n  _getParameter(pname) {\n    switch (pname) {\n      case 4096:\n        return this.width;\n\n      case 4097:\n        return this.height;\n\n      default:\n        this.gl.bindTexture(this.target, this.handle);\n        const value = this.gl.getTexParameter(this.target, pname);\n        this.gl.bindTexture(this.target, null);\n        return value;\n    }\n  }\n\n  _setParameter(pname, param) {\n    this.gl.bindTexture(this.target, this.handle);\n    param = this._getNPOTParam(pname, param);\n\n    switch (pname) {\n      case 33082:\n      case 33083:\n        this.gl.texParameterf(this.handle, pname, param);\n        break;\n\n      case 4096:\n      case 4097:\n        (0,_utils_assert__WEBPACK_IMPORTED_MODULE_4__.assert)(false);\n        break;\n\n      default:\n        this.gl.texParameteri(this.target, pname, param);\n        break;\n    }\n\n    this.gl.bindTexture(this.target, null);\n    return this;\n  }\n\n  _isNPOT() {\n    if ((0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.isWebGL2)(this.gl)) {\n      return false;\n    }\n\n    if (!this.width || !this.height) {\n      return false;\n    }\n\n    return !(0,_utils_utils__WEBPACK_IMPORTED_MODULE_3__.isPowerOfTwo)(this.width) || !(0,_utils_utils__WEBPACK_IMPORTED_MODULE_3__.isPowerOfTwo)(this.height);\n  }\n\n  _updateForNPOT(parameters) {\n    if (parameters[this.gl.TEXTURE_MIN_FILTER] === undefined) {\n      parameters[this.gl.TEXTURE_MIN_FILTER] = this.gl.LINEAR;\n    }\n\n    if (parameters[this.gl.TEXTURE_WRAP_S] === undefined) {\n      parameters[this.gl.TEXTURE_WRAP_S] = this.gl.CLAMP_TO_EDGE;\n    }\n\n    if (parameters[this.gl.TEXTURE_WRAP_T] === undefined) {\n      parameters[this.gl.TEXTURE_WRAP_T] = this.gl.CLAMP_TO_EDGE;\n    }\n  }\n\n  _getNPOTParam(pname, param) {\n    if (this._isNPOT()) {\n      switch (pname) {\n        case 10241:\n          if (NPOT_MIN_FILTERS.indexOf(param) === -1) {\n            param = 9729;\n          }\n\n          break;\n\n        case 10242:\n        case 10243:\n          if (param !== 33071) {\n            param = 33071;\n          }\n\n          break;\n\n        default:\n          break;\n      }\n    }\n\n    return param;\n  }\n\n}\n//# sourceMappingURL=texture.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/classes/texture.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/classes/transform-feedback.js":
/*!****************************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/classes/transform-feedback.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ TransformFeedback)\n/* harmony export */ });\n/* harmony import */ var _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/gltools */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n/* harmony import */ var _resource__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./resource */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/resource.js\");\n/* harmony import */ var _buffer__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./buffer */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/buffer.js\");\n/* harmony import */ var _utils_utils__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/utils */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/utils.js\");\n\n\n\n\nclass TransformFeedback extends _resource__WEBPACK_IMPORTED_MODULE_1__[\"default\"] {\n  get [Symbol.toStringTag]() {\n    return 'TransformFeedback';\n  }\n\n  static isSupported(gl) {\n    return (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.isWebGL2)(gl);\n  }\n\n  constructor(gl) {\n    let props = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.assertWebGL2Context)(gl);\n    super(gl, props);\n    this.initialize(props);\n    this.stubRemovedMethods('TransformFeedback', 'v6.0', ['pause', 'resume']);\n    Object.seal(this);\n  }\n\n  initialize() {\n    let props = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    this.buffers = {};\n    this.unused = {};\n    this.configuration = null;\n    this.bindOnUse = true;\n\n    if (!(0,_utils_utils__WEBPACK_IMPORTED_MODULE_2__.isObjectEmpty)(this.buffers)) {\n      this.bind(() => this._unbindBuffers());\n    }\n\n    this.setProps(props);\n    return this;\n  }\n\n  setProps(props) {\n    if ('program' in props) {\n      this.configuration = props.program && props.program.configuration;\n    }\n\n    if ('configuration' in props) {\n      this.configuration = props.configuration;\n    }\n\n    if ('bindOnUse' in props) {\n      props = props.bindOnUse;\n    }\n\n    if ('buffers' in props) {\n      this.setBuffers(props.buffers);\n    }\n  }\n\n  setBuffers() {\n    let buffers = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    this.bind(() => {\n      for (const bufferName in buffers) {\n        this.setBuffer(bufferName, buffers[bufferName]);\n      }\n    });\n    return this;\n  }\n\n  setBuffer(locationOrName, bufferOrParams) {\n    const location = this._getVaryingIndex(locationOrName);\n\n    const {\n      buffer,\n      byteSize,\n      byteOffset\n    } = this._getBufferParams(bufferOrParams);\n\n    if (location < 0) {\n      this.unused[locationOrName] = buffer;\n      _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.warn(\"\".concat(this.id, \" unused varying buffer \").concat(locationOrName))();\n      return this;\n    }\n\n    this.buffers[location] = bufferOrParams;\n\n    if (!this.bindOnUse) {\n      this._bindBuffer(location, buffer, byteOffset, byteSize);\n    }\n\n    return this;\n  }\n\n  begin() {\n    let primitiveMode = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;\n    this.gl.bindTransformFeedback(36386, this.handle);\n\n    this._bindBuffers();\n\n    this.gl.beginTransformFeedback(primitiveMode);\n    return this;\n  }\n\n  end() {\n    this.gl.endTransformFeedback();\n\n    this._unbindBuffers();\n\n    this.gl.bindTransformFeedback(36386, null);\n    return this;\n  }\n\n  _getBufferParams(bufferOrParams) {\n    let byteOffset;\n    let byteSize;\n    let buffer;\n\n    if (bufferOrParams instanceof _buffer__WEBPACK_IMPORTED_MODULE_3__[\"default\"] === false) {\n      buffer = bufferOrParams.buffer;\n      byteSize = bufferOrParams.byteSize;\n      byteOffset = bufferOrParams.byteOffset;\n    } else {\n      buffer = bufferOrParams;\n    }\n\n    if (byteOffset !== undefined || byteSize !== undefined) {\n      byteOffset = byteOffset || 0;\n      byteSize = byteSize || buffer.byteLength - byteOffset;\n    }\n\n    return {\n      buffer,\n      byteOffset,\n      byteSize\n    };\n  }\n\n  _getVaryingInfo(locationOrName) {\n    return this.configuration && this.configuration.getVaryingInfo(locationOrName);\n  }\n\n  _getVaryingIndex(locationOrName) {\n    if (this.configuration) {\n      return this.configuration.getVaryingInfo(locationOrName).location;\n    }\n\n    const location = Number(locationOrName);\n    return Number.isFinite(location) ? location : -1;\n  }\n\n  _bindBuffers() {\n    if (this.bindOnUse) {\n      for (const bufferIndex in this.buffers) {\n        const {\n          buffer,\n          byteSize,\n          byteOffset\n        } = this._getBufferParams(this.buffers[bufferIndex]);\n\n        this._bindBuffer(bufferIndex, buffer, byteOffset, byteSize);\n      }\n    }\n  }\n\n  _unbindBuffers() {\n    if (this.bindOnUse) {\n      for (const bufferIndex in this.buffers) {\n        this._bindBuffer(bufferIndex, null);\n      }\n    }\n  }\n\n  _bindBuffer(index, buffer) {\n    let byteOffset = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n    let byteSize = arguments.length > 3 ? arguments[3] : undefined;\n    const handle = buffer && buffer.handle;\n\n    if (!handle || byteSize === undefined) {\n      this.gl.bindBufferBase(35982, index, handle);\n    } else {\n      this.gl.bindBufferRange(35982, index, handle, byteOffset, byteSize);\n    }\n\n    return this;\n  }\n\n  _createHandle() {\n    return this.gl.createTransformFeedback();\n  }\n\n  _deleteHandle() {\n    this.gl.deleteTransformFeedback(this.handle);\n  }\n\n  _bindHandle(handle) {\n    this.gl.bindTransformFeedback(36386, this.handle);\n  }\n\n}\n//# sourceMappingURL=transform-feedback.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/classes/transform-feedback.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/classes/uniforms.js":
/*!******************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/classes/uniforms.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   checkUniformValues: () => (/* binding */ checkUniformValues),\n/* harmony export */   copyUniform: () => (/* binding */ copyUniform),\n/* harmony export */   getUniformSetter: () => (/* binding */ getUniformSetter),\n/* harmony export */   parseUniformName: () => (/* binding */ parseUniformName)\n/* harmony export */ });\n/* harmony import */ var _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/gltools */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n/* harmony import */ var _framebuffer__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./framebuffer */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/framebuffer.js\");\n/* harmony import */ var _renderbuffer__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./renderbuffer */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/renderbuffer.js\");\n/* harmony import */ var _texture__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./texture */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/texture.js\");\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../utils/assert */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js\");\n\n\n\n\n\nconst UNIFORM_SETTERS = {\n  [5126]: getArraySetter.bind(null, 'uniform1fv', toFloatArray, 1, setVectorUniform),\n  [35664]: getArraySetter.bind(null, 'uniform2fv', toFloatArray, 2, setVectorUniform),\n  [35665]: getArraySetter.bind(null, 'uniform3fv', toFloatArray, 3, setVectorUniform),\n  [35666]: getArraySetter.bind(null, 'uniform4fv', toFloatArray, 4, setVectorUniform),\n  [5124]: getArraySetter.bind(null, 'uniform1iv', toIntArray, 1, setVectorUniform),\n  [35667]: getArraySetter.bind(null, 'uniform2iv', toIntArray, 2, setVectorUniform),\n  [35668]: getArraySetter.bind(null, 'uniform3iv', toIntArray, 3, setVectorUniform),\n  [35669]: getArraySetter.bind(null, 'uniform4iv', toIntArray, 4, setVectorUniform),\n  [35670]: getArraySetter.bind(null, 'uniform1iv', toIntArray, 1, setVectorUniform),\n  [35671]: getArraySetter.bind(null, 'uniform2iv', toIntArray, 2, setVectorUniform),\n  [35672]: getArraySetter.bind(null, 'uniform3iv', toIntArray, 3, setVectorUniform),\n  [35673]: getArraySetter.bind(null, 'uniform4iv', toIntArray, 4, setVectorUniform),\n  [35674]: getArraySetter.bind(null, 'uniformMatrix2fv', toFloatArray, 4, setMatrixUniform),\n  [35675]: getArraySetter.bind(null, 'uniformMatrix3fv', toFloatArray, 9, setMatrixUniform),\n  [35676]: getArraySetter.bind(null, 'uniformMatrix4fv', toFloatArray, 16, setMatrixUniform),\n  [35678]: getSamplerSetter,\n  [35680]: getSamplerSetter,\n  [5125]: getArraySetter.bind(null, 'uniform1uiv', toUIntArray, 1, setVectorUniform),\n  [36294]: getArraySetter.bind(null, 'uniform2uiv', toUIntArray, 2, setVectorUniform),\n  [36295]: getArraySetter.bind(null, 'uniform3uiv', toUIntArray, 3, setVectorUniform),\n  [36296]: getArraySetter.bind(null, 'uniform4uiv', toUIntArray, 4, setVectorUniform),\n  [35685]: getArraySetter.bind(null, 'uniformMatrix2x3fv', toFloatArray, 6, setMatrixUniform),\n  [35686]: getArraySetter.bind(null, 'uniformMatrix2x4fv', toFloatArray, 8, setMatrixUniform),\n  [35687]: getArraySetter.bind(null, 'uniformMatrix3x2fv', toFloatArray, 6, setMatrixUniform),\n  [35688]: getArraySetter.bind(null, 'uniformMatrix3x4fv', toFloatArray, 12, setMatrixUniform),\n  [35689]: getArraySetter.bind(null, 'uniformMatrix4x2fv', toFloatArray, 8, setMatrixUniform),\n  [35690]: getArraySetter.bind(null, 'uniformMatrix4x3fv', toFloatArray, 12, setMatrixUniform),\n  [35678]: getSamplerSetter,\n  [35680]: getSamplerSetter,\n  [35679]: getSamplerSetter,\n  [35682]: getSamplerSetter,\n  [36289]: getSamplerSetter,\n  [36292]: getSamplerSetter,\n  [36293]: getSamplerSetter,\n  [36298]: getSamplerSetter,\n  [36299]: getSamplerSetter,\n  [36300]: getSamplerSetter,\n  [36303]: getSamplerSetter,\n  [36306]: getSamplerSetter,\n  [36307]: getSamplerSetter,\n  [36308]: getSamplerSetter,\n  [36311]: getSamplerSetter\n};\nconst FLOAT_ARRAY = {};\nconst INT_ARRAY = {};\nconst UINT_ARRAY = {};\nconst array1 = [0];\n\nfunction toTypedArray(value, uniformLength, Type, cache) {\n  if (uniformLength === 1 && typeof value === 'boolean') {\n    value = value ? 1 : 0;\n  }\n\n  if (Number.isFinite(value)) {\n    array1[0] = value;\n    value = array1;\n  }\n\n  const length = value.length;\n\n  if (length % uniformLength) {\n    _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.warn(\"Uniform size should be multiples of \".concat(uniformLength), value)();\n  }\n\n  if (value instanceof Type) {\n    return value;\n  }\n\n  let result = cache[length];\n\n  if (!result) {\n    result = new Type(length);\n    cache[length] = result;\n  }\n\n  for (let i = 0; i < length; i++) {\n    result[i] = value[i];\n  }\n\n  return result;\n}\n\nfunction toFloatArray(value, uniformLength) {\n  return toTypedArray(value, uniformLength, Float32Array, FLOAT_ARRAY);\n}\n\nfunction toIntArray(value, uniformLength) {\n  return toTypedArray(value, uniformLength, Int32Array, INT_ARRAY);\n}\n\nfunction toUIntArray(value, uniformLength) {\n  return toTypedArray(value, uniformLength, Uint32Array, UINT_ARRAY);\n}\n\nfunction getUniformSetter(gl, location, info) {\n  const setter = UNIFORM_SETTERS[info.type];\n\n  if (!setter) {\n    throw new Error(\"Unknown GLSL uniform type \".concat(info.type));\n  }\n\n  return setter().bind(null, gl, location);\n}\nfunction parseUniformName(name) {\n  if (name[name.length - 1] !== ']') {\n    return {\n      name,\n      length: 1,\n      isArray: false\n    };\n  }\n\n  const UNIFORM_NAME_REGEXP = /([^[]*)(\\[[0-9]+\\])?/;\n  const matches = name.match(UNIFORM_NAME_REGEXP);\n\n  if (!matches || matches.length < 2) {\n    throw new Error(\"Failed to parse GLSL uniform name \".concat(name));\n  }\n\n  return {\n    name: matches[1],\n    length: matches[2] || 1,\n    isArray: Boolean(matches[2])\n  };\n}\nfunction checkUniformValues(uniforms, source, uniformMap) {\n  for (const uniformName in uniforms) {\n    const value = uniforms[uniformName];\n    const shouldCheck = !uniformMap || Boolean(uniformMap[uniformName]);\n\n    if (shouldCheck && !checkUniformValue(value)) {\n      source = source ? \"\".concat(source, \" \") : '';\n      console.error(\"\".concat(source, \" Bad uniform \").concat(uniformName), value);\n      throw new Error(\"\".concat(source, \" Bad uniform \").concat(uniformName));\n    }\n  }\n\n  return true;\n}\n\nfunction checkUniformValue(value) {\n  if (Array.isArray(value) || ArrayBuffer.isView(value)) {\n    return checkUniformArray(value);\n  }\n\n  if (isFinite(value)) {\n    return true;\n  } else if (value === true || value === false) {\n    return true;\n  } else if (value instanceof _texture__WEBPACK_IMPORTED_MODULE_1__[\"default\"]) {\n    return true;\n  } else if (value instanceof _renderbuffer__WEBPACK_IMPORTED_MODULE_2__[\"default\"]) {\n    return true;\n  } else if (value instanceof _framebuffer__WEBPACK_IMPORTED_MODULE_3__[\"default\"]) {\n    return Boolean(value.texture);\n  }\n\n  return false;\n}\n\nfunction copyUniform(uniforms, key, value) {\n  if (Array.isArray(value) || ArrayBuffer.isView(value)) {\n    if (uniforms[key]) {\n      const dest = uniforms[key];\n\n      for (let i = 0, len = value.length; i < len; ++i) {\n        dest[i] = value[i];\n      }\n    } else {\n      uniforms[key] = value.slice();\n    }\n  } else {\n    uniforms[key] = value;\n  }\n}\n\nfunction checkUniformArray(value) {\n  if (value.length === 0) {\n    return false;\n  }\n\n  const checkLength = Math.min(value.length, 16);\n\n  for (let i = 0; i < checkLength; ++i) {\n    if (!Number.isFinite(value[i])) {\n      return false;\n    }\n  }\n\n  return true;\n}\n\nfunction getSamplerSetter() {\n  let cache = null;\n  return (gl, location, value) => {\n    const update = cache !== value;\n\n    if (update) {\n      gl.uniform1i(location, value);\n      cache = value;\n    }\n\n    return update;\n  };\n}\n\nfunction getArraySetter(functionName, toArray, size, uniformSetter) {\n  let cache = null;\n  let cacheLength = null;\n  return (gl, location, value) => {\n    const arrayValue = toArray(value, size);\n    const length = arrayValue.length;\n    let update = false;\n\n    if (cache === null) {\n      cache = new Float32Array(length);\n      cacheLength = length;\n      update = true;\n    } else {\n      (0,_utils_assert__WEBPACK_IMPORTED_MODULE_4__.assert)(cacheLength === length, 'Uniform length cannot change.');\n\n      for (let i = 0; i < length; ++i) {\n        if (arrayValue[i] !== cache[i]) {\n          update = true;\n          break;\n        }\n      }\n    }\n\n    if (update) {\n      uniformSetter(gl, functionName, location, arrayValue);\n      cache.set(arrayValue);\n    }\n\n    return update;\n  };\n}\n\nfunction setVectorUniform(gl, functionName, location, value) {\n  gl[functionName](location, value);\n}\n\nfunction setMatrixUniform(gl, functionName, location, value) {\n  gl[functionName](location, false, value);\n}\n//# sourceMappingURL=uniforms.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/classes/uniforms.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/classes/vertex-array-object.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/classes/vertex-array-object.js ***!
  \*****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ VertexArrayObject)\n/* harmony export */ });\n/* harmony import */ var _resource__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./resource */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/resource.js\");\n/* harmony import */ var _buffer__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./buffer */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/buffer.js\");\n/* harmony import */ var _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/gltools */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n/* harmony import */ var _utils_array_utils_flat__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../utils/array-utils-flat */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/array-utils-flat.js\");\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/assert */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js\");\n/* harmony import */ var _probe_gl_env__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @probe.gl/env */ \"./node_modules/@probe.gl/env/dist/esm/lib/get-browser.js\");\n\n\n\n\n\n\nconst ERR_ELEMENTS = 'elements must be GL.ELEMENT_ARRAY_BUFFER';\nclass VertexArrayObject extends _resource__WEBPACK_IMPORTED_MODULE_1__[\"default\"] {\n  get [Symbol.toStringTag]() {\n    return 'VertexArrayObject';\n  }\n\n  static isSupported(gl) {\n    let options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n\n    if (options.constantAttributeZero) {\n      return (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.isWebGL2)(gl) || (0,_probe_gl_env__WEBPACK_IMPORTED_MODULE_2__[\"default\"])() === 'Chrome';\n    }\n\n    return true;\n  }\n\n  static getDefaultArray(gl) {\n    gl.luma = gl.luma || {};\n\n    if (!gl.luma.defaultVertexArray) {\n      gl.luma.defaultVertexArray = new VertexArrayObject(gl, {\n        handle: null,\n        isDefaultArray: true\n      });\n    }\n\n    return gl.luma.defaultVertexArray;\n  }\n\n  static getMaxAttributes(gl) {\n    VertexArrayObject.MAX_ATTRIBUTES = VertexArrayObject.MAX_ATTRIBUTES || gl.getParameter(34921);\n    return VertexArrayObject.MAX_ATTRIBUTES;\n  }\n\n  static setConstant(gl, location, array) {\n    switch (array.constructor) {\n      case Float32Array:\n        VertexArrayObject._setConstantFloatArray(gl, location, array);\n\n        break;\n\n      case Int32Array:\n        VertexArrayObject._setConstantIntArray(gl, location, array);\n\n        break;\n\n      case Uint32Array:\n        VertexArrayObject._setConstantUintArray(gl, location, array);\n\n        break;\n\n      default:\n        (0,_utils_assert__WEBPACK_IMPORTED_MODULE_3__.assert)(false);\n    }\n  }\n\n  constructor(gl) {\n    let opts = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    const id = opts.id || opts.program && opts.program.id;\n    super(gl, Object.assign({}, opts, {\n      id\n    }));\n    this.buffer = null;\n    this.bufferValue = null;\n    this.isDefaultArray = opts.isDefaultArray || false;\n    this.gl2 = gl;\n    this.initialize(opts);\n    Object.seal(this);\n  }\n\n  delete() {\n    super.delete();\n\n    if (this.buffer) {\n      this.buffer.delete();\n    }\n\n    return this;\n  }\n\n  get MAX_ATTRIBUTES() {\n    return VertexArrayObject.getMaxAttributes(this.gl);\n  }\n\n  initialize() {\n    let props = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    return this.setProps(props);\n  }\n\n  setProps(props) {\n    return this;\n  }\n\n  setElementBuffer() {\n    let elementBuffer = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : null;\n    let opts = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_3__.assert)(!elementBuffer || elementBuffer.target === 34963, ERR_ELEMENTS);\n    this.bind(() => {\n      this.gl.bindBuffer(34963, elementBuffer ? elementBuffer.handle : null);\n    });\n    return this;\n  }\n\n  setBuffer(location, buffer, accessor) {\n    if (buffer.target === 34963) {\n      return this.setElementBuffer(buffer, accessor);\n    }\n\n    const {\n      size,\n      type,\n      stride,\n      offset,\n      normalized,\n      integer,\n      divisor\n    } = accessor;\n    const {\n      gl,\n      gl2\n    } = this;\n    location = Number(location);\n    this.bind(() => {\n      gl.bindBuffer(34962, buffer.handle);\n\n      if (integer) {\n        (0,_utils_assert__WEBPACK_IMPORTED_MODULE_3__.assert)((0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.isWebGL2)(gl));\n        gl2.vertexAttribIPointer(location, size, type, stride, offset);\n      } else {\n        gl.vertexAttribPointer(location, size, type, normalized, stride, offset);\n      }\n\n      gl.enableVertexAttribArray(location);\n      gl2.vertexAttribDivisor(location, divisor || 0);\n    });\n    return this;\n  }\n\n  enable(location) {\n    let enable = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : true;\n    const disablingAttributeZero = !enable && location === 0 && !VertexArrayObject.isSupported(this.gl, {\n      constantAttributeZero: true\n    });\n\n    if (!disablingAttributeZero) {\n      location = Number(location);\n      this.bind(() => enable ? this.gl.enableVertexAttribArray(location) : this.gl.disableVertexAttribArray(location));\n    }\n\n    return this;\n  }\n\n  getConstantBuffer(elementCount, value) {\n    const constantValue = this._normalizeConstantArrayValue(value);\n\n    const byteLength = constantValue.byteLength * elementCount;\n    const length = constantValue.length * elementCount;\n    let updateNeeded = !this.buffer;\n    this.buffer = this.buffer || new _buffer__WEBPACK_IMPORTED_MODULE_4__[\"default\"](this.gl, byteLength);\n    updateNeeded = updateNeeded || this.buffer.reallocate(byteLength);\n    updateNeeded = updateNeeded || !this._compareConstantArrayValues(constantValue, this.bufferValue);\n\n    if (updateNeeded) {\n      const typedArray = (0,_utils_array_utils_flat__WEBPACK_IMPORTED_MODULE_5__.getScratchArray)(value.constructor, length);\n      (0,_utils_array_utils_flat__WEBPACK_IMPORTED_MODULE_5__.fillArray)({\n        target: typedArray,\n        source: constantValue,\n        start: 0,\n        count: length\n      });\n      this.buffer.subData(typedArray);\n      this.bufferValue = value;\n    }\n\n    return this.buffer;\n  }\n\n  _normalizeConstantArrayValue(arrayValue) {\n    if (Array.isArray(arrayValue)) {\n      return new Float32Array(arrayValue);\n    }\n\n    return arrayValue;\n  }\n\n  _compareConstantArrayValues(v1, v2) {\n    if (!v1 || !v2 || v1.length !== v2.length || v1.constructor !== v2.constructor) {\n      return false;\n    }\n\n    for (let i = 0; i < v1.length; ++i) {\n      if (v1[i] !== v2[i]) {\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n  static _setConstantFloatArray(gl, location, array) {\n    switch (array.length) {\n      case 1:\n        gl.vertexAttrib1fv(location, array);\n        break;\n\n      case 2:\n        gl.vertexAttrib2fv(location, array);\n        break;\n\n      case 3:\n        gl.vertexAttrib3fv(location, array);\n        break;\n\n      case 4:\n        gl.vertexAttrib4fv(location, array);\n        break;\n\n      default:\n        (0,_utils_assert__WEBPACK_IMPORTED_MODULE_3__.assert)(false);\n    }\n  }\n\n  static _setConstantIntArray(gl, location, array) {\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_3__.assert)((0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.isWebGL2)(gl));\n\n    switch (array.length) {\n      case 1:\n        gl.vertexAttribI1iv(location, array);\n        break;\n\n      case 2:\n        gl.vertexAttribI2iv(location, array);\n        break;\n\n      case 3:\n        gl.vertexAttribI3iv(location, array);\n        break;\n\n      case 4:\n        gl.vertexAttribI4iv(location, array);\n        break;\n\n      default:\n        (0,_utils_assert__WEBPACK_IMPORTED_MODULE_3__.assert)(false);\n    }\n  }\n\n  static _setConstantUintArray(gl, location, array) {\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_3__.assert)((0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.isWebGL2)(gl));\n\n    switch (array.length) {\n      case 1:\n        gl.vertexAttribI1uiv(location, array);\n        break;\n\n      case 2:\n        gl.vertexAttribI2uiv(location, array);\n        break;\n\n      case 3:\n        gl.vertexAttribI3uiv(location, array);\n        break;\n\n      case 4:\n        gl.vertexAttribI4uiv(location, array);\n        break;\n\n      default:\n        (0,_utils_assert__WEBPACK_IMPORTED_MODULE_3__.assert)(false);\n    }\n  }\n\n  _createHandle() {\n    const gl2 = this.gl;\n    return gl2.createVertexArray();\n  }\n\n  _deleteHandle(handle) {\n    this.gl2.deleteVertexArray(handle);\n    return [this.elements];\n  }\n\n  _bindHandle(handle) {\n    this.gl2.bindVertexArray(handle);\n  }\n\n  _getParameter(pname, _ref) {\n    let {\n      location\n    } = _ref;\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_3__.assert)(Number.isFinite(location));\n    return this.bind(() => {\n      switch (pname) {\n        case 34373:\n          return this.gl.getVertexAttribOffset(location, pname);\n\n        default:\n          return this.gl.getVertexAttrib(location, pname);\n      }\n    });\n  }\n\n}\n//# sourceMappingURL=vertex-array-object.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/classes/vertex-array-object.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/classes/vertex-array.js":
/*!**********************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/classes/vertex-array.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ VertexArray)\n/* harmony export */ });\n/* harmony import */ var _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/gltools */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n/* harmony import */ var _accessor__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./accessor */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/accessor.js\");\n/* harmony import */ var _buffer__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./buffer */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/buffer.js\");\n/* harmony import */ var _vertex_array_object__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./vertex-array-object */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/vertex-array-object.js\");\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../utils/assert */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js\");\n/* harmony import */ var _utils_stub_methods__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/stub-methods */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/stub-methods.js\");\n\n\n\n\n\n\nconst ERR_ATTRIBUTE_TYPE = 'VertexArray: attributes must be Buffers or constants (i.e. typed array)';\nconst MULTI_LOCATION_ATTRIBUTE_REGEXP = /^(.+)__LOCATION_([0-9]+)$/;\nconst DEPRECATIONS_V6 = ['setBuffers', 'setGeneric', 'clearBindings', 'setLocations', 'setGenericValues', 'setDivisor', 'enable', 'disable'];\nclass VertexArray {\n  constructor(gl) {\n    let opts = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    const id = opts.id || opts.program && opts.program.id;\n    this.id = id;\n    this.gl = gl;\n    this.configuration = null;\n    this.elements = null;\n    this.elementsAccessor = null;\n    this.values = null;\n    this.accessors = null;\n    this.unused = null;\n    this.drawParams = null;\n    this.buffer = null;\n    this.attributes = {};\n    this.vertexArrayObject = new _vertex_array_object__WEBPACK_IMPORTED_MODULE_1__[\"default\"](gl);\n    (0,_utils_stub_methods__WEBPACK_IMPORTED_MODULE_2__.stubRemovedMethods)(this, 'VertexArray', 'v6.0', DEPRECATIONS_V6);\n    this.initialize(opts);\n    Object.seal(this);\n  }\n\n  delete() {\n    if (this.buffer) {\n      this.buffer.delete();\n    }\n\n    this.vertexArrayObject.delete();\n  }\n\n  initialize() {\n    let props = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    this.reset();\n    this.configuration = null;\n    this.bindOnUse = false;\n    return this.setProps(props);\n  }\n\n  reset() {\n    this.elements = null;\n    this.elementsAccessor = null;\n    const {\n      MAX_ATTRIBUTES\n    } = this.vertexArrayObject;\n    this.values = new Array(MAX_ATTRIBUTES).fill(null);\n    this.accessors = new Array(MAX_ATTRIBUTES).fill(null);\n    this.unused = {};\n    this.drawParams = null;\n    return this;\n  }\n\n  setProps(props) {\n    if ('program' in props) {\n      this.configuration = props.program && props.program.configuration;\n    }\n\n    if ('configuration' in props) {\n      this.configuration = props.configuration;\n    }\n\n    if ('attributes' in props) {\n      this.setAttributes(props.attributes);\n    }\n\n    if ('elements' in props) {\n      this.setElementBuffer(props.elements);\n    }\n\n    if ('bindOnUse' in props) {\n      props = props.bindOnUse;\n    }\n\n    return this;\n  }\n\n  clearDrawParams() {\n    this.drawParams = null;\n  }\n\n  getDrawParams() {\n    this.drawParams = this.drawParams || this._updateDrawParams();\n    return this.drawParams;\n  }\n\n  setAttributes(attributes) {\n    Object.assign(this.attributes, attributes);\n    this.vertexArrayObject.bind(() => {\n      for (const locationOrName in attributes) {\n        const value = attributes[locationOrName];\n\n        this._setAttribute(locationOrName, value);\n      }\n\n      this.gl.bindBuffer(34962, null);\n    });\n    return this;\n  }\n\n  setElementBuffer() {\n    let elementBuffer = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : null;\n    let accessor = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    this.elements = elementBuffer;\n    this.elementsAccessor = accessor;\n    this.clearDrawParams();\n    this.vertexArrayObject.setElementBuffer(elementBuffer, accessor);\n    return this;\n  }\n\n  setBuffer(locationOrName, buffer) {\n    let appAccessor = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n\n    if (buffer.target === 34963) {\n      return this.setElementBuffer(buffer, appAccessor);\n    }\n\n    const {\n      location,\n      accessor\n    } = this._resolveLocationAndAccessor(locationOrName, buffer, buffer.accessor, appAccessor);\n\n    if (location >= 0) {\n      this.values[location] = buffer;\n      this.accessors[location] = accessor;\n      this.clearDrawParams();\n      this.vertexArrayObject.setBuffer(location, buffer, accessor);\n    }\n\n    return this;\n  }\n\n  setConstant(locationOrName, arrayValue) {\n    let appAccessor = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n\n    const {\n      location,\n      accessor\n    } = this._resolveLocationAndAccessor(locationOrName, arrayValue, Object.assign({\n      size: arrayValue.length\n    }, appAccessor));\n\n    if (location >= 0) {\n      arrayValue = this.vertexArrayObject._normalizeConstantArrayValue(arrayValue);\n      this.values[location] = arrayValue;\n      this.accessors[location] = accessor;\n      this.clearDrawParams();\n      this.vertexArrayObject.enable(location, false);\n    }\n\n    return this;\n  }\n\n  unbindBuffers() {\n    this.vertexArrayObject.bind(() => {\n      if (this.elements) {\n        this.vertexArrayObject.setElementBuffer(null);\n      }\n\n      this.buffer = this.buffer || new _buffer__WEBPACK_IMPORTED_MODULE_3__[\"default\"](this.gl, {\n        accessor: {\n          size: 4\n        }\n      });\n\n      for (let location = 0; location < this.vertexArrayObject.MAX_ATTRIBUTES; location++) {\n        if (this.values[location] instanceof _buffer__WEBPACK_IMPORTED_MODULE_3__[\"default\"]) {\n          this.gl.disableVertexAttribArray(location);\n          this.gl.bindBuffer(34962, this.buffer.handle);\n          this.gl.vertexAttribPointer(location, 1, 5126, false, 0, 0);\n        }\n      }\n    });\n    return this;\n  }\n\n  bindBuffers() {\n    this.vertexArrayObject.bind(() => {\n      if (this.elements) {\n        this.setElementBuffer(this.elements);\n      }\n\n      for (let location = 0; location < this.vertexArrayObject.MAX_ATTRIBUTES; location++) {\n        const buffer = this.values[location];\n\n        if (buffer instanceof _buffer__WEBPACK_IMPORTED_MODULE_3__[\"default\"]) {\n          this.setBuffer(location, buffer);\n        }\n      }\n    });\n    return this;\n  }\n\n  bindForDraw(vertexCount, instanceCount, func) {\n    let value;\n    this.vertexArrayObject.bind(() => {\n      this._setConstantAttributes(vertexCount, instanceCount);\n\n      value = func();\n    });\n    return value;\n  }\n\n  _resolveLocationAndAccessor(locationOrName, value, valueAccessor, appAccessor) {\n    const INVALID_RESULT = {\n      location: -1,\n      accessor: null\n    };\n\n    const {\n      location,\n      name\n    } = this._getAttributeIndex(locationOrName);\n\n    if (!Number.isFinite(location) || location < 0) {\n      this.unused[locationOrName] = value;\n      _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.once(3, () => \"unused value \".concat(locationOrName, \" in \").concat(this.id))();\n      return INVALID_RESULT;\n    }\n\n    const accessInfo = this._getAttributeInfo(name || location);\n\n    if (!accessInfo) {\n      return INVALID_RESULT;\n    }\n\n    const currentAccessor = this.accessors[location] || {};\n    const accessor = _accessor__WEBPACK_IMPORTED_MODULE_4__[\"default\"].resolve(accessInfo.accessor, currentAccessor, valueAccessor, appAccessor);\n    const {\n      size,\n      type\n    } = accessor;\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_5__.assert)(Number.isFinite(size) && Number.isFinite(type));\n    return {\n      location,\n      accessor\n    };\n  }\n\n  _getAttributeInfo(attributeName) {\n    return this.configuration && this.configuration.getAttributeInfo(attributeName);\n  }\n\n  _getAttributeIndex(locationOrName) {\n    const location = Number(locationOrName);\n\n    if (Number.isFinite(location)) {\n      return {\n        location\n      };\n    }\n\n    const multiLocation = MULTI_LOCATION_ATTRIBUTE_REGEXP.exec(locationOrName);\n    const name = multiLocation ? multiLocation[1] : locationOrName;\n    const locationOffset = multiLocation ? Number(multiLocation[2]) : 0;\n\n    if (this.configuration) {\n      return {\n        location: this.configuration.getAttributeLocation(name) + locationOffset,\n        name\n      };\n    }\n\n    return {\n      location: -1\n    };\n  }\n\n  _setAttribute(locationOrName, value) {\n    if (value instanceof _buffer__WEBPACK_IMPORTED_MODULE_3__[\"default\"]) {\n      this.setBuffer(locationOrName, value);\n    } else if (Array.isArray(value) && value.length && value[0] instanceof _buffer__WEBPACK_IMPORTED_MODULE_3__[\"default\"]) {\n      const buffer = value[0];\n      const accessor = value[1];\n      this.setBuffer(locationOrName, buffer, accessor);\n    } else if (ArrayBuffer.isView(value) || Array.isArray(value)) {\n      const constant = value;\n      this.setConstant(locationOrName, constant);\n    } else if (value.buffer instanceof _buffer__WEBPACK_IMPORTED_MODULE_3__[\"default\"]) {\n      const accessor = value;\n      this.setBuffer(locationOrName, accessor.buffer, accessor);\n    } else {\n      throw new Error(ERR_ATTRIBUTE_TYPE);\n    }\n  }\n\n  _setConstantAttributes(vertexCount, instanceCount) {\n    const elementCount = Math.max(vertexCount | 0, instanceCount | 0);\n    let constant = this.values[0];\n\n    if (ArrayBuffer.isView(constant)) {\n      this._setConstantAttributeZero(constant, elementCount);\n    }\n\n    for (let location = 1; location < this.vertexArrayObject.MAX_ATTRIBUTES; location++) {\n      constant = this.values[location];\n\n      if (ArrayBuffer.isView(constant)) {\n        this._setConstantAttribute(location, constant);\n      }\n    }\n  }\n\n  _setConstantAttributeZero(constant, elementCount) {\n    if (_vertex_array_object__WEBPACK_IMPORTED_MODULE_1__[\"default\"].isSupported(this.gl, {\n      constantAttributeZero: true\n    })) {\n      this._setConstantAttribute(0, constant);\n\n      return;\n    }\n\n    const buffer = this.vertexArrayObject.getConstantBuffer(elementCount, constant);\n    this.vertexArrayObject.setBuffer(0, buffer, this.accessors[0]);\n  }\n\n  _setConstantAttribute(location, constant) {\n    _vertex_array_object__WEBPACK_IMPORTED_MODULE_1__[\"default\"].setConstant(this.gl, location, constant);\n  }\n\n  _updateDrawParams() {\n    const drawParams = {\n      isIndexed: false,\n      isInstanced: false,\n      indexCount: Infinity,\n      vertexCount: Infinity,\n      instanceCount: Infinity\n    };\n\n    for (let location = 0; location < this.vertexArrayObject.MAX_ATTRIBUTES; location++) {\n      this._updateDrawParamsForLocation(drawParams, location);\n    }\n\n    if (this.elements) {\n      drawParams.elementCount = this.elements.getElementCount(this.elements.accessor);\n      drawParams.isIndexed = true;\n      drawParams.indexType = this.elementsAccessor.type || this.elements.accessor.type;\n      drawParams.indexOffset = this.elementsAccessor.offset || 0;\n    }\n\n    if (drawParams.indexCount === Infinity) {\n      drawParams.indexCount = 0;\n    }\n\n    if (drawParams.vertexCount === Infinity) {\n      drawParams.vertexCount = 0;\n    }\n\n    if (drawParams.instanceCount === Infinity) {\n      drawParams.instanceCount = 0;\n    }\n\n    return drawParams;\n  }\n\n  _updateDrawParamsForLocation(drawParams, location) {\n    const value = this.values[location];\n    const accessor = this.accessors[location];\n\n    if (!value) {\n      return;\n    }\n\n    const {\n      divisor\n    } = accessor;\n    const isInstanced = divisor > 0;\n    drawParams.isInstanced = drawParams.isInstanced || isInstanced;\n\n    if (value instanceof _buffer__WEBPACK_IMPORTED_MODULE_3__[\"default\"]) {\n      const buffer = value;\n\n      if (isInstanced) {\n        const instanceCount = buffer.getVertexCount(accessor);\n        drawParams.instanceCount = Math.min(drawParams.instanceCount, instanceCount);\n      } else {\n        const vertexCount = buffer.getVertexCount(accessor);\n        drawParams.vertexCount = Math.min(drawParams.vertexCount, vertexCount);\n      }\n    }\n  }\n\n  setElements() {\n    let elementBuffer = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : null;\n    let accessor = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.deprecated('setElements', 'setElementBuffer')();\n    return this.setElementBuffer(elementBuffer, accessor);\n  }\n\n}\n//# sourceMappingURL=vertex-array.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/classes/vertex-array.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/debug/debug-program-configuration.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/debug/debug-program-configuration.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getDebugTableForProgramConfiguration: () => (/* binding */ getDebugTableForProgramConfiguration)\n/* harmony export */ });\n/* harmony import */ var _webgl_utils_attribute_utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../webgl-utils/attribute-utils */ \"./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/attribute-utils.js\");\n\nfunction getDebugTableForProgramConfiguration(config) {\n  const table = {};\n  const header = \"Accessors for \".concat(config.id);\n\n  for (const attributeInfo of config.attributeInfos) {\n    if (attributeInfo) {\n      const glslDeclaration = getGLSLDeclaration(attributeInfo);\n      table[\"in \".concat(glslDeclaration)] = {\n        [header]: JSON.stringify(attributeInfo.accessor)\n      };\n    }\n  }\n\n  for (const varyingInfo of config.varyingInfos) {\n    if (varyingInfo) {\n      const glslDeclaration = getGLSLDeclaration(varyingInfo);\n      table[\"out \".concat(glslDeclaration)] = {\n        [header]: JSON.stringify(varyingInfo.accessor)\n      };\n    }\n  }\n\n  return table;\n}\n\nfunction getGLSLDeclaration(attributeInfo) {\n  const {\n    type,\n    size\n  } = attributeInfo.accessor;\n  const typeAndName = (0,_webgl_utils_attribute_utils__WEBPACK_IMPORTED_MODULE_0__.getCompositeGLType)(type, size);\n\n  if (typeAndName) {\n    return \"\".concat(typeAndName.name, \" \").concat(attributeInfo.name);\n  }\n\n  return attributeInfo.name;\n}\n//# sourceMappingURL=debug-program-configuration.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/debug/debug-program-configuration.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/debug/debug-uniforms.js":
/*!**********************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/debug/debug-uniforms.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getDebugTableForUniforms: () => (/* binding */ getDebugTableForUniforms)\n/* harmony export */ });\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/assert */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js\");\n/* harmony import */ var _utils_format_value__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/format-value */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/format-value.js\");\n\n\nfunction getDebugTableForUniforms(_ref) {\n  let {\n    header = 'Uniforms',\n    program,\n    uniforms,\n    undefinedOnly = false\n  } = _ref;\n  (0,_utils_assert__WEBPACK_IMPORTED_MODULE_0__.assert)(program);\n  const SHADER_MODULE_UNIFORM_REGEXP = '.*_.*';\n  const PROJECT_MODULE_UNIFORM_REGEXP = '.*Matrix';\n  const uniformLocations = program._uniformSetters;\n  const table = {};\n  const uniformNames = Object.keys(uniformLocations).sort();\n  let count = 0;\n\n  for (const uniformName of uniformNames) {\n    if (!uniformName.match(SHADER_MODULE_UNIFORM_REGEXP) && !uniformName.match(PROJECT_MODULE_UNIFORM_REGEXP)) {\n      if (addUniformToTable({\n        table,\n        header,\n        uniforms,\n        uniformName,\n        undefinedOnly\n      })) {\n        count++;\n      }\n    }\n  }\n\n  for (const uniformName of uniformNames) {\n    if (uniformName.match(PROJECT_MODULE_UNIFORM_REGEXP)) {\n      if (addUniformToTable({\n        table,\n        header,\n        uniforms,\n        uniformName,\n        undefinedOnly\n      })) {\n        count++;\n      }\n    }\n  }\n\n  for (const uniformName of uniformNames) {\n    if (!table[uniformName]) {\n      if (addUniformToTable({\n        table,\n        header,\n        uniforms,\n        uniformName,\n        undefinedOnly\n      })) {\n        count++;\n      }\n    }\n  }\n\n  let unusedCount = 0;\n  const unusedTable = {};\n\n  if (!undefinedOnly) {\n    for (const uniformName in uniforms) {\n      const uniform = uniforms[uniformName];\n\n      if (!table[uniformName]) {\n        unusedCount++;\n        unusedTable[uniformName] = {\n          Type: \"NOT USED: \".concat(uniform),\n          [header]: (0,_utils_format_value__WEBPACK_IMPORTED_MODULE_1__.formatValue)(uniform)\n        };\n      }\n    }\n  }\n\n  return {\n    table,\n    count,\n    unusedTable,\n    unusedCount\n  };\n}\n\nfunction addUniformToTable(_ref2) {\n  let {\n    table,\n    header,\n    uniforms,\n    uniformName,\n    undefinedOnly\n  } = _ref2;\n  const value = uniforms[uniformName];\n  const isDefined = isUniformDefined(value);\n\n  if (!undefinedOnly || !isDefined) {\n    table[uniformName] = {\n      [header]: isDefined ? (0,_utils_format_value__WEBPACK_IMPORTED_MODULE_1__.formatValue)(value) : 'N/A',\n      'Uniform Type': isDefined ? value : 'NOT PROVIDED'\n    };\n    return true;\n  }\n\n  return false;\n}\n\nfunction isUniformDefined(value) {\n  return value !== undefined && value !== null;\n}\n//# sourceMappingURL=debug-uniforms.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/debug/debug-uniforms.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/debug/debug-vertex-array.js":
/*!**************************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/debug/debug-vertex-array.js ***!
  \**************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getDebugTableForVertexArray: () => (/* binding */ getDebugTableForVertexArray)\n/* harmony export */ });\n/* harmony import */ var _classes_buffer__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../classes/buffer */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/buffer.js\");\n/* harmony import */ var _webgl_utils_constants_to_keys__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../webgl-utils/constants-to-keys */ \"./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/constants-to-keys.js\");\n/* harmony import */ var _webgl_utils_attribute_utils__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../webgl-utils/attribute-utils */ \"./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/attribute-utils.js\");\n/* harmony import */ var _utils_format_value__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/format-value */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/format-value.js\");\n\n\n\n\nfunction getDebugTableForVertexArray(_ref) {\n  let {\n    vertexArray,\n    header = 'Attributes'\n  } = _ref;\n\n  if (!vertexArray.configuration) {\n    return {};\n  }\n\n  const table = {};\n\n  if (vertexArray.elements) {\n    table.ELEMENT_ARRAY_BUFFER = getDebugTableRow(vertexArray, vertexArray.elements, null, header);\n  }\n\n  const attributes = vertexArray.values;\n\n  for (const attributeLocation in attributes) {\n    const info = vertexArray._getAttributeInfo(attributeLocation);\n\n    if (info) {\n      let rowHeader = \"\".concat(attributeLocation, \": \").concat(info.name);\n      const accessor = vertexArray.accessors[info.location];\n\n      if (accessor) {\n        rowHeader = \"\".concat(attributeLocation, \": \").concat(getGLSLDeclaration(info.name, accessor));\n      }\n\n      table[rowHeader] = getDebugTableRow(vertexArray, attributes[attributeLocation], accessor, header);\n    }\n  }\n\n  return table;\n}\n\nfunction getDebugTableRow(vertexArray, attribute, accessor, header) {\n  const {\n    gl\n  } = vertexArray;\n\n  if (!attribute) {\n    return {\n      [header]: 'null',\n      'Format ': 'N/A'\n    };\n  }\n\n  let type = 'NOT PROVIDED';\n  let size = 1;\n  let verts = 0;\n  let bytes = 0;\n  let isInteger;\n  let marker;\n  let value;\n\n  if (accessor) {\n    type = accessor.type;\n    size = accessor.size;\n    type = String(type).replace('Array', '');\n    isInteger = type.indexOf('nt') !== -1;\n  }\n\n  if (attribute instanceof _classes_buffer__WEBPACK_IMPORTED_MODULE_0__[\"default\"]) {\n    const buffer = attribute;\n    const {\n      data,\n      changed\n    } = buffer.getDebugData();\n    marker = changed ? '*' : '';\n    value = data;\n    bytes = buffer.byteLength;\n    verts = bytes / data.BYTES_PER_ELEMENT / size;\n    let format;\n\n    if (accessor) {\n      const instanced = accessor.divisor > 0;\n      format = \"\".concat(instanced ? 'I ' : 'P ', \" \").concat(verts, \" (x\").concat(size, \"=\").concat(bytes, \" bytes \").concat((0,_webgl_utils_constants_to_keys__WEBPACK_IMPORTED_MODULE_1__.getKey)(gl, type), \")\");\n    } else {\n      isInteger = true;\n      format = \"\".concat(bytes, \" bytes\");\n    }\n\n    return {\n      [header]: \"\".concat(marker).concat((0,_utils_format_value__WEBPACK_IMPORTED_MODULE_2__.formatValue)(value, {\n        size,\n        isInteger\n      })),\n      'Format ': format\n    };\n  }\n\n  value = attribute;\n  size = attribute.length;\n  type = String(attribute.constructor.name).replace('Array', '');\n  isInteger = type.indexOf('nt') !== -1;\n  return {\n    [header]: \"\".concat((0,_utils_format_value__WEBPACK_IMPORTED_MODULE_2__.formatValue)(value, {\n      size,\n      isInteger\n    }), \" (constant)\"),\n    'Format ': \"\".concat(size, \"x\").concat(type, \" (constant)\")\n  };\n}\n\nfunction getGLSLDeclaration(name, accessor) {\n  const {\n    type,\n    size\n  } = accessor;\n  const typeAndName = (0,_webgl_utils_attribute_utils__WEBPACK_IMPORTED_MODULE_3__.getCompositeGLType)(type, size);\n  return typeAndName ? \"\".concat(name, \" (\").concat(typeAndName.name, \")\") : name;\n}\n//# sourceMappingURL=debug-vertex-array.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/debug/debug-vertex-array.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/features/features.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/features/features.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getFeatures: () => (/* binding */ getFeatures),\n/* harmony export */   hasFeature: () => (/* binding */ hasFeature),\n/* harmony export */   hasFeatures: () => (/* binding */ hasFeatures)\n/* harmony export */ });\n/* harmony import */ var _webgl_features_table__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./webgl-features-table */ \"./node_modules/@luma.gl/webgl/dist/esm/features/webgl-features-table.js\");\n/* harmony import */ var _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/gltools */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/assert */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js\");\n\n\n\nconst LOG_UNSUPPORTED_FEATURE = 2;\nfunction hasFeature(gl, feature) {\n  return hasFeatures(gl, feature);\n}\nfunction hasFeatures(gl, features) {\n  features = Array.isArray(features) ? features : [features];\n  return features.every(feature => {\n    return isFeatureSupported(gl, feature);\n  });\n}\nfunction getFeatures(gl) {\n  gl.luma = gl.luma || {};\n  gl.luma.caps = gl.luma.caps || {};\n\n  for (const cap in _webgl_features_table__WEBPACK_IMPORTED_MODULE_1__[\"default\"]) {\n    if (gl.luma.caps[cap] === undefined) {\n      gl.luma.caps[cap] = isFeatureSupported(gl, cap);\n    }\n  }\n\n  return gl.luma.caps;\n}\n\nfunction isFeatureSupported(gl, cap) {\n  gl.luma = gl.luma || {};\n  gl.luma.caps = gl.luma.caps || {};\n\n  if (gl.luma.caps[cap] === undefined) {\n    gl.luma.caps[cap] = queryFeature(gl, cap);\n  }\n\n  if (!gl.luma.caps[cap]) {\n    _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.log(LOG_UNSUPPORTED_FEATURE, \"Feature: \".concat(cap, \" not supported\"))();\n  }\n\n  return gl.luma.caps[cap];\n}\n\nfunction queryFeature(gl, cap) {\n  const feature = _webgl_features_table__WEBPACK_IMPORTED_MODULE_1__[\"default\"][cap];\n  (0,_utils_assert__WEBPACK_IMPORTED_MODULE_2__.assert)(feature, cap);\n  let isSupported;\n  const featureDefinition = (0,_luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.isWebGL2)(gl) ? feature[1] || feature[0] : feature[0];\n\n  if (typeof featureDefinition === 'function') {\n    isSupported = featureDefinition(gl);\n  } else if (Array.isArray(featureDefinition)) {\n    isSupported = true;\n\n    for (const extension of featureDefinition) {\n      isSupported = isSupported && Boolean(gl.getExtension(extension));\n    }\n  } else if (typeof featureDefinition === 'string') {\n    isSupported = Boolean(gl.getExtension(featureDefinition));\n  } else if (typeof featureDefinition === 'boolean') {\n    isSupported = featureDefinition;\n  } else {\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_2__.assert)(false);\n  }\n\n  return isSupported;\n}\n//# sourceMappingURL=features.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/features/features.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/features/webgl-features-table.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/features/webgl-features-table.js ***!
  \*******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   FEATURES: () => (/* binding */ FEATURES),\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _classes_framebuffer__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../classes/framebuffer */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/framebuffer.js\");\n/* harmony import */ var _classes_texture_2d__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../classes/texture-2d */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/texture-2d.js\");\n\n\nconst FEATURES = {\n  WEBGL2: 'WEBGL2',\n  VERTEX_ARRAY_OBJECT: 'VERTEX_ARRAY_OBJECT',\n  TIMER_QUERY: 'TIMER_QUERY',\n  INSTANCED_RENDERING: 'INSTANCED_RENDERING',\n  MULTIPLE_RENDER_TARGETS: 'MULTIPLE_RENDER_TARGETS',\n  ELEMENT_INDEX_UINT32: 'ELEMENT_INDEX_UINT32',\n  BLEND_EQUATION_MINMAX: 'BLEND_EQUATION_MINMAX',\n  FLOAT_BLEND: 'FLOAT_BLEND',\n  COLOR_ENCODING_SRGB: 'COLOR_ENCODING_SRGB',\n  TEXTURE_DEPTH: 'TEXTURE_DEPTH',\n  TEXTURE_FLOAT: 'TEXTURE_FLOAT',\n  TEXTURE_HALF_FLOAT: 'TEXTURE_HALF_FLOAT',\n  TEXTURE_FILTER_LINEAR_FLOAT: 'TEXTURE_FILTER_LINEAR_FLOAT',\n  TEXTURE_FILTER_LINEAR_HALF_FLOAT: 'TEXTURE_FILTER_LINEAR_HALF_FLOAT',\n  TEXTURE_FILTER_ANISOTROPIC: 'TEXTURE_FILTER_ANISOTROPIC',\n  COLOR_ATTACHMENT_RGBA32F: 'COLOR_ATTACHMENT_RGBA32F',\n  COLOR_ATTACHMENT_FLOAT: 'COLOR_ATTACHMENT_FLOAT',\n  COLOR_ATTACHMENT_HALF_FLOAT: 'COLOR_ATTACHMENT_HALF_FLOAT',\n  GLSL_FRAG_DATA: 'GLSL_FRAG_DATA',\n  GLSL_FRAG_DEPTH: 'GLSL_FRAG_DEPTH',\n  GLSL_DERIVATIVES: 'GLSL_DERIVATIVES',\n  GLSL_TEXTURE_LOD: 'GLSL_TEXTURE_LOD'\n};\n\nfunction checkFloat32ColorAttachment(gl) {\n  const testTexture = new _classes_texture_2d__WEBPACK_IMPORTED_MODULE_0__[\"default\"](gl, {\n    format: 6408,\n    type: 5126,\n    dataFormat: 6408\n  });\n  const testFb = new _classes_framebuffer__WEBPACK_IMPORTED_MODULE_1__[\"default\"](gl, {\n    id: \"test-framebuffer\",\n    check: false,\n    attachments: {\n      [36064]: testTexture\n    }\n  });\n  const status = testFb.getStatus();\n  testTexture.delete();\n  testFb.delete();\n  return status === 36053;\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ({\n  [FEATURES.WEBGL2]: [false, true],\n  [FEATURES.VERTEX_ARRAY_OBJECT]: ['OES_vertex_array_object', true],\n  [FEATURES.TIMER_QUERY]: ['EXT_disjoint_timer_query', 'EXT_disjoint_timer_query_webgl2'],\n  [FEATURES.INSTANCED_RENDERING]: ['ANGLE_instanced_arrays', true],\n  [FEATURES.MULTIPLE_RENDER_TARGETS]: ['WEBGL_draw_buffers', true],\n  [FEATURES.ELEMENT_INDEX_UINT32]: ['OES_element_index_uint', true],\n  [FEATURES.BLEND_EQUATION_MINMAX]: ['EXT_blend_minmax', true],\n  [FEATURES.FLOAT_BLEND]: ['EXT_float_blend'],\n  [FEATURES.COLOR_ENCODING_SRGB]: ['EXT_sRGB', true],\n  [FEATURES.TEXTURE_DEPTH]: ['WEBGL_depth_texture', true],\n  [FEATURES.TEXTURE_FLOAT]: ['OES_texture_float', true],\n  [FEATURES.TEXTURE_HALF_FLOAT]: ['OES_texture_half_float', true],\n  [FEATURES.TEXTURE_FILTER_LINEAR_FLOAT]: ['OES_texture_float_linear'],\n  [FEATURES.TEXTURE_FILTER_LINEAR_HALF_FLOAT]: ['OES_texture_half_float_linear'],\n  [FEATURES.TEXTURE_FILTER_ANISOTROPIC]: ['EXT_texture_filter_anisotropic'],\n  [FEATURES.COLOR_ATTACHMENT_RGBA32F]: [checkFloat32ColorAttachment, 'EXT_color_buffer_float'],\n  [FEATURES.COLOR_ATTACHMENT_FLOAT]: [false, 'EXT_color_buffer_float'],\n  [FEATURES.COLOR_ATTACHMENT_HALF_FLOAT]: ['EXT_color_buffer_half_float'],\n  [FEATURES.GLSL_FRAG_DATA]: ['WEBGL_draw_buffers', true],\n  [FEATURES.GLSL_FRAG_DEPTH]: ['EXT_frag_depth', true],\n  [FEATURES.GLSL_DERIVATIVES]: ['OES_standard_derivatives', true],\n  [FEATURES.GLSL_TEXTURE_LOD]: ['EXT_shader_texture_lod', true]\n});\n//# sourceMappingURL=webgl-features-table.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/features/webgl-features-table.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/glsl-utils/format-glsl-error.js":
/*!******************************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/glsl-utils/format-glsl-error.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ formatGLSLCompilerError),\n/* harmony export */   parseGLSLCompilerError: () => (/* binding */ parseGLSLCompilerError)\n/* harmony export */ });\n/* harmony import */ var _get_shader_name__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./get-shader-name */ \"./node_modules/@luma.gl/webgl/dist/esm/glsl-utils/get-shader-name.js\");\n/* harmony import */ var _get_shader_type_name__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./get-shader-type-name */ \"./node_modules/@luma.gl/webgl/dist/esm/glsl-utils/get-shader-type-name.js\");\n\n\nfunction formatGLSLCompilerError(errLog, src, shaderType) {\n  const {\n    shaderName,\n    errors,\n    warnings\n  } = parseGLSLCompilerError(errLog, src, shaderType);\n  return \"GLSL compilation error in \".concat(shaderName, \"\\n\\n\").concat(errors, \"\\n\").concat(warnings);\n}\nfunction parseGLSLCompilerError(errLog, src, shaderType, shaderName) {\n  const errorStrings = errLog.split(/\\r?\\n/);\n  const errors = {};\n  const warnings = {};\n  const name = shaderName || (0,_get_shader_name__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(src) || '(unnamed)';\n  const shaderDescription = \"\".concat((0,_get_shader_type_name__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(shaderType), \" shader \").concat(name);\n\n  for (let i = 0; i < errorStrings.length; i++) {\n    const errorString = errorStrings[i];\n\n    if (errorString.length <= 1) {\n      continue;\n    }\n\n    const segments = errorString.split(':');\n    const type = segments[0];\n    const line = parseInt(segments[2], 10);\n\n    if (isNaN(line)) {\n      throw new Error(\"GLSL compilation error in \".concat(shaderDescription, \": \").concat(errLog));\n    }\n\n    if (type !== 'WARNING') {\n      errors[line] = errorString;\n    } else {\n      warnings[line] = errorString;\n    }\n  }\n\n  const lines = addLineNumbers(src);\n  return {\n    shaderName: shaderDescription,\n    errors: formatErrors(errors, lines),\n    warnings: formatErrors(warnings, lines)\n  };\n}\n\nfunction formatErrors(errors, lines) {\n  let message = '';\n\n  for (let i = 0; i < lines.length; i++) {\n    const line = lines[i];\n\n    if (!errors[i + 3] && !errors[i + 2] && !errors[i + 1]) {\n      continue;\n    }\n\n    message += \"\".concat(line, \"\\n\");\n\n    if (errors[i + 1]) {\n      const error = errors[i + 1];\n      const segments = error.split(':', 3);\n      const type = segments[0];\n      const column = parseInt(segments[1], 10) || 0;\n      const err = error.substring(segments.join(':').length + 1).trim();\n      message += padLeft(\"^^^ \".concat(type, \": \").concat(err, \"\\n\\n\"), column);\n    }\n  }\n\n  return message;\n}\n\nfunction addLineNumbers(string) {\n  let start = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;\n  let delim = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : ': ';\n  const lines = string.split(/\\r?\\n/);\n  const maxDigits = String(lines.length + start - 1).length;\n  return lines.map((line, i) => {\n    const lineNumber = String(i + start);\n    const digits = lineNumber.length;\n    const prefix = padLeft(lineNumber, maxDigits - digits);\n    return prefix + delim + line;\n  });\n}\n\nfunction padLeft(string, digits) {\n  let result = '';\n\n  for (let i = 0; i < digits; ++i) {\n    result += ' ';\n  }\n\n  return \"\".concat(result).concat(string);\n}\n//# sourceMappingURL=format-glsl-error.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/glsl-utils/format-glsl-error.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/glsl-utils/get-shader-name.js":
/*!****************************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/glsl-utils/get-shader-name.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ getShaderName)\n/* harmony export */ });\nfunction getShaderName(shader) {\n  let defaultName = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 'unnamed';\n  const SHADER_NAME_REGEXP = /#define[\\s*]SHADER_NAME[\\s*]([A-Za-z0-9_-]+)[\\s*]/;\n  const match = shader.match(SHADER_NAME_REGEXP);\n  return match ? match[1] : defaultName;\n}\n//# sourceMappingURL=get-shader-name.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/glsl-utils/get-shader-name.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/glsl-utils/get-shader-type-name.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/glsl-utils/get-shader-type-name.js ***!
  \*********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ getShaderTypeName)\n/* harmony export */ });\nconst GL_FRAGMENT_SHADER = 0x8b30;\nconst GL_VERTEX_SHADER = 0x8b31;\nfunction getShaderTypeName(type) {\n  switch (type) {\n    case GL_FRAGMENT_SHADER:\n      return 'fragment';\n\n    case GL_VERTEX_SHADER:\n      return 'vertex';\n\n    default:\n      return 'unknown type';\n  }\n}\n//# sourceMappingURL=get-shader-type-name.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/glsl-utils/get-shader-type-name.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/glsl-utils/get-shader-version.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/glsl-utils/get-shader-version.js ***!
  \*******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ getShaderVersion)\n/* harmony export */ });\nfunction getShaderVersion(source) {\n  let version = 100;\n  const words = source.match(/[^\\s]+/g);\n\n  if (words.length >= 2 && words[0] === '#version') {\n    const v = parseInt(words[1], 10);\n\n    if (Number.isFinite(v)) {\n      version = v;\n    }\n  }\n\n  return version;\n}\n//# sourceMappingURL=get-shader-version.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/glsl-utils/get-shader-version.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/init.js":
/*!******************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/init.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   StatsManager: () => (/* binding */ StatsManager),\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__),\n/* harmony export */   lumaStats: () => (/* binding */ lumaStats)\n/* harmony export */ });\n/* harmony import */ var _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/gltools */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n/* harmony import */ var _probe_gl_stats__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @probe.gl/stats */ \"./node_modules/@probe.gl/stats/dist/esm/index.js\");\n/* harmony import */ var _probe_gl_env__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @probe.gl/env */ \"./node_modules/@probe.gl/env/dist/esm/lib/is-browser.js\");\n\n\n\nconst VERSION =  true ? \"8.5.21\" : 0;\nconst STARTUP_MESSAGE = 'set luma.log.level=1 (or higher) to trace rendering';\nclass StatsManager {\n  constructor() {\n    this.stats = new Map();\n  }\n\n  get(name) {\n    if (!this.stats.has(name)) {\n      this.stats.set(name, new _probe_gl_stats__WEBPACK_IMPORTED_MODULE_1__.Stats({\n        id: name\n      }));\n    }\n\n    return this.stats.get(name);\n  }\n\n}\nconst lumaStats = new StatsManager();\n\nif (globalThis.luma && globalThis.luma.VERSION !== VERSION) {\n  throw new Error(\"luma.gl - multiple VERSIONs detected: \".concat(globalThis.luma.VERSION, \" vs \").concat(VERSION));\n}\n\nif (!globalThis.luma) {\n  if ((0,_probe_gl_env__WEBPACK_IMPORTED_MODULE_2__[\"default\"])()) {\n    _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.log(1, \"luma.gl \".concat(VERSION, \" - \").concat(STARTUP_MESSAGE))();\n  }\n\n  globalThis.luma = globalThis.luma || {\n    VERSION,\n    version: VERSION,\n    log: _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log,\n    stats: lumaStats,\n    globals: {\n      modules: {},\n      nodeIO: {}\n    }\n  };\n}\n\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (globalThis.luma);\n//# sourceMappingURL=init.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/init.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/utils/array-utils-flat.js":
/*!************************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/utils/array-utils-flat.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   fillArray: () => (/* binding */ fillArray),\n/* harmony export */   getScratchArray: () => (/* binding */ getScratchArray),\n/* harmony export */   getScratchArrayBuffer: () => (/* binding */ getScratchArrayBuffer)\n/* harmony export */ });\nlet arrayBuffer = null;\nfunction getScratchArrayBuffer(byteLength) {\n  if (!arrayBuffer || arrayBuffer.byteLength < byteLength) {\n    arrayBuffer = new ArrayBuffer(byteLength);\n  }\n\n  return arrayBuffer;\n}\nfunction getScratchArray(Type, length) {\n  const scratchArrayBuffer = getScratchArrayBuffer(Type.BYTES_PER_ELEMENT * length);\n  return new Type(scratchArrayBuffer, 0, length);\n}\nfunction fillArray(_ref) {\n  let {\n    target,\n    source,\n    start = 0,\n    count = 1\n  } = _ref;\n  const length = source.length;\n  const total = count * length;\n  let copied = 0;\n\n  for (let i = start; copied < length; copied++) {\n    target[i++] = source[copied];\n  }\n\n  while (copied < total) {\n    if (copied < total - copied) {\n      target.copyWithin(start + copied, start, start + copied);\n      copied *= 2;\n    } else {\n      target.copyWithin(start + copied, start, start + total - copied);\n      copied = total;\n    }\n  }\n\n  return target;\n}\n//# sourceMappingURL=array-utils-flat.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/utils/array-utils-flat.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js":
/*!**************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   assert: () => (/* binding */ assert)\n/* harmony export */ });\nfunction assert(condition, message) {\n  if (!condition) {\n    throw new Error(message || 'luma.gl: assertion failed.');\n  }\n}\n//# sourceMappingURL=assert.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/utils/check-props.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/utils/check-props.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   checkProps: () => (/* binding */ checkProps)\n/* harmony export */ });\n/* harmony import */ var _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/gltools */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n\nfunction checkProps(className, props, propChecks) {\n  const {\n    removedProps = {},\n    deprecatedProps = {},\n    replacedProps = {}\n  } = propChecks;\n\n  for (const propName in removedProps) {\n    if (propName in props) {\n      const replacementProp = removedProps[propName];\n      const replacement = replacementProp ? \"\".concat(className, \".\").concat(removedProps[propName]) : 'N/A';\n      _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.removed(\"\".concat(className, \".\").concat(propName), replacement)();\n    }\n  }\n\n  for (const propName in deprecatedProps) {\n    if (propName in props) {\n      const replacementProp = deprecatedProps[propName];\n      _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.deprecated(\"\".concat(className, \".\").concat(propName), \"\".concat(className, \".\").concat(replacementProp))();\n    }\n  }\n\n  let newProps = null;\n\n  for (const propName in replacedProps) {\n    if (propName in props) {\n      const replacementProp = replacedProps[propName];\n      _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.deprecated(\"\".concat(className, \".\").concat(propName), \"\".concat(className, \".\").concat(replacementProp))();\n      newProps = newProps || Object.assign({}, props);\n      newProps[replacementProp] = props[propName];\n      delete newProps[propName];\n    }\n  }\n\n  return newProps || props;\n}\n//# sourceMappingURL=check-props.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/utils/check-props.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/utils/format-value.js":
/*!********************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/utils/format-value.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   formatValue: () => (/* binding */ formatValue)\n/* harmony export */ });\nfunction formatArrayValue(v, opts) {\n  const {\n    maxElts = 16,\n    size = 1\n  } = opts;\n  let string = '[';\n\n  for (let i = 0; i < v.length && i < maxElts; ++i) {\n    if (i > 0) {\n      string += \",\".concat(i % size === 0 ? ' ' : '');\n    }\n\n    string += formatValue(v[i], opts);\n  }\n\n  const terminator = v.length > maxElts ? '...' : ']';\n  return \"\".concat(string).concat(terminator);\n}\n\nfunction formatValue(v) {\n  let opts = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  const EPSILON = 1e-16;\n  const {\n    isInteger = false\n  } = opts;\n\n  if (Array.isArray(v) || ArrayBuffer.isView(v)) {\n    return formatArrayValue(v, opts);\n  }\n\n  if (!Number.isFinite(v)) {\n    return String(v);\n  }\n\n  if (Math.abs(v) < EPSILON) {\n    return isInteger ? '0' : '0.';\n  }\n\n  if (isInteger) {\n    return v.toFixed(0);\n  }\n\n  if (Math.abs(v) > 100 && Math.abs(v) < 10000) {\n    return v.toFixed(0);\n  }\n\n  const string = v.toPrecision(2);\n  const decimal = string.indexOf('.0');\n  return decimal === string.length - 2 ? string.slice(0, -1) : string;\n}\n//# sourceMappingURL=format-value.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/utils/format-value.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/utils/load-file.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/utils/load-file.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   loadFile: () => (/* binding */ loadFile),\n/* harmony export */   loadImage: () => (/* binding */ loadImage),\n/* harmony export */   setPathPrefix: () => (/* binding */ setPathPrefix)\n/* harmony export */ });\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/assert */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js\");\n\nlet pathPrefix = '';\nfunction setPathPrefix(prefix) {\n  pathPrefix = prefix;\n}\nfunction loadFile(url) {\n  let options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  (0,_utils_assert__WEBPACK_IMPORTED_MODULE_0__.assert)(typeof url === 'string');\n  url = pathPrefix + url;\n  const dataType = options.dataType || 'text';\n  return fetch(url, options).then(res => res[dataType]());\n}\nfunction loadImage(url, opts) {\n  (0,_utils_assert__WEBPACK_IMPORTED_MODULE_0__.assert)(typeof url === 'string');\n  url = pathPrefix + url;\n  return new Promise((resolve, reject) => {\n    try {\n      const image = new Image();\n\n      image.onload = () => resolve(image);\n\n      image.onerror = () => reject(new Error(\"Could not load image \".concat(url, \".\")));\n\n      image.crossOrigin = opts && opts.crossOrigin || 'anonymous';\n      image.src = url;\n    } catch (error) {\n      reject(error);\n    }\n  });\n}\n//# sourceMappingURL=load-file.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/utils/load-file.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/utils/stub-methods.js":
/*!********************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/utils/stub-methods.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   stubRemovedMethods: () => (/* binding */ stubRemovedMethods)\n/* harmony export */ });\n/* harmony import */ var _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @luma.gl/gltools */ \"./node_modules/@luma.gl/gltools/dist/esm/index.js\");\n\nfunction stubRemovedMethods(instance, className, version, methodNames) {\n  const upgradeMessage = \"See luma.gl \".concat(version, \" Upgrade Guide at https://luma.gl/docs/upgrade-guide\");\n  const prototype = Object.getPrototypeOf(instance);\n  methodNames.forEach(methodName => {\n    if (prototype.methodName) {\n      return;\n    }\n\n    prototype[methodName] = () => {\n      _luma_gl_gltools__WEBPACK_IMPORTED_MODULE_0__.log.removed(\"Calling removed method \".concat(className, \".\").concat(methodName, \": \"), upgradeMessage)();\n      throw new Error(methodName);\n    };\n  });\n}\n//# sourceMappingURL=stub-methods.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/utils/stub-methods.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/utils/utils.js":
/*!*************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/utils/utils.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   isObjectEmpty: () => (/* binding */ isObjectEmpty),\n/* harmony export */   isPowerOfTwo: () => (/* binding */ isPowerOfTwo),\n/* harmony export */   uid: () => (/* binding */ uid)\n/* harmony export */ });\n/* harmony import */ var _assert__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./assert */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js\");\n\nconst uidCounters = {};\nfunction uid() {\n  let id = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 'id';\n  uidCounters[id] = uidCounters[id] || 1;\n  const count = uidCounters[id]++;\n  return \"\".concat(id, \"-\").concat(count);\n}\nfunction isPowerOfTwo(n) {\n  (0,_assert__WEBPACK_IMPORTED_MODULE_0__.assert)(typeof n === 'number', 'Input must be a number');\n  return n && (n & n - 1) === 0;\n}\nfunction isObjectEmpty(obj) {\n  let isEmpty = true;\n\n  for (const key in obj) {\n    isEmpty = false;\n    break;\n  }\n\n  return isEmpty;\n}\n//# sourceMappingURL=utils.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/utils/utils.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/attribute-utils.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/attribute-utils.js ***!
  \*****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   decomposeCompositeGLType: () => (/* binding */ decomposeCompositeGLType),\n/* harmony export */   getCompositeGLType: () => (/* binding */ getCompositeGLType),\n/* harmony export */   getPrimitiveCount: () => (/* binding */ getPrimitiveCount),\n/* harmony export */   getPrimitiveDrawMode: () => (/* binding */ getPrimitiveDrawMode),\n/* harmony export */   getVertexCount: () => (/* binding */ getVertexCount)\n/* harmony export */ });\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/assert */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js\");\n\nconst GL_BYTE = 0x1400;\nconst GL_UNSIGNED_BYTE = 0x1401;\nconst GL_SHORT = 0x1402;\nconst GL_UNSIGNED_SHORT = 0x1403;\nconst GL_POINTS = 0x0;\nconst GL_LINES = 0x1;\nconst GL_LINE_LOOP = 0x2;\nconst GL_LINE_STRIP = 0x3;\nconst GL_TRIANGLES = 0x4;\nconst GL_TRIANGLE_STRIP = 0x5;\nconst GL_TRIANGLE_FAN = 0x6;\nconst GL_FLOAT = 0x1406;\nconst GL_FLOAT_VEC2 = 0x8b50;\nconst GL_FLOAT_VEC3 = 0x8b51;\nconst GL_FLOAT_VEC4 = 0x8b52;\nconst GL_INT = 0x1404;\nconst GL_INT_VEC2 = 0x8b53;\nconst GL_INT_VEC3 = 0x8b54;\nconst GL_INT_VEC4 = 0x8b55;\nconst GL_UNSIGNED_INT = 0x1405;\nconst GL_UNSIGNED_INT_VEC2 = 0x8dc6;\nconst GL_UNSIGNED_INT_VEC3 = 0x8dc7;\nconst GL_UNSIGNED_INT_VEC4 = 0x8dc8;\nconst GL_BOOL = 0x8b56;\nconst GL_BOOL_VEC2 = 0x8b57;\nconst GL_BOOL_VEC3 = 0x8b58;\nconst GL_BOOL_VEC4 = 0x8b59;\nconst GL_FLOAT_MAT2 = 0x8b5a;\nconst GL_FLOAT_MAT3 = 0x8b5b;\nconst GL_FLOAT_MAT4 = 0x8b5c;\nconst GL_FLOAT_MAT2x3 = 0x8b65;\nconst GL_FLOAT_MAT2x4 = 0x8b66;\nconst GL_FLOAT_MAT3x2 = 0x8b67;\nconst GL_FLOAT_MAT3x4 = 0x8b68;\nconst GL_FLOAT_MAT4x2 = 0x8b69;\nconst GL_FLOAT_MAT4x3 = 0x8b6a;\nconst COMPOSITE_GL_TYPES = {\n  [GL_FLOAT]: [GL_FLOAT, 1, 'float'],\n  [GL_FLOAT_VEC2]: [GL_FLOAT, 2, 'vec2'],\n  [GL_FLOAT_VEC3]: [GL_FLOAT, 3, 'vec3'],\n  [GL_FLOAT_VEC4]: [GL_FLOAT, 4, 'vec4'],\n  [GL_INT]: [GL_INT, 1, 'int'],\n  [GL_INT_VEC2]: [GL_INT, 2, 'ivec2'],\n  [GL_INT_VEC3]: [GL_INT, 3, 'ivec3'],\n  [GL_INT_VEC4]: [GL_INT, 4, 'ivec4'],\n  [GL_UNSIGNED_INT]: [GL_UNSIGNED_INT, 1, 'uint'],\n  [GL_UNSIGNED_INT_VEC2]: [GL_UNSIGNED_INT, 2, 'uvec2'],\n  [GL_UNSIGNED_INT_VEC3]: [GL_UNSIGNED_INT, 3, 'uvec3'],\n  [GL_UNSIGNED_INT_VEC4]: [GL_UNSIGNED_INT, 4, 'uvec4'],\n  [GL_BOOL]: [GL_FLOAT, 1, 'bool'],\n  [GL_BOOL_VEC2]: [GL_FLOAT, 2, 'bvec2'],\n  [GL_BOOL_VEC3]: [GL_FLOAT, 3, 'bvec3'],\n  [GL_BOOL_VEC4]: [GL_FLOAT, 4, 'bvec4'],\n  [GL_FLOAT_MAT2]: [GL_FLOAT, 8, 'mat2'],\n  [GL_FLOAT_MAT2x3]: [GL_FLOAT, 8, 'mat2x3'],\n  [GL_FLOAT_MAT2x4]: [GL_FLOAT, 8, 'mat2x4'],\n  [GL_FLOAT_MAT3]: [GL_FLOAT, 12, 'mat3'],\n  [GL_FLOAT_MAT3x2]: [GL_FLOAT, 12, 'mat3x2'],\n  [GL_FLOAT_MAT3x4]: [GL_FLOAT, 12, 'mat3x4'],\n  [GL_FLOAT_MAT4]: [GL_FLOAT, 16, 'mat4'],\n  [GL_FLOAT_MAT4x2]: [GL_FLOAT, 16, 'mat4x2'],\n  [GL_FLOAT_MAT4x3]: [GL_FLOAT, 16, 'mat4x3']\n};\nfunction getPrimitiveDrawMode(drawMode) {\n  switch (drawMode) {\n    case GL_POINTS:\n      return GL_POINTS;\n\n    case GL_LINES:\n      return GL_LINES;\n\n    case GL_LINE_STRIP:\n      return GL_LINES;\n\n    case GL_LINE_LOOP:\n      return GL_LINES;\n\n    case GL_TRIANGLES:\n      return GL_TRIANGLES;\n\n    case GL_TRIANGLE_STRIP:\n      return GL_TRIANGLES;\n\n    case GL_TRIANGLE_FAN:\n      return GL_TRIANGLES;\n\n    default:\n      (0,_utils_assert__WEBPACK_IMPORTED_MODULE_0__.assert)(false);\n      return 0;\n  }\n}\nfunction getPrimitiveCount(_ref) {\n  let {\n    drawMode,\n    vertexCount\n  } = _ref;\n\n  switch (drawMode) {\n    case GL_POINTS:\n    case GL_LINE_LOOP:\n      return vertexCount;\n\n    case GL_LINES:\n      return vertexCount / 2;\n\n    case GL_LINE_STRIP:\n      return vertexCount - 1;\n\n    case GL_TRIANGLES:\n      return vertexCount / 3;\n\n    case GL_TRIANGLE_STRIP:\n    case GL_TRIANGLE_FAN:\n      return vertexCount - 2;\n\n    default:\n      (0,_utils_assert__WEBPACK_IMPORTED_MODULE_0__.assert)(false);\n      return 0;\n  }\n}\nfunction getVertexCount(_ref2) {\n  let {\n    drawMode,\n    vertexCount\n  } = _ref2;\n  const primitiveCount = getPrimitiveCount({\n    drawMode,\n    vertexCount\n  });\n\n  switch (getPrimitiveDrawMode(drawMode)) {\n    case GL_POINTS:\n      return primitiveCount;\n\n    case GL_LINES:\n      return primitiveCount * 2;\n\n    case GL_TRIANGLES:\n      return primitiveCount * 3;\n\n    default:\n      (0,_utils_assert__WEBPACK_IMPORTED_MODULE_0__.assert)(false);\n      return 0;\n  }\n}\nfunction decomposeCompositeGLType(compositeGLType) {\n  const typeAndSize = COMPOSITE_GL_TYPES[compositeGLType];\n\n  if (!typeAndSize) {\n    return null;\n  }\n\n  const [type, components] = typeAndSize;\n  return {\n    type,\n    components\n  };\n}\nfunction getCompositeGLType(type, components) {\n  switch (type) {\n    case GL_BYTE:\n    case GL_UNSIGNED_BYTE:\n    case GL_SHORT:\n    case GL_UNSIGNED_SHORT:\n      type = GL_FLOAT;\n      break;\n\n    default:\n  }\n\n  for (const glType in COMPOSITE_GL_TYPES) {\n    const [compType, compComponents, name] = COMPOSITE_GL_TYPES[glType];\n\n    if (compType === type && compComponents === components) {\n      return {\n        glType,\n        name\n      };\n    }\n  }\n\n  return null;\n}\n//# sourceMappingURL=attribute-utils.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/attribute-utils.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/constants-to-keys.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/constants-to-keys.js ***!
  \*******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getKey: () => (/* binding */ getKey),\n/* harmony export */   getKeyType: () => (/* binding */ getKeyType),\n/* harmony export */   getKeyValue: () => (/* binding */ getKeyValue)\n/* harmony export */ });\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/assert */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js\");\n\nfunction getKeyValue(gl, name) {\n  if (typeof name !== 'string') {\n    return name;\n  }\n\n  const number = Number(name);\n\n  if (!isNaN(number)) {\n    return number;\n  }\n\n  name = name.replace(/^.*\\./, '');\n  const value = gl[name];\n  (0,_utils_assert__WEBPACK_IMPORTED_MODULE_0__.assert)(value !== undefined, \"Accessing undefined constant GL.\".concat(name));\n  return value;\n}\nfunction getKey(gl, value) {\n  value = Number(value);\n\n  for (const key in gl) {\n    if (gl[key] === value) {\n      return \"GL.\".concat(key);\n    }\n  }\n\n  return String(value);\n}\nfunction getKeyType(gl, value) {\n  (0,_utils_assert__WEBPACK_IMPORTED_MODULE_0__.assert)(value !== undefined, 'undefined key');\n  value = Number(value);\n\n  for (const key in gl) {\n    if (gl[key] === value) {\n      return \"GL.\".concat(key);\n    }\n  }\n\n  return String(value);\n}\n//# sourceMappingURL=constants-to-keys.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/constants-to-keys.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/format-utils.js":
/*!**************************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/format-utils.js ***!
  \**************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   glFormatToComponents: () => (/* binding */ glFormatToComponents),\n/* harmony export */   glTypeToBytes: () => (/* binding */ glTypeToBytes)\n/* harmony export */ });\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/assert */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js\");\n\nfunction glFormatToComponents(format) {\n  switch (format) {\n    case 6406:\n    case 33326:\n    case 6403:\n      return 1;\n\n    case 33328:\n    case 33319:\n      return 2;\n\n    case 6407:\n    case 34837:\n      return 3;\n\n    case 6408:\n    case 34836:\n      return 4;\n\n    default:\n      (0,_utils_assert__WEBPACK_IMPORTED_MODULE_0__.assert)(false);\n      return 0;\n  }\n}\nfunction glTypeToBytes(type) {\n  switch (type) {\n    case 5121:\n      return 1;\n\n    case 33635:\n    case 32819:\n    case 32820:\n      return 2;\n\n    case 5126:\n      return 4;\n\n    default:\n      (0,_utils_assert__WEBPACK_IMPORTED_MODULE_0__.assert)(false);\n      return 0;\n  }\n}\n//# sourceMappingURL=format-utils.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/format-utils.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/request-animation-frame.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/request-animation-frame.js ***!
  \*************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   cancelAnimationFrame: () => (/* binding */ cancelAnimationFrame),\n/* harmony export */   requestAnimationFrame: () => (/* binding */ requestAnimationFrame)\n/* harmony export */ });\nfunction requestAnimationFrame(callback) {\n  return typeof window !== 'undefined' && window.requestAnimationFrame ? window.requestAnimationFrame(callback) : setTimeout(callback, 1000 / 60);\n}\nfunction cancelAnimationFrame(timerId) {\n  return typeof window !== 'undefined' && window.cancelAnimationFrame ? window.cancelAnimationFrame(timerId) : clearTimeout(timerId);\n}\n//# sourceMappingURL=request-animation-frame.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/request-animation-frame.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/texture-utils.js":
/*!***************************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/texture-utils.js ***!
  \***************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   cloneTextureFrom: () => (/* binding */ cloneTextureFrom),\n/* harmony export */   toFramebuffer: () => (/* binding */ toFramebuffer)\n/* harmony export */ });\n/* harmony import */ var _classes_texture_2d__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../classes/texture-2d */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/texture-2d.js\");\n/* harmony import */ var _classes_texture_cube__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../classes/texture-cube */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/texture-cube.js\");\n/* harmony import */ var _classes_texture_3d__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../classes/texture-3d */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/texture-3d.js\");\n/* harmony import */ var _classes_framebuffer__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../classes/framebuffer */ \"./node_modules/@luma.gl/webgl/dist/esm/classes/framebuffer.js\");\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/assert */ \"./node_modules/@luma.gl/webgl/dist/esm/utils/assert.js\");\n\n\n\n\n\nfunction cloneTextureFrom(refTexture, overrides) {\n  (0,_utils_assert__WEBPACK_IMPORTED_MODULE_0__.assert)(refTexture instanceof _classes_texture_2d__WEBPACK_IMPORTED_MODULE_1__[\"default\"] || refTexture instanceof _classes_texture_cube__WEBPACK_IMPORTED_MODULE_2__[\"default\"] || refTexture instanceof _classes_texture_3d__WEBPACK_IMPORTED_MODULE_3__[\"default\"]);\n  const TextureType = refTexture.constructor;\n  const {\n    gl,\n    width,\n    height,\n    format,\n    type,\n    dataFormat,\n    border,\n    mipmaps\n  } = refTexture;\n  const textureOptions = Object.assign({\n    width,\n    height,\n    format,\n    type,\n    dataFormat,\n    border,\n    mipmaps\n  }, overrides);\n  return new TextureType(gl, textureOptions);\n}\nfunction toFramebuffer(texture, opts) {\n  const {\n    gl,\n    width,\n    height,\n    id\n  } = texture;\n  const framebuffer = new _classes_framebuffer__WEBPACK_IMPORTED_MODULE_4__[\"default\"](gl, Object.assign({}, opts, {\n    id: \"framebuffer-for-\".concat(id),\n    width,\n    height,\n    attachments: {\n      [36064]: texture\n    }\n  }));\n  return framebuffer;\n}\n//# sourceMappingURL=texture-utils.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/texture-utils.js?");

/***/ }),

/***/ "./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/typed-array-utils.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/typed-array-utils.js ***!
  \*******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   flipRows: () => (/* binding */ flipRows),\n/* harmony export */   getGLTypeFromTypedArray: () => (/* binding */ getGLTypeFromTypedArray),\n/* harmony export */   getTypedArrayFromGLType: () => (/* binding */ getTypedArrayFromGLType),\n/* harmony export */   scalePixels: () => (/* binding */ scalePixels)\n/* harmony export */ });\nconst ERR_TYPE_DEDUCTION = 'Failed to deduce GL constant from typed array';\nfunction getGLTypeFromTypedArray(arrayOrType) {\n  const type = ArrayBuffer.isView(arrayOrType) ? arrayOrType.constructor : arrayOrType;\n\n  switch (type) {\n    case Float32Array:\n      return 5126;\n\n    case Uint16Array:\n      return 5123;\n\n    case Uint32Array:\n      return 5125;\n\n    case Uint8Array:\n      return 5121;\n\n    case Uint8ClampedArray:\n      return 5121;\n\n    case Int8Array:\n      return 5120;\n\n    case Int16Array:\n      return 5122;\n\n    case Int32Array:\n      return 5124;\n\n    default:\n      throw new Error(ERR_TYPE_DEDUCTION);\n  }\n}\nfunction getTypedArrayFromGLType(glType) {\n  let {\n    clamped = true\n  } = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n\n  switch (glType) {\n    case 5126:\n      return Float32Array;\n\n    case 5123:\n    case 33635:\n    case 32819:\n    case 32820:\n      return Uint16Array;\n\n    case 5125:\n      return Uint32Array;\n\n    case 5121:\n      return clamped ? Uint8ClampedArray : Uint8Array;\n\n    case 5120:\n      return Int8Array;\n\n    case 5122:\n      return Int16Array;\n\n    case 5124:\n      return Int32Array;\n\n    default:\n      throw new Error('Failed to deduce typed array type from GL constant');\n  }\n}\nfunction flipRows(_ref) {\n  let {\n    data,\n    width,\n    height,\n    bytesPerPixel = 4,\n    temp\n  } = _ref;\n  const bytesPerRow = width * bytesPerPixel;\n  temp = temp || new Uint8Array(bytesPerRow);\n\n  for (let y = 0; y < height / 2; ++y) {\n    const topOffset = y * bytesPerRow;\n    const bottomOffset = (height - y - 1) * bytesPerRow;\n    temp.set(data.subarray(topOffset, topOffset + bytesPerRow));\n    data.copyWithin(topOffset, bottomOffset, bottomOffset + bytesPerRow);\n    data.set(temp, bottomOffset);\n  }\n}\nfunction scalePixels(_ref2) {\n  let {\n    data,\n    width,\n    height\n  } = _ref2;\n  const newWidth = Math.round(width / 2);\n  const newHeight = Math.round(height / 2);\n  const newData = new Uint8Array(newWidth * newHeight * 4);\n\n  for (let y = 0; y < newHeight; y++) {\n    for (let x = 0; x < newWidth; x++) {\n      for (let c = 0; c < 4; c++) {\n        newData[(y * newWidth + x) * 4 + c] = data[(y * 2 * width + x * 2) * 4 + c];\n      }\n    }\n  }\n\n  return {\n    data: newData,\n    width: newWidth,\n    height: newHeight\n  };\n}\n//# sourceMappingURL=typed-array-utils.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@luma.gl/webgl/dist/esm/webgl-utils/typed-array-utils.js?");

/***/ }),

/***/ "./node_modules/@math.gl/core/dist/esm/classes/base/math-array.js":
/*!************************************************************************!*\
  !*** ./node_modules/@math.gl/core/dist/esm/classes/base/math-array.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ MathArray)\n/* harmony export */ });\n/* harmony import */ var _lib_common__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../lib/common */ \"./node_modules/@math.gl/core/dist/esm/lib/common.js\");\nfunction _extendableBuiltin(cls) {\n  function ExtendableBuiltin() {\n    var instance = Reflect.construct(cls, Array.from(arguments));\n    Object.setPrototypeOf(instance, Object.getPrototypeOf(this));\n    return instance;\n  }\n\n  ExtendableBuiltin.prototype = Object.create(cls.prototype, {\n    constructor: {\n      value: cls,\n      enumerable: false,\n      writable: true,\n      configurable: true\n    }\n  });\n\n  if (Object.setPrototypeOf) {\n    Object.setPrototypeOf(ExtendableBuiltin, cls);\n  } else {\n    ExtendableBuiltin.__proto__ = cls;\n  }\n\n  return ExtendableBuiltin;\n}\n\n\nclass MathArray extends _extendableBuiltin(Array) {\n  clone() {\n    return new this.constructor().copy(this);\n  }\n\n  fromArray(array, offset = 0) {\n    for (let i = 0; i < this.ELEMENTS; ++i) {\n      this[i] = array[i + offset];\n    }\n\n    return this.check();\n  }\n\n  toArray(targetArray = [], offset = 0) {\n    for (let i = 0; i < this.ELEMENTS; ++i) {\n      targetArray[offset + i] = this[i];\n    }\n\n    return targetArray;\n  }\n\n  from(arrayOrObject) {\n    return Array.isArray(arrayOrObject) ? this.copy(arrayOrObject) : this.fromObject(arrayOrObject);\n  }\n\n  to(arrayOrObject) {\n    if (arrayOrObject === this) {\n      return this;\n    }\n\n    return (0,_lib_common__WEBPACK_IMPORTED_MODULE_0__.isArray)(arrayOrObject) ? this.toArray(arrayOrObject) : this.toObject(arrayOrObject);\n  }\n\n  toTarget(target) {\n    return target ? this.to(target) : this;\n  }\n\n  toFloat32Array() {\n    return new Float32Array(this);\n  }\n\n  toString() {\n    return this.formatString(_lib_common__WEBPACK_IMPORTED_MODULE_0__.config);\n  }\n\n  formatString(opts) {\n    let string = '';\n\n    for (let i = 0; i < this.ELEMENTS; ++i) {\n      string += (i > 0 ? ', ' : '') + (0,_lib_common__WEBPACK_IMPORTED_MODULE_0__.formatValue)(this[i], opts);\n    }\n\n    return \"\".concat(opts.printTypes ? this.constructor.name : '', \"[\").concat(string, \"]\");\n  }\n\n  equals(array) {\n    if (!array || this.length !== array.length) {\n      return false;\n    }\n\n    for (let i = 0; i < this.ELEMENTS; ++i) {\n      if (!(0,_lib_common__WEBPACK_IMPORTED_MODULE_0__.equals)(this[i], array[i])) {\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n  exactEquals(array) {\n    if (!array || this.length !== array.length) {\n      return false;\n    }\n\n    for (let i = 0; i < this.ELEMENTS; ++i) {\n      if (this[i] !== array[i]) {\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n  negate() {\n    for (let i = 0; i < this.ELEMENTS; ++i) {\n      this[i] = -this[i];\n    }\n\n    return this.check();\n  }\n\n  lerp(a, b, t) {\n    if (t === undefined) {\n      return this.lerp(this, a, b);\n    }\n\n    for (let i = 0; i < this.ELEMENTS; ++i) {\n      const ai = a[i];\n      this[i] = ai + t * (b[i] - ai);\n    }\n\n    return this.check();\n  }\n\n  min(vector) {\n    for (let i = 0; i < this.ELEMENTS; ++i) {\n      this[i] = Math.min(vector[i], this[i]);\n    }\n\n    return this.check();\n  }\n\n  max(vector) {\n    for (let i = 0; i < this.ELEMENTS; ++i) {\n      this[i] = Math.max(vector[i], this[i]);\n    }\n\n    return this.check();\n  }\n\n  clamp(minVector, maxVector) {\n    for (let i = 0; i < this.ELEMENTS; ++i) {\n      this[i] = Math.min(Math.max(this[i], minVector[i]), maxVector[i]);\n    }\n\n    return this.check();\n  }\n\n  add(...vectors) {\n    for (const vector of vectors) {\n      for (let i = 0; i < this.ELEMENTS; ++i) {\n        this[i] += vector[i];\n      }\n    }\n\n    return this.check();\n  }\n\n  subtract(...vectors) {\n    for (const vector of vectors) {\n      for (let i = 0; i < this.ELEMENTS; ++i) {\n        this[i] -= vector[i];\n      }\n    }\n\n    return this.check();\n  }\n\n  scale(scale) {\n    if (typeof scale === 'number') {\n      for (let i = 0; i < this.ELEMENTS; ++i) {\n        this[i] *= scale;\n      }\n    } else {\n      for (let i = 0; i < this.ELEMENTS && i < scale.length; ++i) {\n        this[i] *= scale[i];\n      }\n    }\n\n    return this.check();\n  }\n\n  multiplyByScalar(scalar) {\n    for (let i = 0; i < this.ELEMENTS; ++i) {\n      this[i] *= scalar;\n    }\n\n    return this.check();\n  }\n\n  check() {\n    if (_lib_common__WEBPACK_IMPORTED_MODULE_0__.config.debug && !this.validate()) {\n      throw new Error(\"math.gl: \".concat(this.constructor.name, \" some fields set to invalid numbers'\"));\n    }\n\n    return this;\n  }\n\n  validate() {\n    let valid = this.length === this.ELEMENTS;\n\n    for (let i = 0; i < this.ELEMENTS; ++i) {\n      valid = valid && Number.isFinite(this[i]);\n    }\n\n    return valid;\n  }\n\n  sub(a) {\n    return this.subtract(a);\n  }\n\n  setScalar(a) {\n    for (let i = 0; i < this.ELEMENTS; ++i) {\n      this[i] = a;\n    }\n\n    return this.check();\n  }\n\n  addScalar(a) {\n    for (let i = 0; i < this.ELEMENTS; ++i) {\n      this[i] += a;\n    }\n\n    return this.check();\n  }\n\n  subScalar(a) {\n    return this.addScalar(-a);\n  }\n\n  multiplyScalar(scalar) {\n    for (let i = 0; i < this.ELEMENTS; ++i) {\n      this[i] *= scalar;\n    }\n\n    return this.check();\n  }\n\n  divideScalar(a) {\n    return this.multiplyByScalar(1 / a);\n  }\n\n  clampScalar(min, max) {\n    for (let i = 0; i < this.ELEMENTS; ++i) {\n      this[i] = Math.min(Math.max(this[i], min), max);\n    }\n\n    return this.check();\n  }\n\n  get elements() {\n    return this;\n  }\n\n}\n//# sourceMappingURL=math-array.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@math.gl/core/dist/esm/classes/base/math-array.js?");

/***/ }),

/***/ "./node_modules/@math.gl/core/dist/esm/classes/base/matrix.js":
/*!********************************************************************!*\
  !*** ./node_modules/@math.gl/core/dist/esm/classes/base/matrix.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Matrix)\n/* harmony export */ });\n/* harmony import */ var _math_array__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./math-array */ \"./node_modules/@math.gl/core/dist/esm/classes/base/math-array.js\");\n/* harmony import */ var _lib_validators__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../lib/validators */ \"./node_modules/@math.gl/core/dist/esm/lib/validators.js\");\n/* harmony import */ var _lib_common__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../lib/common */ \"./node_modules/@math.gl/core/dist/esm/lib/common.js\");\n\n\n\nclass Matrix extends _math_array__WEBPACK_IMPORTED_MODULE_0__[\"default\"] {\n  toString() {\n    let string = '[';\n\n    if (_lib_common__WEBPACK_IMPORTED_MODULE_1__.config.printRowMajor) {\n      string += 'row-major:';\n\n      for (let row = 0; row < this.RANK; ++row) {\n        for (let col = 0; col < this.RANK; ++col) {\n          string += \" \".concat(this[col * this.RANK + row]);\n        }\n      }\n    } else {\n      string += 'column-major:';\n\n      for (let i = 0; i < this.ELEMENTS; ++i) {\n        string += \" \".concat(this[i]);\n      }\n    }\n\n    string += ']';\n    return string;\n  }\n\n  getElementIndex(row, col) {\n    return col * this.RANK + row;\n  }\n\n  getElement(row, col) {\n    return this[col * this.RANK + row];\n  }\n\n  setElement(row, col, value) {\n    this[col * this.RANK + row] = (0,_lib_validators__WEBPACK_IMPORTED_MODULE_2__.checkNumber)(value);\n    return this;\n  }\n\n  getColumn(columnIndex, result = new Array(this.RANK).fill(-0)) {\n    const firstIndex = columnIndex * this.RANK;\n\n    for (let i = 0; i < this.RANK; ++i) {\n      result[i] = this[firstIndex + i];\n    }\n\n    return result;\n  }\n\n  setColumn(columnIndex, columnVector) {\n    const firstIndex = columnIndex * this.RANK;\n\n    for (let i = 0; i < this.RANK; ++i) {\n      this[firstIndex + i] = columnVector[i];\n    }\n\n    return this;\n  }\n\n}\n//# sourceMappingURL=matrix.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@math.gl/core/dist/esm/classes/base/matrix.js?");

/***/ }),

/***/ "./node_modules/@math.gl/core/dist/esm/classes/base/vector.js":
/*!********************************************************************!*\
  !*** ./node_modules/@math.gl/core/dist/esm/classes/base/vector.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Vector)\n/* harmony export */ });\n/* harmony import */ var _math_array__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./math-array */ \"./node_modules/@math.gl/core/dist/esm/classes/base/math-array.js\");\n/* harmony import */ var _lib_validators__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../lib/validators */ \"./node_modules/@math.gl/core/dist/esm/lib/validators.js\");\n/* harmony import */ var _lib_assert__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../lib/assert */ \"./node_modules/@math.gl/core/dist/esm/lib/assert.js\");\n\n\n\nclass Vector extends _math_array__WEBPACK_IMPORTED_MODULE_0__[\"default\"] {\n  get x() {\n    return this[0];\n  }\n\n  set x(value) {\n    this[0] = (0,_lib_validators__WEBPACK_IMPORTED_MODULE_1__.checkNumber)(value);\n  }\n\n  get y() {\n    return this[1];\n  }\n\n  set y(value) {\n    this[1] = (0,_lib_validators__WEBPACK_IMPORTED_MODULE_1__.checkNumber)(value);\n  }\n\n  len() {\n    return Math.sqrt(this.lengthSquared());\n  }\n\n  magnitude() {\n    return this.len();\n  }\n\n  lengthSquared() {\n    let length = 0;\n\n    for (let i = 0; i < this.ELEMENTS; ++i) {\n      length += this[i] * this[i];\n    }\n\n    return length;\n  }\n\n  magnitudeSquared() {\n    return this.lengthSquared();\n  }\n\n  distance(mathArray) {\n    return Math.sqrt(this.distanceSquared(mathArray));\n  }\n\n  distanceSquared(mathArray) {\n    let length = 0;\n\n    for (let i = 0; i < this.ELEMENTS; ++i) {\n      const dist = this[i] - mathArray[i];\n      length += dist * dist;\n    }\n\n    return (0,_lib_validators__WEBPACK_IMPORTED_MODULE_1__.checkNumber)(length);\n  }\n\n  dot(mathArray) {\n    let product = 0;\n\n    for (let i = 0; i < this.ELEMENTS; ++i) {\n      product += this[i] * mathArray[i];\n    }\n\n    return (0,_lib_validators__WEBPACK_IMPORTED_MODULE_1__.checkNumber)(product);\n  }\n\n  normalize() {\n    const length = this.magnitude();\n\n    if (length !== 0) {\n      for (let i = 0; i < this.ELEMENTS; ++i) {\n        this[i] /= length;\n      }\n    }\n\n    return this.check();\n  }\n\n  multiply(...vectors) {\n    for (const vector of vectors) {\n      for (let i = 0; i < this.ELEMENTS; ++i) {\n        this[i] *= vector[i];\n      }\n    }\n\n    return this.check();\n  }\n\n  divide(...vectors) {\n    for (const vector of vectors) {\n      for (let i = 0; i < this.ELEMENTS; ++i) {\n        this[i] /= vector[i];\n      }\n    }\n\n    return this.check();\n  }\n\n  lengthSq() {\n    return this.lengthSquared();\n  }\n\n  distanceTo(vector) {\n    return this.distance(vector);\n  }\n\n  distanceToSquared(vector) {\n    return this.distanceSquared(vector);\n  }\n\n  getComponent(i) {\n    (0,_lib_assert__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(i >= 0 && i < this.ELEMENTS, 'index is out of range');\n    return (0,_lib_validators__WEBPACK_IMPORTED_MODULE_1__.checkNumber)(this[i]);\n  }\n\n  setComponent(i, value) {\n    (0,_lib_assert__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(i >= 0 && i < this.ELEMENTS, 'index is out of range');\n    this[i] = value;\n    return this.check();\n  }\n\n  addVectors(a, b) {\n    return this.copy(a).add(b);\n  }\n\n  subVectors(a, b) {\n    return this.copy(a).subtract(b);\n  }\n\n  multiplyVectors(a, b) {\n    return this.copy(a).multiply(b);\n  }\n\n  addScaledVector(a, b) {\n    return this.add(new this.constructor(a).multiplyScalar(b));\n  }\n\n}\n//# sourceMappingURL=vector.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@math.gl/core/dist/esm/classes/base/vector.js?");

/***/ }),

/***/ "./node_modules/@math.gl/core/dist/esm/classes/matrix4.js":
/*!****************************************************************!*\
  !*** ./node_modules/@math.gl/core/dist/esm/classes/matrix4.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Matrix4)\n/* harmony export */ });\n/* harmony import */ var _base_matrix__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./base/matrix */ \"./node_modules/@math.gl/core/dist/esm/classes/base/matrix.js\");\n/* harmony import */ var _lib_validators__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../lib/validators */ \"./node_modules/@math.gl/core/dist/esm/lib/validators.js\");\n/* harmony import */ var _lib_gl_matrix_extras__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../lib/gl-matrix-extras */ \"./node_modules/@math.gl/core/dist/esm/lib/gl-matrix-extras.js\");\n/* harmony import */ var gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! gl-matrix/mat4 */ \"./node_modules/gl-matrix/esm/mat4.js\");\n/* harmony import */ var gl_matrix_vec2__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! gl-matrix/vec2 */ \"./node_modules/gl-matrix/esm/vec2.js\");\n/* harmony import */ var gl_matrix_vec3__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! gl-matrix/vec3 */ \"./node_modules/gl-matrix/esm/vec3.js\");\n/* harmony import */ var gl_matrix_vec4__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! gl-matrix/vec4 */ \"./node_modules/gl-matrix/esm/vec4.js\");\n\n\n\n\n\n\n\nvar INDICES;\n\n(function (INDICES) {\n  INDICES[INDICES[\"COL0ROW0\"] = 0] = \"COL0ROW0\";\n  INDICES[INDICES[\"COL0ROW1\"] = 1] = \"COL0ROW1\";\n  INDICES[INDICES[\"COL0ROW2\"] = 2] = \"COL0ROW2\";\n  INDICES[INDICES[\"COL0ROW3\"] = 3] = \"COL0ROW3\";\n  INDICES[INDICES[\"COL1ROW0\"] = 4] = \"COL1ROW0\";\n  INDICES[INDICES[\"COL1ROW1\"] = 5] = \"COL1ROW1\";\n  INDICES[INDICES[\"COL1ROW2\"] = 6] = \"COL1ROW2\";\n  INDICES[INDICES[\"COL1ROW3\"] = 7] = \"COL1ROW3\";\n  INDICES[INDICES[\"COL2ROW0\"] = 8] = \"COL2ROW0\";\n  INDICES[INDICES[\"COL2ROW1\"] = 9] = \"COL2ROW1\";\n  INDICES[INDICES[\"COL2ROW2\"] = 10] = \"COL2ROW2\";\n  INDICES[INDICES[\"COL2ROW3\"] = 11] = \"COL2ROW3\";\n  INDICES[INDICES[\"COL3ROW0\"] = 12] = \"COL3ROW0\";\n  INDICES[INDICES[\"COL3ROW1\"] = 13] = \"COL3ROW1\";\n  INDICES[INDICES[\"COL3ROW2\"] = 14] = \"COL3ROW2\";\n  INDICES[INDICES[\"COL3ROW3\"] = 15] = \"COL3ROW3\";\n})(INDICES || (INDICES = {}));\n\nconst DEFAULT_FOVY = 45 * Math.PI / 180;\nconst DEFAULT_ASPECT = 1;\nconst DEFAULT_NEAR = 0.1;\nconst DEFAULT_FAR = 500;\nconst IDENTITY_MATRIX = Object.freeze([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]);\nclass Matrix4 extends _base_matrix__WEBPACK_IMPORTED_MODULE_0__[\"default\"] {\n  static get IDENTITY() {\n    return getIdentityMatrix();\n  }\n\n  static get ZERO() {\n    return getZeroMatrix();\n  }\n\n  get ELEMENTS() {\n    return 16;\n  }\n\n  get RANK() {\n    return 4;\n  }\n\n  get INDICES() {\n    return INDICES;\n  }\n\n  constructor(array) {\n    super(-0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0);\n\n    if (arguments.length === 1 && Array.isArray(array)) {\n      this.copy(array);\n    } else {\n      this.identity();\n    }\n  }\n\n  copy(array) {\n    this[0] = array[0];\n    this[1] = array[1];\n    this[2] = array[2];\n    this[3] = array[3];\n    this[4] = array[4];\n    this[5] = array[5];\n    this[6] = array[6];\n    this[7] = array[7];\n    this[8] = array[8];\n    this[9] = array[9];\n    this[10] = array[10];\n    this[11] = array[11];\n    this[12] = array[12];\n    this[13] = array[13];\n    this[14] = array[14];\n    this[15] = array[15];\n    return this.check();\n  }\n\n  set(m00, m10, m20, m30, m01, m11, m21, m31, m02, m12, m22, m32, m03, m13, m23, m33) {\n    this[0] = m00;\n    this[1] = m10;\n    this[2] = m20;\n    this[3] = m30;\n    this[4] = m01;\n    this[5] = m11;\n    this[6] = m21;\n    this[7] = m31;\n    this[8] = m02;\n    this[9] = m12;\n    this[10] = m22;\n    this[11] = m32;\n    this[12] = m03;\n    this[13] = m13;\n    this[14] = m23;\n    this[15] = m33;\n    return this.check();\n  }\n\n  setRowMajor(m00, m01, m02, m03, m10, m11, m12, m13, m20, m21, m22, m23, m30, m31, m32, m33) {\n    this[0] = m00;\n    this[1] = m10;\n    this[2] = m20;\n    this[3] = m30;\n    this[4] = m01;\n    this[5] = m11;\n    this[6] = m21;\n    this[7] = m31;\n    this[8] = m02;\n    this[9] = m12;\n    this[10] = m22;\n    this[11] = m32;\n    this[12] = m03;\n    this[13] = m13;\n    this[14] = m23;\n    this[15] = m33;\n    return this.check();\n  }\n\n  toRowMajor(result) {\n    result[0] = this[0];\n    result[1] = this[4];\n    result[2] = this[8];\n    result[3] = this[12];\n    result[4] = this[1];\n    result[5] = this[5];\n    result[6] = this[9];\n    result[7] = this[13];\n    result[8] = this[2];\n    result[9] = this[6];\n    result[10] = this[10];\n    result[11] = this[14];\n    result[12] = this[3];\n    result[13] = this[7];\n    result[14] = this[11];\n    result[15] = this[15];\n    return result;\n  }\n\n  identity() {\n    return this.copy(IDENTITY_MATRIX);\n  }\n\n  fromObject(object) {\n    return this.check();\n  }\n\n  fromQuaternion(quaternion) {\n    gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_1__.fromQuat(this, quaternion);\n    return this.check();\n  }\n\n  frustum(view) {\n    const {\n      left,\n      right,\n      bottom,\n      top,\n      near = DEFAULT_NEAR,\n      far = DEFAULT_FAR\n    } = view;\n\n    if (far === Infinity) {\n      computeInfinitePerspectiveOffCenter(this, left, right, bottom, top, near);\n    } else {\n      gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_1__.frustum(this, left, right, bottom, top, near, far);\n    }\n\n    return this.check();\n  }\n\n  lookAt(view) {\n    const {\n      eye,\n      center = [0, 0, 0],\n      up = [0, 1, 0]\n    } = view;\n    gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_1__.lookAt(this, eye, center, up);\n    return this.check();\n  }\n\n  ortho(view) {\n    const {\n      left,\n      right,\n      bottom,\n      top,\n      near = DEFAULT_NEAR,\n      far = DEFAULT_FAR\n    } = view;\n    gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_1__.ortho(this, left, right, bottom, top, near, far);\n    return this.check();\n  }\n\n  orthographic(view) {\n    const {\n      fovy = DEFAULT_FOVY,\n      aspect = DEFAULT_ASPECT,\n      focalDistance = 1,\n      near = DEFAULT_NEAR,\n      far = DEFAULT_FAR\n    } = view;\n    checkRadians(fovy);\n    const halfY = fovy / 2;\n    const top = focalDistance * Math.tan(halfY);\n    const right = top * aspect;\n    return this.ortho({\n      left: -right,\n      right,\n      bottom: -top,\n      top,\n      near,\n      far\n    });\n  }\n\n  perspective(view) {\n    const {\n      fovy = 45 * Math.PI / 180,\n      aspect = 1,\n      near = 0.1,\n      far = 500\n    } = view;\n    checkRadians(fovy);\n    gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_1__.perspective(this, fovy, aspect, near, far);\n    return this.check();\n  }\n\n  determinant() {\n    return gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_1__.determinant(this);\n  }\n\n  getScale(result = [-0, -0, -0]) {\n    result[0] = Math.sqrt(this[0] * this[0] + this[1] * this[1] + this[2] * this[2]);\n    result[1] = Math.sqrt(this[4] * this[4] + this[5] * this[5] + this[6] * this[6]);\n    result[2] = Math.sqrt(this[8] * this[8] + this[9] * this[9] + this[10] * this[10]);\n    return result;\n  }\n\n  getTranslation(result = [-0, -0, -0]) {\n    result[0] = this[12];\n    result[1] = this[13];\n    result[2] = this[14];\n    return result;\n  }\n\n  getRotation(result, scaleResult) {\n    result = result || [-0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0, -0];\n    scaleResult = scaleResult || [-0, -0, -0];\n    const scale = this.getScale(scaleResult);\n    const inverseScale0 = 1 / scale[0];\n    const inverseScale1 = 1 / scale[1];\n    const inverseScale2 = 1 / scale[2];\n    result[0] = this[0] * inverseScale0;\n    result[1] = this[1] * inverseScale1;\n    result[2] = this[2] * inverseScale2;\n    result[3] = 0;\n    result[4] = this[4] * inverseScale0;\n    result[5] = this[5] * inverseScale1;\n    result[6] = this[6] * inverseScale2;\n    result[7] = 0;\n    result[8] = this[8] * inverseScale0;\n    result[9] = this[9] * inverseScale1;\n    result[10] = this[10] * inverseScale2;\n    result[11] = 0;\n    result[12] = 0;\n    result[13] = 0;\n    result[14] = 0;\n    result[15] = 1;\n    return result;\n  }\n\n  getRotationMatrix3(result, scaleResult) {\n    result = result || [-0, -0, -0, -0, -0, -0, -0, -0, -0];\n    scaleResult = scaleResult || [-0, -0, -0];\n    const scale = this.getScale(scaleResult);\n    const inverseScale0 = 1 / scale[0];\n    const inverseScale1 = 1 / scale[1];\n    const inverseScale2 = 1 / scale[2];\n    result[0] = this[0] * inverseScale0;\n    result[1] = this[1] * inverseScale1;\n    result[2] = this[2] * inverseScale2;\n    result[3] = this[4] * inverseScale0;\n    result[4] = this[5] * inverseScale1;\n    result[5] = this[6] * inverseScale2;\n    result[6] = this[8] * inverseScale0;\n    result[7] = this[9] * inverseScale1;\n    result[8] = this[10] * inverseScale2;\n    return result;\n  }\n\n  transpose() {\n    gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_1__.transpose(this, this);\n    return this.check();\n  }\n\n  invert() {\n    gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_1__.invert(this, this);\n    return this.check();\n  }\n\n  multiplyLeft(a) {\n    gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_1__.multiply(this, a, this);\n    return this.check();\n  }\n\n  multiplyRight(a) {\n    gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_1__.multiply(this, this, a);\n    return this.check();\n  }\n\n  rotateX(radians) {\n    gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_1__.rotateX(this, this, radians);\n    return this.check();\n  }\n\n  rotateY(radians) {\n    gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_1__.rotateY(this, this, radians);\n    return this.check();\n  }\n\n  rotateZ(radians) {\n    gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_1__.rotateZ(this, this, radians);\n    return this.check();\n  }\n\n  rotateXYZ(angleXYZ) {\n    return this.rotateX(angleXYZ[0]).rotateY(angleXYZ[1]).rotateZ(angleXYZ[2]);\n  }\n\n  rotateAxis(radians, axis) {\n    gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_1__.rotate(this, this, radians, axis);\n    return this.check();\n  }\n\n  scale(factor) {\n    gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_1__.scale(this, this, Array.isArray(factor) ? factor : [factor, factor, factor]);\n    return this.check();\n  }\n\n  translate(vector) {\n    gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_1__.translate(this, this, vector);\n    return this.check();\n  }\n\n  transform(vector, result) {\n    if (vector.length === 4) {\n      result = gl_matrix_vec4__WEBPACK_IMPORTED_MODULE_2__.transformMat4(result || [-0, -0, -0, -0], vector, this);\n      (0,_lib_validators__WEBPACK_IMPORTED_MODULE_3__.checkVector)(result, 4);\n      return result;\n    }\n\n    return this.transformAsPoint(vector, result);\n  }\n\n  transformAsPoint(vector, result) {\n    const {\n      length\n    } = vector;\n    let out;\n\n    switch (length) {\n      case 2:\n        out = gl_matrix_vec2__WEBPACK_IMPORTED_MODULE_4__.transformMat4(result || [-0, -0], vector, this);\n        break;\n\n      case 3:\n        out = gl_matrix_vec3__WEBPACK_IMPORTED_MODULE_5__.transformMat4(result || [-0, -0, -0], vector, this);\n        break;\n\n      default:\n        throw new Error('Illegal vector');\n    }\n\n    (0,_lib_validators__WEBPACK_IMPORTED_MODULE_3__.checkVector)(out, vector.length);\n    return out;\n  }\n\n  transformAsVector(vector, result) {\n    let out;\n\n    switch (vector.length) {\n      case 2:\n        out = (0,_lib_gl_matrix_extras__WEBPACK_IMPORTED_MODULE_6__.vec2_transformMat4AsVector)(result || [-0, -0], vector, this);\n        break;\n\n      case 3:\n        out = (0,_lib_gl_matrix_extras__WEBPACK_IMPORTED_MODULE_6__.vec3_transformMat4AsVector)(result || [-0, -0, -0], vector, this);\n        break;\n\n      default:\n        throw new Error('Illegal vector');\n    }\n\n    (0,_lib_validators__WEBPACK_IMPORTED_MODULE_3__.checkVector)(out, vector.length);\n    return out;\n  }\n\n  transformPoint(vector, result) {\n    return this.transformAsPoint(vector, result);\n  }\n\n  transformVector(vector, result) {\n    return this.transformAsPoint(vector, result);\n  }\n\n  transformDirection(vector, result) {\n    return this.transformAsVector(vector, result);\n  }\n\n  makeRotationX(radians) {\n    return this.identity().rotateX(radians);\n  }\n\n  makeTranslation(x, y, z) {\n    return this.identity().translate([x, y, z]);\n  }\n\n}\nlet ZERO;\nlet IDENTITY;\n\nfunction getZeroMatrix() {\n  if (!ZERO) {\n    ZERO = new Matrix4([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]);\n    Object.freeze(ZERO);\n  }\n\n  return ZERO;\n}\n\nfunction getIdentityMatrix() {\n  if (!IDENTITY) {\n    IDENTITY = new Matrix4();\n    Object.freeze(IDENTITY);\n  }\n\n  return IDENTITY;\n}\n\nfunction checkRadians(possiblyDegrees) {\n  if (possiblyDegrees > Math.PI * 2) {\n    throw Error('expected radians');\n  }\n}\n\nfunction computeInfinitePerspectiveOffCenter(result, left, right, bottom, top, near) {\n  const column0Row0 = 2 * near / (right - left);\n  const column1Row1 = 2 * near / (top - bottom);\n  const column2Row0 = (right + left) / (right - left);\n  const column2Row1 = (top + bottom) / (top - bottom);\n  const column2Row2 = -1;\n  const column2Row3 = -1;\n  const column3Row2 = -2 * near;\n  result[0] = column0Row0;\n  result[1] = 0;\n  result[2] = 0;\n  result[3] = 0;\n  result[4] = 0;\n  result[5] = column1Row1;\n  result[6] = 0;\n  result[7] = 0;\n  result[8] = column2Row0;\n  result[9] = column2Row1;\n  result[10] = column2Row2;\n  result[11] = column2Row3;\n  result[12] = 0;\n  result[13] = 0;\n  result[14] = column3Row2;\n  result[15] = 0;\n  return result;\n}\n//# sourceMappingURL=matrix4.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@math.gl/core/dist/esm/classes/matrix4.js?");

/***/ }),

/***/ "./node_modules/@math.gl/core/dist/esm/classes/vector3.js":
/*!****************************************************************!*\
  !*** ./node_modules/@math.gl/core/dist/esm/classes/vector3.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Vector3)\n/* harmony export */ });\n/* harmony import */ var _base_vector__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./base/vector */ \"./node_modules/@math.gl/core/dist/esm/classes/base/vector.js\");\n/* harmony import */ var _lib_common__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../lib/common */ \"./node_modules/@math.gl/core/dist/esm/lib/common.js\");\n/* harmony import */ var _lib_validators__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../lib/validators */ \"./node_modules/@math.gl/core/dist/esm/lib/validators.js\");\n/* harmony import */ var gl_matrix_vec3__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! gl-matrix/vec3 */ \"./node_modules/gl-matrix/esm/vec3.js\");\n/* harmony import */ var _lib_gl_matrix_extras__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../lib/gl-matrix-extras */ \"./node_modules/@math.gl/core/dist/esm/lib/gl-matrix-extras.js\");\n\n\n\n\n\nconst ORIGIN = [0, 0, 0];\nlet ZERO;\nclass Vector3 extends _base_vector__WEBPACK_IMPORTED_MODULE_0__[\"default\"] {\n  static get ZERO() {\n    if (!ZERO) {\n      ZERO = new Vector3(0, 0, 0);\n      Object.freeze(ZERO);\n    }\n\n    return ZERO;\n  }\n\n  constructor(x = 0, y = 0, z = 0) {\n    super(-0, -0, -0);\n\n    if (arguments.length === 1 && (0,_lib_common__WEBPACK_IMPORTED_MODULE_1__.isArray)(x)) {\n      this.copy(x);\n    } else {\n      if (_lib_common__WEBPACK_IMPORTED_MODULE_1__.config.debug) {\n        (0,_lib_validators__WEBPACK_IMPORTED_MODULE_2__.checkNumber)(x);\n        (0,_lib_validators__WEBPACK_IMPORTED_MODULE_2__.checkNumber)(y);\n        (0,_lib_validators__WEBPACK_IMPORTED_MODULE_2__.checkNumber)(z);\n      }\n\n      this[0] = x;\n      this[1] = y;\n      this[2] = z;\n    }\n  }\n\n  set(x, y, z) {\n    this[0] = x;\n    this[1] = y;\n    this[2] = z;\n    return this.check();\n  }\n\n  copy(array) {\n    this[0] = array[0];\n    this[1] = array[1];\n    this[2] = array[2];\n    return this.check();\n  }\n\n  fromObject(object) {\n    if (_lib_common__WEBPACK_IMPORTED_MODULE_1__.config.debug) {\n      (0,_lib_validators__WEBPACK_IMPORTED_MODULE_2__.checkNumber)(object.x);\n      (0,_lib_validators__WEBPACK_IMPORTED_MODULE_2__.checkNumber)(object.y);\n      (0,_lib_validators__WEBPACK_IMPORTED_MODULE_2__.checkNumber)(object.z);\n    }\n\n    this[0] = object.x;\n    this[1] = object.y;\n    this[2] = object.z;\n    return this.check();\n  }\n\n  toObject(object) {\n    object.x = this[0];\n    object.y = this[1];\n    object.z = this[2];\n    return object;\n  }\n\n  get ELEMENTS() {\n    return 3;\n  }\n\n  get z() {\n    return this[2];\n  }\n\n  set z(value) {\n    this[2] = (0,_lib_validators__WEBPACK_IMPORTED_MODULE_2__.checkNumber)(value);\n  }\n\n  angle(vector) {\n    return gl_matrix_vec3__WEBPACK_IMPORTED_MODULE_3__.angle(this, vector);\n  }\n\n  cross(vector) {\n    gl_matrix_vec3__WEBPACK_IMPORTED_MODULE_3__.cross(this, this, vector);\n    return this.check();\n  }\n\n  rotateX({\n    radians,\n    origin = ORIGIN\n  }) {\n    gl_matrix_vec3__WEBPACK_IMPORTED_MODULE_3__.rotateX(this, this, origin, radians);\n    return this.check();\n  }\n\n  rotateY({\n    radians,\n    origin = ORIGIN\n  }) {\n    gl_matrix_vec3__WEBPACK_IMPORTED_MODULE_3__.rotateY(this, this, origin, radians);\n    return this.check();\n  }\n\n  rotateZ({\n    radians,\n    origin = ORIGIN\n  }) {\n    gl_matrix_vec3__WEBPACK_IMPORTED_MODULE_3__.rotateZ(this, this, origin, radians);\n    return this.check();\n  }\n\n  transform(matrix4) {\n    return this.transformAsPoint(matrix4);\n  }\n\n  transformAsPoint(matrix4) {\n    gl_matrix_vec3__WEBPACK_IMPORTED_MODULE_3__.transformMat4(this, this, matrix4);\n    return this.check();\n  }\n\n  transformAsVector(matrix4) {\n    (0,_lib_gl_matrix_extras__WEBPACK_IMPORTED_MODULE_4__.vec3_transformMat4AsVector)(this, this, matrix4);\n    return this.check();\n  }\n\n  transformByMatrix3(matrix3) {\n    gl_matrix_vec3__WEBPACK_IMPORTED_MODULE_3__.transformMat3(this, this, matrix3);\n    return this.check();\n  }\n\n  transformByMatrix2(matrix2) {\n    (0,_lib_gl_matrix_extras__WEBPACK_IMPORTED_MODULE_4__.vec3_transformMat2)(this, this, matrix2);\n    return this.check();\n  }\n\n  transformByQuaternion(quaternion) {\n    gl_matrix_vec3__WEBPACK_IMPORTED_MODULE_3__.transformQuat(this, this, quaternion);\n    return this.check();\n  }\n\n}\n//# sourceMappingURL=vector3.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@math.gl/core/dist/esm/classes/vector3.js?");

/***/ }),

/***/ "./node_modules/@math.gl/core/dist/esm/lib/assert.js":
/*!***********************************************************!*\
  !*** ./node_modules/@math.gl/core/dist/esm/lib/assert.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ assert)\n/* harmony export */ });\nfunction assert(condition, message) {\n  if (!condition) {\n    throw new Error(\"math.gl assertion \".concat(message));\n  }\n}\n//# sourceMappingURL=assert.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@math.gl/core/dist/esm/lib/assert.js?");

/***/ }),

/***/ "./node_modules/@math.gl/core/dist/esm/lib/common.js":
/*!***********************************************************!*\
  !*** ./node_modules/@math.gl/core/dist/esm/lib/common.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   acos: () => (/* binding */ acos),\n/* harmony export */   asin: () => (/* binding */ asin),\n/* harmony export */   atan: () => (/* binding */ atan),\n/* harmony export */   clamp: () => (/* binding */ clamp),\n/* harmony export */   clone: () => (/* binding */ clone),\n/* harmony export */   config: () => (/* binding */ config),\n/* harmony export */   configure: () => (/* binding */ configure),\n/* harmony export */   cos: () => (/* binding */ cos),\n/* harmony export */   degrees: () => (/* binding */ degrees),\n/* harmony export */   equals: () => (/* binding */ equals),\n/* harmony export */   exactEquals: () => (/* binding */ exactEquals),\n/* harmony export */   formatValue: () => (/* binding */ formatValue),\n/* harmony export */   isArray: () => (/* binding */ isArray),\n/* harmony export */   lerp: () => (/* binding */ lerp),\n/* harmony export */   radians: () => (/* binding */ radians),\n/* harmony export */   sin: () => (/* binding */ sin),\n/* harmony export */   tan: () => (/* binding */ tan),\n/* harmony export */   toDegrees: () => (/* binding */ toDegrees),\n/* harmony export */   toRadians: () => (/* binding */ toRadians),\n/* harmony export */   withEpsilon: () => (/* binding */ withEpsilon)\n/* harmony export */ });\n/* harmony import */ var _assert__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./assert */ \"./node_modules/@math.gl/core/dist/esm/lib/assert.js\");\n\nconst RADIANS_TO_DEGREES = 1 / Math.PI * 180;\nconst DEGREES_TO_RADIANS = 1 / 180 * Math.PI;\nconst config = {\n  EPSILON: 1e-12,\n  debug: false,\n  precision: 4,\n  printTypes: false,\n  printDegrees: false,\n  printRowMajor: true\n};\nfunction configure(options) {\n  for (const key in options) {\n    (0,_assert__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(key in config);\n    config[key] = options[key];\n  }\n\n  return config;\n}\nfunction formatValue(value, {\n  precision = config.precision\n} = {}) {\n  value = round(value);\n  return \"\".concat(parseFloat(value.toPrecision(precision)));\n}\nfunction isArray(value) {\n  return Array.isArray(value) || ArrayBuffer.isView(value) && !(value instanceof DataView);\n}\nfunction clone(array) {\n  return 'clone' in array ? array.clone() : array.slice();\n}\nfunction toRadians(degrees) {\n  return radians(degrees);\n}\nfunction toDegrees(radians) {\n  return degrees(radians);\n}\nfunction radians(degrees, result) {\n  return map(degrees, degrees => degrees * DEGREES_TO_RADIANS, result);\n}\nfunction degrees(radians, result) {\n  return map(radians, radians => radians * RADIANS_TO_DEGREES, result);\n}\nfunction sin(radians, result) {\n  return map(radians, angle => Math.sin(angle), result);\n}\nfunction cos(radians, result) {\n  return map(radians, angle => Math.cos(angle), result);\n}\nfunction tan(radians, result) {\n  return map(radians, angle => Math.tan(angle), result);\n}\nfunction asin(radians, result) {\n  return map(radians, angle => Math.asin(angle), result);\n}\nfunction acos(radians, result) {\n  return map(radians, angle => Math.acos(angle), result);\n}\nfunction atan(radians, result) {\n  return map(radians, angle => Math.atan(angle), result);\n}\nfunction clamp(value, min, max) {\n  return map(value, value => Math.max(min, Math.min(max, value)));\n}\nfunction lerp(a, b, t) {\n  if (isArray(a)) {\n    return a.map((ai, i) => lerp(ai, b[i], t));\n  }\n\n  return t * b + (1 - t) * a;\n}\nfunction equals(a, b, epsilon) {\n  const oldEpsilon = config.EPSILON;\n\n  if (epsilon) {\n    config.EPSILON = epsilon;\n  }\n\n  try {\n    if (a === b) {\n      return true;\n    }\n\n    if (isArray(a) && isArray(b)) {\n      if (a.length !== b.length) {\n        return false;\n      }\n\n      for (let i = 0; i < a.length; ++i) {\n        if (!equals(a[i], b[i])) {\n          return false;\n        }\n      }\n\n      return true;\n    }\n\n    if (a && a.equals) {\n      return a.equals(b);\n    }\n\n    if (b && b.equals) {\n      return b.equals(a);\n    }\n\n    if (typeof a === 'number' && typeof b === 'number') {\n      return Math.abs(a - b) <= config.EPSILON * Math.max(1, Math.abs(a), Math.abs(b));\n    }\n\n    return false;\n  } finally {\n    config.EPSILON = oldEpsilon;\n  }\n}\nfunction exactEquals(a, b) {\n  if (a === b) {\n    return true;\n  }\n\n  if (a && typeof a === 'object' && b && typeof b === 'object') {\n    if (a.constructor !== b.constructor) {\n      return false;\n    }\n\n    if (a.exactEquals) {\n      return a.exactEquals(b);\n    }\n  }\n\n  if (isArray(a) && isArray(b)) {\n    if (a.length !== b.length) {\n      return false;\n    }\n\n    for (let i = 0; i < a.length; ++i) {\n      if (!exactEquals(a[i], b[i])) {\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n  return false;\n}\nfunction withEpsilon(epsilon, func) {\n  const oldPrecision = config.EPSILON;\n  config.EPSILON = epsilon;\n  let value;\n\n  try {\n    value = func();\n  } finally {\n    config.EPSILON = oldPrecision;\n  }\n\n  return value;\n}\n\nfunction round(value) {\n  return Math.round(value / config.EPSILON) * config.EPSILON;\n}\n\nfunction duplicateArray(array) {\n  return array.clone ? array.clone() : new Array(array.length);\n}\n\nfunction map(value, func, result) {\n  if (isArray(value)) {\n    const array = value;\n    result = result || duplicateArray(array);\n\n    for (let i = 0; i < result.length && i < array.length; ++i) {\n      result[i] = func(value[i], i, result);\n    }\n\n    return result;\n  }\n\n  return func(value);\n}\n//# sourceMappingURL=common.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@math.gl/core/dist/esm/lib/common.js?");

/***/ }),

/***/ "./node_modules/@math.gl/core/dist/esm/lib/gl-matrix-extras.js":
/*!*********************************************************************!*\
  !*** ./node_modules/@math.gl/core/dist/esm/lib/gl-matrix-extras.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   vec2_transformMat4AsVector: () => (/* binding */ vec2_transformMat4AsVector),\n/* harmony export */   vec3_transformMat2: () => (/* binding */ vec3_transformMat2),\n/* harmony export */   vec3_transformMat4AsVector: () => (/* binding */ vec3_transformMat4AsVector),\n/* harmony export */   vec4_transformMat2: () => (/* binding */ vec4_transformMat2),\n/* harmony export */   vec4_transformMat3: () => (/* binding */ vec4_transformMat3)\n/* harmony export */ });\nfunction vec2_transformMat4AsVector(out, a, m) {\n  const x = a[0];\n  const y = a[1];\n  const w = m[3] * x + m[7] * y || 1.0;\n  out[0] = (m[0] * x + m[4] * y) / w;\n  out[1] = (m[1] * x + m[5] * y) / w;\n  return out;\n}\nfunction vec3_transformMat4AsVector(out, a, m) {\n  const x = a[0];\n  const y = a[1];\n  const z = a[2];\n  const w = m[3] * x + m[7] * y + m[11] * z || 1.0;\n  out[0] = (m[0] * x + m[4] * y + m[8] * z) / w;\n  out[1] = (m[1] * x + m[5] * y + m[9] * z) / w;\n  out[2] = (m[2] * x + m[6] * y + m[10] * z) / w;\n  return out;\n}\nfunction vec3_transformMat2(out, a, m) {\n  const x = a[0];\n  const y = a[1];\n  out[0] = m[0] * x + m[2] * y;\n  out[1] = m[1] * x + m[3] * y;\n  out[2] = a[2];\n  return out;\n}\nfunction vec4_transformMat2(out, a, m) {\n  const x = a[0];\n  const y = a[1];\n  out[0] = m[0] * x + m[2] * y;\n  out[1] = m[1] * x + m[3] * y;\n  out[2] = a[2];\n  out[3] = a[3];\n  return out;\n}\nfunction vec4_transformMat3(out, a, m) {\n  const x = a[0];\n  const y = a[1];\n  const z = a[2];\n  out[0] = m[0] * x + m[3] * y + m[6] * z;\n  out[1] = m[1] * x + m[4] * y + m[7] * z;\n  out[2] = m[2] * x + m[5] * y + m[8] * z;\n  out[3] = a[3];\n  return out;\n}\n//# sourceMappingURL=gl-matrix-extras.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@math.gl/core/dist/esm/lib/gl-matrix-extras.js?");

/***/ }),

/***/ "./node_modules/@math.gl/core/dist/esm/lib/validators.js":
/*!***************************************************************!*\
  !*** ./node_modules/@math.gl/core/dist/esm/lib/validators.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   checkNumber: () => (/* binding */ checkNumber),\n/* harmony export */   checkVector: () => (/* binding */ checkVector),\n/* harmony export */   deprecated: () => (/* binding */ deprecated),\n/* harmony export */   validateVector: () => (/* binding */ validateVector)\n/* harmony export */ });\n/* harmony import */ var _common__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./common */ \"./node_modules/@math.gl/core/dist/esm/lib/common.js\");\n\nfunction validateVector(v, length) {\n  if (v.length !== length) {\n    return false;\n  }\n\n  for (let i = 0; i < v.length; ++i) {\n    if (!Number.isFinite(v[i])) {\n      return false;\n    }\n  }\n\n  return true;\n}\nfunction checkNumber(value) {\n  if (!Number.isFinite(value)) {\n    throw new Error(\"Invalid number \".concat(value));\n  }\n\n  return value;\n}\nfunction checkVector(v, length, callerName = '') {\n  if (_common__WEBPACK_IMPORTED_MODULE_0__.config.debug && !validateVector(v, length)) {\n    throw new Error(\"math.gl: \".concat(callerName, \" some fields set to invalid numbers'\"));\n  }\n\n  return v;\n}\nconst map = {};\nfunction deprecated(method, version) {\n  if (!map[method]) {\n    map[method] = true;\n    console.warn(\"\".concat(method, \" has been removed in version \").concat(version, \", see upgrade guide for more information\"));\n  }\n}\n//# sourceMappingURL=validators.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@math.gl/core/dist/esm/lib/validators.js?");

/***/ }),

/***/ "./node_modules/@math.gl/web-mercator/dist/esm/assert.js":
/*!***************************************************************!*\
  !*** ./node_modules/@math.gl/web-mercator/dist/esm/assert.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ assert)\n/* harmony export */ });\nfunction assert(condition, message) {\n  if (!condition) {\n    throw new Error(message || '@math.gl/web-mercator: assertion failed.');\n  }\n}\n//# sourceMappingURL=assert.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@math.gl/web-mercator/dist/esm/assert.js?");

/***/ }),

/***/ "./node_modules/@math.gl/web-mercator/dist/esm/fit-bounds.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@math.gl/web-mercator/dist/esm/fit-bounds.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ fitBounds)\n/* harmony export */ });\n/* harmony import */ var _assert__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./assert */ \"./node_modules/@math.gl/web-mercator/dist/esm/assert.js\");\n/* harmony import */ var _math_utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./math-utils */ \"./node_modules/@math.gl/web-mercator/dist/esm/math-utils.js\");\n/* harmony import */ var _web_mercator_utils__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./web-mercator-utils */ \"./node_modules/@math.gl/web-mercator/dist/esm/web-mercator-utils.js\");\n\n\n\nfunction fitBounds(options) {\n  const {\n    width,\n    height,\n    bounds,\n    minExtent = 0,\n    maxZoom = 24,\n    offset = [0, 0]\n  } = options;\n  const [[west, south], [east, north]] = bounds;\n  const padding = getPaddingObject(options.padding);\n  const nw = (0,_web_mercator_utils__WEBPACK_IMPORTED_MODULE_2__.lngLatToWorld)([west, (0,_math_utils__WEBPACK_IMPORTED_MODULE_1__.clamp)(north, -_web_mercator_utils__WEBPACK_IMPORTED_MODULE_2__.MAX_LATITUDE, _web_mercator_utils__WEBPACK_IMPORTED_MODULE_2__.MAX_LATITUDE)]);\n  const se = (0,_web_mercator_utils__WEBPACK_IMPORTED_MODULE_2__.lngLatToWorld)([east, (0,_math_utils__WEBPACK_IMPORTED_MODULE_1__.clamp)(south, -_web_mercator_utils__WEBPACK_IMPORTED_MODULE_2__.MAX_LATITUDE, _web_mercator_utils__WEBPACK_IMPORTED_MODULE_2__.MAX_LATITUDE)]);\n  const size = [Math.max(Math.abs(se[0] - nw[0]), minExtent), Math.max(Math.abs(se[1] - nw[1]), minExtent)];\n  const targetSize = [width - padding.left - padding.right - Math.abs(offset[0]) * 2, height - padding.top - padding.bottom - Math.abs(offset[1]) * 2];\n  (0,_assert__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(targetSize[0] > 0 && targetSize[1] > 0);\n  const scaleX = targetSize[0] / size[0];\n  const scaleY = targetSize[1] / size[1];\n  const offsetX = (padding.right - padding.left) / 2 / scaleX;\n  const offsetY = (padding.top - padding.bottom) / 2 / scaleY;\n  const center = [(se[0] + nw[0]) / 2 + offsetX, (se[1] + nw[1]) / 2 + offsetY];\n  const centerLngLat = (0,_web_mercator_utils__WEBPACK_IMPORTED_MODULE_2__.worldToLngLat)(center);\n  const zoom = Math.min(maxZoom, (0,_math_utils__WEBPACK_IMPORTED_MODULE_1__.log2)(Math.abs(Math.min(scaleX, scaleY))));\n  (0,_assert__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(Number.isFinite(zoom));\n  return {\n    longitude: centerLngLat[0],\n    latitude: centerLngLat[1],\n    zoom\n  };\n}\n\nfunction getPaddingObject(padding = 0) {\n  if (typeof padding === 'number') {\n    return {\n      top: padding,\n      bottom: padding,\n      left: padding,\n      right: padding\n    };\n  }\n\n  (0,_assert__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(Number.isFinite(padding.top) && Number.isFinite(padding.bottom) && Number.isFinite(padding.left) && Number.isFinite(padding.right));\n  return padding;\n}\n//# sourceMappingURL=fit-bounds.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@math.gl/web-mercator/dist/esm/fit-bounds.js?");

/***/ }),

/***/ "./node_modules/@math.gl/web-mercator/dist/esm/fly-to-viewport.js":
/*!************************************************************************!*\
  !*** ./node_modules/@math.gl/web-mercator/dist/esm/fly-to-viewport.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ flyToViewport),\n/* harmony export */   getFlyToDuration: () => (/* binding */ getFlyToDuration)\n/* harmony export */ });\n/* harmony import */ var _math_utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./math-utils */ \"./node_modules/@math.gl/web-mercator/dist/esm/math-utils.js\");\n/* harmony import */ var _web_mercator_utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./web-mercator-utils */ \"./node_modules/@math.gl/web-mercator/dist/esm/web-mercator-utils.js\");\n/* harmony import */ var gl_matrix_vec2__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! gl-matrix/vec2 */ \"./node_modules/gl-matrix/esm/vec2.js\");\n\n\n\nconst EPSILON = 0.01;\nconst VIEWPORT_TRANSITION_PROPS = ['longitude', 'latitude', 'zoom'];\nconst DEFAULT_OPTS = {\n  curve: 1.414,\n  speed: 1.2\n};\nfunction flyToViewport(startProps, endProps, t, options) {\n  const {\n    startZoom,\n    startCenterXY,\n    uDelta,\n    w0,\n    u1,\n    S,\n    rho,\n    rho2,\n    r0\n  } = getFlyToTransitionParams(startProps, endProps, options);\n\n  if (u1 < EPSILON) {\n    const viewport = {};\n\n    for (const key of VIEWPORT_TRANSITION_PROPS) {\n      const startValue = startProps[key];\n      const endValue = endProps[key];\n      viewport[key] = (0,_math_utils__WEBPACK_IMPORTED_MODULE_0__.lerp)(startValue, endValue, t);\n    }\n\n    return viewport;\n  }\n\n  const s = t * S;\n  const w = Math.cosh(r0) / Math.cosh(r0 + rho * s);\n  const u = w0 * ((Math.cosh(r0) * Math.tanh(r0 + rho * s) - Math.sinh(r0)) / rho2) / u1;\n  const scaleIncrement = 1 / w;\n  const newZoom = startZoom + (0,_web_mercator_utils__WEBPACK_IMPORTED_MODULE_1__.scaleToZoom)(scaleIncrement);\n  const newCenterWorld = gl_matrix_vec2__WEBPACK_IMPORTED_MODULE_2__.scale([], uDelta, u);\n  gl_matrix_vec2__WEBPACK_IMPORTED_MODULE_2__.add(newCenterWorld, newCenterWorld, startCenterXY);\n  const newCenter = (0,_web_mercator_utils__WEBPACK_IMPORTED_MODULE_1__.worldToLngLat)(newCenterWorld);\n  return {\n    longitude: newCenter[0],\n    latitude: newCenter[1],\n    zoom: newZoom\n  };\n}\nfunction getFlyToDuration(startProps, endProps, options) {\n  const opts = { ...DEFAULT_OPTS,\n    ...options\n  };\n  const {\n    screenSpeed,\n    speed,\n    maxDuration\n  } = opts;\n  const {\n    S,\n    rho\n  } = getFlyToTransitionParams(startProps, endProps, opts);\n  const length = 1000 * S;\n  let duration;\n\n  if (Number.isFinite(screenSpeed)) {\n    duration = length / (screenSpeed / rho);\n  } else {\n    duration = length / speed;\n  }\n\n  return Number.isFinite(maxDuration) && duration > maxDuration ? 0 : duration;\n}\n\nfunction getFlyToTransitionParams(startProps, endProps, opts) {\n  opts = Object.assign({}, DEFAULT_OPTS, opts);\n  const rho = opts.curve;\n  const startZoom = startProps.zoom;\n  const startCenter = [startProps.longitude, startProps.latitude];\n  const startScale = (0,_web_mercator_utils__WEBPACK_IMPORTED_MODULE_1__.zoomToScale)(startZoom);\n  const endZoom = endProps.zoom;\n  const endCenter = [endProps.longitude, endProps.latitude];\n  const scale = (0,_web_mercator_utils__WEBPACK_IMPORTED_MODULE_1__.zoomToScale)(endZoom - startZoom);\n  const startCenterXY = (0,_web_mercator_utils__WEBPACK_IMPORTED_MODULE_1__.lngLatToWorld)(startCenter);\n  const endCenterXY = (0,_web_mercator_utils__WEBPACK_IMPORTED_MODULE_1__.lngLatToWorld)(endCenter);\n  const uDelta = gl_matrix_vec2__WEBPACK_IMPORTED_MODULE_2__.sub([], endCenterXY, startCenterXY);\n  const w0 = Math.max(startProps.width, startProps.height);\n  const w1 = w0 / scale;\n  const u1 = gl_matrix_vec2__WEBPACK_IMPORTED_MODULE_2__.length(uDelta) * startScale;\n\n  const _u1 = Math.max(u1, EPSILON);\n\n  const rho2 = rho * rho;\n  const b0 = (w1 * w1 - w0 * w0 + rho2 * rho2 * _u1 * _u1) / (2 * w0 * rho2 * _u1);\n  const b1 = (w1 * w1 - w0 * w0 - rho2 * rho2 * _u1 * _u1) / (2 * w1 * rho2 * _u1);\n  const r0 = Math.log(Math.sqrt(b0 * b0 + 1) - b0);\n  const r1 = Math.log(Math.sqrt(b1 * b1 + 1) - b1);\n  const S = (r1 - r0) / rho;\n  return {\n    startZoom,\n    startCenterXY,\n    uDelta,\n    w0,\n    u1,\n    S,\n    rho,\n    rho2,\n    r0,\n    r1\n  };\n}\n//# sourceMappingURL=fly-to-viewport.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@math.gl/web-mercator/dist/esm/fly-to-viewport.js?");

/***/ }),

/***/ "./node_modules/@math.gl/web-mercator/dist/esm/get-bounds.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@math.gl/web-mercator/dist/esm/get-bounds.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ getBounds)\n/* harmony export */ });\n/* harmony import */ var _web_mercator_utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./web-mercator-utils */ \"./node_modules/@math.gl/web-mercator/dist/esm/web-mercator-utils.js\");\n/* harmony import */ var gl_matrix_vec2__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! gl-matrix/vec2 */ \"./node_modules/gl-matrix/esm/vec2.js\");\n/* harmony import */ var _math_utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./math-utils */ \"./node_modules/@math.gl/web-mercator/dist/esm/math-utils.js\");\n\n\n\nconst DEGREES_TO_RADIANS = Math.PI / 180;\nfunction getBounds(viewport, z = 0) {\n  const {\n    width,\n    height,\n    unproject\n  } = viewport;\n  const unprojectOps = {\n    targetZ: z\n  };\n  const bottomLeft = unproject([0, height], unprojectOps);\n  const bottomRight = unproject([width, height], unprojectOps);\n  let topLeft;\n  let topRight;\n  const halfFov = viewport.fovy ? 0.5 * viewport.fovy * DEGREES_TO_RADIANS : Math.atan(0.5 / viewport.altitude);\n  const angleToGround = (90 - viewport.pitch) * DEGREES_TO_RADIANS;\n\n  if (halfFov > angleToGround - 0.01) {\n    topLeft = unprojectOnFarPlane(viewport, 0, z);\n    topRight = unprojectOnFarPlane(viewport, width, z);\n  } else {\n    topLeft = unproject([0, 0], unprojectOps);\n    topRight = unproject([width, 0], unprojectOps);\n  }\n\n  return [bottomLeft, bottomRight, topRight, topLeft];\n}\n\nfunction unprojectOnFarPlane(viewport, x, targetZ) {\n  const {\n    pixelUnprojectionMatrix\n  } = viewport;\n  const coord0 = (0,_math_utils__WEBPACK_IMPORTED_MODULE_1__.transformVector)(pixelUnprojectionMatrix, [x, 0, 1, 1]);\n  const coord1 = (0,_math_utils__WEBPACK_IMPORTED_MODULE_1__.transformVector)(pixelUnprojectionMatrix, [x, viewport.height, 1, 1]);\n  const z = targetZ * viewport.distanceScales.unitsPerMeter[2];\n  const t = (z - coord0[2]) / (coord1[2] - coord0[2]);\n  const coord = gl_matrix_vec2__WEBPACK_IMPORTED_MODULE_2__.lerp([], coord0, coord1, t);\n  const result = (0,_web_mercator_utils__WEBPACK_IMPORTED_MODULE_0__.worldToLngLat)(coord);\n  result.push(targetZ);\n  return result;\n}\n//# sourceMappingURL=get-bounds.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@math.gl/web-mercator/dist/esm/get-bounds.js?");

/***/ }),

/***/ "./node_modules/@math.gl/web-mercator/dist/esm/index.js":
/*!**************************************************************!*\
  !*** ./node_modules/@math.gl/web-mercator/dist/esm/index.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   MAX_LATITUDE: () => (/* reexport safe */ _web_mercator_utils__WEBPACK_IMPORTED_MODULE_5__.MAX_LATITUDE),\n/* harmony export */   WebMercatorViewport: () => (/* reexport safe */ _web_mercator_viewport__WEBPACK_IMPORTED_MODULE_0__[\"default\"]),\n/* harmony export */   addMetersToLngLat: () => (/* reexport safe */ _web_mercator_utils__WEBPACK_IMPORTED_MODULE_5__.addMetersToLngLat),\n/* harmony export */   altitudeToFovy: () => (/* reexport safe */ _web_mercator_utils__WEBPACK_IMPORTED_MODULE_5__.altitudeToFovy),\n/* harmony export */   \"default\": () => (/* reexport safe */ _web_mercator_viewport__WEBPACK_IMPORTED_MODULE_0__[\"default\"]),\n/* harmony export */   fitBounds: () => (/* reexport safe */ _fit_bounds__WEBPACK_IMPORTED_MODULE_2__[\"default\"]),\n/* harmony export */   flyToViewport: () => (/* reexport safe */ _fly_to_viewport__WEBPACK_IMPORTED_MODULE_4__[\"default\"]),\n/* harmony export */   fovyToAltitude: () => (/* reexport safe */ _web_mercator_utils__WEBPACK_IMPORTED_MODULE_5__.fovyToAltitude),\n/* harmony export */   getBounds: () => (/* reexport safe */ _get_bounds__WEBPACK_IMPORTED_MODULE_1__[\"default\"]),\n/* harmony export */   getDistanceScales: () => (/* reexport safe */ _web_mercator_utils__WEBPACK_IMPORTED_MODULE_5__.getDistanceScales),\n/* harmony export */   getFlyToDuration: () => (/* reexport safe */ _fly_to_viewport__WEBPACK_IMPORTED_MODULE_4__.getFlyToDuration),\n/* harmony export */   getMeterZoom: () => (/* reexport safe */ _web_mercator_utils__WEBPACK_IMPORTED_MODULE_5__.getMeterZoom),\n/* harmony export */   getProjectionMatrix: () => (/* reexport safe */ _web_mercator_utils__WEBPACK_IMPORTED_MODULE_5__.getProjectionMatrix),\n/* harmony export */   getProjectionParameters: () => (/* reexport safe */ _web_mercator_utils__WEBPACK_IMPORTED_MODULE_5__.getProjectionParameters),\n/* harmony export */   getViewMatrix: () => (/* reexport safe */ _web_mercator_utils__WEBPACK_IMPORTED_MODULE_5__.getViewMatrix),\n/* harmony export */   lngLatToWorld: () => (/* reexport safe */ _web_mercator_utils__WEBPACK_IMPORTED_MODULE_5__.lngLatToWorld),\n/* harmony export */   normalizeViewportProps: () => (/* reexport safe */ _normalize_viewport_props__WEBPACK_IMPORTED_MODULE_3__[\"default\"]),\n/* harmony export */   pixelsToWorld: () => (/* reexport safe */ _web_mercator_utils__WEBPACK_IMPORTED_MODULE_5__.pixelsToWorld),\n/* harmony export */   scaleToZoom: () => (/* reexport safe */ _web_mercator_utils__WEBPACK_IMPORTED_MODULE_5__.scaleToZoom),\n/* harmony export */   unitsPerMeter: () => (/* reexport safe */ _web_mercator_utils__WEBPACK_IMPORTED_MODULE_5__.unitsPerMeter),\n/* harmony export */   worldToLngLat: () => (/* reexport safe */ _web_mercator_utils__WEBPACK_IMPORTED_MODULE_5__.worldToLngLat),\n/* harmony export */   worldToPixels: () => (/* reexport safe */ _web_mercator_utils__WEBPACK_IMPORTED_MODULE_5__.worldToPixels),\n/* harmony export */   zoomToScale: () => (/* reexport safe */ _web_mercator_utils__WEBPACK_IMPORTED_MODULE_5__.zoomToScale)\n/* harmony export */ });\n/* harmony import */ var _web_mercator_viewport__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./web-mercator-viewport */ \"./node_modules/@math.gl/web-mercator/dist/esm/web-mercator-viewport.js\");\n/* harmony import */ var _get_bounds__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./get-bounds */ \"./node_modules/@math.gl/web-mercator/dist/esm/get-bounds.js\");\n/* harmony import */ var _fit_bounds__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./fit-bounds */ \"./node_modules/@math.gl/web-mercator/dist/esm/fit-bounds.js\");\n/* harmony import */ var _normalize_viewport_props__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./normalize-viewport-props */ \"./node_modules/@math.gl/web-mercator/dist/esm/normalize-viewport-props.js\");\n/* harmony import */ var _fly_to_viewport__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./fly-to-viewport */ \"./node_modules/@math.gl/web-mercator/dist/esm/fly-to-viewport.js\");\n/* harmony import */ var _web_mercator_utils__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./web-mercator-utils */ \"./node_modules/@math.gl/web-mercator/dist/esm/web-mercator-utils.js\");\n\n\n\n\n\n\n\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@math.gl/web-mercator/dist/esm/index.js?");

/***/ }),

/***/ "./node_modules/@math.gl/web-mercator/dist/esm/math-utils.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@math.gl/web-mercator/dist/esm/math-utils.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   clamp: () => (/* binding */ clamp),\n/* harmony export */   createMat4: () => (/* binding */ createMat4),\n/* harmony export */   lerp: () => (/* binding */ lerp),\n/* harmony export */   log2: () => (/* binding */ log2),\n/* harmony export */   mod: () => (/* binding */ mod),\n/* harmony export */   transformVector: () => (/* binding */ transformVector)\n/* harmony export */ });\n/* harmony import */ var gl_matrix_vec4__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! gl-matrix/vec4 */ \"./node_modules/gl-matrix/esm/vec4.js\");\n\nfunction createMat4() {\n  return [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1];\n}\nfunction transformVector(matrix, vector) {\n  const result = (0,gl_matrix_vec4__WEBPACK_IMPORTED_MODULE_0__.transformMat4)([], vector, matrix);\n  (0,gl_matrix_vec4__WEBPACK_IMPORTED_MODULE_0__.scale)(result, result, 1 / result[3]);\n  return result;\n}\nfunction mod(value, divisor) {\n  const modulus = value % divisor;\n  return modulus < 0 ? divisor + modulus : modulus;\n}\nfunction lerp(start, end, step) {\n  return step * end + (1 - step) * start;\n}\nfunction clamp(x, min, max) {\n  return x < min ? min : x > max ? max : x;\n}\n\nfunction ieLog2(x) {\n  return Math.log(x) * Math.LOG2E;\n}\n\nconst log2 = Math.log2 || ieLog2;\n//# sourceMappingURL=math-utils.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@math.gl/web-mercator/dist/esm/math-utils.js?");

/***/ }),

/***/ "./node_modules/@math.gl/web-mercator/dist/esm/normalize-viewport-props.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/@math.gl/web-mercator/dist/esm/normalize-viewport-props.js ***!
  \*********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ normalizeViewportProps)\n/* harmony export */ });\n/* harmony import */ var _web_mercator_utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./web-mercator-utils */ \"./node_modules/@math.gl/web-mercator/dist/esm/web-mercator-utils.js\");\n/* harmony import */ var _math_utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./math-utils */ \"./node_modules/@math.gl/web-mercator/dist/esm/math-utils.js\");\n\n\nconst TILE_SIZE = 512;\nfunction normalizeViewportProps(props) {\n  const {\n    width,\n    height,\n    pitch = 0\n  } = props;\n  let {\n    longitude,\n    latitude,\n    zoom,\n    bearing = 0\n  } = props;\n\n  if (longitude < -180 || longitude > 180) {\n    longitude = (0,_math_utils__WEBPACK_IMPORTED_MODULE_1__.mod)(longitude + 180, 360) - 180;\n  }\n\n  if (bearing < -180 || bearing > 180) {\n    bearing = (0,_math_utils__WEBPACK_IMPORTED_MODULE_1__.mod)(bearing + 180, 360) - 180;\n  }\n\n  const minZoom = (0,_math_utils__WEBPACK_IMPORTED_MODULE_1__.log2)(height / TILE_SIZE);\n\n  if (zoom <= minZoom) {\n    zoom = minZoom;\n    latitude = 0;\n  } else {\n    const halfHeightPixels = height / 2 / Math.pow(2, zoom);\n    const minLatitude = (0,_web_mercator_utils__WEBPACK_IMPORTED_MODULE_0__.worldToLngLat)([0, halfHeightPixels])[1];\n\n    if (latitude < minLatitude) {\n      latitude = minLatitude;\n    } else {\n      const maxLatitude = (0,_web_mercator_utils__WEBPACK_IMPORTED_MODULE_0__.worldToLngLat)([0, TILE_SIZE - halfHeightPixels])[1];\n\n      if (latitude > maxLatitude) {\n        latitude = maxLatitude;\n      }\n    }\n  }\n\n  return {\n    width,\n    height,\n    longitude,\n    latitude,\n    zoom,\n    pitch,\n    bearing\n  };\n}\n//# sourceMappingURL=normalize-viewport-props.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@math.gl/web-mercator/dist/esm/normalize-viewport-props.js?");

/***/ }),

/***/ "./node_modules/@math.gl/web-mercator/dist/esm/web-mercator-utils.js":
/*!***************************************************************************!*\
  !*** ./node_modules/@math.gl/web-mercator/dist/esm/web-mercator-utils.js ***!
  \***************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   DEFAULT_ALTITUDE: () => (/* binding */ DEFAULT_ALTITUDE),\n/* harmony export */   MAX_LATITUDE: () => (/* binding */ MAX_LATITUDE),\n/* harmony export */   addMetersToLngLat: () => (/* binding */ addMetersToLngLat),\n/* harmony export */   altitudeToFovy: () => (/* binding */ altitudeToFovy),\n/* harmony export */   fovyToAltitude: () => (/* binding */ fovyToAltitude),\n/* harmony export */   getDistanceScales: () => (/* binding */ getDistanceScales),\n/* harmony export */   getMeterZoom: () => (/* binding */ getMeterZoom),\n/* harmony export */   getProjectionMatrix: () => (/* binding */ getProjectionMatrix),\n/* harmony export */   getProjectionParameters: () => (/* binding */ getProjectionParameters),\n/* harmony export */   getViewMatrix: () => (/* binding */ getViewMatrix),\n/* harmony export */   lngLatToWorld: () => (/* binding */ lngLatToWorld),\n/* harmony export */   pixelsToWorld: () => (/* binding */ pixelsToWorld),\n/* harmony export */   scaleToZoom: () => (/* binding */ scaleToZoom),\n/* harmony export */   unitsPerMeter: () => (/* binding */ unitsPerMeter),\n/* harmony export */   worldToLngLat: () => (/* binding */ worldToLngLat),\n/* harmony export */   worldToPixels: () => (/* binding */ worldToPixels),\n/* harmony export */   zoomToScale: () => (/* binding */ zoomToScale)\n/* harmony export */ });\n/* harmony import */ var _math_utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./math-utils */ \"./node_modules/@math.gl/web-mercator/dist/esm/math-utils.js\");\n/* harmony import */ var gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! gl-matrix/mat4 */ \"./node_modules/gl-matrix/esm/mat4.js\");\n/* harmony import */ var gl_matrix_vec2__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! gl-matrix/vec2 */ \"./node_modules/gl-matrix/esm/vec2.js\");\n/* harmony import */ var gl_matrix_vec3__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! gl-matrix/vec3 */ \"./node_modules/gl-matrix/esm/vec3.js\");\n/* harmony import */ var _assert__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./assert */ \"./node_modules/@math.gl/web-mercator/dist/esm/assert.js\");\n\n\n\n\n\nconst PI = Math.PI;\nconst PI_4 = PI / 4;\nconst DEGREES_TO_RADIANS = PI / 180;\nconst RADIANS_TO_DEGREES = 180 / PI;\nconst TILE_SIZE = 512;\nconst EARTH_CIRCUMFERENCE = 40.03e6;\nconst MAX_LATITUDE = 85.051129;\nconst DEFAULT_ALTITUDE = 1.5;\nfunction zoomToScale(zoom) {\n  return Math.pow(2, zoom);\n}\nfunction scaleToZoom(scale) {\n  return (0,_math_utils__WEBPACK_IMPORTED_MODULE_0__.log2)(scale);\n}\nfunction lngLatToWorld(lngLat) {\n  const [lng, lat] = lngLat;\n  (0,_assert__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(Number.isFinite(lng));\n  (0,_assert__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(Number.isFinite(lat) && lat >= -90 && lat <= 90, 'invalid latitude');\n  const lambda2 = lng * DEGREES_TO_RADIANS;\n  const phi2 = lat * DEGREES_TO_RADIANS;\n  const x = TILE_SIZE * (lambda2 + PI) / (2 * PI);\n  const y = TILE_SIZE * (PI + Math.log(Math.tan(PI_4 + phi2 * 0.5))) / (2 * PI);\n  return [x, y];\n}\nfunction worldToLngLat(xy) {\n  const [x, y] = xy;\n  const lambda2 = x / TILE_SIZE * (2 * PI) - PI;\n  const phi2 = 2 * (Math.atan(Math.exp(y / TILE_SIZE * (2 * PI) - PI)) - PI_4);\n  return [lambda2 * RADIANS_TO_DEGREES, phi2 * RADIANS_TO_DEGREES];\n}\nfunction getMeterZoom(options) {\n  const {\n    latitude\n  } = options;\n  (0,_assert__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(Number.isFinite(latitude));\n  const latCosine = Math.cos(latitude * DEGREES_TO_RADIANS);\n  return scaleToZoom(EARTH_CIRCUMFERENCE * latCosine) - 9;\n}\nfunction unitsPerMeter(latitude) {\n  const latCosine = Math.cos(latitude * DEGREES_TO_RADIANS);\n  return TILE_SIZE / EARTH_CIRCUMFERENCE / latCosine;\n}\nfunction getDistanceScales(options) {\n  const {\n    latitude,\n    longitude,\n    highPrecision = false\n  } = options;\n  (0,_assert__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(Number.isFinite(latitude) && Number.isFinite(longitude));\n  const worldSize = TILE_SIZE;\n  const latCosine = Math.cos(latitude * DEGREES_TO_RADIANS);\n  const unitsPerDegreeX = worldSize / 360;\n  const unitsPerDegreeY = unitsPerDegreeX / latCosine;\n  const altUnitsPerMeter = worldSize / EARTH_CIRCUMFERENCE / latCosine;\n  const result = {\n    unitsPerMeter: [altUnitsPerMeter, altUnitsPerMeter, altUnitsPerMeter],\n    metersPerUnit: [1 / altUnitsPerMeter, 1 / altUnitsPerMeter, 1 / altUnitsPerMeter],\n    unitsPerDegree: [unitsPerDegreeX, unitsPerDegreeY, altUnitsPerMeter],\n    degreesPerUnit: [1 / unitsPerDegreeX, 1 / unitsPerDegreeY, 1 / altUnitsPerMeter]\n  };\n\n  if (highPrecision) {\n    const latCosine2 = DEGREES_TO_RADIANS * Math.tan(latitude * DEGREES_TO_RADIANS) / latCosine;\n    const unitsPerDegreeY2 = unitsPerDegreeX * latCosine2 / 2;\n    const altUnitsPerDegree2 = worldSize / EARTH_CIRCUMFERENCE * latCosine2;\n    const altUnitsPerMeter2 = altUnitsPerDegree2 / unitsPerDegreeY * altUnitsPerMeter;\n    result.unitsPerDegree2 = [0, unitsPerDegreeY2, altUnitsPerDegree2];\n    result.unitsPerMeter2 = [altUnitsPerMeter2, 0, altUnitsPerMeter2];\n  }\n\n  return result;\n}\nfunction addMetersToLngLat(lngLatZ, xyz) {\n  const [longitude, latitude, z0] = lngLatZ;\n  const [x, y, z] = xyz;\n  const {\n    unitsPerMeter,\n    unitsPerMeter2\n  } = getDistanceScales({\n    longitude,\n    latitude,\n    highPrecision: true\n  });\n  const worldspace = lngLatToWorld(lngLatZ);\n  worldspace[0] += x * (unitsPerMeter[0] + unitsPerMeter2[0] * y);\n  worldspace[1] += y * (unitsPerMeter[1] + unitsPerMeter2[1] * y);\n  const newLngLat = worldToLngLat(worldspace);\n  const newZ = (z0 || 0) + (z || 0);\n  return Number.isFinite(z0) || Number.isFinite(z) ? [newLngLat[0], newLngLat[1], newZ] : newLngLat;\n}\nfunction getViewMatrix(options) {\n  const {\n    height,\n    pitch,\n    bearing,\n    altitude,\n    scale,\n    center\n  } = options;\n  const vm = (0,_math_utils__WEBPACK_IMPORTED_MODULE_0__.createMat4)();\n  gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_2__.translate(vm, vm, [0, 0, -altitude]);\n  gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_2__.rotateX(vm, vm, -pitch * DEGREES_TO_RADIANS);\n  gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_2__.rotateZ(vm, vm, bearing * DEGREES_TO_RADIANS);\n  const relativeScale = scale / height;\n  gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_2__.scale(vm, vm, [relativeScale, relativeScale, relativeScale]);\n\n  if (center) {\n    gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_2__.translate(vm, vm, gl_matrix_vec3__WEBPACK_IMPORTED_MODULE_3__.negate([], center));\n  }\n\n  return vm;\n}\nfunction getProjectionParameters(options) {\n  const {\n    width,\n    height,\n    altitude,\n    pitch = 0,\n    offset,\n    center,\n    scale,\n    nearZMultiplier = 1,\n    farZMultiplier = 1\n  } = options;\n  let {\n    fovy = altitudeToFovy(DEFAULT_ALTITUDE)\n  } = options;\n\n  if (altitude !== undefined) {\n    fovy = altitudeToFovy(altitude);\n  }\n\n  const fovRadians = fovy * DEGREES_TO_RADIANS;\n  const pitchRadians = pitch * DEGREES_TO_RADIANS;\n  const focalDistance = fovyToAltitude(fovy);\n  let cameraToSeaLevelDistance = focalDistance;\n\n  if (center) {\n    cameraToSeaLevelDistance += center[2] * scale / Math.cos(pitchRadians) / height;\n  }\n\n  const fovAboveCenter = fovRadians * (0.5 + (offset ? offset[1] : 0) / height);\n  const topHalfSurfaceDistance = Math.sin(fovAboveCenter) * cameraToSeaLevelDistance / Math.sin((0,_math_utils__WEBPACK_IMPORTED_MODULE_0__.clamp)(Math.PI / 2 - pitchRadians - fovAboveCenter, 0.01, Math.PI - 0.01));\n  const furthestDistance = Math.sin(pitchRadians) * topHalfSurfaceDistance + cameraToSeaLevelDistance;\n  const horizonDistance = cameraToSeaLevelDistance * 10;\n  const farZ = Math.min(furthestDistance * farZMultiplier, horizonDistance);\n  return {\n    fov: fovRadians,\n    aspect: width / height,\n    focalDistance,\n    near: nearZMultiplier,\n    far: farZ\n  };\n}\nfunction getProjectionMatrix(options) {\n  const {\n    fov,\n    aspect,\n    near,\n    far\n  } = getProjectionParameters(options);\n  const projectionMatrix = gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_2__.perspective([], fov, aspect, near, far);\n  return projectionMatrix;\n}\nfunction altitudeToFovy(altitude) {\n  return 2 * Math.atan(0.5 / altitude) * RADIANS_TO_DEGREES;\n}\nfunction fovyToAltitude(fovy) {\n  return 0.5 / Math.tan(0.5 * fovy * DEGREES_TO_RADIANS);\n}\nfunction worldToPixels(xyz, pixelProjectionMatrix) {\n  const [x, y, z = 0] = xyz;\n  (0,_assert__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(Number.isFinite(x) && Number.isFinite(y) && Number.isFinite(z));\n  return (0,_math_utils__WEBPACK_IMPORTED_MODULE_0__.transformVector)(pixelProjectionMatrix, [x, y, z, 1]);\n}\nfunction pixelsToWorld(xyz, pixelUnprojectionMatrix, targetZ = 0) {\n  const [x, y, z] = xyz;\n  (0,_assert__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(Number.isFinite(x) && Number.isFinite(y), 'invalid pixel coordinate');\n\n  if (Number.isFinite(z)) {\n    const coord = (0,_math_utils__WEBPACK_IMPORTED_MODULE_0__.transformVector)(pixelUnprojectionMatrix, [x, y, z, 1]);\n    return coord;\n  }\n\n  const coord0 = (0,_math_utils__WEBPACK_IMPORTED_MODULE_0__.transformVector)(pixelUnprojectionMatrix, [x, y, 0, 1]);\n  const coord1 = (0,_math_utils__WEBPACK_IMPORTED_MODULE_0__.transformVector)(pixelUnprojectionMatrix, [x, y, 1, 1]);\n  const z0 = coord0[2];\n  const z1 = coord1[2];\n  const t = z0 === z1 ? 0 : ((targetZ || 0) - z0) / (z1 - z0);\n  return gl_matrix_vec2__WEBPACK_IMPORTED_MODULE_4__.lerp([], coord0, coord1, t);\n}\n//# sourceMappingURL=web-mercator-utils.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@math.gl/web-mercator/dist/esm/web-mercator-utils.js?");

/***/ }),

/***/ "./node_modules/@math.gl/web-mercator/dist/esm/web-mercator-viewport.js":
/*!******************************************************************************!*\
  !*** ./node_modules/@math.gl/web-mercator/dist/esm/web-mercator-viewport.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ WebMercatorViewport)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _math_utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./math-utils */ \"./node_modules/@math.gl/web-mercator/dist/esm/math-utils.js\");\n/* harmony import */ var _web_mercator_utils__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./web-mercator-utils */ \"./node_modules/@math.gl/web-mercator/dist/esm/web-mercator-utils.js\");\n/* harmony import */ var _fit_bounds__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./fit-bounds */ \"./node_modules/@math.gl/web-mercator/dist/esm/fit-bounds.js\");\n/* harmony import */ var _get_bounds__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./get-bounds */ \"./node_modules/@math.gl/web-mercator/dist/esm/get-bounds.js\");\n/* harmony import */ var gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! gl-matrix/mat4 */ \"./node_modules/gl-matrix/esm/mat4.js\");\n/* harmony import */ var gl_matrix_vec2__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! gl-matrix/vec2 */ \"./node_modules/gl-matrix/esm/vec2.js\");\n/* harmony import */ var gl_matrix_vec3__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! gl-matrix/vec3 */ \"./node_modules/gl-matrix/esm/vec3.js\");\n\n\n\n\n\n\n\n\nclass WebMercatorViewport {\n  constructor(props = {\n    width: 1,\n    height: 1\n  }) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"latitude\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"longitude\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"zoom\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"pitch\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"bearing\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"altitude\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"fovy\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"meterOffset\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"center\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"width\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"height\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"scale\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"distanceScales\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"viewMatrix\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"projectionMatrix\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"viewProjectionMatrix\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"pixelProjectionMatrix\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"pixelUnprojectionMatrix\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"equals\", viewport => {\n      if (!(viewport instanceof WebMercatorViewport)) {\n        return false;\n      }\n\n      return viewport.width === this.width && viewport.height === this.height && gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_5__.equals(viewport.projectionMatrix, this.projectionMatrix) && gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_5__.equals(viewport.viewMatrix, this.viewMatrix);\n    });\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"project\", (lngLatZ, options = {}) => {\n      const {\n        topLeft = true\n      } = options;\n      const worldPosition = this.projectPosition(lngLatZ);\n      const coord = (0,_web_mercator_utils__WEBPACK_IMPORTED_MODULE_2__.worldToPixels)(worldPosition, this.pixelProjectionMatrix);\n      const [x, y] = coord;\n      const y2 = topLeft ? y : this.height - y;\n      return lngLatZ.length === 2 ? [x, y2] : [x, y2, coord[2]];\n    });\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"unproject\", (xyz, options = {}) => {\n      const {\n        topLeft = true,\n        targetZ = undefined\n      } = options;\n      const [x, y, z] = xyz;\n      const y2 = topLeft ? y : this.height - y;\n      const targetZWorld = targetZ && targetZ * this.distanceScales.unitsPerMeter[2];\n      const coord = (0,_web_mercator_utils__WEBPACK_IMPORTED_MODULE_2__.pixelsToWorld)([x, y2, z], this.pixelUnprojectionMatrix, targetZWorld);\n      const [X, Y, Z] = this.unprojectPosition(coord);\n\n      if (Number.isFinite(z)) {\n        return [X, Y, Z];\n      }\n\n      return Number.isFinite(targetZ) ? [X, Y, targetZ] : [X, Y];\n    });\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"projectPosition\", xyz => {\n      const [X, Y] = (0,_web_mercator_utils__WEBPACK_IMPORTED_MODULE_2__.lngLatToWorld)(xyz);\n      const Z = (xyz[2] || 0) * this.distanceScales.unitsPerMeter[2];\n      return [X, Y, Z];\n    });\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"unprojectPosition\", xyz => {\n      const [X, Y] = (0,_web_mercator_utils__WEBPACK_IMPORTED_MODULE_2__.worldToLngLat)(xyz);\n      const Z = (xyz[2] || 0) * this.distanceScales.metersPerUnit[2];\n      return [X, Y, Z];\n    });\n\n    let {\n      width,\n      height,\n      altitude = null,\n      fovy = null\n    } = props;\n    const {\n      latitude = 0,\n      longitude = 0,\n      zoom = 0,\n      pitch = 0,\n      bearing = 0,\n      position = null,\n      nearZMultiplier = 0.02,\n      farZMultiplier = 1.01\n    } = props;\n    width = width || 1;\n    height = height || 1;\n\n    if (fovy === null && altitude === null) {\n      altitude = _web_mercator_utils__WEBPACK_IMPORTED_MODULE_2__.DEFAULT_ALTITUDE;\n      fovy = (0,_web_mercator_utils__WEBPACK_IMPORTED_MODULE_2__.altitudeToFovy)(altitude);\n    } else if (fovy === null) {\n      fovy = (0,_web_mercator_utils__WEBPACK_IMPORTED_MODULE_2__.altitudeToFovy)(altitude);\n    } else if (altitude === null) {\n      altitude = (0,_web_mercator_utils__WEBPACK_IMPORTED_MODULE_2__.fovyToAltitude)(fovy);\n    }\n\n    const scale = (0,_web_mercator_utils__WEBPACK_IMPORTED_MODULE_2__.zoomToScale)(zoom);\n    altitude = Math.max(0.75, altitude);\n    const distanceScales = (0,_web_mercator_utils__WEBPACK_IMPORTED_MODULE_2__.getDistanceScales)({\n      longitude,\n      latitude\n    });\n    const center = (0,_web_mercator_utils__WEBPACK_IMPORTED_MODULE_2__.lngLatToWorld)([longitude, latitude]);\n    center.push(0);\n\n    if (position) {\n      gl_matrix_vec3__WEBPACK_IMPORTED_MODULE_6__.add(center, center, gl_matrix_vec3__WEBPACK_IMPORTED_MODULE_6__.mul([], position, distanceScales.unitsPerMeter));\n    }\n\n    this.projectionMatrix = (0,_web_mercator_utils__WEBPACK_IMPORTED_MODULE_2__.getProjectionMatrix)({\n      width,\n      height,\n      scale,\n      center,\n      pitch,\n      fovy,\n      nearZMultiplier,\n      farZMultiplier\n    });\n    this.viewMatrix = (0,_web_mercator_utils__WEBPACK_IMPORTED_MODULE_2__.getViewMatrix)({\n      height,\n      scale,\n      center,\n      pitch,\n      bearing,\n      altitude\n    });\n    this.width = width;\n    this.height = height;\n    this.scale = scale;\n    this.latitude = latitude;\n    this.longitude = longitude;\n    this.zoom = zoom;\n    this.pitch = pitch;\n    this.bearing = bearing;\n    this.altitude = altitude;\n    this.fovy = fovy;\n    this.center = center;\n    this.meterOffset = position || [0, 0, 0];\n    this.distanceScales = distanceScales;\n\n    this._initMatrices();\n\n    Object.freeze(this);\n  }\n\n  _initMatrices() {\n    const {\n      width,\n      height,\n      projectionMatrix,\n      viewMatrix\n    } = this;\n    const vpm = (0,_math_utils__WEBPACK_IMPORTED_MODULE_1__.createMat4)();\n    gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_5__.multiply(vpm, vpm, projectionMatrix);\n    gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_5__.multiply(vpm, vpm, viewMatrix);\n    this.viewProjectionMatrix = vpm;\n    const m = (0,_math_utils__WEBPACK_IMPORTED_MODULE_1__.createMat4)();\n    gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_5__.scale(m, m, [width / 2, -height / 2, 1]);\n    gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_5__.translate(m, m, [1, -1, 0]);\n    gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_5__.multiply(m, m, vpm);\n    const mInverse = gl_matrix_mat4__WEBPACK_IMPORTED_MODULE_5__.invert((0,_math_utils__WEBPACK_IMPORTED_MODULE_1__.createMat4)(), m);\n\n    if (!mInverse) {\n      throw new Error('Pixel project matrix not invertible');\n    }\n\n    this.pixelProjectionMatrix = m;\n    this.pixelUnprojectionMatrix = mInverse;\n  }\n\n  projectFlat(lngLat) {\n    return (0,_web_mercator_utils__WEBPACK_IMPORTED_MODULE_2__.lngLatToWorld)(lngLat);\n  }\n\n  unprojectFlat(xy) {\n    return (0,_web_mercator_utils__WEBPACK_IMPORTED_MODULE_2__.worldToLngLat)(xy);\n  }\n\n  getMapCenterByLngLatPosition({\n    lngLat,\n    pos\n  }) {\n    const fromLocation = (0,_web_mercator_utils__WEBPACK_IMPORTED_MODULE_2__.pixelsToWorld)(pos, this.pixelUnprojectionMatrix);\n    const toLocation = (0,_web_mercator_utils__WEBPACK_IMPORTED_MODULE_2__.lngLatToWorld)(lngLat);\n    const translate = gl_matrix_vec2__WEBPACK_IMPORTED_MODULE_7__.add([], toLocation, gl_matrix_vec2__WEBPACK_IMPORTED_MODULE_7__.negate([], fromLocation));\n    const newCenter = gl_matrix_vec2__WEBPACK_IMPORTED_MODULE_7__.add([], this.center, translate);\n    return (0,_web_mercator_utils__WEBPACK_IMPORTED_MODULE_2__.worldToLngLat)(newCenter);\n  }\n\n  fitBounds(bounds, options = {}) {\n    const {\n      width,\n      height\n    } = this;\n    const {\n      longitude,\n      latitude,\n      zoom\n    } = (0,_fit_bounds__WEBPACK_IMPORTED_MODULE_3__[\"default\"])(Object.assign({\n      width,\n      height,\n      bounds\n    }, options));\n    return new WebMercatorViewport({\n      width,\n      height,\n      longitude,\n      latitude,\n      zoom\n    });\n  }\n\n  getBounds(options) {\n    const corners = this.getBoundingRegion(options);\n    const west = Math.min(...corners.map(p => p[0]));\n    const east = Math.max(...corners.map(p => p[0]));\n    const south = Math.min(...corners.map(p => p[1]));\n    const north = Math.max(...corners.map(p => p[1]));\n    return [[west, south], [east, north]];\n  }\n\n  getBoundingRegion(options = {}) {\n    return (0,_get_bounds__WEBPACK_IMPORTED_MODULE_4__[\"default\"])(this, options.z || 0);\n  }\n\n  getLocationAtPoint({\n    lngLat,\n    pos\n  }) {\n    return this.getMapCenterByLngLatPosition({\n      lngLat,\n      pos\n    });\n  }\n\n}\n//# sourceMappingURL=web-mercator-viewport.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@math.gl/web-mercator/dist/esm/web-mercator-viewport.js?");

/***/ }),

/***/ "./node_modules/@probe.gl/env/dist/esm/lib/get-browser.js":
/*!****************************************************************!*\
  !*** ./node_modules/@probe.gl/env/dist/esm/lib/get-browser.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ getBrowser),\n/* harmony export */   isMobile: () => (/* binding */ isMobile)\n/* harmony export */ });\n/* harmony import */ var _is_browser__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./is-browser */ \"./node_modules/@probe.gl/env/dist/esm/lib/is-browser.js\");\n/* harmony import */ var _is_electron__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./is-electron */ \"./node_modules/@probe.gl/env/dist/esm/lib/is-electron.js\");\n\n\nconst window = globalThis;\nfunction isMobile() {\n  return typeof window.orientation !== 'undefined';\n}\nfunction getBrowser(mockUserAgent) {\n  if (!mockUserAgent && !(0,_is_browser__WEBPACK_IMPORTED_MODULE_0__[\"default\"])()) {\n    return 'Node';\n  }\n\n  if ((0,_is_electron__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(mockUserAgent)) {\n    return 'Electron';\n  }\n\n  const navigator_ = typeof navigator !== 'undefined' ? navigator : {};\n  const userAgent = mockUserAgent || navigator_.userAgent || '';\n\n  if (userAgent.indexOf('Edge') > -1) {\n    return 'Edge';\n  }\n\n  const isMSIE = userAgent.indexOf('MSIE ') !== -1;\n  const isTrident = userAgent.indexOf('Trident/') !== -1;\n\n  if (isMSIE || isTrident) {\n    return 'IE';\n  }\n\n  if (window.chrome) {\n    return 'Chrome';\n  }\n\n  if (window.safari) {\n    return 'Safari';\n  }\n\n  if (window.mozInnerScreenX) {\n    return 'Firefox';\n  }\n\n  return 'Unknown';\n}\n//# sourceMappingURL=get-browser.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@probe.gl/env/dist/esm/lib/get-browser.js?");

/***/ }),

/***/ "./node_modules/@probe.gl/env/dist/esm/lib/globals.js":
/*!************************************************************!*\
  !*** ./node_modules/@probe.gl/env/dist/esm/lib/globals.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   console: () => (/* binding */ console_),\n/* harmony export */   document: () => (/* binding */ document_),\n/* harmony export */   global: () => (/* binding */ global_),\n/* harmony export */   process: () => (/* binding */ process_),\n/* harmony export */   self: () => (/* binding */ self_),\n/* harmony export */   window: () => (/* binding */ window_)\n/* harmony export */ });\nconst globals = {\n  self: typeof self !== 'undefined' && self,\n  window: typeof window !== 'undefined' && window,\n  global: typeof __webpack_require__.g !== 'undefined' && __webpack_require__.g,\n  document: typeof document !== 'undefined' && document,\n  process: typeof process === 'object' && process\n};\nconst global_ = globalThis;\nconst self_ = globals.self || globals.window || globals.global;\nconst window_ = globals.window || globals.self || globals.global;\nconst document_ = globals.document || {};\nconst process_ = globals.process || {};\nconst console_ = console;\n\n//# sourceMappingURL=globals.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@probe.gl/env/dist/esm/lib/globals.js?");

/***/ }),

/***/ "./node_modules/@probe.gl/env/dist/esm/lib/is-browser.js":
/*!***************************************************************!*\
  !*** ./node_modules/@probe.gl/env/dist/esm/lib/is-browser.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ isBrowser),\n/* harmony export */   isBrowserMainThread: () => (/* binding */ isBrowserMainThread)\n/* harmony export */ });\n/* harmony import */ var _is_electron__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./is-electron */ \"./node_modules/@probe.gl/env/dist/esm/lib/is-electron.js\");\n\nfunction isBrowser() {\n  const isNode = typeof process === 'object' && String(process) === '[object process]' && !process.browser;\n  return !isNode || (0,_is_electron__WEBPACK_IMPORTED_MODULE_0__[\"default\"])();\n}\nfunction isBrowserMainThread() {\n  return isBrowser() && typeof document !== 'undefined';\n}\n//# sourceMappingURL=is-browser.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@probe.gl/env/dist/esm/lib/is-browser.js?");

/***/ }),

/***/ "./node_modules/@probe.gl/env/dist/esm/lib/is-electron.js":
/*!****************************************************************!*\
  !*** ./node_modules/@probe.gl/env/dist/esm/lib/is-electron.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ isElectron)\n/* harmony export */ });\nfunction isElectron(mockUserAgent) {\n  if (typeof window !== 'undefined' && typeof window.process === 'object' && window.process.type === 'renderer') {\n    return true;\n  }\n\n  if (typeof process !== 'undefined' && typeof process.versions === 'object' && Boolean(process.versions['electron'])) {\n    return true;\n  }\n\n  const realUserAgent = typeof navigator === 'object' && typeof navigator.userAgent === 'string' && navigator.userAgent;\n  const userAgent = mockUserAgent || realUserAgent;\n\n  if (userAgent && userAgent.indexOf('Electron') >= 0) {\n    return true;\n  }\n\n  return false;\n}\n//# sourceMappingURL=is-electron.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@probe.gl/env/dist/esm/lib/is-electron.js?");

/***/ }),

/***/ "./node_modules/@probe.gl/env/dist/esm/utils/globals.js":
/*!**************************************************************!*\
  !*** ./node_modules/@probe.gl/env/dist/esm/utils/globals.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   VERSION: () => (/* binding */ VERSION),\n/* harmony export */   console: () => (/* reexport safe */ _lib_globals__WEBPACK_IMPORTED_MODULE_0__.console),\n/* harmony export */   document: () => (/* reexport safe */ _lib_globals__WEBPACK_IMPORTED_MODULE_0__.document),\n/* harmony export */   global: () => (/* reexport safe */ _lib_globals__WEBPACK_IMPORTED_MODULE_0__.global),\n/* harmony export */   isBrowser: () => (/* binding */ isBrowser),\n/* harmony export */   process: () => (/* reexport safe */ _lib_globals__WEBPACK_IMPORTED_MODULE_0__.process),\n/* harmony export */   self: () => (/* reexport safe */ _lib_globals__WEBPACK_IMPORTED_MODULE_0__.self),\n/* harmony export */   window: () => (/* reexport safe */ _lib_globals__WEBPACK_IMPORTED_MODULE_0__.window)\n/* harmony export */ });\n/* harmony import */ var _lib_is_browser__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../lib/is-browser */ \"./node_modules/@probe.gl/env/dist/esm/lib/is-browser.js\");\n/* harmony import */ var _lib_globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../lib/globals */ \"./node_modules/@probe.gl/env/dist/esm/lib/globals.js\");\n\n\nconst VERSION = typeof __VERSION__ !== 'undefined' ? __VERSION__ : 'untranspiled source';\nconst isBrowser = (0,_lib_is_browser__WEBPACK_IMPORTED_MODULE_1__[\"default\"])();\n//# sourceMappingURL=globals.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@probe.gl/env/dist/esm/utils/globals.js?");

/***/ }),

/***/ "./node_modules/@probe.gl/log/dist/esm/log.js":
/*!****************************************************!*\
  !*** ./node_modules/@probe.gl/log/dist/esm/log.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Log: () => (/* binding */ Log),\n/* harmony export */   normalizeArguments: () => (/* binding */ normalizeArguments)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _probe_gl_env__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @probe.gl/env */ \"./node_modules/@probe.gl/env/dist/esm/lib/is-browser.js\");\n/* harmony import */ var _probe_gl_env__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @probe.gl/env */ \"./node_modules/@probe.gl/env/dist/esm/utils/globals.js\");\n/* harmony import */ var _utils_local_storage__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./utils/local-storage */ \"./node_modules/@probe.gl/log/dist/esm/utils/local-storage.js\");\n/* harmony import */ var _utils_formatters__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./utils/formatters */ \"./node_modules/@probe.gl/log/dist/esm/utils/formatters.js\");\n/* harmony import */ var _utils_color__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./utils/color */ \"./node_modules/@probe.gl/log/dist/esm/utils/color.js\");\n/* harmony import */ var _utils_autobind__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./utils/autobind */ \"./node_modules/@probe.gl/log/dist/esm/utils/autobind.js\");\n/* harmony import */ var _utils_assert__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./utils/assert */ \"./node_modules/@probe.gl/log/dist/esm/utils/assert.js\");\n/* harmony import */ var _utils_hi_res_timestamp__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./utils/hi-res-timestamp */ \"./node_modules/@probe.gl/log/dist/esm/utils/hi-res-timestamp.js\");\n\n\n\n\n\n\n\n\nconst originalConsole = {\n  debug: _probe_gl_env__WEBPACK_IMPORTED_MODULE_1__[\"default\"] ? console.debug || console.log : console.log,\n  log: console.log,\n  info: console.info,\n  warn: console.warn,\n  error: console.error\n};\nconst DEFAULT_SETTINGS = {\n  enabled: true,\n  level: 0\n};\n\nfunction noop() {}\n\nconst cache = {};\nconst ONCE = {\n  once: true\n};\nclass Log {\n  constructor() {\n    let {\n      id\n    } = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {\n      id: ''\n    };\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"id\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"VERSION\", _probe_gl_env__WEBPACK_IMPORTED_MODULE_2__.VERSION);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_startTs\", (0,_utils_hi_res_timestamp__WEBPACK_IMPORTED_MODULE_3__.getHiResTimestamp)());\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_deltaTs\", (0,_utils_hi_res_timestamp__WEBPACK_IMPORTED_MODULE_3__.getHiResTimestamp)());\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_storage\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"userData\", {});\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"LOG_THROTTLE_TIMEOUT\", 0);\n\n    this.id = id;\n    this.userData = {};\n    this._storage = new _utils_local_storage__WEBPACK_IMPORTED_MODULE_4__.LocalStorage(\"__probe-\".concat(this.id, \"__\"), DEFAULT_SETTINGS);\n    this.timeStamp(\"\".concat(this.id, \" started\"));\n    (0,_utils_autobind__WEBPACK_IMPORTED_MODULE_5__.autobind)(this);\n    Object.seal(this);\n  }\n\n  set level(newLevel) {\n    this.setLevel(newLevel);\n  }\n\n  get level() {\n    return this.getLevel();\n  }\n\n  isEnabled() {\n    return this._storage.config.enabled;\n  }\n\n  getLevel() {\n    return this._storage.config.level;\n  }\n\n  getTotal() {\n    return Number(((0,_utils_hi_res_timestamp__WEBPACK_IMPORTED_MODULE_3__.getHiResTimestamp)() - this._startTs).toPrecision(10));\n  }\n\n  getDelta() {\n    return Number(((0,_utils_hi_res_timestamp__WEBPACK_IMPORTED_MODULE_3__.getHiResTimestamp)() - this._deltaTs).toPrecision(10));\n  }\n\n  set priority(newPriority) {\n    this.level = newPriority;\n  }\n\n  get priority() {\n    return this.level;\n  }\n\n  getPriority() {\n    return this.level;\n  }\n\n  enable() {\n    let enabled = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : true;\n\n    this._storage.setConfiguration({\n      enabled\n    });\n\n    return this;\n  }\n\n  setLevel(level) {\n    this._storage.setConfiguration({\n      level\n    });\n\n    return this;\n  }\n\n  get(setting) {\n    return this._storage.config[setting];\n  }\n\n  set(setting, value) {\n    this._storage.setConfiguration({\n      [setting]: value\n    });\n  }\n\n  settings() {\n    if (console.table) {\n      console.table(this._storage.config);\n    } else {\n      console.log(this._storage.config);\n    }\n  }\n\n  assert(condition, message) {\n    (0,_utils_assert__WEBPACK_IMPORTED_MODULE_6__[\"default\"])(condition, message);\n  }\n\n  warn(message) {\n    return this._getLogFunction(0, message, originalConsole.warn, arguments, ONCE);\n  }\n\n  error(message) {\n    return this._getLogFunction(0, message, originalConsole.error, arguments);\n  }\n\n  deprecated(oldUsage, newUsage) {\n    return this.warn(\"`\".concat(oldUsage, \"` is deprecated and will be removed in a later version. Use `\").concat(newUsage, \"` instead\"));\n  }\n\n  removed(oldUsage, newUsage) {\n    return this.error(\"`\".concat(oldUsage, \"` has been removed. Use `\").concat(newUsage, \"` instead\"));\n  }\n\n  probe(logLevel, message) {\n    return this._getLogFunction(logLevel, message, originalConsole.log, arguments, {\n      time: true,\n      once: true\n    });\n  }\n\n  log(logLevel, message) {\n    return this._getLogFunction(logLevel, message, originalConsole.debug, arguments);\n  }\n\n  info(logLevel, message) {\n    return this._getLogFunction(logLevel, message, console.info, arguments);\n  }\n\n  once(logLevel, message) {\n    for (var _len = arguments.length, args = new Array(_len > 2 ? _len - 2 : 0), _key = 2; _key < _len; _key++) {\n      args[_key - 2] = arguments[_key];\n    }\n\n    return this._getLogFunction(logLevel, message, originalConsole.debug || originalConsole.info, arguments, ONCE);\n  }\n\n  table(logLevel, table, columns) {\n    if (table) {\n      return this._getLogFunction(logLevel, table, console.table || noop, columns && [columns], {\n        tag: getTableHeader(table)\n      });\n    }\n\n    return noop;\n  }\n\n  image(_ref) {\n    let {\n      logLevel,\n      priority,\n      image,\n      message = '',\n      scale = 1\n    } = _ref;\n\n    if (!this._shouldLog(logLevel || priority)) {\n      return noop;\n    }\n\n    return _probe_gl_env__WEBPACK_IMPORTED_MODULE_1__[\"default\"] ? logImageInBrowser({\n      image,\n      message,\n      scale\n    }) : logImageInNode({\n      image,\n      message,\n      scale\n    });\n  }\n\n  time(logLevel, message) {\n    return this._getLogFunction(logLevel, message, console.time ? console.time : console.info);\n  }\n\n  timeEnd(logLevel, message) {\n    return this._getLogFunction(logLevel, message, console.timeEnd ? console.timeEnd : console.info);\n  }\n\n  timeStamp(logLevel, message) {\n    return this._getLogFunction(logLevel, message, console.timeStamp || noop);\n  }\n\n  group(logLevel, message) {\n    let opts = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {\n      collapsed: false\n    };\n    const options = normalizeArguments({\n      logLevel,\n      message,\n      opts\n    });\n    const {\n      collapsed\n    } = opts;\n    options.method = (collapsed ? console.groupCollapsed : console.group) || console.info;\n    return this._getLogFunction(options);\n  }\n\n  groupCollapsed(logLevel, message) {\n    let opts = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n    return this.group(logLevel, message, Object.assign({}, opts, {\n      collapsed: true\n    }));\n  }\n\n  groupEnd(logLevel) {\n    return this._getLogFunction(logLevel, '', console.groupEnd || noop);\n  }\n\n  withGroup(logLevel, message, func) {\n    this.group(logLevel, message)();\n\n    try {\n      func();\n    } finally {\n      this.groupEnd(logLevel)();\n    }\n  }\n\n  trace() {\n    if (console.trace) {\n      console.trace();\n    }\n  }\n\n  _shouldLog(logLevel) {\n    return this.isEnabled() && this.getLevel() >= normalizeLogLevel(logLevel);\n  }\n\n  _getLogFunction(logLevel, message, method, args, opts) {\n    if (this._shouldLog(logLevel)) {\n      opts = normalizeArguments({\n        logLevel,\n        message,\n        args,\n        opts\n      });\n      method = method || opts.method;\n      (0,_utils_assert__WEBPACK_IMPORTED_MODULE_6__[\"default\"])(method);\n      opts.total = this.getTotal();\n      opts.delta = this.getDelta();\n      this._deltaTs = (0,_utils_hi_res_timestamp__WEBPACK_IMPORTED_MODULE_3__.getHiResTimestamp)();\n      const tag = opts.tag || opts.message;\n\n      if (opts.once) {\n        if (!cache[tag]) {\n          cache[tag] = (0,_utils_hi_res_timestamp__WEBPACK_IMPORTED_MODULE_3__.getHiResTimestamp)();\n        } else {\n          return noop;\n        }\n      }\n\n      message = decorateMessage(this.id, opts.message, opts);\n      return method.bind(console, message, ...opts.args);\n    }\n\n    return noop;\n  }\n\n}\n\n(0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(Log, \"VERSION\", _probe_gl_env__WEBPACK_IMPORTED_MODULE_2__.VERSION);\n\nfunction normalizeLogLevel(logLevel) {\n  if (!logLevel) {\n    return 0;\n  }\n\n  let resolvedLevel;\n\n  switch (typeof logLevel) {\n    case 'number':\n      resolvedLevel = logLevel;\n      break;\n\n    case 'object':\n      resolvedLevel = logLevel.logLevel || logLevel.priority || 0;\n      break;\n\n    default:\n      return 0;\n  }\n\n  (0,_utils_assert__WEBPACK_IMPORTED_MODULE_6__[\"default\"])(Number.isFinite(resolvedLevel) && resolvedLevel >= 0);\n  return resolvedLevel;\n}\n\nfunction normalizeArguments(opts) {\n  const {\n    logLevel,\n    message\n  } = opts;\n  opts.logLevel = normalizeLogLevel(logLevel);\n  const args = opts.args ? Array.from(opts.args) : [];\n\n  while (args.length && args.shift() !== message) {}\n\n  switch (typeof logLevel) {\n    case 'string':\n    case 'function':\n      if (message !== undefined) {\n        args.unshift(message);\n      }\n\n      opts.message = logLevel;\n      break;\n\n    case 'object':\n      Object.assign(opts, logLevel);\n      break;\n\n    default:\n  }\n\n  if (typeof opts.message === 'function') {\n    opts.message = opts.message();\n  }\n\n  const messageType = typeof opts.message;\n  (0,_utils_assert__WEBPACK_IMPORTED_MODULE_6__[\"default\"])(messageType === 'string' || messageType === 'object');\n  return Object.assign(opts, {\n    args\n  }, opts.opts);\n}\n\nfunction decorateMessage(id, message, opts) {\n  if (typeof message === 'string') {\n    const time = opts.time ? (0,_utils_formatters__WEBPACK_IMPORTED_MODULE_7__.leftPad)((0,_utils_formatters__WEBPACK_IMPORTED_MODULE_7__.formatTime)(opts.total)) : '';\n    message = opts.time ? \"\".concat(id, \": \").concat(time, \"  \").concat(message) : \"\".concat(id, \": \").concat(message);\n    message = (0,_utils_color__WEBPACK_IMPORTED_MODULE_8__.addColor)(message, opts.color, opts.background);\n  }\n\n  return message;\n}\n\nfunction logImageInNode(_ref2) {\n  let {\n    image,\n    message = '',\n    scale = 1\n  } = _ref2;\n  console.warn('removed');\n  return noop;\n}\n\nfunction logImageInBrowser(_ref3) {\n  let {\n    image,\n    message = '',\n    scale = 1\n  } = _ref3;\n\n  if (typeof image === 'string') {\n    const img = new Image();\n\n    img.onload = () => {\n      const args = (0,_utils_formatters__WEBPACK_IMPORTED_MODULE_7__.formatImage)(img, message, scale);\n      console.log(...args);\n    };\n\n    img.src = image;\n    return noop;\n  }\n\n  const element = image.nodeName || '';\n\n  if (element.toLowerCase() === 'img') {\n    console.log(...(0,_utils_formatters__WEBPACK_IMPORTED_MODULE_7__.formatImage)(image, message, scale));\n    return noop;\n  }\n\n  if (element.toLowerCase() === 'canvas') {\n    const img = new Image();\n\n    img.onload = () => console.log(...(0,_utils_formatters__WEBPACK_IMPORTED_MODULE_7__.formatImage)(img, message, scale));\n\n    img.src = image.toDataURL();\n    return noop;\n  }\n\n  return noop;\n}\n\nfunction getTableHeader(table) {\n  for (const key in table) {\n    for (const title in table[key]) {\n      return title || 'untitled';\n    }\n  }\n\n  return 'empty';\n}\n//# sourceMappingURL=log.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@probe.gl/log/dist/esm/log.js?");

/***/ }),

/***/ "./node_modules/@probe.gl/log/dist/esm/utils/assert.js":
/*!*************************************************************!*\
  !*** ./node_modules/@probe.gl/log/dist/esm/utils/assert.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ assert)\n/* harmony export */ });\nfunction assert(condition, message) {\n  if (!condition) {\n    throw new Error(message || 'Assertion failed');\n  }\n}\n//# sourceMappingURL=assert.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@probe.gl/log/dist/esm/utils/assert.js?");

/***/ }),

/***/ "./node_modules/@probe.gl/log/dist/esm/utils/autobind.js":
/*!***************************************************************!*\
  !*** ./node_modules/@probe.gl/log/dist/esm/utils/autobind.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   autobind: () => (/* binding */ autobind)\n/* harmony export */ });\nfunction autobind(obj) {\n  let predefined = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : ['constructor'];\n  const proto = Object.getPrototypeOf(obj);\n  const propNames = Object.getOwnPropertyNames(proto);\n\n  for (const key of propNames) {\n    if (typeof obj[key] === 'function') {\n      if (!predefined.find(name => key === name)) {\n        obj[key] = obj[key].bind(obj);\n      }\n    }\n  }\n}\n//# sourceMappingURL=autobind.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@probe.gl/log/dist/esm/utils/autobind.js?");

/***/ }),

/***/ "./node_modules/@probe.gl/log/dist/esm/utils/color.js":
/*!************************************************************!*\
  !*** ./node_modules/@probe.gl/log/dist/esm/utils/color.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   COLOR: () => (/* binding */ COLOR),\n/* harmony export */   addColor: () => (/* binding */ addColor)\n/* harmony export */ });\n/* harmony import */ var _probe_gl_env__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @probe.gl/env */ \"./node_modules/@probe.gl/env/dist/esm/lib/is-browser.js\");\n\nlet COLOR;\n\n(function (COLOR) {\n  COLOR[COLOR[\"BLACK\"] = 30] = \"BLACK\";\n  COLOR[COLOR[\"RED\"] = 31] = \"RED\";\n  COLOR[COLOR[\"GREEN\"] = 32] = \"GREEN\";\n  COLOR[COLOR[\"YELLOW\"] = 33] = \"YELLOW\";\n  COLOR[COLOR[\"BLUE\"] = 34] = \"BLUE\";\n  COLOR[COLOR[\"MAGENTA\"] = 35] = \"MAGENTA\";\n  COLOR[COLOR[\"CYAN\"] = 36] = \"CYAN\";\n  COLOR[COLOR[\"WHITE\"] = 37] = \"WHITE\";\n  COLOR[COLOR[\"BRIGHT_BLACK\"] = 90] = \"BRIGHT_BLACK\";\n  COLOR[COLOR[\"BRIGHT_RED\"] = 91] = \"BRIGHT_RED\";\n  COLOR[COLOR[\"BRIGHT_GREEN\"] = 92] = \"BRIGHT_GREEN\";\n  COLOR[COLOR[\"BRIGHT_YELLOW\"] = 93] = \"BRIGHT_YELLOW\";\n  COLOR[COLOR[\"BRIGHT_BLUE\"] = 94] = \"BRIGHT_BLUE\";\n  COLOR[COLOR[\"BRIGHT_MAGENTA\"] = 95] = \"BRIGHT_MAGENTA\";\n  COLOR[COLOR[\"BRIGHT_CYAN\"] = 96] = \"BRIGHT_CYAN\";\n  COLOR[COLOR[\"BRIGHT_WHITE\"] = 97] = \"BRIGHT_WHITE\";\n})(COLOR || (COLOR = {}));\n\nfunction getColor(color) {\n  return typeof color === 'string' ? COLOR[color.toUpperCase()] || COLOR.WHITE : color;\n}\n\nfunction addColor(string, color, background) {\n  if (!_probe_gl_env__WEBPACK_IMPORTED_MODULE_0__[\"default\"] && typeof string === 'string') {\n    if (color) {\n      color = getColor(color);\n      string = \"\\x1B[\".concat(color, \"m\").concat(string, \"\\x1B[39m\");\n    }\n\n    if (background) {\n      color = getColor(background);\n      string = \"\\x1B[\".concat(background + 10, \"m\").concat(string, \"\\x1B[49m\");\n    }\n  }\n\n  return string;\n}\n//# sourceMappingURL=color.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@probe.gl/log/dist/esm/utils/color.js?");

/***/ }),

/***/ "./node_modules/@probe.gl/log/dist/esm/utils/formatters.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@probe.gl/log/dist/esm/utils/formatters.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   formatImage: () => (/* binding */ formatImage),\n/* harmony export */   formatTime: () => (/* binding */ formatTime),\n/* harmony export */   formatValue: () => (/* binding */ formatValue),\n/* harmony export */   leftPad: () => (/* binding */ leftPad),\n/* harmony export */   rightPad: () => (/* binding */ rightPad)\n/* harmony export */ });\nfunction formatTime(ms) {\n  let formatted;\n\n  if (ms < 10) {\n    formatted = \"\".concat(ms.toFixed(2), \"ms\");\n  } else if (ms < 100) {\n    formatted = \"\".concat(ms.toFixed(1), \"ms\");\n  } else if (ms < 1000) {\n    formatted = \"\".concat(ms.toFixed(0), \"ms\");\n  } else {\n    formatted = \"\".concat((ms / 1000).toFixed(2), \"s\");\n  }\n\n  return formatted;\n}\nfunction leftPad(string) {\n  let length = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 8;\n  const padLength = Math.max(length - string.length, 0);\n  return \"\".concat(' '.repeat(padLength)).concat(string);\n}\nfunction rightPad(string) {\n  let length = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 8;\n  const padLength = Math.max(length - string.length, 0);\n  return \"\".concat(string).concat(' '.repeat(padLength));\n}\nfunction formatValue(v) {\n  let opts = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  const EPSILON = 1e-16;\n  const {\n    isInteger = false\n  } = opts;\n\n  if (Array.isArray(v) || ArrayBuffer.isView(v)) {\n    return formatArrayValue(v, opts);\n  }\n\n  if (!Number.isFinite(v)) {\n    return String(v);\n  }\n\n  if (Math.abs(v) < EPSILON) {\n    return isInteger ? '0' : '0.';\n  }\n\n  if (isInteger) {\n    return v.toFixed(0);\n  }\n\n  if (Math.abs(v) > 100 && Math.abs(v) < 10000) {\n    return v.toFixed(0);\n  }\n\n  const string = v.toPrecision(2);\n  const decimal = string.indexOf('.0');\n  return decimal === string.length - 2 ? string.slice(0, -1) : string;\n}\n\nfunction formatArrayValue(v, opts) {\n  const {\n    maxElts = 16,\n    size = 1\n  } = opts;\n  let string = '[';\n\n  for (let i = 0; i < v.length && i < maxElts; ++i) {\n    if (i > 0) {\n      string += \",\".concat(i % size === 0 ? ' ' : '');\n    }\n\n    string += formatValue(v[i], opts);\n  }\n\n  const terminator = v.length > maxElts ? '...' : ']';\n  return \"\".concat(string).concat(terminator);\n}\n\nfunction formatImage(image, message, scale) {\n  let maxWidth = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 600;\n  const imageUrl = image.src.replace(/\\(/g, '%28').replace(/\\)/g, '%29');\n\n  if (image.width > maxWidth) {\n    scale = Math.min(scale, maxWidth / image.width);\n  }\n\n  const width = image.width * scale;\n  const height = image.height * scale;\n  const style = ['font-size:1px;', \"padding:\".concat(Math.floor(height / 2), \"px \").concat(Math.floor(width / 2), \"px;\"), \"line-height:\".concat(height, \"px;\"), \"background:url(\".concat(imageUrl, \");\"), \"background-size:\".concat(width, \"px \").concat(height, \"px;\"), 'color:transparent;'].join('');\n  return [\"\".concat(message, \" %c+\"), style];\n}\n//# sourceMappingURL=formatters.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@probe.gl/log/dist/esm/utils/formatters.js?");

/***/ }),

/***/ "./node_modules/@probe.gl/log/dist/esm/utils/hi-res-timestamp.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@probe.gl/log/dist/esm/utils/hi-res-timestamp.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getHiResTimestamp: () => (/* binding */ getHiResTimestamp)\n/* harmony export */ });\n/* harmony import */ var _probe_gl_env__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @probe.gl/env */ \"./node_modules/@probe.gl/env/dist/esm/lib/is-browser.js\");\n/* harmony import */ var _probe_gl_env__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @probe.gl/env */ \"./node_modules/@probe.gl/env/dist/esm/lib/globals.js\");\n\nfunction getHiResTimestamp() {\n  let timestamp;\n\n  if (_probe_gl_env__WEBPACK_IMPORTED_MODULE_0__[\"default\"] && \"performance\" in _probe_gl_env__WEBPACK_IMPORTED_MODULE_1__.window) {\n    var _window$performance, _window$performance$n;\n\n    timestamp = _probe_gl_env__WEBPACK_IMPORTED_MODULE_1__.window === null || _probe_gl_env__WEBPACK_IMPORTED_MODULE_1__.window === void 0 ? void 0 : (_window$performance = _probe_gl_env__WEBPACK_IMPORTED_MODULE_1__.window.performance) === null || _window$performance === void 0 ? void 0 : (_window$performance$n = _window$performance.now) === null || _window$performance$n === void 0 ? void 0 : _window$performance$n.call(_window$performance);\n  } else if (\"hrtime\" in _probe_gl_env__WEBPACK_IMPORTED_MODULE_1__.process) {\n    var _process$hrtime;\n\n    const timeParts = _probe_gl_env__WEBPACK_IMPORTED_MODULE_1__.process === null || _probe_gl_env__WEBPACK_IMPORTED_MODULE_1__.process === void 0 ? void 0 : (_process$hrtime = _probe_gl_env__WEBPACK_IMPORTED_MODULE_1__.process.hrtime) === null || _process$hrtime === void 0 ? void 0 : _process$hrtime.call(_probe_gl_env__WEBPACK_IMPORTED_MODULE_1__.process);\n    timestamp = timeParts[0] * 1000 + timeParts[1] / 1e6;\n  } else {\n    timestamp = Date.now();\n  }\n\n  return timestamp;\n}\n//# sourceMappingURL=hi-res-timestamp.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@probe.gl/log/dist/esm/utils/hi-res-timestamp.js?");

/***/ }),

/***/ "./node_modules/@probe.gl/log/dist/esm/utils/local-storage.js":
/*!********************************************************************!*\
  !*** ./node_modules/@probe.gl/log/dist/esm/utils/local-storage.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   LocalStorage: () => (/* binding */ LocalStorage)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n\n\nfunction getStorage(type) {\n  try {\n    const storage = window[type];\n    const x = '__storage_test__';\n    storage.setItem(x, x);\n    storage.removeItem(x);\n    return storage;\n  } catch (e) {\n    return null;\n  }\n}\n\nclass LocalStorage {\n  constructor(id, defaultConfig) {\n    let type = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 'sessionStorage';\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"storage\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"id\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"config\", void 0);\n\n    this.storage = getStorage(type);\n    this.id = id;\n    this.config = defaultConfig;\n\n    this._loadConfiguration();\n  }\n\n  getConfiguration() {\n    return this.config;\n  }\n\n  setConfiguration(configuration) {\n    Object.assign(this.config, configuration);\n\n    if (this.storage) {\n      const serialized = JSON.stringify(this.config);\n      this.storage.setItem(this.id, serialized);\n    }\n  }\n\n  _loadConfiguration() {\n    let configuration = {};\n\n    if (this.storage) {\n      const serializedConfiguration = this.storage.getItem(this.id);\n      configuration = serializedConfiguration ? JSON.parse(serializedConfiguration) : {};\n    }\n\n    Object.assign(this.config, configuration);\n    return this;\n  }\n\n}\n//# sourceMappingURL=local-storage.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@probe.gl/log/dist/esm/utils/local-storage.js?");

/***/ }),

/***/ "./node_modules/@probe.gl/stats/dist/esm/index.js":
/*!********************************************************!*\
  !*** ./node_modules/@probe.gl/stats/dist/esm/index.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Stat: () => (/* reexport safe */ _lib_stat__WEBPACK_IMPORTED_MODULE_1__[\"default\"]),\n/* harmony export */   Stats: () => (/* reexport safe */ _lib_stats__WEBPACK_IMPORTED_MODULE_0__[\"default\"]),\n/* harmony export */   _getHiResTimestamp: () => (/* reexport safe */ _utils_hi_res_timestamp__WEBPACK_IMPORTED_MODULE_2__[\"default\"])\n/* harmony export */ });\n/* harmony import */ var _lib_stats__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./lib/stats */ \"./node_modules/@probe.gl/stats/dist/esm/lib/stats.js\");\n/* harmony import */ var _lib_stat__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./lib/stat */ \"./node_modules/@probe.gl/stats/dist/esm/lib/stat.js\");\n/* harmony import */ var _utils_hi_res_timestamp__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./utils/hi-res-timestamp */ \"./node_modules/@probe.gl/stats/dist/esm/utils/hi-res-timestamp.js\");\n\n\n\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@probe.gl/stats/dist/esm/index.js?");

/***/ }),

/***/ "./node_modules/@probe.gl/stats/dist/esm/lib/stat.js":
/*!***********************************************************!*\
  !*** ./node_modules/@probe.gl/stats/dist/esm/lib/stat.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Stat)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _utils_hi_res_timestamp__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/hi-res-timestamp */ \"./node_modules/@probe.gl/stats/dist/esm/utils/hi-res-timestamp.js\");\n\n\nclass Stat {\n  constructor(name, type) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"name\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"type\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"sampleSize\", 1);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"time\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"count\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"samples\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"lastTiming\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"lastSampleTime\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"lastSampleCount\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_count\", 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_time\", 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_samples\", 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_startTime\", 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"_timerPending\", false);\n\n    this.name = name;\n    this.type = type;\n    this.reset();\n  }\n\n  setSampleSize(samples) {\n    this.sampleSize = samples;\n    return this;\n  }\n\n  incrementCount() {\n    this.addCount(1);\n    return this;\n  }\n\n  decrementCount() {\n    this.subtractCount(1);\n    return this;\n  }\n\n  addCount(value) {\n    this._count += value;\n    this._samples++;\n\n    this._checkSampling();\n\n    return this;\n  }\n\n  subtractCount(value) {\n    this._count -= value;\n    this._samples++;\n\n    this._checkSampling();\n\n    return this;\n  }\n\n  addTime(time) {\n    this._time += time;\n    this.lastTiming = time;\n    this._samples++;\n\n    this._checkSampling();\n\n    return this;\n  }\n\n  timeStart() {\n    this._startTime = (0,_utils_hi_res_timestamp__WEBPACK_IMPORTED_MODULE_1__[\"default\"])();\n    this._timerPending = true;\n    return this;\n  }\n\n  timeEnd() {\n    if (!this._timerPending) {\n      return this;\n    }\n\n    this.addTime((0,_utils_hi_res_timestamp__WEBPACK_IMPORTED_MODULE_1__[\"default\"])() - this._startTime);\n    this._timerPending = false;\n\n    this._checkSampling();\n\n    return this;\n  }\n\n  getSampleAverageCount() {\n    return this.sampleSize > 0 ? this.lastSampleCount / this.sampleSize : 0;\n  }\n\n  getSampleAverageTime() {\n    return this.sampleSize > 0 ? this.lastSampleTime / this.sampleSize : 0;\n  }\n\n  getSampleHz() {\n    return this.lastSampleTime > 0 ? this.sampleSize / (this.lastSampleTime / 1000) : 0;\n  }\n\n  getAverageCount() {\n    return this.samples > 0 ? this.count / this.samples : 0;\n  }\n\n  getAverageTime() {\n    return this.samples > 0 ? this.time / this.samples : 0;\n  }\n\n  getHz() {\n    return this.time > 0 ? this.samples / (this.time / 1000) : 0;\n  }\n\n  reset() {\n    this.time = 0;\n    this.count = 0;\n    this.samples = 0;\n    this.lastTiming = 0;\n    this.lastSampleTime = 0;\n    this.lastSampleCount = 0;\n    this._count = 0;\n    this._time = 0;\n    this._samples = 0;\n    this._startTime = 0;\n    this._timerPending = false;\n    return this;\n  }\n\n  _checkSampling() {\n    if (this._samples === this.sampleSize) {\n      this.lastSampleTime = this._time;\n      this.lastSampleCount = this._count;\n      this.count += this._count;\n      this.time += this._time;\n      this.samples += this._samples;\n      this._time = 0;\n      this._count = 0;\n      this._samples = 0;\n    }\n  }\n\n}\n//# sourceMappingURL=stat.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@probe.gl/stats/dist/esm/lib/stat.js?");

/***/ }),

/***/ "./node_modules/@probe.gl/stats/dist/esm/lib/stats.js":
/*!************************************************************!*\
  !*** ./node_modules/@probe.gl/stats/dist/esm/lib/stats.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Stats)\n/* harmony export */ });\n/* harmony import */ var _babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @babel/runtime/helpers/esm/defineProperty */ \"./node_modules/@babel/runtime/helpers/esm/defineProperty.js\");\n/* harmony import */ var _stat__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./stat */ \"./node_modules/@probe.gl/stats/dist/esm/lib/stat.js\");\n\n\nclass Stats {\n  constructor(options) {\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"id\", void 0);\n\n    (0,_babel_runtime_helpers_esm_defineProperty__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, \"stats\", {});\n\n    this.id = options.id;\n    this.stats = {};\n\n    this._initializeStats(options.stats);\n\n    Object.seal(this);\n  }\n\n  get(name) {\n    let type = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 'count';\n    return this._getOrCreate({\n      name,\n      type\n    });\n  }\n\n  get size() {\n    return Object.keys(this.stats).length;\n  }\n\n  reset() {\n    for (const key in this.stats) {\n      this.stats[key].reset();\n    }\n\n    return this;\n  }\n\n  forEach(fn) {\n    for (const key in this.stats) {\n      fn(this.stats[key]);\n    }\n  }\n\n  getTable() {\n    const table = {};\n    this.forEach(stat => {\n      table[stat.name] = {\n        time: stat.time || 0,\n        count: stat.count || 0,\n        average: stat.getAverageTime() || 0,\n        hz: stat.getHz() || 0\n      };\n    });\n    return table;\n  }\n\n  _initializeStats() {\n    let stats = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : [];\n    stats.forEach(stat => this._getOrCreate(stat));\n  }\n\n  _getOrCreate(stat) {\n    if (!stat || !stat.name) {\n      return null;\n    }\n\n    const {\n      name,\n      type\n    } = stat;\n\n    if (!this.stats[name]) {\n      if (stat instanceof _stat__WEBPACK_IMPORTED_MODULE_1__[\"default\"]) {\n        this.stats[name] = stat;\n      } else {\n        this.stats[name] = new _stat__WEBPACK_IMPORTED_MODULE_1__[\"default\"](name, type);\n      }\n    }\n\n    return this.stats[name];\n  }\n\n}\n//# sourceMappingURL=stats.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@probe.gl/stats/dist/esm/lib/stats.js?");

/***/ }),

/***/ "./node_modules/@probe.gl/stats/dist/esm/utils/hi-res-timestamp.js":
/*!*************************************************************************!*\
  !*** ./node_modules/@probe.gl/stats/dist/esm/utils/hi-res-timestamp.js ***!
  \*************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ getHiResTimestamp)\n/* harmony export */ });\nfunction getHiResTimestamp() {\n  let timestamp;\n\n  if (typeof window !== 'undefined' && window.performance) {\n    timestamp = window.performance.now();\n  } else if (typeof process !== 'undefined' && process.hrtime) {\n    const timeParts = process.hrtime();\n    timestamp = timeParts[0] * 1000 + timeParts[1] / 1e6;\n  } else {\n    timestamp = Date.now();\n  }\n\n  return timestamp;\n}\n//# sourceMappingURL=hi-res-timestamp.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@probe.gl/stats/dist/esm/utils/hi-res-timestamp.js?");

/***/ }),

/***/ "./node_modules/bootstrap/dist/js/bootstrap.bundle.min.js":
/*!****************************************************************!*\
  !*** ./node_modules/bootstrap/dist/js/bootstrap.bundle.min.js ***!
  \****************************************************************/
/***/ (function(module) {

eval("/*!\n  * Bootstrap v5.3.3 (https://getbootstrap.com/)\n  * Copyright 2011-2024 The Bootstrap Authors (https://github.com/twbs/bootstrap/graphs/contributors)\n  * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE)\n  */\n!function(t,e){ true?module.exports=e():0}(this,(function(){\"use strict\";const t=new Map,e={set(e,i,n){t.has(e)||t.set(e,new Map);const s=t.get(e);s.has(i)||0===s.size?s.set(i,n):console.error(`Bootstrap doesn't allow more than one instance per element. Bound instance: ${Array.from(s.keys())[0]}.`)},get:(e,i)=>t.has(e)&&t.get(e).get(i)||null,remove(e,i){if(!t.has(e))return;const n=t.get(e);n.delete(i),0===n.size&&t.delete(e)}},i=\"transitionend\",n=t=>(t&&window.CSS&&window.CSS.escape&&(t=t.replace(/#([^\\s\"#']+)/g,((t,e)=>`#${CSS.escape(e)}`))),t),s=t=>{t.dispatchEvent(new Event(i))},o=t=>!(!t||\"object\"!=typeof t)&&(void 0!==t.jquery&&(t=t[0]),void 0!==t.nodeType),r=t=>o(t)?t.jquery?t[0]:t:\"string\"==typeof t&&t.length>0?document.querySelector(n(t)):null,a=t=>{if(!o(t)||0===t.getClientRects().length)return!1;const e=\"visible\"===getComputedStyle(t).getPropertyValue(\"visibility\"),i=t.closest(\"details:not([open])\");if(!i)return e;if(i!==t){const e=t.closest(\"summary\");if(e&&e.parentNode!==i)return!1;if(null===e)return!1}return e},l=t=>!t||t.nodeType!==Node.ELEMENT_NODE||!!t.classList.contains(\"disabled\")||(void 0!==t.disabled?t.disabled:t.hasAttribute(\"disabled\")&&\"false\"!==t.getAttribute(\"disabled\")),c=t=>{if(!document.documentElement.attachShadow)return null;if(\"function\"==typeof t.getRootNode){const e=t.getRootNode();return e instanceof ShadowRoot?e:null}return t instanceof ShadowRoot?t:t.parentNode?c(t.parentNode):null},h=()=>{},d=t=>{t.offsetHeight},u=()=>window.jQuery&&!document.body.hasAttribute(\"data-bs-no-jquery\")?window.jQuery:null,f=[],p=()=>\"rtl\"===document.documentElement.dir,m=t=>{var e;e=()=>{const e=u();if(e){const i=t.NAME,n=e.fn[i];e.fn[i]=t.jQueryInterface,e.fn[i].Constructor=t,e.fn[i].noConflict=()=>(e.fn[i]=n,t.jQueryInterface)}},\"loading\"===document.readyState?(f.length||document.addEventListener(\"DOMContentLoaded\",(()=>{for(const t of f)t()})),f.push(e)):e()},g=(t,e=[],i=t)=>\"function\"==typeof t?t(...e):i,_=(t,e,n=!0)=>{if(!n)return void g(t);const o=(t=>{if(!t)return 0;let{transitionDuration:e,transitionDelay:i}=window.getComputedStyle(t);const n=Number.parseFloat(e),s=Number.parseFloat(i);return n||s?(e=e.split(\",\")[0],i=i.split(\",\")[0],1e3*(Number.parseFloat(e)+Number.parseFloat(i))):0})(e)+5;let r=!1;const a=({target:n})=>{n===e&&(r=!0,e.removeEventListener(i,a),g(t))};e.addEventListener(i,a),setTimeout((()=>{r||s(e)}),o)},b=(t,e,i,n)=>{const s=t.length;let o=t.indexOf(e);return-1===o?!i&&n?t[s-1]:t[0]:(o+=i?1:-1,n&&(o=(o+s)%s),t[Math.max(0,Math.min(o,s-1))])},v=/[^.]*(?=\\..*)\\.|.*/,y=/\\..*/,w=/::\\d+$/,A={};let E=1;const T={mouseenter:\"mouseover\",mouseleave:\"mouseout\"},C=new Set([\"click\",\"dblclick\",\"mouseup\",\"mousedown\",\"contextmenu\",\"mousewheel\",\"DOMMouseScroll\",\"mouseover\",\"mouseout\",\"mousemove\",\"selectstart\",\"selectend\",\"keydown\",\"keypress\",\"keyup\",\"orientationchange\",\"touchstart\",\"touchmove\",\"touchend\",\"touchcancel\",\"pointerdown\",\"pointermove\",\"pointerup\",\"pointerleave\",\"pointercancel\",\"gesturestart\",\"gesturechange\",\"gestureend\",\"focus\",\"blur\",\"change\",\"reset\",\"select\",\"submit\",\"focusin\",\"focusout\",\"load\",\"unload\",\"beforeunload\",\"resize\",\"move\",\"DOMContentLoaded\",\"readystatechange\",\"error\",\"abort\",\"scroll\"]);function O(t,e){return e&&`${e}::${E++}`||t.uidEvent||E++}function x(t){const e=O(t);return t.uidEvent=e,A[e]=A[e]||{},A[e]}function k(t,e,i=null){return Object.values(t).find((t=>t.callable===e&&t.delegationSelector===i))}function L(t,e,i){const n=\"string\"==typeof e,s=n?i:e||i;let o=I(t);return C.has(o)||(o=t),[n,s,o]}function S(t,e,i,n,s){if(\"string\"!=typeof e||!t)return;let[o,r,a]=L(e,i,n);if(e in T){const t=t=>function(e){if(!e.relatedTarget||e.relatedTarget!==e.delegateTarget&&!e.delegateTarget.contains(e.relatedTarget))return t.call(this,e)};r=t(r)}const l=x(t),c=l[a]||(l[a]={}),h=k(c,r,o?i:null);if(h)return void(h.oneOff=h.oneOff&&s);const d=O(r,e.replace(v,\"\")),u=o?function(t,e,i){return function n(s){const o=t.querySelectorAll(e);for(let{target:r}=s;r&&r!==this;r=r.parentNode)for(const a of o)if(a===r)return P(s,{delegateTarget:r}),n.oneOff&&N.off(t,s.type,e,i),i.apply(r,[s])}}(t,i,r):function(t,e){return function i(n){return P(n,{delegateTarget:t}),i.oneOff&&N.off(t,n.type,e),e.apply(t,[n])}}(t,r);u.delegationSelector=o?i:null,u.callable=r,u.oneOff=s,u.uidEvent=d,c[d]=u,t.addEventListener(a,u,o)}function D(t,e,i,n,s){const o=k(e[i],n,s);o&&(t.removeEventListener(i,o,Boolean(s)),delete e[i][o.uidEvent])}function $(t,e,i,n){const s=e[i]||{};for(const[o,r]of Object.entries(s))o.includes(n)&&D(t,e,i,r.callable,r.delegationSelector)}function I(t){return t=t.replace(y,\"\"),T[t]||t}const N={on(t,e,i,n){S(t,e,i,n,!1)},one(t,e,i,n){S(t,e,i,n,!0)},off(t,e,i,n){if(\"string\"!=typeof e||!t)return;const[s,o,r]=L(e,i,n),a=r!==e,l=x(t),c=l[r]||{},h=e.startsWith(\".\");if(void 0===o){if(h)for(const i of Object.keys(l))$(t,l,i,e.slice(1));for(const[i,n]of Object.entries(c)){const s=i.replace(w,\"\");a&&!e.includes(s)||D(t,l,r,n.callable,n.delegationSelector)}}else{if(!Object.keys(c).length)return;D(t,l,r,o,s?i:null)}},trigger(t,e,i){if(\"string\"!=typeof e||!t)return null;const n=u();let s=null,o=!0,r=!0,a=!1;e!==I(e)&&n&&(s=n.Event(e,i),n(t).trigger(s),o=!s.isPropagationStopped(),r=!s.isImmediatePropagationStopped(),a=s.isDefaultPrevented());const l=P(new Event(e,{bubbles:o,cancelable:!0}),i);return a&&l.preventDefault(),r&&t.dispatchEvent(l),l.defaultPrevented&&s&&s.preventDefault(),l}};function P(t,e={}){for(const[i,n]of Object.entries(e))try{t[i]=n}catch(e){Object.defineProperty(t,i,{configurable:!0,get:()=>n})}return t}function j(t){if(\"true\"===t)return!0;if(\"false\"===t)return!1;if(t===Number(t).toString())return Number(t);if(\"\"===t||\"null\"===t)return null;if(\"string\"!=typeof t)return t;try{return JSON.parse(decodeURIComponent(t))}catch(e){return t}}function M(t){return t.replace(/[A-Z]/g,(t=>`-${t.toLowerCase()}`))}const F={setDataAttribute(t,e,i){t.setAttribute(`data-bs-${M(e)}`,i)},removeDataAttribute(t,e){t.removeAttribute(`data-bs-${M(e)}`)},getDataAttributes(t){if(!t)return{};const e={},i=Object.keys(t.dataset).filter((t=>t.startsWith(\"bs\")&&!t.startsWith(\"bsConfig\")));for(const n of i){let i=n.replace(/^bs/,\"\");i=i.charAt(0).toLowerCase()+i.slice(1,i.length),e[i]=j(t.dataset[n])}return e},getDataAttribute:(t,e)=>j(t.getAttribute(`data-bs-${M(e)}`))};class H{static get Default(){return{}}static get DefaultType(){return{}}static get NAME(){throw new Error('You have to implement the static method \"NAME\", for each component!')}_getConfig(t){return t=this._mergeConfigObj(t),t=this._configAfterMerge(t),this._typeCheckConfig(t),t}_configAfterMerge(t){return t}_mergeConfigObj(t,e){const i=o(e)?F.getDataAttribute(e,\"config\"):{};return{...this.constructor.Default,...\"object\"==typeof i?i:{},...o(e)?F.getDataAttributes(e):{},...\"object\"==typeof t?t:{}}}_typeCheckConfig(t,e=this.constructor.DefaultType){for(const[n,s]of Object.entries(e)){const e=t[n],r=o(e)?\"element\":null==(i=e)?`${i}`:Object.prototype.toString.call(i).match(/\\s([a-z]+)/i)[1].toLowerCase();if(!new RegExp(s).test(r))throw new TypeError(`${this.constructor.NAME.toUpperCase()}: Option \"${n}\" provided type \"${r}\" but expected type \"${s}\".`)}var i}}class W extends H{constructor(t,i){super(),(t=r(t))&&(this._element=t,this._config=this._getConfig(i),e.set(this._element,this.constructor.DATA_KEY,this))}dispose(){e.remove(this._element,this.constructor.DATA_KEY),N.off(this._element,this.constructor.EVENT_KEY);for(const t of Object.getOwnPropertyNames(this))this[t]=null}_queueCallback(t,e,i=!0){_(t,e,i)}_getConfig(t){return t=this._mergeConfigObj(t,this._element),t=this._configAfterMerge(t),this._typeCheckConfig(t),t}static getInstance(t){return e.get(r(t),this.DATA_KEY)}static getOrCreateInstance(t,e={}){return this.getInstance(t)||new this(t,\"object\"==typeof e?e:null)}static get VERSION(){return\"5.3.3\"}static get DATA_KEY(){return`bs.${this.NAME}`}static get EVENT_KEY(){return`.${this.DATA_KEY}`}static eventName(t){return`${t}${this.EVENT_KEY}`}}const B=t=>{let e=t.getAttribute(\"data-bs-target\");if(!e||\"#\"===e){let i=t.getAttribute(\"href\");if(!i||!i.includes(\"#\")&&!i.startsWith(\".\"))return null;i.includes(\"#\")&&!i.startsWith(\"#\")&&(i=`#${i.split(\"#\")[1]}`),e=i&&\"#\"!==i?i.trim():null}return e?e.split(\",\").map((t=>n(t))).join(\",\"):null},z={find:(t,e=document.documentElement)=>[].concat(...Element.prototype.querySelectorAll.call(e,t)),findOne:(t,e=document.documentElement)=>Element.prototype.querySelector.call(e,t),children:(t,e)=>[].concat(...t.children).filter((t=>t.matches(e))),parents(t,e){const i=[];let n=t.parentNode.closest(e);for(;n;)i.push(n),n=n.parentNode.closest(e);return i},prev(t,e){let i=t.previousElementSibling;for(;i;){if(i.matches(e))return[i];i=i.previousElementSibling}return[]},next(t,e){let i=t.nextElementSibling;for(;i;){if(i.matches(e))return[i];i=i.nextElementSibling}return[]},focusableChildren(t){const e=[\"a\",\"button\",\"input\",\"textarea\",\"select\",\"details\",\"[tabindex]\",'[contenteditable=\"true\"]'].map((t=>`${t}:not([tabindex^=\"-\"])`)).join(\",\");return this.find(e,t).filter((t=>!l(t)&&a(t)))},getSelectorFromElement(t){const e=B(t);return e&&z.findOne(e)?e:null},getElementFromSelector(t){const e=B(t);return e?z.findOne(e):null},getMultipleElementsFromSelector(t){const e=B(t);return e?z.find(e):[]}},R=(t,e=\"hide\")=>{const i=`click.dismiss${t.EVENT_KEY}`,n=t.NAME;N.on(document,i,`[data-bs-dismiss=\"${n}\"]`,(function(i){if([\"A\",\"AREA\"].includes(this.tagName)&&i.preventDefault(),l(this))return;const s=z.getElementFromSelector(this)||this.closest(`.${n}`);t.getOrCreateInstance(s)[e]()}))},q=\".bs.alert\",V=`close${q}`,K=`closed${q}`;class Q extends W{static get NAME(){return\"alert\"}close(){if(N.trigger(this._element,V).defaultPrevented)return;this._element.classList.remove(\"show\");const t=this._element.classList.contains(\"fade\");this._queueCallback((()=>this._destroyElement()),this._element,t)}_destroyElement(){this._element.remove(),N.trigger(this._element,K),this.dispose()}static jQueryInterface(t){return this.each((function(){const e=Q.getOrCreateInstance(this);if(\"string\"==typeof t){if(void 0===e[t]||t.startsWith(\"_\")||\"constructor\"===t)throw new TypeError(`No method named \"${t}\"`);e[t](this)}}))}}R(Q,\"close\"),m(Q);const X='[data-bs-toggle=\"button\"]';class Y extends W{static get NAME(){return\"button\"}toggle(){this._element.setAttribute(\"aria-pressed\",this._element.classList.toggle(\"active\"))}static jQueryInterface(t){return this.each((function(){const e=Y.getOrCreateInstance(this);\"toggle\"===t&&e[t]()}))}}N.on(document,\"click.bs.button.data-api\",X,(t=>{t.preventDefault();const e=t.target.closest(X);Y.getOrCreateInstance(e).toggle()})),m(Y);const U=\".bs.swipe\",G=`touchstart${U}`,J=`touchmove${U}`,Z=`touchend${U}`,tt=`pointerdown${U}`,et=`pointerup${U}`,it={endCallback:null,leftCallback:null,rightCallback:null},nt={endCallback:\"(function|null)\",leftCallback:\"(function|null)\",rightCallback:\"(function|null)\"};class st extends H{constructor(t,e){super(),this._element=t,t&&st.isSupported()&&(this._config=this._getConfig(e),this._deltaX=0,this._supportPointerEvents=Boolean(window.PointerEvent),this._initEvents())}static get Default(){return it}static get DefaultType(){return nt}static get NAME(){return\"swipe\"}dispose(){N.off(this._element,U)}_start(t){this._supportPointerEvents?this._eventIsPointerPenTouch(t)&&(this._deltaX=t.clientX):this._deltaX=t.touches[0].clientX}_end(t){this._eventIsPointerPenTouch(t)&&(this._deltaX=t.clientX-this._deltaX),this._handleSwipe(),g(this._config.endCallback)}_move(t){this._deltaX=t.touches&&t.touches.length>1?0:t.touches[0].clientX-this._deltaX}_handleSwipe(){const t=Math.abs(this._deltaX);if(t<=40)return;const e=t/this._deltaX;this._deltaX=0,e&&g(e>0?this._config.rightCallback:this._config.leftCallback)}_initEvents(){this._supportPointerEvents?(N.on(this._element,tt,(t=>this._start(t))),N.on(this._element,et,(t=>this._end(t))),this._element.classList.add(\"pointer-event\")):(N.on(this._element,G,(t=>this._start(t))),N.on(this._element,J,(t=>this._move(t))),N.on(this._element,Z,(t=>this._end(t))))}_eventIsPointerPenTouch(t){return this._supportPointerEvents&&(\"pen\"===t.pointerType||\"touch\"===t.pointerType)}static isSupported(){return\"ontouchstart\"in document.documentElement||navigator.maxTouchPoints>0}}const ot=\".bs.carousel\",rt=\".data-api\",at=\"next\",lt=\"prev\",ct=\"left\",ht=\"right\",dt=`slide${ot}`,ut=`slid${ot}`,ft=`keydown${ot}`,pt=`mouseenter${ot}`,mt=`mouseleave${ot}`,gt=`dragstart${ot}`,_t=`load${ot}${rt}`,bt=`click${ot}${rt}`,vt=\"carousel\",yt=\"active\",wt=\".active\",At=\".carousel-item\",Et=wt+At,Tt={ArrowLeft:ht,ArrowRight:ct},Ct={interval:5e3,keyboard:!0,pause:\"hover\",ride:!1,touch:!0,wrap:!0},Ot={interval:\"(number|boolean)\",keyboard:\"boolean\",pause:\"(string|boolean)\",ride:\"(boolean|string)\",touch:\"boolean\",wrap:\"boolean\"};class xt extends W{constructor(t,e){super(t,e),this._interval=null,this._activeElement=null,this._isSliding=!1,this.touchTimeout=null,this._swipeHelper=null,this._indicatorsElement=z.findOne(\".carousel-indicators\",this._element),this._addEventListeners(),this._config.ride===vt&&this.cycle()}static get Default(){return Ct}static get DefaultType(){return Ot}static get NAME(){return\"carousel\"}next(){this._slide(at)}nextWhenVisible(){!document.hidden&&a(this._element)&&this.next()}prev(){this._slide(lt)}pause(){this._isSliding&&s(this._element),this._clearInterval()}cycle(){this._clearInterval(),this._updateInterval(),this._interval=setInterval((()=>this.nextWhenVisible()),this._config.interval)}_maybeEnableCycle(){this._config.ride&&(this._isSliding?N.one(this._element,ut,(()=>this.cycle())):this.cycle())}to(t){const e=this._getItems();if(t>e.length-1||t<0)return;if(this._isSliding)return void N.one(this._element,ut,(()=>this.to(t)));const i=this._getItemIndex(this._getActive());if(i===t)return;const n=t>i?at:lt;this._slide(n,e[t])}dispose(){this._swipeHelper&&this._swipeHelper.dispose(),super.dispose()}_configAfterMerge(t){return t.defaultInterval=t.interval,t}_addEventListeners(){this._config.keyboard&&N.on(this._element,ft,(t=>this._keydown(t))),\"hover\"===this._config.pause&&(N.on(this._element,pt,(()=>this.pause())),N.on(this._element,mt,(()=>this._maybeEnableCycle()))),this._config.touch&&st.isSupported()&&this._addTouchEventListeners()}_addTouchEventListeners(){for(const t of z.find(\".carousel-item img\",this._element))N.on(t,gt,(t=>t.preventDefault()));const t={leftCallback:()=>this._slide(this._directionToOrder(ct)),rightCallback:()=>this._slide(this._directionToOrder(ht)),endCallback:()=>{\"hover\"===this._config.pause&&(this.pause(),this.touchTimeout&&clearTimeout(this.touchTimeout),this.touchTimeout=setTimeout((()=>this._maybeEnableCycle()),500+this._config.interval))}};this._swipeHelper=new st(this._element,t)}_keydown(t){if(/input|textarea/i.test(t.target.tagName))return;const e=Tt[t.key];e&&(t.preventDefault(),this._slide(this._directionToOrder(e)))}_getItemIndex(t){return this._getItems().indexOf(t)}_setActiveIndicatorElement(t){if(!this._indicatorsElement)return;const e=z.findOne(wt,this._indicatorsElement);e.classList.remove(yt),e.removeAttribute(\"aria-current\");const i=z.findOne(`[data-bs-slide-to=\"${t}\"]`,this._indicatorsElement);i&&(i.classList.add(yt),i.setAttribute(\"aria-current\",\"true\"))}_updateInterval(){const t=this._activeElement||this._getActive();if(!t)return;const e=Number.parseInt(t.getAttribute(\"data-bs-interval\"),10);this._config.interval=e||this._config.defaultInterval}_slide(t,e=null){if(this._isSliding)return;const i=this._getActive(),n=t===at,s=e||b(this._getItems(),i,n,this._config.wrap);if(s===i)return;const o=this._getItemIndex(s),r=e=>N.trigger(this._element,e,{relatedTarget:s,direction:this._orderToDirection(t),from:this._getItemIndex(i),to:o});if(r(dt).defaultPrevented)return;if(!i||!s)return;const a=Boolean(this._interval);this.pause(),this._isSliding=!0,this._setActiveIndicatorElement(o),this._activeElement=s;const l=n?\"carousel-item-start\":\"carousel-item-end\",c=n?\"carousel-item-next\":\"carousel-item-prev\";s.classList.add(c),d(s),i.classList.add(l),s.classList.add(l),this._queueCallback((()=>{s.classList.remove(l,c),s.classList.add(yt),i.classList.remove(yt,c,l),this._isSliding=!1,r(ut)}),i,this._isAnimated()),a&&this.cycle()}_isAnimated(){return this._element.classList.contains(\"slide\")}_getActive(){return z.findOne(Et,this._element)}_getItems(){return z.find(At,this._element)}_clearInterval(){this._interval&&(clearInterval(this._interval),this._interval=null)}_directionToOrder(t){return p()?t===ct?lt:at:t===ct?at:lt}_orderToDirection(t){return p()?t===lt?ct:ht:t===lt?ht:ct}static jQueryInterface(t){return this.each((function(){const e=xt.getOrCreateInstance(this,t);if(\"number\"!=typeof t){if(\"string\"==typeof t){if(void 0===e[t]||t.startsWith(\"_\")||\"constructor\"===t)throw new TypeError(`No method named \"${t}\"`);e[t]()}}else e.to(t)}))}}N.on(document,bt,\"[data-bs-slide], [data-bs-slide-to]\",(function(t){const e=z.getElementFromSelector(this);if(!e||!e.classList.contains(vt))return;t.preventDefault();const i=xt.getOrCreateInstance(e),n=this.getAttribute(\"data-bs-slide-to\");return n?(i.to(n),void i._maybeEnableCycle()):\"next\"===F.getDataAttribute(this,\"slide\")?(i.next(),void i._maybeEnableCycle()):(i.prev(),void i._maybeEnableCycle())})),N.on(window,_t,(()=>{const t=z.find('[data-bs-ride=\"carousel\"]');for(const e of t)xt.getOrCreateInstance(e)})),m(xt);const kt=\".bs.collapse\",Lt=`show${kt}`,St=`shown${kt}`,Dt=`hide${kt}`,$t=`hidden${kt}`,It=`click${kt}.data-api`,Nt=\"show\",Pt=\"collapse\",jt=\"collapsing\",Mt=`:scope .${Pt} .${Pt}`,Ft='[data-bs-toggle=\"collapse\"]',Ht={parent:null,toggle:!0},Wt={parent:\"(null|element)\",toggle:\"boolean\"};class Bt extends W{constructor(t,e){super(t,e),this._isTransitioning=!1,this._triggerArray=[];const i=z.find(Ft);for(const t of i){const e=z.getSelectorFromElement(t),i=z.find(e).filter((t=>t===this._element));null!==e&&i.length&&this._triggerArray.push(t)}this._initializeChildren(),this._config.parent||this._addAriaAndCollapsedClass(this._triggerArray,this._isShown()),this._config.toggle&&this.toggle()}static get Default(){return Ht}static get DefaultType(){return Wt}static get NAME(){return\"collapse\"}toggle(){this._isShown()?this.hide():this.show()}show(){if(this._isTransitioning||this._isShown())return;let t=[];if(this._config.parent&&(t=this._getFirstLevelChildren(\".collapse.show, .collapse.collapsing\").filter((t=>t!==this._element)).map((t=>Bt.getOrCreateInstance(t,{toggle:!1})))),t.length&&t[0]._isTransitioning)return;if(N.trigger(this._element,Lt).defaultPrevented)return;for(const e of t)e.hide();const e=this._getDimension();this._element.classList.remove(Pt),this._element.classList.add(jt),this._element.style[e]=0,this._addAriaAndCollapsedClass(this._triggerArray,!0),this._isTransitioning=!0;const i=`scroll${e[0].toUpperCase()+e.slice(1)}`;this._queueCallback((()=>{this._isTransitioning=!1,this._element.classList.remove(jt),this._element.classList.add(Pt,Nt),this._element.style[e]=\"\",N.trigger(this._element,St)}),this._element,!0),this._element.style[e]=`${this._element[i]}px`}hide(){if(this._isTransitioning||!this._isShown())return;if(N.trigger(this._element,Dt).defaultPrevented)return;const t=this._getDimension();this._element.style[t]=`${this._element.getBoundingClientRect()[t]}px`,d(this._element),this._element.classList.add(jt),this._element.classList.remove(Pt,Nt);for(const t of this._triggerArray){const e=z.getElementFromSelector(t);e&&!this._isShown(e)&&this._addAriaAndCollapsedClass([t],!1)}this._isTransitioning=!0,this._element.style[t]=\"\",this._queueCallback((()=>{this._isTransitioning=!1,this._element.classList.remove(jt),this._element.classList.add(Pt),N.trigger(this._element,$t)}),this._element,!0)}_isShown(t=this._element){return t.classList.contains(Nt)}_configAfterMerge(t){return t.toggle=Boolean(t.toggle),t.parent=r(t.parent),t}_getDimension(){return this._element.classList.contains(\"collapse-horizontal\")?\"width\":\"height\"}_initializeChildren(){if(!this._config.parent)return;const t=this._getFirstLevelChildren(Ft);for(const e of t){const t=z.getElementFromSelector(e);t&&this._addAriaAndCollapsedClass([e],this._isShown(t))}}_getFirstLevelChildren(t){const e=z.find(Mt,this._config.parent);return z.find(t,this._config.parent).filter((t=>!e.includes(t)))}_addAriaAndCollapsedClass(t,e){if(t.length)for(const i of t)i.classList.toggle(\"collapsed\",!e),i.setAttribute(\"aria-expanded\",e)}static jQueryInterface(t){const e={};return\"string\"==typeof t&&/show|hide/.test(t)&&(e.toggle=!1),this.each((function(){const i=Bt.getOrCreateInstance(this,e);if(\"string\"==typeof t){if(void 0===i[t])throw new TypeError(`No method named \"${t}\"`);i[t]()}}))}}N.on(document,It,Ft,(function(t){(\"A\"===t.target.tagName||t.delegateTarget&&\"A\"===t.delegateTarget.tagName)&&t.preventDefault();for(const t of z.getMultipleElementsFromSelector(this))Bt.getOrCreateInstance(t,{toggle:!1}).toggle()})),m(Bt);var zt=\"top\",Rt=\"bottom\",qt=\"right\",Vt=\"left\",Kt=\"auto\",Qt=[zt,Rt,qt,Vt],Xt=\"start\",Yt=\"end\",Ut=\"clippingParents\",Gt=\"viewport\",Jt=\"popper\",Zt=\"reference\",te=Qt.reduce((function(t,e){return t.concat([e+\"-\"+Xt,e+\"-\"+Yt])}),[]),ee=[].concat(Qt,[Kt]).reduce((function(t,e){return t.concat([e,e+\"-\"+Xt,e+\"-\"+Yt])}),[]),ie=\"beforeRead\",ne=\"read\",se=\"afterRead\",oe=\"beforeMain\",re=\"main\",ae=\"afterMain\",le=\"beforeWrite\",ce=\"write\",he=\"afterWrite\",de=[ie,ne,se,oe,re,ae,le,ce,he];function ue(t){return t?(t.nodeName||\"\").toLowerCase():null}function fe(t){if(null==t)return window;if(\"[object Window]\"!==t.toString()){var e=t.ownerDocument;return e&&e.defaultView||window}return t}function pe(t){return t instanceof fe(t).Element||t instanceof Element}function me(t){return t instanceof fe(t).HTMLElement||t instanceof HTMLElement}function ge(t){return\"undefined\"!=typeof ShadowRoot&&(t instanceof fe(t).ShadowRoot||t instanceof ShadowRoot)}const _e={name:\"applyStyles\",enabled:!0,phase:\"write\",fn:function(t){var e=t.state;Object.keys(e.elements).forEach((function(t){var i=e.styles[t]||{},n=e.attributes[t]||{},s=e.elements[t];me(s)&&ue(s)&&(Object.assign(s.style,i),Object.keys(n).forEach((function(t){var e=n[t];!1===e?s.removeAttribute(t):s.setAttribute(t,!0===e?\"\":e)})))}))},effect:function(t){var e=t.state,i={popper:{position:e.options.strategy,left:\"0\",top:\"0\",margin:\"0\"},arrow:{position:\"absolute\"},reference:{}};return Object.assign(e.elements.popper.style,i.popper),e.styles=i,e.elements.arrow&&Object.assign(e.elements.arrow.style,i.arrow),function(){Object.keys(e.elements).forEach((function(t){var n=e.elements[t],s=e.attributes[t]||{},o=Object.keys(e.styles.hasOwnProperty(t)?e.styles[t]:i[t]).reduce((function(t,e){return t[e]=\"\",t}),{});me(n)&&ue(n)&&(Object.assign(n.style,o),Object.keys(s).forEach((function(t){n.removeAttribute(t)})))}))}},requires:[\"computeStyles\"]};function be(t){return t.split(\"-\")[0]}var ve=Math.max,ye=Math.min,we=Math.round;function Ae(){var t=navigator.userAgentData;return null!=t&&t.brands&&Array.isArray(t.brands)?t.brands.map((function(t){return t.brand+\"/\"+t.version})).join(\" \"):navigator.userAgent}function Ee(){return!/^((?!chrome|android).)*safari/i.test(Ae())}function Te(t,e,i){void 0===e&&(e=!1),void 0===i&&(i=!1);var n=t.getBoundingClientRect(),s=1,o=1;e&&me(t)&&(s=t.offsetWidth>0&&we(n.width)/t.offsetWidth||1,o=t.offsetHeight>0&&we(n.height)/t.offsetHeight||1);var r=(pe(t)?fe(t):window).visualViewport,a=!Ee()&&i,l=(n.left+(a&&r?r.offsetLeft:0))/s,c=(n.top+(a&&r?r.offsetTop:0))/o,h=n.width/s,d=n.height/o;return{width:h,height:d,top:c,right:l+h,bottom:c+d,left:l,x:l,y:c}}function Ce(t){var e=Te(t),i=t.offsetWidth,n=t.offsetHeight;return Math.abs(e.width-i)<=1&&(i=e.width),Math.abs(e.height-n)<=1&&(n=e.height),{x:t.offsetLeft,y:t.offsetTop,width:i,height:n}}function Oe(t,e){var i=e.getRootNode&&e.getRootNode();if(t.contains(e))return!0;if(i&&ge(i)){var n=e;do{if(n&&t.isSameNode(n))return!0;n=n.parentNode||n.host}while(n)}return!1}function xe(t){return fe(t).getComputedStyle(t)}function ke(t){return[\"table\",\"td\",\"th\"].indexOf(ue(t))>=0}function Le(t){return((pe(t)?t.ownerDocument:t.document)||window.document).documentElement}function Se(t){return\"html\"===ue(t)?t:t.assignedSlot||t.parentNode||(ge(t)?t.host:null)||Le(t)}function De(t){return me(t)&&\"fixed\"!==xe(t).position?t.offsetParent:null}function $e(t){for(var e=fe(t),i=De(t);i&&ke(i)&&\"static\"===xe(i).position;)i=De(i);return i&&(\"html\"===ue(i)||\"body\"===ue(i)&&\"static\"===xe(i).position)?e:i||function(t){var e=/firefox/i.test(Ae());if(/Trident/i.test(Ae())&&me(t)&&\"fixed\"===xe(t).position)return null;var i=Se(t);for(ge(i)&&(i=i.host);me(i)&&[\"html\",\"body\"].indexOf(ue(i))<0;){var n=xe(i);if(\"none\"!==n.transform||\"none\"!==n.perspective||\"paint\"===n.contain||-1!==[\"transform\",\"perspective\"].indexOf(n.willChange)||e&&\"filter\"===n.willChange||e&&n.filter&&\"none\"!==n.filter)return i;i=i.parentNode}return null}(t)||e}function Ie(t){return[\"top\",\"bottom\"].indexOf(t)>=0?\"x\":\"y\"}function Ne(t,e,i){return ve(t,ye(e,i))}function Pe(t){return Object.assign({},{top:0,right:0,bottom:0,left:0},t)}function je(t,e){return e.reduce((function(e,i){return e[i]=t,e}),{})}const Me={name:\"arrow\",enabled:!0,phase:\"main\",fn:function(t){var e,i=t.state,n=t.name,s=t.options,o=i.elements.arrow,r=i.modifiersData.popperOffsets,a=be(i.placement),l=Ie(a),c=[Vt,qt].indexOf(a)>=0?\"height\":\"width\";if(o&&r){var h=function(t,e){return Pe(\"number\"!=typeof(t=\"function\"==typeof t?t(Object.assign({},e.rects,{placement:e.placement})):t)?t:je(t,Qt))}(s.padding,i),d=Ce(o),u=\"y\"===l?zt:Vt,f=\"y\"===l?Rt:qt,p=i.rects.reference[c]+i.rects.reference[l]-r[l]-i.rects.popper[c],m=r[l]-i.rects.reference[l],g=$e(o),_=g?\"y\"===l?g.clientHeight||0:g.clientWidth||0:0,b=p/2-m/2,v=h[u],y=_-d[c]-h[f],w=_/2-d[c]/2+b,A=Ne(v,w,y),E=l;i.modifiersData[n]=((e={})[E]=A,e.centerOffset=A-w,e)}},effect:function(t){var e=t.state,i=t.options.element,n=void 0===i?\"[data-popper-arrow]\":i;null!=n&&(\"string\"!=typeof n||(n=e.elements.popper.querySelector(n)))&&Oe(e.elements.popper,n)&&(e.elements.arrow=n)},requires:[\"popperOffsets\"],requiresIfExists:[\"preventOverflow\"]};function Fe(t){return t.split(\"-\")[1]}var He={top:\"auto\",right:\"auto\",bottom:\"auto\",left:\"auto\"};function We(t){var e,i=t.popper,n=t.popperRect,s=t.placement,o=t.variation,r=t.offsets,a=t.position,l=t.gpuAcceleration,c=t.adaptive,h=t.roundOffsets,d=t.isFixed,u=r.x,f=void 0===u?0:u,p=r.y,m=void 0===p?0:p,g=\"function\"==typeof h?h({x:f,y:m}):{x:f,y:m};f=g.x,m=g.y;var _=r.hasOwnProperty(\"x\"),b=r.hasOwnProperty(\"y\"),v=Vt,y=zt,w=window;if(c){var A=$e(i),E=\"clientHeight\",T=\"clientWidth\";A===fe(i)&&\"static\"!==xe(A=Le(i)).position&&\"absolute\"===a&&(E=\"scrollHeight\",T=\"scrollWidth\"),(s===zt||(s===Vt||s===qt)&&o===Yt)&&(y=Rt,m-=(d&&A===w&&w.visualViewport?w.visualViewport.height:A[E])-n.height,m*=l?1:-1),s!==Vt&&(s!==zt&&s!==Rt||o!==Yt)||(v=qt,f-=(d&&A===w&&w.visualViewport?w.visualViewport.width:A[T])-n.width,f*=l?1:-1)}var C,O=Object.assign({position:a},c&&He),x=!0===h?function(t,e){var i=t.x,n=t.y,s=e.devicePixelRatio||1;return{x:we(i*s)/s||0,y:we(n*s)/s||0}}({x:f,y:m},fe(i)):{x:f,y:m};return f=x.x,m=x.y,l?Object.assign({},O,((C={})[y]=b?\"0\":\"\",C[v]=_?\"0\":\"\",C.transform=(w.devicePixelRatio||1)<=1?\"translate(\"+f+\"px, \"+m+\"px)\":\"translate3d(\"+f+\"px, \"+m+\"px, 0)\",C)):Object.assign({},O,((e={})[y]=b?m+\"px\":\"\",e[v]=_?f+\"px\":\"\",e.transform=\"\",e))}const Be={name:\"computeStyles\",enabled:!0,phase:\"beforeWrite\",fn:function(t){var e=t.state,i=t.options,n=i.gpuAcceleration,s=void 0===n||n,o=i.adaptive,r=void 0===o||o,a=i.roundOffsets,l=void 0===a||a,c={placement:be(e.placement),variation:Fe(e.placement),popper:e.elements.popper,popperRect:e.rects.popper,gpuAcceleration:s,isFixed:\"fixed\"===e.options.strategy};null!=e.modifiersData.popperOffsets&&(e.styles.popper=Object.assign({},e.styles.popper,We(Object.assign({},c,{offsets:e.modifiersData.popperOffsets,position:e.options.strategy,adaptive:r,roundOffsets:l})))),null!=e.modifiersData.arrow&&(e.styles.arrow=Object.assign({},e.styles.arrow,We(Object.assign({},c,{offsets:e.modifiersData.arrow,position:\"absolute\",adaptive:!1,roundOffsets:l})))),e.attributes.popper=Object.assign({},e.attributes.popper,{\"data-popper-placement\":e.placement})},data:{}};var ze={passive:!0};const Re={name:\"eventListeners\",enabled:!0,phase:\"write\",fn:function(){},effect:function(t){var e=t.state,i=t.instance,n=t.options,s=n.scroll,o=void 0===s||s,r=n.resize,a=void 0===r||r,l=fe(e.elements.popper),c=[].concat(e.scrollParents.reference,e.scrollParents.popper);return o&&c.forEach((function(t){t.addEventListener(\"scroll\",i.update,ze)})),a&&l.addEventListener(\"resize\",i.update,ze),function(){o&&c.forEach((function(t){t.removeEventListener(\"scroll\",i.update,ze)})),a&&l.removeEventListener(\"resize\",i.update,ze)}},data:{}};var qe={left:\"right\",right:\"left\",bottom:\"top\",top:\"bottom\"};function Ve(t){return t.replace(/left|right|bottom|top/g,(function(t){return qe[t]}))}var Ke={start:\"end\",end:\"start\"};function Qe(t){return t.replace(/start|end/g,(function(t){return Ke[t]}))}function Xe(t){var e=fe(t);return{scrollLeft:e.pageXOffset,scrollTop:e.pageYOffset}}function Ye(t){return Te(Le(t)).left+Xe(t).scrollLeft}function Ue(t){var e=xe(t),i=e.overflow,n=e.overflowX,s=e.overflowY;return/auto|scroll|overlay|hidden/.test(i+s+n)}function Ge(t){return[\"html\",\"body\",\"#document\"].indexOf(ue(t))>=0?t.ownerDocument.body:me(t)&&Ue(t)?t:Ge(Se(t))}function Je(t,e){var i;void 0===e&&(e=[]);var n=Ge(t),s=n===(null==(i=t.ownerDocument)?void 0:i.body),o=fe(n),r=s?[o].concat(o.visualViewport||[],Ue(n)?n:[]):n,a=e.concat(r);return s?a:a.concat(Je(Se(r)))}function Ze(t){return Object.assign({},t,{left:t.x,top:t.y,right:t.x+t.width,bottom:t.y+t.height})}function ti(t,e,i){return e===Gt?Ze(function(t,e){var i=fe(t),n=Le(t),s=i.visualViewport,o=n.clientWidth,r=n.clientHeight,a=0,l=0;if(s){o=s.width,r=s.height;var c=Ee();(c||!c&&\"fixed\"===e)&&(a=s.offsetLeft,l=s.offsetTop)}return{width:o,height:r,x:a+Ye(t),y:l}}(t,i)):pe(e)?function(t,e){var i=Te(t,!1,\"fixed\"===e);return i.top=i.top+t.clientTop,i.left=i.left+t.clientLeft,i.bottom=i.top+t.clientHeight,i.right=i.left+t.clientWidth,i.width=t.clientWidth,i.height=t.clientHeight,i.x=i.left,i.y=i.top,i}(e,i):Ze(function(t){var e,i=Le(t),n=Xe(t),s=null==(e=t.ownerDocument)?void 0:e.body,o=ve(i.scrollWidth,i.clientWidth,s?s.scrollWidth:0,s?s.clientWidth:0),r=ve(i.scrollHeight,i.clientHeight,s?s.scrollHeight:0,s?s.clientHeight:0),a=-n.scrollLeft+Ye(t),l=-n.scrollTop;return\"rtl\"===xe(s||i).direction&&(a+=ve(i.clientWidth,s?s.clientWidth:0)-o),{width:o,height:r,x:a,y:l}}(Le(t)))}function ei(t){var e,i=t.reference,n=t.element,s=t.placement,o=s?be(s):null,r=s?Fe(s):null,a=i.x+i.width/2-n.width/2,l=i.y+i.height/2-n.height/2;switch(o){case zt:e={x:a,y:i.y-n.height};break;case Rt:e={x:a,y:i.y+i.height};break;case qt:e={x:i.x+i.width,y:l};break;case Vt:e={x:i.x-n.width,y:l};break;default:e={x:i.x,y:i.y}}var c=o?Ie(o):null;if(null!=c){var h=\"y\"===c?\"height\":\"width\";switch(r){case Xt:e[c]=e[c]-(i[h]/2-n[h]/2);break;case Yt:e[c]=e[c]+(i[h]/2-n[h]/2)}}return e}function ii(t,e){void 0===e&&(e={});var i=e,n=i.placement,s=void 0===n?t.placement:n,o=i.strategy,r=void 0===o?t.strategy:o,a=i.boundary,l=void 0===a?Ut:a,c=i.rootBoundary,h=void 0===c?Gt:c,d=i.elementContext,u=void 0===d?Jt:d,f=i.altBoundary,p=void 0!==f&&f,m=i.padding,g=void 0===m?0:m,_=Pe(\"number\"!=typeof g?g:je(g,Qt)),b=u===Jt?Zt:Jt,v=t.rects.popper,y=t.elements[p?b:u],w=function(t,e,i,n){var s=\"clippingParents\"===e?function(t){var e=Je(Se(t)),i=[\"absolute\",\"fixed\"].indexOf(xe(t).position)>=0&&me(t)?$e(t):t;return pe(i)?e.filter((function(t){return pe(t)&&Oe(t,i)&&\"body\"!==ue(t)})):[]}(t):[].concat(e),o=[].concat(s,[i]),r=o[0],a=o.reduce((function(e,i){var s=ti(t,i,n);return e.top=ve(s.top,e.top),e.right=ye(s.right,e.right),e.bottom=ye(s.bottom,e.bottom),e.left=ve(s.left,e.left),e}),ti(t,r,n));return a.width=a.right-a.left,a.height=a.bottom-a.top,a.x=a.left,a.y=a.top,a}(pe(y)?y:y.contextElement||Le(t.elements.popper),l,h,r),A=Te(t.elements.reference),E=ei({reference:A,element:v,strategy:\"absolute\",placement:s}),T=Ze(Object.assign({},v,E)),C=u===Jt?T:A,O={top:w.top-C.top+_.top,bottom:C.bottom-w.bottom+_.bottom,left:w.left-C.left+_.left,right:C.right-w.right+_.right},x=t.modifiersData.offset;if(u===Jt&&x){var k=x[s];Object.keys(O).forEach((function(t){var e=[qt,Rt].indexOf(t)>=0?1:-1,i=[zt,Rt].indexOf(t)>=0?\"y\":\"x\";O[t]+=k[i]*e}))}return O}function ni(t,e){void 0===e&&(e={});var i=e,n=i.placement,s=i.boundary,o=i.rootBoundary,r=i.padding,a=i.flipVariations,l=i.allowedAutoPlacements,c=void 0===l?ee:l,h=Fe(n),d=h?a?te:te.filter((function(t){return Fe(t)===h})):Qt,u=d.filter((function(t){return c.indexOf(t)>=0}));0===u.length&&(u=d);var f=u.reduce((function(e,i){return e[i]=ii(t,{placement:i,boundary:s,rootBoundary:o,padding:r})[be(i)],e}),{});return Object.keys(f).sort((function(t,e){return f[t]-f[e]}))}const si={name:\"flip\",enabled:!0,phase:\"main\",fn:function(t){var e=t.state,i=t.options,n=t.name;if(!e.modifiersData[n]._skip){for(var s=i.mainAxis,o=void 0===s||s,r=i.altAxis,a=void 0===r||r,l=i.fallbackPlacements,c=i.padding,h=i.boundary,d=i.rootBoundary,u=i.altBoundary,f=i.flipVariations,p=void 0===f||f,m=i.allowedAutoPlacements,g=e.options.placement,_=be(g),b=l||(_!==g&&p?function(t){if(be(t)===Kt)return[];var e=Ve(t);return[Qe(t),e,Qe(e)]}(g):[Ve(g)]),v=[g].concat(b).reduce((function(t,i){return t.concat(be(i)===Kt?ni(e,{placement:i,boundary:h,rootBoundary:d,padding:c,flipVariations:p,allowedAutoPlacements:m}):i)}),[]),y=e.rects.reference,w=e.rects.popper,A=new Map,E=!0,T=v[0],C=0;C<v.length;C++){var O=v[C],x=be(O),k=Fe(O)===Xt,L=[zt,Rt].indexOf(x)>=0,S=L?\"width\":\"height\",D=ii(e,{placement:O,boundary:h,rootBoundary:d,altBoundary:u,padding:c}),$=L?k?qt:Vt:k?Rt:zt;y[S]>w[S]&&($=Ve($));var I=Ve($),N=[];if(o&&N.push(D[x]<=0),a&&N.push(D[$]<=0,D[I]<=0),N.every((function(t){return t}))){T=O,E=!1;break}A.set(O,N)}if(E)for(var P=function(t){var e=v.find((function(e){var i=A.get(e);if(i)return i.slice(0,t).every((function(t){return t}))}));if(e)return T=e,\"break\"},j=p?3:1;j>0&&\"break\"!==P(j);j--);e.placement!==T&&(e.modifiersData[n]._skip=!0,e.placement=T,e.reset=!0)}},requiresIfExists:[\"offset\"],data:{_skip:!1}};function oi(t,e,i){return void 0===i&&(i={x:0,y:0}),{top:t.top-e.height-i.y,right:t.right-e.width+i.x,bottom:t.bottom-e.height+i.y,left:t.left-e.width-i.x}}function ri(t){return[zt,qt,Rt,Vt].some((function(e){return t[e]>=0}))}const ai={name:\"hide\",enabled:!0,phase:\"main\",requiresIfExists:[\"preventOverflow\"],fn:function(t){var e=t.state,i=t.name,n=e.rects.reference,s=e.rects.popper,o=e.modifiersData.preventOverflow,r=ii(e,{elementContext:\"reference\"}),a=ii(e,{altBoundary:!0}),l=oi(r,n),c=oi(a,s,o),h=ri(l),d=ri(c);e.modifiersData[i]={referenceClippingOffsets:l,popperEscapeOffsets:c,isReferenceHidden:h,hasPopperEscaped:d},e.attributes.popper=Object.assign({},e.attributes.popper,{\"data-popper-reference-hidden\":h,\"data-popper-escaped\":d})}},li={name:\"offset\",enabled:!0,phase:\"main\",requires:[\"popperOffsets\"],fn:function(t){var e=t.state,i=t.options,n=t.name,s=i.offset,o=void 0===s?[0,0]:s,r=ee.reduce((function(t,i){return t[i]=function(t,e,i){var n=be(t),s=[Vt,zt].indexOf(n)>=0?-1:1,o=\"function\"==typeof i?i(Object.assign({},e,{placement:t})):i,r=o[0],a=o[1];return r=r||0,a=(a||0)*s,[Vt,qt].indexOf(n)>=0?{x:a,y:r}:{x:r,y:a}}(i,e.rects,o),t}),{}),a=r[e.placement],l=a.x,c=a.y;null!=e.modifiersData.popperOffsets&&(e.modifiersData.popperOffsets.x+=l,e.modifiersData.popperOffsets.y+=c),e.modifiersData[n]=r}},ci={name:\"popperOffsets\",enabled:!0,phase:\"read\",fn:function(t){var e=t.state,i=t.name;e.modifiersData[i]=ei({reference:e.rects.reference,element:e.rects.popper,strategy:\"absolute\",placement:e.placement})},data:{}},hi={name:\"preventOverflow\",enabled:!0,phase:\"main\",fn:function(t){var e=t.state,i=t.options,n=t.name,s=i.mainAxis,o=void 0===s||s,r=i.altAxis,a=void 0!==r&&r,l=i.boundary,c=i.rootBoundary,h=i.altBoundary,d=i.padding,u=i.tether,f=void 0===u||u,p=i.tetherOffset,m=void 0===p?0:p,g=ii(e,{boundary:l,rootBoundary:c,padding:d,altBoundary:h}),_=be(e.placement),b=Fe(e.placement),v=!b,y=Ie(_),w=\"x\"===y?\"y\":\"x\",A=e.modifiersData.popperOffsets,E=e.rects.reference,T=e.rects.popper,C=\"function\"==typeof m?m(Object.assign({},e.rects,{placement:e.placement})):m,O=\"number\"==typeof C?{mainAxis:C,altAxis:C}:Object.assign({mainAxis:0,altAxis:0},C),x=e.modifiersData.offset?e.modifiersData.offset[e.placement]:null,k={x:0,y:0};if(A){if(o){var L,S=\"y\"===y?zt:Vt,D=\"y\"===y?Rt:qt,$=\"y\"===y?\"height\":\"width\",I=A[y],N=I+g[S],P=I-g[D],j=f?-T[$]/2:0,M=b===Xt?E[$]:T[$],F=b===Xt?-T[$]:-E[$],H=e.elements.arrow,W=f&&H?Ce(H):{width:0,height:0},B=e.modifiersData[\"arrow#persistent\"]?e.modifiersData[\"arrow#persistent\"].padding:{top:0,right:0,bottom:0,left:0},z=B[S],R=B[D],q=Ne(0,E[$],W[$]),V=v?E[$]/2-j-q-z-O.mainAxis:M-q-z-O.mainAxis,K=v?-E[$]/2+j+q+R+O.mainAxis:F+q+R+O.mainAxis,Q=e.elements.arrow&&$e(e.elements.arrow),X=Q?\"y\"===y?Q.clientTop||0:Q.clientLeft||0:0,Y=null!=(L=null==x?void 0:x[y])?L:0,U=I+K-Y,G=Ne(f?ye(N,I+V-Y-X):N,I,f?ve(P,U):P);A[y]=G,k[y]=G-I}if(a){var J,Z=\"x\"===y?zt:Vt,tt=\"x\"===y?Rt:qt,et=A[w],it=\"y\"===w?\"height\":\"width\",nt=et+g[Z],st=et-g[tt],ot=-1!==[zt,Vt].indexOf(_),rt=null!=(J=null==x?void 0:x[w])?J:0,at=ot?nt:et-E[it]-T[it]-rt+O.altAxis,lt=ot?et+E[it]+T[it]-rt-O.altAxis:st,ct=f&&ot?function(t,e,i){var n=Ne(t,e,i);return n>i?i:n}(at,et,lt):Ne(f?at:nt,et,f?lt:st);A[w]=ct,k[w]=ct-et}e.modifiersData[n]=k}},requiresIfExists:[\"offset\"]};function di(t,e,i){void 0===i&&(i=!1);var n,s,o=me(e),r=me(e)&&function(t){var e=t.getBoundingClientRect(),i=we(e.width)/t.offsetWidth||1,n=we(e.height)/t.offsetHeight||1;return 1!==i||1!==n}(e),a=Le(e),l=Te(t,r,i),c={scrollLeft:0,scrollTop:0},h={x:0,y:0};return(o||!o&&!i)&&((\"body\"!==ue(e)||Ue(a))&&(c=(n=e)!==fe(n)&&me(n)?{scrollLeft:(s=n).scrollLeft,scrollTop:s.scrollTop}:Xe(n)),me(e)?((h=Te(e,!0)).x+=e.clientLeft,h.y+=e.clientTop):a&&(h.x=Ye(a))),{x:l.left+c.scrollLeft-h.x,y:l.top+c.scrollTop-h.y,width:l.width,height:l.height}}function ui(t){var e=new Map,i=new Set,n=[];function s(t){i.add(t.name),[].concat(t.requires||[],t.requiresIfExists||[]).forEach((function(t){if(!i.has(t)){var n=e.get(t);n&&s(n)}})),n.push(t)}return t.forEach((function(t){e.set(t.name,t)})),t.forEach((function(t){i.has(t.name)||s(t)})),n}var fi={placement:\"bottom\",modifiers:[],strategy:\"absolute\"};function pi(){for(var t=arguments.length,e=new Array(t),i=0;i<t;i++)e[i]=arguments[i];return!e.some((function(t){return!(t&&\"function\"==typeof t.getBoundingClientRect)}))}function mi(t){void 0===t&&(t={});var e=t,i=e.defaultModifiers,n=void 0===i?[]:i,s=e.defaultOptions,o=void 0===s?fi:s;return function(t,e,i){void 0===i&&(i=o);var s,r,a={placement:\"bottom\",orderedModifiers:[],options:Object.assign({},fi,o),modifiersData:{},elements:{reference:t,popper:e},attributes:{},styles:{}},l=[],c=!1,h={state:a,setOptions:function(i){var s=\"function\"==typeof i?i(a.options):i;d(),a.options=Object.assign({},o,a.options,s),a.scrollParents={reference:pe(t)?Je(t):t.contextElement?Je(t.contextElement):[],popper:Je(e)};var r,c,u=function(t){var e=ui(t);return de.reduce((function(t,i){return t.concat(e.filter((function(t){return t.phase===i})))}),[])}((r=[].concat(n,a.options.modifiers),c=r.reduce((function(t,e){var i=t[e.name];return t[e.name]=i?Object.assign({},i,e,{options:Object.assign({},i.options,e.options),data:Object.assign({},i.data,e.data)}):e,t}),{}),Object.keys(c).map((function(t){return c[t]}))));return a.orderedModifiers=u.filter((function(t){return t.enabled})),a.orderedModifiers.forEach((function(t){var e=t.name,i=t.options,n=void 0===i?{}:i,s=t.effect;if(\"function\"==typeof s){var o=s({state:a,name:e,instance:h,options:n});l.push(o||function(){})}})),h.update()},forceUpdate:function(){if(!c){var t=a.elements,e=t.reference,i=t.popper;if(pi(e,i)){a.rects={reference:di(e,$e(i),\"fixed\"===a.options.strategy),popper:Ce(i)},a.reset=!1,a.placement=a.options.placement,a.orderedModifiers.forEach((function(t){return a.modifiersData[t.name]=Object.assign({},t.data)}));for(var n=0;n<a.orderedModifiers.length;n++)if(!0!==a.reset){var s=a.orderedModifiers[n],o=s.fn,r=s.options,l=void 0===r?{}:r,d=s.name;\"function\"==typeof o&&(a=o({state:a,options:l,name:d,instance:h})||a)}else a.reset=!1,n=-1}}},update:(s=function(){return new Promise((function(t){h.forceUpdate(),t(a)}))},function(){return r||(r=new Promise((function(t){Promise.resolve().then((function(){r=void 0,t(s())}))}))),r}),destroy:function(){d(),c=!0}};if(!pi(t,e))return h;function d(){l.forEach((function(t){return t()})),l=[]}return h.setOptions(i).then((function(t){!c&&i.onFirstUpdate&&i.onFirstUpdate(t)})),h}}var gi=mi(),_i=mi({defaultModifiers:[Re,ci,Be,_e]}),bi=mi({defaultModifiers:[Re,ci,Be,_e,li,si,hi,Me,ai]});const vi=Object.freeze(Object.defineProperty({__proto__:null,afterMain:ae,afterRead:se,afterWrite:he,applyStyles:_e,arrow:Me,auto:Kt,basePlacements:Qt,beforeMain:oe,beforeRead:ie,beforeWrite:le,bottom:Rt,clippingParents:Ut,computeStyles:Be,createPopper:bi,createPopperBase:gi,createPopperLite:_i,detectOverflow:ii,end:Yt,eventListeners:Re,flip:si,hide:ai,left:Vt,main:re,modifierPhases:de,offset:li,placements:ee,popper:Jt,popperGenerator:mi,popperOffsets:ci,preventOverflow:hi,read:ne,reference:Zt,right:qt,start:Xt,top:zt,variationPlacements:te,viewport:Gt,write:ce},Symbol.toStringTag,{value:\"Module\"})),yi=\"dropdown\",wi=\".bs.dropdown\",Ai=\".data-api\",Ei=\"ArrowUp\",Ti=\"ArrowDown\",Ci=`hide${wi}`,Oi=`hidden${wi}`,xi=`show${wi}`,ki=`shown${wi}`,Li=`click${wi}${Ai}`,Si=`keydown${wi}${Ai}`,Di=`keyup${wi}${Ai}`,$i=\"show\",Ii='[data-bs-toggle=\"dropdown\"]:not(.disabled):not(:disabled)',Ni=`${Ii}.${$i}`,Pi=\".dropdown-menu\",ji=p()?\"top-end\":\"top-start\",Mi=p()?\"top-start\":\"top-end\",Fi=p()?\"bottom-end\":\"bottom-start\",Hi=p()?\"bottom-start\":\"bottom-end\",Wi=p()?\"left-start\":\"right-start\",Bi=p()?\"right-start\":\"left-start\",zi={autoClose:!0,boundary:\"clippingParents\",display:\"dynamic\",offset:[0,2],popperConfig:null,reference:\"toggle\"},Ri={autoClose:\"(boolean|string)\",boundary:\"(string|element)\",display:\"string\",offset:\"(array|string|function)\",popperConfig:\"(null|object|function)\",reference:\"(string|element|object)\"};class qi extends W{constructor(t,e){super(t,e),this._popper=null,this._parent=this._element.parentNode,this._menu=z.next(this._element,Pi)[0]||z.prev(this._element,Pi)[0]||z.findOne(Pi,this._parent),this._inNavbar=this._detectNavbar()}static get Default(){return zi}static get DefaultType(){return Ri}static get NAME(){return yi}toggle(){return this._isShown()?this.hide():this.show()}show(){if(l(this._element)||this._isShown())return;const t={relatedTarget:this._element};if(!N.trigger(this._element,xi,t).defaultPrevented){if(this._createPopper(),\"ontouchstart\"in document.documentElement&&!this._parent.closest(\".navbar-nav\"))for(const t of[].concat(...document.body.children))N.on(t,\"mouseover\",h);this._element.focus(),this._element.setAttribute(\"aria-expanded\",!0),this._menu.classList.add($i),this._element.classList.add($i),N.trigger(this._element,ki,t)}}hide(){if(l(this._element)||!this._isShown())return;const t={relatedTarget:this._element};this._completeHide(t)}dispose(){this._popper&&this._popper.destroy(),super.dispose()}update(){this._inNavbar=this._detectNavbar(),this._popper&&this._popper.update()}_completeHide(t){if(!N.trigger(this._element,Ci,t).defaultPrevented){if(\"ontouchstart\"in document.documentElement)for(const t of[].concat(...document.body.children))N.off(t,\"mouseover\",h);this._popper&&this._popper.destroy(),this._menu.classList.remove($i),this._element.classList.remove($i),this._element.setAttribute(\"aria-expanded\",\"false\"),F.removeDataAttribute(this._menu,\"popper\"),N.trigger(this._element,Oi,t)}}_getConfig(t){if(\"object\"==typeof(t=super._getConfig(t)).reference&&!o(t.reference)&&\"function\"!=typeof t.reference.getBoundingClientRect)throw new TypeError(`${yi.toUpperCase()}: Option \"reference\" provided type \"object\" without a required \"getBoundingClientRect\" method.`);return t}_createPopper(){if(void 0===vi)throw new TypeError(\"Bootstrap's dropdowns require Popper (https://popper.js.org)\");let t=this._element;\"parent\"===this._config.reference?t=this._parent:o(this._config.reference)?t=r(this._config.reference):\"object\"==typeof this._config.reference&&(t=this._config.reference);const e=this._getPopperConfig();this._popper=bi(t,this._menu,e)}_isShown(){return this._menu.classList.contains($i)}_getPlacement(){const t=this._parent;if(t.classList.contains(\"dropend\"))return Wi;if(t.classList.contains(\"dropstart\"))return Bi;if(t.classList.contains(\"dropup-center\"))return\"top\";if(t.classList.contains(\"dropdown-center\"))return\"bottom\";const e=\"end\"===getComputedStyle(this._menu).getPropertyValue(\"--bs-position\").trim();return t.classList.contains(\"dropup\")?e?Mi:ji:e?Hi:Fi}_detectNavbar(){return null!==this._element.closest(\".navbar\")}_getOffset(){const{offset:t}=this._config;return\"string\"==typeof t?t.split(\",\").map((t=>Number.parseInt(t,10))):\"function\"==typeof t?e=>t(e,this._element):t}_getPopperConfig(){const t={placement:this._getPlacement(),modifiers:[{name:\"preventOverflow\",options:{boundary:this._config.boundary}},{name:\"offset\",options:{offset:this._getOffset()}}]};return(this._inNavbar||\"static\"===this._config.display)&&(F.setDataAttribute(this._menu,\"popper\",\"static\"),t.modifiers=[{name:\"applyStyles\",enabled:!1}]),{...t,...g(this._config.popperConfig,[t])}}_selectMenuItem({key:t,target:e}){const i=z.find(\".dropdown-menu .dropdown-item:not(.disabled):not(:disabled)\",this._menu).filter((t=>a(t)));i.length&&b(i,e,t===Ti,!i.includes(e)).focus()}static jQueryInterface(t){return this.each((function(){const e=qi.getOrCreateInstance(this,t);if(\"string\"==typeof t){if(void 0===e[t])throw new TypeError(`No method named \"${t}\"`);e[t]()}}))}static clearMenus(t){if(2===t.button||\"keyup\"===t.type&&\"Tab\"!==t.key)return;const e=z.find(Ni);for(const i of e){const e=qi.getInstance(i);if(!e||!1===e._config.autoClose)continue;const n=t.composedPath(),s=n.includes(e._menu);if(n.includes(e._element)||\"inside\"===e._config.autoClose&&!s||\"outside\"===e._config.autoClose&&s)continue;if(e._menu.contains(t.target)&&(\"keyup\"===t.type&&\"Tab\"===t.key||/input|select|option|textarea|form/i.test(t.target.tagName)))continue;const o={relatedTarget:e._element};\"click\"===t.type&&(o.clickEvent=t),e._completeHide(o)}}static dataApiKeydownHandler(t){const e=/input|textarea/i.test(t.target.tagName),i=\"Escape\"===t.key,n=[Ei,Ti].includes(t.key);if(!n&&!i)return;if(e&&!i)return;t.preventDefault();const s=this.matches(Ii)?this:z.prev(this,Ii)[0]||z.next(this,Ii)[0]||z.findOne(Ii,t.delegateTarget.parentNode),o=qi.getOrCreateInstance(s);if(n)return t.stopPropagation(),o.show(),void o._selectMenuItem(t);o._isShown()&&(t.stopPropagation(),o.hide(),s.focus())}}N.on(document,Si,Ii,qi.dataApiKeydownHandler),N.on(document,Si,Pi,qi.dataApiKeydownHandler),N.on(document,Li,qi.clearMenus),N.on(document,Di,qi.clearMenus),N.on(document,Li,Ii,(function(t){t.preventDefault(),qi.getOrCreateInstance(this).toggle()})),m(qi);const Vi=\"backdrop\",Ki=\"show\",Qi=`mousedown.bs.${Vi}`,Xi={className:\"modal-backdrop\",clickCallback:null,isAnimated:!1,isVisible:!0,rootElement:\"body\"},Yi={className:\"string\",clickCallback:\"(function|null)\",isAnimated:\"boolean\",isVisible:\"boolean\",rootElement:\"(element|string)\"};class Ui extends H{constructor(t){super(),this._config=this._getConfig(t),this._isAppended=!1,this._element=null}static get Default(){return Xi}static get DefaultType(){return Yi}static get NAME(){return Vi}show(t){if(!this._config.isVisible)return void g(t);this._append();const e=this._getElement();this._config.isAnimated&&d(e),e.classList.add(Ki),this._emulateAnimation((()=>{g(t)}))}hide(t){this._config.isVisible?(this._getElement().classList.remove(Ki),this._emulateAnimation((()=>{this.dispose(),g(t)}))):g(t)}dispose(){this._isAppended&&(N.off(this._element,Qi),this._element.remove(),this._isAppended=!1)}_getElement(){if(!this._element){const t=document.createElement(\"div\");t.className=this._config.className,this._config.isAnimated&&t.classList.add(\"fade\"),this._element=t}return this._element}_configAfterMerge(t){return t.rootElement=r(t.rootElement),t}_append(){if(this._isAppended)return;const t=this._getElement();this._config.rootElement.append(t),N.on(t,Qi,(()=>{g(this._config.clickCallback)})),this._isAppended=!0}_emulateAnimation(t){_(t,this._getElement(),this._config.isAnimated)}}const Gi=\".bs.focustrap\",Ji=`focusin${Gi}`,Zi=`keydown.tab${Gi}`,tn=\"backward\",en={autofocus:!0,trapElement:null},nn={autofocus:\"boolean\",trapElement:\"element\"};class sn extends H{constructor(t){super(),this._config=this._getConfig(t),this._isActive=!1,this._lastTabNavDirection=null}static get Default(){return en}static get DefaultType(){return nn}static get NAME(){return\"focustrap\"}activate(){this._isActive||(this._config.autofocus&&this._config.trapElement.focus(),N.off(document,Gi),N.on(document,Ji,(t=>this._handleFocusin(t))),N.on(document,Zi,(t=>this._handleKeydown(t))),this._isActive=!0)}deactivate(){this._isActive&&(this._isActive=!1,N.off(document,Gi))}_handleFocusin(t){const{trapElement:e}=this._config;if(t.target===document||t.target===e||e.contains(t.target))return;const i=z.focusableChildren(e);0===i.length?e.focus():this._lastTabNavDirection===tn?i[i.length-1].focus():i[0].focus()}_handleKeydown(t){\"Tab\"===t.key&&(this._lastTabNavDirection=t.shiftKey?tn:\"forward\")}}const on=\".fixed-top, .fixed-bottom, .is-fixed, .sticky-top\",rn=\".sticky-top\",an=\"padding-right\",ln=\"margin-right\";class cn{constructor(){this._element=document.body}getWidth(){const t=document.documentElement.clientWidth;return Math.abs(window.innerWidth-t)}hide(){const t=this.getWidth();this._disableOverFlow(),this._setElementAttributes(this._element,an,(e=>e+t)),this._setElementAttributes(on,an,(e=>e+t)),this._setElementAttributes(rn,ln,(e=>e-t))}reset(){this._resetElementAttributes(this._element,\"overflow\"),this._resetElementAttributes(this._element,an),this._resetElementAttributes(on,an),this._resetElementAttributes(rn,ln)}isOverflowing(){return this.getWidth()>0}_disableOverFlow(){this._saveInitialAttribute(this._element,\"overflow\"),this._element.style.overflow=\"hidden\"}_setElementAttributes(t,e,i){const n=this.getWidth();this._applyManipulationCallback(t,(t=>{if(t!==this._element&&window.innerWidth>t.clientWidth+n)return;this._saveInitialAttribute(t,e);const s=window.getComputedStyle(t).getPropertyValue(e);t.style.setProperty(e,`${i(Number.parseFloat(s))}px`)}))}_saveInitialAttribute(t,e){const i=t.style.getPropertyValue(e);i&&F.setDataAttribute(t,e,i)}_resetElementAttributes(t,e){this._applyManipulationCallback(t,(t=>{const i=F.getDataAttribute(t,e);null!==i?(F.removeDataAttribute(t,e),t.style.setProperty(e,i)):t.style.removeProperty(e)}))}_applyManipulationCallback(t,e){if(o(t))e(t);else for(const i of z.find(t,this._element))e(i)}}const hn=\".bs.modal\",dn=`hide${hn}`,un=`hidePrevented${hn}`,fn=`hidden${hn}`,pn=`show${hn}`,mn=`shown${hn}`,gn=`resize${hn}`,_n=`click.dismiss${hn}`,bn=`mousedown.dismiss${hn}`,vn=`keydown.dismiss${hn}`,yn=`click${hn}.data-api`,wn=\"modal-open\",An=\"show\",En=\"modal-static\",Tn={backdrop:!0,focus:!0,keyboard:!0},Cn={backdrop:\"(boolean|string)\",focus:\"boolean\",keyboard:\"boolean\"};class On extends W{constructor(t,e){super(t,e),this._dialog=z.findOne(\".modal-dialog\",this._element),this._backdrop=this._initializeBackDrop(),this._focustrap=this._initializeFocusTrap(),this._isShown=!1,this._isTransitioning=!1,this._scrollBar=new cn,this._addEventListeners()}static get Default(){return Tn}static get DefaultType(){return Cn}static get NAME(){return\"modal\"}toggle(t){return this._isShown?this.hide():this.show(t)}show(t){this._isShown||this._isTransitioning||N.trigger(this._element,pn,{relatedTarget:t}).defaultPrevented||(this._isShown=!0,this._isTransitioning=!0,this._scrollBar.hide(),document.body.classList.add(wn),this._adjustDialog(),this._backdrop.show((()=>this._showElement(t))))}hide(){this._isShown&&!this._isTransitioning&&(N.trigger(this._element,dn).defaultPrevented||(this._isShown=!1,this._isTransitioning=!0,this._focustrap.deactivate(),this._element.classList.remove(An),this._queueCallback((()=>this._hideModal()),this._element,this._isAnimated())))}dispose(){N.off(window,hn),N.off(this._dialog,hn),this._backdrop.dispose(),this._focustrap.deactivate(),super.dispose()}handleUpdate(){this._adjustDialog()}_initializeBackDrop(){return new Ui({isVisible:Boolean(this._config.backdrop),isAnimated:this._isAnimated()})}_initializeFocusTrap(){return new sn({trapElement:this._element})}_showElement(t){document.body.contains(this._element)||document.body.append(this._element),this._element.style.display=\"block\",this._element.removeAttribute(\"aria-hidden\"),this._element.setAttribute(\"aria-modal\",!0),this._element.setAttribute(\"role\",\"dialog\"),this._element.scrollTop=0;const e=z.findOne(\".modal-body\",this._dialog);e&&(e.scrollTop=0),d(this._element),this._element.classList.add(An),this._queueCallback((()=>{this._config.focus&&this._focustrap.activate(),this._isTransitioning=!1,N.trigger(this._element,mn,{relatedTarget:t})}),this._dialog,this._isAnimated())}_addEventListeners(){N.on(this._element,vn,(t=>{\"Escape\"===t.key&&(this._config.keyboard?this.hide():this._triggerBackdropTransition())})),N.on(window,gn,(()=>{this._isShown&&!this._isTransitioning&&this._adjustDialog()})),N.on(this._element,bn,(t=>{N.one(this._element,_n,(e=>{this._element===t.target&&this._element===e.target&&(\"static\"!==this._config.backdrop?this._config.backdrop&&this.hide():this._triggerBackdropTransition())}))}))}_hideModal(){this._element.style.display=\"none\",this._element.setAttribute(\"aria-hidden\",!0),this._element.removeAttribute(\"aria-modal\"),this._element.removeAttribute(\"role\"),this._isTransitioning=!1,this._backdrop.hide((()=>{document.body.classList.remove(wn),this._resetAdjustments(),this._scrollBar.reset(),N.trigger(this._element,fn)}))}_isAnimated(){return this._element.classList.contains(\"fade\")}_triggerBackdropTransition(){if(N.trigger(this._element,un).defaultPrevented)return;const t=this._element.scrollHeight>document.documentElement.clientHeight,e=this._element.style.overflowY;\"hidden\"===e||this._element.classList.contains(En)||(t||(this._element.style.overflowY=\"hidden\"),this._element.classList.add(En),this._queueCallback((()=>{this._element.classList.remove(En),this._queueCallback((()=>{this._element.style.overflowY=e}),this._dialog)}),this._dialog),this._element.focus())}_adjustDialog(){const t=this._element.scrollHeight>document.documentElement.clientHeight,e=this._scrollBar.getWidth(),i=e>0;if(i&&!t){const t=p()?\"paddingLeft\":\"paddingRight\";this._element.style[t]=`${e}px`}if(!i&&t){const t=p()?\"paddingRight\":\"paddingLeft\";this._element.style[t]=`${e}px`}}_resetAdjustments(){this._element.style.paddingLeft=\"\",this._element.style.paddingRight=\"\"}static jQueryInterface(t,e){return this.each((function(){const i=On.getOrCreateInstance(this,t);if(\"string\"==typeof t){if(void 0===i[t])throw new TypeError(`No method named \"${t}\"`);i[t](e)}}))}}N.on(document,yn,'[data-bs-toggle=\"modal\"]',(function(t){const e=z.getElementFromSelector(this);[\"A\",\"AREA\"].includes(this.tagName)&&t.preventDefault(),N.one(e,pn,(t=>{t.defaultPrevented||N.one(e,fn,(()=>{a(this)&&this.focus()}))}));const i=z.findOne(\".modal.show\");i&&On.getInstance(i).hide(),On.getOrCreateInstance(e).toggle(this)})),R(On),m(On);const xn=\".bs.offcanvas\",kn=\".data-api\",Ln=`load${xn}${kn}`,Sn=\"show\",Dn=\"showing\",$n=\"hiding\",In=\".offcanvas.show\",Nn=`show${xn}`,Pn=`shown${xn}`,jn=`hide${xn}`,Mn=`hidePrevented${xn}`,Fn=`hidden${xn}`,Hn=`resize${xn}`,Wn=`click${xn}${kn}`,Bn=`keydown.dismiss${xn}`,zn={backdrop:!0,keyboard:!0,scroll:!1},Rn={backdrop:\"(boolean|string)\",keyboard:\"boolean\",scroll:\"boolean\"};class qn extends W{constructor(t,e){super(t,e),this._isShown=!1,this._backdrop=this._initializeBackDrop(),this._focustrap=this._initializeFocusTrap(),this._addEventListeners()}static get Default(){return zn}static get DefaultType(){return Rn}static get NAME(){return\"offcanvas\"}toggle(t){return this._isShown?this.hide():this.show(t)}show(t){this._isShown||N.trigger(this._element,Nn,{relatedTarget:t}).defaultPrevented||(this._isShown=!0,this._backdrop.show(),this._config.scroll||(new cn).hide(),this._element.setAttribute(\"aria-modal\",!0),this._element.setAttribute(\"role\",\"dialog\"),this._element.classList.add(Dn),this._queueCallback((()=>{this._config.scroll&&!this._config.backdrop||this._focustrap.activate(),this._element.classList.add(Sn),this._element.classList.remove(Dn),N.trigger(this._element,Pn,{relatedTarget:t})}),this._element,!0))}hide(){this._isShown&&(N.trigger(this._element,jn).defaultPrevented||(this._focustrap.deactivate(),this._element.blur(),this._isShown=!1,this._element.classList.add($n),this._backdrop.hide(),this._queueCallback((()=>{this._element.classList.remove(Sn,$n),this._element.removeAttribute(\"aria-modal\"),this._element.removeAttribute(\"role\"),this._config.scroll||(new cn).reset(),N.trigger(this._element,Fn)}),this._element,!0)))}dispose(){this._backdrop.dispose(),this._focustrap.deactivate(),super.dispose()}_initializeBackDrop(){const t=Boolean(this._config.backdrop);return new Ui({className:\"offcanvas-backdrop\",isVisible:t,isAnimated:!0,rootElement:this._element.parentNode,clickCallback:t?()=>{\"static\"!==this._config.backdrop?this.hide():N.trigger(this._element,Mn)}:null})}_initializeFocusTrap(){return new sn({trapElement:this._element})}_addEventListeners(){N.on(this._element,Bn,(t=>{\"Escape\"===t.key&&(this._config.keyboard?this.hide():N.trigger(this._element,Mn))}))}static jQueryInterface(t){return this.each((function(){const e=qn.getOrCreateInstance(this,t);if(\"string\"==typeof t){if(void 0===e[t]||t.startsWith(\"_\")||\"constructor\"===t)throw new TypeError(`No method named \"${t}\"`);e[t](this)}}))}}N.on(document,Wn,'[data-bs-toggle=\"offcanvas\"]',(function(t){const e=z.getElementFromSelector(this);if([\"A\",\"AREA\"].includes(this.tagName)&&t.preventDefault(),l(this))return;N.one(e,Fn,(()=>{a(this)&&this.focus()}));const i=z.findOne(In);i&&i!==e&&qn.getInstance(i).hide(),qn.getOrCreateInstance(e).toggle(this)})),N.on(window,Ln,(()=>{for(const t of z.find(In))qn.getOrCreateInstance(t).show()})),N.on(window,Hn,(()=>{for(const t of z.find(\"[aria-modal][class*=show][class*=offcanvas-]\"))\"fixed\"!==getComputedStyle(t).position&&qn.getOrCreateInstance(t).hide()})),R(qn),m(qn);const Vn={\"*\":[\"class\",\"dir\",\"id\",\"lang\",\"role\",/^aria-[\\w-]*$/i],a:[\"target\",\"href\",\"title\",\"rel\"],area:[],b:[],br:[],col:[],code:[],dd:[],div:[],dl:[],dt:[],em:[],hr:[],h1:[],h2:[],h3:[],h4:[],h5:[],h6:[],i:[],img:[\"src\",\"srcset\",\"alt\",\"title\",\"width\",\"height\"],li:[],ol:[],p:[],pre:[],s:[],small:[],span:[],sub:[],sup:[],strong:[],u:[],ul:[]},Kn=new Set([\"background\",\"cite\",\"href\",\"itemtype\",\"longdesc\",\"poster\",\"src\",\"xlink:href\"]),Qn=/^(?!javascript:)(?:[a-z0-9+.-]+:|[^&:/?#]*(?:[/?#]|$))/i,Xn=(t,e)=>{const i=t.nodeName.toLowerCase();return e.includes(i)?!Kn.has(i)||Boolean(Qn.test(t.nodeValue)):e.filter((t=>t instanceof RegExp)).some((t=>t.test(i)))},Yn={allowList:Vn,content:{},extraClass:\"\",html:!1,sanitize:!0,sanitizeFn:null,template:\"<div></div>\"},Un={allowList:\"object\",content:\"object\",extraClass:\"(string|function)\",html:\"boolean\",sanitize:\"boolean\",sanitizeFn:\"(null|function)\",template:\"string\"},Gn={entry:\"(string|element|function|null)\",selector:\"(string|element)\"};class Jn extends H{constructor(t){super(),this._config=this._getConfig(t)}static get Default(){return Yn}static get DefaultType(){return Un}static get NAME(){return\"TemplateFactory\"}getContent(){return Object.values(this._config.content).map((t=>this._resolvePossibleFunction(t))).filter(Boolean)}hasContent(){return this.getContent().length>0}changeContent(t){return this._checkContent(t),this._config.content={...this._config.content,...t},this}toHtml(){const t=document.createElement(\"div\");t.innerHTML=this._maybeSanitize(this._config.template);for(const[e,i]of Object.entries(this._config.content))this._setContent(t,i,e);const e=t.children[0],i=this._resolvePossibleFunction(this._config.extraClass);return i&&e.classList.add(...i.split(\" \")),e}_typeCheckConfig(t){super._typeCheckConfig(t),this._checkContent(t.content)}_checkContent(t){for(const[e,i]of Object.entries(t))super._typeCheckConfig({selector:e,entry:i},Gn)}_setContent(t,e,i){const n=z.findOne(i,t);n&&((e=this._resolvePossibleFunction(e))?o(e)?this._putElementInTemplate(r(e),n):this._config.html?n.innerHTML=this._maybeSanitize(e):n.textContent=e:n.remove())}_maybeSanitize(t){return this._config.sanitize?function(t,e,i){if(!t.length)return t;if(i&&\"function\"==typeof i)return i(t);const n=(new window.DOMParser).parseFromString(t,\"text/html\"),s=[].concat(...n.body.querySelectorAll(\"*\"));for(const t of s){const i=t.nodeName.toLowerCase();if(!Object.keys(e).includes(i)){t.remove();continue}const n=[].concat(...t.attributes),s=[].concat(e[\"*\"]||[],e[i]||[]);for(const e of n)Xn(e,s)||t.removeAttribute(e.nodeName)}return n.body.innerHTML}(t,this._config.allowList,this._config.sanitizeFn):t}_resolvePossibleFunction(t){return g(t,[this])}_putElementInTemplate(t,e){if(this._config.html)return e.innerHTML=\"\",void e.append(t);e.textContent=t.textContent}}const Zn=new Set([\"sanitize\",\"allowList\",\"sanitizeFn\"]),ts=\"fade\",es=\"show\",is=\".modal\",ns=\"hide.bs.modal\",ss=\"hover\",os=\"focus\",rs={AUTO:\"auto\",TOP:\"top\",RIGHT:p()?\"left\":\"right\",BOTTOM:\"bottom\",LEFT:p()?\"right\":\"left\"},as={allowList:Vn,animation:!0,boundary:\"clippingParents\",container:!1,customClass:\"\",delay:0,fallbackPlacements:[\"top\",\"right\",\"bottom\",\"left\"],html:!1,offset:[0,6],placement:\"top\",popperConfig:null,sanitize:!0,sanitizeFn:null,selector:!1,template:'<div class=\"tooltip\" role=\"tooltip\"><div class=\"tooltip-arrow\"></div><div class=\"tooltip-inner\"></div></div>',title:\"\",trigger:\"hover focus\"},ls={allowList:\"object\",animation:\"boolean\",boundary:\"(string|element)\",container:\"(string|element|boolean)\",customClass:\"(string|function)\",delay:\"(number|object)\",fallbackPlacements:\"array\",html:\"boolean\",offset:\"(array|string|function)\",placement:\"(string|function)\",popperConfig:\"(null|object|function)\",sanitize:\"boolean\",sanitizeFn:\"(null|function)\",selector:\"(string|boolean)\",template:\"string\",title:\"(string|element|function)\",trigger:\"string\"};class cs extends W{constructor(t,e){if(void 0===vi)throw new TypeError(\"Bootstrap's tooltips require Popper (https://popper.js.org)\");super(t,e),this._isEnabled=!0,this._timeout=0,this._isHovered=null,this._activeTrigger={},this._popper=null,this._templateFactory=null,this._newContent=null,this.tip=null,this._setListeners(),this._config.selector||this._fixTitle()}static get Default(){return as}static get DefaultType(){return ls}static get NAME(){return\"tooltip\"}enable(){this._isEnabled=!0}disable(){this._isEnabled=!1}toggleEnabled(){this._isEnabled=!this._isEnabled}toggle(){this._isEnabled&&(this._activeTrigger.click=!this._activeTrigger.click,this._isShown()?this._leave():this._enter())}dispose(){clearTimeout(this._timeout),N.off(this._element.closest(is),ns,this._hideModalHandler),this._element.getAttribute(\"data-bs-original-title\")&&this._element.setAttribute(\"title\",this._element.getAttribute(\"data-bs-original-title\")),this._disposePopper(),super.dispose()}show(){if(\"none\"===this._element.style.display)throw new Error(\"Please use show on visible elements\");if(!this._isWithContent()||!this._isEnabled)return;const t=N.trigger(this._element,this.constructor.eventName(\"show\")),e=(c(this._element)||this._element.ownerDocument.documentElement).contains(this._element);if(t.defaultPrevented||!e)return;this._disposePopper();const i=this._getTipElement();this._element.setAttribute(\"aria-describedby\",i.getAttribute(\"id\"));const{container:n}=this._config;if(this._element.ownerDocument.documentElement.contains(this.tip)||(n.append(i),N.trigger(this._element,this.constructor.eventName(\"inserted\"))),this._popper=this._createPopper(i),i.classList.add(es),\"ontouchstart\"in document.documentElement)for(const t of[].concat(...document.body.children))N.on(t,\"mouseover\",h);this._queueCallback((()=>{N.trigger(this._element,this.constructor.eventName(\"shown\")),!1===this._isHovered&&this._leave(),this._isHovered=!1}),this.tip,this._isAnimated())}hide(){if(this._isShown()&&!N.trigger(this._element,this.constructor.eventName(\"hide\")).defaultPrevented){if(this._getTipElement().classList.remove(es),\"ontouchstart\"in document.documentElement)for(const t of[].concat(...document.body.children))N.off(t,\"mouseover\",h);this._activeTrigger.click=!1,this._activeTrigger[os]=!1,this._activeTrigger[ss]=!1,this._isHovered=null,this._queueCallback((()=>{this._isWithActiveTrigger()||(this._isHovered||this._disposePopper(),this._element.removeAttribute(\"aria-describedby\"),N.trigger(this._element,this.constructor.eventName(\"hidden\")))}),this.tip,this._isAnimated())}}update(){this._popper&&this._popper.update()}_isWithContent(){return Boolean(this._getTitle())}_getTipElement(){return this.tip||(this.tip=this._createTipElement(this._newContent||this._getContentForTemplate())),this.tip}_createTipElement(t){const e=this._getTemplateFactory(t).toHtml();if(!e)return null;e.classList.remove(ts,es),e.classList.add(`bs-${this.constructor.NAME}-auto`);const i=(t=>{do{t+=Math.floor(1e6*Math.random())}while(document.getElementById(t));return t})(this.constructor.NAME).toString();return e.setAttribute(\"id\",i),this._isAnimated()&&e.classList.add(ts),e}setContent(t){this._newContent=t,this._isShown()&&(this._disposePopper(),this.show())}_getTemplateFactory(t){return this._templateFactory?this._templateFactory.changeContent(t):this._templateFactory=new Jn({...this._config,content:t,extraClass:this._resolvePossibleFunction(this._config.customClass)}),this._templateFactory}_getContentForTemplate(){return{\".tooltip-inner\":this._getTitle()}}_getTitle(){return this._resolvePossibleFunction(this._config.title)||this._element.getAttribute(\"data-bs-original-title\")}_initializeOnDelegatedTarget(t){return this.constructor.getOrCreateInstance(t.delegateTarget,this._getDelegateConfig())}_isAnimated(){return this._config.animation||this.tip&&this.tip.classList.contains(ts)}_isShown(){return this.tip&&this.tip.classList.contains(es)}_createPopper(t){const e=g(this._config.placement,[this,t,this._element]),i=rs[e.toUpperCase()];return bi(this._element,t,this._getPopperConfig(i))}_getOffset(){const{offset:t}=this._config;return\"string\"==typeof t?t.split(\",\").map((t=>Number.parseInt(t,10))):\"function\"==typeof t?e=>t(e,this._element):t}_resolvePossibleFunction(t){return g(t,[this._element])}_getPopperConfig(t){const e={placement:t,modifiers:[{name:\"flip\",options:{fallbackPlacements:this._config.fallbackPlacements}},{name:\"offset\",options:{offset:this._getOffset()}},{name:\"preventOverflow\",options:{boundary:this._config.boundary}},{name:\"arrow\",options:{element:`.${this.constructor.NAME}-arrow`}},{name:\"preSetPlacement\",enabled:!0,phase:\"beforeMain\",fn:t=>{this._getTipElement().setAttribute(\"data-popper-placement\",t.state.placement)}}]};return{...e,...g(this._config.popperConfig,[e])}}_setListeners(){const t=this._config.trigger.split(\" \");for(const e of t)if(\"click\"===e)N.on(this._element,this.constructor.eventName(\"click\"),this._config.selector,(t=>{this._initializeOnDelegatedTarget(t).toggle()}));else if(\"manual\"!==e){const t=e===ss?this.constructor.eventName(\"mouseenter\"):this.constructor.eventName(\"focusin\"),i=e===ss?this.constructor.eventName(\"mouseleave\"):this.constructor.eventName(\"focusout\");N.on(this._element,t,this._config.selector,(t=>{const e=this._initializeOnDelegatedTarget(t);e._activeTrigger[\"focusin\"===t.type?os:ss]=!0,e._enter()})),N.on(this._element,i,this._config.selector,(t=>{const e=this._initializeOnDelegatedTarget(t);e._activeTrigger[\"focusout\"===t.type?os:ss]=e._element.contains(t.relatedTarget),e._leave()}))}this._hideModalHandler=()=>{this._element&&this.hide()},N.on(this._element.closest(is),ns,this._hideModalHandler)}_fixTitle(){const t=this._element.getAttribute(\"title\");t&&(this._element.getAttribute(\"aria-label\")||this._element.textContent.trim()||this._element.setAttribute(\"aria-label\",t),this._element.setAttribute(\"data-bs-original-title\",t),this._element.removeAttribute(\"title\"))}_enter(){this._isShown()||this._isHovered?this._isHovered=!0:(this._isHovered=!0,this._setTimeout((()=>{this._isHovered&&this.show()}),this._config.delay.show))}_leave(){this._isWithActiveTrigger()||(this._isHovered=!1,this._setTimeout((()=>{this._isHovered||this.hide()}),this._config.delay.hide))}_setTimeout(t,e){clearTimeout(this._timeout),this._timeout=setTimeout(t,e)}_isWithActiveTrigger(){return Object.values(this._activeTrigger).includes(!0)}_getConfig(t){const e=F.getDataAttributes(this._element);for(const t of Object.keys(e))Zn.has(t)&&delete e[t];return t={...e,...\"object\"==typeof t&&t?t:{}},t=this._mergeConfigObj(t),t=this._configAfterMerge(t),this._typeCheckConfig(t),t}_configAfterMerge(t){return t.container=!1===t.container?document.body:r(t.container),\"number\"==typeof t.delay&&(t.delay={show:t.delay,hide:t.delay}),\"number\"==typeof t.title&&(t.title=t.title.toString()),\"number\"==typeof t.content&&(t.content=t.content.toString()),t}_getDelegateConfig(){const t={};for(const[e,i]of Object.entries(this._config))this.constructor.Default[e]!==i&&(t[e]=i);return t.selector=!1,t.trigger=\"manual\",t}_disposePopper(){this._popper&&(this._popper.destroy(),this._popper=null),this.tip&&(this.tip.remove(),this.tip=null)}static jQueryInterface(t){return this.each((function(){const e=cs.getOrCreateInstance(this,t);if(\"string\"==typeof t){if(void 0===e[t])throw new TypeError(`No method named \"${t}\"`);e[t]()}}))}}m(cs);const hs={...cs.Default,content:\"\",offset:[0,8],placement:\"right\",template:'<div class=\"popover\" role=\"tooltip\"><div class=\"popover-arrow\"></div><h3 class=\"popover-header\"></h3><div class=\"popover-body\"></div></div>',trigger:\"click\"},ds={...cs.DefaultType,content:\"(null|string|element|function)\"};class us extends cs{static get Default(){return hs}static get DefaultType(){return ds}static get NAME(){return\"popover\"}_isWithContent(){return this._getTitle()||this._getContent()}_getContentForTemplate(){return{\".popover-header\":this._getTitle(),\".popover-body\":this._getContent()}}_getContent(){return this._resolvePossibleFunction(this._config.content)}static jQueryInterface(t){return this.each((function(){const e=us.getOrCreateInstance(this,t);if(\"string\"==typeof t){if(void 0===e[t])throw new TypeError(`No method named \"${t}\"`);e[t]()}}))}}m(us);const fs=\".bs.scrollspy\",ps=`activate${fs}`,ms=`click${fs}`,gs=`load${fs}.data-api`,_s=\"active\",bs=\"[href]\",vs=\".nav-link\",ys=`${vs}, .nav-item > ${vs}, .list-group-item`,ws={offset:null,rootMargin:\"0px 0px -25%\",smoothScroll:!1,target:null,threshold:[.1,.5,1]},As={offset:\"(number|null)\",rootMargin:\"string\",smoothScroll:\"boolean\",target:\"element\",threshold:\"array\"};class Es extends W{constructor(t,e){super(t,e),this._targetLinks=new Map,this._observableSections=new Map,this._rootElement=\"visible\"===getComputedStyle(this._element).overflowY?null:this._element,this._activeTarget=null,this._observer=null,this._previousScrollData={visibleEntryTop:0,parentScrollTop:0},this.refresh()}static get Default(){return ws}static get DefaultType(){return As}static get NAME(){return\"scrollspy\"}refresh(){this._initializeTargetsAndObservables(),this._maybeEnableSmoothScroll(),this._observer?this._observer.disconnect():this._observer=this._getNewObserver();for(const t of this._observableSections.values())this._observer.observe(t)}dispose(){this._observer.disconnect(),super.dispose()}_configAfterMerge(t){return t.target=r(t.target)||document.body,t.rootMargin=t.offset?`${t.offset}px 0px -30%`:t.rootMargin,\"string\"==typeof t.threshold&&(t.threshold=t.threshold.split(\",\").map((t=>Number.parseFloat(t)))),t}_maybeEnableSmoothScroll(){this._config.smoothScroll&&(N.off(this._config.target,ms),N.on(this._config.target,ms,bs,(t=>{const e=this._observableSections.get(t.target.hash);if(e){t.preventDefault();const i=this._rootElement||window,n=e.offsetTop-this._element.offsetTop;if(i.scrollTo)return void i.scrollTo({top:n,behavior:\"smooth\"});i.scrollTop=n}})))}_getNewObserver(){const t={root:this._rootElement,threshold:this._config.threshold,rootMargin:this._config.rootMargin};return new IntersectionObserver((t=>this._observerCallback(t)),t)}_observerCallback(t){const e=t=>this._targetLinks.get(`#${t.target.id}`),i=t=>{this._previousScrollData.visibleEntryTop=t.target.offsetTop,this._process(e(t))},n=(this._rootElement||document.documentElement).scrollTop,s=n>=this._previousScrollData.parentScrollTop;this._previousScrollData.parentScrollTop=n;for(const o of t){if(!o.isIntersecting){this._activeTarget=null,this._clearActiveClass(e(o));continue}const t=o.target.offsetTop>=this._previousScrollData.visibleEntryTop;if(s&&t){if(i(o),!n)return}else s||t||i(o)}}_initializeTargetsAndObservables(){this._targetLinks=new Map,this._observableSections=new Map;const t=z.find(bs,this._config.target);for(const e of t){if(!e.hash||l(e))continue;const t=z.findOne(decodeURI(e.hash),this._element);a(t)&&(this._targetLinks.set(decodeURI(e.hash),e),this._observableSections.set(e.hash,t))}}_process(t){this._activeTarget!==t&&(this._clearActiveClass(this._config.target),this._activeTarget=t,t.classList.add(_s),this._activateParents(t),N.trigger(this._element,ps,{relatedTarget:t}))}_activateParents(t){if(t.classList.contains(\"dropdown-item\"))z.findOne(\".dropdown-toggle\",t.closest(\".dropdown\")).classList.add(_s);else for(const e of z.parents(t,\".nav, .list-group\"))for(const t of z.prev(e,ys))t.classList.add(_s)}_clearActiveClass(t){t.classList.remove(_s);const e=z.find(`${bs}.${_s}`,t);for(const t of e)t.classList.remove(_s)}static jQueryInterface(t){return this.each((function(){const e=Es.getOrCreateInstance(this,t);if(\"string\"==typeof t){if(void 0===e[t]||t.startsWith(\"_\")||\"constructor\"===t)throw new TypeError(`No method named \"${t}\"`);e[t]()}}))}}N.on(window,gs,(()=>{for(const t of z.find('[data-bs-spy=\"scroll\"]'))Es.getOrCreateInstance(t)})),m(Es);const Ts=\".bs.tab\",Cs=`hide${Ts}`,Os=`hidden${Ts}`,xs=`show${Ts}`,ks=`shown${Ts}`,Ls=`click${Ts}`,Ss=`keydown${Ts}`,Ds=`load${Ts}`,$s=\"ArrowLeft\",Is=\"ArrowRight\",Ns=\"ArrowUp\",Ps=\"ArrowDown\",js=\"Home\",Ms=\"End\",Fs=\"active\",Hs=\"fade\",Ws=\"show\",Bs=\".dropdown-toggle\",zs=`:not(${Bs})`,Rs='[data-bs-toggle=\"tab\"], [data-bs-toggle=\"pill\"], [data-bs-toggle=\"list\"]',qs=`.nav-link${zs}, .list-group-item${zs}, [role=\"tab\"]${zs}, ${Rs}`,Vs=`.${Fs}[data-bs-toggle=\"tab\"], .${Fs}[data-bs-toggle=\"pill\"], .${Fs}[data-bs-toggle=\"list\"]`;class Ks extends W{constructor(t){super(t),this._parent=this._element.closest('.list-group, .nav, [role=\"tablist\"]'),this._parent&&(this._setInitialAttributes(this._parent,this._getChildren()),N.on(this._element,Ss,(t=>this._keydown(t))))}static get NAME(){return\"tab\"}show(){const t=this._element;if(this._elemIsActive(t))return;const e=this._getActiveElem(),i=e?N.trigger(e,Cs,{relatedTarget:t}):null;N.trigger(t,xs,{relatedTarget:e}).defaultPrevented||i&&i.defaultPrevented||(this._deactivate(e,t),this._activate(t,e))}_activate(t,e){t&&(t.classList.add(Fs),this._activate(z.getElementFromSelector(t)),this._queueCallback((()=>{\"tab\"===t.getAttribute(\"role\")?(t.removeAttribute(\"tabindex\"),t.setAttribute(\"aria-selected\",!0),this._toggleDropDown(t,!0),N.trigger(t,ks,{relatedTarget:e})):t.classList.add(Ws)}),t,t.classList.contains(Hs)))}_deactivate(t,e){t&&(t.classList.remove(Fs),t.blur(),this._deactivate(z.getElementFromSelector(t)),this._queueCallback((()=>{\"tab\"===t.getAttribute(\"role\")?(t.setAttribute(\"aria-selected\",!1),t.setAttribute(\"tabindex\",\"-1\"),this._toggleDropDown(t,!1),N.trigger(t,Os,{relatedTarget:e})):t.classList.remove(Ws)}),t,t.classList.contains(Hs)))}_keydown(t){if(![$s,Is,Ns,Ps,js,Ms].includes(t.key))return;t.stopPropagation(),t.preventDefault();const e=this._getChildren().filter((t=>!l(t)));let i;if([js,Ms].includes(t.key))i=e[t.key===js?0:e.length-1];else{const n=[Is,Ps].includes(t.key);i=b(e,t.target,n,!0)}i&&(i.focus({preventScroll:!0}),Ks.getOrCreateInstance(i).show())}_getChildren(){return z.find(qs,this._parent)}_getActiveElem(){return this._getChildren().find((t=>this._elemIsActive(t)))||null}_setInitialAttributes(t,e){this._setAttributeIfNotExists(t,\"role\",\"tablist\");for(const t of e)this._setInitialAttributesOnChild(t)}_setInitialAttributesOnChild(t){t=this._getInnerElement(t);const e=this._elemIsActive(t),i=this._getOuterElement(t);t.setAttribute(\"aria-selected\",e),i!==t&&this._setAttributeIfNotExists(i,\"role\",\"presentation\"),e||t.setAttribute(\"tabindex\",\"-1\"),this._setAttributeIfNotExists(t,\"role\",\"tab\"),this._setInitialAttributesOnTargetPanel(t)}_setInitialAttributesOnTargetPanel(t){const e=z.getElementFromSelector(t);e&&(this._setAttributeIfNotExists(e,\"role\",\"tabpanel\"),t.id&&this._setAttributeIfNotExists(e,\"aria-labelledby\",`${t.id}`))}_toggleDropDown(t,e){const i=this._getOuterElement(t);if(!i.classList.contains(\"dropdown\"))return;const n=(t,n)=>{const s=z.findOne(t,i);s&&s.classList.toggle(n,e)};n(Bs,Fs),n(\".dropdown-menu\",Ws),i.setAttribute(\"aria-expanded\",e)}_setAttributeIfNotExists(t,e,i){t.hasAttribute(e)||t.setAttribute(e,i)}_elemIsActive(t){return t.classList.contains(Fs)}_getInnerElement(t){return t.matches(qs)?t:z.findOne(qs,t)}_getOuterElement(t){return t.closest(\".nav-item, .list-group-item\")||t}static jQueryInterface(t){return this.each((function(){const e=Ks.getOrCreateInstance(this);if(\"string\"==typeof t){if(void 0===e[t]||t.startsWith(\"_\")||\"constructor\"===t)throw new TypeError(`No method named \"${t}\"`);e[t]()}}))}}N.on(document,Ls,Rs,(function(t){[\"A\",\"AREA\"].includes(this.tagName)&&t.preventDefault(),l(this)||Ks.getOrCreateInstance(this).show()})),N.on(window,Ds,(()=>{for(const t of z.find(Vs))Ks.getOrCreateInstance(t)})),m(Ks);const Qs=\".bs.toast\",Xs=`mouseover${Qs}`,Ys=`mouseout${Qs}`,Us=`focusin${Qs}`,Gs=`focusout${Qs}`,Js=`hide${Qs}`,Zs=`hidden${Qs}`,to=`show${Qs}`,eo=`shown${Qs}`,io=\"hide\",no=\"show\",so=\"showing\",oo={animation:\"boolean\",autohide:\"boolean\",delay:\"number\"},ro={animation:!0,autohide:!0,delay:5e3};class ao extends W{constructor(t,e){super(t,e),this._timeout=null,this._hasMouseInteraction=!1,this._hasKeyboardInteraction=!1,this._setListeners()}static get Default(){return ro}static get DefaultType(){return oo}static get NAME(){return\"toast\"}show(){N.trigger(this._element,to).defaultPrevented||(this._clearTimeout(),this._config.animation&&this._element.classList.add(\"fade\"),this._element.classList.remove(io),d(this._element),this._element.classList.add(no,so),this._queueCallback((()=>{this._element.classList.remove(so),N.trigger(this._element,eo),this._maybeScheduleHide()}),this._element,this._config.animation))}hide(){this.isShown()&&(N.trigger(this._element,Js).defaultPrevented||(this._element.classList.add(so),this._queueCallback((()=>{this._element.classList.add(io),this._element.classList.remove(so,no),N.trigger(this._element,Zs)}),this._element,this._config.animation)))}dispose(){this._clearTimeout(),this.isShown()&&this._element.classList.remove(no),super.dispose()}isShown(){return this._element.classList.contains(no)}_maybeScheduleHide(){this._config.autohide&&(this._hasMouseInteraction||this._hasKeyboardInteraction||(this._timeout=setTimeout((()=>{this.hide()}),this._config.delay)))}_onInteraction(t,e){switch(t.type){case\"mouseover\":case\"mouseout\":this._hasMouseInteraction=e;break;case\"focusin\":case\"focusout\":this._hasKeyboardInteraction=e}if(e)return void this._clearTimeout();const i=t.relatedTarget;this._element===i||this._element.contains(i)||this._maybeScheduleHide()}_setListeners(){N.on(this._element,Xs,(t=>this._onInteraction(t,!0))),N.on(this._element,Ys,(t=>this._onInteraction(t,!1))),N.on(this._element,Us,(t=>this._onInteraction(t,!0))),N.on(this._element,Gs,(t=>this._onInteraction(t,!1)))}_clearTimeout(){clearTimeout(this._timeout),this._timeout=null}static jQueryInterface(t){return this.each((function(){const e=ao.getOrCreateInstance(this,t);if(\"string\"==typeof t){if(void 0===e[t])throw new TypeError(`No method named \"${t}\"`);e[t](this)}}))}}return R(ao),m(ao),{Alert:Q,Button:Y,Carousel:xt,Collapse:Bt,Dropdown:qi,Modal:On,Offcanvas:qn,Popover:us,ScrollSpy:Es,Tab:Ks,Toast:ao,Tooltip:cs}}));\n//# sourceMappingURL=bootstrap.bundle.min.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/bootstrap/dist/js/bootstrap.bundle.min.js?");

/***/ }),

/***/ "./node_modules/codemirror/addon/search/searchcursor.js":
/*!**************************************************************!*\
  !*** ./node_modules/codemirror/addon/search/searchcursor.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __unused_webpack_exports, __webpack_require__) => {

eval("// CodeMirror, copyright (c) by Marijn Haverbeke and others\n// Distributed under an MIT license: https://codemirror.net/5/LICENSE\n\n(function(mod) {\n  if (true) // CommonJS\n    mod(__webpack_require__(/*! ../../lib/codemirror */ \"./node_modules/codemirror/lib/codemirror.js\"))\n  else {}\n})(function(CodeMirror) {\n  \"use strict\"\n  var Pos = CodeMirror.Pos\n\n  function regexpFlags(regexp) {\n    var flags = regexp.flags\n    return flags != null ? flags : (regexp.ignoreCase ? \"i\" : \"\")\n      + (regexp.global ? \"g\" : \"\")\n      + (regexp.multiline ? \"m\" : \"\")\n  }\n\n  function ensureFlags(regexp, flags) {\n    var current = regexpFlags(regexp), target = current\n    for (var i = 0; i < flags.length; i++) if (target.indexOf(flags.charAt(i)) == -1)\n      target += flags.charAt(i)\n    return current == target ? regexp : new RegExp(regexp.source, target)\n  }\n\n  function maybeMultiline(regexp) {\n    return /\\\\s|\\\\n|\\n|\\\\W|\\\\D|\\[\\^/.test(regexp.source)\n  }\n\n  function searchRegexpForward(doc, regexp, start) {\n    regexp = ensureFlags(regexp, \"g\")\n    for (var line = start.line, ch = start.ch, last = doc.lastLine(); line <= last; line++, ch = 0) {\n      regexp.lastIndex = ch\n      var string = doc.getLine(line), match = regexp.exec(string)\n      if (match)\n        return {from: Pos(line, match.index),\n                to: Pos(line, match.index + match[0].length),\n                match: match}\n    }\n  }\n\n  function searchRegexpForwardMultiline(doc, regexp, start) {\n    if (!maybeMultiline(regexp)) return searchRegexpForward(doc, regexp, start)\n\n    regexp = ensureFlags(regexp, \"gm\")\n    var string, chunk = 1\n    for (var line = start.line, last = doc.lastLine(); line <= last;) {\n      // This grows the search buffer in exponentially-sized chunks\n      // between matches, so that nearby matches are fast and don't\n      // require concatenating the whole document (in case we're\n      // searching for something that has tons of matches), but at the\n      // same time, the amount of retries is limited.\n      for (var i = 0; i < chunk; i++) {\n        if (line > last) break\n        var curLine = doc.getLine(line++)\n        string = string == null ? curLine : string + \"\\n\" + curLine\n      }\n      chunk = chunk * 2\n      regexp.lastIndex = start.ch\n      var match = regexp.exec(string)\n      if (match) {\n        var before = string.slice(0, match.index).split(\"\\n\"), inside = match[0].split(\"\\n\")\n        var startLine = start.line + before.length - 1, startCh = before[before.length - 1].length\n        return {from: Pos(startLine, startCh),\n                to: Pos(startLine + inside.length - 1,\n                        inside.length == 1 ? startCh + inside[0].length : inside[inside.length - 1].length),\n                match: match}\n      }\n    }\n  }\n\n  function lastMatchIn(string, regexp, endMargin) {\n    var match, from = 0\n    while (from <= string.length) {\n      regexp.lastIndex = from\n      var newMatch = regexp.exec(string)\n      if (!newMatch) break\n      var end = newMatch.index + newMatch[0].length\n      if (end > string.length - endMargin) break\n      if (!match || end > match.index + match[0].length)\n        match = newMatch\n      from = newMatch.index + 1\n    }\n    return match\n  }\n\n  function searchRegexpBackward(doc, regexp, start) {\n    regexp = ensureFlags(regexp, \"g\")\n    for (var line = start.line, ch = start.ch, first = doc.firstLine(); line >= first; line--, ch = -1) {\n      var string = doc.getLine(line)\n      var match = lastMatchIn(string, regexp, ch < 0 ? 0 : string.length - ch)\n      if (match)\n        return {from: Pos(line, match.index),\n                to: Pos(line, match.index + match[0].length),\n                match: match}\n    }\n  }\n\n  function searchRegexpBackwardMultiline(doc, regexp, start) {\n    if (!maybeMultiline(regexp)) return searchRegexpBackward(doc, regexp, start)\n    regexp = ensureFlags(regexp, \"gm\")\n    var string, chunkSize = 1, endMargin = doc.getLine(start.line).length - start.ch\n    for (var line = start.line, first = doc.firstLine(); line >= first;) {\n      for (var i = 0; i < chunkSize && line >= first; i++) {\n        var curLine = doc.getLine(line--)\n        string = string == null ? curLine : curLine + \"\\n\" + string\n      }\n      chunkSize *= 2\n\n      var match = lastMatchIn(string, regexp, endMargin)\n      if (match) {\n        var before = string.slice(0, match.index).split(\"\\n\"), inside = match[0].split(\"\\n\")\n        var startLine = line + before.length, startCh = before[before.length - 1].length\n        return {from: Pos(startLine, startCh),\n                to: Pos(startLine + inside.length - 1,\n                        inside.length == 1 ? startCh + inside[0].length : inside[inside.length - 1].length),\n                match: match}\n      }\n    }\n  }\n\n  var doFold, noFold\n  if (String.prototype.normalize) {\n    doFold = function(str) { return str.normalize(\"NFD\").toLowerCase() }\n    noFold = function(str) { return str.normalize(\"NFD\") }\n  } else {\n    doFold = function(str) { return str.toLowerCase() }\n    noFold = function(str) { return str }\n  }\n\n  // Maps a position in a case-folded line back to a position in the original line\n  // (compensating for codepoints increasing in number during folding)\n  function adjustPos(orig, folded, pos, foldFunc) {\n    if (orig.length == folded.length) return pos\n    for (var min = 0, max = pos + Math.max(0, orig.length - folded.length);;) {\n      if (min == max) return min\n      var mid = (min + max) >> 1\n      var len = foldFunc(orig.slice(0, mid)).length\n      if (len == pos) return mid\n      else if (len > pos) max = mid\n      else min = mid + 1\n    }\n  }\n\n  function searchStringForward(doc, query, start, caseFold) {\n    // Empty string would match anything and never progress, so we\n    // define it to match nothing instead.\n    if (!query.length) return null\n    var fold = caseFold ? doFold : noFold\n    var lines = fold(query).split(/\\r|\\n\\r?/)\n\n    search: for (var line = start.line, ch = start.ch, last = doc.lastLine() + 1 - lines.length; line <= last; line++, ch = 0) {\n      var orig = doc.getLine(line).slice(ch), string = fold(orig)\n      if (lines.length == 1) {\n        var found = string.indexOf(lines[0])\n        if (found == -1) continue search\n        var start = adjustPos(orig, string, found, fold) + ch\n        return {from: Pos(line, adjustPos(orig, string, found, fold) + ch),\n                to: Pos(line, adjustPos(orig, string, found + lines[0].length, fold) + ch)}\n      } else {\n        var cutFrom = string.length - lines[0].length\n        if (string.slice(cutFrom) != lines[0]) continue search\n        for (var i = 1; i < lines.length - 1; i++)\n          if (fold(doc.getLine(line + i)) != lines[i]) continue search\n        var end = doc.getLine(line + lines.length - 1), endString = fold(end), lastLine = lines[lines.length - 1]\n        if (endString.slice(0, lastLine.length) != lastLine) continue search\n        return {from: Pos(line, adjustPos(orig, string, cutFrom, fold) + ch),\n                to: Pos(line + lines.length - 1, adjustPos(end, endString, lastLine.length, fold))}\n      }\n    }\n  }\n\n  function searchStringBackward(doc, query, start, caseFold) {\n    if (!query.length) return null\n    var fold = caseFold ? doFold : noFold\n    var lines = fold(query).split(/\\r|\\n\\r?/)\n\n    search: for (var line = start.line, ch = start.ch, first = doc.firstLine() - 1 + lines.length; line >= first; line--, ch = -1) {\n      var orig = doc.getLine(line)\n      if (ch > -1) orig = orig.slice(0, ch)\n      var string = fold(orig)\n      if (lines.length == 1) {\n        var found = string.lastIndexOf(lines[0])\n        if (found == -1) continue search\n        return {from: Pos(line, adjustPos(orig, string, found, fold)),\n                to: Pos(line, adjustPos(orig, string, found + lines[0].length, fold))}\n      } else {\n        var lastLine = lines[lines.length - 1]\n        if (string.slice(0, lastLine.length) != lastLine) continue search\n        for (var i = 1, start = line - lines.length + 1; i < lines.length - 1; i++)\n          if (fold(doc.getLine(start + i)) != lines[i]) continue search\n        var top = doc.getLine(line + 1 - lines.length), topString = fold(top)\n        if (topString.slice(topString.length - lines[0].length) != lines[0]) continue search\n        return {from: Pos(line + 1 - lines.length, adjustPos(top, topString, top.length - lines[0].length, fold)),\n                to: Pos(line, adjustPos(orig, string, lastLine.length, fold))}\n      }\n    }\n  }\n\n  function SearchCursor(doc, query, pos, options) {\n    this.atOccurrence = false\n    this.afterEmptyMatch = false\n    this.doc = doc\n    pos = pos ? doc.clipPos(pos) : Pos(0, 0)\n    this.pos = {from: pos, to: pos}\n\n    var caseFold\n    if (typeof options == \"object\") {\n      caseFold = options.caseFold\n    } else { // Backwards compat for when caseFold was the 4th argument\n      caseFold = options\n      options = null\n    }\n\n    if (typeof query == \"string\") {\n      if (caseFold == null) caseFold = false\n      this.matches = function(reverse, pos) {\n        return (reverse ? searchStringBackward : searchStringForward)(doc, query, pos, caseFold)\n      }\n    } else {\n      query = ensureFlags(query, \"gm\")\n      if (!options || options.multiline !== false)\n        this.matches = function(reverse, pos) {\n          return (reverse ? searchRegexpBackwardMultiline : searchRegexpForwardMultiline)(doc, query, pos)\n        }\n      else\n        this.matches = function(reverse, pos) {\n          return (reverse ? searchRegexpBackward : searchRegexpForward)(doc, query, pos)\n        }\n    }\n  }\n\n  SearchCursor.prototype = {\n    findNext: function() {return this.find(false)},\n    findPrevious: function() {return this.find(true)},\n\n    find: function(reverse) {\n      var head = this.doc.clipPos(reverse ? this.pos.from : this.pos.to);\n      if (this.afterEmptyMatch && this.atOccurrence) {\n        // do not return the same 0 width match twice\n        head = Pos(head.line, head.ch)\n        if (reverse) {\n          head.ch--;\n          if (head.ch < 0) {\n            head.line--;\n            head.ch = (this.doc.getLine(head.line) || \"\").length;\n          }\n        } else {\n          head.ch++;\n          if (head.ch > (this.doc.getLine(head.line) || \"\").length) {\n            head.ch = 0;\n            head.line++;\n          }\n        }\n        if (CodeMirror.cmpPos(head, this.doc.clipPos(head)) != 0) {\n           return this.atOccurrence = false\n        }\n      }\n      var result = this.matches(reverse, head)\n      this.afterEmptyMatch = result && CodeMirror.cmpPos(result.from, result.to) == 0\n\n      if (result) {\n        this.pos = result\n        this.atOccurrence = true\n        return this.pos.match || true\n      } else {\n        var end = Pos(reverse ? this.doc.firstLine() : this.doc.lastLine() + 1, 0)\n        this.pos = {from: end, to: end}\n        return this.atOccurrence = false\n      }\n    },\n\n    from: function() {if (this.atOccurrence) return this.pos.from},\n    to: function() {if (this.atOccurrence) return this.pos.to},\n\n    replace: function(newText, origin) {\n      if (!this.atOccurrence) return\n      var lines = CodeMirror.splitLines(newText)\n      this.doc.replaceRange(lines, this.pos.from, this.pos.to, origin)\n      this.pos.to = Pos(this.pos.from.line + lines.length - 1,\n                        lines[lines.length - 1].length + (lines.length == 1 ? this.pos.from.ch : 0))\n    }\n  }\n\n  CodeMirror.defineExtension(\"getSearchCursor\", function(query, pos, caseFold) {\n    return new SearchCursor(this.doc, query, pos, caseFold)\n  })\n  CodeMirror.defineDocExtension(\"getSearchCursor\", function(query, pos, caseFold) {\n    return new SearchCursor(this, query, pos, caseFold)\n  })\n\n  CodeMirror.defineExtension(\"selectMatches\", function(query, caseFold) {\n    var ranges = []\n    var cur = this.getSearchCursor(query, this.getCursor(\"from\"), caseFold)\n    while (cur.findNext()) {\n      if (CodeMirror.cmpPos(cur.to(), this.getCursor(\"to\")) > 0) break\n      ranges.push({anchor: cur.from(), head: cur.to()})\n    }\n    if (ranges.length)\n      this.setSelections(ranges, 0)\n  })\n});\n\n\n//# sourceURL=webpack://semanticfinder/./node_modules/codemirror/addon/search/searchcursor.js?");

/***/ }),

/***/ "./node_modules/codemirror/lib/codemirror.js":
/*!***************************************************!*\
  !*** ./node_modules/codemirror/lib/codemirror.js ***!
  \***************************************************/
/***/ (function(module) {

eval("// CodeMirror, copyright (c) by Marijn Haverbeke and others\n// Distributed under an MIT license: https://codemirror.net/5/LICENSE\n\n// This is CodeMirror (https://codemirror.net/5), a code editor\n// implemented in JavaScript on top of the browser's DOM.\n//\n// You can find some technical background for some of the code below\n// at http://marijnhaverbeke.nl/blog/#cm-internals .\n\n(function (global, factory) {\n   true ? module.exports = factory() :\n  0;\n}(this, (function () { 'use strict';\n\n  // Kludges for bugs and behavior differences that can't be feature\n  // detected are enabled based on userAgent etc sniffing.\n  var userAgent = navigator.userAgent;\n  var platform = navigator.platform;\n\n  var gecko = /gecko\\/\\d/i.test(userAgent);\n  var ie_upto10 = /MSIE \\d/.test(userAgent);\n  var ie_11up = /Trident\\/(?:[7-9]|\\d{2,})\\..*rv:(\\d+)/.exec(userAgent);\n  var edge = /Edge\\/(\\d+)/.exec(userAgent);\n  var ie = ie_upto10 || ie_11up || edge;\n  var ie_version = ie && (ie_upto10 ? document.documentMode || 6 : +(edge || ie_11up)[1]);\n  var webkit = !edge && /WebKit\\//.test(userAgent);\n  var qtwebkit = webkit && /Qt\\/\\d+\\.\\d+/.test(userAgent);\n  var chrome = !edge && /Chrome\\/(\\d+)/.exec(userAgent);\n  var chrome_version = chrome && +chrome[1];\n  var presto = /Opera\\//.test(userAgent);\n  var safari = /Apple Computer/.test(navigator.vendor);\n  var mac_geMountainLion = /Mac OS X 1\\d\\D([8-9]|\\d\\d)\\D/.test(userAgent);\n  var phantom = /PhantomJS/.test(userAgent);\n\n  var ios = safari && (/Mobile\\/\\w+/.test(userAgent) || navigator.maxTouchPoints > 2);\n  var android = /Android/.test(userAgent);\n  // This is woefully incomplete. Suggestions for alternative methods welcome.\n  var mobile = ios || android || /webOS|BlackBerry|Opera Mini|Opera Mobi|IEMobile/i.test(userAgent);\n  var mac = ios || /Mac/.test(platform);\n  var chromeOS = /\\bCrOS\\b/.test(userAgent);\n  var windows = /win/i.test(platform);\n\n  var presto_version = presto && userAgent.match(/Version\\/(\\d*\\.\\d*)/);\n  if (presto_version) { presto_version = Number(presto_version[1]); }\n  if (presto_version && presto_version >= 15) { presto = false; webkit = true; }\n  // Some browsers use the wrong event properties to signal cmd/ctrl on OS X\n  var flipCtrlCmd = mac && (qtwebkit || presto && (presto_version == null || presto_version < 12.11));\n  var captureRightClick = gecko || (ie && ie_version >= 9);\n\n  function classTest(cls) { return new RegExp(\"(^|\\\\s)\" + cls + \"(?:$|\\\\s)\\\\s*\") }\n\n  var rmClass = function(node, cls) {\n    var current = node.className;\n    var match = classTest(cls).exec(current);\n    if (match) {\n      var after = current.slice(match.index + match[0].length);\n      node.className = current.slice(0, match.index) + (after ? match[1] + after : \"\");\n    }\n  };\n\n  function removeChildren(e) {\n    for (var count = e.childNodes.length; count > 0; --count)\n      { e.removeChild(e.firstChild); }\n    return e\n  }\n\n  function removeChildrenAndAdd(parent, e) {\n    return removeChildren(parent).appendChild(e)\n  }\n\n  function elt(tag, content, className, style) {\n    var e = document.createElement(tag);\n    if (className) { e.className = className; }\n    if (style) { e.style.cssText = style; }\n    if (typeof content == \"string\") { e.appendChild(document.createTextNode(content)); }\n    else if (content) { for (var i = 0; i < content.length; ++i) { e.appendChild(content[i]); } }\n    return e\n  }\n  // wrapper for elt, which removes the elt from the accessibility tree\n  function eltP(tag, content, className, style) {\n    var e = elt(tag, content, className, style);\n    e.setAttribute(\"role\", \"presentation\");\n    return e\n  }\n\n  var range;\n  if (document.createRange) { range = function(node, start, end, endNode) {\n    var r = document.createRange();\n    r.setEnd(endNode || node, end);\n    r.setStart(node, start);\n    return r\n  }; }\n  else { range = function(node, start, end) {\n    var r = document.body.createTextRange();\n    try { r.moveToElementText(node.parentNode); }\n    catch(e) { return r }\n    r.collapse(true);\n    r.moveEnd(\"character\", end);\n    r.moveStart(\"character\", start);\n    return r\n  }; }\n\n  function contains(parent, child) {\n    if (child.nodeType == 3) // Android browser always returns false when child is a textnode\n      { child = child.parentNode; }\n    if (parent.contains)\n      { return parent.contains(child) }\n    do {\n      if (child.nodeType == 11) { child = child.host; }\n      if (child == parent) { return true }\n    } while (child = child.parentNode)\n  }\n\n  function activeElt(rootNode) {\n    // IE and Edge may throw an \"Unspecified Error\" when accessing document.activeElement.\n    // IE < 10 will throw when accessed while the page is loading or in an iframe.\n    // IE > 9 and Edge will throw when accessed in an iframe if document.body is unavailable.\n    var doc = rootNode.ownerDocument || rootNode;\n    var activeElement;\n    try {\n      activeElement = rootNode.activeElement;\n    } catch(e) {\n      activeElement = doc.body || null;\n    }\n    while (activeElement && activeElement.shadowRoot && activeElement.shadowRoot.activeElement)\n      { activeElement = activeElement.shadowRoot.activeElement; }\n    return activeElement\n  }\n\n  function addClass(node, cls) {\n    var current = node.className;\n    if (!classTest(cls).test(current)) { node.className += (current ? \" \" : \"\") + cls; }\n  }\n  function joinClasses(a, b) {\n    var as = a.split(\" \");\n    for (var i = 0; i < as.length; i++)\n      { if (as[i] && !classTest(as[i]).test(b)) { b += \" \" + as[i]; } }\n    return b\n  }\n\n  var selectInput = function(node) { node.select(); };\n  if (ios) // Mobile Safari apparently has a bug where select() is broken.\n    { selectInput = function(node) { node.selectionStart = 0; node.selectionEnd = node.value.length; }; }\n  else if (ie) // Suppress mysterious IE10 errors\n    { selectInput = function(node) { try { node.select(); } catch(_e) {} }; }\n\n  function doc(cm) { return cm.display.wrapper.ownerDocument }\n\n  function root(cm) {\n    return rootNode(cm.display.wrapper)\n  }\n\n  function rootNode(element) {\n    // Detect modern browsers (2017+).\n    return element.getRootNode ? element.getRootNode() : element.ownerDocument\n  }\n\n  function win(cm) { return doc(cm).defaultView }\n\n  function bind(f) {\n    var args = Array.prototype.slice.call(arguments, 1);\n    return function(){return f.apply(null, args)}\n  }\n\n  function copyObj(obj, target, overwrite) {\n    if (!target) { target = {}; }\n    for (var prop in obj)\n      { if (obj.hasOwnProperty(prop) && (overwrite !== false || !target.hasOwnProperty(prop)))\n        { target[prop] = obj[prop]; } }\n    return target\n  }\n\n  // Counts the column offset in a string, taking tabs into account.\n  // Used mostly to find indentation.\n  function countColumn(string, end, tabSize, startIndex, startValue) {\n    if (end == null) {\n      end = string.search(/[^\\s\\u00a0]/);\n      if (end == -1) { end = string.length; }\n    }\n    for (var i = startIndex || 0, n = startValue || 0;;) {\n      var nextTab = string.indexOf(\"\\t\", i);\n      if (nextTab < 0 || nextTab >= end)\n        { return n + (end - i) }\n      n += nextTab - i;\n      n += tabSize - (n % tabSize);\n      i = nextTab + 1;\n    }\n  }\n\n  var Delayed = function() {\n    this.id = null;\n    this.f = null;\n    this.time = 0;\n    this.handler = bind(this.onTimeout, this);\n  };\n  Delayed.prototype.onTimeout = function (self) {\n    self.id = 0;\n    if (self.time <= +new Date) {\n      self.f();\n    } else {\n      setTimeout(self.handler, self.time - +new Date);\n    }\n  };\n  Delayed.prototype.set = function (ms, f) {\n    this.f = f;\n    var time = +new Date + ms;\n    if (!this.id || time < this.time) {\n      clearTimeout(this.id);\n      this.id = setTimeout(this.handler, ms);\n      this.time = time;\n    }\n  };\n\n  function indexOf(array, elt) {\n    for (var i = 0; i < array.length; ++i)\n      { if (array[i] == elt) { return i } }\n    return -1\n  }\n\n  // Number of pixels added to scroller and sizer to hide scrollbar\n  var scrollerGap = 50;\n\n  // Returned or thrown by various protocols to signal 'I'm not\n  // handling this'.\n  var Pass = {toString: function(){return \"CodeMirror.Pass\"}};\n\n  // Reused option objects for setSelection & friends\n  var sel_dontScroll = {scroll: false}, sel_mouse = {origin: \"*mouse\"}, sel_move = {origin: \"+move\"};\n\n  // The inverse of countColumn -- find the offset that corresponds to\n  // a particular column.\n  function findColumn(string, goal, tabSize) {\n    for (var pos = 0, col = 0;;) {\n      var nextTab = string.indexOf(\"\\t\", pos);\n      if (nextTab == -1) { nextTab = string.length; }\n      var skipped = nextTab - pos;\n      if (nextTab == string.length || col + skipped >= goal)\n        { return pos + Math.min(skipped, goal - col) }\n      col += nextTab - pos;\n      col += tabSize - (col % tabSize);\n      pos = nextTab + 1;\n      if (col >= goal) { return pos }\n    }\n  }\n\n  var spaceStrs = [\"\"];\n  function spaceStr(n) {\n    while (spaceStrs.length <= n)\n      { spaceStrs.push(lst(spaceStrs) + \" \"); }\n    return spaceStrs[n]\n  }\n\n  function lst(arr) { return arr[arr.length-1] }\n\n  function map(array, f) {\n    var out = [];\n    for (var i = 0; i < array.length; i++) { out[i] = f(array[i], i); }\n    return out\n  }\n\n  function insertSorted(array, value, score) {\n    var pos = 0, priority = score(value);\n    while (pos < array.length && score(array[pos]) <= priority) { pos++; }\n    array.splice(pos, 0, value);\n  }\n\n  function nothing() {}\n\n  function createObj(base, props) {\n    var inst;\n    if (Object.create) {\n      inst = Object.create(base);\n    } else {\n      nothing.prototype = base;\n      inst = new nothing();\n    }\n    if (props) { copyObj(props, inst); }\n    return inst\n  }\n\n  var nonASCIISingleCaseWordChar = /[\\u00df\\u0587\\u0590-\\u05f4\\u0600-\\u06ff\\u3040-\\u309f\\u30a0-\\u30ff\\u3400-\\u4db5\\u4e00-\\u9fcc\\uac00-\\ud7af]/;\n  function isWordCharBasic(ch) {\n    return /\\w/.test(ch) || ch > \"\\x80\" &&\n      (ch.toUpperCase() != ch.toLowerCase() || nonASCIISingleCaseWordChar.test(ch))\n  }\n  function isWordChar(ch, helper) {\n    if (!helper) { return isWordCharBasic(ch) }\n    if (helper.source.indexOf(\"\\\\w\") > -1 && isWordCharBasic(ch)) { return true }\n    return helper.test(ch)\n  }\n\n  function isEmpty(obj) {\n    for (var n in obj) { if (obj.hasOwnProperty(n) && obj[n]) { return false } }\n    return true\n  }\n\n  // Extending unicode characters. A series of a non-extending char +\n  // any number of extending chars is treated as a single unit as far\n  // as editing and measuring is concerned. This is not fully correct,\n  // since some scripts/fonts/browsers also treat other configurations\n  // of code points as a group.\n  var extendingChars = /[\\u0300-\\u036f\\u0483-\\u0489\\u0591-\\u05bd\\u05bf\\u05c1\\u05c2\\u05c4\\u05c5\\u05c7\\u0610-\\u061a\\u064b-\\u065e\\u0670\\u06d6-\\u06dc\\u06de-\\u06e4\\u06e7\\u06e8\\u06ea-\\u06ed\\u0711\\u0730-\\u074a\\u07a6-\\u07b0\\u07eb-\\u07f3\\u0816-\\u0819\\u081b-\\u0823\\u0825-\\u0827\\u0829-\\u082d\\u0900-\\u0902\\u093c\\u0941-\\u0948\\u094d\\u0951-\\u0955\\u0962\\u0963\\u0981\\u09bc\\u09be\\u09c1-\\u09c4\\u09cd\\u09d7\\u09e2\\u09e3\\u0a01\\u0a02\\u0a3c\\u0a41\\u0a42\\u0a47\\u0a48\\u0a4b-\\u0a4d\\u0a51\\u0a70\\u0a71\\u0a75\\u0a81\\u0a82\\u0abc\\u0ac1-\\u0ac5\\u0ac7\\u0ac8\\u0acd\\u0ae2\\u0ae3\\u0b01\\u0b3c\\u0b3e\\u0b3f\\u0b41-\\u0b44\\u0b4d\\u0b56\\u0b57\\u0b62\\u0b63\\u0b82\\u0bbe\\u0bc0\\u0bcd\\u0bd7\\u0c3e-\\u0c40\\u0c46-\\u0c48\\u0c4a-\\u0c4d\\u0c55\\u0c56\\u0c62\\u0c63\\u0cbc\\u0cbf\\u0cc2\\u0cc6\\u0ccc\\u0ccd\\u0cd5\\u0cd6\\u0ce2\\u0ce3\\u0d3e\\u0d41-\\u0d44\\u0d4d\\u0d57\\u0d62\\u0d63\\u0dca\\u0dcf\\u0dd2-\\u0dd4\\u0dd6\\u0ddf\\u0e31\\u0e34-\\u0e3a\\u0e47-\\u0e4e\\u0eb1\\u0eb4-\\u0eb9\\u0ebb\\u0ebc\\u0ec8-\\u0ecd\\u0f18\\u0f19\\u0f35\\u0f37\\u0f39\\u0f71-\\u0f7e\\u0f80-\\u0f84\\u0f86\\u0f87\\u0f90-\\u0f97\\u0f99-\\u0fbc\\u0fc6\\u102d-\\u1030\\u1032-\\u1037\\u1039\\u103a\\u103d\\u103e\\u1058\\u1059\\u105e-\\u1060\\u1071-\\u1074\\u1082\\u1085\\u1086\\u108d\\u109d\\u135f\\u1712-\\u1714\\u1732-\\u1734\\u1752\\u1753\\u1772\\u1773\\u17b7-\\u17bd\\u17c6\\u17c9-\\u17d3\\u17dd\\u180b-\\u180d\\u18a9\\u1920-\\u1922\\u1927\\u1928\\u1932\\u1939-\\u193b\\u1a17\\u1a18\\u1a56\\u1a58-\\u1a5e\\u1a60\\u1a62\\u1a65-\\u1a6c\\u1a73-\\u1a7c\\u1a7f\\u1b00-\\u1b03\\u1b34\\u1b36-\\u1b3a\\u1b3c\\u1b42\\u1b6b-\\u1b73\\u1b80\\u1b81\\u1ba2-\\u1ba5\\u1ba8\\u1ba9\\u1c2c-\\u1c33\\u1c36\\u1c37\\u1cd0-\\u1cd2\\u1cd4-\\u1ce0\\u1ce2-\\u1ce8\\u1ced\\u1dc0-\\u1de6\\u1dfd-\\u1dff\\u200c\\u200d\\u20d0-\\u20f0\\u2cef-\\u2cf1\\u2de0-\\u2dff\\u302a-\\u302f\\u3099\\u309a\\ua66f-\\ua672\\ua67c\\ua67d\\ua6f0\\ua6f1\\ua802\\ua806\\ua80b\\ua825\\ua826\\ua8c4\\ua8e0-\\ua8f1\\ua926-\\ua92d\\ua947-\\ua951\\ua980-\\ua982\\ua9b3\\ua9b6-\\ua9b9\\ua9bc\\uaa29-\\uaa2e\\uaa31\\uaa32\\uaa35\\uaa36\\uaa43\\uaa4c\\uaab0\\uaab2-\\uaab4\\uaab7\\uaab8\\uaabe\\uaabf\\uaac1\\uabe5\\uabe8\\uabed\\udc00-\\udfff\\ufb1e\\ufe00-\\ufe0f\\ufe20-\\ufe26\\uff9e\\uff9f]/;\n  function isExtendingChar(ch) { return ch.charCodeAt(0) >= 768 && extendingChars.test(ch) }\n\n  // Returns a number from the range [`0`; `str.length`] unless `pos` is outside that range.\n  function skipExtendingChars(str, pos, dir) {\n    while ((dir < 0 ? pos > 0 : pos < str.length) && isExtendingChar(str.charAt(pos))) { pos += dir; }\n    return pos\n  }\n\n  // Returns the value from the range [`from`; `to`] that satisfies\n  // `pred` and is closest to `from`. Assumes that at least `to`\n  // satisfies `pred`. Supports `from` being greater than `to`.\n  function findFirst(pred, from, to) {\n    // At any point we are certain `to` satisfies `pred`, don't know\n    // whether `from` does.\n    var dir = from > to ? -1 : 1;\n    for (;;) {\n      if (from == to) { return from }\n      var midF = (from + to) / 2, mid = dir < 0 ? Math.ceil(midF) : Math.floor(midF);\n      if (mid == from) { return pred(mid) ? from : to }\n      if (pred(mid)) { to = mid; }\n      else { from = mid + dir; }\n    }\n  }\n\n  // BIDI HELPERS\n\n  function iterateBidiSections(order, from, to, f) {\n    if (!order) { return f(from, to, \"ltr\", 0) }\n    var found = false;\n    for (var i = 0; i < order.length; ++i) {\n      var part = order[i];\n      if (part.from < to && part.to > from || from == to && part.to == from) {\n        f(Math.max(part.from, from), Math.min(part.to, to), part.level == 1 ? \"rtl\" : \"ltr\", i);\n        found = true;\n      }\n    }\n    if (!found) { f(from, to, \"ltr\"); }\n  }\n\n  var bidiOther = null;\n  function getBidiPartAt(order, ch, sticky) {\n    var found;\n    bidiOther = null;\n    for (var i = 0; i < order.length; ++i) {\n      var cur = order[i];\n      if (cur.from < ch && cur.to > ch) { return i }\n      if (cur.to == ch) {\n        if (cur.from != cur.to && sticky == \"before\") { found = i; }\n        else { bidiOther = i; }\n      }\n      if (cur.from == ch) {\n        if (cur.from != cur.to && sticky != \"before\") { found = i; }\n        else { bidiOther = i; }\n      }\n    }\n    return found != null ? found : bidiOther\n  }\n\n  // Bidirectional ordering algorithm\n  // See http://unicode.org/reports/tr9/tr9-13.html for the algorithm\n  // that this (partially) implements.\n\n  // One-char codes used for character types:\n  // L (L):   Left-to-Right\n  // R (R):   Right-to-Left\n  // r (AL):  Right-to-Left Arabic\n  // 1 (EN):  European Number\n  // + (ES):  European Number Separator\n  // % (ET):  European Number Terminator\n  // n (AN):  Arabic Number\n  // , (CS):  Common Number Separator\n  // m (NSM): Non-Spacing Mark\n  // b (BN):  Boundary Neutral\n  // s (B):   Paragraph Separator\n  // t (S):   Segment Separator\n  // w (WS):  Whitespace\n  // N (ON):  Other Neutrals\n\n  // Returns null if characters are ordered as they appear\n  // (left-to-right), or an array of sections ({from, to, level}\n  // objects) in the order in which they occur visually.\n  var bidiOrdering = (function() {\n    // Character types for codepoints 0 to 0xff\n    var lowTypes = \"bbbbbbbbbtstwsbbbbbbbbbbbbbbssstwNN%%%NNNNNN,N,N1111111111NNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNbbbbbbsbbbbbbbbbbbbbbbbbbbbbbbbbb,N%%%%NNNNLNNNNN%%11NLNNN1LNNNNNLLLLLLLLLLLLLLLLLLLLLLLNLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLN\";\n    // Character types for codepoints 0x600 to 0x6f9\n    var arabicTypes = \"nnnnnnNNr%%r,rNNmmmmmmmmmmmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmmmmmmmmmmmmmmmnnnnnnnnnn%nnrrrmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmnNmmmmmmrrmmNmmmmrr1111111111\";\n    function charType(code) {\n      if (code <= 0xf7) { return lowTypes.charAt(code) }\n      else if (0x590 <= code && code <= 0x5f4) { return \"R\" }\n      else if (0x600 <= code && code <= 0x6f9) { return arabicTypes.charAt(code - 0x600) }\n      else if (0x6ee <= code && code <= 0x8ac) { return \"r\" }\n      else if (0x2000 <= code && code <= 0x200b) { return \"w\" }\n      else if (code == 0x200c) { return \"b\" }\n      else { return \"L\" }\n    }\n\n    var bidiRE = /[\\u0590-\\u05f4\\u0600-\\u06ff\\u0700-\\u08ac]/;\n    var isNeutral = /[stwN]/, isStrong = /[LRr]/, countsAsLeft = /[Lb1n]/, countsAsNum = /[1n]/;\n\n    function BidiSpan(level, from, to) {\n      this.level = level;\n      this.from = from; this.to = to;\n    }\n\n    return function(str, direction) {\n      var outerType = direction == \"ltr\" ? \"L\" : \"R\";\n\n      if (str.length == 0 || direction == \"ltr\" && !bidiRE.test(str)) { return false }\n      var len = str.length, types = [];\n      for (var i = 0; i < len; ++i)\n        { types.push(charType(str.charCodeAt(i))); }\n\n      // W1. Examine each non-spacing mark (NSM) in the level run, and\n      // change the type of the NSM to the type of the previous\n      // character. If the NSM is at the start of the level run, it will\n      // get the type of sor.\n      for (var i$1 = 0, prev = outerType; i$1 < len; ++i$1) {\n        var type = types[i$1];\n        if (type == \"m\") { types[i$1] = prev; }\n        else { prev = type; }\n      }\n\n      // W2. Search backwards from each instance of a European number\n      // until the first strong type (R, L, AL, or sor) is found. If an\n      // AL is found, change the type of the European number to Arabic\n      // number.\n      // W3. Change all ALs to R.\n      for (var i$2 = 0, cur = outerType; i$2 < len; ++i$2) {\n        var type$1 = types[i$2];\n        if (type$1 == \"1\" && cur == \"r\") { types[i$2] = \"n\"; }\n        else if (isStrong.test(type$1)) { cur = type$1; if (type$1 == \"r\") { types[i$2] = \"R\"; } }\n      }\n\n      // W4. A single European separator between two European numbers\n      // changes to a European number. A single common separator between\n      // two numbers of the same type changes to that type.\n      for (var i$3 = 1, prev$1 = types[0]; i$3 < len - 1; ++i$3) {\n        var type$2 = types[i$3];\n        if (type$2 == \"+\" && prev$1 == \"1\" && types[i$3+1] == \"1\") { types[i$3] = \"1\"; }\n        else if (type$2 == \",\" && prev$1 == types[i$3+1] &&\n                 (prev$1 == \"1\" || prev$1 == \"n\")) { types[i$3] = prev$1; }\n        prev$1 = type$2;\n      }\n\n      // W5. A sequence of European terminators adjacent to European\n      // numbers changes to all European numbers.\n      // W6. Otherwise, separators and terminators change to Other\n      // Neutral.\n      for (var i$4 = 0; i$4 < len; ++i$4) {\n        var type$3 = types[i$4];\n        if (type$3 == \",\") { types[i$4] = \"N\"; }\n        else if (type$3 == \"%\") {\n          var end = (void 0);\n          for (end = i$4 + 1; end < len && types[end] == \"%\"; ++end) {}\n          var replace = (i$4 && types[i$4-1] == \"!\") || (end < len && types[end] == \"1\") ? \"1\" : \"N\";\n          for (var j = i$4; j < end; ++j) { types[j] = replace; }\n          i$4 = end - 1;\n        }\n      }\n\n      // W7. Search backwards from each instance of a European number\n      // until the first strong type (R, L, or sor) is found. If an L is\n      // found, then change the type of the European number to L.\n      for (var i$5 = 0, cur$1 = outerType; i$5 < len; ++i$5) {\n        var type$4 = types[i$5];\n        if (cur$1 == \"L\" && type$4 == \"1\") { types[i$5] = \"L\"; }\n        else if (isStrong.test(type$4)) { cur$1 = type$4; }\n      }\n\n      // N1. A sequence of neutrals takes the direction of the\n      // surrounding strong text if the text on both sides has the same\n      // direction. European and Arabic numbers act as if they were R in\n      // terms of their influence on neutrals. Start-of-level-run (sor)\n      // and end-of-level-run (eor) are used at level run boundaries.\n      // N2. Any remaining neutrals take the embedding direction.\n      for (var i$6 = 0; i$6 < len; ++i$6) {\n        if (isNeutral.test(types[i$6])) {\n          var end$1 = (void 0);\n          for (end$1 = i$6 + 1; end$1 < len && isNeutral.test(types[end$1]); ++end$1) {}\n          var before = (i$6 ? types[i$6-1] : outerType) == \"L\";\n          var after = (end$1 < len ? types[end$1] : outerType) == \"L\";\n          var replace$1 = before == after ? (before ? \"L\" : \"R\") : outerType;\n          for (var j$1 = i$6; j$1 < end$1; ++j$1) { types[j$1] = replace$1; }\n          i$6 = end$1 - 1;\n        }\n      }\n\n      // Here we depart from the documented algorithm, in order to avoid\n      // building up an actual levels array. Since there are only three\n      // levels (0, 1, 2) in an implementation that doesn't take\n      // explicit embedding into account, we can build up the order on\n      // the fly, without following the level-based algorithm.\n      var order = [], m;\n      for (var i$7 = 0; i$7 < len;) {\n        if (countsAsLeft.test(types[i$7])) {\n          var start = i$7;\n          for (++i$7; i$7 < len && countsAsLeft.test(types[i$7]); ++i$7) {}\n          order.push(new BidiSpan(0, start, i$7));\n        } else {\n          var pos = i$7, at = order.length, isRTL = direction == \"rtl\" ? 1 : 0;\n          for (++i$7; i$7 < len && types[i$7] != \"L\"; ++i$7) {}\n          for (var j$2 = pos; j$2 < i$7;) {\n            if (countsAsNum.test(types[j$2])) {\n              if (pos < j$2) { order.splice(at, 0, new BidiSpan(1, pos, j$2)); at += isRTL; }\n              var nstart = j$2;\n              for (++j$2; j$2 < i$7 && countsAsNum.test(types[j$2]); ++j$2) {}\n              order.splice(at, 0, new BidiSpan(2, nstart, j$2));\n              at += isRTL;\n              pos = j$2;\n            } else { ++j$2; }\n          }\n          if (pos < i$7) { order.splice(at, 0, new BidiSpan(1, pos, i$7)); }\n        }\n      }\n      if (direction == \"ltr\") {\n        if (order[0].level == 1 && (m = str.match(/^\\s+/))) {\n          order[0].from = m[0].length;\n          order.unshift(new BidiSpan(0, 0, m[0].length));\n        }\n        if (lst(order).level == 1 && (m = str.match(/\\s+$/))) {\n          lst(order).to -= m[0].length;\n          order.push(new BidiSpan(0, len - m[0].length, len));\n        }\n      }\n\n      return direction == \"rtl\" ? order.reverse() : order\n    }\n  })();\n\n  // Get the bidi ordering for the given line (and cache it). Returns\n  // false for lines that are fully left-to-right, and an array of\n  // BidiSpan objects otherwise.\n  function getOrder(line, direction) {\n    var order = line.order;\n    if (order == null) { order = line.order = bidiOrdering(line.text, direction); }\n    return order\n  }\n\n  // EVENT HANDLING\n\n  // Lightweight event framework. on/off also work on DOM nodes,\n  // registering native DOM handlers.\n\n  var noHandlers = [];\n\n  var on = function(emitter, type, f) {\n    if (emitter.addEventListener) {\n      emitter.addEventListener(type, f, false);\n    } else if (emitter.attachEvent) {\n      emitter.attachEvent(\"on\" + type, f);\n    } else {\n      var map = emitter._handlers || (emitter._handlers = {});\n      map[type] = (map[type] || noHandlers).concat(f);\n    }\n  };\n\n  function getHandlers(emitter, type) {\n    return emitter._handlers && emitter._handlers[type] || noHandlers\n  }\n\n  function off(emitter, type, f) {\n    if (emitter.removeEventListener) {\n      emitter.removeEventListener(type, f, false);\n    } else if (emitter.detachEvent) {\n      emitter.detachEvent(\"on\" + type, f);\n    } else {\n      var map = emitter._handlers, arr = map && map[type];\n      if (arr) {\n        var index = indexOf(arr, f);\n        if (index > -1)\n          { map[type] = arr.slice(0, index).concat(arr.slice(index + 1)); }\n      }\n    }\n  }\n\n  function signal(emitter, type /*, values...*/) {\n    var handlers = getHandlers(emitter, type);\n    if (!handlers.length) { return }\n    var args = Array.prototype.slice.call(arguments, 2);\n    for (var i = 0; i < handlers.length; ++i) { handlers[i].apply(null, args); }\n  }\n\n  // The DOM events that CodeMirror handles can be overridden by\n  // registering a (non-DOM) handler on the editor for the event name,\n  // and preventDefault-ing the event in that handler.\n  function signalDOMEvent(cm, e, override) {\n    if (typeof e == \"string\")\n      { e = {type: e, preventDefault: function() { this.defaultPrevented = true; }}; }\n    signal(cm, override || e.type, cm, e);\n    return e_defaultPrevented(e) || e.codemirrorIgnore\n  }\n\n  function signalCursorActivity(cm) {\n    var arr = cm._handlers && cm._handlers.cursorActivity;\n    if (!arr) { return }\n    var set = cm.curOp.cursorActivityHandlers || (cm.curOp.cursorActivityHandlers = []);\n    for (var i = 0; i < arr.length; ++i) { if (indexOf(set, arr[i]) == -1)\n      { set.push(arr[i]); } }\n  }\n\n  function hasHandler(emitter, type) {\n    return getHandlers(emitter, type).length > 0\n  }\n\n  // Add on and off methods to a constructor's prototype, to make\n  // registering events on such objects more convenient.\n  function eventMixin(ctor) {\n    ctor.prototype.on = function(type, f) {on(this, type, f);};\n    ctor.prototype.off = function(type, f) {off(this, type, f);};\n  }\n\n  // Due to the fact that we still support jurassic IE versions, some\n  // compatibility wrappers are needed.\n\n  function e_preventDefault(e) {\n    if (e.preventDefault) { e.preventDefault(); }\n    else { e.returnValue = false; }\n  }\n  function e_stopPropagation(e) {\n    if (e.stopPropagation) { e.stopPropagation(); }\n    else { e.cancelBubble = true; }\n  }\n  function e_defaultPrevented(e) {\n    return e.defaultPrevented != null ? e.defaultPrevented : e.returnValue == false\n  }\n  function e_stop(e) {e_preventDefault(e); e_stopPropagation(e);}\n\n  function e_target(e) {return e.target || e.srcElement}\n  function e_button(e) {\n    var b = e.which;\n    if (b == null) {\n      if (e.button & 1) { b = 1; }\n      else if (e.button & 2) { b = 3; }\n      else if (e.button & 4) { b = 2; }\n    }\n    if (mac && e.ctrlKey && b == 1) { b = 3; }\n    return b\n  }\n\n  // Detect drag-and-drop\n  var dragAndDrop = function() {\n    // There is *some* kind of drag-and-drop support in IE6-8, but I\n    // couldn't get it to work yet.\n    if (ie && ie_version < 9) { return false }\n    var div = elt('div');\n    return \"draggable\" in div || \"dragDrop\" in div\n  }();\n\n  var zwspSupported;\n  function zeroWidthElement(measure) {\n    if (zwspSupported == null) {\n      var test = elt(\"span\", \"\\u200b\");\n      removeChildrenAndAdd(measure, elt(\"span\", [test, document.createTextNode(\"x\")]));\n      if (measure.firstChild.offsetHeight != 0)\n        { zwspSupported = test.offsetWidth <= 1 && test.offsetHeight > 2 && !(ie && ie_version < 8); }\n    }\n    var node = zwspSupported ? elt(\"span\", \"\\u200b\") :\n      elt(\"span\", \"\\u00a0\", null, \"display: inline-block; width: 1px; margin-right: -1px\");\n    node.setAttribute(\"cm-text\", \"\");\n    return node\n  }\n\n  // Feature-detect IE's crummy client rect reporting for bidi text\n  var badBidiRects;\n  function hasBadBidiRects(measure) {\n    if (badBidiRects != null) { return badBidiRects }\n    var txt = removeChildrenAndAdd(measure, document.createTextNode(\"A\\u062eA\"));\n    var r0 = range(txt, 0, 1).getBoundingClientRect();\n    var r1 = range(txt, 1, 2).getBoundingClientRect();\n    removeChildren(measure);\n    if (!r0 || r0.left == r0.right) { return false } // Safari returns null in some cases (#2780)\n    return badBidiRects = (r1.right - r0.right < 3)\n  }\n\n  // See if \"\".split is the broken IE version, if so, provide an\n  // alternative way to split lines.\n  var splitLinesAuto = \"\\n\\nb\".split(/\\n/).length != 3 ? function (string) {\n    var pos = 0, result = [], l = string.length;\n    while (pos <= l) {\n      var nl = string.indexOf(\"\\n\", pos);\n      if (nl == -1) { nl = string.length; }\n      var line = string.slice(pos, string.charAt(nl - 1) == \"\\r\" ? nl - 1 : nl);\n      var rt = line.indexOf(\"\\r\");\n      if (rt != -1) {\n        result.push(line.slice(0, rt));\n        pos += rt + 1;\n      } else {\n        result.push(line);\n        pos = nl + 1;\n      }\n    }\n    return result\n  } : function (string) { return string.split(/\\r\\n?|\\n/); };\n\n  var hasSelection = window.getSelection ? function (te) {\n    try { return te.selectionStart != te.selectionEnd }\n    catch(e) { return false }\n  } : function (te) {\n    var range;\n    try {range = te.ownerDocument.selection.createRange();}\n    catch(e) {}\n    if (!range || range.parentElement() != te) { return false }\n    return range.compareEndPoints(\"StartToEnd\", range) != 0\n  };\n\n  var hasCopyEvent = (function () {\n    var e = elt(\"div\");\n    if (\"oncopy\" in e) { return true }\n    e.setAttribute(\"oncopy\", \"return;\");\n    return typeof e.oncopy == \"function\"\n  })();\n\n  var badZoomedRects = null;\n  function hasBadZoomedRects(measure) {\n    if (badZoomedRects != null) { return badZoomedRects }\n    var node = removeChildrenAndAdd(measure, elt(\"span\", \"x\"));\n    var normal = node.getBoundingClientRect();\n    var fromRange = range(node, 0, 1).getBoundingClientRect();\n    return badZoomedRects = Math.abs(normal.left - fromRange.left) > 1\n  }\n\n  // Known modes, by name and by MIME\n  var modes = {}, mimeModes = {};\n\n  // Extra arguments are stored as the mode's dependencies, which is\n  // used by (legacy) mechanisms like loadmode.js to automatically\n  // load a mode. (Preferred mechanism is the require/define calls.)\n  function defineMode(name, mode) {\n    if (arguments.length > 2)\n      { mode.dependencies = Array.prototype.slice.call(arguments, 2); }\n    modes[name] = mode;\n  }\n\n  function defineMIME(mime, spec) {\n    mimeModes[mime] = spec;\n  }\n\n  // Given a MIME type, a {name, ...options} config object, or a name\n  // string, return a mode config object.\n  function resolveMode(spec) {\n    if (typeof spec == \"string\" && mimeModes.hasOwnProperty(spec)) {\n      spec = mimeModes[spec];\n    } else if (spec && typeof spec.name == \"string\" && mimeModes.hasOwnProperty(spec.name)) {\n      var found = mimeModes[spec.name];\n      if (typeof found == \"string\") { found = {name: found}; }\n      spec = createObj(found, spec);\n      spec.name = found.name;\n    } else if (typeof spec == \"string\" && /^[\\w\\-]+\\/[\\w\\-]+\\+xml$/.test(spec)) {\n      return resolveMode(\"application/xml\")\n    } else if (typeof spec == \"string\" && /^[\\w\\-]+\\/[\\w\\-]+\\+json$/.test(spec)) {\n      return resolveMode(\"application/json\")\n    }\n    if (typeof spec == \"string\") { return {name: spec} }\n    else { return spec || {name: \"null\"} }\n  }\n\n  // Given a mode spec (anything that resolveMode accepts), find and\n  // initialize an actual mode object.\n  function getMode(options, spec) {\n    spec = resolveMode(spec);\n    var mfactory = modes[spec.name];\n    if (!mfactory) { return getMode(options, \"text/plain\") }\n    var modeObj = mfactory(options, spec);\n    if (modeExtensions.hasOwnProperty(spec.name)) {\n      var exts = modeExtensions[spec.name];\n      for (var prop in exts) {\n        if (!exts.hasOwnProperty(prop)) { continue }\n        if (modeObj.hasOwnProperty(prop)) { modeObj[\"_\" + prop] = modeObj[prop]; }\n        modeObj[prop] = exts[prop];\n      }\n    }\n    modeObj.name = spec.name;\n    if (spec.helperType) { modeObj.helperType = spec.helperType; }\n    if (spec.modeProps) { for (var prop$1 in spec.modeProps)\n      { modeObj[prop$1] = spec.modeProps[prop$1]; } }\n\n    return modeObj\n  }\n\n  // This can be used to attach properties to mode objects from\n  // outside the actual mode definition.\n  var modeExtensions = {};\n  function extendMode(mode, properties) {\n    var exts = modeExtensions.hasOwnProperty(mode) ? modeExtensions[mode] : (modeExtensions[mode] = {});\n    copyObj(properties, exts);\n  }\n\n  function copyState(mode, state) {\n    if (state === true) { return state }\n    if (mode.copyState) { return mode.copyState(state) }\n    var nstate = {};\n    for (var n in state) {\n      var val = state[n];\n      if (val instanceof Array) { val = val.concat([]); }\n      nstate[n] = val;\n    }\n    return nstate\n  }\n\n  // Given a mode and a state (for that mode), find the inner mode and\n  // state at the position that the state refers to.\n  function innerMode(mode, state) {\n    var info;\n    while (mode.innerMode) {\n      info = mode.innerMode(state);\n      if (!info || info.mode == mode) { break }\n      state = info.state;\n      mode = info.mode;\n    }\n    return info || {mode: mode, state: state}\n  }\n\n  function startState(mode, a1, a2) {\n    return mode.startState ? mode.startState(a1, a2) : true\n  }\n\n  // STRING STREAM\n\n  // Fed to the mode parsers, provides helper functions to make\n  // parsers more succinct.\n\n  var StringStream = function(string, tabSize, lineOracle) {\n    this.pos = this.start = 0;\n    this.string = string;\n    this.tabSize = tabSize || 8;\n    this.lastColumnPos = this.lastColumnValue = 0;\n    this.lineStart = 0;\n    this.lineOracle = lineOracle;\n  };\n\n  StringStream.prototype.eol = function () {return this.pos >= this.string.length};\n  StringStream.prototype.sol = function () {return this.pos == this.lineStart};\n  StringStream.prototype.peek = function () {return this.string.charAt(this.pos) || undefined};\n  StringStream.prototype.next = function () {\n    if (this.pos < this.string.length)\n      { return this.string.charAt(this.pos++) }\n  };\n  StringStream.prototype.eat = function (match) {\n    var ch = this.string.charAt(this.pos);\n    var ok;\n    if (typeof match == \"string\") { ok = ch == match; }\n    else { ok = ch && (match.test ? match.test(ch) : match(ch)); }\n    if (ok) {++this.pos; return ch}\n  };\n  StringStream.prototype.eatWhile = function (match) {\n    var start = this.pos;\n    while (this.eat(match)){}\n    return this.pos > start\n  };\n  StringStream.prototype.eatSpace = function () {\n    var start = this.pos;\n    while (/[\\s\\u00a0]/.test(this.string.charAt(this.pos))) { ++this.pos; }\n    return this.pos > start\n  };\n  StringStream.prototype.skipToEnd = function () {this.pos = this.string.length;};\n  StringStream.prototype.skipTo = function (ch) {\n    var found = this.string.indexOf(ch, this.pos);\n    if (found > -1) {this.pos = found; return true}\n  };\n  StringStream.prototype.backUp = function (n) {this.pos -= n;};\n  StringStream.prototype.column = function () {\n    if (this.lastColumnPos < this.start) {\n      this.lastColumnValue = countColumn(this.string, this.start, this.tabSize, this.lastColumnPos, this.lastColumnValue);\n      this.lastColumnPos = this.start;\n    }\n    return this.lastColumnValue - (this.lineStart ? countColumn(this.string, this.lineStart, this.tabSize) : 0)\n  };\n  StringStream.prototype.indentation = function () {\n    return countColumn(this.string, null, this.tabSize) -\n      (this.lineStart ? countColumn(this.string, this.lineStart, this.tabSize) : 0)\n  };\n  StringStream.prototype.match = function (pattern, consume, caseInsensitive) {\n    if (typeof pattern == \"string\") {\n      var cased = function (str) { return caseInsensitive ? str.toLowerCase() : str; };\n      var substr = this.string.substr(this.pos, pattern.length);\n      if (cased(substr) == cased(pattern)) {\n        if (consume !== false) { this.pos += pattern.length; }\n        return true\n      }\n    } else {\n      var match = this.string.slice(this.pos).match(pattern);\n      if (match && match.index > 0) { return null }\n      if (match && consume !== false) { this.pos += match[0].length; }\n      return match\n    }\n  };\n  StringStream.prototype.current = function (){return this.string.slice(this.start, this.pos)};\n  StringStream.prototype.hideFirstChars = function (n, inner) {\n    this.lineStart += n;\n    try { return inner() }\n    finally { this.lineStart -= n; }\n  };\n  StringStream.prototype.lookAhead = function (n) {\n    var oracle = this.lineOracle;\n    return oracle && oracle.lookAhead(n)\n  };\n  StringStream.prototype.baseToken = function () {\n    var oracle = this.lineOracle;\n    return oracle && oracle.baseToken(this.pos)\n  };\n\n  // Find the line object corresponding to the given line number.\n  function getLine(doc, n) {\n    n -= doc.first;\n    if (n < 0 || n >= doc.size) { throw new Error(\"There is no line \" + (n + doc.first) + \" in the document.\") }\n    var chunk = doc;\n    while (!chunk.lines) {\n      for (var i = 0;; ++i) {\n        var child = chunk.children[i], sz = child.chunkSize();\n        if (n < sz) { chunk = child; break }\n        n -= sz;\n      }\n    }\n    return chunk.lines[n]\n  }\n\n  // Get the part of a document between two positions, as an array of\n  // strings.\n  function getBetween(doc, start, end) {\n    var out = [], n = start.line;\n    doc.iter(start.line, end.line + 1, function (line) {\n      var text = line.text;\n      if (n == end.line) { text = text.slice(0, end.ch); }\n      if (n == start.line) { text = text.slice(start.ch); }\n      out.push(text);\n      ++n;\n    });\n    return out\n  }\n  // Get the lines between from and to, as array of strings.\n  function getLines(doc, from, to) {\n    var out = [];\n    doc.iter(from, to, function (line) { out.push(line.text); }); // iter aborts when callback returns truthy value\n    return out\n  }\n\n  // Update the height of a line, propagating the height change\n  // upwards to parent nodes.\n  function updateLineHeight(line, height) {\n    var diff = height - line.height;\n    if (diff) { for (var n = line; n; n = n.parent) { n.height += diff; } }\n  }\n\n  // Given a line object, find its line number by walking up through\n  // its parent links.\n  function lineNo(line) {\n    if (line.parent == null) { return null }\n    var cur = line.parent, no = indexOf(cur.lines, line);\n    for (var chunk = cur.parent; chunk; cur = chunk, chunk = chunk.parent) {\n      for (var i = 0;; ++i) {\n        if (chunk.children[i] == cur) { break }\n        no += chunk.children[i].chunkSize();\n      }\n    }\n    return no + cur.first\n  }\n\n  // Find the line at the given vertical position, using the height\n  // information in the document tree.\n  function lineAtHeight(chunk, h) {\n    var n = chunk.first;\n    outer: do {\n      for (var i$1 = 0; i$1 < chunk.children.length; ++i$1) {\n        var child = chunk.children[i$1], ch = child.height;\n        if (h < ch) { chunk = child; continue outer }\n        h -= ch;\n        n += child.chunkSize();\n      }\n      return n\n    } while (!chunk.lines)\n    var i = 0;\n    for (; i < chunk.lines.length; ++i) {\n      var line = chunk.lines[i], lh = line.height;\n      if (h < lh) { break }\n      h -= lh;\n    }\n    return n + i\n  }\n\n  function isLine(doc, l) {return l >= doc.first && l < doc.first + doc.size}\n\n  function lineNumberFor(options, i) {\n    return String(options.lineNumberFormatter(i + options.firstLineNumber))\n  }\n\n  // A Pos instance represents a position within the text.\n  function Pos(line, ch, sticky) {\n    if ( sticky === void 0 ) sticky = null;\n\n    if (!(this instanceof Pos)) { return new Pos(line, ch, sticky) }\n    this.line = line;\n    this.ch = ch;\n    this.sticky = sticky;\n  }\n\n  // Compare two positions, return 0 if they are the same, a negative\n  // number when a is less, and a positive number otherwise.\n  function cmp(a, b) { return a.line - b.line || a.ch - b.ch }\n\n  function equalCursorPos(a, b) { return a.sticky == b.sticky && cmp(a, b) == 0 }\n\n  function copyPos(x) {return Pos(x.line, x.ch)}\n  function maxPos(a, b) { return cmp(a, b) < 0 ? b : a }\n  function minPos(a, b) { return cmp(a, b) < 0 ? a : b }\n\n  // Most of the external API clips given positions to make sure they\n  // actually exist within the document.\n  function clipLine(doc, n) {return Math.max(doc.first, Math.min(n, doc.first + doc.size - 1))}\n  function clipPos(doc, pos) {\n    if (pos.line < doc.first) { return Pos(doc.first, 0) }\n    var last = doc.first + doc.size - 1;\n    if (pos.line > last) { return Pos(last, getLine(doc, last).text.length) }\n    return clipToLen(pos, getLine(doc, pos.line).text.length)\n  }\n  function clipToLen(pos, linelen) {\n    var ch = pos.ch;\n    if (ch == null || ch > linelen) { return Pos(pos.line, linelen) }\n    else if (ch < 0) { return Pos(pos.line, 0) }\n    else { return pos }\n  }\n  function clipPosArray(doc, array) {\n    var out = [];\n    for (var i = 0; i < array.length; i++) { out[i] = clipPos(doc, array[i]); }\n    return out\n  }\n\n  var SavedContext = function(state, lookAhead) {\n    this.state = state;\n    this.lookAhead = lookAhead;\n  };\n\n  var Context = function(doc, state, line, lookAhead) {\n    this.state = state;\n    this.doc = doc;\n    this.line = line;\n    this.maxLookAhead = lookAhead || 0;\n    this.baseTokens = null;\n    this.baseTokenPos = 1;\n  };\n\n  Context.prototype.lookAhead = function (n) {\n    var line = this.doc.getLine(this.line + n);\n    if (line != null && n > this.maxLookAhead) { this.maxLookAhead = n; }\n    return line\n  };\n\n  Context.prototype.baseToken = function (n) {\n    if (!this.baseTokens) { return null }\n    while (this.baseTokens[this.baseTokenPos] <= n)\n      { this.baseTokenPos += 2; }\n    var type = this.baseTokens[this.baseTokenPos + 1];\n    return {type: type && type.replace(/( |^)overlay .*/, \"\"),\n            size: this.baseTokens[this.baseTokenPos] - n}\n  };\n\n  Context.prototype.nextLine = function () {\n    this.line++;\n    if (this.maxLookAhead > 0) { this.maxLookAhead--; }\n  };\n\n  Context.fromSaved = function (doc, saved, line) {\n    if (saved instanceof SavedContext)\n      { return new Context(doc, copyState(doc.mode, saved.state), line, saved.lookAhead) }\n    else\n      { return new Context(doc, copyState(doc.mode, saved), line) }\n  };\n\n  Context.prototype.save = function (copy) {\n    var state = copy !== false ? copyState(this.doc.mode, this.state) : this.state;\n    return this.maxLookAhead > 0 ? new SavedContext(state, this.maxLookAhead) : state\n  };\n\n\n  // Compute a style array (an array starting with a mode generation\n  // -- for invalidation -- followed by pairs of end positions and\n  // style strings), which is used to highlight the tokens on the\n  // line.\n  function highlightLine(cm, line, context, forceToEnd) {\n    // A styles array always starts with a number identifying the\n    // mode/overlays that it is based on (for easy invalidation).\n    var st = [cm.state.modeGen], lineClasses = {};\n    // Compute the base array of styles\n    runMode(cm, line.text, cm.doc.mode, context, function (end, style) { return st.push(end, style); },\n            lineClasses, forceToEnd);\n    var state = context.state;\n\n    // Run overlays, adjust style array.\n    var loop = function ( o ) {\n      context.baseTokens = st;\n      var overlay = cm.state.overlays[o], i = 1, at = 0;\n      context.state = true;\n      runMode(cm, line.text, overlay.mode, context, function (end, style) {\n        var start = i;\n        // Ensure there's a token end at the current position, and that i points at it\n        while (at < end) {\n          var i_end = st[i];\n          if (i_end > end)\n            { st.splice(i, 1, end, st[i+1], i_end); }\n          i += 2;\n          at = Math.min(end, i_end);\n        }\n        if (!style) { return }\n        if (overlay.opaque) {\n          st.splice(start, i - start, end, \"overlay \" + style);\n          i = start + 2;\n        } else {\n          for (; start < i; start += 2) {\n            var cur = st[start+1];\n            st[start+1] = (cur ? cur + \" \" : \"\") + \"overlay \" + style;\n          }\n        }\n      }, lineClasses);\n      context.state = state;\n      context.baseTokens = null;\n      context.baseTokenPos = 1;\n    };\n\n    for (var o = 0; o < cm.state.overlays.length; ++o) loop( o );\n\n    return {styles: st, classes: lineClasses.bgClass || lineClasses.textClass ? lineClasses : null}\n  }\n\n  function getLineStyles(cm, line, updateFrontier) {\n    if (!line.styles || line.styles[0] != cm.state.modeGen) {\n      var context = getContextBefore(cm, lineNo(line));\n      var resetState = line.text.length > cm.options.maxHighlightLength && copyState(cm.doc.mode, context.state);\n      var result = highlightLine(cm, line, context);\n      if (resetState) { context.state = resetState; }\n      line.stateAfter = context.save(!resetState);\n      line.styles = result.styles;\n      if (result.classes) { line.styleClasses = result.classes; }\n      else if (line.styleClasses) { line.styleClasses = null; }\n      if (updateFrontier === cm.doc.highlightFrontier)\n        { cm.doc.modeFrontier = Math.max(cm.doc.modeFrontier, ++cm.doc.highlightFrontier); }\n    }\n    return line.styles\n  }\n\n  function getContextBefore(cm, n, precise) {\n    var doc = cm.doc, display = cm.display;\n    if (!doc.mode.startState) { return new Context(doc, true, n) }\n    var start = findStartLine(cm, n, precise);\n    var saved = start > doc.first && getLine(doc, start - 1).stateAfter;\n    var context = saved ? Context.fromSaved(doc, saved, start) : new Context(doc, startState(doc.mode), start);\n\n    doc.iter(start, n, function (line) {\n      processLine(cm, line.text, context);\n      var pos = context.line;\n      line.stateAfter = pos == n - 1 || pos % 5 == 0 || pos >= display.viewFrom && pos < display.viewTo ? context.save() : null;\n      context.nextLine();\n    });\n    if (precise) { doc.modeFrontier = context.line; }\n    return context\n  }\n\n  // Lightweight form of highlight -- proceed over this line and\n  // update state, but don't save a style array. Used for lines that\n  // aren't currently visible.\n  function processLine(cm, text, context, startAt) {\n    var mode = cm.doc.mode;\n    var stream = new StringStream(text, cm.options.tabSize, context);\n    stream.start = stream.pos = startAt || 0;\n    if (text == \"\") { callBlankLine(mode, context.state); }\n    while (!stream.eol()) {\n      readToken(mode, stream, context.state);\n      stream.start = stream.pos;\n    }\n  }\n\n  function callBlankLine(mode, state) {\n    if (mode.blankLine) { return mode.blankLine(state) }\n    if (!mode.innerMode) { return }\n    var inner = innerMode(mode, state);\n    if (inner.mode.blankLine) { return inner.mode.blankLine(inner.state) }\n  }\n\n  function readToken(mode, stream, state, inner) {\n    for (var i = 0; i < 10; i++) {\n      if (inner) { inner[0] = innerMode(mode, state).mode; }\n      var style = mode.token(stream, state);\n      if (stream.pos > stream.start) { return style }\n    }\n    throw new Error(\"Mode \" + mode.name + \" failed to advance stream.\")\n  }\n\n  var Token = function(stream, type, state) {\n    this.start = stream.start; this.end = stream.pos;\n    this.string = stream.current();\n    this.type = type || null;\n    this.state = state;\n  };\n\n  // Utility for getTokenAt and getLineTokens\n  function takeToken(cm, pos, precise, asArray) {\n    var doc = cm.doc, mode = doc.mode, style;\n    pos = clipPos(doc, pos);\n    var line = getLine(doc, pos.line), context = getContextBefore(cm, pos.line, precise);\n    var stream = new StringStream(line.text, cm.options.tabSize, context), tokens;\n    if (asArray) { tokens = []; }\n    while ((asArray || stream.pos < pos.ch) && !stream.eol()) {\n      stream.start = stream.pos;\n      style = readToken(mode, stream, context.state);\n      if (asArray) { tokens.push(new Token(stream, style, copyState(doc.mode, context.state))); }\n    }\n    return asArray ? tokens : new Token(stream, style, context.state)\n  }\n\n  function extractLineClasses(type, output) {\n    if (type) { for (;;) {\n      var lineClass = type.match(/(?:^|\\s+)line-(background-)?(\\S+)/);\n      if (!lineClass) { break }\n      type = type.slice(0, lineClass.index) + type.slice(lineClass.index + lineClass[0].length);\n      var prop = lineClass[1] ? \"bgClass\" : \"textClass\";\n      if (output[prop] == null)\n        { output[prop] = lineClass[2]; }\n      else if (!(new RegExp(\"(?:^|\\\\s)\" + lineClass[2] + \"(?:$|\\\\s)\")).test(output[prop]))\n        { output[prop] += \" \" + lineClass[2]; }\n    } }\n    return type\n  }\n\n  // Run the given mode's parser over a line, calling f for each token.\n  function runMode(cm, text, mode, context, f, lineClasses, forceToEnd) {\n    var flattenSpans = mode.flattenSpans;\n    if (flattenSpans == null) { flattenSpans = cm.options.flattenSpans; }\n    var curStart = 0, curStyle = null;\n    var stream = new StringStream(text, cm.options.tabSize, context), style;\n    var inner = cm.options.addModeClass && [null];\n    if (text == \"\") { extractLineClasses(callBlankLine(mode, context.state), lineClasses); }\n    while (!stream.eol()) {\n      if (stream.pos > cm.options.maxHighlightLength) {\n        flattenSpans = false;\n        if (forceToEnd) { processLine(cm, text, context, stream.pos); }\n        stream.pos = text.length;\n        style = null;\n      } else {\n        style = extractLineClasses(readToken(mode, stream, context.state, inner), lineClasses);\n      }\n      if (inner) {\n        var mName = inner[0].name;\n        if (mName) { style = \"m-\" + (style ? mName + \" \" + style : mName); }\n      }\n      if (!flattenSpans || curStyle != style) {\n        while (curStart < stream.start) {\n          curStart = Math.min(stream.start, curStart + 5000);\n          f(curStart, curStyle);\n        }\n        curStyle = style;\n      }\n      stream.start = stream.pos;\n    }\n    while (curStart < stream.pos) {\n      // Webkit seems to refuse to render text nodes longer than 57444\n      // characters, and returns inaccurate measurements in nodes\n      // starting around 5000 chars.\n      var pos = Math.min(stream.pos, curStart + 5000);\n      f(pos, curStyle);\n      curStart = pos;\n    }\n  }\n\n  // Finds the line to start with when starting a parse. Tries to\n  // find a line with a stateAfter, so that it can start with a\n  // valid state. If that fails, it returns the line with the\n  // smallest indentation, which tends to need the least context to\n  // parse correctly.\n  function findStartLine(cm, n, precise) {\n    var minindent, minline, doc = cm.doc;\n    var lim = precise ? -1 : n - (cm.doc.mode.innerMode ? 1000 : 100);\n    for (var search = n; search > lim; --search) {\n      if (search <= doc.first) { return doc.first }\n      var line = getLine(doc, search - 1), after = line.stateAfter;\n      if (after && (!precise || search + (after instanceof SavedContext ? after.lookAhead : 0) <= doc.modeFrontier))\n        { return search }\n      var indented = countColumn(line.text, null, cm.options.tabSize);\n      if (minline == null || minindent > indented) {\n        minline = search - 1;\n        minindent = indented;\n      }\n    }\n    return minline\n  }\n\n  function retreatFrontier(doc, n) {\n    doc.modeFrontier = Math.min(doc.modeFrontier, n);\n    if (doc.highlightFrontier < n - 10) { return }\n    var start = doc.first;\n    for (var line = n - 1; line > start; line--) {\n      var saved = getLine(doc, line).stateAfter;\n      // change is on 3\n      // state on line 1 looked ahead 2 -- so saw 3\n      // test 1 + 2 < 3 should cover this\n      if (saved && (!(saved instanceof SavedContext) || line + saved.lookAhead < n)) {\n        start = line + 1;\n        break\n      }\n    }\n    doc.highlightFrontier = Math.min(doc.highlightFrontier, start);\n  }\n\n  // Optimize some code when these features are not used.\n  var sawReadOnlySpans = false, sawCollapsedSpans = false;\n\n  function seeReadOnlySpans() {\n    sawReadOnlySpans = true;\n  }\n\n  function seeCollapsedSpans() {\n    sawCollapsedSpans = true;\n  }\n\n  // TEXTMARKER SPANS\n\n  function MarkedSpan(marker, from, to) {\n    this.marker = marker;\n    this.from = from; this.to = to;\n  }\n\n  // Search an array of spans for a span matching the given marker.\n  function getMarkedSpanFor(spans, marker) {\n    if (spans) { for (var i = 0; i < spans.length; ++i) {\n      var span = spans[i];\n      if (span.marker == marker) { return span }\n    } }\n  }\n\n  // Remove a span from an array, returning undefined if no spans are\n  // left (we don't store arrays for lines without spans).\n  function removeMarkedSpan(spans, span) {\n    var r;\n    for (var i = 0; i < spans.length; ++i)\n      { if (spans[i] != span) { (r || (r = [])).push(spans[i]); } }\n    return r\n  }\n\n  // Add a span to a line.\n  function addMarkedSpan(line, span, op) {\n    var inThisOp = op && window.WeakSet && (op.markedSpans || (op.markedSpans = new WeakSet));\n    if (inThisOp && line.markedSpans && inThisOp.has(line.markedSpans)) {\n      line.markedSpans.push(span);\n    } else {\n      line.markedSpans = line.markedSpans ? line.markedSpans.concat([span]) : [span];\n      if (inThisOp) { inThisOp.add(line.markedSpans); }\n    }\n    span.marker.attachLine(line);\n  }\n\n  // Used for the algorithm that adjusts markers for a change in the\n  // document. These functions cut an array of spans at a given\n  // character position, returning an array of remaining chunks (or\n  // undefined if nothing remains).\n  function markedSpansBefore(old, startCh, isInsert) {\n    var nw;\n    if (old) { for (var i = 0; i < old.length; ++i) {\n      var span = old[i], marker = span.marker;\n      var startsBefore = span.from == null || (marker.inclusiveLeft ? span.from <= startCh : span.from < startCh);\n      if (startsBefore || span.from == startCh && marker.type == \"bookmark\" && (!isInsert || !span.marker.insertLeft)) {\n        var endsAfter = span.to == null || (marker.inclusiveRight ? span.to >= startCh : span.to > startCh)\n        ;(nw || (nw = [])).push(new MarkedSpan(marker, span.from, endsAfter ? null : span.to));\n      }\n    } }\n    return nw\n  }\n  function markedSpansAfter(old, endCh, isInsert) {\n    var nw;\n    if (old) { for (var i = 0; i < old.length; ++i) {\n      var span = old[i], marker = span.marker;\n      var endsAfter = span.to == null || (marker.inclusiveRight ? span.to >= endCh : span.to > endCh);\n      if (endsAfter || span.from == endCh && marker.type == \"bookmark\" && (!isInsert || span.marker.insertLeft)) {\n        var startsBefore = span.from == null || (marker.inclusiveLeft ? span.from <= endCh : span.from < endCh)\n        ;(nw || (nw = [])).push(new MarkedSpan(marker, startsBefore ? null : span.from - endCh,\n                                              span.to == null ? null : span.to - endCh));\n      }\n    } }\n    return nw\n  }\n\n  // Given a change object, compute the new set of marker spans that\n  // cover the line in which the change took place. Removes spans\n  // entirely within the change, reconnects spans belonging to the\n  // same marker that appear on both sides of the change, and cuts off\n  // spans partially within the change. Returns an array of span\n  // arrays with one element for each line in (after) the change.\n  function stretchSpansOverChange(doc, change) {\n    if (change.full) { return null }\n    var oldFirst = isLine(doc, change.from.line) && getLine(doc, change.from.line).markedSpans;\n    var oldLast = isLine(doc, change.to.line) && getLine(doc, change.to.line).markedSpans;\n    if (!oldFirst && !oldLast) { return null }\n\n    var startCh = change.from.ch, endCh = change.to.ch, isInsert = cmp(change.from, change.to) == 0;\n    // Get the spans that 'stick out' on both sides\n    var first = markedSpansBefore(oldFirst, startCh, isInsert);\n    var last = markedSpansAfter(oldLast, endCh, isInsert);\n\n    // Next, merge those two ends\n    var sameLine = change.text.length == 1, offset = lst(change.text).length + (sameLine ? startCh : 0);\n    if (first) {\n      // Fix up .to properties of first\n      for (var i = 0; i < first.length; ++i) {\n        var span = first[i];\n        if (span.to == null) {\n          var found = getMarkedSpanFor(last, span.marker);\n          if (!found) { span.to = startCh; }\n          else if (sameLine) { span.to = found.to == null ? null : found.to + offset; }\n        }\n      }\n    }\n    if (last) {\n      // Fix up .from in last (or move them into first in case of sameLine)\n      for (var i$1 = 0; i$1 < last.length; ++i$1) {\n        var span$1 = last[i$1];\n        if (span$1.to != null) { span$1.to += offset; }\n        if (span$1.from == null) {\n          var found$1 = getMarkedSpanFor(first, span$1.marker);\n          if (!found$1) {\n            span$1.from = offset;\n            if (sameLine) { (first || (first = [])).push(span$1); }\n          }\n        } else {\n          span$1.from += offset;\n          if (sameLine) { (first || (first = [])).push(span$1); }\n        }\n      }\n    }\n    // Make sure we didn't create any zero-length spans\n    if (first) { first = clearEmptySpans(first); }\n    if (last && last != first) { last = clearEmptySpans(last); }\n\n    var newMarkers = [first];\n    if (!sameLine) {\n      // Fill gap with whole-line-spans\n      var gap = change.text.length - 2, gapMarkers;\n      if (gap > 0 && first)\n        { for (var i$2 = 0; i$2 < first.length; ++i$2)\n          { if (first[i$2].to == null)\n            { (gapMarkers || (gapMarkers = [])).push(new MarkedSpan(first[i$2].marker, null, null)); } } }\n      for (var i$3 = 0; i$3 < gap; ++i$3)\n        { newMarkers.push(gapMarkers); }\n      newMarkers.push(last);\n    }\n    return newMarkers\n  }\n\n  // Remove spans that are empty and don't have a clearWhenEmpty\n  // option of false.\n  function clearEmptySpans(spans) {\n    for (var i = 0; i < spans.length; ++i) {\n      var span = spans[i];\n      if (span.from != null && span.from == span.to && span.marker.clearWhenEmpty !== false)\n        { spans.splice(i--, 1); }\n    }\n    if (!spans.length) { return null }\n    return spans\n  }\n\n  // Used to 'clip' out readOnly ranges when making a change.\n  function removeReadOnlyRanges(doc, from, to) {\n    var markers = null;\n    doc.iter(from.line, to.line + 1, function (line) {\n      if (line.markedSpans) { for (var i = 0; i < line.markedSpans.length; ++i) {\n        var mark = line.markedSpans[i].marker;\n        if (mark.readOnly && (!markers || indexOf(markers, mark) == -1))\n          { (markers || (markers = [])).push(mark); }\n      } }\n    });\n    if (!markers) { return null }\n    var parts = [{from: from, to: to}];\n    for (var i = 0; i < markers.length; ++i) {\n      var mk = markers[i], m = mk.find(0);\n      for (var j = 0; j < parts.length; ++j) {\n        var p = parts[j];\n        if (cmp(p.to, m.from) < 0 || cmp(p.from, m.to) > 0) { continue }\n        var newParts = [j, 1], dfrom = cmp(p.from, m.from), dto = cmp(p.to, m.to);\n        if (dfrom < 0 || !mk.inclusiveLeft && !dfrom)\n          { newParts.push({from: p.from, to: m.from}); }\n        if (dto > 0 || !mk.inclusiveRight && !dto)\n          { newParts.push({from: m.to, to: p.to}); }\n        parts.splice.apply(parts, newParts);\n        j += newParts.length - 3;\n      }\n    }\n    return parts\n  }\n\n  // Connect or disconnect spans from a line.\n  function detachMarkedSpans(line) {\n    var spans = line.markedSpans;\n    if (!spans) { return }\n    for (var i = 0; i < spans.length; ++i)\n      { spans[i].marker.detachLine(line); }\n    line.markedSpans = null;\n  }\n  function attachMarkedSpans(line, spans) {\n    if (!spans) { return }\n    for (var i = 0; i < spans.length; ++i)\n      { spans[i].marker.attachLine(line); }\n    line.markedSpans = spans;\n  }\n\n  // Helpers used when computing which overlapping collapsed span\n  // counts as the larger one.\n  function extraLeft(marker) { return marker.inclusiveLeft ? -1 : 0 }\n  function extraRight(marker) { return marker.inclusiveRight ? 1 : 0 }\n\n  // Returns a number indicating which of two overlapping collapsed\n  // spans is larger (and thus includes the other). Falls back to\n  // comparing ids when the spans cover exactly the same range.\n  function compareCollapsedMarkers(a, b) {\n    var lenDiff = a.lines.length - b.lines.length;\n    if (lenDiff != 0) { return lenDiff }\n    var aPos = a.find(), bPos = b.find();\n    var fromCmp = cmp(aPos.from, bPos.from) || extraLeft(a) - extraLeft(b);\n    if (fromCmp) { return -fromCmp }\n    var toCmp = cmp(aPos.to, bPos.to) || extraRight(a) - extraRight(b);\n    if (toCmp) { return toCmp }\n    return b.id - a.id\n  }\n\n  // Find out whether a line ends or starts in a collapsed span. If\n  // so, return the marker for that span.\n  function collapsedSpanAtSide(line, start) {\n    var sps = sawCollapsedSpans && line.markedSpans, found;\n    if (sps) { for (var sp = (void 0), i = 0; i < sps.length; ++i) {\n      sp = sps[i];\n      if (sp.marker.collapsed && (start ? sp.from : sp.to) == null &&\n          (!found || compareCollapsedMarkers(found, sp.marker) < 0))\n        { found = sp.marker; }\n    } }\n    return found\n  }\n  function collapsedSpanAtStart(line) { return collapsedSpanAtSide(line, true) }\n  function collapsedSpanAtEnd(line) { return collapsedSpanAtSide(line, false) }\n\n  function collapsedSpanAround(line, ch) {\n    var sps = sawCollapsedSpans && line.markedSpans, found;\n    if (sps) { for (var i = 0; i < sps.length; ++i) {\n      var sp = sps[i];\n      if (sp.marker.collapsed && (sp.from == null || sp.from < ch) && (sp.to == null || sp.to > ch) &&\n          (!found || compareCollapsedMarkers(found, sp.marker) < 0)) { found = sp.marker; }\n    } }\n    return found\n  }\n\n  // Test whether there exists a collapsed span that partially\n  // overlaps (covers the start or end, but not both) of a new span.\n  // Such overlap is not allowed.\n  function conflictingCollapsedRange(doc, lineNo, from, to, marker) {\n    var line = getLine(doc, lineNo);\n    var sps = sawCollapsedSpans && line.markedSpans;\n    if (sps) { for (var i = 0; i < sps.length; ++i) {\n      var sp = sps[i];\n      if (!sp.marker.collapsed) { continue }\n      var found = sp.marker.find(0);\n      var fromCmp = cmp(found.from, from) || extraLeft(sp.marker) - extraLeft(marker);\n      var toCmp = cmp(found.to, to) || extraRight(sp.marker) - extraRight(marker);\n      if (fromCmp >= 0 && toCmp <= 0 || fromCmp <= 0 && toCmp >= 0) { continue }\n      if (fromCmp <= 0 && (sp.marker.inclusiveRight && marker.inclusiveLeft ? cmp(found.to, from) >= 0 : cmp(found.to, from) > 0) ||\n          fromCmp >= 0 && (sp.marker.inclusiveRight && marker.inclusiveLeft ? cmp(found.from, to) <= 0 : cmp(found.from, to) < 0))\n        { return true }\n    } }\n  }\n\n  // A visual line is a line as drawn on the screen. Folding, for\n  // example, can cause multiple logical lines to appear on the same\n  // visual line. This finds the start of the visual line that the\n  // given line is part of (usually that is the line itself).\n  function visualLine(line) {\n    var merged;\n    while (merged = collapsedSpanAtStart(line))\n      { line = merged.find(-1, true).line; }\n    return line\n  }\n\n  function visualLineEnd(line) {\n    var merged;\n    while (merged = collapsedSpanAtEnd(line))\n      { line = merged.find(1, true).line; }\n    return line\n  }\n\n  // Returns an array of logical lines that continue the visual line\n  // started by the argument, or undefined if there are no such lines.\n  function visualLineContinued(line) {\n    var merged, lines;\n    while (merged = collapsedSpanAtEnd(line)) {\n      line = merged.find(1, true).line\n      ;(lines || (lines = [])).push(line);\n    }\n    return lines\n  }\n\n  // Get the line number of the start of the visual line that the\n  // given line number is part of.\n  function visualLineNo(doc, lineN) {\n    var line = getLine(doc, lineN), vis = visualLine(line);\n    if (line == vis) { return lineN }\n    return lineNo(vis)\n  }\n\n  // Get the line number of the start of the next visual line after\n  // the given line.\n  function visualLineEndNo(doc, lineN) {\n    if (lineN > doc.lastLine()) { return lineN }\n    var line = getLine(doc, lineN), merged;\n    if (!lineIsHidden(doc, line)) { return lineN }\n    while (merged = collapsedSpanAtEnd(line))\n      { line = merged.find(1, true).line; }\n    return lineNo(line) + 1\n  }\n\n  // Compute whether a line is hidden. Lines count as hidden when they\n  // are part of a visual line that starts with another line, or when\n  // they are entirely covered by collapsed, non-widget span.\n  function lineIsHidden(doc, line) {\n    var sps = sawCollapsedSpans && line.markedSpans;\n    if (sps) { for (var sp = (void 0), i = 0; i < sps.length; ++i) {\n      sp = sps[i];\n      if (!sp.marker.collapsed) { continue }\n      if (sp.from == null) { return true }\n      if (sp.marker.widgetNode) { continue }\n      if (sp.from == 0 && sp.marker.inclusiveLeft && lineIsHiddenInner(doc, line, sp))\n        { return true }\n    } }\n  }\n  function lineIsHiddenInner(doc, line, span) {\n    if (span.to == null) {\n      var end = span.marker.find(1, true);\n      return lineIsHiddenInner(doc, end.line, getMarkedSpanFor(end.line.markedSpans, span.marker))\n    }\n    if (span.marker.inclusiveRight && span.to == line.text.length)\n      { return true }\n    for (var sp = (void 0), i = 0; i < line.markedSpans.length; ++i) {\n      sp = line.markedSpans[i];\n      if (sp.marker.collapsed && !sp.marker.widgetNode && sp.from == span.to &&\n          (sp.to == null || sp.to != span.from) &&\n          (sp.marker.inclusiveLeft || span.marker.inclusiveRight) &&\n          lineIsHiddenInner(doc, line, sp)) { return true }\n    }\n  }\n\n  // Find the height above the given line.\n  function heightAtLine(lineObj) {\n    lineObj = visualLine(lineObj);\n\n    var h = 0, chunk = lineObj.parent;\n    for (var i = 0; i < chunk.lines.length; ++i) {\n      var line = chunk.lines[i];\n      if (line == lineObj) { break }\n      else { h += line.height; }\n    }\n    for (var p = chunk.parent; p; chunk = p, p = chunk.parent) {\n      for (var i$1 = 0; i$1 < p.children.length; ++i$1) {\n        var cur = p.children[i$1];\n        if (cur == chunk) { break }\n        else { h += cur.height; }\n      }\n    }\n    return h\n  }\n\n  // Compute the character length of a line, taking into account\n  // collapsed ranges (see markText) that might hide parts, and join\n  // other lines onto it.\n  function lineLength(line) {\n    if (line.height == 0) { return 0 }\n    var len = line.text.length, merged, cur = line;\n    while (merged = collapsedSpanAtStart(cur)) {\n      var found = merged.find(0, true);\n      cur = found.from.line;\n      len += found.from.ch - found.to.ch;\n    }\n    cur = line;\n    while (merged = collapsedSpanAtEnd(cur)) {\n      var found$1 = merged.find(0, true);\n      len -= cur.text.length - found$1.from.ch;\n      cur = found$1.to.line;\n      len += cur.text.length - found$1.to.ch;\n    }\n    return len\n  }\n\n  // Find the longest line in the document.\n  function findMaxLine(cm) {\n    var d = cm.display, doc = cm.doc;\n    d.maxLine = getLine(doc, doc.first);\n    d.maxLineLength = lineLength(d.maxLine);\n    d.maxLineChanged = true;\n    doc.iter(function (line) {\n      var len = lineLength(line);\n      if (len > d.maxLineLength) {\n        d.maxLineLength = len;\n        d.maxLine = line;\n      }\n    });\n  }\n\n  // LINE DATA STRUCTURE\n\n  // Line objects. These hold state related to a line, including\n  // highlighting info (the styles array).\n  var Line = function(text, markedSpans, estimateHeight) {\n    this.text = text;\n    attachMarkedSpans(this, markedSpans);\n    this.height = estimateHeight ? estimateHeight(this) : 1;\n  };\n\n  Line.prototype.lineNo = function () { return lineNo(this) };\n  eventMixin(Line);\n\n  // Change the content (text, markers) of a line. Automatically\n  // invalidates cached information and tries to re-estimate the\n  // line's height.\n  function updateLine(line, text, markedSpans, estimateHeight) {\n    line.text = text;\n    if (line.stateAfter) { line.stateAfter = null; }\n    if (line.styles) { line.styles = null; }\n    if (line.order != null) { line.order = null; }\n    detachMarkedSpans(line);\n    attachMarkedSpans(line, markedSpans);\n    var estHeight = estimateHeight ? estimateHeight(line) : 1;\n    if (estHeight != line.height) { updateLineHeight(line, estHeight); }\n  }\n\n  // Detach a line from the document tree and its markers.\n  function cleanUpLine(line) {\n    line.parent = null;\n    detachMarkedSpans(line);\n  }\n\n  // Convert a style as returned by a mode (either null, or a string\n  // containing one or more styles) to a CSS style. This is cached,\n  // and also looks for line-wide styles.\n  var styleToClassCache = {}, styleToClassCacheWithMode = {};\n  function interpretTokenStyle(style, options) {\n    if (!style || /^\\s*$/.test(style)) { return null }\n    var cache = options.addModeClass ? styleToClassCacheWithMode : styleToClassCache;\n    return cache[style] ||\n      (cache[style] = style.replace(/\\S+/g, \"cm-$&\"))\n  }\n\n  // Render the DOM representation of the text of a line. Also builds\n  // up a 'line map', which points at the DOM nodes that represent\n  // specific stretches of text, and is used by the measuring code.\n  // The returned object contains the DOM node, this map, and\n  // information about line-wide styles that were set by the mode.\n  function buildLineContent(cm, lineView) {\n    // The padding-right forces the element to have a 'border', which\n    // is needed on Webkit to be able to get line-level bounding\n    // rectangles for it (in measureChar).\n    var content = eltP(\"span\", null, null, webkit ? \"padding-right: .1px\" : null);\n    var builder = {pre: eltP(\"pre\", [content], \"CodeMirror-line\"), content: content,\n                   col: 0, pos: 0, cm: cm,\n                   trailingSpace: false,\n                   splitSpaces: cm.getOption(\"lineWrapping\")};\n    lineView.measure = {};\n\n    // Iterate over the logical lines that make up this visual line.\n    for (var i = 0; i <= (lineView.rest ? lineView.rest.length : 0); i++) {\n      var line = i ? lineView.rest[i - 1] : lineView.line, order = (void 0);\n      builder.pos = 0;\n      builder.addToken = buildToken;\n      // Optionally wire in some hacks into the token-rendering\n      // algorithm, to deal with browser quirks.\n      if (hasBadBidiRects(cm.display.measure) && (order = getOrder(line, cm.doc.direction)))\n        { builder.addToken = buildTokenBadBidi(builder.addToken, order); }\n      builder.map = [];\n      var allowFrontierUpdate = lineView != cm.display.externalMeasured && lineNo(line);\n      insertLineContent(line, builder, getLineStyles(cm, line, allowFrontierUpdate));\n      if (line.styleClasses) {\n        if (line.styleClasses.bgClass)\n          { builder.bgClass = joinClasses(line.styleClasses.bgClass, builder.bgClass || \"\"); }\n        if (line.styleClasses.textClass)\n          { builder.textClass = joinClasses(line.styleClasses.textClass, builder.textClass || \"\"); }\n      }\n\n      // Ensure at least a single node is present, for measuring.\n      if (builder.map.length == 0)\n        { builder.map.push(0, 0, builder.content.appendChild(zeroWidthElement(cm.display.measure))); }\n\n      // Store the map and a cache object for the current logical line\n      if (i == 0) {\n        lineView.measure.map = builder.map;\n        lineView.measure.cache = {};\n      } else {\n  (lineView.measure.maps || (lineView.measure.maps = [])).push(builder.map)\n        ;(lineView.measure.caches || (lineView.measure.caches = [])).push({});\n      }\n    }\n\n    // See issue #2901\n    if (webkit) {\n      var last = builder.content.lastChild;\n      if (/\\bcm-tab\\b/.test(last.className) || (last.querySelector && last.querySelector(\".cm-tab\")))\n        { builder.content.className = \"cm-tab-wrap-hack\"; }\n    }\n\n    signal(cm, \"renderLine\", cm, lineView.line, builder.pre);\n    if (builder.pre.className)\n      { builder.textClass = joinClasses(builder.pre.className, builder.textClass || \"\"); }\n\n    return builder\n  }\n\n  function defaultSpecialCharPlaceholder(ch) {\n    var token = elt(\"span\", \"\\u2022\", \"cm-invalidchar\");\n    token.title = \"\\\\u\" + ch.charCodeAt(0).toString(16);\n    token.setAttribute(\"aria-label\", token.title);\n    return token\n  }\n\n  // Build up the DOM representation for a single token, and add it to\n  // the line map. Takes care to render special characters separately.\n  function buildToken(builder, text, style, startStyle, endStyle, css, attributes) {\n    if (!text) { return }\n    var displayText = builder.splitSpaces ? splitSpaces(text, builder.trailingSpace) : text;\n    var special = builder.cm.state.specialChars, mustWrap = false;\n    var content;\n    if (!special.test(text)) {\n      builder.col += text.length;\n      content = document.createTextNode(displayText);\n      builder.map.push(builder.pos, builder.pos + text.length, content);\n      if (ie && ie_version < 9) { mustWrap = true; }\n      builder.pos += text.length;\n    } else {\n      content = document.createDocumentFragment();\n      var pos = 0;\n      while (true) {\n        special.lastIndex = pos;\n        var m = special.exec(text);\n        var skipped = m ? m.index - pos : text.length - pos;\n        if (skipped) {\n          var txt = document.createTextNode(displayText.slice(pos, pos + skipped));\n          if (ie && ie_version < 9) { content.appendChild(elt(\"span\", [txt])); }\n          else { content.appendChild(txt); }\n          builder.map.push(builder.pos, builder.pos + skipped, txt);\n          builder.col += skipped;\n          builder.pos += skipped;\n        }\n        if (!m) { break }\n        pos += skipped + 1;\n        var txt$1 = (void 0);\n        if (m[0] == \"\\t\") {\n          var tabSize = builder.cm.options.tabSize, tabWidth = tabSize - builder.col % tabSize;\n          txt$1 = content.appendChild(elt(\"span\", spaceStr(tabWidth), \"cm-tab\"));\n          txt$1.setAttribute(\"role\", \"presentation\");\n          txt$1.setAttribute(\"cm-text\", \"\\t\");\n          builder.col += tabWidth;\n        } else if (m[0] == \"\\r\" || m[0] == \"\\n\") {\n          txt$1 = content.appendChild(elt(\"span\", m[0] == \"\\r\" ? \"\\u240d\" : \"\\u2424\", \"cm-invalidchar\"));\n          txt$1.setAttribute(\"cm-text\", m[0]);\n          builder.col += 1;\n        } else {\n          txt$1 = builder.cm.options.specialCharPlaceholder(m[0]);\n          txt$1.setAttribute(\"cm-text\", m[0]);\n          if (ie && ie_version < 9) { content.appendChild(elt(\"span\", [txt$1])); }\n          else { content.appendChild(txt$1); }\n          builder.col += 1;\n        }\n        builder.map.push(builder.pos, builder.pos + 1, txt$1);\n        builder.pos++;\n      }\n    }\n    builder.trailingSpace = displayText.charCodeAt(text.length - 1) == 32;\n    if (style || startStyle || endStyle || mustWrap || css || attributes) {\n      var fullStyle = style || \"\";\n      if (startStyle) { fullStyle += startStyle; }\n      if (endStyle) { fullStyle += endStyle; }\n      var token = elt(\"span\", [content], fullStyle, css);\n      if (attributes) {\n        for (var attr in attributes) { if (attributes.hasOwnProperty(attr) && attr != \"style\" && attr != \"class\")\n          { token.setAttribute(attr, attributes[attr]); } }\n      }\n      return builder.content.appendChild(token)\n    }\n    builder.content.appendChild(content);\n  }\n\n  // Change some spaces to NBSP to prevent the browser from collapsing\n  // trailing spaces at the end of a line when rendering text (issue #1362).\n  function splitSpaces(text, trailingBefore) {\n    if (text.length > 1 && !/  /.test(text)) { return text }\n    var spaceBefore = trailingBefore, result = \"\";\n    for (var i = 0; i < text.length; i++) {\n      var ch = text.charAt(i);\n      if (ch == \" \" && spaceBefore && (i == text.length - 1 || text.charCodeAt(i + 1) == 32))\n        { ch = \"\\u00a0\"; }\n      result += ch;\n      spaceBefore = ch == \" \";\n    }\n    return result\n  }\n\n  // Work around nonsense dimensions being reported for stretches of\n  // right-to-left text.\n  function buildTokenBadBidi(inner, order) {\n    return function (builder, text, style, startStyle, endStyle, css, attributes) {\n      style = style ? style + \" cm-force-border\" : \"cm-force-border\";\n      var start = builder.pos, end = start + text.length;\n      for (;;) {\n        // Find the part that overlaps with the start of this text\n        var part = (void 0);\n        for (var i = 0; i < order.length; i++) {\n          part = order[i];\n          if (part.to > start && part.from <= start) { break }\n        }\n        if (part.to >= end) { return inner(builder, text, style, startStyle, endStyle, css, attributes) }\n        inner(builder, text.slice(0, part.to - start), style, startStyle, null, css, attributes);\n        startStyle = null;\n        text = text.slice(part.to - start);\n        start = part.to;\n      }\n    }\n  }\n\n  function buildCollapsedSpan(builder, size, marker, ignoreWidget) {\n    var widget = !ignoreWidget && marker.widgetNode;\n    if (widget) { builder.map.push(builder.pos, builder.pos + size, widget); }\n    if (!ignoreWidget && builder.cm.display.input.needsContentAttribute) {\n      if (!widget)\n        { widget = builder.content.appendChild(document.createElement(\"span\")); }\n      widget.setAttribute(\"cm-marker\", marker.id);\n    }\n    if (widget) {\n      builder.cm.display.input.setUneditable(widget);\n      builder.content.appendChild(widget);\n    }\n    builder.pos += size;\n    builder.trailingSpace = false;\n  }\n\n  // Outputs a number of spans to make up a line, taking highlighting\n  // and marked text into account.\n  function insertLineContent(line, builder, styles) {\n    var spans = line.markedSpans, allText = line.text, at = 0;\n    if (!spans) {\n      for (var i$1 = 1; i$1 < styles.length; i$1+=2)\n        { builder.addToken(builder, allText.slice(at, at = styles[i$1]), interpretTokenStyle(styles[i$1+1], builder.cm.options)); }\n      return\n    }\n\n    var len = allText.length, pos = 0, i = 1, text = \"\", style, css;\n    var nextChange = 0, spanStyle, spanEndStyle, spanStartStyle, collapsed, attributes;\n    for (;;) {\n      if (nextChange == pos) { // Update current marker set\n        spanStyle = spanEndStyle = spanStartStyle = css = \"\";\n        attributes = null;\n        collapsed = null; nextChange = Infinity;\n        var foundBookmarks = [], endStyles = (void 0);\n        for (var j = 0; j < spans.length; ++j) {\n          var sp = spans[j], m = sp.marker;\n          if (m.type == \"bookmark\" && sp.from == pos && m.widgetNode) {\n            foundBookmarks.push(m);\n          } else if (sp.from <= pos && (sp.to == null || sp.to > pos || m.collapsed && sp.to == pos && sp.from == pos)) {\n            if (sp.to != null && sp.to != pos && nextChange > sp.to) {\n              nextChange = sp.to;\n              spanEndStyle = \"\";\n            }\n            if (m.className) { spanStyle += \" \" + m.className; }\n            if (m.css) { css = (css ? css + \";\" : \"\") + m.css; }\n            if (m.startStyle && sp.from == pos) { spanStartStyle += \" \" + m.startStyle; }\n            if (m.endStyle && sp.to == nextChange) { (endStyles || (endStyles = [])).push(m.endStyle, sp.to); }\n            // support for the old title property\n            // https://github.com/codemirror/CodeMirror/pull/5673\n            if (m.title) { (attributes || (attributes = {})).title = m.title; }\n            if (m.attributes) {\n              for (var attr in m.attributes)\n                { (attributes || (attributes = {}))[attr] = m.attributes[attr]; }\n            }\n            if (m.collapsed && (!collapsed || compareCollapsedMarkers(collapsed.marker, m) < 0))\n              { collapsed = sp; }\n          } else if (sp.from > pos && nextChange > sp.from) {\n            nextChange = sp.from;\n          }\n        }\n        if (endStyles) { for (var j$1 = 0; j$1 < endStyles.length; j$1 += 2)\n          { if (endStyles[j$1 + 1] == nextChange) { spanEndStyle += \" \" + endStyles[j$1]; } } }\n\n        if (!collapsed || collapsed.from == pos) { for (var j$2 = 0; j$2 < foundBookmarks.length; ++j$2)\n          { buildCollapsedSpan(builder, 0, foundBookmarks[j$2]); } }\n        if (collapsed && (collapsed.from || 0) == pos) {\n          buildCollapsedSpan(builder, (collapsed.to == null ? len + 1 : collapsed.to) - pos,\n                             collapsed.marker, collapsed.from == null);\n          if (collapsed.to == null) { return }\n          if (collapsed.to == pos) { collapsed = false; }\n        }\n      }\n      if (pos >= len) { break }\n\n      var upto = Math.min(len, nextChange);\n      while (true) {\n        if (text) {\n          var end = pos + text.length;\n          if (!collapsed) {\n            var tokenText = end > upto ? text.slice(0, upto - pos) : text;\n            builder.addToken(builder, tokenText, style ? style + spanStyle : spanStyle,\n                             spanStartStyle, pos + tokenText.length == nextChange ? spanEndStyle : \"\", css, attributes);\n          }\n          if (end >= upto) {text = text.slice(upto - pos); pos = upto; break}\n          pos = end;\n          spanStartStyle = \"\";\n        }\n        text = allText.slice(at, at = styles[i++]);\n        style = interpretTokenStyle(styles[i++], builder.cm.options);\n      }\n    }\n  }\n\n\n  // These objects are used to represent the visible (currently drawn)\n  // part of the document. A LineView may correspond to multiple\n  // logical lines, if those are connected by collapsed ranges.\n  function LineView(doc, line, lineN) {\n    // The starting line\n    this.line = line;\n    // Continuing lines, if any\n    this.rest = visualLineContinued(line);\n    // Number of logical lines in this visual line\n    this.size = this.rest ? lineNo(lst(this.rest)) - lineN + 1 : 1;\n    this.node = this.text = null;\n    this.hidden = lineIsHidden(doc, line);\n  }\n\n  // Create a range of LineView objects for the given lines.\n  function buildViewArray(cm, from, to) {\n    var array = [], nextPos;\n    for (var pos = from; pos < to; pos = nextPos) {\n      var view = new LineView(cm.doc, getLine(cm.doc, pos), pos);\n      nextPos = pos + view.size;\n      array.push(view);\n    }\n    return array\n  }\n\n  var operationGroup = null;\n\n  function pushOperation(op) {\n    if (operationGroup) {\n      operationGroup.ops.push(op);\n    } else {\n      op.ownsGroup = operationGroup = {\n        ops: [op],\n        delayedCallbacks: []\n      };\n    }\n  }\n\n  function fireCallbacksForOps(group) {\n    // Calls delayed callbacks and cursorActivity handlers until no\n    // new ones appear\n    var callbacks = group.delayedCallbacks, i = 0;\n    do {\n      for (; i < callbacks.length; i++)\n        { callbacks[i].call(null); }\n      for (var j = 0; j < group.ops.length; j++) {\n        var op = group.ops[j];\n        if (op.cursorActivityHandlers)\n          { while (op.cursorActivityCalled < op.cursorActivityHandlers.length)\n            { op.cursorActivityHandlers[op.cursorActivityCalled++].call(null, op.cm); } }\n      }\n    } while (i < callbacks.length)\n  }\n\n  function finishOperation(op, endCb) {\n    var group = op.ownsGroup;\n    if (!group) { return }\n\n    try { fireCallbacksForOps(group); }\n    finally {\n      operationGroup = null;\n      endCb(group);\n    }\n  }\n\n  var orphanDelayedCallbacks = null;\n\n  // Often, we want to signal events at a point where we are in the\n  // middle of some work, but don't want the handler to start calling\n  // other methods on the editor, which might be in an inconsistent\n  // state or simply not expect any other events to happen.\n  // signalLater looks whether there are any handlers, and schedules\n  // them to be executed when the last operation ends, or, if no\n  // operation is active, when a timeout fires.\n  function signalLater(emitter, type /*, values...*/) {\n    var arr = getHandlers(emitter, type);\n    if (!arr.length) { return }\n    var args = Array.prototype.slice.call(arguments, 2), list;\n    if (operationGroup) {\n      list = operationGroup.delayedCallbacks;\n    } else if (orphanDelayedCallbacks) {\n      list = orphanDelayedCallbacks;\n    } else {\n      list = orphanDelayedCallbacks = [];\n      setTimeout(fireOrphanDelayed, 0);\n    }\n    var loop = function ( i ) {\n      list.push(function () { return arr[i].apply(null, args); });\n    };\n\n    for (var i = 0; i < arr.length; ++i)\n      loop( i );\n  }\n\n  function fireOrphanDelayed() {\n    var delayed = orphanDelayedCallbacks;\n    orphanDelayedCallbacks = null;\n    for (var i = 0; i < delayed.length; ++i) { delayed[i](); }\n  }\n\n  // When an aspect of a line changes, a string is added to\n  // lineView.changes. This updates the relevant part of the line's\n  // DOM structure.\n  function updateLineForChanges(cm, lineView, lineN, dims) {\n    for (var j = 0; j < lineView.changes.length; j++) {\n      var type = lineView.changes[j];\n      if (type == \"text\") { updateLineText(cm, lineView); }\n      else if (type == \"gutter\") { updateLineGutter(cm, lineView, lineN, dims); }\n      else if (type == \"class\") { updateLineClasses(cm, lineView); }\n      else if (type == \"widget\") { updateLineWidgets(cm, lineView, dims); }\n    }\n    lineView.changes = null;\n  }\n\n  // Lines with gutter elements, widgets or a background class need to\n  // be wrapped, and have the extra elements added to the wrapper div\n  function ensureLineWrapped(lineView) {\n    if (lineView.node == lineView.text) {\n      lineView.node = elt(\"div\", null, null, \"position: relative\");\n      if (lineView.text.parentNode)\n        { lineView.text.parentNode.replaceChild(lineView.node, lineView.text); }\n      lineView.node.appendChild(lineView.text);\n      if (ie && ie_version < 8) { lineView.node.style.zIndex = 2; }\n    }\n    return lineView.node\n  }\n\n  function updateLineBackground(cm, lineView) {\n    var cls = lineView.bgClass ? lineView.bgClass + \" \" + (lineView.line.bgClass || \"\") : lineView.line.bgClass;\n    if (cls) { cls += \" CodeMirror-linebackground\"; }\n    if (lineView.background) {\n      if (cls) { lineView.background.className = cls; }\n      else { lineView.background.parentNode.removeChild(lineView.background); lineView.background = null; }\n    } else if (cls) {\n      var wrap = ensureLineWrapped(lineView);\n      lineView.background = wrap.insertBefore(elt(\"div\", null, cls), wrap.firstChild);\n      cm.display.input.setUneditable(lineView.background);\n    }\n  }\n\n  // Wrapper around buildLineContent which will reuse the structure\n  // in display.externalMeasured when possible.\n  function getLineContent(cm, lineView) {\n    var ext = cm.display.externalMeasured;\n    if (ext && ext.line == lineView.line) {\n      cm.display.externalMeasured = null;\n      lineView.measure = ext.measure;\n      return ext.built\n    }\n    return buildLineContent(cm, lineView)\n  }\n\n  // Redraw the line's text. Interacts with the background and text\n  // classes because the mode may output tokens that influence these\n  // classes.\n  function updateLineText(cm, lineView) {\n    var cls = lineView.text.className;\n    var built = getLineContent(cm, lineView);\n    if (lineView.text == lineView.node) { lineView.node = built.pre; }\n    lineView.text.parentNode.replaceChild(built.pre, lineView.text);\n    lineView.text = built.pre;\n    if (built.bgClass != lineView.bgClass || built.textClass != lineView.textClass) {\n      lineView.bgClass = built.bgClass;\n      lineView.textClass = built.textClass;\n      updateLineClasses(cm, lineView);\n    } else if (cls) {\n      lineView.text.className = cls;\n    }\n  }\n\n  function updateLineClasses(cm, lineView) {\n    updateLineBackground(cm, lineView);\n    if (lineView.line.wrapClass)\n      { ensureLineWrapped(lineView).className = lineView.line.wrapClass; }\n    else if (lineView.node != lineView.text)\n      { lineView.node.className = \"\"; }\n    var textClass = lineView.textClass ? lineView.textClass + \" \" + (lineView.line.textClass || \"\") : lineView.line.textClass;\n    lineView.text.className = textClass || \"\";\n  }\n\n  function updateLineGutter(cm, lineView, lineN, dims) {\n    if (lineView.gutter) {\n      lineView.node.removeChild(lineView.gutter);\n      lineView.gutter = null;\n    }\n    if (lineView.gutterBackground) {\n      lineView.node.removeChild(lineView.gutterBackground);\n      lineView.gutterBackground = null;\n    }\n    if (lineView.line.gutterClass) {\n      var wrap = ensureLineWrapped(lineView);\n      lineView.gutterBackground = elt(\"div\", null, \"CodeMirror-gutter-background \" + lineView.line.gutterClass,\n                                      (\"left: \" + (cm.options.fixedGutter ? dims.fixedPos : -dims.gutterTotalWidth) + \"px; width: \" + (dims.gutterTotalWidth) + \"px\"));\n      cm.display.input.setUneditable(lineView.gutterBackground);\n      wrap.insertBefore(lineView.gutterBackground, lineView.text);\n    }\n    var markers = lineView.line.gutterMarkers;\n    if (cm.options.lineNumbers || markers) {\n      var wrap$1 = ensureLineWrapped(lineView);\n      var gutterWrap = lineView.gutter = elt(\"div\", null, \"CodeMirror-gutter-wrapper\", (\"left: \" + (cm.options.fixedGutter ? dims.fixedPos : -dims.gutterTotalWidth) + \"px\"));\n      gutterWrap.setAttribute(\"aria-hidden\", \"true\");\n      cm.display.input.setUneditable(gutterWrap);\n      wrap$1.insertBefore(gutterWrap, lineView.text);\n      if (lineView.line.gutterClass)\n        { gutterWrap.className += \" \" + lineView.line.gutterClass; }\n      if (cm.options.lineNumbers && (!markers || !markers[\"CodeMirror-linenumbers\"]))\n        { lineView.lineNumber = gutterWrap.appendChild(\n          elt(\"div\", lineNumberFor(cm.options, lineN),\n              \"CodeMirror-linenumber CodeMirror-gutter-elt\",\n              (\"left: \" + (dims.gutterLeft[\"CodeMirror-linenumbers\"]) + \"px; width: \" + (cm.display.lineNumInnerWidth) + \"px\"))); }\n      if (markers) { for (var k = 0; k < cm.display.gutterSpecs.length; ++k) {\n        var id = cm.display.gutterSpecs[k].className, found = markers.hasOwnProperty(id) && markers[id];\n        if (found)\n          { gutterWrap.appendChild(elt(\"div\", [found], \"CodeMirror-gutter-elt\",\n                                     (\"left: \" + (dims.gutterLeft[id]) + \"px; width: \" + (dims.gutterWidth[id]) + \"px\"))); }\n      } }\n    }\n  }\n\n  function updateLineWidgets(cm, lineView, dims) {\n    if (lineView.alignable) { lineView.alignable = null; }\n    var isWidget = classTest(\"CodeMirror-linewidget\");\n    for (var node = lineView.node.firstChild, next = (void 0); node; node = next) {\n      next = node.nextSibling;\n      if (isWidget.test(node.className)) { lineView.node.removeChild(node); }\n    }\n    insertLineWidgets(cm, lineView, dims);\n  }\n\n  // Build a line's DOM representation from scratch\n  function buildLineElement(cm, lineView, lineN, dims) {\n    var built = getLineContent(cm, lineView);\n    lineView.text = lineView.node = built.pre;\n    if (built.bgClass) { lineView.bgClass = built.bgClass; }\n    if (built.textClass) { lineView.textClass = built.textClass; }\n\n    updateLineClasses(cm, lineView);\n    updateLineGutter(cm, lineView, lineN, dims);\n    insertLineWidgets(cm, lineView, dims);\n    return lineView.node\n  }\n\n  // A lineView may contain multiple logical lines (when merged by\n  // collapsed spans). The widgets for all of them need to be drawn.\n  function insertLineWidgets(cm, lineView, dims) {\n    insertLineWidgetsFor(cm, lineView.line, lineView, dims, true);\n    if (lineView.rest) { for (var i = 0; i < lineView.rest.length; i++)\n      { insertLineWidgetsFor(cm, lineView.rest[i], lineView, dims, false); } }\n  }\n\n  function insertLineWidgetsFor(cm, line, lineView, dims, allowAbove) {\n    if (!line.widgets) { return }\n    var wrap = ensureLineWrapped(lineView);\n    for (var i = 0, ws = line.widgets; i < ws.length; ++i) {\n      var widget = ws[i], node = elt(\"div\", [widget.node], \"CodeMirror-linewidget\" + (widget.className ? \" \" + widget.className : \"\"));\n      if (!widget.handleMouseEvents) { node.setAttribute(\"cm-ignore-events\", \"true\"); }\n      positionLineWidget(widget, node, lineView, dims);\n      cm.display.input.setUneditable(node);\n      if (allowAbove && widget.above)\n        { wrap.insertBefore(node, lineView.gutter || lineView.text); }\n      else\n        { wrap.appendChild(node); }\n      signalLater(widget, \"redraw\");\n    }\n  }\n\n  function positionLineWidget(widget, node, lineView, dims) {\n    if (widget.noHScroll) {\n  (lineView.alignable || (lineView.alignable = [])).push(node);\n      var width = dims.wrapperWidth;\n      node.style.left = dims.fixedPos + \"px\";\n      if (!widget.coverGutter) {\n        width -= dims.gutterTotalWidth;\n        node.style.paddingLeft = dims.gutterTotalWidth + \"px\";\n      }\n      node.style.width = width + \"px\";\n    }\n    if (widget.coverGutter) {\n      node.style.zIndex = 5;\n      node.style.position = \"relative\";\n      if (!widget.noHScroll) { node.style.marginLeft = -dims.gutterTotalWidth + \"px\"; }\n    }\n  }\n\n  function widgetHeight(widget) {\n    if (widget.height != null) { return widget.height }\n    var cm = widget.doc.cm;\n    if (!cm) { return 0 }\n    if (!contains(document.body, widget.node)) {\n      var parentStyle = \"position: relative;\";\n      if (widget.coverGutter)\n        { parentStyle += \"margin-left: -\" + cm.display.gutters.offsetWidth + \"px;\"; }\n      if (widget.noHScroll)\n        { parentStyle += \"width: \" + cm.display.wrapper.clientWidth + \"px;\"; }\n      removeChildrenAndAdd(cm.display.measure, elt(\"div\", [widget.node], null, parentStyle));\n    }\n    return widget.height = widget.node.parentNode.offsetHeight\n  }\n\n  // Return true when the given mouse event happened in a widget\n  function eventInWidget(display, e) {\n    for (var n = e_target(e); n != display.wrapper; n = n.parentNode) {\n      if (!n || (n.nodeType == 1 && n.getAttribute(\"cm-ignore-events\") == \"true\") ||\n          (n.parentNode == display.sizer && n != display.mover))\n        { return true }\n    }\n  }\n\n  // POSITION MEASUREMENT\n\n  function paddingTop(display) {return display.lineSpace.offsetTop}\n  function paddingVert(display) {return display.mover.offsetHeight - display.lineSpace.offsetHeight}\n  function paddingH(display) {\n    if (display.cachedPaddingH) { return display.cachedPaddingH }\n    var e = removeChildrenAndAdd(display.measure, elt(\"pre\", \"x\", \"CodeMirror-line-like\"));\n    var style = window.getComputedStyle ? window.getComputedStyle(e) : e.currentStyle;\n    var data = {left: parseInt(style.paddingLeft), right: parseInt(style.paddingRight)};\n    if (!isNaN(data.left) && !isNaN(data.right)) { display.cachedPaddingH = data; }\n    return data\n  }\n\n  function scrollGap(cm) { return scrollerGap - cm.display.nativeBarWidth }\n  function displayWidth(cm) {\n    return cm.display.scroller.clientWidth - scrollGap(cm) - cm.display.barWidth\n  }\n  function displayHeight(cm) {\n    return cm.display.scroller.clientHeight - scrollGap(cm) - cm.display.barHeight\n  }\n\n  // Ensure the lineView.wrapping.heights array is populated. This is\n  // an array of bottom offsets for the lines that make up a drawn\n  // line. When lineWrapping is on, there might be more than one\n  // height.\n  function ensureLineHeights(cm, lineView, rect) {\n    var wrapping = cm.options.lineWrapping;\n    var curWidth = wrapping && displayWidth(cm);\n    if (!lineView.measure.heights || wrapping && lineView.measure.width != curWidth) {\n      var heights = lineView.measure.heights = [];\n      if (wrapping) {\n        lineView.measure.width = curWidth;\n        var rects = lineView.text.firstChild.getClientRects();\n        for (var i = 0; i < rects.length - 1; i++) {\n          var cur = rects[i], next = rects[i + 1];\n          if (Math.abs(cur.bottom - next.bottom) > 2)\n            { heights.push((cur.bottom + next.top) / 2 - rect.top); }\n        }\n      }\n      heights.push(rect.bottom - rect.top);\n    }\n  }\n\n  // Find a line map (mapping character offsets to text nodes) and a\n  // measurement cache for the given line number. (A line view might\n  // contain multiple lines when collapsed ranges are present.)\n  function mapFromLineView(lineView, line, lineN) {\n    if (lineView.line == line)\n      { return {map: lineView.measure.map, cache: lineView.measure.cache} }\n    if (lineView.rest) {\n      for (var i = 0; i < lineView.rest.length; i++)\n        { if (lineView.rest[i] == line)\n          { return {map: lineView.measure.maps[i], cache: lineView.measure.caches[i]} } }\n      for (var i$1 = 0; i$1 < lineView.rest.length; i$1++)\n        { if (lineNo(lineView.rest[i$1]) > lineN)\n          { return {map: lineView.measure.maps[i$1], cache: lineView.measure.caches[i$1], before: true} } }\n    }\n  }\n\n  // Render a line into the hidden node display.externalMeasured. Used\n  // when measurement is needed for a line that's not in the viewport.\n  function updateExternalMeasurement(cm, line) {\n    line = visualLine(line);\n    var lineN = lineNo(line);\n    var view = cm.display.externalMeasured = new LineView(cm.doc, line, lineN);\n    view.lineN = lineN;\n    var built = view.built = buildLineContent(cm, view);\n    view.text = built.pre;\n    removeChildrenAndAdd(cm.display.lineMeasure, built.pre);\n    return view\n  }\n\n  // Get a {top, bottom, left, right} box (in line-local coordinates)\n  // for a given character.\n  function measureChar(cm, line, ch, bias) {\n    return measureCharPrepared(cm, prepareMeasureForLine(cm, line), ch, bias)\n  }\n\n  // Find a line view that corresponds to the given line number.\n  function findViewForLine(cm, lineN) {\n    if (lineN >= cm.display.viewFrom && lineN < cm.display.viewTo)\n      { return cm.display.view[findViewIndex(cm, lineN)] }\n    var ext = cm.display.externalMeasured;\n    if (ext && lineN >= ext.lineN && lineN < ext.lineN + ext.size)\n      { return ext }\n  }\n\n  // Measurement can be split in two steps, the set-up work that\n  // applies to the whole line, and the measurement of the actual\n  // character. Functions like coordsChar, that need to do a lot of\n  // measurements in a row, can thus ensure that the set-up work is\n  // only done once.\n  function prepareMeasureForLine(cm, line) {\n    var lineN = lineNo(line);\n    var view = findViewForLine(cm, lineN);\n    if (view && !view.text) {\n      view = null;\n    } else if (view && view.changes) {\n      updateLineForChanges(cm, view, lineN, getDimensions(cm));\n      cm.curOp.forceUpdate = true;\n    }\n    if (!view)\n      { view = updateExternalMeasurement(cm, line); }\n\n    var info = mapFromLineView(view, line, lineN);\n    return {\n      line: line, view: view, rect: null,\n      map: info.map, cache: info.cache, before: info.before,\n      hasHeights: false\n    }\n  }\n\n  // Given a prepared measurement object, measures the position of an\n  // actual character (or fetches it from the cache).\n  function measureCharPrepared(cm, prepared, ch, bias, varHeight) {\n    if (prepared.before) { ch = -1; }\n    var key = ch + (bias || \"\"), found;\n    if (prepared.cache.hasOwnProperty(key)) {\n      found = prepared.cache[key];\n    } else {\n      if (!prepared.rect)\n        { prepared.rect = prepared.view.text.getBoundingClientRect(); }\n      if (!prepared.hasHeights) {\n        ensureLineHeights(cm, prepared.view, prepared.rect);\n        prepared.hasHeights = true;\n      }\n      found = measureCharInner(cm, prepared, ch, bias);\n      if (!found.bogus) { prepared.cache[key] = found; }\n    }\n    return {left: found.left, right: found.right,\n            top: varHeight ? found.rtop : found.top,\n            bottom: varHeight ? found.rbottom : found.bottom}\n  }\n\n  var nullRect = {left: 0, right: 0, top: 0, bottom: 0};\n\n  function nodeAndOffsetInLineMap(map, ch, bias) {\n    var node, start, end, collapse, mStart, mEnd;\n    // First, search the line map for the text node corresponding to,\n    // or closest to, the target character.\n    for (var i = 0; i < map.length; i += 3) {\n      mStart = map[i];\n      mEnd = map[i + 1];\n      if (ch < mStart) {\n        start = 0; end = 1;\n        collapse = \"left\";\n      } else if (ch < mEnd) {\n        start = ch - mStart;\n        end = start + 1;\n      } else if (i == map.length - 3 || ch == mEnd && map[i + 3] > ch) {\n        end = mEnd - mStart;\n        start = end - 1;\n        if (ch >= mEnd) { collapse = \"right\"; }\n      }\n      if (start != null) {\n        node = map[i + 2];\n        if (mStart == mEnd && bias == (node.insertLeft ? \"left\" : \"right\"))\n          { collapse = bias; }\n        if (bias == \"left\" && start == 0)\n          { while (i && map[i - 2] == map[i - 3] && map[i - 1].insertLeft) {\n            node = map[(i -= 3) + 2];\n            collapse = \"left\";\n          } }\n        if (bias == \"right\" && start == mEnd - mStart)\n          { while (i < map.length - 3 && map[i + 3] == map[i + 4] && !map[i + 5].insertLeft) {\n            node = map[(i += 3) + 2];\n            collapse = \"right\";\n          } }\n        break\n      }\n    }\n    return {node: node, start: start, end: end, collapse: collapse, coverStart: mStart, coverEnd: mEnd}\n  }\n\n  function getUsefulRect(rects, bias) {\n    var rect = nullRect;\n    if (bias == \"left\") { for (var i = 0; i < rects.length; i++) {\n      if ((rect = rects[i]).left != rect.right) { break }\n    } } else { for (var i$1 = rects.length - 1; i$1 >= 0; i$1--) {\n      if ((rect = rects[i$1]).left != rect.right) { break }\n    } }\n    return rect\n  }\n\n  function measureCharInner(cm, prepared, ch, bias) {\n    var place = nodeAndOffsetInLineMap(prepared.map, ch, bias);\n    var node = place.node, start = place.start, end = place.end, collapse = place.collapse;\n\n    var rect;\n    if (node.nodeType == 3) { // If it is a text node, use a range to retrieve the coordinates.\n      for (var i$1 = 0; i$1 < 4; i$1++) { // Retry a maximum of 4 times when nonsense rectangles are returned\n        while (start && isExtendingChar(prepared.line.text.charAt(place.coverStart + start))) { --start; }\n        while (place.coverStart + end < place.coverEnd && isExtendingChar(prepared.line.text.charAt(place.coverStart + end))) { ++end; }\n        if (ie && ie_version < 9 && start == 0 && end == place.coverEnd - place.coverStart)\n          { rect = node.parentNode.getBoundingClientRect(); }\n        else\n          { rect = getUsefulRect(range(node, start, end).getClientRects(), bias); }\n        if (rect.left || rect.right || start == 0) { break }\n        end = start;\n        start = start - 1;\n        collapse = \"right\";\n      }\n      if (ie && ie_version < 11) { rect = maybeUpdateRectForZooming(cm.display.measure, rect); }\n    } else { // If it is a widget, simply get the box for the whole widget.\n      if (start > 0) { collapse = bias = \"right\"; }\n      var rects;\n      if (cm.options.lineWrapping && (rects = node.getClientRects()).length > 1)\n        { rect = rects[bias == \"right\" ? rects.length - 1 : 0]; }\n      else\n        { rect = node.getBoundingClientRect(); }\n    }\n    if (ie && ie_version < 9 && !start && (!rect || !rect.left && !rect.right)) {\n      var rSpan = node.parentNode.getClientRects()[0];\n      if (rSpan)\n        { rect = {left: rSpan.left, right: rSpan.left + charWidth(cm.display), top: rSpan.top, bottom: rSpan.bottom}; }\n      else\n        { rect = nullRect; }\n    }\n\n    var rtop = rect.top - prepared.rect.top, rbot = rect.bottom - prepared.rect.top;\n    var mid = (rtop + rbot) / 2;\n    var heights = prepared.view.measure.heights;\n    var i = 0;\n    for (; i < heights.length - 1; i++)\n      { if (mid < heights[i]) { break } }\n    var top = i ? heights[i - 1] : 0, bot = heights[i];\n    var result = {left: (collapse == \"right\" ? rect.right : rect.left) - prepared.rect.left,\n                  right: (collapse == \"left\" ? rect.left : rect.right) - prepared.rect.left,\n                  top: top, bottom: bot};\n    if (!rect.left && !rect.right) { result.bogus = true; }\n    if (!cm.options.singleCursorHeightPerLine) { result.rtop = rtop; result.rbottom = rbot; }\n\n    return result\n  }\n\n  // Work around problem with bounding client rects on ranges being\n  // returned incorrectly when zoomed on IE10 and below.\n  function maybeUpdateRectForZooming(measure, rect) {\n    if (!window.screen || screen.logicalXDPI == null ||\n        screen.logicalXDPI == screen.deviceXDPI || !hasBadZoomedRects(measure))\n      { return rect }\n    var scaleX = screen.logicalXDPI / screen.deviceXDPI;\n    var scaleY = screen.logicalYDPI / screen.deviceYDPI;\n    return {left: rect.left * scaleX, right: rect.right * scaleX,\n            top: rect.top * scaleY, bottom: rect.bottom * scaleY}\n  }\n\n  function clearLineMeasurementCacheFor(lineView) {\n    if (lineView.measure) {\n      lineView.measure.cache = {};\n      lineView.measure.heights = null;\n      if (lineView.rest) { for (var i = 0; i < lineView.rest.length; i++)\n        { lineView.measure.caches[i] = {}; } }\n    }\n  }\n\n  function clearLineMeasurementCache(cm) {\n    cm.display.externalMeasure = null;\n    removeChildren(cm.display.lineMeasure);\n    for (var i = 0; i < cm.display.view.length; i++)\n      { clearLineMeasurementCacheFor(cm.display.view[i]); }\n  }\n\n  function clearCaches(cm) {\n    clearLineMeasurementCache(cm);\n    cm.display.cachedCharWidth = cm.display.cachedTextHeight = cm.display.cachedPaddingH = null;\n    if (!cm.options.lineWrapping) { cm.display.maxLineChanged = true; }\n    cm.display.lineNumChars = null;\n  }\n\n  function pageScrollX(doc) {\n    // Work around https://bugs.chromium.org/p/chromium/issues/detail?id=489206\n    // which causes page_Offset and bounding client rects to use\n    // different reference viewports and invalidate our calculations.\n    if (chrome && android) { return -(doc.body.getBoundingClientRect().left - parseInt(getComputedStyle(doc.body).marginLeft)) }\n    return doc.defaultView.pageXOffset || (doc.documentElement || doc.body).scrollLeft\n  }\n  function pageScrollY(doc) {\n    if (chrome && android) { return -(doc.body.getBoundingClientRect().top - parseInt(getComputedStyle(doc.body).marginTop)) }\n    return doc.defaultView.pageYOffset || (doc.documentElement || doc.body).scrollTop\n  }\n\n  function widgetTopHeight(lineObj) {\n    var ref = visualLine(lineObj);\n    var widgets = ref.widgets;\n    var height = 0;\n    if (widgets) { for (var i = 0; i < widgets.length; ++i) { if (widgets[i].above)\n      { height += widgetHeight(widgets[i]); } } }\n    return height\n  }\n\n  // Converts a {top, bottom, left, right} box from line-local\n  // coordinates into another coordinate system. Context may be one of\n  // \"line\", \"div\" (display.lineDiv), \"local\"./null (editor), \"window\",\n  // or \"page\".\n  function intoCoordSystem(cm, lineObj, rect, context, includeWidgets) {\n    if (!includeWidgets) {\n      var height = widgetTopHeight(lineObj);\n      rect.top += height; rect.bottom += height;\n    }\n    if (context == \"line\") { return rect }\n    if (!context) { context = \"local\"; }\n    var yOff = heightAtLine(lineObj);\n    if (context == \"local\") { yOff += paddingTop(cm.display); }\n    else { yOff -= cm.display.viewOffset; }\n    if (context == \"page\" || context == \"window\") {\n      var lOff = cm.display.lineSpace.getBoundingClientRect();\n      yOff += lOff.top + (context == \"window\" ? 0 : pageScrollY(doc(cm)));\n      var xOff = lOff.left + (context == \"window\" ? 0 : pageScrollX(doc(cm)));\n      rect.left += xOff; rect.right += xOff;\n    }\n    rect.top += yOff; rect.bottom += yOff;\n    return rect\n  }\n\n  // Coverts a box from \"div\" coords to another coordinate system.\n  // Context may be \"window\", \"page\", \"div\", or \"local\"./null.\n  function fromCoordSystem(cm, coords, context) {\n    if (context == \"div\") { return coords }\n    var left = coords.left, top = coords.top;\n    // First move into \"page\" coordinate system\n    if (context == \"page\") {\n      left -= pageScrollX(doc(cm));\n      top -= pageScrollY(doc(cm));\n    } else if (context == \"local\" || !context) {\n      var localBox = cm.display.sizer.getBoundingClientRect();\n      left += localBox.left;\n      top += localBox.top;\n    }\n\n    var lineSpaceBox = cm.display.lineSpace.getBoundingClientRect();\n    return {left: left - lineSpaceBox.left, top: top - lineSpaceBox.top}\n  }\n\n  function charCoords(cm, pos, context, lineObj, bias) {\n    if (!lineObj) { lineObj = getLine(cm.doc, pos.line); }\n    return intoCoordSystem(cm, lineObj, measureChar(cm, lineObj, pos.ch, bias), context)\n  }\n\n  // Returns a box for a given cursor position, which may have an\n  // 'other' property containing the position of the secondary cursor\n  // on a bidi boundary.\n  // A cursor Pos(line, char, \"before\") is on the same visual line as `char - 1`\n  // and after `char - 1` in writing order of `char - 1`\n  // A cursor Pos(line, char, \"after\") is on the same visual line as `char`\n  // and before `char` in writing order of `char`\n  // Examples (upper-case letters are RTL, lower-case are LTR):\n  //     Pos(0, 1, ...)\n  //     before   after\n  // ab     a|b     a|b\n  // aB     a|B     aB|\n  // Ab     |Ab     A|b\n  // AB     B|A     B|A\n  // Every position after the last character on a line is considered to stick\n  // to the last character on the line.\n  function cursorCoords(cm, pos, context, lineObj, preparedMeasure, varHeight) {\n    lineObj = lineObj || getLine(cm.doc, pos.line);\n    if (!preparedMeasure) { preparedMeasure = prepareMeasureForLine(cm, lineObj); }\n    function get(ch, right) {\n      var m = measureCharPrepared(cm, preparedMeasure, ch, right ? \"right\" : \"left\", varHeight);\n      if (right) { m.left = m.right; } else { m.right = m.left; }\n      return intoCoordSystem(cm, lineObj, m, context)\n    }\n    var order = getOrder(lineObj, cm.doc.direction), ch = pos.ch, sticky = pos.sticky;\n    if (ch >= lineObj.text.length) {\n      ch = lineObj.text.length;\n      sticky = \"before\";\n    } else if (ch <= 0) {\n      ch = 0;\n      sticky = \"after\";\n    }\n    if (!order) { return get(sticky == \"before\" ? ch - 1 : ch, sticky == \"before\") }\n\n    function getBidi(ch, partPos, invert) {\n      var part = order[partPos], right = part.level == 1;\n      return get(invert ? ch - 1 : ch, right != invert)\n    }\n    var partPos = getBidiPartAt(order, ch, sticky);\n    var other = bidiOther;\n    var val = getBidi(ch, partPos, sticky == \"before\");\n    if (other != null) { val.other = getBidi(ch, other, sticky != \"before\"); }\n    return val\n  }\n\n  // Used to cheaply estimate the coordinates for a position. Used for\n  // intermediate scroll updates.\n  function estimateCoords(cm, pos) {\n    var left = 0;\n    pos = clipPos(cm.doc, pos);\n    if (!cm.options.lineWrapping) { left = charWidth(cm.display) * pos.ch; }\n    var lineObj = getLine(cm.doc, pos.line);\n    var top = heightAtLine(lineObj) + paddingTop(cm.display);\n    return {left: left, right: left, top: top, bottom: top + lineObj.height}\n  }\n\n  // Positions returned by coordsChar contain some extra information.\n  // xRel is the relative x position of the input coordinates compared\n  // to the found position (so xRel > 0 means the coordinates are to\n  // the right of the character position, for example). When outside\n  // is true, that means the coordinates lie outside the line's\n  // vertical range.\n  function PosWithInfo(line, ch, sticky, outside, xRel) {\n    var pos = Pos(line, ch, sticky);\n    pos.xRel = xRel;\n    if (outside) { pos.outside = outside; }\n    return pos\n  }\n\n  // Compute the character position closest to the given coordinates.\n  // Input must be lineSpace-local (\"div\" coordinate system).\n  function coordsChar(cm, x, y) {\n    var doc = cm.doc;\n    y += cm.display.viewOffset;\n    if (y < 0) { return PosWithInfo(doc.first, 0, null, -1, -1) }\n    var lineN = lineAtHeight(doc, y), last = doc.first + doc.size - 1;\n    if (lineN > last)\n      { return PosWithInfo(doc.first + doc.size - 1, getLine(doc, last).text.length, null, 1, 1) }\n    if (x < 0) { x = 0; }\n\n    var lineObj = getLine(doc, lineN);\n    for (;;) {\n      var found = coordsCharInner(cm, lineObj, lineN, x, y);\n      var collapsed = collapsedSpanAround(lineObj, found.ch + (found.xRel > 0 || found.outside > 0 ? 1 : 0));\n      if (!collapsed) { return found }\n      var rangeEnd = collapsed.find(1);\n      if (rangeEnd.line == lineN) { return rangeEnd }\n      lineObj = getLine(doc, lineN = rangeEnd.line);\n    }\n  }\n\n  function wrappedLineExtent(cm, lineObj, preparedMeasure, y) {\n    y -= widgetTopHeight(lineObj);\n    var end = lineObj.text.length;\n    var begin = findFirst(function (ch) { return measureCharPrepared(cm, preparedMeasure, ch - 1).bottom <= y; }, end, 0);\n    end = findFirst(function (ch) { return measureCharPrepared(cm, preparedMeasure, ch).top > y; }, begin, end);\n    return {begin: begin, end: end}\n  }\n\n  function wrappedLineExtentChar(cm, lineObj, preparedMeasure, target) {\n    if (!preparedMeasure) { preparedMeasure = prepareMeasureForLine(cm, lineObj); }\n    var targetTop = intoCoordSystem(cm, lineObj, measureCharPrepared(cm, preparedMeasure, target), \"line\").top;\n    return wrappedLineExtent(cm, lineObj, preparedMeasure, targetTop)\n  }\n\n  // Returns true if the given side of a box is after the given\n  // coordinates, in top-to-bottom, left-to-right order.\n  function boxIsAfter(box, x, y, left) {\n    return box.bottom <= y ? false : box.top > y ? true : (left ? box.left : box.right) > x\n  }\n\n  function coordsCharInner(cm, lineObj, lineNo, x, y) {\n    // Move y into line-local coordinate space\n    y -= heightAtLine(lineObj);\n    var preparedMeasure = prepareMeasureForLine(cm, lineObj);\n    // When directly calling `measureCharPrepared`, we have to adjust\n    // for the widgets at this line.\n    var widgetHeight = widgetTopHeight(lineObj);\n    var begin = 0, end = lineObj.text.length, ltr = true;\n\n    var order = getOrder(lineObj, cm.doc.direction);\n    // If the line isn't plain left-to-right text, first figure out\n    // which bidi section the coordinates fall into.\n    if (order) {\n      var part = (cm.options.lineWrapping ? coordsBidiPartWrapped : coordsBidiPart)\n                   (cm, lineObj, lineNo, preparedMeasure, order, x, y);\n      ltr = part.level != 1;\n      // The awkward -1 offsets are needed because findFirst (called\n      // on these below) will treat its first bound as inclusive,\n      // second as exclusive, but we want to actually address the\n      // characters in the part's range\n      begin = ltr ? part.from : part.to - 1;\n      end = ltr ? part.to : part.from - 1;\n    }\n\n    // A binary search to find the first character whose bounding box\n    // starts after the coordinates. If we run across any whose box wrap\n    // the coordinates, store that.\n    var chAround = null, boxAround = null;\n    var ch = findFirst(function (ch) {\n      var box = measureCharPrepared(cm, preparedMeasure, ch);\n      box.top += widgetHeight; box.bottom += widgetHeight;\n      if (!boxIsAfter(box, x, y, false)) { return false }\n      if (box.top <= y && box.left <= x) {\n        chAround = ch;\n        boxAround = box;\n      }\n      return true\n    }, begin, end);\n\n    var baseX, sticky, outside = false;\n    // If a box around the coordinates was found, use that\n    if (boxAround) {\n      // Distinguish coordinates nearer to the left or right side of the box\n      var atLeft = x - boxAround.left < boxAround.right - x, atStart = atLeft == ltr;\n      ch = chAround + (atStart ? 0 : 1);\n      sticky = atStart ? \"after\" : \"before\";\n      baseX = atLeft ? boxAround.left : boxAround.right;\n    } else {\n      // (Adjust for extended bound, if necessary.)\n      if (!ltr && (ch == end || ch == begin)) { ch++; }\n      // To determine which side to associate with, get the box to the\n      // left of the character and compare it's vertical position to the\n      // coordinates\n      sticky = ch == 0 ? \"after\" : ch == lineObj.text.length ? \"before\" :\n        (measureCharPrepared(cm, preparedMeasure, ch - (ltr ? 1 : 0)).bottom + widgetHeight <= y) == ltr ?\n        \"after\" : \"before\";\n      // Now get accurate coordinates for this place, in order to get a\n      // base X position\n      var coords = cursorCoords(cm, Pos(lineNo, ch, sticky), \"line\", lineObj, preparedMeasure);\n      baseX = coords.left;\n      outside = y < coords.top ? -1 : y >= coords.bottom ? 1 : 0;\n    }\n\n    ch = skipExtendingChars(lineObj.text, ch, 1);\n    return PosWithInfo(lineNo, ch, sticky, outside, x - baseX)\n  }\n\n  function coordsBidiPart(cm, lineObj, lineNo, preparedMeasure, order, x, y) {\n    // Bidi parts are sorted left-to-right, and in a non-line-wrapping\n    // situation, we can take this ordering to correspond to the visual\n    // ordering. This finds the first part whose end is after the given\n    // coordinates.\n    var index = findFirst(function (i) {\n      var part = order[i], ltr = part.level != 1;\n      return boxIsAfter(cursorCoords(cm, Pos(lineNo, ltr ? part.to : part.from, ltr ? \"before\" : \"after\"),\n                                     \"line\", lineObj, preparedMeasure), x, y, true)\n    }, 0, order.length - 1);\n    var part = order[index];\n    // If this isn't the first part, the part's start is also after\n    // the coordinates, and the coordinates aren't on the same line as\n    // that start, move one part back.\n    if (index > 0) {\n      var ltr = part.level != 1;\n      var start = cursorCoords(cm, Pos(lineNo, ltr ? part.from : part.to, ltr ? \"after\" : \"before\"),\n                               \"line\", lineObj, preparedMeasure);\n      if (boxIsAfter(start, x, y, true) && start.top > y)\n        { part = order[index - 1]; }\n    }\n    return part\n  }\n\n  function coordsBidiPartWrapped(cm, lineObj, _lineNo, preparedMeasure, order, x, y) {\n    // In a wrapped line, rtl text on wrapping boundaries can do things\n    // that don't correspond to the ordering in our `order` array at\n    // all, so a binary search doesn't work, and we want to return a\n    // part that only spans one line so that the binary search in\n    // coordsCharInner is safe. As such, we first find the extent of the\n    // wrapped line, and then do a flat search in which we discard any\n    // spans that aren't on the line.\n    var ref = wrappedLineExtent(cm, lineObj, preparedMeasure, y);\n    var begin = ref.begin;\n    var end = ref.end;\n    if (/\\s/.test(lineObj.text.charAt(end - 1))) { end--; }\n    var part = null, closestDist = null;\n    for (var i = 0; i < order.length; i++) {\n      var p = order[i];\n      if (p.from >= end || p.to <= begin) { continue }\n      var ltr = p.level != 1;\n      var endX = measureCharPrepared(cm, preparedMeasure, ltr ? Math.min(end, p.to) - 1 : Math.max(begin, p.from)).right;\n      // Weigh against spans ending before this, so that they are only\n      // picked if nothing ends after\n      var dist = endX < x ? x - endX + 1e9 : endX - x;\n      if (!part || closestDist > dist) {\n        part = p;\n        closestDist = dist;\n      }\n    }\n    if (!part) { part = order[order.length - 1]; }\n    // Clip the part to the wrapped line.\n    if (part.from < begin) { part = {from: begin, to: part.to, level: part.level}; }\n    if (part.to > end) { part = {from: part.from, to: end, level: part.level}; }\n    return part\n  }\n\n  var measureText;\n  // Compute the default text height.\n  function textHeight(display) {\n    if (display.cachedTextHeight != null) { return display.cachedTextHeight }\n    if (measureText == null) {\n      measureText = elt(\"pre\", null, \"CodeMirror-line-like\");\n      // Measure a bunch of lines, for browsers that compute\n      // fractional heights.\n      for (var i = 0; i < 49; ++i) {\n        measureText.appendChild(document.createTextNode(\"x\"));\n        measureText.appendChild(elt(\"br\"));\n      }\n      measureText.appendChild(document.createTextNode(\"x\"));\n    }\n    removeChildrenAndAdd(display.measure, measureText);\n    var height = measureText.offsetHeight / 50;\n    if (height > 3) { display.cachedTextHeight = height; }\n    removeChildren(display.measure);\n    return height || 1\n  }\n\n  // Compute the default character width.\n  function charWidth(display) {\n    if (display.cachedCharWidth != null) { return display.cachedCharWidth }\n    var anchor = elt(\"span\", \"xxxxxxxxxx\");\n    var pre = elt(\"pre\", [anchor], \"CodeMirror-line-like\");\n    removeChildrenAndAdd(display.measure, pre);\n    var rect = anchor.getBoundingClientRect(), width = (rect.right - rect.left) / 10;\n    if (width > 2) { display.cachedCharWidth = width; }\n    return width || 10\n  }\n\n  // Do a bulk-read of the DOM positions and sizes needed to draw the\n  // view, so that we don't interleave reading and writing to the DOM.\n  function getDimensions(cm) {\n    var d = cm.display, left = {}, width = {};\n    var gutterLeft = d.gutters.clientLeft;\n    for (var n = d.gutters.firstChild, i = 0; n; n = n.nextSibling, ++i) {\n      var id = cm.display.gutterSpecs[i].className;\n      left[id] = n.offsetLeft + n.clientLeft + gutterLeft;\n      width[id] = n.clientWidth;\n    }\n    return {fixedPos: compensateForHScroll(d),\n            gutterTotalWidth: d.gutters.offsetWidth,\n            gutterLeft: left,\n            gutterWidth: width,\n            wrapperWidth: d.wrapper.clientWidth}\n  }\n\n  // Computes display.scroller.scrollLeft + display.gutters.offsetWidth,\n  // but using getBoundingClientRect to get a sub-pixel-accurate\n  // result.\n  function compensateForHScroll(display) {\n    return display.scroller.getBoundingClientRect().left - display.sizer.getBoundingClientRect().left\n  }\n\n  // Returns a function that estimates the height of a line, to use as\n  // first approximation until the line becomes visible (and is thus\n  // properly measurable).\n  function estimateHeight(cm) {\n    var th = textHeight(cm.display), wrapping = cm.options.lineWrapping;\n    var perLine = wrapping && Math.max(5, cm.display.scroller.clientWidth / charWidth(cm.display) - 3);\n    return function (line) {\n      if (lineIsHidden(cm.doc, line)) { return 0 }\n\n      var widgetsHeight = 0;\n      if (line.widgets) { for (var i = 0; i < line.widgets.length; i++) {\n        if (line.widgets[i].height) { widgetsHeight += line.widgets[i].height; }\n      } }\n\n      if (wrapping)\n        { return widgetsHeight + (Math.ceil(line.text.length / perLine) || 1) * th }\n      else\n        { return widgetsHeight + th }\n    }\n  }\n\n  function estimateLineHeights(cm) {\n    var doc = cm.doc, est = estimateHeight(cm);\n    doc.iter(function (line) {\n      var estHeight = est(line);\n      if (estHeight != line.height) { updateLineHeight(line, estHeight); }\n    });\n  }\n\n  // Given a mouse event, find the corresponding position. If liberal\n  // is false, it checks whether a gutter or scrollbar was clicked,\n  // and returns null if it was. forRect is used by rectangular\n  // selections, and tries to estimate a character position even for\n  // coordinates beyond the right of the text.\n  function posFromMouse(cm, e, liberal, forRect) {\n    var display = cm.display;\n    if (!liberal && e_target(e).getAttribute(\"cm-not-content\") == \"true\") { return null }\n\n    var x, y, space = display.lineSpace.getBoundingClientRect();\n    // Fails unpredictably on IE[67] when mouse is dragged around quickly.\n    try { x = e.clientX - space.left; y = e.clientY - space.top; }\n    catch (e$1) { return null }\n    var coords = coordsChar(cm, x, y), line;\n    if (forRect && coords.xRel > 0 && (line = getLine(cm.doc, coords.line).text).length == coords.ch) {\n      var colDiff = countColumn(line, line.length, cm.options.tabSize) - line.length;\n      coords = Pos(coords.line, Math.max(0, Math.round((x - paddingH(cm.display).left) / charWidth(cm.display)) - colDiff));\n    }\n    return coords\n  }\n\n  // Find the view element corresponding to a given line. Return null\n  // when the line isn't visible.\n  function findViewIndex(cm, n) {\n    if (n >= cm.display.viewTo) { return null }\n    n -= cm.display.viewFrom;\n    if (n < 0) { return null }\n    var view = cm.display.view;\n    for (var i = 0; i < view.length; i++) {\n      n -= view[i].size;\n      if (n < 0) { return i }\n    }\n  }\n\n  // Updates the display.view data structure for a given change to the\n  // document. From and to are in pre-change coordinates. Lendiff is\n  // the amount of lines added or subtracted by the change. This is\n  // used for changes that span multiple lines, or change the way\n  // lines are divided into visual lines. regLineChange (below)\n  // registers single-line changes.\n  function regChange(cm, from, to, lendiff) {\n    if (from == null) { from = cm.doc.first; }\n    if (to == null) { to = cm.doc.first + cm.doc.size; }\n    if (!lendiff) { lendiff = 0; }\n\n    var display = cm.display;\n    if (lendiff && to < display.viewTo &&\n        (display.updateLineNumbers == null || display.updateLineNumbers > from))\n      { display.updateLineNumbers = from; }\n\n    cm.curOp.viewChanged = true;\n\n    if (from >= display.viewTo) { // Change after\n      if (sawCollapsedSpans && visualLineNo(cm.doc, from) < display.viewTo)\n        { resetView(cm); }\n    } else if (to <= display.viewFrom) { // Change before\n      if (sawCollapsedSpans && visualLineEndNo(cm.doc, to + lendiff) > display.viewFrom) {\n        resetView(cm);\n      } else {\n        display.viewFrom += lendiff;\n        display.viewTo += lendiff;\n      }\n    } else if (from <= display.viewFrom && to >= display.viewTo) { // Full overlap\n      resetView(cm);\n    } else if (from <= display.viewFrom) { // Top overlap\n      var cut = viewCuttingPoint(cm, to, to + lendiff, 1);\n      if (cut) {\n        display.view = display.view.slice(cut.index);\n        display.viewFrom = cut.lineN;\n        display.viewTo += lendiff;\n      } else {\n        resetView(cm);\n      }\n    } else if (to >= display.viewTo) { // Bottom overlap\n      var cut$1 = viewCuttingPoint(cm, from, from, -1);\n      if (cut$1) {\n        display.view = display.view.slice(0, cut$1.index);\n        display.viewTo = cut$1.lineN;\n      } else {\n        resetView(cm);\n      }\n    } else { // Gap in the middle\n      var cutTop = viewCuttingPoint(cm, from, from, -1);\n      var cutBot = viewCuttingPoint(cm, to, to + lendiff, 1);\n      if (cutTop && cutBot) {\n        display.view = display.view.slice(0, cutTop.index)\n          .concat(buildViewArray(cm, cutTop.lineN, cutBot.lineN))\n          .concat(display.view.slice(cutBot.index));\n        display.viewTo += lendiff;\n      } else {\n        resetView(cm);\n      }\n    }\n\n    var ext = display.externalMeasured;\n    if (ext) {\n      if (to < ext.lineN)\n        { ext.lineN += lendiff; }\n      else if (from < ext.lineN + ext.size)\n        { display.externalMeasured = null; }\n    }\n  }\n\n  // Register a change to a single line. Type must be one of \"text\",\n  // \"gutter\", \"class\", \"widget\"\n  function regLineChange(cm, line, type) {\n    cm.curOp.viewChanged = true;\n    var display = cm.display, ext = cm.display.externalMeasured;\n    if (ext && line >= ext.lineN && line < ext.lineN + ext.size)\n      { display.externalMeasured = null; }\n\n    if (line < display.viewFrom || line >= display.viewTo) { return }\n    var lineView = display.view[findViewIndex(cm, line)];\n    if (lineView.node == null) { return }\n    var arr = lineView.changes || (lineView.changes = []);\n    if (indexOf(arr, type) == -1) { arr.push(type); }\n  }\n\n  // Clear the view.\n  function resetView(cm) {\n    cm.display.viewFrom = cm.display.viewTo = cm.doc.first;\n    cm.display.view = [];\n    cm.display.viewOffset = 0;\n  }\n\n  function viewCuttingPoint(cm, oldN, newN, dir) {\n    var index = findViewIndex(cm, oldN), diff, view = cm.display.view;\n    if (!sawCollapsedSpans || newN == cm.doc.first + cm.doc.size)\n      { return {index: index, lineN: newN} }\n    var n = cm.display.viewFrom;\n    for (var i = 0; i < index; i++)\n      { n += view[i].size; }\n    if (n != oldN) {\n      if (dir > 0) {\n        if (index == view.length - 1) { return null }\n        diff = (n + view[index].size) - oldN;\n        index++;\n      } else {\n        diff = n - oldN;\n      }\n      oldN += diff; newN += diff;\n    }\n    while (visualLineNo(cm.doc, newN) != newN) {\n      if (index == (dir < 0 ? 0 : view.length - 1)) { return null }\n      newN += dir * view[index - (dir < 0 ? 1 : 0)].size;\n      index += dir;\n    }\n    return {index: index, lineN: newN}\n  }\n\n  // Force the view to cover a given range, adding empty view element\n  // or clipping off existing ones as needed.\n  function adjustView(cm, from, to) {\n    var display = cm.display, view = display.view;\n    if (view.length == 0 || from >= display.viewTo || to <= display.viewFrom) {\n      display.view = buildViewArray(cm, from, to);\n      display.viewFrom = from;\n    } else {\n      if (display.viewFrom > from)\n        { display.view = buildViewArray(cm, from, display.viewFrom).concat(display.view); }\n      else if (display.viewFrom < from)\n        { display.view = display.view.slice(findViewIndex(cm, from)); }\n      display.viewFrom = from;\n      if (display.viewTo < to)\n        { display.view = display.view.concat(buildViewArray(cm, display.viewTo, to)); }\n      else if (display.viewTo > to)\n        { display.view = display.view.slice(0, findViewIndex(cm, to)); }\n    }\n    display.viewTo = to;\n  }\n\n  // Count the number of lines in the view whose DOM representation is\n  // out of date (or nonexistent).\n  function countDirtyView(cm) {\n    var view = cm.display.view, dirty = 0;\n    for (var i = 0; i < view.length; i++) {\n      var lineView = view[i];\n      if (!lineView.hidden && (!lineView.node || lineView.changes)) { ++dirty; }\n    }\n    return dirty\n  }\n\n  function updateSelection(cm) {\n    cm.display.input.showSelection(cm.display.input.prepareSelection());\n  }\n\n  function prepareSelection(cm, primary) {\n    if ( primary === void 0 ) primary = true;\n\n    var doc = cm.doc, result = {};\n    var curFragment = result.cursors = document.createDocumentFragment();\n    var selFragment = result.selection = document.createDocumentFragment();\n\n    var customCursor = cm.options.$customCursor;\n    if (customCursor) { primary = true; }\n    for (var i = 0; i < doc.sel.ranges.length; i++) {\n      if (!primary && i == doc.sel.primIndex) { continue }\n      var range = doc.sel.ranges[i];\n      if (range.from().line >= cm.display.viewTo || range.to().line < cm.display.viewFrom) { continue }\n      var collapsed = range.empty();\n      if (customCursor) {\n        var head = customCursor(cm, range);\n        if (head) { drawSelectionCursor(cm, head, curFragment); }\n      } else if (collapsed || cm.options.showCursorWhenSelecting) {\n        drawSelectionCursor(cm, range.head, curFragment);\n      }\n      if (!collapsed)\n        { drawSelectionRange(cm, range, selFragment); }\n    }\n    return result\n  }\n\n  // Draws a cursor for the given range\n  function drawSelectionCursor(cm, head, output) {\n    var pos = cursorCoords(cm, head, \"div\", null, null, !cm.options.singleCursorHeightPerLine);\n\n    var cursor = output.appendChild(elt(\"div\", \"\\u00a0\", \"CodeMirror-cursor\"));\n    cursor.style.left = pos.left + \"px\";\n    cursor.style.top = pos.top + \"px\";\n    cursor.style.height = Math.max(0, pos.bottom - pos.top) * cm.options.cursorHeight + \"px\";\n\n    if (/\\bcm-fat-cursor\\b/.test(cm.getWrapperElement().className)) {\n      var charPos = charCoords(cm, head, \"div\", null, null);\n      var width = charPos.right - charPos.left;\n      cursor.style.width = (width > 0 ? width : cm.defaultCharWidth()) + \"px\";\n    }\n\n    if (pos.other) {\n      // Secondary cursor, shown when on a 'jump' in bi-directional text\n      var otherCursor = output.appendChild(elt(\"div\", \"\\u00a0\", \"CodeMirror-cursor CodeMirror-secondarycursor\"));\n      otherCursor.style.display = \"\";\n      otherCursor.style.left = pos.other.left + \"px\";\n      otherCursor.style.top = pos.other.top + \"px\";\n      otherCursor.style.height = (pos.other.bottom - pos.other.top) * .85 + \"px\";\n    }\n  }\n\n  function cmpCoords(a, b) { return a.top - b.top || a.left - b.left }\n\n  // Draws the given range as a highlighted selection\n  function drawSelectionRange(cm, range, output) {\n    var display = cm.display, doc = cm.doc;\n    var fragment = document.createDocumentFragment();\n    var padding = paddingH(cm.display), leftSide = padding.left;\n    var rightSide = Math.max(display.sizerWidth, displayWidth(cm) - display.sizer.offsetLeft) - padding.right;\n    var docLTR = doc.direction == \"ltr\";\n\n    function add(left, top, width, bottom) {\n      if (top < 0) { top = 0; }\n      top = Math.round(top);\n      bottom = Math.round(bottom);\n      fragment.appendChild(elt(\"div\", null, \"CodeMirror-selected\", (\"position: absolute; left: \" + left + \"px;\\n                             top: \" + top + \"px; width: \" + (width == null ? rightSide - left : width) + \"px;\\n                             height: \" + (bottom - top) + \"px\")));\n    }\n\n    function drawForLine(line, fromArg, toArg) {\n      var lineObj = getLine(doc, line);\n      var lineLen = lineObj.text.length;\n      var start, end;\n      function coords(ch, bias) {\n        return charCoords(cm, Pos(line, ch), \"div\", lineObj, bias)\n      }\n\n      function wrapX(pos, dir, side) {\n        var extent = wrappedLineExtentChar(cm, lineObj, null, pos);\n        var prop = (dir == \"ltr\") == (side == \"after\") ? \"left\" : \"right\";\n        var ch = side == \"after\" ? extent.begin : extent.end - (/\\s/.test(lineObj.text.charAt(extent.end - 1)) ? 2 : 1);\n        return coords(ch, prop)[prop]\n      }\n\n      var order = getOrder(lineObj, doc.direction);\n      iterateBidiSections(order, fromArg || 0, toArg == null ? lineLen : toArg, function (from, to, dir, i) {\n        var ltr = dir == \"ltr\";\n        var fromPos = coords(from, ltr ? \"left\" : \"right\");\n        var toPos = coords(to - 1, ltr ? \"right\" : \"left\");\n\n        var openStart = fromArg == null && from == 0, openEnd = toArg == null && to == lineLen;\n        var first = i == 0, last = !order || i == order.length - 1;\n        if (toPos.top - fromPos.top <= 3) { // Single line\n          var openLeft = (docLTR ? openStart : openEnd) && first;\n          var openRight = (docLTR ? openEnd : openStart) && last;\n          var left = openLeft ? leftSide : (ltr ? fromPos : toPos).left;\n          var right = openRight ? rightSide : (ltr ? toPos : fromPos).right;\n          add(left, fromPos.top, right - left, fromPos.bottom);\n        } else { // Multiple lines\n          var topLeft, topRight, botLeft, botRight;\n          if (ltr) {\n            topLeft = docLTR && openStart && first ? leftSide : fromPos.left;\n            topRight = docLTR ? rightSide : wrapX(from, dir, \"before\");\n            botLeft = docLTR ? leftSide : wrapX(to, dir, \"after\");\n            botRight = docLTR && openEnd && last ? rightSide : toPos.right;\n          } else {\n            topLeft = !docLTR ? leftSide : wrapX(from, dir, \"before\");\n            topRight = !docLTR && openStart && first ? rightSide : fromPos.right;\n            botLeft = !docLTR && openEnd && last ? leftSide : toPos.left;\n            botRight = !docLTR ? rightSide : wrapX(to, dir, \"after\");\n          }\n          add(topLeft, fromPos.top, topRight - topLeft, fromPos.bottom);\n          if (fromPos.bottom < toPos.top) { add(leftSide, fromPos.bottom, null, toPos.top); }\n          add(botLeft, toPos.top, botRight - botLeft, toPos.bottom);\n        }\n\n        if (!start || cmpCoords(fromPos, start) < 0) { start = fromPos; }\n        if (cmpCoords(toPos, start) < 0) { start = toPos; }\n        if (!end || cmpCoords(fromPos, end) < 0) { end = fromPos; }\n        if (cmpCoords(toPos, end) < 0) { end = toPos; }\n      });\n      return {start: start, end: end}\n    }\n\n    var sFrom = range.from(), sTo = range.to();\n    if (sFrom.line == sTo.line) {\n      drawForLine(sFrom.line, sFrom.ch, sTo.ch);\n    } else {\n      var fromLine = getLine(doc, sFrom.line), toLine = getLine(doc, sTo.line);\n      var singleVLine = visualLine(fromLine) == visualLine(toLine);\n      var leftEnd = drawForLine(sFrom.line, sFrom.ch, singleVLine ? fromLine.text.length + 1 : null).end;\n      var rightStart = drawForLine(sTo.line, singleVLine ? 0 : null, sTo.ch).start;\n      if (singleVLine) {\n        if (leftEnd.top < rightStart.top - 2) {\n          add(leftEnd.right, leftEnd.top, null, leftEnd.bottom);\n          add(leftSide, rightStart.top, rightStart.left, rightStart.bottom);\n        } else {\n          add(leftEnd.right, leftEnd.top, rightStart.left - leftEnd.right, leftEnd.bottom);\n        }\n      }\n      if (leftEnd.bottom < rightStart.top)\n        { add(leftSide, leftEnd.bottom, null, rightStart.top); }\n    }\n\n    output.appendChild(fragment);\n  }\n\n  // Cursor-blinking\n  function restartBlink(cm) {\n    if (!cm.state.focused) { return }\n    var display = cm.display;\n    clearInterval(display.blinker);\n    var on = true;\n    display.cursorDiv.style.visibility = \"\";\n    if (cm.options.cursorBlinkRate > 0)\n      { display.blinker = setInterval(function () {\n        if (!cm.hasFocus()) { onBlur(cm); }\n        display.cursorDiv.style.visibility = (on = !on) ? \"\" : \"hidden\";\n      }, cm.options.cursorBlinkRate); }\n    else if (cm.options.cursorBlinkRate < 0)\n      { display.cursorDiv.style.visibility = \"hidden\"; }\n  }\n\n  function ensureFocus(cm) {\n    if (!cm.hasFocus()) {\n      cm.display.input.focus();\n      if (!cm.state.focused) { onFocus(cm); }\n    }\n  }\n\n  function delayBlurEvent(cm) {\n    cm.state.delayingBlurEvent = true;\n    setTimeout(function () { if (cm.state.delayingBlurEvent) {\n      cm.state.delayingBlurEvent = false;\n      if (cm.state.focused) { onBlur(cm); }\n    } }, 100);\n  }\n\n  function onFocus(cm, e) {\n    if (cm.state.delayingBlurEvent && !cm.state.draggingText) { cm.state.delayingBlurEvent = false; }\n\n    if (cm.options.readOnly == \"nocursor\") { return }\n    if (!cm.state.focused) {\n      signal(cm, \"focus\", cm, e);\n      cm.state.focused = true;\n      addClass(cm.display.wrapper, \"CodeMirror-focused\");\n      // This test prevents this from firing when a context\n      // menu is closed (since the input reset would kill the\n      // select-all detection hack)\n      if (!cm.curOp && cm.display.selForContextMenu != cm.doc.sel) {\n        cm.display.input.reset();\n        if (webkit) { setTimeout(function () { return cm.display.input.reset(true); }, 20); } // Issue #1730\n      }\n      cm.display.input.receivedFocus();\n    }\n    restartBlink(cm);\n  }\n  function onBlur(cm, e) {\n    if (cm.state.delayingBlurEvent) { return }\n\n    if (cm.state.focused) {\n      signal(cm, \"blur\", cm, e);\n      cm.state.focused = false;\n      rmClass(cm.display.wrapper, \"CodeMirror-focused\");\n    }\n    clearInterval(cm.display.blinker);\n    setTimeout(function () { if (!cm.state.focused) { cm.display.shift = false; } }, 150);\n  }\n\n  // Read the actual heights of the rendered lines, and update their\n  // stored heights to match.\n  function updateHeightsInViewport(cm) {\n    var display = cm.display;\n    var prevBottom = display.lineDiv.offsetTop;\n    var viewTop = Math.max(0, display.scroller.getBoundingClientRect().top);\n    var oldHeight = display.lineDiv.getBoundingClientRect().top;\n    var mustScroll = 0;\n    for (var i = 0; i < display.view.length; i++) {\n      var cur = display.view[i], wrapping = cm.options.lineWrapping;\n      var height = (void 0), width = 0;\n      if (cur.hidden) { continue }\n      oldHeight += cur.line.height;\n      if (ie && ie_version < 8) {\n        var bot = cur.node.offsetTop + cur.node.offsetHeight;\n        height = bot - prevBottom;\n        prevBottom = bot;\n      } else {\n        var box = cur.node.getBoundingClientRect();\n        height = box.bottom - box.top;\n        // Check that lines don't extend past the right of the current\n        // editor width\n        if (!wrapping && cur.text.firstChild)\n          { width = cur.text.firstChild.getBoundingClientRect().right - box.left - 1; }\n      }\n      var diff = cur.line.height - height;\n      if (diff > .005 || diff < -.005) {\n        if (oldHeight < viewTop) { mustScroll -= diff; }\n        updateLineHeight(cur.line, height);\n        updateWidgetHeight(cur.line);\n        if (cur.rest) { for (var j = 0; j < cur.rest.length; j++)\n          { updateWidgetHeight(cur.rest[j]); } }\n      }\n      if (width > cm.display.sizerWidth) {\n        var chWidth = Math.ceil(width / charWidth(cm.display));\n        if (chWidth > cm.display.maxLineLength) {\n          cm.display.maxLineLength = chWidth;\n          cm.display.maxLine = cur.line;\n          cm.display.maxLineChanged = true;\n        }\n      }\n    }\n    if (Math.abs(mustScroll) > 2) { display.scroller.scrollTop += mustScroll; }\n  }\n\n  // Read and store the height of line widgets associated with the\n  // given line.\n  function updateWidgetHeight(line) {\n    if (line.widgets) { for (var i = 0; i < line.widgets.length; ++i) {\n      var w = line.widgets[i], parent = w.node.parentNode;\n      if (parent) { w.height = parent.offsetHeight; }\n    } }\n  }\n\n  // Compute the lines that are visible in a given viewport (defaults\n  // the the current scroll position). viewport may contain top,\n  // height, and ensure (see op.scrollToPos) properties.\n  function visibleLines(display, doc, viewport) {\n    var top = viewport && viewport.top != null ? Math.max(0, viewport.top) : display.scroller.scrollTop;\n    top = Math.floor(top - paddingTop(display));\n    var bottom = viewport && viewport.bottom != null ? viewport.bottom : top + display.wrapper.clientHeight;\n\n    var from = lineAtHeight(doc, top), to = lineAtHeight(doc, bottom);\n    // Ensure is a {from: {line, ch}, to: {line, ch}} object, and\n    // forces those lines into the viewport (if possible).\n    if (viewport && viewport.ensure) {\n      var ensureFrom = viewport.ensure.from.line, ensureTo = viewport.ensure.to.line;\n      if (ensureFrom < from) {\n        from = ensureFrom;\n        to = lineAtHeight(doc, heightAtLine(getLine(doc, ensureFrom)) + display.wrapper.clientHeight);\n      } else if (Math.min(ensureTo, doc.lastLine()) >= to) {\n        from = lineAtHeight(doc, heightAtLine(getLine(doc, ensureTo)) - display.wrapper.clientHeight);\n        to = ensureTo;\n      }\n    }\n    return {from: from, to: Math.max(to, from + 1)}\n  }\n\n  // SCROLLING THINGS INTO VIEW\n\n  // If an editor sits on the top or bottom of the window, partially\n  // scrolled out of view, this ensures that the cursor is visible.\n  function maybeScrollWindow(cm, rect) {\n    if (signalDOMEvent(cm, \"scrollCursorIntoView\")) { return }\n\n    var display = cm.display, box = display.sizer.getBoundingClientRect(), doScroll = null;\n    var doc = display.wrapper.ownerDocument;\n    if (rect.top + box.top < 0) { doScroll = true; }\n    else if (rect.bottom + box.top > (doc.defaultView.innerHeight || doc.documentElement.clientHeight)) { doScroll = false; }\n    if (doScroll != null && !phantom) {\n      var scrollNode = elt(\"div\", \"\\u200b\", null, (\"position: absolute;\\n                         top: \" + (rect.top - display.viewOffset - paddingTop(cm.display)) + \"px;\\n                         height: \" + (rect.bottom - rect.top + scrollGap(cm) + display.barHeight) + \"px;\\n                         left: \" + (rect.left) + \"px; width: \" + (Math.max(2, rect.right - rect.left)) + \"px;\"));\n      cm.display.lineSpace.appendChild(scrollNode);\n      scrollNode.scrollIntoView(doScroll);\n      cm.display.lineSpace.removeChild(scrollNode);\n    }\n  }\n\n  // Scroll a given position into view (immediately), verifying that\n  // it actually became visible (as line heights are accurately\n  // measured, the position of something may 'drift' during drawing).\n  function scrollPosIntoView(cm, pos, end, margin) {\n    if (margin == null) { margin = 0; }\n    var rect;\n    if (!cm.options.lineWrapping && pos == end) {\n      // Set pos and end to the cursor positions around the character pos sticks to\n      // If pos.sticky == \"before\", that is around pos.ch - 1, otherwise around pos.ch\n      // If pos == Pos(_, 0, \"before\"), pos and end are unchanged\n      end = pos.sticky == \"before\" ? Pos(pos.line, pos.ch + 1, \"before\") : pos;\n      pos = pos.ch ? Pos(pos.line, pos.sticky == \"before\" ? pos.ch - 1 : pos.ch, \"after\") : pos;\n    }\n    for (var limit = 0; limit < 5; limit++) {\n      var changed = false;\n      var coords = cursorCoords(cm, pos);\n      var endCoords = !end || end == pos ? coords : cursorCoords(cm, end);\n      rect = {left: Math.min(coords.left, endCoords.left),\n              top: Math.min(coords.top, endCoords.top) - margin,\n              right: Math.max(coords.left, endCoords.left),\n              bottom: Math.max(coords.bottom, endCoords.bottom) + margin};\n      var scrollPos = calculateScrollPos(cm, rect);\n      var startTop = cm.doc.scrollTop, startLeft = cm.doc.scrollLeft;\n      if (scrollPos.scrollTop != null) {\n        updateScrollTop(cm, scrollPos.scrollTop);\n        if (Math.abs(cm.doc.scrollTop - startTop) > 1) { changed = true; }\n      }\n      if (scrollPos.scrollLeft != null) {\n        setScrollLeft(cm, scrollPos.scrollLeft);\n        if (Math.abs(cm.doc.scrollLeft - startLeft) > 1) { changed = true; }\n      }\n      if (!changed) { break }\n    }\n    return rect\n  }\n\n  // Scroll a given set of coordinates into view (immediately).\n  function scrollIntoView(cm, rect) {\n    var scrollPos = calculateScrollPos(cm, rect);\n    if (scrollPos.scrollTop != null) { updateScrollTop(cm, scrollPos.scrollTop); }\n    if (scrollPos.scrollLeft != null) { setScrollLeft(cm, scrollPos.scrollLeft); }\n  }\n\n  // Calculate a new scroll position needed to scroll the given\n  // rectangle into view. Returns an object with scrollTop and\n  // scrollLeft properties. When these are undefined, the\n  // vertical/horizontal position does not need to be adjusted.\n  function calculateScrollPos(cm, rect) {\n    var display = cm.display, snapMargin = textHeight(cm.display);\n    if (rect.top < 0) { rect.top = 0; }\n    var screentop = cm.curOp && cm.curOp.scrollTop != null ? cm.curOp.scrollTop : display.scroller.scrollTop;\n    var screen = displayHeight(cm), result = {};\n    if (rect.bottom - rect.top > screen) { rect.bottom = rect.top + screen; }\n    var docBottom = cm.doc.height + paddingVert(display);\n    var atTop = rect.top < snapMargin, atBottom = rect.bottom > docBottom - snapMargin;\n    if (rect.top < screentop) {\n      result.scrollTop = atTop ? 0 : rect.top;\n    } else if (rect.bottom > screentop + screen) {\n      var newTop = Math.min(rect.top, (atBottom ? docBottom : rect.bottom) - screen);\n      if (newTop != screentop) { result.scrollTop = newTop; }\n    }\n\n    var gutterSpace = cm.options.fixedGutter ? 0 : display.gutters.offsetWidth;\n    var screenleft = cm.curOp && cm.curOp.scrollLeft != null ? cm.curOp.scrollLeft : display.scroller.scrollLeft - gutterSpace;\n    var screenw = displayWidth(cm) - display.gutters.offsetWidth;\n    var tooWide = rect.right - rect.left > screenw;\n    if (tooWide) { rect.right = rect.left + screenw; }\n    if (rect.left < 10)\n      { result.scrollLeft = 0; }\n    else if (rect.left < screenleft)\n      { result.scrollLeft = Math.max(0, rect.left + gutterSpace - (tooWide ? 0 : 10)); }\n    else if (rect.right > screenw + screenleft - 3)\n      { result.scrollLeft = rect.right + (tooWide ? 0 : 10) - screenw; }\n    return result\n  }\n\n  // Store a relative adjustment to the scroll position in the current\n  // operation (to be applied when the operation finishes).\n  function addToScrollTop(cm, top) {\n    if (top == null) { return }\n    resolveScrollToPos(cm);\n    cm.curOp.scrollTop = (cm.curOp.scrollTop == null ? cm.doc.scrollTop : cm.curOp.scrollTop) + top;\n  }\n\n  // Make sure that at the end of the operation the current cursor is\n  // shown.\n  function ensureCursorVisible(cm) {\n    resolveScrollToPos(cm);\n    var cur = cm.getCursor();\n    cm.curOp.scrollToPos = {from: cur, to: cur, margin: cm.options.cursorScrollMargin};\n  }\n\n  function scrollToCoords(cm, x, y) {\n    if (x != null || y != null) { resolveScrollToPos(cm); }\n    if (x != null) { cm.curOp.scrollLeft = x; }\n    if (y != null) { cm.curOp.scrollTop = y; }\n  }\n\n  function scrollToRange(cm, range) {\n    resolveScrollToPos(cm);\n    cm.curOp.scrollToPos = range;\n  }\n\n  // When an operation has its scrollToPos property set, and another\n  // scroll action is applied before the end of the operation, this\n  // 'simulates' scrolling that position into view in a cheap way, so\n  // that the effect of intermediate scroll commands is not ignored.\n  function resolveScrollToPos(cm) {\n    var range = cm.curOp.scrollToPos;\n    if (range) {\n      cm.curOp.scrollToPos = null;\n      var from = estimateCoords(cm, range.from), to = estimateCoords(cm, range.to);\n      scrollToCoordsRange(cm, from, to, range.margin);\n    }\n  }\n\n  function scrollToCoordsRange(cm, from, to, margin) {\n    var sPos = calculateScrollPos(cm, {\n      left: Math.min(from.left, to.left),\n      top: Math.min(from.top, to.top) - margin,\n      right: Math.max(from.right, to.right),\n      bottom: Math.max(from.bottom, to.bottom) + margin\n    });\n    scrollToCoords(cm, sPos.scrollLeft, sPos.scrollTop);\n  }\n\n  // Sync the scrollable area and scrollbars, ensure the viewport\n  // covers the visible area.\n  function updateScrollTop(cm, val) {\n    if (Math.abs(cm.doc.scrollTop - val) < 2) { return }\n    if (!gecko) { updateDisplaySimple(cm, {top: val}); }\n    setScrollTop(cm, val, true);\n    if (gecko) { updateDisplaySimple(cm); }\n    startWorker(cm, 100);\n  }\n\n  function setScrollTop(cm, val, forceScroll) {\n    val = Math.max(0, Math.min(cm.display.scroller.scrollHeight - cm.display.scroller.clientHeight, val));\n    if (cm.display.scroller.scrollTop == val && !forceScroll) { return }\n    cm.doc.scrollTop = val;\n    cm.display.scrollbars.setScrollTop(val);\n    if (cm.display.scroller.scrollTop != val) { cm.display.scroller.scrollTop = val; }\n  }\n\n  // Sync scroller and scrollbar, ensure the gutter elements are\n  // aligned.\n  function setScrollLeft(cm, val, isScroller, forceScroll) {\n    val = Math.max(0, Math.min(val, cm.display.scroller.scrollWidth - cm.display.scroller.clientWidth));\n    if ((isScroller ? val == cm.doc.scrollLeft : Math.abs(cm.doc.scrollLeft - val) < 2) && !forceScroll) { return }\n    cm.doc.scrollLeft = val;\n    alignHorizontally(cm);\n    if (cm.display.scroller.scrollLeft != val) { cm.display.scroller.scrollLeft = val; }\n    cm.display.scrollbars.setScrollLeft(val);\n  }\n\n  // SCROLLBARS\n\n  // Prepare DOM reads needed to update the scrollbars. Done in one\n  // shot to minimize update/measure roundtrips.\n  function measureForScrollbars(cm) {\n    var d = cm.display, gutterW = d.gutters.offsetWidth;\n    var docH = Math.round(cm.doc.height + paddingVert(cm.display));\n    return {\n      clientHeight: d.scroller.clientHeight,\n      viewHeight: d.wrapper.clientHeight,\n      scrollWidth: d.scroller.scrollWidth, clientWidth: d.scroller.clientWidth,\n      viewWidth: d.wrapper.clientWidth,\n      barLeft: cm.options.fixedGutter ? gutterW : 0,\n      docHeight: docH,\n      scrollHeight: docH + scrollGap(cm) + d.barHeight,\n      nativeBarWidth: d.nativeBarWidth,\n      gutterWidth: gutterW\n    }\n  }\n\n  var NativeScrollbars = function(place, scroll, cm) {\n    this.cm = cm;\n    var vert = this.vert = elt(\"div\", [elt(\"div\", null, null, \"min-width: 1px\")], \"CodeMirror-vscrollbar\");\n    var horiz = this.horiz = elt(\"div\", [elt(\"div\", null, null, \"height: 100%; min-height: 1px\")], \"CodeMirror-hscrollbar\");\n    vert.tabIndex = horiz.tabIndex = -1;\n    place(vert); place(horiz);\n\n    on(vert, \"scroll\", function () {\n      if (vert.clientHeight) { scroll(vert.scrollTop, \"vertical\"); }\n    });\n    on(horiz, \"scroll\", function () {\n      if (horiz.clientWidth) { scroll(horiz.scrollLeft, \"horizontal\"); }\n    });\n\n    this.checkedZeroWidth = false;\n    // Need to set a minimum width to see the scrollbar on IE7 (but must not set it on IE8).\n    if (ie && ie_version < 8) { this.horiz.style.minHeight = this.vert.style.minWidth = \"18px\"; }\n  };\n\n  NativeScrollbars.prototype.update = function (measure) {\n    var needsH = measure.scrollWidth > measure.clientWidth + 1;\n    var needsV = measure.scrollHeight > measure.clientHeight + 1;\n    var sWidth = measure.nativeBarWidth;\n\n    if (needsV) {\n      this.vert.style.display = \"block\";\n      this.vert.style.bottom = needsH ? sWidth + \"px\" : \"0\";\n      var totalHeight = measure.viewHeight - (needsH ? sWidth : 0);\n      // A bug in IE8 can cause this value to be negative, so guard it.\n      this.vert.firstChild.style.height =\n        Math.max(0, measure.scrollHeight - measure.clientHeight + totalHeight) + \"px\";\n    } else {\n      this.vert.scrollTop = 0;\n      this.vert.style.display = \"\";\n      this.vert.firstChild.style.height = \"0\";\n    }\n\n    if (needsH) {\n      this.horiz.style.display = \"block\";\n      this.horiz.style.right = needsV ? sWidth + \"px\" : \"0\";\n      this.horiz.style.left = measure.barLeft + \"px\";\n      var totalWidth = measure.viewWidth - measure.barLeft - (needsV ? sWidth : 0);\n      this.horiz.firstChild.style.width =\n        Math.max(0, measure.scrollWidth - measure.clientWidth + totalWidth) + \"px\";\n    } else {\n      this.horiz.style.display = \"\";\n      this.horiz.firstChild.style.width = \"0\";\n    }\n\n    if (!this.checkedZeroWidth && measure.clientHeight > 0) {\n      if (sWidth == 0) { this.zeroWidthHack(); }\n      this.checkedZeroWidth = true;\n    }\n\n    return {right: needsV ? sWidth : 0, bottom: needsH ? sWidth : 0}\n  };\n\n  NativeScrollbars.prototype.setScrollLeft = function (pos) {\n    if (this.horiz.scrollLeft != pos) { this.horiz.scrollLeft = pos; }\n    if (this.disableHoriz) { this.enableZeroWidthBar(this.horiz, this.disableHoriz, \"horiz\"); }\n  };\n\n  NativeScrollbars.prototype.setScrollTop = function (pos) {\n    if (this.vert.scrollTop != pos) { this.vert.scrollTop = pos; }\n    if (this.disableVert) { this.enableZeroWidthBar(this.vert, this.disableVert, \"vert\"); }\n  };\n\n  NativeScrollbars.prototype.zeroWidthHack = function () {\n    var w = mac && !mac_geMountainLion ? \"12px\" : \"18px\";\n    this.horiz.style.height = this.vert.style.width = w;\n    this.horiz.style.visibility = this.vert.style.visibility = \"hidden\";\n    this.disableHoriz = new Delayed;\n    this.disableVert = new Delayed;\n  };\n\n  NativeScrollbars.prototype.enableZeroWidthBar = function (bar, delay, type) {\n    bar.style.visibility = \"\";\n    function maybeDisable() {\n      // To find out whether the scrollbar is still visible, we\n      // check whether the element under the pixel in the bottom\n      // right corner of the scrollbar box is the scrollbar box\n      // itself (when the bar is still visible) or its filler child\n      // (when the bar is hidden). If it is still visible, we keep\n      // it enabled, if it's hidden, we disable pointer events.\n      var box = bar.getBoundingClientRect();\n      var elt = type == \"vert\" ? document.elementFromPoint(box.right - 1, (box.top + box.bottom) / 2)\n          : document.elementFromPoint((box.right + box.left) / 2, box.bottom - 1);\n      if (elt != bar) { bar.style.visibility = \"hidden\"; }\n      else { delay.set(1000, maybeDisable); }\n    }\n    delay.set(1000, maybeDisable);\n  };\n\n  NativeScrollbars.prototype.clear = function () {\n    var parent = this.horiz.parentNode;\n    parent.removeChild(this.horiz);\n    parent.removeChild(this.vert);\n  };\n\n  var NullScrollbars = function () {};\n\n  NullScrollbars.prototype.update = function () { return {bottom: 0, right: 0} };\n  NullScrollbars.prototype.setScrollLeft = function () {};\n  NullScrollbars.prototype.setScrollTop = function () {};\n  NullScrollbars.prototype.clear = function () {};\n\n  function updateScrollbars(cm, measure) {\n    if (!measure) { measure = measureForScrollbars(cm); }\n    var startWidth = cm.display.barWidth, startHeight = cm.display.barHeight;\n    updateScrollbarsInner(cm, measure);\n    for (var i = 0; i < 4 && startWidth != cm.display.barWidth || startHeight != cm.display.barHeight; i++) {\n      if (startWidth != cm.display.barWidth && cm.options.lineWrapping)\n        { updateHeightsInViewport(cm); }\n      updateScrollbarsInner(cm, measureForScrollbars(cm));\n      startWidth = cm.display.barWidth; startHeight = cm.display.barHeight;\n    }\n  }\n\n  // Re-synchronize the fake scrollbars with the actual size of the\n  // content.\n  function updateScrollbarsInner(cm, measure) {\n    var d = cm.display;\n    var sizes = d.scrollbars.update(measure);\n\n    d.sizer.style.paddingRight = (d.barWidth = sizes.right) + \"px\";\n    d.sizer.style.paddingBottom = (d.barHeight = sizes.bottom) + \"px\";\n    d.heightForcer.style.borderBottom = sizes.bottom + \"px solid transparent\";\n\n    if (sizes.right && sizes.bottom) {\n      d.scrollbarFiller.style.display = \"block\";\n      d.scrollbarFiller.style.height = sizes.bottom + \"px\";\n      d.scrollbarFiller.style.width = sizes.right + \"px\";\n    } else { d.scrollbarFiller.style.display = \"\"; }\n    if (sizes.bottom && cm.options.coverGutterNextToScrollbar && cm.options.fixedGutter) {\n      d.gutterFiller.style.display = \"block\";\n      d.gutterFiller.style.height = sizes.bottom + \"px\";\n      d.gutterFiller.style.width = measure.gutterWidth + \"px\";\n    } else { d.gutterFiller.style.display = \"\"; }\n  }\n\n  var scrollbarModel = {\"native\": NativeScrollbars, \"null\": NullScrollbars};\n\n  function initScrollbars(cm) {\n    if (cm.display.scrollbars) {\n      cm.display.scrollbars.clear();\n      if (cm.display.scrollbars.addClass)\n        { rmClass(cm.display.wrapper, cm.display.scrollbars.addClass); }\n    }\n\n    cm.display.scrollbars = new scrollbarModel[cm.options.scrollbarStyle](function (node) {\n      cm.display.wrapper.insertBefore(node, cm.display.scrollbarFiller);\n      // Prevent clicks in the scrollbars from killing focus\n      on(node, \"mousedown\", function () {\n        if (cm.state.focused) { setTimeout(function () { return cm.display.input.focus(); }, 0); }\n      });\n      node.setAttribute(\"cm-not-content\", \"true\");\n    }, function (pos, axis) {\n      if (axis == \"horizontal\") { setScrollLeft(cm, pos); }\n      else { updateScrollTop(cm, pos); }\n    }, cm);\n    if (cm.display.scrollbars.addClass)\n      { addClass(cm.display.wrapper, cm.display.scrollbars.addClass); }\n  }\n\n  // Operations are used to wrap a series of changes to the editor\n  // state in such a way that each change won't have to update the\n  // cursor and display (which would be awkward, slow, and\n  // error-prone). Instead, display updates are batched and then all\n  // combined and executed at once.\n\n  var nextOpId = 0;\n  // Start a new operation.\n  function startOperation(cm) {\n    cm.curOp = {\n      cm: cm,\n      viewChanged: false,      // Flag that indicates that lines might need to be redrawn\n      startHeight: cm.doc.height, // Used to detect need to update scrollbar\n      forceUpdate: false,      // Used to force a redraw\n      updateInput: 0,       // Whether to reset the input textarea\n      typing: false,           // Whether this reset should be careful to leave existing text (for compositing)\n      changeObjs: null,        // Accumulated changes, for firing change events\n      cursorActivityHandlers: null, // Set of handlers to fire cursorActivity on\n      cursorActivityCalled: 0, // Tracks which cursorActivity handlers have been called already\n      selectionChanged: false, // Whether the selection needs to be redrawn\n      updateMaxLine: false,    // Set when the widest line needs to be determined anew\n      scrollLeft: null, scrollTop: null, // Intermediate scroll position, not pushed to DOM yet\n      scrollToPos: null,       // Used to scroll to a specific position\n      focus: false,\n      id: ++nextOpId,          // Unique ID\n      markArrays: null         // Used by addMarkedSpan\n    };\n    pushOperation(cm.curOp);\n  }\n\n  // Finish an operation, updating the display and signalling delayed events\n  function endOperation(cm) {\n    var op = cm.curOp;\n    if (op) { finishOperation(op, function (group) {\n      for (var i = 0; i < group.ops.length; i++)\n        { group.ops[i].cm.curOp = null; }\n      endOperations(group);\n    }); }\n  }\n\n  // The DOM updates done when an operation finishes are batched so\n  // that the minimum number of relayouts are required.\n  function endOperations(group) {\n    var ops = group.ops;\n    for (var i = 0; i < ops.length; i++) // Read DOM\n      { endOperation_R1(ops[i]); }\n    for (var i$1 = 0; i$1 < ops.length; i$1++) // Write DOM (maybe)\n      { endOperation_W1(ops[i$1]); }\n    for (var i$2 = 0; i$2 < ops.length; i$2++) // Read DOM\n      { endOperation_R2(ops[i$2]); }\n    for (var i$3 = 0; i$3 < ops.length; i$3++) // Write DOM (maybe)\n      { endOperation_W2(ops[i$3]); }\n    for (var i$4 = 0; i$4 < ops.length; i$4++) // Read DOM\n      { endOperation_finish(ops[i$4]); }\n  }\n\n  function endOperation_R1(op) {\n    var cm = op.cm, display = cm.display;\n    maybeClipScrollbars(cm);\n    if (op.updateMaxLine) { findMaxLine(cm); }\n\n    op.mustUpdate = op.viewChanged || op.forceUpdate || op.scrollTop != null ||\n      op.scrollToPos && (op.scrollToPos.from.line < display.viewFrom ||\n                         op.scrollToPos.to.line >= display.viewTo) ||\n      display.maxLineChanged && cm.options.lineWrapping;\n    op.update = op.mustUpdate &&\n      new DisplayUpdate(cm, op.mustUpdate && {top: op.scrollTop, ensure: op.scrollToPos}, op.forceUpdate);\n  }\n\n  function endOperation_W1(op) {\n    op.updatedDisplay = op.mustUpdate && updateDisplayIfNeeded(op.cm, op.update);\n  }\n\n  function endOperation_R2(op) {\n    var cm = op.cm, display = cm.display;\n    if (op.updatedDisplay) { updateHeightsInViewport(cm); }\n\n    op.barMeasure = measureForScrollbars(cm);\n\n    // If the max line changed since it was last measured, measure it,\n    // and ensure the document's width matches it.\n    // updateDisplay_W2 will use these properties to do the actual resizing\n    if (display.maxLineChanged && !cm.options.lineWrapping) {\n      op.adjustWidthTo = measureChar(cm, display.maxLine, display.maxLine.text.length).left + 3;\n      cm.display.sizerWidth = op.adjustWidthTo;\n      op.barMeasure.scrollWidth =\n        Math.max(display.scroller.clientWidth, display.sizer.offsetLeft + op.adjustWidthTo + scrollGap(cm) + cm.display.barWidth);\n      op.maxScrollLeft = Math.max(0, display.sizer.offsetLeft + op.adjustWidthTo - displayWidth(cm));\n    }\n\n    if (op.updatedDisplay || op.selectionChanged)\n      { op.preparedSelection = display.input.prepareSelection(); }\n  }\n\n  function endOperation_W2(op) {\n    var cm = op.cm;\n\n    if (op.adjustWidthTo != null) {\n      cm.display.sizer.style.minWidth = op.adjustWidthTo + \"px\";\n      if (op.maxScrollLeft < cm.doc.scrollLeft)\n        { setScrollLeft(cm, Math.min(cm.display.scroller.scrollLeft, op.maxScrollLeft), true); }\n      cm.display.maxLineChanged = false;\n    }\n\n    var takeFocus = op.focus && op.focus == activeElt(root(cm));\n    if (op.preparedSelection)\n      { cm.display.input.showSelection(op.preparedSelection, takeFocus); }\n    if (op.updatedDisplay || op.startHeight != cm.doc.height)\n      { updateScrollbars(cm, op.barMeasure); }\n    if (op.updatedDisplay)\n      { setDocumentHeight(cm, op.barMeasure); }\n\n    if (op.selectionChanged) { restartBlink(cm); }\n\n    if (cm.state.focused && op.updateInput)\n      { cm.display.input.reset(op.typing); }\n    if (takeFocus) { ensureFocus(op.cm); }\n  }\n\n  function endOperation_finish(op) {\n    var cm = op.cm, display = cm.display, doc = cm.doc;\n\n    if (op.updatedDisplay) { postUpdateDisplay(cm, op.update); }\n\n    // Abort mouse wheel delta measurement, when scrolling explicitly\n    if (display.wheelStartX != null && (op.scrollTop != null || op.scrollLeft != null || op.scrollToPos))\n      { display.wheelStartX = display.wheelStartY = null; }\n\n    // Propagate the scroll position to the actual DOM scroller\n    if (op.scrollTop != null) { setScrollTop(cm, op.scrollTop, op.forceScroll); }\n\n    if (op.scrollLeft != null) { setScrollLeft(cm, op.scrollLeft, true, true); }\n    // If we need to scroll a specific position into view, do so.\n    if (op.scrollToPos) {\n      var rect = scrollPosIntoView(cm, clipPos(doc, op.scrollToPos.from),\n                                   clipPos(doc, op.scrollToPos.to), op.scrollToPos.margin);\n      maybeScrollWindow(cm, rect);\n    }\n\n    // Fire events for markers that are hidden/unidden by editing or\n    // undoing\n    var hidden = op.maybeHiddenMarkers, unhidden = op.maybeUnhiddenMarkers;\n    if (hidden) { for (var i = 0; i < hidden.length; ++i)\n      { if (!hidden[i].lines.length) { signal(hidden[i], \"hide\"); } } }\n    if (unhidden) { for (var i$1 = 0; i$1 < unhidden.length; ++i$1)\n      { if (unhidden[i$1].lines.length) { signal(unhidden[i$1], \"unhide\"); } } }\n\n    if (display.wrapper.offsetHeight)\n      { doc.scrollTop = cm.display.scroller.scrollTop; }\n\n    // Fire change events, and delayed event handlers\n    if (op.changeObjs)\n      { signal(cm, \"changes\", cm, op.changeObjs); }\n    if (op.update)\n      { op.update.finish(); }\n  }\n\n  // Run the given function in an operation\n  function runInOp(cm, f) {\n    if (cm.curOp) { return f() }\n    startOperation(cm);\n    try { return f() }\n    finally { endOperation(cm); }\n  }\n  // Wraps a function in an operation. Returns the wrapped function.\n  function operation(cm, f) {\n    return function() {\n      if (cm.curOp) { return f.apply(cm, arguments) }\n      startOperation(cm);\n      try { return f.apply(cm, arguments) }\n      finally { endOperation(cm); }\n    }\n  }\n  // Used to add methods to editor and doc instances, wrapping them in\n  // operations.\n  function methodOp(f) {\n    return function() {\n      if (this.curOp) { return f.apply(this, arguments) }\n      startOperation(this);\n      try { return f.apply(this, arguments) }\n      finally { endOperation(this); }\n    }\n  }\n  function docMethodOp(f) {\n    return function() {\n      var cm = this.cm;\n      if (!cm || cm.curOp) { return f.apply(this, arguments) }\n      startOperation(cm);\n      try { return f.apply(this, arguments) }\n      finally { endOperation(cm); }\n    }\n  }\n\n  // HIGHLIGHT WORKER\n\n  function startWorker(cm, time) {\n    if (cm.doc.highlightFrontier < cm.display.viewTo)\n      { cm.state.highlight.set(time, bind(highlightWorker, cm)); }\n  }\n\n  function highlightWorker(cm) {\n    var doc = cm.doc;\n    if (doc.highlightFrontier >= cm.display.viewTo) { return }\n    var end = +new Date + cm.options.workTime;\n    var context = getContextBefore(cm, doc.highlightFrontier);\n    var changedLines = [];\n\n    doc.iter(context.line, Math.min(doc.first + doc.size, cm.display.viewTo + 500), function (line) {\n      if (context.line >= cm.display.viewFrom) { // Visible\n        var oldStyles = line.styles;\n        var resetState = line.text.length > cm.options.maxHighlightLength ? copyState(doc.mode, context.state) : null;\n        var highlighted = highlightLine(cm, line, context, true);\n        if (resetState) { context.state = resetState; }\n        line.styles = highlighted.styles;\n        var oldCls = line.styleClasses, newCls = highlighted.classes;\n        if (newCls) { line.styleClasses = newCls; }\n        else if (oldCls) { line.styleClasses = null; }\n        var ischange = !oldStyles || oldStyles.length != line.styles.length ||\n          oldCls != newCls && (!oldCls || !newCls || oldCls.bgClass != newCls.bgClass || oldCls.textClass != newCls.textClass);\n        for (var i = 0; !ischange && i < oldStyles.length; ++i) { ischange = oldStyles[i] != line.styles[i]; }\n        if (ischange) { changedLines.push(context.line); }\n        line.stateAfter = context.save();\n        context.nextLine();\n      } else {\n        if (line.text.length <= cm.options.maxHighlightLength)\n          { processLine(cm, line.text, context); }\n        line.stateAfter = context.line % 5 == 0 ? context.save() : null;\n        context.nextLine();\n      }\n      if (+new Date > end) {\n        startWorker(cm, cm.options.workDelay);\n        return true\n      }\n    });\n    doc.highlightFrontier = context.line;\n    doc.modeFrontier = Math.max(doc.modeFrontier, context.line);\n    if (changedLines.length) { runInOp(cm, function () {\n      for (var i = 0; i < changedLines.length; i++)\n        { regLineChange(cm, changedLines[i], \"text\"); }\n    }); }\n  }\n\n  // DISPLAY DRAWING\n\n  var DisplayUpdate = function(cm, viewport, force) {\n    var display = cm.display;\n\n    this.viewport = viewport;\n    // Store some values that we'll need later (but don't want to force a relayout for)\n    this.visible = visibleLines(display, cm.doc, viewport);\n    this.editorIsHidden = !display.wrapper.offsetWidth;\n    this.wrapperHeight = display.wrapper.clientHeight;\n    this.wrapperWidth = display.wrapper.clientWidth;\n    this.oldDisplayWidth = displayWidth(cm);\n    this.force = force;\n    this.dims = getDimensions(cm);\n    this.events = [];\n  };\n\n  DisplayUpdate.prototype.signal = function (emitter, type) {\n    if (hasHandler(emitter, type))\n      { this.events.push(arguments); }\n  };\n  DisplayUpdate.prototype.finish = function () {\n    for (var i = 0; i < this.events.length; i++)\n      { signal.apply(null, this.events[i]); }\n  };\n\n  function maybeClipScrollbars(cm) {\n    var display = cm.display;\n    if (!display.scrollbarsClipped && display.scroller.offsetWidth) {\n      display.nativeBarWidth = display.scroller.offsetWidth - display.scroller.clientWidth;\n      display.heightForcer.style.height = scrollGap(cm) + \"px\";\n      display.sizer.style.marginBottom = -display.nativeBarWidth + \"px\";\n      display.sizer.style.borderRightWidth = scrollGap(cm) + \"px\";\n      display.scrollbarsClipped = true;\n    }\n  }\n\n  function selectionSnapshot(cm) {\n    if (cm.hasFocus()) { return null }\n    var active = activeElt(root(cm));\n    if (!active || !contains(cm.display.lineDiv, active)) { return null }\n    var result = {activeElt: active};\n    if (window.getSelection) {\n      var sel = win(cm).getSelection();\n      if (sel.anchorNode && sel.extend && contains(cm.display.lineDiv, sel.anchorNode)) {\n        result.anchorNode = sel.anchorNode;\n        result.anchorOffset = sel.anchorOffset;\n        result.focusNode = sel.focusNode;\n        result.focusOffset = sel.focusOffset;\n      }\n    }\n    return result\n  }\n\n  function restoreSelection(snapshot) {\n    if (!snapshot || !snapshot.activeElt || snapshot.activeElt == activeElt(rootNode(snapshot.activeElt))) { return }\n    snapshot.activeElt.focus();\n    if (!/^(INPUT|TEXTAREA)$/.test(snapshot.activeElt.nodeName) &&\n        snapshot.anchorNode && contains(document.body, snapshot.anchorNode) && contains(document.body, snapshot.focusNode)) {\n      var doc = snapshot.activeElt.ownerDocument;\n      var sel = doc.defaultView.getSelection(), range = doc.createRange();\n      range.setEnd(snapshot.anchorNode, snapshot.anchorOffset);\n      range.collapse(false);\n      sel.removeAllRanges();\n      sel.addRange(range);\n      sel.extend(snapshot.focusNode, snapshot.focusOffset);\n    }\n  }\n\n  // Does the actual updating of the line display. Bails out\n  // (returning false) when there is nothing to be done and forced is\n  // false.\n  function updateDisplayIfNeeded(cm, update) {\n    var display = cm.display, doc = cm.doc;\n\n    if (update.editorIsHidden) {\n      resetView(cm);\n      return false\n    }\n\n    // Bail out if the visible area is already rendered and nothing changed.\n    if (!update.force &&\n        update.visible.from >= display.viewFrom && update.visible.to <= display.viewTo &&\n        (display.updateLineNumbers == null || display.updateLineNumbers >= display.viewTo) &&\n        display.renderedView == display.view && countDirtyView(cm) == 0)\n      { return false }\n\n    if (maybeUpdateLineNumberWidth(cm)) {\n      resetView(cm);\n      update.dims = getDimensions(cm);\n    }\n\n    // Compute a suitable new viewport (from & to)\n    var end = doc.first + doc.size;\n    var from = Math.max(update.visible.from - cm.options.viewportMargin, doc.first);\n    var to = Math.min(end, update.visible.to + cm.options.viewportMargin);\n    if (display.viewFrom < from && from - display.viewFrom < 20) { from = Math.max(doc.first, display.viewFrom); }\n    if (display.viewTo > to && display.viewTo - to < 20) { to = Math.min(end, display.viewTo); }\n    if (sawCollapsedSpans) {\n      from = visualLineNo(cm.doc, from);\n      to = visualLineEndNo(cm.doc, to);\n    }\n\n    var different = from != display.viewFrom || to != display.viewTo ||\n      display.lastWrapHeight != update.wrapperHeight || display.lastWrapWidth != update.wrapperWidth;\n    adjustView(cm, from, to);\n\n    display.viewOffset = heightAtLine(getLine(cm.doc, display.viewFrom));\n    // Position the mover div to align with the current scroll position\n    cm.display.mover.style.top = display.viewOffset + \"px\";\n\n    var toUpdate = countDirtyView(cm);\n    if (!different && toUpdate == 0 && !update.force && display.renderedView == display.view &&\n        (display.updateLineNumbers == null || display.updateLineNumbers >= display.viewTo))\n      { return false }\n\n    // For big changes, we hide the enclosing element during the\n    // update, since that speeds up the operations on most browsers.\n    var selSnapshot = selectionSnapshot(cm);\n    if (toUpdate > 4) { display.lineDiv.style.display = \"none\"; }\n    patchDisplay(cm, display.updateLineNumbers, update.dims);\n    if (toUpdate > 4) { display.lineDiv.style.display = \"\"; }\n    display.renderedView = display.view;\n    // There might have been a widget with a focused element that got\n    // hidden or updated, if so re-focus it.\n    restoreSelection(selSnapshot);\n\n    // Prevent selection and cursors from interfering with the scroll\n    // width and height.\n    removeChildren(display.cursorDiv);\n    removeChildren(display.selectionDiv);\n    display.gutters.style.height = display.sizer.style.minHeight = 0;\n\n    if (different) {\n      display.lastWrapHeight = update.wrapperHeight;\n      display.lastWrapWidth = update.wrapperWidth;\n      startWorker(cm, 400);\n    }\n\n    display.updateLineNumbers = null;\n\n    return true\n  }\n\n  function postUpdateDisplay(cm, update) {\n    var viewport = update.viewport;\n\n    for (var first = true;; first = false) {\n      if (!first || !cm.options.lineWrapping || update.oldDisplayWidth == displayWidth(cm)) {\n        // Clip forced viewport to actual scrollable area.\n        if (viewport && viewport.top != null)\n          { viewport = {top: Math.min(cm.doc.height + paddingVert(cm.display) - displayHeight(cm), viewport.top)}; }\n        // Updated line heights might result in the drawn area not\n        // actually covering the viewport. Keep looping until it does.\n        update.visible = visibleLines(cm.display, cm.doc, viewport);\n        if (update.visible.from >= cm.display.viewFrom && update.visible.to <= cm.display.viewTo)\n          { break }\n      } else if (first) {\n        update.visible = visibleLines(cm.display, cm.doc, viewport);\n      }\n      if (!updateDisplayIfNeeded(cm, update)) { break }\n      updateHeightsInViewport(cm);\n      var barMeasure = measureForScrollbars(cm);\n      updateSelection(cm);\n      updateScrollbars(cm, barMeasure);\n      setDocumentHeight(cm, barMeasure);\n      update.force = false;\n    }\n\n    update.signal(cm, \"update\", cm);\n    if (cm.display.viewFrom != cm.display.reportedViewFrom || cm.display.viewTo != cm.display.reportedViewTo) {\n      update.signal(cm, \"viewportChange\", cm, cm.display.viewFrom, cm.display.viewTo);\n      cm.display.reportedViewFrom = cm.display.viewFrom; cm.display.reportedViewTo = cm.display.viewTo;\n    }\n  }\n\n  function updateDisplaySimple(cm, viewport) {\n    var update = new DisplayUpdate(cm, viewport);\n    if (updateDisplayIfNeeded(cm, update)) {\n      updateHeightsInViewport(cm);\n      postUpdateDisplay(cm, update);\n      var barMeasure = measureForScrollbars(cm);\n      updateSelection(cm);\n      updateScrollbars(cm, barMeasure);\n      setDocumentHeight(cm, barMeasure);\n      update.finish();\n    }\n  }\n\n  // Sync the actual display DOM structure with display.view, removing\n  // nodes for lines that are no longer in view, and creating the ones\n  // that are not there yet, and updating the ones that are out of\n  // date.\n  function patchDisplay(cm, updateNumbersFrom, dims) {\n    var display = cm.display, lineNumbers = cm.options.lineNumbers;\n    var container = display.lineDiv, cur = container.firstChild;\n\n    function rm(node) {\n      var next = node.nextSibling;\n      // Works around a throw-scroll bug in OS X Webkit\n      if (webkit && mac && cm.display.currentWheelTarget == node)\n        { node.style.display = \"none\"; }\n      else\n        { node.parentNode.removeChild(node); }\n      return next\n    }\n\n    var view = display.view, lineN = display.viewFrom;\n    // Loop over the elements in the view, syncing cur (the DOM nodes\n    // in display.lineDiv) with the view as we go.\n    for (var i = 0; i < view.length; i++) {\n      var lineView = view[i];\n      if (lineView.hidden) ; else if (!lineView.node || lineView.node.parentNode != container) { // Not drawn yet\n        var node = buildLineElement(cm, lineView, lineN, dims);\n        container.insertBefore(node, cur);\n      } else { // Already drawn\n        while (cur != lineView.node) { cur = rm(cur); }\n        var updateNumber = lineNumbers && updateNumbersFrom != null &&\n          updateNumbersFrom <= lineN && lineView.lineNumber;\n        if (lineView.changes) {\n          if (indexOf(lineView.changes, \"gutter\") > -1) { updateNumber = false; }\n          updateLineForChanges(cm, lineView, lineN, dims);\n        }\n        if (updateNumber) {\n          removeChildren(lineView.lineNumber);\n          lineView.lineNumber.appendChild(document.createTextNode(lineNumberFor(cm.options, lineN)));\n        }\n        cur = lineView.node.nextSibling;\n      }\n      lineN += lineView.size;\n    }\n    while (cur) { cur = rm(cur); }\n  }\n\n  function updateGutterSpace(display) {\n    var width = display.gutters.offsetWidth;\n    display.sizer.style.marginLeft = width + \"px\";\n    // Send an event to consumers responding to changes in gutter width.\n    signalLater(display, \"gutterChanged\", display);\n  }\n\n  function setDocumentHeight(cm, measure) {\n    cm.display.sizer.style.minHeight = measure.docHeight + \"px\";\n    cm.display.heightForcer.style.top = measure.docHeight + \"px\";\n    cm.display.gutters.style.height = (measure.docHeight + cm.display.barHeight + scrollGap(cm)) + \"px\";\n  }\n\n  // Re-align line numbers and gutter marks to compensate for\n  // horizontal scrolling.\n  function alignHorizontally(cm) {\n    var display = cm.display, view = display.view;\n    if (!display.alignWidgets && (!display.gutters.firstChild || !cm.options.fixedGutter)) { return }\n    var comp = compensateForHScroll(display) - display.scroller.scrollLeft + cm.doc.scrollLeft;\n    var gutterW = display.gutters.offsetWidth, left = comp + \"px\";\n    for (var i = 0; i < view.length; i++) { if (!view[i].hidden) {\n      if (cm.options.fixedGutter) {\n        if (view[i].gutter)\n          { view[i].gutter.style.left = left; }\n        if (view[i].gutterBackground)\n          { view[i].gutterBackground.style.left = left; }\n      }\n      var align = view[i].alignable;\n      if (align) { for (var j = 0; j < align.length; j++)\n        { align[j].style.left = left; } }\n    } }\n    if (cm.options.fixedGutter)\n      { display.gutters.style.left = (comp + gutterW) + \"px\"; }\n  }\n\n  // Used to ensure that the line number gutter is still the right\n  // size for the current document size. Returns true when an update\n  // is needed.\n  function maybeUpdateLineNumberWidth(cm) {\n    if (!cm.options.lineNumbers) { return false }\n    var doc = cm.doc, last = lineNumberFor(cm.options, doc.first + doc.size - 1), display = cm.display;\n    if (last.length != display.lineNumChars) {\n      var test = display.measure.appendChild(elt(\"div\", [elt(\"div\", last)],\n                                                 \"CodeMirror-linenumber CodeMirror-gutter-elt\"));\n      var innerW = test.firstChild.offsetWidth, padding = test.offsetWidth - innerW;\n      display.lineGutter.style.width = \"\";\n      display.lineNumInnerWidth = Math.max(innerW, display.lineGutter.offsetWidth - padding) + 1;\n      display.lineNumWidth = display.lineNumInnerWidth + padding;\n      display.lineNumChars = display.lineNumInnerWidth ? last.length : -1;\n      display.lineGutter.style.width = display.lineNumWidth + \"px\";\n      updateGutterSpace(cm.display);\n      return true\n    }\n    return false\n  }\n\n  function getGutters(gutters, lineNumbers) {\n    var result = [], sawLineNumbers = false;\n    for (var i = 0; i < gutters.length; i++) {\n      var name = gutters[i], style = null;\n      if (typeof name != \"string\") { style = name.style; name = name.className; }\n      if (name == \"CodeMirror-linenumbers\") {\n        if (!lineNumbers) { continue }\n        else { sawLineNumbers = true; }\n      }\n      result.push({className: name, style: style});\n    }\n    if (lineNumbers && !sawLineNumbers) { result.push({className: \"CodeMirror-linenumbers\", style: null}); }\n    return result\n  }\n\n  // Rebuild the gutter elements, ensure the margin to the left of the\n  // code matches their width.\n  function renderGutters(display) {\n    var gutters = display.gutters, specs = display.gutterSpecs;\n    removeChildren(gutters);\n    display.lineGutter = null;\n    for (var i = 0; i < specs.length; ++i) {\n      var ref = specs[i];\n      var className = ref.className;\n      var style = ref.style;\n      var gElt = gutters.appendChild(elt(\"div\", null, \"CodeMirror-gutter \" + className));\n      if (style) { gElt.style.cssText = style; }\n      if (className == \"CodeMirror-linenumbers\") {\n        display.lineGutter = gElt;\n        gElt.style.width = (display.lineNumWidth || 1) + \"px\";\n      }\n    }\n    gutters.style.display = specs.length ? \"\" : \"none\";\n    updateGutterSpace(display);\n  }\n\n  function updateGutters(cm) {\n    renderGutters(cm.display);\n    regChange(cm);\n    alignHorizontally(cm);\n  }\n\n  // The display handles the DOM integration, both for input reading\n  // and content drawing. It holds references to DOM nodes and\n  // display-related state.\n\n  function Display(place, doc, input, options) {\n    var d = this;\n    this.input = input;\n\n    // Covers bottom-right square when both scrollbars are present.\n    d.scrollbarFiller = elt(\"div\", null, \"CodeMirror-scrollbar-filler\");\n    d.scrollbarFiller.setAttribute(\"cm-not-content\", \"true\");\n    // Covers bottom of gutter when coverGutterNextToScrollbar is on\n    // and h scrollbar is present.\n    d.gutterFiller = elt(\"div\", null, \"CodeMirror-gutter-filler\");\n    d.gutterFiller.setAttribute(\"cm-not-content\", \"true\");\n    // Will contain the actual code, positioned to cover the viewport.\n    d.lineDiv = eltP(\"div\", null, \"CodeMirror-code\");\n    // Elements are added to these to represent selection and cursors.\n    d.selectionDiv = elt(\"div\", null, null, \"position: relative; z-index: 1\");\n    d.cursorDiv = elt(\"div\", null, \"CodeMirror-cursors\");\n    // A visibility: hidden element used to find the size of things.\n    d.measure = elt(\"div\", null, \"CodeMirror-measure\");\n    // When lines outside of the viewport are measured, they are drawn in this.\n    d.lineMeasure = elt(\"div\", null, \"CodeMirror-measure\");\n    // Wraps everything that needs to exist inside the vertically-padded coordinate system\n    d.lineSpace = eltP(\"div\", [d.measure, d.lineMeasure, d.selectionDiv, d.cursorDiv, d.lineDiv],\n                      null, \"position: relative; outline: none\");\n    var lines = eltP(\"div\", [d.lineSpace], \"CodeMirror-lines\");\n    // Moved around its parent to cover visible view.\n    d.mover = elt(\"div\", [lines], null, \"position: relative\");\n    // Set to the height of the document, allowing scrolling.\n    d.sizer = elt(\"div\", [d.mover], \"CodeMirror-sizer\");\n    d.sizerWidth = null;\n    // Behavior of elts with overflow: auto and padding is\n    // inconsistent across browsers. This is used to ensure the\n    // scrollable area is big enough.\n    d.heightForcer = elt(\"div\", null, null, \"position: absolute; height: \" + scrollerGap + \"px; width: 1px;\");\n    // Will contain the gutters, if any.\n    d.gutters = elt(\"div\", null, \"CodeMirror-gutters\");\n    d.lineGutter = null;\n    // Actual scrollable element.\n    d.scroller = elt(\"div\", [d.sizer, d.heightForcer, d.gutters], \"CodeMirror-scroll\");\n    d.scroller.setAttribute(\"tabIndex\", \"-1\");\n    // The element in which the editor lives.\n    d.wrapper = elt(\"div\", [d.scrollbarFiller, d.gutterFiller, d.scroller], \"CodeMirror\");\n    // See #6982. FIXME remove when this has been fixed for a while in Chrome\n    if (chrome && chrome_version >= 105) { d.wrapper.style.clipPath = \"inset(0px)\"; }\n\n    // This attribute is respected by automatic translation systems such as Google Translate,\n    // and may also be respected by tools used by human translators.\n    d.wrapper.setAttribute('translate', 'no');\n\n    // Work around IE7 z-index bug (not perfect, hence IE7 not really being supported)\n    if (ie && ie_version < 8) { d.gutters.style.zIndex = -1; d.scroller.style.paddingRight = 0; }\n    if (!webkit && !(gecko && mobile)) { d.scroller.draggable = true; }\n\n    if (place) {\n      if (place.appendChild) { place.appendChild(d.wrapper); }\n      else { place(d.wrapper); }\n    }\n\n    // Current rendered range (may be bigger than the view window).\n    d.viewFrom = d.viewTo = doc.first;\n    d.reportedViewFrom = d.reportedViewTo = doc.first;\n    // Information about the rendered lines.\n    d.view = [];\n    d.renderedView = null;\n    // Holds info about a single rendered line when it was rendered\n    // for measurement, while not in view.\n    d.externalMeasured = null;\n    // Empty space (in pixels) above the view\n    d.viewOffset = 0;\n    d.lastWrapHeight = d.lastWrapWidth = 0;\n    d.updateLineNumbers = null;\n\n    d.nativeBarWidth = d.barHeight = d.barWidth = 0;\n    d.scrollbarsClipped = false;\n\n    // Used to only resize the line number gutter when necessary (when\n    // the amount of lines crosses a boundary that makes its width change)\n    d.lineNumWidth = d.lineNumInnerWidth = d.lineNumChars = null;\n    // Set to true when a non-horizontal-scrolling line widget is\n    // added. As an optimization, line widget aligning is skipped when\n    // this is false.\n    d.alignWidgets = false;\n\n    d.cachedCharWidth = d.cachedTextHeight = d.cachedPaddingH = null;\n\n    // Tracks the maximum line length so that the horizontal scrollbar\n    // can be kept static when scrolling.\n    d.maxLine = null;\n    d.maxLineLength = 0;\n    d.maxLineChanged = false;\n\n    // Used for measuring wheel scrolling granularity\n    d.wheelDX = d.wheelDY = d.wheelStartX = d.wheelStartY = null;\n\n    // True when shift is held down.\n    d.shift = false;\n\n    // Used to track whether anything happened since the context menu\n    // was opened.\n    d.selForContextMenu = null;\n\n    d.activeTouch = null;\n\n    d.gutterSpecs = getGutters(options.gutters, options.lineNumbers);\n    renderGutters(d);\n\n    input.init(d);\n  }\n\n  // Since the delta values reported on mouse wheel events are\n  // unstandardized between browsers and even browser versions, and\n  // generally horribly unpredictable, this code starts by measuring\n  // the scroll effect that the first few mouse wheel events have,\n  // and, from that, detects the way it can convert deltas to pixel\n  // offsets afterwards.\n  //\n  // The reason we want to know the amount a wheel event will scroll\n  // is that it gives us a chance to update the display before the\n  // actual scrolling happens, reducing flickering.\n\n  var wheelSamples = 0, wheelPixelsPerUnit = null;\n  // Fill in a browser-detected starting value on browsers where we\n  // know one. These don't have to be accurate -- the result of them\n  // being wrong would just be a slight flicker on the first wheel\n  // scroll (if it is large enough).\n  if (ie) { wheelPixelsPerUnit = -.53; }\n  else if (gecko) { wheelPixelsPerUnit = 15; }\n  else if (chrome) { wheelPixelsPerUnit = -.7; }\n  else if (safari) { wheelPixelsPerUnit = -1/3; }\n\n  function wheelEventDelta(e) {\n    var dx = e.wheelDeltaX, dy = e.wheelDeltaY;\n    if (dx == null && e.detail && e.axis == e.HORIZONTAL_AXIS) { dx = e.detail; }\n    if (dy == null && e.detail && e.axis == e.VERTICAL_AXIS) { dy = e.detail; }\n    else if (dy == null) { dy = e.wheelDelta; }\n    return {x: dx, y: dy}\n  }\n  function wheelEventPixels(e) {\n    var delta = wheelEventDelta(e);\n    delta.x *= wheelPixelsPerUnit;\n    delta.y *= wheelPixelsPerUnit;\n    return delta\n  }\n\n  function onScrollWheel(cm, e) {\n    // On Chrome 102, viewport updates somehow stop wheel-based\n    // scrolling. Turning off pointer events during the scroll seems\n    // to avoid the issue.\n    if (chrome && chrome_version == 102) {\n      if (cm.display.chromeScrollHack == null) { cm.display.sizer.style.pointerEvents = \"none\"; }\n      else { clearTimeout(cm.display.chromeScrollHack); }\n      cm.display.chromeScrollHack = setTimeout(function () {\n        cm.display.chromeScrollHack = null;\n        cm.display.sizer.style.pointerEvents = \"\";\n      }, 100);\n    }\n    var delta = wheelEventDelta(e), dx = delta.x, dy = delta.y;\n    var pixelsPerUnit = wheelPixelsPerUnit;\n    if (e.deltaMode === 0) {\n      dx = e.deltaX;\n      dy = e.deltaY;\n      pixelsPerUnit = 1;\n    }\n\n    var display = cm.display, scroll = display.scroller;\n    // Quit if there's nothing to scroll here\n    var canScrollX = scroll.scrollWidth > scroll.clientWidth;\n    var canScrollY = scroll.scrollHeight > scroll.clientHeight;\n    if (!(dx && canScrollX || dy && canScrollY)) { return }\n\n    // Webkit browsers on OS X abort momentum scrolls when the target\n    // of the scroll event is removed from the scrollable element.\n    // This hack (see related code in patchDisplay) makes sure the\n    // element is kept around.\n    if (dy && mac && webkit) {\n      outer: for (var cur = e.target, view = display.view; cur != scroll; cur = cur.parentNode) {\n        for (var i = 0; i < view.length; i++) {\n          if (view[i].node == cur) {\n            cm.display.currentWheelTarget = cur;\n            break outer\n          }\n        }\n      }\n    }\n\n    // On some browsers, horizontal scrolling will cause redraws to\n    // happen before the gutter has been realigned, causing it to\n    // wriggle around in a most unseemly way. When we have an\n    // estimated pixels/delta value, we just handle horizontal\n    // scrolling entirely here. It'll be slightly off from native, but\n    // better than glitching out.\n    if (dx && !gecko && !presto && pixelsPerUnit != null) {\n      if (dy && canScrollY)\n        { updateScrollTop(cm, Math.max(0, scroll.scrollTop + dy * pixelsPerUnit)); }\n      setScrollLeft(cm, Math.max(0, scroll.scrollLeft + dx * pixelsPerUnit));\n      // Only prevent default scrolling if vertical scrolling is\n      // actually possible. Otherwise, it causes vertical scroll\n      // jitter on OSX trackpads when deltaX is small and deltaY\n      // is large (issue #3579)\n      if (!dy || (dy && canScrollY))\n        { e_preventDefault(e); }\n      display.wheelStartX = null; // Abort measurement, if in progress\n      return\n    }\n\n    // 'Project' the visible viewport to cover the area that is being\n    // scrolled into view (if we know enough to estimate it).\n    if (dy && pixelsPerUnit != null) {\n      var pixels = dy * pixelsPerUnit;\n      var top = cm.doc.scrollTop, bot = top + display.wrapper.clientHeight;\n      if (pixels < 0) { top = Math.max(0, top + pixels - 50); }\n      else { bot = Math.min(cm.doc.height, bot + pixels + 50); }\n      updateDisplaySimple(cm, {top: top, bottom: bot});\n    }\n\n    if (wheelSamples < 20 && e.deltaMode !== 0) {\n      if (display.wheelStartX == null) {\n        display.wheelStartX = scroll.scrollLeft; display.wheelStartY = scroll.scrollTop;\n        display.wheelDX = dx; display.wheelDY = dy;\n        setTimeout(function () {\n          if (display.wheelStartX == null) { return }\n          var movedX = scroll.scrollLeft - display.wheelStartX;\n          var movedY = scroll.scrollTop - display.wheelStartY;\n          var sample = (movedY && display.wheelDY && movedY / display.wheelDY) ||\n            (movedX && display.wheelDX && movedX / display.wheelDX);\n          display.wheelStartX = display.wheelStartY = null;\n          if (!sample) { return }\n          wheelPixelsPerUnit = (wheelPixelsPerUnit * wheelSamples + sample) / (wheelSamples + 1);\n          ++wheelSamples;\n        }, 200);\n      } else {\n        display.wheelDX += dx; display.wheelDY += dy;\n      }\n    }\n  }\n\n  // Selection objects are immutable. A new one is created every time\n  // the selection changes. A selection is one or more non-overlapping\n  // (and non-touching) ranges, sorted, and an integer that indicates\n  // which one is the primary selection (the one that's scrolled into\n  // view, that getCursor returns, etc).\n  var Selection = function(ranges, primIndex) {\n    this.ranges = ranges;\n    this.primIndex = primIndex;\n  };\n\n  Selection.prototype.primary = function () { return this.ranges[this.primIndex] };\n\n  Selection.prototype.equals = function (other) {\n    if (other == this) { return true }\n    if (other.primIndex != this.primIndex || other.ranges.length != this.ranges.length) { return false }\n    for (var i = 0; i < this.ranges.length; i++) {\n      var here = this.ranges[i], there = other.ranges[i];\n      if (!equalCursorPos(here.anchor, there.anchor) || !equalCursorPos(here.head, there.head)) { return false }\n    }\n    return true\n  };\n\n  Selection.prototype.deepCopy = function () {\n    var out = [];\n    for (var i = 0; i < this.ranges.length; i++)\n      { out[i] = new Range(copyPos(this.ranges[i].anchor), copyPos(this.ranges[i].head)); }\n    return new Selection(out, this.primIndex)\n  };\n\n  Selection.prototype.somethingSelected = function () {\n    for (var i = 0; i < this.ranges.length; i++)\n      { if (!this.ranges[i].empty()) { return true } }\n    return false\n  };\n\n  Selection.prototype.contains = function (pos, end) {\n    if (!end) { end = pos; }\n    for (var i = 0; i < this.ranges.length; i++) {\n      var range = this.ranges[i];\n      if (cmp(end, range.from()) >= 0 && cmp(pos, range.to()) <= 0)\n        { return i }\n    }\n    return -1\n  };\n\n  var Range = function(anchor, head) {\n    this.anchor = anchor; this.head = head;\n  };\n\n  Range.prototype.from = function () { return minPos(this.anchor, this.head) };\n  Range.prototype.to = function () { return maxPos(this.anchor, this.head) };\n  Range.prototype.empty = function () { return this.head.line == this.anchor.line && this.head.ch == this.anchor.ch };\n\n  // Take an unsorted, potentially overlapping set of ranges, and\n  // build a selection out of it. 'Consumes' ranges array (modifying\n  // it).\n  function normalizeSelection(cm, ranges, primIndex) {\n    var mayTouch = cm && cm.options.selectionsMayTouch;\n    var prim = ranges[primIndex];\n    ranges.sort(function (a, b) { return cmp(a.from(), b.from()); });\n    primIndex = indexOf(ranges, prim);\n    for (var i = 1; i < ranges.length; i++) {\n      var cur = ranges[i], prev = ranges[i - 1];\n      var diff = cmp(prev.to(), cur.from());\n      if (mayTouch && !cur.empty() ? diff > 0 : diff >= 0) {\n        var from = minPos(prev.from(), cur.from()), to = maxPos(prev.to(), cur.to());\n        var inv = prev.empty() ? cur.from() == cur.head : prev.from() == prev.head;\n        if (i <= primIndex) { --primIndex; }\n        ranges.splice(--i, 2, new Range(inv ? to : from, inv ? from : to));\n      }\n    }\n    return new Selection(ranges, primIndex)\n  }\n\n  function simpleSelection(anchor, head) {\n    return new Selection([new Range(anchor, head || anchor)], 0)\n  }\n\n  // Compute the position of the end of a change (its 'to' property\n  // refers to the pre-change end).\n  function changeEnd(change) {\n    if (!change.text) { return change.to }\n    return Pos(change.from.line + change.text.length - 1,\n               lst(change.text).length + (change.text.length == 1 ? change.from.ch : 0))\n  }\n\n  // Adjust a position to refer to the post-change position of the\n  // same text, or the end of the change if the change covers it.\n  function adjustForChange(pos, change) {\n    if (cmp(pos, change.from) < 0) { return pos }\n    if (cmp(pos, change.to) <= 0) { return changeEnd(change) }\n\n    var line = pos.line + change.text.length - (change.to.line - change.from.line) - 1, ch = pos.ch;\n    if (pos.line == change.to.line) { ch += changeEnd(change).ch - change.to.ch; }\n    return Pos(line, ch)\n  }\n\n  function computeSelAfterChange(doc, change) {\n    var out = [];\n    for (var i = 0; i < doc.sel.ranges.length; i++) {\n      var range = doc.sel.ranges[i];\n      out.push(new Range(adjustForChange(range.anchor, change),\n                         adjustForChange(range.head, change)));\n    }\n    return normalizeSelection(doc.cm, out, doc.sel.primIndex)\n  }\n\n  function offsetPos(pos, old, nw) {\n    if (pos.line == old.line)\n      { return Pos(nw.line, pos.ch - old.ch + nw.ch) }\n    else\n      { return Pos(nw.line + (pos.line - old.line), pos.ch) }\n  }\n\n  // Used by replaceSelections to allow moving the selection to the\n  // start or around the replaced test. Hint may be \"start\" or \"around\".\n  function computeReplacedSel(doc, changes, hint) {\n    var out = [];\n    var oldPrev = Pos(doc.first, 0), newPrev = oldPrev;\n    for (var i = 0; i < changes.length; i++) {\n      var change = changes[i];\n      var from = offsetPos(change.from, oldPrev, newPrev);\n      var to = offsetPos(changeEnd(change), oldPrev, newPrev);\n      oldPrev = change.to;\n      newPrev = to;\n      if (hint == \"around\") {\n        var range = doc.sel.ranges[i], inv = cmp(range.head, range.anchor) < 0;\n        out[i] = new Range(inv ? to : from, inv ? from : to);\n      } else {\n        out[i] = new Range(from, from);\n      }\n    }\n    return new Selection(out, doc.sel.primIndex)\n  }\n\n  // Used to get the editor into a consistent state again when options change.\n\n  function loadMode(cm) {\n    cm.doc.mode = getMode(cm.options, cm.doc.modeOption);\n    resetModeState(cm);\n  }\n\n  function resetModeState(cm) {\n    cm.doc.iter(function (line) {\n      if (line.stateAfter) { line.stateAfter = null; }\n      if (line.styles) { line.styles = null; }\n    });\n    cm.doc.modeFrontier = cm.doc.highlightFrontier = cm.doc.first;\n    startWorker(cm, 100);\n    cm.state.modeGen++;\n    if (cm.curOp) { regChange(cm); }\n  }\n\n  // DOCUMENT DATA STRUCTURE\n\n  // By default, updates that start and end at the beginning of a line\n  // are treated specially, in order to make the association of line\n  // widgets and marker elements with the text behave more intuitive.\n  function isWholeLineUpdate(doc, change) {\n    return change.from.ch == 0 && change.to.ch == 0 && lst(change.text) == \"\" &&\n      (!doc.cm || doc.cm.options.wholeLineUpdateBefore)\n  }\n\n  // Perform a change on the document data structure.\n  function updateDoc(doc, change, markedSpans, estimateHeight) {\n    function spansFor(n) {return markedSpans ? markedSpans[n] : null}\n    function update(line, text, spans) {\n      updateLine(line, text, spans, estimateHeight);\n      signalLater(line, \"change\", line, change);\n    }\n    function linesFor(start, end) {\n      var result = [];\n      for (var i = start; i < end; ++i)\n        { result.push(new Line(text[i], spansFor(i), estimateHeight)); }\n      return result\n    }\n\n    var from = change.from, to = change.to, text = change.text;\n    var firstLine = getLine(doc, from.line), lastLine = getLine(doc, to.line);\n    var lastText = lst(text), lastSpans = spansFor(text.length - 1), nlines = to.line - from.line;\n\n    // Adjust the line structure\n    if (change.full) {\n      doc.insert(0, linesFor(0, text.length));\n      doc.remove(text.length, doc.size - text.length);\n    } else if (isWholeLineUpdate(doc, change)) {\n      // This is a whole-line replace. Treated specially to make\n      // sure line objects move the way they are supposed to.\n      var added = linesFor(0, text.length - 1);\n      update(lastLine, lastLine.text, lastSpans);\n      if (nlines) { doc.remove(from.line, nlines); }\n      if (added.length) { doc.insert(from.line, added); }\n    } else if (firstLine == lastLine) {\n      if (text.length == 1) {\n        update(firstLine, firstLine.text.slice(0, from.ch) + lastText + firstLine.text.slice(to.ch), lastSpans);\n      } else {\n        var added$1 = linesFor(1, text.length - 1);\n        added$1.push(new Line(lastText + firstLine.text.slice(to.ch), lastSpans, estimateHeight));\n        update(firstLine, firstLine.text.slice(0, from.ch) + text[0], spansFor(0));\n        doc.insert(from.line + 1, added$1);\n      }\n    } else if (text.length == 1) {\n      update(firstLine, firstLine.text.slice(0, from.ch) + text[0] + lastLine.text.slice(to.ch), spansFor(0));\n      doc.remove(from.line + 1, nlines);\n    } else {\n      update(firstLine, firstLine.text.slice(0, from.ch) + text[0], spansFor(0));\n      update(lastLine, lastText + lastLine.text.slice(to.ch), lastSpans);\n      var added$2 = linesFor(1, text.length - 1);\n      if (nlines > 1) { doc.remove(from.line + 1, nlines - 1); }\n      doc.insert(from.line + 1, added$2);\n    }\n\n    signalLater(doc, \"change\", doc, change);\n  }\n\n  // Call f for all linked documents.\n  function linkedDocs(doc, f, sharedHistOnly) {\n    function propagate(doc, skip, sharedHist) {\n      if (doc.linked) { for (var i = 0; i < doc.linked.length; ++i) {\n        var rel = doc.linked[i];\n        if (rel.doc == skip) { continue }\n        var shared = sharedHist && rel.sharedHist;\n        if (sharedHistOnly && !shared) { continue }\n        f(rel.doc, shared);\n        propagate(rel.doc, doc, shared);\n      } }\n    }\n    propagate(doc, null, true);\n  }\n\n  // Attach a document to an editor.\n  function attachDoc(cm, doc) {\n    if (doc.cm) { throw new Error(\"This document is already in use.\") }\n    cm.doc = doc;\n    doc.cm = cm;\n    estimateLineHeights(cm);\n    loadMode(cm);\n    setDirectionClass(cm);\n    cm.options.direction = doc.direction;\n    if (!cm.options.lineWrapping) { findMaxLine(cm); }\n    cm.options.mode = doc.modeOption;\n    regChange(cm);\n  }\n\n  function setDirectionClass(cm) {\n  (cm.doc.direction == \"rtl\" ? addClass : rmClass)(cm.display.lineDiv, \"CodeMirror-rtl\");\n  }\n\n  function directionChanged(cm) {\n    runInOp(cm, function () {\n      setDirectionClass(cm);\n      regChange(cm);\n    });\n  }\n\n  function History(prev) {\n    // Arrays of change events and selections. Doing something adds an\n    // event to done and clears undo. Undoing moves events from done\n    // to undone, redoing moves them in the other direction.\n    this.done = []; this.undone = [];\n    this.undoDepth = prev ? prev.undoDepth : Infinity;\n    // Used to track when changes can be merged into a single undo\n    // event\n    this.lastModTime = this.lastSelTime = 0;\n    this.lastOp = this.lastSelOp = null;\n    this.lastOrigin = this.lastSelOrigin = null;\n    // Used by the isClean() method\n    this.generation = this.maxGeneration = prev ? prev.maxGeneration : 1;\n  }\n\n  // Create a history change event from an updateDoc-style change\n  // object.\n  function historyChangeFromChange(doc, change) {\n    var histChange = {from: copyPos(change.from), to: changeEnd(change), text: getBetween(doc, change.from, change.to)};\n    attachLocalSpans(doc, histChange, change.from.line, change.to.line + 1);\n    linkedDocs(doc, function (doc) { return attachLocalSpans(doc, histChange, change.from.line, change.to.line + 1); }, true);\n    return histChange\n  }\n\n  // Pop all selection events off the end of a history array. Stop at\n  // a change event.\n  function clearSelectionEvents(array) {\n    while (array.length) {\n      var last = lst(array);\n      if (last.ranges) { array.pop(); }\n      else { break }\n    }\n  }\n\n  // Find the top change event in the history. Pop off selection\n  // events that are in the way.\n  function lastChangeEvent(hist, force) {\n    if (force) {\n      clearSelectionEvents(hist.done);\n      return lst(hist.done)\n    } else if (hist.done.length && !lst(hist.done).ranges) {\n      return lst(hist.done)\n    } else if (hist.done.length > 1 && !hist.done[hist.done.length - 2].ranges) {\n      hist.done.pop();\n      return lst(hist.done)\n    }\n  }\n\n  // Register a change in the history. Merges changes that are within\n  // a single operation, or are close together with an origin that\n  // allows merging (starting with \"+\") into a single event.\n  function addChangeToHistory(doc, change, selAfter, opId) {\n    var hist = doc.history;\n    hist.undone.length = 0;\n    var time = +new Date, cur;\n    var last;\n\n    if ((hist.lastOp == opId ||\n         hist.lastOrigin == change.origin && change.origin &&\n         ((change.origin.charAt(0) == \"+\" && hist.lastModTime > time - (doc.cm ? doc.cm.options.historyEventDelay : 500)) ||\n          change.origin.charAt(0) == \"*\")) &&\n        (cur = lastChangeEvent(hist, hist.lastOp == opId))) {\n      // Merge this change into the last event\n      last = lst(cur.changes);\n      if (cmp(change.from, change.to) == 0 && cmp(change.from, last.to) == 0) {\n        // Optimized case for simple insertion -- don't want to add\n        // new changesets for every character typed\n        last.to = changeEnd(change);\n      } else {\n        // Add new sub-event\n        cur.changes.push(historyChangeFromChange(doc, change));\n      }\n    } else {\n      // Can not be merged, start a new event.\n      var before = lst(hist.done);\n      if (!before || !before.ranges)\n        { pushSelectionToHistory(doc.sel, hist.done); }\n      cur = {changes: [historyChangeFromChange(doc, change)],\n             generation: hist.generation};\n      hist.done.push(cur);\n      while (hist.done.length > hist.undoDepth) {\n        hist.done.shift();\n        if (!hist.done[0].ranges) { hist.done.shift(); }\n      }\n    }\n    hist.done.push(selAfter);\n    hist.generation = ++hist.maxGeneration;\n    hist.lastModTime = hist.lastSelTime = time;\n    hist.lastOp = hist.lastSelOp = opId;\n    hist.lastOrigin = hist.lastSelOrigin = change.origin;\n\n    if (!last) { signal(doc, \"historyAdded\"); }\n  }\n\n  function selectionEventCanBeMerged(doc, origin, prev, sel) {\n    var ch = origin.charAt(0);\n    return ch == \"*\" ||\n      ch == \"+\" &&\n      prev.ranges.length == sel.ranges.length &&\n      prev.somethingSelected() == sel.somethingSelected() &&\n      new Date - doc.history.lastSelTime <= (doc.cm ? doc.cm.options.historyEventDelay : 500)\n  }\n\n  // Called whenever the selection changes, sets the new selection as\n  // the pending selection in the history, and pushes the old pending\n  // selection into the 'done' array when it was significantly\n  // different (in number of selected ranges, emptiness, or time).\n  function addSelectionToHistory(doc, sel, opId, options) {\n    var hist = doc.history, origin = options && options.origin;\n\n    // A new event is started when the previous origin does not match\n    // the current, or the origins don't allow matching. Origins\n    // starting with * are always merged, those starting with + are\n    // merged when similar and close together in time.\n    if (opId == hist.lastSelOp ||\n        (origin && hist.lastSelOrigin == origin &&\n         (hist.lastModTime == hist.lastSelTime && hist.lastOrigin == origin ||\n          selectionEventCanBeMerged(doc, origin, lst(hist.done), sel))))\n      { hist.done[hist.done.length - 1] = sel; }\n    else\n      { pushSelectionToHistory(sel, hist.done); }\n\n    hist.lastSelTime = +new Date;\n    hist.lastSelOrigin = origin;\n    hist.lastSelOp = opId;\n    if (options && options.clearRedo !== false)\n      { clearSelectionEvents(hist.undone); }\n  }\n\n  function pushSelectionToHistory(sel, dest) {\n    var top = lst(dest);\n    if (!(top && top.ranges && top.equals(sel)))\n      { dest.push(sel); }\n  }\n\n  // Used to store marked span information in the history.\n  function attachLocalSpans(doc, change, from, to) {\n    var existing = change[\"spans_\" + doc.id], n = 0;\n    doc.iter(Math.max(doc.first, from), Math.min(doc.first + doc.size, to), function (line) {\n      if (line.markedSpans)\n        { (existing || (existing = change[\"spans_\" + doc.id] = {}))[n] = line.markedSpans; }\n      ++n;\n    });\n  }\n\n  // When un/re-doing restores text containing marked spans, those\n  // that have been explicitly cleared should not be restored.\n  function removeClearedSpans(spans) {\n    if (!spans) { return null }\n    var out;\n    for (var i = 0; i < spans.length; ++i) {\n      if (spans[i].marker.explicitlyCleared) { if (!out) { out = spans.slice(0, i); } }\n      else if (out) { out.push(spans[i]); }\n    }\n    return !out ? spans : out.length ? out : null\n  }\n\n  // Retrieve and filter the old marked spans stored in a change event.\n  function getOldSpans(doc, change) {\n    var found = change[\"spans_\" + doc.id];\n    if (!found) { return null }\n    var nw = [];\n    for (var i = 0; i < change.text.length; ++i)\n      { nw.push(removeClearedSpans(found[i])); }\n    return nw\n  }\n\n  // Used for un/re-doing changes from the history. Combines the\n  // result of computing the existing spans with the set of spans that\n  // existed in the history (so that deleting around a span and then\n  // undoing brings back the span).\n  function mergeOldSpans(doc, change) {\n    var old = getOldSpans(doc, change);\n    var stretched = stretchSpansOverChange(doc, change);\n    if (!old) { return stretched }\n    if (!stretched) { return old }\n\n    for (var i = 0; i < old.length; ++i) {\n      var oldCur = old[i], stretchCur = stretched[i];\n      if (oldCur && stretchCur) {\n        spans: for (var j = 0; j < stretchCur.length; ++j) {\n          var span = stretchCur[j];\n          for (var k = 0; k < oldCur.length; ++k)\n            { if (oldCur[k].marker == span.marker) { continue spans } }\n          oldCur.push(span);\n        }\n      } else if (stretchCur) {\n        old[i] = stretchCur;\n      }\n    }\n    return old\n  }\n\n  // Used both to provide a JSON-safe object in .getHistory, and, when\n  // detaching a document, to split the history in two\n  function copyHistoryArray(events, newGroup, instantiateSel) {\n    var copy = [];\n    for (var i = 0; i < events.length; ++i) {\n      var event = events[i];\n      if (event.ranges) {\n        copy.push(instantiateSel ? Selection.prototype.deepCopy.call(event) : event);\n        continue\n      }\n      var changes = event.changes, newChanges = [];\n      copy.push({changes: newChanges});\n      for (var j = 0; j < changes.length; ++j) {\n        var change = changes[j], m = (void 0);\n        newChanges.push({from: change.from, to: change.to, text: change.text});\n        if (newGroup) { for (var prop in change) { if (m = prop.match(/^spans_(\\d+)$/)) {\n          if (indexOf(newGroup, Number(m[1])) > -1) {\n            lst(newChanges)[prop] = change[prop];\n            delete change[prop];\n          }\n        } } }\n      }\n    }\n    return copy\n  }\n\n  // The 'scroll' parameter given to many of these indicated whether\n  // the new cursor position should be scrolled into view after\n  // modifying the selection.\n\n  // If shift is held or the extend flag is set, extends a range to\n  // include a given position (and optionally a second position).\n  // Otherwise, simply returns the range between the given positions.\n  // Used for cursor motion and such.\n  function extendRange(range, head, other, extend) {\n    if (extend) {\n      var anchor = range.anchor;\n      if (other) {\n        var posBefore = cmp(head, anchor) < 0;\n        if (posBefore != (cmp(other, anchor) < 0)) {\n          anchor = head;\n          head = other;\n        } else if (posBefore != (cmp(head, other) < 0)) {\n          head = other;\n        }\n      }\n      return new Range(anchor, head)\n    } else {\n      return new Range(other || head, head)\n    }\n  }\n\n  // Extend the primary selection range, discard the rest.\n  function extendSelection(doc, head, other, options, extend) {\n    if (extend == null) { extend = doc.cm && (doc.cm.display.shift || doc.extend); }\n    setSelection(doc, new Selection([extendRange(doc.sel.primary(), head, other, extend)], 0), options);\n  }\n\n  // Extend all selections (pos is an array of selections with length\n  // equal the number of selections)\n  function extendSelections(doc, heads, options) {\n    var out = [];\n    var extend = doc.cm && (doc.cm.display.shift || doc.extend);\n    for (var i = 0; i < doc.sel.ranges.length; i++)\n      { out[i] = extendRange(doc.sel.ranges[i], heads[i], null, extend); }\n    var newSel = normalizeSelection(doc.cm, out, doc.sel.primIndex);\n    setSelection(doc, newSel, options);\n  }\n\n  // Updates a single range in the selection.\n  function replaceOneSelection(doc, i, range, options) {\n    var ranges = doc.sel.ranges.slice(0);\n    ranges[i] = range;\n    setSelection(doc, normalizeSelection(doc.cm, ranges, doc.sel.primIndex), options);\n  }\n\n  // Reset the selection to a single range.\n  function setSimpleSelection(doc, anchor, head, options) {\n    setSelection(doc, simpleSelection(anchor, head), options);\n  }\n\n  // Give beforeSelectionChange handlers a change to influence a\n  // selection update.\n  function filterSelectionChange(doc, sel, options) {\n    var obj = {\n      ranges: sel.ranges,\n      update: function(ranges) {\n        this.ranges = [];\n        for (var i = 0; i < ranges.length; i++)\n          { this.ranges[i] = new Range(clipPos(doc, ranges[i].anchor),\n                                     clipPos(doc, ranges[i].head)); }\n      },\n      origin: options && options.origin\n    };\n    signal(doc, \"beforeSelectionChange\", doc, obj);\n    if (doc.cm) { signal(doc.cm, \"beforeSelectionChange\", doc.cm, obj); }\n    if (obj.ranges != sel.ranges) { return normalizeSelection(doc.cm, obj.ranges, obj.ranges.length - 1) }\n    else { return sel }\n  }\n\n  function setSelectionReplaceHistory(doc, sel, options) {\n    var done = doc.history.done, last = lst(done);\n    if (last && last.ranges) {\n      done[done.length - 1] = sel;\n      setSelectionNoUndo(doc, sel, options);\n    } else {\n      setSelection(doc, sel, options);\n    }\n  }\n\n  // Set a new selection.\n  function setSelection(doc, sel, options) {\n    setSelectionNoUndo(doc, sel, options);\n    addSelectionToHistory(doc, doc.sel, doc.cm ? doc.cm.curOp.id : NaN, options);\n  }\n\n  function setSelectionNoUndo(doc, sel, options) {\n    if (hasHandler(doc, \"beforeSelectionChange\") || doc.cm && hasHandler(doc.cm, \"beforeSelectionChange\"))\n      { sel = filterSelectionChange(doc, sel, options); }\n\n    var bias = options && options.bias ||\n      (cmp(sel.primary().head, doc.sel.primary().head) < 0 ? -1 : 1);\n    setSelectionInner(doc, skipAtomicInSelection(doc, sel, bias, true));\n\n    if (!(options && options.scroll === false) && doc.cm && doc.cm.getOption(\"readOnly\") != \"nocursor\")\n      { ensureCursorVisible(doc.cm); }\n  }\n\n  function setSelectionInner(doc, sel) {\n    if (sel.equals(doc.sel)) { return }\n\n    doc.sel = sel;\n\n    if (doc.cm) {\n      doc.cm.curOp.updateInput = 1;\n      doc.cm.curOp.selectionChanged = true;\n      signalCursorActivity(doc.cm);\n    }\n    signalLater(doc, \"cursorActivity\", doc);\n  }\n\n  // Verify that the selection does not partially select any atomic\n  // marked ranges.\n  function reCheckSelection(doc) {\n    setSelectionInner(doc, skipAtomicInSelection(doc, doc.sel, null, false));\n  }\n\n  // Return a selection that does not partially select any atomic\n  // ranges.\n  function skipAtomicInSelection(doc, sel, bias, mayClear) {\n    var out;\n    for (var i = 0; i < sel.ranges.length; i++) {\n      var range = sel.ranges[i];\n      var old = sel.ranges.length == doc.sel.ranges.length && doc.sel.ranges[i];\n      var newAnchor = skipAtomic(doc, range.anchor, old && old.anchor, bias, mayClear);\n      var newHead = range.head == range.anchor ? newAnchor : skipAtomic(doc, range.head, old && old.head, bias, mayClear);\n      if (out || newAnchor != range.anchor || newHead != range.head) {\n        if (!out) { out = sel.ranges.slice(0, i); }\n        out[i] = new Range(newAnchor, newHead);\n      }\n    }\n    return out ? normalizeSelection(doc.cm, out, sel.primIndex) : sel\n  }\n\n  function skipAtomicInner(doc, pos, oldPos, dir, mayClear) {\n    var line = getLine(doc, pos.line);\n    if (line.markedSpans) { for (var i = 0; i < line.markedSpans.length; ++i) {\n      var sp = line.markedSpans[i], m = sp.marker;\n\n      // Determine if we should prevent the cursor being placed to the left/right of an atomic marker\n      // Historically this was determined using the inclusiveLeft/Right option, but the new way to control it\n      // is with selectLeft/Right\n      var preventCursorLeft = (\"selectLeft\" in m) ? !m.selectLeft : m.inclusiveLeft;\n      var preventCursorRight = (\"selectRight\" in m) ? !m.selectRight : m.inclusiveRight;\n\n      if ((sp.from == null || (preventCursorLeft ? sp.from <= pos.ch : sp.from < pos.ch)) &&\n          (sp.to == null || (preventCursorRight ? sp.to >= pos.ch : sp.to > pos.ch))) {\n        if (mayClear) {\n          signal(m, \"beforeCursorEnter\");\n          if (m.explicitlyCleared) {\n            if (!line.markedSpans) { break }\n            else {--i; continue}\n          }\n        }\n        if (!m.atomic) { continue }\n\n        if (oldPos) {\n          var near = m.find(dir < 0 ? 1 : -1), diff = (void 0);\n          if (dir < 0 ? preventCursorRight : preventCursorLeft)\n            { near = movePos(doc, near, -dir, near && near.line == pos.line ? line : null); }\n          if (near && near.line == pos.line && (diff = cmp(near, oldPos)) && (dir < 0 ? diff < 0 : diff > 0))\n            { return skipAtomicInner(doc, near, pos, dir, mayClear) }\n        }\n\n        var far = m.find(dir < 0 ? -1 : 1);\n        if (dir < 0 ? preventCursorLeft : preventCursorRight)\n          { far = movePos(doc, far, dir, far.line == pos.line ? line : null); }\n        return far ? skipAtomicInner(doc, far, pos, dir, mayClear) : null\n      }\n    } }\n    return pos\n  }\n\n  // Ensure a given position is not inside an atomic range.\n  function skipAtomic(doc, pos, oldPos, bias, mayClear) {\n    var dir = bias || 1;\n    var found = skipAtomicInner(doc, pos, oldPos, dir, mayClear) ||\n        (!mayClear && skipAtomicInner(doc, pos, oldPos, dir, true)) ||\n        skipAtomicInner(doc, pos, oldPos, -dir, mayClear) ||\n        (!mayClear && skipAtomicInner(doc, pos, oldPos, -dir, true));\n    if (!found) {\n      doc.cantEdit = true;\n      return Pos(doc.first, 0)\n    }\n    return found\n  }\n\n  function movePos(doc, pos, dir, line) {\n    if (dir < 0 && pos.ch == 0) {\n      if (pos.line > doc.first) { return clipPos(doc, Pos(pos.line - 1)) }\n      else { return null }\n    } else if (dir > 0 && pos.ch == (line || getLine(doc, pos.line)).text.length) {\n      if (pos.line < doc.first + doc.size - 1) { return Pos(pos.line + 1, 0) }\n      else { return null }\n    } else {\n      return new Pos(pos.line, pos.ch + dir)\n    }\n  }\n\n  function selectAll(cm) {\n    cm.setSelection(Pos(cm.firstLine(), 0), Pos(cm.lastLine()), sel_dontScroll);\n  }\n\n  // UPDATING\n\n  // Allow \"beforeChange\" event handlers to influence a change\n  function filterChange(doc, change, update) {\n    var obj = {\n      canceled: false,\n      from: change.from,\n      to: change.to,\n      text: change.text,\n      origin: change.origin,\n      cancel: function () { return obj.canceled = true; }\n    };\n    if (update) { obj.update = function (from, to, text, origin) {\n      if (from) { obj.from = clipPos(doc, from); }\n      if (to) { obj.to = clipPos(doc, to); }\n      if (text) { obj.text = text; }\n      if (origin !== undefined) { obj.origin = origin; }\n    }; }\n    signal(doc, \"beforeChange\", doc, obj);\n    if (doc.cm) { signal(doc.cm, \"beforeChange\", doc.cm, obj); }\n\n    if (obj.canceled) {\n      if (doc.cm) { doc.cm.curOp.updateInput = 2; }\n      return null\n    }\n    return {from: obj.from, to: obj.to, text: obj.text, origin: obj.origin}\n  }\n\n  // Apply a change to a document, and add it to the document's\n  // history, and propagating it to all linked documents.\n  function makeChange(doc, change, ignoreReadOnly) {\n    if (doc.cm) {\n      if (!doc.cm.curOp) { return operation(doc.cm, makeChange)(doc, change, ignoreReadOnly) }\n      if (doc.cm.state.suppressEdits) { return }\n    }\n\n    if (hasHandler(doc, \"beforeChange\") || doc.cm && hasHandler(doc.cm, \"beforeChange\")) {\n      change = filterChange(doc, change, true);\n      if (!change) { return }\n    }\n\n    // Possibly split or suppress the update based on the presence\n    // of read-only spans in its range.\n    var split = sawReadOnlySpans && !ignoreReadOnly && removeReadOnlyRanges(doc, change.from, change.to);\n    if (split) {\n      for (var i = split.length - 1; i >= 0; --i)\n        { makeChangeInner(doc, {from: split[i].from, to: split[i].to, text: i ? [\"\"] : change.text, origin: change.origin}); }\n    } else {\n      makeChangeInner(doc, change);\n    }\n  }\n\n  function makeChangeInner(doc, change) {\n    if (change.text.length == 1 && change.text[0] == \"\" && cmp(change.from, change.to) == 0) { return }\n    var selAfter = computeSelAfterChange(doc, change);\n    addChangeToHistory(doc, change, selAfter, doc.cm ? doc.cm.curOp.id : NaN);\n\n    makeChangeSingleDoc(doc, change, selAfter, stretchSpansOverChange(doc, change));\n    var rebased = [];\n\n    linkedDocs(doc, function (doc, sharedHist) {\n      if (!sharedHist && indexOf(rebased, doc.history) == -1) {\n        rebaseHist(doc.history, change);\n        rebased.push(doc.history);\n      }\n      makeChangeSingleDoc(doc, change, null, stretchSpansOverChange(doc, change));\n    });\n  }\n\n  // Revert a change stored in a document's history.\n  function makeChangeFromHistory(doc, type, allowSelectionOnly) {\n    var suppress = doc.cm && doc.cm.state.suppressEdits;\n    if (suppress && !allowSelectionOnly) { return }\n\n    var hist = doc.history, event, selAfter = doc.sel;\n    var source = type == \"undo\" ? hist.done : hist.undone, dest = type == \"undo\" ? hist.undone : hist.done;\n\n    // Verify that there is a useable event (so that ctrl-z won't\n    // needlessly clear selection events)\n    var i = 0;\n    for (; i < source.length; i++) {\n      event = source[i];\n      if (allowSelectionOnly ? event.ranges && !event.equals(doc.sel) : !event.ranges)\n        { break }\n    }\n    if (i == source.length) { return }\n    hist.lastOrigin = hist.lastSelOrigin = null;\n\n    for (;;) {\n      event = source.pop();\n      if (event.ranges) {\n        pushSelectionToHistory(event, dest);\n        if (allowSelectionOnly && !event.equals(doc.sel)) {\n          setSelection(doc, event, {clearRedo: false});\n          return\n        }\n        selAfter = event;\n      } else if (suppress) {\n        source.push(event);\n        return\n      } else { break }\n    }\n\n    // Build up a reverse change object to add to the opposite history\n    // stack (redo when undoing, and vice versa).\n    var antiChanges = [];\n    pushSelectionToHistory(selAfter, dest);\n    dest.push({changes: antiChanges, generation: hist.generation});\n    hist.generation = event.generation || ++hist.maxGeneration;\n\n    var filter = hasHandler(doc, \"beforeChange\") || doc.cm && hasHandler(doc.cm, \"beforeChange\");\n\n    var loop = function ( i ) {\n      var change = event.changes[i];\n      change.origin = type;\n      if (filter && !filterChange(doc, change, false)) {\n        source.length = 0;\n        return {}\n      }\n\n      antiChanges.push(historyChangeFromChange(doc, change));\n\n      var after = i ? computeSelAfterChange(doc, change) : lst(source);\n      makeChangeSingleDoc(doc, change, after, mergeOldSpans(doc, change));\n      if (!i && doc.cm) { doc.cm.scrollIntoView({from: change.from, to: changeEnd(change)}); }\n      var rebased = [];\n\n      // Propagate to the linked documents\n      linkedDocs(doc, function (doc, sharedHist) {\n        if (!sharedHist && indexOf(rebased, doc.history) == -1) {\n          rebaseHist(doc.history, change);\n          rebased.push(doc.history);\n        }\n        makeChangeSingleDoc(doc, change, null, mergeOldSpans(doc, change));\n      });\n    };\n\n    for (var i$1 = event.changes.length - 1; i$1 >= 0; --i$1) {\n      var returned = loop( i$1 );\n\n      if ( returned ) return returned.v;\n    }\n  }\n\n  // Sub-views need their line numbers shifted when text is added\n  // above or below them in the parent document.\n  function shiftDoc(doc, distance) {\n    if (distance == 0) { return }\n    doc.first += distance;\n    doc.sel = new Selection(map(doc.sel.ranges, function (range) { return new Range(\n      Pos(range.anchor.line + distance, range.anchor.ch),\n      Pos(range.head.line + distance, range.head.ch)\n    ); }), doc.sel.primIndex);\n    if (doc.cm) {\n      regChange(doc.cm, doc.first, doc.first - distance, distance);\n      for (var d = doc.cm.display, l = d.viewFrom; l < d.viewTo; l++)\n        { regLineChange(doc.cm, l, \"gutter\"); }\n    }\n  }\n\n  // More lower-level change function, handling only a single document\n  // (not linked ones).\n  function makeChangeSingleDoc(doc, change, selAfter, spans) {\n    if (doc.cm && !doc.cm.curOp)\n      { return operation(doc.cm, makeChangeSingleDoc)(doc, change, selAfter, spans) }\n\n    if (change.to.line < doc.first) {\n      shiftDoc(doc, change.text.length - 1 - (change.to.line - change.from.line));\n      return\n    }\n    if (change.from.line > doc.lastLine()) { return }\n\n    // Clip the change to the size of this doc\n    if (change.from.line < doc.first) {\n      var shift = change.text.length - 1 - (doc.first - change.from.line);\n      shiftDoc(doc, shift);\n      change = {from: Pos(doc.first, 0), to: Pos(change.to.line + shift, change.to.ch),\n                text: [lst(change.text)], origin: change.origin};\n    }\n    var last = doc.lastLine();\n    if (change.to.line > last) {\n      change = {from: change.from, to: Pos(last, getLine(doc, last).text.length),\n                text: [change.text[0]], origin: change.origin};\n    }\n\n    change.removed = getBetween(doc, change.from, change.to);\n\n    if (!selAfter) { selAfter = computeSelAfterChange(doc, change); }\n    if (doc.cm) { makeChangeSingleDocInEditor(doc.cm, change, spans); }\n    else { updateDoc(doc, change, spans); }\n    setSelectionNoUndo(doc, selAfter, sel_dontScroll);\n\n    if (doc.cantEdit && skipAtomic(doc, Pos(doc.firstLine(), 0)))\n      { doc.cantEdit = false; }\n  }\n\n  // Handle the interaction of a change to a document with the editor\n  // that this document is part of.\n  function makeChangeSingleDocInEditor(cm, change, spans) {\n    var doc = cm.doc, display = cm.display, from = change.from, to = change.to;\n\n    var recomputeMaxLength = false, checkWidthStart = from.line;\n    if (!cm.options.lineWrapping) {\n      checkWidthStart = lineNo(visualLine(getLine(doc, from.line)));\n      doc.iter(checkWidthStart, to.line + 1, function (line) {\n        if (line == display.maxLine) {\n          recomputeMaxLength = true;\n          return true\n        }\n      });\n    }\n\n    if (doc.sel.contains(change.from, change.to) > -1)\n      { signalCursorActivity(cm); }\n\n    updateDoc(doc, change, spans, estimateHeight(cm));\n\n    if (!cm.options.lineWrapping) {\n      doc.iter(checkWidthStart, from.line + change.text.length, function (line) {\n        var len = lineLength(line);\n        if (len > display.maxLineLength) {\n          display.maxLine = line;\n          display.maxLineLength = len;\n          display.maxLineChanged = true;\n          recomputeMaxLength = false;\n        }\n      });\n      if (recomputeMaxLength) { cm.curOp.updateMaxLine = true; }\n    }\n\n    retreatFrontier(doc, from.line);\n    startWorker(cm, 400);\n\n    var lendiff = change.text.length - (to.line - from.line) - 1;\n    // Remember that these lines changed, for updating the display\n    if (change.full)\n      { regChange(cm); }\n    else if (from.line == to.line && change.text.length == 1 && !isWholeLineUpdate(cm.doc, change))\n      { regLineChange(cm, from.line, \"text\"); }\n    else\n      { regChange(cm, from.line, to.line + 1, lendiff); }\n\n    var changesHandler = hasHandler(cm, \"changes\"), changeHandler = hasHandler(cm, \"change\");\n    if (changeHandler || changesHandler) {\n      var obj = {\n        from: from, to: to,\n        text: change.text,\n        removed: change.removed,\n        origin: change.origin\n      };\n      if (changeHandler) { signalLater(cm, \"change\", cm, obj); }\n      if (changesHandler) { (cm.curOp.changeObjs || (cm.curOp.changeObjs = [])).push(obj); }\n    }\n    cm.display.selForContextMenu = null;\n  }\n\n  function replaceRange(doc, code, from, to, origin) {\n    var assign;\n\n    if (!to) { to = from; }\n    if (cmp(to, from) < 0) { (assign = [to, from], from = assign[0], to = assign[1]); }\n    if (typeof code == \"string\") { code = doc.splitLines(code); }\n    makeChange(doc, {from: from, to: to, text: code, origin: origin});\n  }\n\n  // Rebasing/resetting history to deal with externally-sourced changes\n\n  function rebaseHistSelSingle(pos, from, to, diff) {\n    if (to < pos.line) {\n      pos.line += diff;\n    } else if (from < pos.line) {\n      pos.line = from;\n      pos.ch = 0;\n    }\n  }\n\n  // Tries to rebase an array of history events given a change in the\n  // document. If the change touches the same lines as the event, the\n  // event, and everything 'behind' it, is discarded. If the change is\n  // before the event, the event's positions are updated. Uses a\n  // copy-on-write scheme for the positions, to avoid having to\n  // reallocate them all on every rebase, but also avoid problems with\n  // shared position objects being unsafely updated.\n  function rebaseHistArray(array, from, to, diff) {\n    for (var i = 0; i < array.length; ++i) {\n      var sub = array[i], ok = true;\n      if (sub.ranges) {\n        if (!sub.copied) { sub = array[i] = sub.deepCopy(); sub.copied = true; }\n        for (var j = 0; j < sub.ranges.length; j++) {\n          rebaseHistSelSingle(sub.ranges[j].anchor, from, to, diff);\n          rebaseHistSelSingle(sub.ranges[j].head, from, to, diff);\n        }\n        continue\n      }\n      for (var j$1 = 0; j$1 < sub.changes.length; ++j$1) {\n        var cur = sub.changes[j$1];\n        if (to < cur.from.line) {\n          cur.from = Pos(cur.from.line + diff, cur.from.ch);\n          cur.to = Pos(cur.to.line + diff, cur.to.ch);\n        } else if (from <= cur.to.line) {\n          ok = false;\n          break\n        }\n      }\n      if (!ok) {\n        array.splice(0, i + 1);\n        i = 0;\n      }\n    }\n  }\n\n  function rebaseHist(hist, change) {\n    var from = change.from.line, to = change.to.line, diff = change.text.length - (to - from) - 1;\n    rebaseHistArray(hist.done, from, to, diff);\n    rebaseHistArray(hist.undone, from, to, diff);\n  }\n\n  // Utility for applying a change to a line by handle or number,\n  // returning the number and optionally registering the line as\n  // changed.\n  function changeLine(doc, handle, changeType, op) {\n    var no = handle, line = handle;\n    if (typeof handle == \"number\") { line = getLine(doc, clipLine(doc, handle)); }\n    else { no = lineNo(handle); }\n    if (no == null) { return null }\n    if (op(line, no) && doc.cm) { regLineChange(doc.cm, no, changeType); }\n    return line\n  }\n\n  // The document is represented as a BTree consisting of leaves, with\n  // chunk of lines in them, and branches, with up to ten leaves or\n  // other branch nodes below them. The top node is always a branch\n  // node, and is the document object itself (meaning it has\n  // additional methods and properties).\n  //\n  // All nodes have parent links. The tree is used both to go from\n  // line numbers to line objects, and to go from objects to numbers.\n  // It also indexes by height, and is used to convert between height\n  // and line object, and to find the total height of the document.\n  //\n  // See also http://marijnhaverbeke.nl/blog/codemirror-line-tree.html\n\n  function LeafChunk(lines) {\n    this.lines = lines;\n    this.parent = null;\n    var height = 0;\n    for (var i = 0; i < lines.length; ++i) {\n      lines[i].parent = this;\n      height += lines[i].height;\n    }\n    this.height = height;\n  }\n\n  LeafChunk.prototype = {\n    chunkSize: function() { return this.lines.length },\n\n    // Remove the n lines at offset 'at'.\n    removeInner: function(at, n) {\n      for (var i = at, e = at + n; i < e; ++i) {\n        var line = this.lines[i];\n        this.height -= line.height;\n        cleanUpLine(line);\n        signalLater(line, \"delete\");\n      }\n      this.lines.splice(at, n);\n    },\n\n    // Helper used to collapse a small branch into a single leaf.\n    collapse: function(lines) {\n      lines.push.apply(lines, this.lines);\n    },\n\n    // Insert the given array of lines at offset 'at', count them as\n    // having the given height.\n    insertInner: function(at, lines, height) {\n      this.height += height;\n      this.lines = this.lines.slice(0, at).concat(lines).concat(this.lines.slice(at));\n      for (var i = 0; i < lines.length; ++i) { lines[i].parent = this; }\n    },\n\n    // Used to iterate over a part of the tree.\n    iterN: function(at, n, op) {\n      for (var e = at + n; at < e; ++at)\n        { if (op(this.lines[at])) { return true } }\n    }\n  };\n\n  function BranchChunk(children) {\n    this.children = children;\n    var size = 0, height = 0;\n    for (var i = 0; i < children.length; ++i) {\n      var ch = children[i];\n      size += ch.chunkSize(); height += ch.height;\n      ch.parent = this;\n    }\n    this.size = size;\n    this.height = height;\n    this.parent = null;\n  }\n\n  BranchChunk.prototype = {\n    chunkSize: function() { return this.size },\n\n    removeInner: function(at, n) {\n      this.size -= n;\n      for (var i = 0; i < this.children.length; ++i) {\n        var child = this.children[i], sz = child.chunkSize();\n        if (at < sz) {\n          var rm = Math.min(n, sz - at), oldHeight = child.height;\n          child.removeInner(at, rm);\n          this.height -= oldHeight - child.height;\n          if (sz == rm) { this.children.splice(i--, 1); child.parent = null; }\n          if ((n -= rm) == 0) { break }\n          at = 0;\n        } else { at -= sz; }\n      }\n      // If the result is smaller than 25 lines, ensure that it is a\n      // single leaf node.\n      if (this.size - n < 25 &&\n          (this.children.length > 1 || !(this.children[0] instanceof LeafChunk))) {\n        var lines = [];\n        this.collapse(lines);\n        this.children = [new LeafChunk(lines)];\n        this.children[0].parent = this;\n      }\n    },\n\n    collapse: function(lines) {\n      for (var i = 0; i < this.children.length; ++i) { this.children[i].collapse(lines); }\n    },\n\n    insertInner: function(at, lines, height) {\n      this.size += lines.length;\n      this.height += height;\n      for (var i = 0; i < this.children.length; ++i) {\n        var child = this.children[i], sz = child.chunkSize();\n        if (at <= sz) {\n          child.insertInner(at, lines, height);\n          if (child.lines && child.lines.length > 50) {\n            // To avoid memory thrashing when child.lines is huge (e.g. first view of a large file), it's never spliced.\n            // Instead, small slices are taken. They're taken in order because sequential memory accesses are fastest.\n            var remaining = child.lines.length % 25 + 25;\n            for (var pos = remaining; pos < child.lines.length;) {\n              var leaf = new LeafChunk(child.lines.slice(pos, pos += 25));\n              child.height -= leaf.height;\n              this.children.splice(++i, 0, leaf);\n              leaf.parent = this;\n            }\n            child.lines = child.lines.slice(0, remaining);\n            this.maybeSpill();\n          }\n          break\n        }\n        at -= sz;\n      }\n    },\n\n    // When a node has grown, check whether it should be split.\n    maybeSpill: function() {\n      if (this.children.length <= 10) { return }\n      var me = this;\n      do {\n        var spilled = me.children.splice(me.children.length - 5, 5);\n        var sibling = new BranchChunk(spilled);\n        if (!me.parent) { // Become the parent node\n          var copy = new BranchChunk(me.children);\n          copy.parent = me;\n          me.children = [copy, sibling];\n          me = copy;\n       } else {\n          me.size -= sibling.size;\n          me.height -= sibling.height;\n          var myIndex = indexOf(me.parent.children, me);\n          me.parent.children.splice(myIndex + 1, 0, sibling);\n        }\n        sibling.parent = me.parent;\n      } while (me.children.length > 10)\n      me.parent.maybeSpill();\n    },\n\n    iterN: function(at, n, op) {\n      for (var i = 0; i < this.children.length; ++i) {\n        var child = this.children[i], sz = child.chunkSize();\n        if (at < sz) {\n          var used = Math.min(n, sz - at);\n          if (child.iterN(at, used, op)) { return true }\n          if ((n -= used) == 0) { break }\n          at = 0;\n        } else { at -= sz; }\n      }\n    }\n  };\n\n  // Line widgets are block elements displayed above or below a line.\n\n  var LineWidget = function(doc, node, options) {\n    if (options) { for (var opt in options) { if (options.hasOwnProperty(opt))\n      { this[opt] = options[opt]; } } }\n    this.doc = doc;\n    this.node = node;\n  };\n\n  LineWidget.prototype.clear = function () {\n    var cm = this.doc.cm, ws = this.line.widgets, line = this.line, no = lineNo(line);\n    if (no == null || !ws) { return }\n    for (var i = 0; i < ws.length; ++i) { if (ws[i] == this) { ws.splice(i--, 1); } }\n    if (!ws.length) { line.widgets = null; }\n    var height = widgetHeight(this);\n    updateLineHeight(line, Math.max(0, line.height - height));\n    if (cm) {\n      runInOp(cm, function () {\n        adjustScrollWhenAboveVisible(cm, line, -height);\n        regLineChange(cm, no, \"widget\");\n      });\n      signalLater(cm, \"lineWidgetCleared\", cm, this, no);\n    }\n  };\n\n  LineWidget.prototype.changed = function () {\n      var this$1 = this;\n\n    var oldH = this.height, cm = this.doc.cm, line = this.line;\n    this.height = null;\n    var diff = widgetHeight(this) - oldH;\n    if (!diff) { return }\n    if (!lineIsHidden(this.doc, line)) { updateLineHeight(line, line.height + diff); }\n    if (cm) {\n      runInOp(cm, function () {\n        cm.curOp.forceUpdate = true;\n        adjustScrollWhenAboveVisible(cm, line, diff);\n        signalLater(cm, \"lineWidgetChanged\", cm, this$1, lineNo(line));\n      });\n    }\n  };\n  eventMixin(LineWidget);\n\n  function adjustScrollWhenAboveVisible(cm, line, diff) {\n    if (heightAtLine(line) < ((cm.curOp && cm.curOp.scrollTop) || cm.doc.scrollTop))\n      { addToScrollTop(cm, diff); }\n  }\n\n  function addLineWidget(doc, handle, node, options) {\n    var widget = new LineWidget(doc, node, options);\n    var cm = doc.cm;\n    if (cm && widget.noHScroll) { cm.display.alignWidgets = true; }\n    changeLine(doc, handle, \"widget\", function (line) {\n      var widgets = line.widgets || (line.widgets = []);\n      if (widget.insertAt == null) { widgets.push(widget); }\n      else { widgets.splice(Math.min(widgets.length, Math.max(0, widget.insertAt)), 0, widget); }\n      widget.line = line;\n      if (cm && !lineIsHidden(doc, line)) {\n        var aboveVisible = heightAtLine(line) < doc.scrollTop;\n        updateLineHeight(line, line.height + widgetHeight(widget));\n        if (aboveVisible) { addToScrollTop(cm, widget.height); }\n        cm.curOp.forceUpdate = true;\n      }\n      return true\n    });\n    if (cm) { signalLater(cm, \"lineWidgetAdded\", cm, widget, typeof handle == \"number\" ? handle : lineNo(handle)); }\n    return widget\n  }\n\n  // TEXTMARKERS\n\n  // Created with markText and setBookmark methods. A TextMarker is a\n  // handle that can be used to clear or find a marked position in the\n  // document. Line objects hold arrays (markedSpans) containing\n  // {from, to, marker} object pointing to such marker objects, and\n  // indicating that such a marker is present on that line. Multiple\n  // lines may point to the same marker when it spans across lines.\n  // The spans will have null for their from/to properties when the\n  // marker continues beyond the start/end of the line. Markers have\n  // links back to the lines they currently touch.\n\n  // Collapsed markers have unique ids, in order to be able to order\n  // them, which is needed for uniquely determining an outer marker\n  // when they overlap (they may nest, but not partially overlap).\n  var nextMarkerId = 0;\n\n  var TextMarker = function(doc, type) {\n    this.lines = [];\n    this.type = type;\n    this.doc = doc;\n    this.id = ++nextMarkerId;\n  };\n\n  // Clear the marker.\n  TextMarker.prototype.clear = function () {\n    if (this.explicitlyCleared) { return }\n    var cm = this.doc.cm, withOp = cm && !cm.curOp;\n    if (withOp) { startOperation(cm); }\n    if (hasHandler(this, \"clear\")) {\n      var found = this.find();\n      if (found) { signalLater(this, \"clear\", found.from, found.to); }\n    }\n    var min = null, max = null;\n    for (var i = 0; i < this.lines.length; ++i) {\n      var line = this.lines[i];\n      var span = getMarkedSpanFor(line.markedSpans, this);\n      if (cm && !this.collapsed) { regLineChange(cm, lineNo(line), \"text\"); }\n      else if (cm) {\n        if (span.to != null) { max = lineNo(line); }\n        if (span.from != null) { min = lineNo(line); }\n      }\n      line.markedSpans = removeMarkedSpan(line.markedSpans, span);\n      if (span.from == null && this.collapsed && !lineIsHidden(this.doc, line) && cm)\n        { updateLineHeight(line, textHeight(cm.display)); }\n    }\n    if (cm && this.collapsed && !cm.options.lineWrapping) { for (var i$1 = 0; i$1 < this.lines.length; ++i$1) {\n      var visual = visualLine(this.lines[i$1]), len = lineLength(visual);\n      if (len > cm.display.maxLineLength) {\n        cm.display.maxLine = visual;\n        cm.display.maxLineLength = len;\n        cm.display.maxLineChanged = true;\n      }\n    } }\n\n    if (min != null && cm && this.collapsed) { regChange(cm, min, max + 1); }\n    this.lines.length = 0;\n    this.explicitlyCleared = true;\n    if (this.atomic && this.doc.cantEdit) {\n      this.doc.cantEdit = false;\n      if (cm) { reCheckSelection(cm.doc); }\n    }\n    if (cm) { signalLater(cm, \"markerCleared\", cm, this, min, max); }\n    if (withOp) { endOperation(cm); }\n    if (this.parent) { this.parent.clear(); }\n  };\n\n  // Find the position of the marker in the document. Returns a {from,\n  // to} object by default. Side can be passed to get a specific side\n  // -- 0 (both), -1 (left), or 1 (right). When lineObj is true, the\n  // Pos objects returned contain a line object, rather than a line\n  // number (used to prevent looking up the same line twice).\n  TextMarker.prototype.find = function (side, lineObj) {\n    if (side == null && this.type == \"bookmark\") { side = 1; }\n    var from, to;\n    for (var i = 0; i < this.lines.length; ++i) {\n      var line = this.lines[i];\n      var span = getMarkedSpanFor(line.markedSpans, this);\n      if (span.from != null) {\n        from = Pos(lineObj ? line : lineNo(line), span.from);\n        if (side == -1) { return from }\n      }\n      if (span.to != null) {\n        to = Pos(lineObj ? line : lineNo(line), span.to);\n        if (side == 1) { return to }\n      }\n    }\n    return from && {from: from, to: to}\n  };\n\n  // Signals that the marker's widget changed, and surrounding layout\n  // should be recomputed.\n  TextMarker.prototype.changed = function () {\n      var this$1 = this;\n\n    var pos = this.find(-1, true), widget = this, cm = this.doc.cm;\n    if (!pos || !cm) { return }\n    runInOp(cm, function () {\n      var line = pos.line, lineN = lineNo(pos.line);\n      var view = findViewForLine(cm, lineN);\n      if (view) {\n        clearLineMeasurementCacheFor(view);\n        cm.curOp.selectionChanged = cm.curOp.forceUpdate = true;\n      }\n      cm.curOp.updateMaxLine = true;\n      if (!lineIsHidden(widget.doc, line) && widget.height != null) {\n        var oldHeight = widget.height;\n        widget.height = null;\n        var dHeight = widgetHeight(widget) - oldHeight;\n        if (dHeight)\n          { updateLineHeight(line, line.height + dHeight); }\n      }\n      signalLater(cm, \"markerChanged\", cm, this$1);\n    });\n  };\n\n  TextMarker.prototype.attachLine = function (line) {\n    if (!this.lines.length && this.doc.cm) {\n      var op = this.doc.cm.curOp;\n      if (!op.maybeHiddenMarkers || indexOf(op.maybeHiddenMarkers, this) == -1)\n        { (op.maybeUnhiddenMarkers || (op.maybeUnhiddenMarkers = [])).push(this); }\n    }\n    this.lines.push(line);\n  };\n\n  TextMarker.prototype.detachLine = function (line) {\n    this.lines.splice(indexOf(this.lines, line), 1);\n    if (!this.lines.length && this.doc.cm) {\n      var op = this.doc.cm.curOp\n      ;(op.maybeHiddenMarkers || (op.maybeHiddenMarkers = [])).push(this);\n    }\n  };\n  eventMixin(TextMarker);\n\n  // Create a marker, wire it up to the right lines, and\n  function markText(doc, from, to, options, type) {\n    // Shared markers (across linked documents) are handled separately\n    // (markTextShared will call out to this again, once per\n    // document).\n    if (options && options.shared) { return markTextShared(doc, from, to, options, type) }\n    // Ensure we are in an operation.\n    if (doc.cm && !doc.cm.curOp) { return operation(doc.cm, markText)(doc, from, to, options, type) }\n\n    var marker = new TextMarker(doc, type), diff = cmp(from, to);\n    if (options) { copyObj(options, marker, false); }\n    // Don't connect empty markers unless clearWhenEmpty is false\n    if (diff > 0 || diff == 0 && marker.clearWhenEmpty !== false)\n      { return marker }\n    if (marker.replacedWith) {\n      // Showing up as a widget implies collapsed (widget replaces text)\n      marker.collapsed = true;\n      marker.widgetNode = eltP(\"span\", [marker.replacedWith], \"CodeMirror-widget\");\n      if (!options.handleMouseEvents) { marker.widgetNode.setAttribute(\"cm-ignore-events\", \"true\"); }\n      if (options.insertLeft) { marker.widgetNode.insertLeft = true; }\n    }\n    if (marker.collapsed) {\n      if (conflictingCollapsedRange(doc, from.line, from, to, marker) ||\n          from.line != to.line && conflictingCollapsedRange(doc, to.line, from, to, marker))\n        { throw new Error(\"Inserting collapsed marker partially overlapping an existing one\") }\n      seeCollapsedSpans();\n    }\n\n    if (marker.addToHistory)\n      { addChangeToHistory(doc, {from: from, to: to, origin: \"markText\"}, doc.sel, NaN); }\n\n    var curLine = from.line, cm = doc.cm, updateMaxLine;\n    doc.iter(curLine, to.line + 1, function (line) {\n      if (cm && marker.collapsed && !cm.options.lineWrapping && visualLine(line) == cm.display.maxLine)\n        { updateMaxLine = true; }\n      if (marker.collapsed && curLine != from.line) { updateLineHeight(line, 0); }\n      addMarkedSpan(line, new MarkedSpan(marker,\n                                         curLine == from.line ? from.ch : null,\n                                         curLine == to.line ? to.ch : null), doc.cm && doc.cm.curOp);\n      ++curLine;\n    });\n    // lineIsHidden depends on the presence of the spans, so needs a second pass\n    if (marker.collapsed) { doc.iter(from.line, to.line + 1, function (line) {\n      if (lineIsHidden(doc, line)) { updateLineHeight(line, 0); }\n    }); }\n\n    if (marker.clearOnEnter) { on(marker, \"beforeCursorEnter\", function () { return marker.clear(); }); }\n\n    if (marker.readOnly) {\n      seeReadOnlySpans();\n      if (doc.history.done.length || doc.history.undone.length)\n        { doc.clearHistory(); }\n    }\n    if (marker.collapsed) {\n      marker.id = ++nextMarkerId;\n      marker.atomic = true;\n    }\n    if (cm) {\n      // Sync editor state\n      if (updateMaxLine) { cm.curOp.updateMaxLine = true; }\n      if (marker.collapsed)\n        { regChange(cm, from.line, to.line + 1); }\n      else if (marker.className || marker.startStyle || marker.endStyle || marker.css ||\n               marker.attributes || marker.title)\n        { for (var i = from.line; i <= to.line; i++) { regLineChange(cm, i, \"text\"); } }\n      if (marker.atomic) { reCheckSelection(cm.doc); }\n      signalLater(cm, \"markerAdded\", cm, marker);\n    }\n    return marker\n  }\n\n  // SHARED TEXTMARKERS\n\n  // A shared marker spans multiple linked documents. It is\n  // implemented as a meta-marker-object controlling multiple normal\n  // markers.\n  var SharedTextMarker = function(markers, primary) {\n    this.markers = markers;\n    this.primary = primary;\n    for (var i = 0; i < markers.length; ++i)\n      { markers[i].parent = this; }\n  };\n\n  SharedTextMarker.prototype.clear = function () {\n    if (this.explicitlyCleared) { return }\n    this.explicitlyCleared = true;\n    for (var i = 0; i < this.markers.length; ++i)\n      { this.markers[i].clear(); }\n    signalLater(this, \"clear\");\n  };\n\n  SharedTextMarker.prototype.find = function (side, lineObj) {\n    return this.primary.find(side, lineObj)\n  };\n  eventMixin(SharedTextMarker);\n\n  function markTextShared(doc, from, to, options, type) {\n    options = copyObj(options);\n    options.shared = false;\n    var markers = [markText(doc, from, to, options, type)], primary = markers[0];\n    var widget = options.widgetNode;\n    linkedDocs(doc, function (doc) {\n      if (widget) { options.widgetNode = widget.cloneNode(true); }\n      markers.push(markText(doc, clipPos(doc, from), clipPos(doc, to), options, type));\n      for (var i = 0; i < doc.linked.length; ++i)\n        { if (doc.linked[i].isParent) { return } }\n      primary = lst(markers);\n    });\n    return new SharedTextMarker(markers, primary)\n  }\n\n  function findSharedMarkers(doc) {\n    return doc.findMarks(Pos(doc.first, 0), doc.clipPos(Pos(doc.lastLine())), function (m) { return m.parent; })\n  }\n\n  function copySharedMarkers(doc, markers) {\n    for (var i = 0; i < markers.length; i++) {\n      var marker = markers[i], pos = marker.find();\n      var mFrom = doc.clipPos(pos.from), mTo = doc.clipPos(pos.to);\n      if (cmp(mFrom, mTo)) {\n        var subMark = markText(doc, mFrom, mTo, marker.primary, marker.primary.type);\n        marker.markers.push(subMark);\n        subMark.parent = marker;\n      }\n    }\n  }\n\n  function detachSharedMarkers(markers) {\n    var loop = function ( i ) {\n      var marker = markers[i], linked = [marker.primary.doc];\n      linkedDocs(marker.primary.doc, function (d) { return linked.push(d); });\n      for (var j = 0; j < marker.markers.length; j++) {\n        var subMarker = marker.markers[j];\n        if (indexOf(linked, subMarker.doc) == -1) {\n          subMarker.parent = null;\n          marker.markers.splice(j--, 1);\n        }\n      }\n    };\n\n    for (var i = 0; i < markers.length; i++) loop( i );\n  }\n\n  var nextDocId = 0;\n  var Doc = function(text, mode, firstLine, lineSep, direction) {\n    if (!(this instanceof Doc)) { return new Doc(text, mode, firstLine, lineSep, direction) }\n    if (firstLine == null) { firstLine = 0; }\n\n    BranchChunk.call(this, [new LeafChunk([new Line(\"\", null)])]);\n    this.first = firstLine;\n    this.scrollTop = this.scrollLeft = 0;\n    this.cantEdit = false;\n    this.cleanGeneration = 1;\n    this.modeFrontier = this.highlightFrontier = firstLine;\n    var start = Pos(firstLine, 0);\n    this.sel = simpleSelection(start);\n    this.history = new History(null);\n    this.id = ++nextDocId;\n    this.modeOption = mode;\n    this.lineSep = lineSep;\n    this.direction = (direction == \"rtl\") ? \"rtl\" : \"ltr\";\n    this.extend = false;\n\n    if (typeof text == \"string\") { text = this.splitLines(text); }\n    updateDoc(this, {from: start, to: start, text: text});\n    setSelection(this, simpleSelection(start), sel_dontScroll);\n  };\n\n  Doc.prototype = createObj(BranchChunk.prototype, {\n    constructor: Doc,\n    // Iterate over the document. Supports two forms -- with only one\n    // argument, it calls that for each line in the document. With\n    // three, it iterates over the range given by the first two (with\n    // the second being non-inclusive).\n    iter: function(from, to, op) {\n      if (op) { this.iterN(from - this.first, to - from, op); }\n      else { this.iterN(this.first, this.first + this.size, from); }\n    },\n\n    // Non-public interface for adding and removing lines.\n    insert: function(at, lines) {\n      var height = 0;\n      for (var i = 0; i < lines.length; ++i) { height += lines[i].height; }\n      this.insertInner(at - this.first, lines, height);\n    },\n    remove: function(at, n) { this.removeInner(at - this.first, n); },\n\n    // From here, the methods are part of the public interface. Most\n    // are also available from CodeMirror (editor) instances.\n\n    getValue: function(lineSep) {\n      var lines = getLines(this, this.first, this.first + this.size);\n      if (lineSep === false) { return lines }\n      return lines.join(lineSep || this.lineSeparator())\n    },\n    setValue: docMethodOp(function(code) {\n      var top = Pos(this.first, 0), last = this.first + this.size - 1;\n      makeChange(this, {from: top, to: Pos(last, getLine(this, last).text.length),\n                        text: this.splitLines(code), origin: \"setValue\", full: true}, true);\n      if (this.cm) { scrollToCoords(this.cm, 0, 0); }\n      setSelection(this, simpleSelection(top), sel_dontScroll);\n    }),\n    replaceRange: function(code, from, to, origin) {\n      from = clipPos(this, from);\n      to = to ? clipPos(this, to) : from;\n      replaceRange(this, code, from, to, origin);\n    },\n    getRange: function(from, to, lineSep) {\n      var lines = getBetween(this, clipPos(this, from), clipPos(this, to));\n      if (lineSep === false) { return lines }\n      if (lineSep === '') { return lines.join('') }\n      return lines.join(lineSep || this.lineSeparator())\n    },\n\n    getLine: function(line) {var l = this.getLineHandle(line); return l && l.text},\n\n    getLineHandle: function(line) {if (isLine(this, line)) { return getLine(this, line) }},\n    getLineNumber: function(line) {return lineNo(line)},\n\n    getLineHandleVisualStart: function(line) {\n      if (typeof line == \"number\") { line = getLine(this, line); }\n      return visualLine(line)\n    },\n\n    lineCount: function() {return this.size},\n    firstLine: function() {return this.first},\n    lastLine: function() {return this.first + this.size - 1},\n\n    clipPos: function(pos) {return clipPos(this, pos)},\n\n    getCursor: function(start) {\n      var range = this.sel.primary(), pos;\n      if (start == null || start == \"head\") { pos = range.head; }\n      else if (start == \"anchor\") { pos = range.anchor; }\n      else if (start == \"end\" || start == \"to\" || start === false) { pos = range.to(); }\n      else { pos = range.from(); }\n      return pos\n    },\n    listSelections: function() { return this.sel.ranges },\n    somethingSelected: function() {return this.sel.somethingSelected()},\n\n    setCursor: docMethodOp(function(line, ch, options) {\n      setSimpleSelection(this, clipPos(this, typeof line == \"number\" ? Pos(line, ch || 0) : line), null, options);\n    }),\n    setSelection: docMethodOp(function(anchor, head, options) {\n      setSimpleSelection(this, clipPos(this, anchor), clipPos(this, head || anchor), options);\n    }),\n    extendSelection: docMethodOp(function(head, other, options) {\n      extendSelection(this, clipPos(this, head), other && clipPos(this, other), options);\n    }),\n    extendSelections: docMethodOp(function(heads, options) {\n      extendSelections(this, clipPosArray(this, heads), options);\n    }),\n    extendSelectionsBy: docMethodOp(function(f, options) {\n      var heads = map(this.sel.ranges, f);\n      extendSelections(this, clipPosArray(this, heads), options);\n    }),\n    setSelections: docMethodOp(function(ranges, primary, options) {\n      if (!ranges.length) { return }\n      var out = [];\n      for (var i = 0; i < ranges.length; i++)\n        { out[i] = new Range(clipPos(this, ranges[i].anchor),\n                           clipPos(this, ranges[i].head || ranges[i].anchor)); }\n      if (primary == null) { primary = Math.min(ranges.length - 1, this.sel.primIndex); }\n      setSelection(this, normalizeSelection(this.cm, out, primary), options);\n    }),\n    addSelection: docMethodOp(function(anchor, head, options) {\n      var ranges = this.sel.ranges.slice(0);\n      ranges.push(new Range(clipPos(this, anchor), clipPos(this, head || anchor)));\n      setSelection(this, normalizeSelection(this.cm, ranges, ranges.length - 1), options);\n    }),\n\n    getSelection: function(lineSep) {\n      var ranges = this.sel.ranges, lines;\n      for (var i = 0; i < ranges.length; i++) {\n        var sel = getBetween(this, ranges[i].from(), ranges[i].to());\n        lines = lines ? lines.concat(sel) : sel;\n      }\n      if (lineSep === false) { return lines }\n      else { return lines.join(lineSep || this.lineSeparator()) }\n    },\n    getSelections: function(lineSep) {\n      var parts = [], ranges = this.sel.ranges;\n      for (var i = 0; i < ranges.length; i++) {\n        var sel = getBetween(this, ranges[i].from(), ranges[i].to());\n        if (lineSep !== false) { sel = sel.join(lineSep || this.lineSeparator()); }\n        parts[i] = sel;\n      }\n      return parts\n    },\n    replaceSelection: function(code, collapse, origin) {\n      var dup = [];\n      for (var i = 0; i < this.sel.ranges.length; i++)\n        { dup[i] = code; }\n      this.replaceSelections(dup, collapse, origin || \"+input\");\n    },\n    replaceSelections: docMethodOp(function(code, collapse, origin) {\n      var changes = [], sel = this.sel;\n      for (var i = 0; i < sel.ranges.length; i++) {\n        var range = sel.ranges[i];\n        changes[i] = {from: range.from(), to: range.to(), text: this.splitLines(code[i]), origin: origin};\n      }\n      var newSel = collapse && collapse != \"end\" && computeReplacedSel(this, changes, collapse);\n      for (var i$1 = changes.length - 1; i$1 >= 0; i$1--)\n        { makeChange(this, changes[i$1]); }\n      if (newSel) { setSelectionReplaceHistory(this, newSel); }\n      else if (this.cm) { ensureCursorVisible(this.cm); }\n    }),\n    undo: docMethodOp(function() {makeChangeFromHistory(this, \"undo\");}),\n    redo: docMethodOp(function() {makeChangeFromHistory(this, \"redo\");}),\n    undoSelection: docMethodOp(function() {makeChangeFromHistory(this, \"undo\", true);}),\n    redoSelection: docMethodOp(function() {makeChangeFromHistory(this, \"redo\", true);}),\n\n    setExtending: function(val) {this.extend = val;},\n    getExtending: function() {return this.extend},\n\n    historySize: function() {\n      var hist = this.history, done = 0, undone = 0;\n      for (var i = 0; i < hist.done.length; i++) { if (!hist.done[i].ranges) { ++done; } }\n      for (var i$1 = 0; i$1 < hist.undone.length; i$1++) { if (!hist.undone[i$1].ranges) { ++undone; } }\n      return {undo: done, redo: undone}\n    },\n    clearHistory: function() {\n      var this$1 = this;\n\n      this.history = new History(this.history);\n      linkedDocs(this, function (doc) { return doc.history = this$1.history; }, true);\n    },\n\n    markClean: function() {\n      this.cleanGeneration = this.changeGeneration(true);\n    },\n    changeGeneration: function(forceSplit) {\n      if (forceSplit)\n        { this.history.lastOp = this.history.lastSelOp = this.history.lastOrigin = null; }\n      return this.history.generation\n    },\n    isClean: function (gen) {\n      return this.history.generation == (gen || this.cleanGeneration)\n    },\n\n    getHistory: function() {\n      return {done: copyHistoryArray(this.history.done),\n              undone: copyHistoryArray(this.history.undone)}\n    },\n    setHistory: function(histData) {\n      var hist = this.history = new History(this.history);\n      hist.done = copyHistoryArray(histData.done.slice(0), null, true);\n      hist.undone = copyHistoryArray(histData.undone.slice(0), null, true);\n    },\n\n    setGutterMarker: docMethodOp(function(line, gutterID, value) {\n      return changeLine(this, line, \"gutter\", function (line) {\n        var markers = line.gutterMarkers || (line.gutterMarkers = {});\n        markers[gutterID] = value;\n        if (!value && isEmpty(markers)) { line.gutterMarkers = null; }\n        return true\n      })\n    }),\n\n    clearGutter: docMethodOp(function(gutterID) {\n      var this$1 = this;\n\n      this.iter(function (line) {\n        if (line.gutterMarkers && line.gutterMarkers[gutterID]) {\n          changeLine(this$1, line, \"gutter\", function () {\n            line.gutterMarkers[gutterID] = null;\n            if (isEmpty(line.gutterMarkers)) { line.gutterMarkers = null; }\n            return true\n          });\n        }\n      });\n    }),\n\n    lineInfo: function(line) {\n      var n;\n      if (typeof line == \"number\") {\n        if (!isLine(this, line)) { return null }\n        n = line;\n        line = getLine(this, line);\n        if (!line) { return null }\n      } else {\n        n = lineNo(line);\n        if (n == null) { return null }\n      }\n      return {line: n, handle: line, text: line.text, gutterMarkers: line.gutterMarkers,\n              textClass: line.textClass, bgClass: line.bgClass, wrapClass: line.wrapClass,\n              widgets: line.widgets}\n    },\n\n    addLineClass: docMethodOp(function(handle, where, cls) {\n      return changeLine(this, handle, where == \"gutter\" ? \"gutter\" : \"class\", function (line) {\n        var prop = where == \"text\" ? \"textClass\"\n                 : where == \"background\" ? \"bgClass\"\n                 : where == \"gutter\" ? \"gutterClass\" : \"wrapClass\";\n        if (!line[prop]) { line[prop] = cls; }\n        else if (classTest(cls).test(line[prop])) { return false }\n        else { line[prop] += \" \" + cls; }\n        return true\n      })\n    }),\n    removeLineClass: docMethodOp(function(handle, where, cls) {\n      return changeLine(this, handle, where == \"gutter\" ? \"gutter\" : \"class\", function (line) {\n        var prop = where == \"text\" ? \"textClass\"\n                 : where == \"background\" ? \"bgClass\"\n                 : where == \"gutter\" ? \"gutterClass\" : \"wrapClass\";\n        var cur = line[prop];\n        if (!cur) { return false }\n        else if (cls == null) { line[prop] = null; }\n        else {\n          var found = cur.match(classTest(cls));\n          if (!found) { return false }\n          var end = found.index + found[0].length;\n          line[prop] = cur.slice(0, found.index) + (!found.index || end == cur.length ? \"\" : \" \") + cur.slice(end) || null;\n        }\n        return true\n      })\n    }),\n\n    addLineWidget: docMethodOp(function(handle, node, options) {\n      return addLineWidget(this, handle, node, options)\n    }),\n    removeLineWidget: function(widget) { widget.clear(); },\n\n    markText: function(from, to, options) {\n      return markText(this, clipPos(this, from), clipPos(this, to), options, options && options.type || \"range\")\n    },\n    setBookmark: function(pos, options) {\n      var realOpts = {replacedWith: options && (options.nodeType == null ? options.widget : options),\n                      insertLeft: options && options.insertLeft,\n                      clearWhenEmpty: false, shared: options && options.shared,\n                      handleMouseEvents: options && options.handleMouseEvents};\n      pos = clipPos(this, pos);\n      return markText(this, pos, pos, realOpts, \"bookmark\")\n    },\n    findMarksAt: function(pos) {\n      pos = clipPos(this, pos);\n      var markers = [], spans = getLine(this, pos.line).markedSpans;\n      if (spans) { for (var i = 0; i < spans.length; ++i) {\n        var span = spans[i];\n        if ((span.from == null || span.from <= pos.ch) &&\n            (span.to == null || span.to >= pos.ch))\n          { markers.push(span.marker.parent || span.marker); }\n      } }\n      return markers\n    },\n    findMarks: function(from, to, filter) {\n      from = clipPos(this, from); to = clipPos(this, to);\n      var found = [], lineNo = from.line;\n      this.iter(from.line, to.line + 1, function (line) {\n        var spans = line.markedSpans;\n        if (spans) { for (var i = 0; i < spans.length; i++) {\n          var span = spans[i];\n          if (!(span.to != null && lineNo == from.line && from.ch >= span.to ||\n                span.from == null && lineNo != from.line ||\n                span.from != null && lineNo == to.line && span.from >= to.ch) &&\n              (!filter || filter(span.marker)))\n            { found.push(span.marker.parent || span.marker); }\n        } }\n        ++lineNo;\n      });\n      return found\n    },\n    getAllMarks: function() {\n      var markers = [];\n      this.iter(function (line) {\n        var sps = line.markedSpans;\n        if (sps) { for (var i = 0; i < sps.length; ++i)\n          { if (sps[i].from != null) { markers.push(sps[i].marker); } } }\n      });\n      return markers\n    },\n\n    posFromIndex: function(off) {\n      var ch, lineNo = this.first, sepSize = this.lineSeparator().length;\n      this.iter(function (line) {\n        var sz = line.text.length + sepSize;\n        if (sz > off) { ch = off; return true }\n        off -= sz;\n        ++lineNo;\n      });\n      return clipPos(this, Pos(lineNo, ch))\n    },\n    indexFromPos: function (coords) {\n      coords = clipPos(this, coords);\n      var index = coords.ch;\n      if (coords.line < this.first || coords.ch < 0) { return 0 }\n      var sepSize = this.lineSeparator().length;\n      this.iter(this.first, coords.line, function (line) { // iter aborts when callback returns a truthy value\n        index += line.text.length + sepSize;\n      });\n      return index\n    },\n\n    copy: function(copyHistory) {\n      var doc = new Doc(getLines(this, this.first, this.first + this.size),\n                        this.modeOption, this.first, this.lineSep, this.direction);\n      doc.scrollTop = this.scrollTop; doc.scrollLeft = this.scrollLeft;\n      doc.sel = this.sel;\n      doc.extend = false;\n      if (copyHistory) {\n        doc.history.undoDepth = this.history.undoDepth;\n        doc.setHistory(this.getHistory());\n      }\n      return doc\n    },\n\n    linkedDoc: function(options) {\n      if (!options) { options = {}; }\n      var from = this.first, to = this.first + this.size;\n      if (options.from != null && options.from > from) { from = options.from; }\n      if (options.to != null && options.to < to) { to = options.to; }\n      var copy = new Doc(getLines(this, from, to), options.mode || this.modeOption, from, this.lineSep, this.direction);\n      if (options.sharedHist) { copy.history = this.history\n      ; }(this.linked || (this.linked = [])).push({doc: copy, sharedHist: options.sharedHist});\n      copy.linked = [{doc: this, isParent: true, sharedHist: options.sharedHist}];\n      copySharedMarkers(copy, findSharedMarkers(this));\n      return copy\n    },\n    unlinkDoc: function(other) {\n      if (other instanceof CodeMirror) { other = other.doc; }\n      if (this.linked) { for (var i = 0; i < this.linked.length; ++i) {\n        var link = this.linked[i];\n        if (link.doc != other) { continue }\n        this.linked.splice(i, 1);\n        other.unlinkDoc(this);\n        detachSharedMarkers(findSharedMarkers(this));\n        break\n      } }\n      // If the histories were shared, split them again\n      if (other.history == this.history) {\n        var splitIds = [other.id];\n        linkedDocs(other, function (doc) { return splitIds.push(doc.id); }, true);\n        other.history = new History(null);\n        other.history.done = copyHistoryArray(this.history.done, splitIds);\n        other.history.undone = copyHistoryArray(this.history.undone, splitIds);\n      }\n    },\n    iterLinkedDocs: function(f) {linkedDocs(this, f);},\n\n    getMode: function() {return this.mode},\n    getEditor: function() {return this.cm},\n\n    splitLines: function(str) {\n      if (this.lineSep) { return str.split(this.lineSep) }\n      return splitLinesAuto(str)\n    },\n    lineSeparator: function() { return this.lineSep || \"\\n\" },\n\n    setDirection: docMethodOp(function (dir) {\n      if (dir != \"rtl\") { dir = \"ltr\"; }\n      if (dir == this.direction) { return }\n      this.direction = dir;\n      this.iter(function (line) { return line.order = null; });\n      if (this.cm) { directionChanged(this.cm); }\n    })\n  });\n\n  // Public alias.\n  Doc.prototype.eachLine = Doc.prototype.iter;\n\n  // Kludge to work around strange IE behavior where it'll sometimes\n  // re-fire a series of drag-related events right after the drop (#1551)\n  var lastDrop = 0;\n\n  function onDrop(e) {\n    var cm = this;\n    clearDragCursor(cm);\n    if (signalDOMEvent(cm, e) || eventInWidget(cm.display, e))\n      { return }\n    e_preventDefault(e);\n    if (ie) { lastDrop = +new Date; }\n    var pos = posFromMouse(cm, e, true), files = e.dataTransfer.files;\n    if (!pos || cm.isReadOnly()) { return }\n    // Might be a file drop, in which case we simply extract the text\n    // and insert it.\n    if (files && files.length && window.FileReader && window.File) {\n      var n = files.length, text = Array(n), read = 0;\n      var markAsReadAndPasteIfAllFilesAreRead = function () {\n        if (++read == n) {\n          operation(cm, function () {\n            pos = clipPos(cm.doc, pos);\n            var change = {from: pos, to: pos,\n                          text: cm.doc.splitLines(\n                              text.filter(function (t) { return t != null; }).join(cm.doc.lineSeparator())),\n                          origin: \"paste\"};\n            makeChange(cm.doc, change);\n            setSelectionReplaceHistory(cm.doc, simpleSelection(clipPos(cm.doc, pos), clipPos(cm.doc, changeEnd(change))));\n          })();\n        }\n      };\n      var readTextFromFile = function (file, i) {\n        if (cm.options.allowDropFileTypes &&\n            indexOf(cm.options.allowDropFileTypes, file.type) == -1) {\n          markAsReadAndPasteIfAllFilesAreRead();\n          return\n        }\n        var reader = new FileReader;\n        reader.onerror = function () { return markAsReadAndPasteIfAllFilesAreRead(); };\n        reader.onload = function () {\n          var content = reader.result;\n          if (/[\\x00-\\x08\\x0e-\\x1f]{2}/.test(content)) {\n            markAsReadAndPasteIfAllFilesAreRead();\n            return\n          }\n          text[i] = content;\n          markAsReadAndPasteIfAllFilesAreRead();\n        };\n        reader.readAsText(file);\n      };\n      for (var i = 0; i < files.length; i++) { readTextFromFile(files[i], i); }\n    } else { // Normal drop\n      // Don't do a replace if the drop happened inside of the selected text.\n      if (cm.state.draggingText && cm.doc.sel.contains(pos) > -1) {\n        cm.state.draggingText(e);\n        // Ensure the editor is re-focused\n        setTimeout(function () { return cm.display.input.focus(); }, 20);\n        return\n      }\n      try {\n        var text$1 = e.dataTransfer.getData(\"Text\");\n        if (text$1) {\n          var selected;\n          if (cm.state.draggingText && !cm.state.draggingText.copy)\n            { selected = cm.listSelections(); }\n          setSelectionNoUndo(cm.doc, simpleSelection(pos, pos));\n          if (selected) { for (var i$1 = 0; i$1 < selected.length; ++i$1)\n            { replaceRange(cm.doc, \"\", selected[i$1].anchor, selected[i$1].head, \"drag\"); } }\n          cm.replaceSelection(text$1, \"around\", \"paste\");\n          cm.display.input.focus();\n        }\n      }\n      catch(e$1){}\n    }\n  }\n\n  function onDragStart(cm, e) {\n    if (ie && (!cm.state.draggingText || +new Date - lastDrop < 100)) { e_stop(e); return }\n    if (signalDOMEvent(cm, e) || eventInWidget(cm.display, e)) { return }\n\n    e.dataTransfer.setData(\"Text\", cm.getSelection());\n    e.dataTransfer.effectAllowed = \"copyMove\";\n\n    // Use dummy image instead of default browsers image.\n    // Recent Safari (~6.0.2) have a tendency to segfault when this happens, so we don't do it there.\n    if (e.dataTransfer.setDragImage && !safari) {\n      var img = elt(\"img\", null, null, \"position: fixed; left: 0; top: 0;\");\n      img.src = \"data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\";\n      if (presto) {\n        img.width = img.height = 1;\n        cm.display.wrapper.appendChild(img);\n        // Force a relayout, or Opera won't use our image for some obscure reason\n        img._top = img.offsetTop;\n      }\n      e.dataTransfer.setDragImage(img, 0, 0);\n      if (presto) { img.parentNode.removeChild(img); }\n    }\n  }\n\n  function onDragOver(cm, e) {\n    var pos = posFromMouse(cm, e);\n    if (!pos) { return }\n    var frag = document.createDocumentFragment();\n    drawSelectionCursor(cm, pos, frag);\n    if (!cm.display.dragCursor) {\n      cm.display.dragCursor = elt(\"div\", null, \"CodeMirror-cursors CodeMirror-dragcursors\");\n      cm.display.lineSpace.insertBefore(cm.display.dragCursor, cm.display.cursorDiv);\n    }\n    removeChildrenAndAdd(cm.display.dragCursor, frag);\n  }\n\n  function clearDragCursor(cm) {\n    if (cm.display.dragCursor) {\n      cm.display.lineSpace.removeChild(cm.display.dragCursor);\n      cm.display.dragCursor = null;\n    }\n  }\n\n  // These must be handled carefully, because naively registering a\n  // handler for each editor will cause the editors to never be\n  // garbage collected.\n\n  function forEachCodeMirror(f) {\n    if (!document.getElementsByClassName) { return }\n    var byClass = document.getElementsByClassName(\"CodeMirror\"), editors = [];\n    for (var i = 0; i < byClass.length; i++) {\n      var cm = byClass[i].CodeMirror;\n      if (cm) { editors.push(cm); }\n    }\n    if (editors.length) { editors[0].operation(function () {\n      for (var i = 0; i < editors.length; i++) { f(editors[i]); }\n    }); }\n  }\n\n  var globalsRegistered = false;\n  function ensureGlobalHandlers() {\n    if (globalsRegistered) { return }\n    registerGlobalHandlers();\n    globalsRegistered = true;\n  }\n  function registerGlobalHandlers() {\n    // When the window resizes, we need to refresh active editors.\n    var resizeTimer;\n    on(window, \"resize\", function () {\n      if (resizeTimer == null) { resizeTimer = setTimeout(function () {\n        resizeTimer = null;\n        forEachCodeMirror(onResize);\n      }, 100); }\n    });\n    // When the window loses focus, we want to show the editor as blurred\n    on(window, \"blur\", function () { return forEachCodeMirror(onBlur); });\n  }\n  // Called when the window resizes\n  function onResize(cm) {\n    var d = cm.display;\n    // Might be a text scaling operation, clear size caches.\n    d.cachedCharWidth = d.cachedTextHeight = d.cachedPaddingH = null;\n    d.scrollbarsClipped = false;\n    cm.setSize();\n  }\n\n  var keyNames = {\n    3: \"Pause\", 8: \"Backspace\", 9: \"Tab\", 13: \"Enter\", 16: \"Shift\", 17: \"Ctrl\", 18: \"Alt\",\n    19: \"Pause\", 20: \"CapsLock\", 27: \"Esc\", 32: \"Space\", 33: \"PageUp\", 34: \"PageDown\", 35: \"End\",\n    36: \"Home\", 37: \"Left\", 38: \"Up\", 39: \"Right\", 40: \"Down\", 44: \"PrintScrn\", 45: \"Insert\",\n    46: \"Delete\", 59: \";\", 61: \"=\", 91: \"Mod\", 92: \"Mod\", 93: \"Mod\",\n    106: \"*\", 107: \"=\", 109: \"-\", 110: \".\", 111: \"/\", 145: \"ScrollLock\",\n    173: \"-\", 186: \";\", 187: \"=\", 188: \",\", 189: \"-\", 190: \".\", 191: \"/\", 192: \"`\", 219: \"[\", 220: \"\\\\\",\n    221: \"]\", 222: \"'\", 224: \"Mod\", 63232: \"Up\", 63233: \"Down\", 63234: \"Left\", 63235: \"Right\", 63272: \"Delete\",\n    63273: \"Home\", 63275: \"End\", 63276: \"PageUp\", 63277: \"PageDown\", 63302: \"Insert\"\n  };\n\n  // Number keys\n  for (var i = 0; i < 10; i++) { keyNames[i + 48] = keyNames[i + 96] = String(i); }\n  // Alphabetic keys\n  for (var i$1 = 65; i$1 <= 90; i$1++) { keyNames[i$1] = String.fromCharCode(i$1); }\n  // Function keys\n  for (var i$2 = 1; i$2 <= 12; i$2++) { keyNames[i$2 + 111] = keyNames[i$2 + 63235] = \"F\" + i$2; }\n\n  var keyMap = {};\n\n  keyMap.basic = {\n    \"Left\": \"goCharLeft\", \"Right\": \"goCharRight\", \"Up\": \"goLineUp\", \"Down\": \"goLineDown\",\n    \"End\": \"goLineEnd\", \"Home\": \"goLineStartSmart\", \"PageUp\": \"goPageUp\", \"PageDown\": \"goPageDown\",\n    \"Delete\": \"delCharAfter\", \"Backspace\": \"delCharBefore\", \"Shift-Backspace\": \"delCharBefore\",\n    \"Tab\": \"defaultTab\", \"Shift-Tab\": \"indentAuto\",\n    \"Enter\": \"newlineAndIndent\", \"Insert\": \"toggleOverwrite\",\n    \"Esc\": \"singleSelection\"\n  };\n  // Note that the save and find-related commands aren't defined by\n  // default. User code or addons can define them. Unknown commands\n  // are simply ignored.\n  keyMap.pcDefault = {\n    \"Ctrl-A\": \"selectAll\", \"Ctrl-D\": \"deleteLine\", \"Ctrl-Z\": \"undo\", \"Shift-Ctrl-Z\": \"redo\", \"Ctrl-Y\": \"redo\",\n    \"Ctrl-Home\": \"goDocStart\", \"Ctrl-End\": \"goDocEnd\", \"Ctrl-Up\": \"goLineUp\", \"Ctrl-Down\": \"goLineDown\",\n    \"Ctrl-Left\": \"goGroupLeft\", \"Ctrl-Right\": \"goGroupRight\", \"Alt-Left\": \"goLineStart\", \"Alt-Right\": \"goLineEnd\",\n    \"Ctrl-Backspace\": \"delGroupBefore\", \"Ctrl-Delete\": \"delGroupAfter\", \"Ctrl-S\": \"save\", \"Ctrl-F\": \"find\",\n    \"Ctrl-G\": \"findNext\", \"Shift-Ctrl-G\": \"findPrev\", \"Shift-Ctrl-F\": \"replace\", \"Shift-Ctrl-R\": \"replaceAll\",\n    \"Ctrl-[\": \"indentLess\", \"Ctrl-]\": \"indentMore\",\n    \"Ctrl-U\": \"undoSelection\", \"Shift-Ctrl-U\": \"redoSelection\", \"Alt-U\": \"redoSelection\",\n    \"fallthrough\": \"basic\"\n  };\n  // Very basic readline/emacs-style bindings, which are standard on Mac.\n  keyMap.emacsy = {\n    \"Ctrl-F\": \"goCharRight\", \"Ctrl-B\": \"goCharLeft\", \"Ctrl-P\": \"goLineUp\", \"Ctrl-N\": \"goLineDown\",\n    \"Ctrl-A\": \"goLineStart\", \"Ctrl-E\": \"goLineEnd\", \"Ctrl-V\": \"goPageDown\", \"Shift-Ctrl-V\": \"goPageUp\",\n    \"Ctrl-D\": \"delCharAfter\", \"Ctrl-H\": \"delCharBefore\", \"Alt-Backspace\": \"delWordBefore\", \"Ctrl-K\": \"killLine\",\n    \"Ctrl-T\": \"transposeChars\", \"Ctrl-O\": \"openLine\"\n  };\n  keyMap.macDefault = {\n    \"Cmd-A\": \"selectAll\", \"Cmd-D\": \"deleteLine\", \"Cmd-Z\": \"undo\", \"Shift-Cmd-Z\": \"redo\", \"Cmd-Y\": \"redo\",\n    \"Cmd-Home\": \"goDocStart\", \"Cmd-Up\": \"goDocStart\", \"Cmd-End\": \"goDocEnd\", \"Cmd-Down\": \"goDocEnd\", \"Alt-Left\": \"goGroupLeft\",\n    \"Alt-Right\": \"goGroupRight\", \"Cmd-Left\": \"goLineLeft\", \"Cmd-Right\": \"goLineRight\", \"Alt-Backspace\": \"delGroupBefore\",\n    \"Ctrl-Alt-Backspace\": \"delGroupAfter\", \"Alt-Delete\": \"delGroupAfter\", \"Cmd-S\": \"save\", \"Cmd-F\": \"find\",\n    \"Cmd-G\": \"findNext\", \"Shift-Cmd-G\": \"findPrev\", \"Cmd-Alt-F\": \"replace\", \"Shift-Cmd-Alt-F\": \"replaceAll\",\n    \"Cmd-[\": \"indentLess\", \"Cmd-]\": \"indentMore\", \"Cmd-Backspace\": \"delWrappedLineLeft\", \"Cmd-Delete\": \"delWrappedLineRight\",\n    \"Cmd-U\": \"undoSelection\", \"Shift-Cmd-U\": \"redoSelection\", \"Ctrl-Up\": \"goDocStart\", \"Ctrl-Down\": \"goDocEnd\",\n    \"fallthrough\": [\"basic\", \"emacsy\"]\n  };\n  keyMap[\"default\"] = mac ? keyMap.macDefault : keyMap.pcDefault;\n\n  // KEYMAP DISPATCH\n\n  function normalizeKeyName(name) {\n    var parts = name.split(/-(?!$)/);\n    name = parts[parts.length - 1];\n    var alt, ctrl, shift, cmd;\n    for (var i = 0; i < parts.length - 1; i++) {\n      var mod = parts[i];\n      if (/^(cmd|meta|m)$/i.test(mod)) { cmd = true; }\n      else if (/^a(lt)?$/i.test(mod)) { alt = true; }\n      else if (/^(c|ctrl|control)$/i.test(mod)) { ctrl = true; }\n      else if (/^s(hift)?$/i.test(mod)) { shift = true; }\n      else { throw new Error(\"Unrecognized modifier name: \" + mod) }\n    }\n    if (alt) { name = \"Alt-\" + name; }\n    if (ctrl) { name = \"Ctrl-\" + name; }\n    if (cmd) { name = \"Cmd-\" + name; }\n    if (shift) { name = \"Shift-\" + name; }\n    return name\n  }\n\n  // This is a kludge to keep keymaps mostly working as raw objects\n  // (backwards compatibility) while at the same time support features\n  // like normalization and multi-stroke key bindings. It compiles a\n  // new normalized keymap, and then updates the old object to reflect\n  // this.\n  function normalizeKeyMap(keymap) {\n    var copy = {};\n    for (var keyname in keymap) { if (keymap.hasOwnProperty(keyname)) {\n      var value = keymap[keyname];\n      if (/^(name|fallthrough|(de|at)tach)$/.test(keyname)) { continue }\n      if (value == \"...\") { delete keymap[keyname]; continue }\n\n      var keys = map(keyname.split(\" \"), normalizeKeyName);\n      for (var i = 0; i < keys.length; i++) {\n        var val = (void 0), name = (void 0);\n        if (i == keys.length - 1) {\n          name = keys.join(\" \");\n          val = value;\n        } else {\n          name = keys.slice(0, i + 1).join(\" \");\n          val = \"...\";\n        }\n        var prev = copy[name];\n        if (!prev) { copy[name] = val; }\n        else if (prev != val) { throw new Error(\"Inconsistent bindings for \" + name) }\n      }\n      delete keymap[keyname];\n    } }\n    for (var prop in copy) { keymap[prop] = copy[prop]; }\n    return keymap\n  }\n\n  function lookupKey(key, map, handle, context) {\n    map = getKeyMap(map);\n    var found = map.call ? map.call(key, context) : map[key];\n    if (found === false) { return \"nothing\" }\n    if (found === \"...\") { return \"multi\" }\n    if (found != null && handle(found)) { return \"handled\" }\n\n    if (map.fallthrough) {\n      if (Object.prototype.toString.call(map.fallthrough) != \"[object Array]\")\n        { return lookupKey(key, map.fallthrough, handle, context) }\n      for (var i = 0; i < map.fallthrough.length; i++) {\n        var result = lookupKey(key, map.fallthrough[i], handle, context);\n        if (result) { return result }\n      }\n    }\n  }\n\n  // Modifier key presses don't count as 'real' key presses for the\n  // purpose of keymap fallthrough.\n  function isModifierKey(value) {\n    var name = typeof value == \"string\" ? value : keyNames[value.keyCode];\n    return name == \"Ctrl\" || name == \"Alt\" || name == \"Shift\" || name == \"Mod\"\n  }\n\n  function addModifierNames(name, event, noShift) {\n    var base = name;\n    if (event.altKey && base != \"Alt\") { name = \"Alt-\" + name; }\n    if ((flipCtrlCmd ? event.metaKey : event.ctrlKey) && base != \"Ctrl\") { name = \"Ctrl-\" + name; }\n    if ((flipCtrlCmd ? event.ctrlKey : event.metaKey) && base != \"Mod\") { name = \"Cmd-\" + name; }\n    if (!noShift && event.shiftKey && base != \"Shift\") { name = \"Shift-\" + name; }\n    return name\n  }\n\n  // Look up the name of a key as indicated by an event object.\n  function keyName(event, noShift) {\n    if (presto && event.keyCode == 34 && event[\"char\"]) { return false }\n    var name = keyNames[event.keyCode];\n    if (name == null || event.altGraphKey) { return false }\n    // Ctrl-ScrollLock has keyCode 3, same as Ctrl-Pause,\n    // so we'll use event.code when available (Chrome 48+, FF 38+, Safari 10.1+)\n    if (event.keyCode == 3 && event.code) { name = event.code; }\n    return addModifierNames(name, event, noShift)\n  }\n\n  function getKeyMap(val) {\n    return typeof val == \"string\" ? keyMap[val] : val\n  }\n\n  // Helper for deleting text near the selection(s), used to implement\n  // backspace, delete, and similar functionality.\n  function deleteNearSelection(cm, compute) {\n    var ranges = cm.doc.sel.ranges, kill = [];\n    // Build up a set of ranges to kill first, merging overlapping\n    // ranges.\n    for (var i = 0; i < ranges.length; i++) {\n      var toKill = compute(ranges[i]);\n      while (kill.length && cmp(toKill.from, lst(kill).to) <= 0) {\n        var replaced = kill.pop();\n        if (cmp(replaced.from, toKill.from) < 0) {\n          toKill.from = replaced.from;\n          break\n        }\n      }\n      kill.push(toKill);\n    }\n    // Next, remove those actual ranges.\n    runInOp(cm, function () {\n      for (var i = kill.length - 1; i >= 0; i--)\n        { replaceRange(cm.doc, \"\", kill[i].from, kill[i].to, \"+delete\"); }\n      ensureCursorVisible(cm);\n    });\n  }\n\n  function moveCharLogically(line, ch, dir) {\n    var target = skipExtendingChars(line.text, ch + dir, dir);\n    return target < 0 || target > line.text.length ? null : target\n  }\n\n  function moveLogically(line, start, dir) {\n    var ch = moveCharLogically(line, start.ch, dir);\n    return ch == null ? null : new Pos(start.line, ch, dir < 0 ? \"after\" : \"before\")\n  }\n\n  function endOfLine(visually, cm, lineObj, lineNo, dir) {\n    if (visually) {\n      if (cm.doc.direction == \"rtl\") { dir = -dir; }\n      var order = getOrder(lineObj, cm.doc.direction);\n      if (order) {\n        var part = dir < 0 ? lst(order) : order[0];\n        var moveInStorageOrder = (dir < 0) == (part.level == 1);\n        var sticky = moveInStorageOrder ? \"after\" : \"before\";\n        var ch;\n        // With a wrapped rtl chunk (possibly spanning multiple bidi parts),\n        // it could be that the last bidi part is not on the last visual line,\n        // since visual lines contain content order-consecutive chunks.\n        // Thus, in rtl, we are looking for the first (content-order) character\n        // in the rtl chunk that is on the last line (that is, the same line\n        // as the last (content-order) character).\n        if (part.level > 0 || cm.doc.direction == \"rtl\") {\n          var prep = prepareMeasureForLine(cm, lineObj);\n          ch = dir < 0 ? lineObj.text.length - 1 : 0;\n          var targetTop = measureCharPrepared(cm, prep, ch).top;\n          ch = findFirst(function (ch) { return measureCharPrepared(cm, prep, ch).top == targetTop; }, (dir < 0) == (part.level == 1) ? part.from : part.to - 1, ch);\n          if (sticky == \"before\") { ch = moveCharLogically(lineObj, ch, 1); }\n        } else { ch = dir < 0 ? part.to : part.from; }\n        return new Pos(lineNo, ch, sticky)\n      }\n    }\n    return new Pos(lineNo, dir < 0 ? lineObj.text.length : 0, dir < 0 ? \"before\" : \"after\")\n  }\n\n  function moveVisually(cm, line, start, dir) {\n    var bidi = getOrder(line, cm.doc.direction);\n    if (!bidi) { return moveLogically(line, start, dir) }\n    if (start.ch >= line.text.length) {\n      start.ch = line.text.length;\n      start.sticky = \"before\";\n    } else if (start.ch <= 0) {\n      start.ch = 0;\n      start.sticky = \"after\";\n    }\n    var partPos = getBidiPartAt(bidi, start.ch, start.sticky), part = bidi[partPos];\n    if (cm.doc.direction == \"ltr\" && part.level % 2 == 0 && (dir > 0 ? part.to > start.ch : part.from < start.ch)) {\n      // Case 1: We move within an ltr part in an ltr editor. Even with wrapped lines,\n      // nothing interesting happens.\n      return moveLogically(line, start, dir)\n    }\n\n    var mv = function (pos, dir) { return moveCharLogically(line, pos instanceof Pos ? pos.ch : pos, dir); };\n    var prep;\n    var getWrappedLineExtent = function (ch) {\n      if (!cm.options.lineWrapping) { return {begin: 0, end: line.text.length} }\n      prep = prep || prepareMeasureForLine(cm, line);\n      return wrappedLineExtentChar(cm, line, prep, ch)\n    };\n    var wrappedLineExtent = getWrappedLineExtent(start.sticky == \"before\" ? mv(start, -1) : start.ch);\n\n    if (cm.doc.direction == \"rtl\" || part.level == 1) {\n      var moveInStorageOrder = (part.level == 1) == (dir < 0);\n      var ch = mv(start, moveInStorageOrder ? 1 : -1);\n      if (ch != null && (!moveInStorageOrder ? ch >= part.from && ch >= wrappedLineExtent.begin : ch <= part.to && ch <= wrappedLineExtent.end)) {\n        // Case 2: We move within an rtl part or in an rtl editor on the same visual line\n        var sticky = moveInStorageOrder ? \"before\" : \"after\";\n        return new Pos(start.line, ch, sticky)\n      }\n    }\n\n    // Case 3: Could not move within this bidi part in this visual line, so leave\n    // the current bidi part\n\n    var searchInVisualLine = function (partPos, dir, wrappedLineExtent) {\n      var getRes = function (ch, moveInStorageOrder) { return moveInStorageOrder\n        ? new Pos(start.line, mv(ch, 1), \"before\")\n        : new Pos(start.line, ch, \"after\"); };\n\n      for (; partPos >= 0 && partPos < bidi.length; partPos += dir) {\n        var part = bidi[partPos];\n        var moveInStorageOrder = (dir > 0) == (part.level != 1);\n        var ch = moveInStorageOrder ? wrappedLineExtent.begin : mv(wrappedLineExtent.end, -1);\n        if (part.from <= ch && ch < part.to) { return getRes(ch, moveInStorageOrder) }\n        ch = moveInStorageOrder ? part.from : mv(part.to, -1);\n        if (wrappedLineExtent.begin <= ch && ch < wrappedLineExtent.end) { return getRes(ch, moveInStorageOrder) }\n      }\n    };\n\n    // Case 3a: Look for other bidi parts on the same visual line\n    var res = searchInVisualLine(partPos + dir, dir, wrappedLineExtent);\n    if (res) { return res }\n\n    // Case 3b: Look for other bidi parts on the next visual line\n    var nextCh = dir > 0 ? wrappedLineExtent.end : mv(wrappedLineExtent.begin, -1);\n    if (nextCh != null && !(dir > 0 && nextCh == line.text.length)) {\n      res = searchInVisualLine(dir > 0 ? 0 : bidi.length - 1, dir, getWrappedLineExtent(nextCh));\n      if (res) { return res }\n    }\n\n    // Case 4: Nowhere to move\n    return null\n  }\n\n  // Commands are parameter-less actions that can be performed on an\n  // editor, mostly used for keybindings.\n  var commands = {\n    selectAll: selectAll,\n    singleSelection: function (cm) { return cm.setSelection(cm.getCursor(\"anchor\"), cm.getCursor(\"head\"), sel_dontScroll); },\n    killLine: function (cm) { return deleteNearSelection(cm, function (range) {\n      if (range.empty()) {\n        var len = getLine(cm.doc, range.head.line).text.length;\n        if (range.head.ch == len && range.head.line < cm.lastLine())\n          { return {from: range.head, to: Pos(range.head.line + 1, 0)} }\n        else\n          { return {from: range.head, to: Pos(range.head.line, len)} }\n      } else {\n        return {from: range.from(), to: range.to()}\n      }\n    }); },\n    deleteLine: function (cm) { return deleteNearSelection(cm, function (range) { return ({\n      from: Pos(range.from().line, 0),\n      to: clipPos(cm.doc, Pos(range.to().line + 1, 0))\n    }); }); },\n    delLineLeft: function (cm) { return deleteNearSelection(cm, function (range) { return ({\n      from: Pos(range.from().line, 0), to: range.from()\n    }); }); },\n    delWrappedLineLeft: function (cm) { return deleteNearSelection(cm, function (range) {\n      var top = cm.charCoords(range.head, \"div\").top + 5;\n      var leftPos = cm.coordsChar({left: 0, top: top}, \"div\");\n      return {from: leftPos, to: range.from()}\n    }); },\n    delWrappedLineRight: function (cm) { return deleteNearSelection(cm, function (range) {\n      var top = cm.charCoords(range.head, \"div\").top + 5;\n      var rightPos = cm.coordsChar({left: cm.display.lineDiv.offsetWidth + 100, top: top}, \"div\");\n      return {from: range.from(), to: rightPos }\n    }); },\n    undo: function (cm) { return cm.undo(); },\n    redo: function (cm) { return cm.redo(); },\n    undoSelection: function (cm) { return cm.undoSelection(); },\n    redoSelection: function (cm) { return cm.redoSelection(); },\n    goDocStart: function (cm) { return cm.extendSelection(Pos(cm.firstLine(), 0)); },\n    goDocEnd: function (cm) { return cm.extendSelection(Pos(cm.lastLine())); },\n    goLineStart: function (cm) { return cm.extendSelectionsBy(function (range) { return lineStart(cm, range.head.line); },\n      {origin: \"+move\", bias: 1}\n    ); },\n    goLineStartSmart: function (cm) { return cm.extendSelectionsBy(function (range) { return lineStartSmart(cm, range.head); },\n      {origin: \"+move\", bias: 1}\n    ); },\n    goLineEnd: function (cm) { return cm.extendSelectionsBy(function (range) { return lineEnd(cm, range.head.line); },\n      {origin: \"+move\", bias: -1}\n    ); },\n    goLineRight: function (cm) { return cm.extendSelectionsBy(function (range) {\n      var top = cm.cursorCoords(range.head, \"div\").top + 5;\n      return cm.coordsChar({left: cm.display.lineDiv.offsetWidth + 100, top: top}, \"div\")\n    }, sel_move); },\n    goLineLeft: function (cm) { return cm.extendSelectionsBy(function (range) {\n      var top = cm.cursorCoords(range.head, \"div\").top + 5;\n      return cm.coordsChar({left: 0, top: top}, \"div\")\n    }, sel_move); },\n    goLineLeftSmart: function (cm) { return cm.extendSelectionsBy(function (range) {\n      var top = cm.cursorCoords(range.head, \"div\").top + 5;\n      var pos = cm.coordsChar({left: 0, top: top}, \"div\");\n      if (pos.ch < cm.getLine(pos.line).search(/\\S/)) { return lineStartSmart(cm, range.head) }\n      return pos\n    }, sel_move); },\n    goLineUp: function (cm) { return cm.moveV(-1, \"line\"); },\n    goLineDown: function (cm) { return cm.moveV(1, \"line\"); },\n    goPageUp: function (cm) { return cm.moveV(-1, \"page\"); },\n    goPageDown: function (cm) { return cm.moveV(1, \"page\"); },\n    goCharLeft: function (cm) { return cm.moveH(-1, \"char\"); },\n    goCharRight: function (cm) { return cm.moveH(1, \"char\"); },\n    goColumnLeft: function (cm) { return cm.moveH(-1, \"column\"); },\n    goColumnRight: function (cm) { return cm.moveH(1, \"column\"); },\n    goWordLeft: function (cm) { return cm.moveH(-1, \"word\"); },\n    goGroupRight: function (cm) { return cm.moveH(1, \"group\"); },\n    goGroupLeft: function (cm) { return cm.moveH(-1, \"group\"); },\n    goWordRight: function (cm) { return cm.moveH(1, \"word\"); },\n    delCharBefore: function (cm) { return cm.deleteH(-1, \"codepoint\"); },\n    delCharAfter: function (cm) { return cm.deleteH(1, \"char\"); },\n    delWordBefore: function (cm) { return cm.deleteH(-1, \"word\"); },\n    delWordAfter: function (cm) { return cm.deleteH(1, \"word\"); },\n    delGroupBefore: function (cm) { return cm.deleteH(-1, \"group\"); },\n    delGroupAfter: function (cm) { return cm.deleteH(1, \"group\"); },\n    indentAuto: function (cm) { return cm.indentSelection(\"smart\"); },\n    indentMore: function (cm) { return cm.indentSelection(\"add\"); },\n    indentLess: function (cm) { return cm.indentSelection(\"subtract\"); },\n    insertTab: function (cm) { return cm.replaceSelection(\"\\t\"); },\n    insertSoftTab: function (cm) {\n      var spaces = [], ranges = cm.listSelections(), tabSize = cm.options.tabSize;\n      for (var i = 0; i < ranges.length; i++) {\n        var pos = ranges[i].from();\n        var col = countColumn(cm.getLine(pos.line), pos.ch, tabSize);\n        spaces.push(spaceStr(tabSize - col % tabSize));\n      }\n      cm.replaceSelections(spaces);\n    },\n    defaultTab: function (cm) {\n      if (cm.somethingSelected()) { cm.indentSelection(\"add\"); }\n      else { cm.execCommand(\"insertTab\"); }\n    },\n    // Swap the two chars left and right of each selection's head.\n    // Move cursor behind the two swapped characters afterwards.\n    //\n    // Doesn't consider line feeds a character.\n    // Doesn't scan more than one line above to find a character.\n    // Doesn't do anything on an empty line.\n    // Doesn't do anything with non-empty selections.\n    transposeChars: function (cm) { return runInOp(cm, function () {\n      var ranges = cm.listSelections(), newSel = [];\n      for (var i = 0; i < ranges.length; i++) {\n        if (!ranges[i].empty()) { continue }\n        var cur = ranges[i].head, line = getLine(cm.doc, cur.line).text;\n        if (line) {\n          if (cur.ch == line.length) { cur = new Pos(cur.line, cur.ch - 1); }\n          if (cur.ch > 0) {\n            cur = new Pos(cur.line, cur.ch + 1);\n            cm.replaceRange(line.charAt(cur.ch - 1) + line.charAt(cur.ch - 2),\n                            Pos(cur.line, cur.ch - 2), cur, \"+transpose\");\n          } else if (cur.line > cm.doc.first) {\n            var prev = getLine(cm.doc, cur.line - 1).text;\n            if (prev) {\n              cur = new Pos(cur.line, 1);\n              cm.replaceRange(line.charAt(0) + cm.doc.lineSeparator() +\n                              prev.charAt(prev.length - 1),\n                              Pos(cur.line - 1, prev.length - 1), cur, \"+transpose\");\n            }\n          }\n        }\n        newSel.push(new Range(cur, cur));\n      }\n      cm.setSelections(newSel);\n    }); },\n    newlineAndIndent: function (cm) { return runInOp(cm, function () {\n      var sels = cm.listSelections();\n      for (var i = sels.length - 1; i >= 0; i--)\n        { cm.replaceRange(cm.doc.lineSeparator(), sels[i].anchor, sels[i].head, \"+input\"); }\n      sels = cm.listSelections();\n      for (var i$1 = 0; i$1 < sels.length; i$1++)\n        { cm.indentLine(sels[i$1].from().line, null, true); }\n      ensureCursorVisible(cm);\n    }); },\n    openLine: function (cm) { return cm.replaceSelection(\"\\n\", \"start\"); },\n    toggleOverwrite: function (cm) { return cm.toggleOverwrite(); }\n  };\n\n\n  function lineStart(cm, lineN) {\n    var line = getLine(cm.doc, lineN);\n    var visual = visualLine(line);\n    if (visual != line) { lineN = lineNo(visual); }\n    return endOfLine(true, cm, visual, lineN, 1)\n  }\n  function lineEnd(cm, lineN) {\n    var line = getLine(cm.doc, lineN);\n    var visual = visualLineEnd(line);\n    if (visual != line) { lineN = lineNo(visual); }\n    return endOfLine(true, cm, line, lineN, -1)\n  }\n  function lineStartSmart(cm, pos) {\n    var start = lineStart(cm, pos.line);\n    var line = getLine(cm.doc, start.line);\n    var order = getOrder(line, cm.doc.direction);\n    if (!order || order[0].level == 0) {\n      var firstNonWS = Math.max(start.ch, line.text.search(/\\S/));\n      var inWS = pos.line == start.line && pos.ch <= firstNonWS && pos.ch;\n      return Pos(start.line, inWS ? 0 : firstNonWS, start.sticky)\n    }\n    return start\n  }\n\n  // Run a handler that was bound to a key.\n  function doHandleBinding(cm, bound, dropShift) {\n    if (typeof bound == \"string\") {\n      bound = commands[bound];\n      if (!bound) { return false }\n    }\n    // Ensure previous input has been read, so that the handler sees a\n    // consistent view of the document\n    cm.display.input.ensurePolled();\n    var prevShift = cm.display.shift, done = false;\n    try {\n      if (cm.isReadOnly()) { cm.state.suppressEdits = true; }\n      if (dropShift) { cm.display.shift = false; }\n      done = bound(cm) != Pass;\n    } finally {\n      cm.display.shift = prevShift;\n      cm.state.suppressEdits = false;\n    }\n    return done\n  }\n\n  function lookupKeyForEditor(cm, name, handle) {\n    for (var i = 0; i < cm.state.keyMaps.length; i++) {\n      var result = lookupKey(name, cm.state.keyMaps[i], handle, cm);\n      if (result) { return result }\n    }\n    return (cm.options.extraKeys && lookupKey(name, cm.options.extraKeys, handle, cm))\n      || lookupKey(name, cm.options.keyMap, handle, cm)\n  }\n\n  // Note that, despite the name, this function is also used to check\n  // for bound mouse clicks.\n\n  var stopSeq = new Delayed;\n\n  function dispatchKey(cm, name, e, handle) {\n    var seq = cm.state.keySeq;\n    if (seq) {\n      if (isModifierKey(name)) { return \"handled\" }\n      if (/\\'$/.test(name))\n        { cm.state.keySeq = null; }\n      else\n        { stopSeq.set(50, function () {\n          if (cm.state.keySeq == seq) {\n            cm.state.keySeq = null;\n            cm.display.input.reset();\n          }\n        }); }\n      if (dispatchKeyInner(cm, seq + \" \" + name, e, handle)) { return true }\n    }\n    return dispatchKeyInner(cm, name, e, handle)\n  }\n\n  function dispatchKeyInner(cm, name, e, handle) {\n    var result = lookupKeyForEditor(cm, name, handle);\n\n    if (result == \"multi\")\n      { cm.state.keySeq = name; }\n    if (result == \"handled\")\n      { signalLater(cm, \"keyHandled\", cm, name, e); }\n\n    if (result == \"handled\" || result == \"multi\") {\n      e_preventDefault(e);\n      restartBlink(cm);\n    }\n\n    return !!result\n  }\n\n  // Handle a key from the keydown event.\n  function handleKeyBinding(cm, e) {\n    var name = keyName(e, true);\n    if (!name) { return false }\n\n    if (e.shiftKey && !cm.state.keySeq) {\n      // First try to resolve full name (including 'Shift-'). Failing\n      // that, see if there is a cursor-motion command (starting with\n      // 'go') bound to the keyname without 'Shift-'.\n      return dispatchKey(cm, \"Shift-\" + name, e, function (b) { return doHandleBinding(cm, b, true); })\n          || dispatchKey(cm, name, e, function (b) {\n               if (typeof b == \"string\" ? /^go[A-Z]/.test(b) : b.motion)\n                 { return doHandleBinding(cm, b) }\n             })\n    } else {\n      return dispatchKey(cm, name, e, function (b) { return doHandleBinding(cm, b); })\n    }\n  }\n\n  // Handle a key from the keypress event\n  function handleCharBinding(cm, e, ch) {\n    return dispatchKey(cm, \"'\" + ch + \"'\", e, function (b) { return doHandleBinding(cm, b, true); })\n  }\n\n  var lastStoppedKey = null;\n  function onKeyDown(e) {\n    var cm = this;\n    if (e.target && e.target != cm.display.input.getField()) { return }\n    cm.curOp.focus = activeElt(root(cm));\n    if (signalDOMEvent(cm, e)) { return }\n    // IE does strange things with escape.\n    if (ie && ie_version < 11 && e.keyCode == 27) { e.returnValue = false; }\n    var code = e.keyCode;\n    cm.display.shift = code == 16 || e.shiftKey;\n    var handled = handleKeyBinding(cm, e);\n    if (presto) {\n      lastStoppedKey = handled ? code : null;\n      // Opera has no cut event... we try to at least catch the key combo\n      if (!handled && code == 88 && !hasCopyEvent && (mac ? e.metaKey : e.ctrlKey))\n        { cm.replaceSelection(\"\", null, \"cut\"); }\n    }\n    if (gecko && !mac && !handled && code == 46 && e.shiftKey && !e.ctrlKey && document.execCommand)\n      { document.execCommand(\"cut\"); }\n\n    // Turn mouse into crosshair when Alt is held on Mac.\n    if (code == 18 && !/\\bCodeMirror-crosshair\\b/.test(cm.display.lineDiv.className))\n      { showCrossHair(cm); }\n  }\n\n  function showCrossHair(cm) {\n    var lineDiv = cm.display.lineDiv;\n    addClass(lineDiv, \"CodeMirror-crosshair\");\n\n    function up(e) {\n      if (e.keyCode == 18 || !e.altKey) {\n        rmClass(lineDiv, \"CodeMirror-crosshair\");\n        off(document, \"keyup\", up);\n        off(document, \"mouseover\", up);\n      }\n    }\n    on(document, \"keyup\", up);\n    on(document, \"mouseover\", up);\n  }\n\n  function onKeyUp(e) {\n    if (e.keyCode == 16) { this.doc.sel.shift = false; }\n    signalDOMEvent(this, e);\n  }\n\n  function onKeyPress(e) {\n    var cm = this;\n    if (e.target && e.target != cm.display.input.getField()) { return }\n    if (eventInWidget(cm.display, e) || signalDOMEvent(cm, e) || e.ctrlKey && !e.altKey || mac && e.metaKey) { return }\n    var keyCode = e.keyCode, charCode = e.charCode;\n    if (presto && keyCode == lastStoppedKey) {lastStoppedKey = null; e_preventDefault(e); return}\n    if ((presto && (!e.which || e.which < 10)) && handleKeyBinding(cm, e)) { return }\n    var ch = String.fromCharCode(charCode == null ? keyCode : charCode);\n    // Some browsers fire keypress events for backspace\n    if (ch == \"\\x08\") { return }\n    if (handleCharBinding(cm, e, ch)) { return }\n    cm.display.input.onKeyPress(e);\n  }\n\n  var DOUBLECLICK_DELAY = 400;\n\n  var PastClick = function(time, pos, button) {\n    this.time = time;\n    this.pos = pos;\n    this.button = button;\n  };\n\n  PastClick.prototype.compare = function (time, pos, button) {\n    return this.time + DOUBLECLICK_DELAY > time &&\n      cmp(pos, this.pos) == 0 && button == this.button\n  };\n\n  var lastClick, lastDoubleClick;\n  function clickRepeat(pos, button) {\n    var now = +new Date;\n    if (lastDoubleClick && lastDoubleClick.compare(now, pos, button)) {\n      lastClick = lastDoubleClick = null;\n      return \"triple\"\n    } else if (lastClick && lastClick.compare(now, pos, button)) {\n      lastDoubleClick = new PastClick(now, pos, button);\n      lastClick = null;\n      return \"double\"\n    } else {\n      lastClick = new PastClick(now, pos, button);\n      lastDoubleClick = null;\n      return \"single\"\n    }\n  }\n\n  // A mouse down can be a single click, double click, triple click,\n  // start of selection drag, start of text drag, new cursor\n  // (ctrl-click), rectangle drag (alt-drag), or xwin\n  // middle-click-paste. Or it might be a click on something we should\n  // not interfere with, such as a scrollbar or widget.\n  function onMouseDown(e) {\n    var cm = this, display = cm.display;\n    if (signalDOMEvent(cm, e) || display.activeTouch && display.input.supportsTouch()) { return }\n    display.input.ensurePolled();\n    display.shift = e.shiftKey;\n\n    if (eventInWidget(display, e)) {\n      if (!webkit) {\n        // Briefly turn off draggability, to allow widgets to do\n        // normal dragging things.\n        display.scroller.draggable = false;\n        setTimeout(function () { return display.scroller.draggable = true; }, 100);\n      }\n      return\n    }\n    if (clickInGutter(cm, e)) { return }\n    var pos = posFromMouse(cm, e), button = e_button(e), repeat = pos ? clickRepeat(pos, button) : \"single\";\n    win(cm).focus();\n\n    // #3261: make sure, that we're not starting a second selection\n    if (button == 1 && cm.state.selectingText)\n      { cm.state.selectingText(e); }\n\n    if (pos && handleMappedButton(cm, button, pos, repeat, e)) { return }\n\n    if (button == 1) {\n      if (pos) { leftButtonDown(cm, pos, repeat, e); }\n      else if (e_target(e) == display.scroller) { e_preventDefault(e); }\n    } else if (button == 2) {\n      if (pos) { extendSelection(cm.doc, pos); }\n      setTimeout(function () { return display.input.focus(); }, 20);\n    } else if (button == 3) {\n      if (captureRightClick) { cm.display.input.onContextMenu(e); }\n      else { delayBlurEvent(cm); }\n    }\n  }\n\n  function handleMappedButton(cm, button, pos, repeat, event) {\n    var name = \"Click\";\n    if (repeat == \"double\") { name = \"Double\" + name; }\n    else if (repeat == \"triple\") { name = \"Triple\" + name; }\n    name = (button == 1 ? \"Left\" : button == 2 ? \"Middle\" : \"Right\") + name;\n\n    return dispatchKey(cm,  addModifierNames(name, event), event, function (bound) {\n      if (typeof bound == \"string\") { bound = commands[bound]; }\n      if (!bound) { return false }\n      var done = false;\n      try {\n        if (cm.isReadOnly()) { cm.state.suppressEdits = true; }\n        done = bound(cm, pos) != Pass;\n      } finally {\n        cm.state.suppressEdits = false;\n      }\n      return done\n    })\n  }\n\n  function configureMouse(cm, repeat, event) {\n    var option = cm.getOption(\"configureMouse\");\n    var value = option ? option(cm, repeat, event) : {};\n    if (value.unit == null) {\n      var rect = chromeOS ? event.shiftKey && event.metaKey : event.altKey;\n      value.unit = rect ? \"rectangle\" : repeat == \"single\" ? \"char\" : repeat == \"double\" ? \"word\" : \"line\";\n    }\n    if (value.extend == null || cm.doc.extend) { value.extend = cm.doc.extend || event.shiftKey; }\n    if (value.addNew == null) { value.addNew = mac ? event.metaKey : event.ctrlKey; }\n    if (value.moveOnDrag == null) { value.moveOnDrag = !(mac ? event.altKey : event.ctrlKey); }\n    return value\n  }\n\n  function leftButtonDown(cm, pos, repeat, event) {\n    if (ie) { setTimeout(bind(ensureFocus, cm), 0); }\n    else { cm.curOp.focus = activeElt(root(cm)); }\n\n    var behavior = configureMouse(cm, repeat, event);\n\n    var sel = cm.doc.sel, contained;\n    if (cm.options.dragDrop && dragAndDrop && !cm.isReadOnly() &&\n        repeat == \"single\" && (contained = sel.contains(pos)) > -1 &&\n        (cmp((contained = sel.ranges[contained]).from(), pos) < 0 || pos.xRel > 0) &&\n        (cmp(contained.to(), pos) > 0 || pos.xRel < 0))\n      { leftButtonStartDrag(cm, event, pos, behavior); }\n    else\n      { leftButtonSelect(cm, event, pos, behavior); }\n  }\n\n  // Start a text drag. When it ends, see if any dragging actually\n  // happen, and treat as a click if it didn't.\n  function leftButtonStartDrag(cm, event, pos, behavior) {\n    var display = cm.display, moved = false;\n    var dragEnd = operation(cm, function (e) {\n      if (webkit) { display.scroller.draggable = false; }\n      cm.state.draggingText = false;\n      if (cm.state.delayingBlurEvent) {\n        if (cm.hasFocus()) { cm.state.delayingBlurEvent = false; }\n        else { delayBlurEvent(cm); }\n      }\n      off(display.wrapper.ownerDocument, \"mouseup\", dragEnd);\n      off(display.wrapper.ownerDocument, \"mousemove\", mouseMove);\n      off(display.scroller, \"dragstart\", dragStart);\n      off(display.scroller, \"drop\", dragEnd);\n      if (!moved) {\n        e_preventDefault(e);\n        if (!behavior.addNew)\n          { extendSelection(cm.doc, pos, null, null, behavior.extend); }\n        // Work around unexplainable focus problem in IE9 (#2127) and Chrome (#3081)\n        if ((webkit && !safari) || ie && ie_version == 9)\n          { setTimeout(function () {display.wrapper.ownerDocument.body.focus({preventScroll: true}); display.input.focus();}, 20); }\n        else\n          { display.input.focus(); }\n      }\n    });\n    var mouseMove = function(e2) {\n      moved = moved || Math.abs(event.clientX - e2.clientX) + Math.abs(event.clientY - e2.clientY) >= 10;\n    };\n    var dragStart = function () { return moved = true; };\n    // Let the drag handler handle this.\n    if (webkit) { display.scroller.draggable = true; }\n    cm.state.draggingText = dragEnd;\n    dragEnd.copy = !behavior.moveOnDrag;\n    on(display.wrapper.ownerDocument, \"mouseup\", dragEnd);\n    on(display.wrapper.ownerDocument, \"mousemove\", mouseMove);\n    on(display.scroller, \"dragstart\", dragStart);\n    on(display.scroller, \"drop\", dragEnd);\n\n    cm.state.delayingBlurEvent = true;\n    setTimeout(function () { return display.input.focus(); }, 20);\n    // IE's approach to draggable\n    if (display.scroller.dragDrop) { display.scroller.dragDrop(); }\n  }\n\n  function rangeForUnit(cm, pos, unit) {\n    if (unit == \"char\") { return new Range(pos, pos) }\n    if (unit == \"word\") { return cm.findWordAt(pos) }\n    if (unit == \"line\") { return new Range(Pos(pos.line, 0), clipPos(cm.doc, Pos(pos.line + 1, 0))) }\n    var result = unit(cm, pos);\n    return new Range(result.from, result.to)\n  }\n\n  // Normal selection, as opposed to text dragging.\n  function leftButtonSelect(cm, event, start, behavior) {\n    if (ie) { delayBlurEvent(cm); }\n    var display = cm.display, doc = cm.doc;\n    e_preventDefault(event);\n\n    var ourRange, ourIndex, startSel = doc.sel, ranges = startSel.ranges;\n    if (behavior.addNew && !behavior.extend) {\n      ourIndex = doc.sel.contains(start);\n      if (ourIndex > -1)\n        { ourRange = ranges[ourIndex]; }\n      else\n        { ourRange = new Range(start, start); }\n    } else {\n      ourRange = doc.sel.primary();\n      ourIndex = doc.sel.primIndex;\n    }\n\n    if (behavior.unit == \"rectangle\") {\n      if (!behavior.addNew) { ourRange = new Range(start, start); }\n      start = posFromMouse(cm, event, true, true);\n      ourIndex = -1;\n    } else {\n      var range = rangeForUnit(cm, start, behavior.unit);\n      if (behavior.extend)\n        { ourRange = extendRange(ourRange, range.anchor, range.head, behavior.extend); }\n      else\n        { ourRange = range; }\n    }\n\n    if (!behavior.addNew) {\n      ourIndex = 0;\n      setSelection(doc, new Selection([ourRange], 0), sel_mouse);\n      startSel = doc.sel;\n    } else if (ourIndex == -1) {\n      ourIndex = ranges.length;\n      setSelection(doc, normalizeSelection(cm, ranges.concat([ourRange]), ourIndex),\n                   {scroll: false, origin: \"*mouse\"});\n    } else if (ranges.length > 1 && ranges[ourIndex].empty() && behavior.unit == \"char\" && !behavior.extend) {\n      setSelection(doc, normalizeSelection(cm, ranges.slice(0, ourIndex).concat(ranges.slice(ourIndex + 1)), 0),\n                   {scroll: false, origin: \"*mouse\"});\n      startSel = doc.sel;\n    } else {\n      replaceOneSelection(doc, ourIndex, ourRange, sel_mouse);\n    }\n\n    var lastPos = start;\n    function extendTo(pos) {\n      if (cmp(lastPos, pos) == 0) { return }\n      lastPos = pos;\n\n      if (behavior.unit == \"rectangle\") {\n        var ranges = [], tabSize = cm.options.tabSize;\n        var startCol = countColumn(getLine(doc, start.line).text, start.ch, tabSize);\n        var posCol = countColumn(getLine(doc, pos.line).text, pos.ch, tabSize);\n        var left = Math.min(startCol, posCol), right = Math.max(startCol, posCol);\n        for (var line = Math.min(start.line, pos.line), end = Math.min(cm.lastLine(), Math.max(start.line, pos.line));\n             line <= end; line++) {\n          var text = getLine(doc, line).text, leftPos = findColumn(text, left, tabSize);\n          if (left == right)\n            { ranges.push(new Range(Pos(line, leftPos), Pos(line, leftPos))); }\n          else if (text.length > leftPos)\n            { ranges.push(new Range(Pos(line, leftPos), Pos(line, findColumn(text, right, tabSize)))); }\n        }\n        if (!ranges.length) { ranges.push(new Range(start, start)); }\n        setSelection(doc, normalizeSelection(cm, startSel.ranges.slice(0, ourIndex).concat(ranges), ourIndex),\n                     {origin: \"*mouse\", scroll: false});\n        cm.scrollIntoView(pos);\n      } else {\n        var oldRange = ourRange;\n        var range = rangeForUnit(cm, pos, behavior.unit);\n        var anchor = oldRange.anchor, head;\n        if (cmp(range.anchor, anchor) > 0) {\n          head = range.head;\n          anchor = minPos(oldRange.from(), range.anchor);\n        } else {\n          head = range.anchor;\n          anchor = maxPos(oldRange.to(), range.head);\n        }\n        var ranges$1 = startSel.ranges.slice(0);\n        ranges$1[ourIndex] = bidiSimplify(cm, new Range(clipPos(doc, anchor), head));\n        setSelection(doc, normalizeSelection(cm, ranges$1, ourIndex), sel_mouse);\n      }\n    }\n\n    var editorSize = display.wrapper.getBoundingClientRect();\n    // Used to ensure timeout re-tries don't fire when another extend\n    // happened in the meantime (clearTimeout isn't reliable -- at\n    // least on Chrome, the timeouts still happen even when cleared,\n    // if the clear happens after their scheduled firing time).\n    var counter = 0;\n\n    function extend(e) {\n      var curCount = ++counter;\n      var cur = posFromMouse(cm, e, true, behavior.unit == \"rectangle\");\n      if (!cur) { return }\n      if (cmp(cur, lastPos) != 0) {\n        cm.curOp.focus = activeElt(root(cm));\n        extendTo(cur);\n        var visible = visibleLines(display, doc);\n        if (cur.line >= visible.to || cur.line < visible.from)\n          { setTimeout(operation(cm, function () {if (counter == curCount) { extend(e); }}), 150); }\n      } else {\n        var outside = e.clientY < editorSize.top ? -20 : e.clientY > editorSize.bottom ? 20 : 0;\n        if (outside) { setTimeout(operation(cm, function () {\n          if (counter != curCount) { return }\n          display.scroller.scrollTop += outside;\n          extend(e);\n        }), 50); }\n      }\n    }\n\n    function done(e) {\n      cm.state.selectingText = false;\n      counter = Infinity;\n      // If e is null or undefined we interpret this as someone trying\n      // to explicitly cancel the selection rather than the user\n      // letting go of the mouse button.\n      if (e) {\n        e_preventDefault(e);\n        display.input.focus();\n      }\n      off(display.wrapper.ownerDocument, \"mousemove\", move);\n      off(display.wrapper.ownerDocument, \"mouseup\", up);\n      doc.history.lastSelOrigin = null;\n    }\n\n    var move = operation(cm, function (e) {\n      if (e.buttons === 0 || !e_button(e)) { done(e); }\n      else { extend(e); }\n    });\n    var up = operation(cm, done);\n    cm.state.selectingText = up;\n    on(display.wrapper.ownerDocument, \"mousemove\", move);\n    on(display.wrapper.ownerDocument, \"mouseup\", up);\n  }\n\n  // Used when mouse-selecting to adjust the anchor to the proper side\n  // of a bidi jump depending on the visual position of the head.\n  function bidiSimplify(cm, range) {\n    var anchor = range.anchor;\n    var head = range.head;\n    var anchorLine = getLine(cm.doc, anchor.line);\n    if (cmp(anchor, head) == 0 && anchor.sticky == head.sticky) { return range }\n    var order = getOrder(anchorLine);\n    if (!order) { return range }\n    var index = getBidiPartAt(order, anchor.ch, anchor.sticky), part = order[index];\n    if (part.from != anchor.ch && part.to != anchor.ch) { return range }\n    var boundary = index + ((part.from == anchor.ch) == (part.level != 1) ? 0 : 1);\n    if (boundary == 0 || boundary == order.length) { return range }\n\n    // Compute the relative visual position of the head compared to the\n    // anchor (<0 is to the left, >0 to the right)\n    var leftSide;\n    if (head.line != anchor.line) {\n      leftSide = (head.line - anchor.line) * (cm.doc.direction == \"ltr\" ? 1 : -1) > 0;\n    } else {\n      var headIndex = getBidiPartAt(order, head.ch, head.sticky);\n      var dir = headIndex - index || (head.ch - anchor.ch) * (part.level == 1 ? -1 : 1);\n      if (headIndex == boundary - 1 || headIndex == boundary)\n        { leftSide = dir < 0; }\n      else\n        { leftSide = dir > 0; }\n    }\n\n    var usePart = order[boundary + (leftSide ? -1 : 0)];\n    var from = leftSide == (usePart.level == 1);\n    var ch = from ? usePart.from : usePart.to, sticky = from ? \"after\" : \"before\";\n    return anchor.ch == ch && anchor.sticky == sticky ? range : new Range(new Pos(anchor.line, ch, sticky), head)\n  }\n\n\n  // Determines whether an event happened in the gutter, and fires the\n  // handlers for the corresponding event.\n  function gutterEvent(cm, e, type, prevent) {\n    var mX, mY;\n    if (e.touches) {\n      mX = e.touches[0].clientX;\n      mY = e.touches[0].clientY;\n    } else {\n      try { mX = e.clientX; mY = e.clientY; }\n      catch(e$1) { return false }\n    }\n    if (mX >= Math.floor(cm.display.gutters.getBoundingClientRect().right)) { return false }\n    if (prevent) { e_preventDefault(e); }\n\n    var display = cm.display;\n    var lineBox = display.lineDiv.getBoundingClientRect();\n\n    if (mY > lineBox.bottom || !hasHandler(cm, type)) { return e_defaultPrevented(e) }\n    mY -= lineBox.top - display.viewOffset;\n\n    for (var i = 0; i < cm.display.gutterSpecs.length; ++i) {\n      var g = display.gutters.childNodes[i];\n      if (g && g.getBoundingClientRect().right >= mX) {\n        var line = lineAtHeight(cm.doc, mY);\n        var gutter = cm.display.gutterSpecs[i];\n        signal(cm, type, cm, line, gutter.className, e);\n        return e_defaultPrevented(e)\n      }\n    }\n  }\n\n  function clickInGutter(cm, e) {\n    return gutterEvent(cm, e, \"gutterClick\", true)\n  }\n\n  // CONTEXT MENU HANDLING\n\n  // To make the context menu work, we need to briefly unhide the\n  // textarea (making it as unobtrusive as possible) to let the\n  // right-click take effect on it.\n  function onContextMenu(cm, e) {\n    if (eventInWidget(cm.display, e) || contextMenuInGutter(cm, e)) { return }\n    if (signalDOMEvent(cm, e, \"contextmenu\")) { return }\n    if (!captureRightClick) { cm.display.input.onContextMenu(e); }\n  }\n\n  function contextMenuInGutter(cm, e) {\n    if (!hasHandler(cm, \"gutterContextMenu\")) { return false }\n    return gutterEvent(cm, e, \"gutterContextMenu\", false)\n  }\n\n  function themeChanged(cm) {\n    cm.display.wrapper.className = cm.display.wrapper.className.replace(/\\s*cm-s-\\S+/g, \"\") +\n      cm.options.theme.replace(/(^|\\s)\\s*/g, \" cm-s-\");\n    clearCaches(cm);\n  }\n\n  var Init = {toString: function(){return \"CodeMirror.Init\"}};\n\n  var defaults = {};\n  var optionHandlers = {};\n\n  function defineOptions(CodeMirror) {\n    var optionHandlers = CodeMirror.optionHandlers;\n\n    function option(name, deflt, handle, notOnInit) {\n      CodeMirror.defaults[name] = deflt;\n      if (handle) { optionHandlers[name] =\n        notOnInit ? function (cm, val, old) {if (old != Init) { handle(cm, val, old); }} : handle; }\n    }\n\n    CodeMirror.defineOption = option;\n\n    // Passed to option handlers when there is no old value.\n    CodeMirror.Init = Init;\n\n    // These two are, on init, called from the constructor because they\n    // have to be initialized before the editor can start at all.\n    option(\"value\", \"\", function (cm, val) { return cm.setValue(val); }, true);\n    option(\"mode\", null, function (cm, val) {\n      cm.doc.modeOption = val;\n      loadMode(cm);\n    }, true);\n\n    option(\"indentUnit\", 2, loadMode, true);\n    option(\"indentWithTabs\", false);\n    option(\"smartIndent\", true);\n    option(\"tabSize\", 4, function (cm) {\n      resetModeState(cm);\n      clearCaches(cm);\n      regChange(cm);\n    }, true);\n\n    option(\"lineSeparator\", null, function (cm, val) {\n      cm.doc.lineSep = val;\n      if (!val) { return }\n      var newBreaks = [], lineNo = cm.doc.first;\n      cm.doc.iter(function (line) {\n        for (var pos = 0;;) {\n          var found = line.text.indexOf(val, pos);\n          if (found == -1) { break }\n          pos = found + val.length;\n          newBreaks.push(Pos(lineNo, found));\n        }\n        lineNo++;\n      });\n      for (var i = newBreaks.length - 1; i >= 0; i--)\n        { replaceRange(cm.doc, val, newBreaks[i], Pos(newBreaks[i].line, newBreaks[i].ch + val.length)); }\n    });\n    option(\"specialChars\", /[\\u0000-\\u001f\\u007f-\\u009f\\u00ad\\u061c\\u200b\\u200e\\u200f\\u2028\\u2029\\u202d\\u202e\\u2066\\u2067\\u2069\\ufeff\\ufff9-\\ufffc]/g, function (cm, val, old) {\n      cm.state.specialChars = new RegExp(val.source + (val.test(\"\\t\") ? \"\" : \"|\\t\"), \"g\");\n      if (old != Init) { cm.refresh(); }\n    });\n    option(\"specialCharPlaceholder\", defaultSpecialCharPlaceholder, function (cm) { return cm.refresh(); }, true);\n    option(\"electricChars\", true);\n    option(\"inputStyle\", mobile ? \"contenteditable\" : \"textarea\", function () {\n      throw new Error(\"inputStyle can not (yet) be changed in a running editor\") // FIXME\n    }, true);\n    option(\"spellcheck\", false, function (cm, val) { return cm.getInputField().spellcheck = val; }, true);\n    option(\"autocorrect\", false, function (cm, val) { return cm.getInputField().autocorrect = val; }, true);\n    option(\"autocapitalize\", false, function (cm, val) { return cm.getInputField().autocapitalize = val; }, true);\n    option(\"rtlMoveVisually\", !windows);\n    option(\"wholeLineUpdateBefore\", true);\n\n    option(\"theme\", \"default\", function (cm) {\n      themeChanged(cm);\n      updateGutters(cm);\n    }, true);\n    option(\"keyMap\", \"default\", function (cm, val, old) {\n      var next = getKeyMap(val);\n      var prev = old != Init && getKeyMap(old);\n      if (prev && prev.detach) { prev.detach(cm, next); }\n      if (next.attach) { next.attach(cm, prev || null); }\n    });\n    option(\"extraKeys\", null);\n    option(\"configureMouse\", null);\n\n    option(\"lineWrapping\", false, wrappingChanged, true);\n    option(\"gutters\", [], function (cm, val) {\n      cm.display.gutterSpecs = getGutters(val, cm.options.lineNumbers);\n      updateGutters(cm);\n    }, true);\n    option(\"fixedGutter\", true, function (cm, val) {\n      cm.display.gutters.style.left = val ? compensateForHScroll(cm.display) + \"px\" : \"0\";\n      cm.refresh();\n    }, true);\n    option(\"coverGutterNextToScrollbar\", false, function (cm) { return updateScrollbars(cm); }, true);\n    option(\"scrollbarStyle\", \"native\", function (cm) {\n      initScrollbars(cm);\n      updateScrollbars(cm);\n      cm.display.scrollbars.setScrollTop(cm.doc.scrollTop);\n      cm.display.scrollbars.setScrollLeft(cm.doc.scrollLeft);\n    }, true);\n    option(\"lineNumbers\", false, function (cm, val) {\n      cm.display.gutterSpecs = getGutters(cm.options.gutters, val);\n      updateGutters(cm);\n    }, true);\n    option(\"firstLineNumber\", 1, updateGutters, true);\n    option(\"lineNumberFormatter\", function (integer) { return integer; }, updateGutters, true);\n    option(\"showCursorWhenSelecting\", false, updateSelection, true);\n\n    option(\"resetSelectionOnContextMenu\", true);\n    option(\"lineWiseCopyCut\", true);\n    option(\"pasteLinesPerSelection\", true);\n    option(\"selectionsMayTouch\", false);\n\n    option(\"readOnly\", false, function (cm, val) {\n      if (val == \"nocursor\") {\n        onBlur(cm);\n        cm.display.input.blur();\n      }\n      cm.display.input.readOnlyChanged(val);\n    });\n\n    option(\"screenReaderLabel\", null, function (cm, val) {\n      val = (val === '') ? null : val;\n      cm.display.input.screenReaderLabelChanged(val);\n    });\n\n    option(\"disableInput\", false, function (cm, val) {if (!val) { cm.display.input.reset(); }}, true);\n    option(\"dragDrop\", true, dragDropChanged);\n    option(\"allowDropFileTypes\", null);\n\n    option(\"cursorBlinkRate\", 530);\n    option(\"cursorScrollMargin\", 0);\n    option(\"cursorHeight\", 1, updateSelection, true);\n    option(\"singleCursorHeightPerLine\", true, updateSelection, true);\n    option(\"workTime\", 100);\n    option(\"workDelay\", 100);\n    option(\"flattenSpans\", true, resetModeState, true);\n    option(\"addModeClass\", false, resetModeState, true);\n    option(\"pollInterval\", 100);\n    option(\"undoDepth\", 200, function (cm, val) { return cm.doc.history.undoDepth = val; });\n    option(\"historyEventDelay\", 1250);\n    option(\"viewportMargin\", 10, function (cm) { return cm.refresh(); }, true);\n    option(\"maxHighlightLength\", 10000, resetModeState, true);\n    option(\"moveInputWithCursor\", true, function (cm, val) {\n      if (!val) { cm.display.input.resetPosition(); }\n    });\n\n    option(\"tabindex\", null, function (cm, val) { return cm.display.input.getField().tabIndex = val || \"\"; });\n    option(\"autofocus\", null);\n    option(\"direction\", \"ltr\", function (cm, val) { return cm.doc.setDirection(val); }, true);\n    option(\"phrases\", null);\n  }\n\n  function dragDropChanged(cm, value, old) {\n    var wasOn = old && old != Init;\n    if (!value != !wasOn) {\n      var funcs = cm.display.dragFunctions;\n      var toggle = value ? on : off;\n      toggle(cm.display.scroller, \"dragstart\", funcs.start);\n      toggle(cm.display.scroller, \"dragenter\", funcs.enter);\n      toggle(cm.display.scroller, \"dragover\", funcs.over);\n      toggle(cm.display.scroller, \"dragleave\", funcs.leave);\n      toggle(cm.display.scroller, \"drop\", funcs.drop);\n    }\n  }\n\n  function wrappingChanged(cm) {\n    if (cm.options.lineWrapping) {\n      addClass(cm.display.wrapper, \"CodeMirror-wrap\");\n      cm.display.sizer.style.minWidth = \"\";\n      cm.display.sizerWidth = null;\n    } else {\n      rmClass(cm.display.wrapper, \"CodeMirror-wrap\");\n      findMaxLine(cm);\n    }\n    estimateLineHeights(cm);\n    regChange(cm);\n    clearCaches(cm);\n    setTimeout(function () { return updateScrollbars(cm); }, 100);\n  }\n\n  // A CodeMirror instance represents an editor. This is the object\n  // that user code is usually dealing with.\n\n  function CodeMirror(place, options) {\n    var this$1 = this;\n\n    if (!(this instanceof CodeMirror)) { return new CodeMirror(place, options) }\n\n    this.options = options = options ? copyObj(options) : {};\n    // Determine effective options based on given values and defaults.\n    copyObj(defaults, options, false);\n\n    var doc = options.value;\n    if (typeof doc == \"string\") { doc = new Doc(doc, options.mode, null, options.lineSeparator, options.direction); }\n    else if (options.mode) { doc.modeOption = options.mode; }\n    this.doc = doc;\n\n    var input = new CodeMirror.inputStyles[options.inputStyle](this);\n    var display = this.display = new Display(place, doc, input, options);\n    display.wrapper.CodeMirror = this;\n    themeChanged(this);\n    if (options.lineWrapping)\n      { this.display.wrapper.className += \" CodeMirror-wrap\"; }\n    initScrollbars(this);\n\n    this.state = {\n      keyMaps: [],  // stores maps added by addKeyMap\n      overlays: [], // highlighting overlays, as added by addOverlay\n      modeGen: 0,   // bumped when mode/overlay changes, used to invalidate highlighting info\n      overwrite: false,\n      delayingBlurEvent: false,\n      focused: false,\n      suppressEdits: false, // used to disable editing during key handlers when in readOnly mode\n      pasteIncoming: -1, cutIncoming: -1, // help recognize paste/cut edits in input.poll\n      selectingText: false,\n      draggingText: false,\n      highlight: new Delayed(), // stores highlight worker timeout\n      keySeq: null,  // Unfinished key sequence\n      specialChars: null\n    };\n\n    if (options.autofocus && !mobile) { display.input.focus(); }\n\n    // Override magic textarea content restore that IE sometimes does\n    // on our hidden textarea on reload\n    if (ie && ie_version < 11) { setTimeout(function () { return this$1.display.input.reset(true); }, 20); }\n\n    registerEventHandlers(this);\n    ensureGlobalHandlers();\n\n    startOperation(this);\n    this.curOp.forceUpdate = true;\n    attachDoc(this, doc);\n\n    if ((options.autofocus && !mobile) || this.hasFocus())\n      { setTimeout(function () {\n        if (this$1.hasFocus() && !this$1.state.focused) { onFocus(this$1); }\n      }, 20); }\n    else\n      { onBlur(this); }\n\n    for (var opt in optionHandlers) { if (optionHandlers.hasOwnProperty(opt))\n      { optionHandlers[opt](this, options[opt], Init); } }\n    maybeUpdateLineNumberWidth(this);\n    if (options.finishInit) { options.finishInit(this); }\n    for (var i = 0; i < initHooks.length; ++i) { initHooks[i](this); }\n    endOperation(this);\n    // Suppress optimizelegibility in Webkit, since it breaks text\n    // measuring on line wrapping boundaries.\n    if (webkit && options.lineWrapping &&\n        getComputedStyle(display.lineDiv).textRendering == \"optimizelegibility\")\n      { display.lineDiv.style.textRendering = \"auto\"; }\n  }\n\n  // The default configuration options.\n  CodeMirror.defaults = defaults;\n  // Functions to run when options are changed.\n  CodeMirror.optionHandlers = optionHandlers;\n\n  // Attach the necessary event handlers when initializing the editor\n  function registerEventHandlers(cm) {\n    var d = cm.display;\n    on(d.scroller, \"mousedown\", operation(cm, onMouseDown));\n    // Older IE's will not fire a second mousedown for a double click\n    if (ie && ie_version < 11)\n      { on(d.scroller, \"dblclick\", operation(cm, function (e) {\n        if (signalDOMEvent(cm, e)) { return }\n        var pos = posFromMouse(cm, e);\n        if (!pos || clickInGutter(cm, e) || eventInWidget(cm.display, e)) { return }\n        e_preventDefault(e);\n        var word = cm.findWordAt(pos);\n        extendSelection(cm.doc, word.anchor, word.head);\n      })); }\n    else\n      { on(d.scroller, \"dblclick\", function (e) { return signalDOMEvent(cm, e) || e_preventDefault(e); }); }\n    // Some browsers fire contextmenu *after* opening the menu, at\n    // which point we can't mess with it anymore. Context menu is\n    // handled in onMouseDown for these browsers.\n    on(d.scroller, \"contextmenu\", function (e) { return onContextMenu(cm, e); });\n    on(d.input.getField(), \"contextmenu\", function (e) {\n      if (!d.scroller.contains(e.target)) { onContextMenu(cm, e); }\n    });\n\n    // Used to suppress mouse event handling when a touch happens\n    var touchFinished, prevTouch = {end: 0};\n    function finishTouch() {\n      if (d.activeTouch) {\n        touchFinished = setTimeout(function () { return d.activeTouch = null; }, 1000);\n        prevTouch = d.activeTouch;\n        prevTouch.end = +new Date;\n      }\n    }\n    function isMouseLikeTouchEvent(e) {\n      if (e.touches.length != 1) { return false }\n      var touch = e.touches[0];\n      return touch.radiusX <= 1 && touch.radiusY <= 1\n    }\n    function farAway(touch, other) {\n      if (other.left == null) { return true }\n      var dx = other.left - touch.left, dy = other.top - touch.top;\n      return dx * dx + dy * dy > 20 * 20\n    }\n    on(d.scroller, \"touchstart\", function (e) {\n      if (!signalDOMEvent(cm, e) && !isMouseLikeTouchEvent(e) && !clickInGutter(cm, e)) {\n        d.input.ensurePolled();\n        clearTimeout(touchFinished);\n        var now = +new Date;\n        d.activeTouch = {start: now, moved: false,\n                         prev: now - prevTouch.end <= 300 ? prevTouch : null};\n        if (e.touches.length == 1) {\n          d.activeTouch.left = e.touches[0].pageX;\n          d.activeTouch.top = e.touches[0].pageY;\n        }\n      }\n    });\n    on(d.scroller, \"touchmove\", function () {\n      if (d.activeTouch) { d.activeTouch.moved = true; }\n    });\n    on(d.scroller, \"touchend\", function (e) {\n      var touch = d.activeTouch;\n      if (touch && !eventInWidget(d, e) && touch.left != null &&\n          !touch.moved && new Date - touch.start < 300) {\n        var pos = cm.coordsChar(d.activeTouch, \"page\"), range;\n        if (!touch.prev || farAway(touch, touch.prev)) // Single tap\n          { range = new Range(pos, pos); }\n        else if (!touch.prev.prev || farAway(touch, touch.prev.prev)) // Double tap\n          { range = cm.findWordAt(pos); }\n        else // Triple tap\n          { range = new Range(Pos(pos.line, 0), clipPos(cm.doc, Pos(pos.line + 1, 0))); }\n        cm.setSelection(range.anchor, range.head);\n        cm.focus();\n        e_preventDefault(e);\n      }\n      finishTouch();\n    });\n    on(d.scroller, \"touchcancel\", finishTouch);\n\n    // Sync scrolling between fake scrollbars and real scrollable\n    // area, ensure viewport is updated when scrolling.\n    on(d.scroller, \"scroll\", function () {\n      if (d.scroller.clientHeight) {\n        updateScrollTop(cm, d.scroller.scrollTop);\n        setScrollLeft(cm, d.scroller.scrollLeft, true);\n        signal(cm, \"scroll\", cm);\n      }\n    });\n\n    // Listen to wheel events in order to try and update the viewport on time.\n    on(d.scroller, \"mousewheel\", function (e) { return onScrollWheel(cm, e); });\n    on(d.scroller, \"DOMMouseScroll\", function (e) { return onScrollWheel(cm, e); });\n\n    // Prevent wrapper from ever scrolling\n    on(d.wrapper, \"scroll\", function () { return d.wrapper.scrollTop = d.wrapper.scrollLeft = 0; });\n\n    d.dragFunctions = {\n      enter: function (e) {if (!signalDOMEvent(cm, e)) { e_stop(e); }},\n      over: function (e) {if (!signalDOMEvent(cm, e)) { onDragOver(cm, e); e_stop(e); }},\n      start: function (e) { return onDragStart(cm, e); },\n      drop: operation(cm, onDrop),\n      leave: function (e) {if (!signalDOMEvent(cm, e)) { clearDragCursor(cm); }}\n    };\n\n    var inp = d.input.getField();\n    on(inp, \"keyup\", function (e) { return onKeyUp.call(cm, e); });\n    on(inp, \"keydown\", operation(cm, onKeyDown));\n    on(inp, \"keypress\", operation(cm, onKeyPress));\n    on(inp, \"focus\", function (e) { return onFocus(cm, e); });\n    on(inp, \"blur\", function (e) { return onBlur(cm, e); });\n  }\n\n  var initHooks = [];\n  CodeMirror.defineInitHook = function (f) { return initHooks.push(f); };\n\n  // Indent the given line. The how parameter can be \"smart\",\n  // \"add\"/null, \"subtract\", or \"prev\". When aggressive is false\n  // (typically set to true for forced single-line indents), empty\n  // lines are not indented, and places where the mode returns Pass\n  // are left alone.\n  function indentLine(cm, n, how, aggressive) {\n    var doc = cm.doc, state;\n    if (how == null) { how = \"add\"; }\n    if (how == \"smart\") {\n      // Fall back to \"prev\" when the mode doesn't have an indentation\n      // method.\n      if (!doc.mode.indent) { how = \"prev\"; }\n      else { state = getContextBefore(cm, n).state; }\n    }\n\n    var tabSize = cm.options.tabSize;\n    var line = getLine(doc, n), curSpace = countColumn(line.text, null, tabSize);\n    if (line.stateAfter) { line.stateAfter = null; }\n    var curSpaceString = line.text.match(/^\\s*/)[0], indentation;\n    if (!aggressive && !/\\S/.test(line.text)) {\n      indentation = 0;\n      how = \"not\";\n    } else if (how == \"smart\") {\n      indentation = doc.mode.indent(state, line.text.slice(curSpaceString.length), line.text);\n      if (indentation == Pass || indentation > 150) {\n        if (!aggressive) { return }\n        how = \"prev\";\n      }\n    }\n    if (how == \"prev\") {\n      if (n > doc.first) { indentation = countColumn(getLine(doc, n-1).text, null, tabSize); }\n      else { indentation = 0; }\n    } else if (how == \"add\") {\n      indentation = curSpace + cm.options.indentUnit;\n    } else if (how == \"subtract\") {\n      indentation = curSpace - cm.options.indentUnit;\n    } else if (typeof how == \"number\") {\n      indentation = curSpace + how;\n    }\n    indentation = Math.max(0, indentation);\n\n    var indentString = \"\", pos = 0;\n    if (cm.options.indentWithTabs)\n      { for (var i = Math.floor(indentation / tabSize); i; --i) {pos += tabSize; indentString += \"\\t\";} }\n    if (pos < indentation) { indentString += spaceStr(indentation - pos); }\n\n    if (indentString != curSpaceString) {\n      replaceRange(doc, indentString, Pos(n, 0), Pos(n, curSpaceString.length), \"+input\");\n      line.stateAfter = null;\n      return true\n    } else {\n      // Ensure that, if the cursor was in the whitespace at the start\n      // of the line, it is moved to the end of that space.\n      for (var i$1 = 0; i$1 < doc.sel.ranges.length; i$1++) {\n        var range = doc.sel.ranges[i$1];\n        if (range.head.line == n && range.head.ch < curSpaceString.length) {\n          var pos$1 = Pos(n, curSpaceString.length);\n          replaceOneSelection(doc, i$1, new Range(pos$1, pos$1));\n          break\n        }\n      }\n    }\n  }\n\n  // This will be set to a {lineWise: bool, text: [string]} object, so\n  // that, when pasting, we know what kind of selections the copied\n  // text was made out of.\n  var lastCopied = null;\n\n  function setLastCopied(newLastCopied) {\n    lastCopied = newLastCopied;\n  }\n\n  function applyTextInput(cm, inserted, deleted, sel, origin) {\n    var doc = cm.doc;\n    cm.display.shift = false;\n    if (!sel) { sel = doc.sel; }\n\n    var recent = +new Date - 200;\n    var paste = origin == \"paste\" || cm.state.pasteIncoming > recent;\n    var textLines = splitLinesAuto(inserted), multiPaste = null;\n    // When pasting N lines into N selections, insert one line per selection\n    if (paste && sel.ranges.length > 1) {\n      if (lastCopied && lastCopied.text.join(\"\\n\") == inserted) {\n        if (sel.ranges.length % lastCopied.text.length == 0) {\n          multiPaste = [];\n          for (var i = 0; i < lastCopied.text.length; i++)\n            { multiPaste.push(doc.splitLines(lastCopied.text[i])); }\n        }\n      } else if (textLines.length == sel.ranges.length && cm.options.pasteLinesPerSelection) {\n        multiPaste = map(textLines, function (l) { return [l]; });\n      }\n    }\n\n    var updateInput = cm.curOp.updateInput;\n    // Normal behavior is to insert the new text into every selection\n    for (var i$1 = sel.ranges.length - 1; i$1 >= 0; i$1--) {\n      var range = sel.ranges[i$1];\n      var from = range.from(), to = range.to();\n      if (range.empty()) {\n        if (deleted && deleted > 0) // Handle deletion\n          { from = Pos(from.line, from.ch - deleted); }\n        else if (cm.state.overwrite && !paste) // Handle overwrite\n          { to = Pos(to.line, Math.min(getLine(doc, to.line).text.length, to.ch + lst(textLines).length)); }\n        else if (paste && lastCopied && lastCopied.lineWise && lastCopied.text.join(\"\\n\") == textLines.join(\"\\n\"))\n          { from = to = Pos(from.line, 0); }\n      }\n      var changeEvent = {from: from, to: to, text: multiPaste ? multiPaste[i$1 % multiPaste.length] : textLines,\n                         origin: origin || (paste ? \"paste\" : cm.state.cutIncoming > recent ? \"cut\" : \"+input\")};\n      makeChange(cm.doc, changeEvent);\n      signalLater(cm, \"inputRead\", cm, changeEvent);\n    }\n    if (inserted && !paste)\n      { triggerElectric(cm, inserted); }\n\n    ensureCursorVisible(cm);\n    if (cm.curOp.updateInput < 2) { cm.curOp.updateInput = updateInput; }\n    cm.curOp.typing = true;\n    cm.state.pasteIncoming = cm.state.cutIncoming = -1;\n  }\n\n  function handlePaste(e, cm) {\n    var pasted = e.clipboardData && e.clipboardData.getData(\"Text\");\n    if (pasted) {\n      e.preventDefault();\n      if (!cm.isReadOnly() && !cm.options.disableInput && cm.hasFocus())\n        { runInOp(cm, function () { return applyTextInput(cm, pasted, 0, null, \"paste\"); }); }\n      return true\n    }\n  }\n\n  function triggerElectric(cm, inserted) {\n    // When an 'electric' character is inserted, immediately trigger a reindent\n    if (!cm.options.electricChars || !cm.options.smartIndent) { return }\n    var sel = cm.doc.sel;\n\n    for (var i = sel.ranges.length - 1; i >= 0; i--) {\n      var range = sel.ranges[i];\n      if (range.head.ch > 100 || (i && sel.ranges[i - 1].head.line == range.head.line)) { continue }\n      var mode = cm.getModeAt(range.head);\n      var indented = false;\n      if (mode.electricChars) {\n        for (var j = 0; j < mode.electricChars.length; j++)\n          { if (inserted.indexOf(mode.electricChars.charAt(j)) > -1) {\n            indented = indentLine(cm, range.head.line, \"smart\");\n            break\n          } }\n      } else if (mode.electricInput) {\n        if (mode.electricInput.test(getLine(cm.doc, range.head.line).text.slice(0, range.head.ch)))\n          { indented = indentLine(cm, range.head.line, \"smart\"); }\n      }\n      if (indented) { signalLater(cm, \"electricInput\", cm, range.head.line); }\n    }\n  }\n\n  function copyableRanges(cm) {\n    var text = [], ranges = [];\n    for (var i = 0; i < cm.doc.sel.ranges.length; i++) {\n      var line = cm.doc.sel.ranges[i].head.line;\n      var lineRange = {anchor: Pos(line, 0), head: Pos(line + 1, 0)};\n      ranges.push(lineRange);\n      text.push(cm.getRange(lineRange.anchor, lineRange.head));\n    }\n    return {text: text, ranges: ranges}\n  }\n\n  function disableBrowserMagic(field, spellcheck, autocorrect, autocapitalize) {\n    field.setAttribute(\"autocorrect\", autocorrect ? \"on\" : \"off\");\n    field.setAttribute(\"autocapitalize\", autocapitalize ? \"on\" : \"off\");\n    field.setAttribute(\"spellcheck\", !!spellcheck);\n  }\n\n  function hiddenTextarea() {\n    var te = elt(\"textarea\", null, null, \"position: absolute; bottom: -1em; padding: 0; width: 1px; height: 1em; min-height: 1em; outline: none\");\n    var div = elt(\"div\", [te], null, \"overflow: hidden; position: relative; width: 3px; height: 0px;\");\n    // The textarea is kept positioned near the cursor to prevent the\n    // fact that it'll be scrolled into view on input from scrolling\n    // our fake cursor out of view. On webkit, when wrap=off, paste is\n    // very slow. So make the area wide instead.\n    if (webkit) { te.style.width = \"1000px\"; }\n    else { te.setAttribute(\"wrap\", \"off\"); }\n    // If border: 0; -- iOS fails to open keyboard (issue #1287)\n    if (ios) { te.style.border = \"1px solid black\"; }\n    return div\n  }\n\n  // The publicly visible API. Note that methodOp(f) means\n  // 'wrap f in an operation, performed on its `this` parameter'.\n\n  // This is not the complete set of editor methods. Most of the\n  // methods defined on the Doc type are also injected into\n  // CodeMirror.prototype, for backwards compatibility and\n  // convenience.\n\n  function addEditorMethods(CodeMirror) {\n    var optionHandlers = CodeMirror.optionHandlers;\n\n    var helpers = CodeMirror.helpers = {};\n\n    CodeMirror.prototype = {\n      constructor: CodeMirror,\n      focus: function(){win(this).focus(); this.display.input.focus();},\n\n      setOption: function(option, value) {\n        var options = this.options, old = options[option];\n        if (options[option] == value && option != \"mode\") { return }\n        options[option] = value;\n        if (optionHandlers.hasOwnProperty(option))\n          { operation(this, optionHandlers[option])(this, value, old); }\n        signal(this, \"optionChange\", this, option);\n      },\n\n      getOption: function(option) {return this.options[option]},\n      getDoc: function() {return this.doc},\n\n      addKeyMap: function(map, bottom) {\n        this.state.keyMaps[bottom ? \"push\" : \"unshift\"](getKeyMap(map));\n      },\n      removeKeyMap: function(map) {\n        var maps = this.state.keyMaps;\n        for (var i = 0; i < maps.length; ++i)\n          { if (maps[i] == map || maps[i].name == map) {\n            maps.splice(i, 1);\n            return true\n          } }\n      },\n\n      addOverlay: methodOp(function(spec, options) {\n        var mode = spec.token ? spec : CodeMirror.getMode(this.options, spec);\n        if (mode.startState) { throw new Error(\"Overlays may not be stateful.\") }\n        insertSorted(this.state.overlays,\n                     {mode: mode, modeSpec: spec, opaque: options && options.opaque,\n                      priority: (options && options.priority) || 0},\n                     function (overlay) { return overlay.priority; });\n        this.state.modeGen++;\n        regChange(this);\n      }),\n      removeOverlay: methodOp(function(spec) {\n        var overlays = this.state.overlays;\n        for (var i = 0; i < overlays.length; ++i) {\n          var cur = overlays[i].modeSpec;\n          if (cur == spec || typeof spec == \"string\" && cur.name == spec) {\n            overlays.splice(i, 1);\n            this.state.modeGen++;\n            regChange(this);\n            return\n          }\n        }\n      }),\n\n      indentLine: methodOp(function(n, dir, aggressive) {\n        if (typeof dir != \"string\" && typeof dir != \"number\") {\n          if (dir == null) { dir = this.options.smartIndent ? \"smart\" : \"prev\"; }\n          else { dir = dir ? \"add\" : \"subtract\"; }\n        }\n        if (isLine(this.doc, n)) { indentLine(this, n, dir, aggressive); }\n      }),\n      indentSelection: methodOp(function(how) {\n        var ranges = this.doc.sel.ranges, end = -1;\n        for (var i = 0; i < ranges.length; i++) {\n          var range = ranges[i];\n          if (!range.empty()) {\n            var from = range.from(), to = range.to();\n            var start = Math.max(end, from.line);\n            end = Math.min(this.lastLine(), to.line - (to.ch ? 0 : 1)) + 1;\n            for (var j = start; j < end; ++j)\n              { indentLine(this, j, how); }\n            var newRanges = this.doc.sel.ranges;\n            if (from.ch == 0 && ranges.length == newRanges.length && newRanges[i].from().ch > 0)\n              { replaceOneSelection(this.doc, i, new Range(from, newRanges[i].to()), sel_dontScroll); }\n          } else if (range.head.line > end) {\n            indentLine(this, range.head.line, how, true);\n            end = range.head.line;\n            if (i == this.doc.sel.primIndex) { ensureCursorVisible(this); }\n          }\n        }\n      }),\n\n      // Fetch the parser token for a given character. Useful for hacks\n      // that want to inspect the mode state (say, for completion).\n      getTokenAt: function(pos, precise) {\n        return takeToken(this, pos, precise)\n      },\n\n      getLineTokens: function(line, precise) {\n        return takeToken(this, Pos(line), precise, true)\n      },\n\n      getTokenTypeAt: function(pos) {\n        pos = clipPos(this.doc, pos);\n        var styles = getLineStyles(this, getLine(this.doc, pos.line));\n        var before = 0, after = (styles.length - 1) / 2, ch = pos.ch;\n        var type;\n        if (ch == 0) { type = styles[2]; }\n        else { for (;;) {\n          var mid = (before + after) >> 1;\n          if ((mid ? styles[mid * 2 - 1] : 0) >= ch) { after = mid; }\n          else if (styles[mid * 2 + 1] < ch) { before = mid + 1; }\n          else { type = styles[mid * 2 + 2]; break }\n        } }\n        var cut = type ? type.indexOf(\"overlay \") : -1;\n        return cut < 0 ? type : cut == 0 ? null : type.slice(0, cut - 1)\n      },\n\n      getModeAt: function(pos) {\n        var mode = this.doc.mode;\n        if (!mode.innerMode) { return mode }\n        return CodeMirror.innerMode(mode, this.getTokenAt(pos).state).mode\n      },\n\n      getHelper: function(pos, type) {\n        return this.getHelpers(pos, type)[0]\n      },\n\n      getHelpers: function(pos, type) {\n        var found = [];\n        if (!helpers.hasOwnProperty(type)) { return found }\n        var help = helpers[type], mode = this.getModeAt(pos);\n        if (typeof mode[type] == \"string\") {\n          if (help[mode[type]]) { found.push(help[mode[type]]); }\n        } else if (mode[type]) {\n          for (var i = 0; i < mode[type].length; i++) {\n            var val = help[mode[type][i]];\n            if (val) { found.push(val); }\n          }\n        } else if (mode.helperType && help[mode.helperType]) {\n          found.push(help[mode.helperType]);\n        } else if (help[mode.name]) {\n          found.push(help[mode.name]);\n        }\n        for (var i$1 = 0; i$1 < help._global.length; i$1++) {\n          var cur = help._global[i$1];\n          if (cur.pred(mode, this) && indexOf(found, cur.val) == -1)\n            { found.push(cur.val); }\n        }\n        return found\n      },\n\n      getStateAfter: function(line, precise) {\n        var doc = this.doc;\n        line = clipLine(doc, line == null ? doc.first + doc.size - 1: line);\n        return getContextBefore(this, line + 1, precise).state\n      },\n\n      cursorCoords: function(start, mode) {\n        var pos, range = this.doc.sel.primary();\n        if (start == null) { pos = range.head; }\n        else if (typeof start == \"object\") { pos = clipPos(this.doc, start); }\n        else { pos = start ? range.from() : range.to(); }\n        return cursorCoords(this, pos, mode || \"page\")\n      },\n\n      charCoords: function(pos, mode) {\n        return charCoords(this, clipPos(this.doc, pos), mode || \"page\")\n      },\n\n      coordsChar: function(coords, mode) {\n        coords = fromCoordSystem(this, coords, mode || \"page\");\n        return coordsChar(this, coords.left, coords.top)\n      },\n\n      lineAtHeight: function(height, mode) {\n        height = fromCoordSystem(this, {top: height, left: 0}, mode || \"page\").top;\n        return lineAtHeight(this.doc, height + this.display.viewOffset)\n      },\n      heightAtLine: function(line, mode, includeWidgets) {\n        var end = false, lineObj;\n        if (typeof line == \"number\") {\n          var last = this.doc.first + this.doc.size - 1;\n          if (line < this.doc.first) { line = this.doc.first; }\n          else if (line > last) { line = last; end = true; }\n          lineObj = getLine(this.doc, line);\n        } else {\n          lineObj = line;\n        }\n        return intoCoordSystem(this, lineObj, {top: 0, left: 0}, mode || \"page\", includeWidgets || end).top +\n          (end ? this.doc.height - heightAtLine(lineObj) : 0)\n      },\n\n      defaultTextHeight: function() { return textHeight(this.display) },\n      defaultCharWidth: function() { return charWidth(this.display) },\n\n      getViewport: function() { return {from: this.display.viewFrom, to: this.display.viewTo}},\n\n      addWidget: function(pos, node, scroll, vert, horiz) {\n        var display = this.display;\n        pos = cursorCoords(this, clipPos(this.doc, pos));\n        var top = pos.bottom, left = pos.left;\n        node.style.position = \"absolute\";\n        node.setAttribute(\"cm-ignore-events\", \"true\");\n        this.display.input.setUneditable(node);\n        display.sizer.appendChild(node);\n        if (vert == \"over\") {\n          top = pos.top;\n        } else if (vert == \"above\" || vert == \"near\") {\n          var vspace = Math.max(display.wrapper.clientHeight, this.doc.height),\n          hspace = Math.max(display.sizer.clientWidth, display.lineSpace.clientWidth);\n          // Default to positioning above (if specified and possible); otherwise default to positioning below\n          if ((vert == 'above' || pos.bottom + node.offsetHeight > vspace) && pos.top > node.offsetHeight)\n            { top = pos.top - node.offsetHeight; }\n          else if (pos.bottom + node.offsetHeight <= vspace)\n            { top = pos.bottom; }\n          if (left + node.offsetWidth > hspace)\n            { left = hspace - node.offsetWidth; }\n        }\n        node.style.top = top + \"px\";\n        node.style.left = node.style.right = \"\";\n        if (horiz == \"right\") {\n          left = display.sizer.clientWidth - node.offsetWidth;\n          node.style.right = \"0px\";\n        } else {\n          if (horiz == \"left\") { left = 0; }\n          else if (horiz == \"middle\") { left = (display.sizer.clientWidth - node.offsetWidth) / 2; }\n          node.style.left = left + \"px\";\n        }\n        if (scroll)\n          { scrollIntoView(this, {left: left, top: top, right: left + node.offsetWidth, bottom: top + node.offsetHeight}); }\n      },\n\n      triggerOnKeyDown: methodOp(onKeyDown),\n      triggerOnKeyPress: methodOp(onKeyPress),\n      triggerOnKeyUp: onKeyUp,\n      triggerOnMouseDown: methodOp(onMouseDown),\n\n      execCommand: function(cmd) {\n        if (commands.hasOwnProperty(cmd))\n          { return commands[cmd].call(null, this) }\n      },\n\n      triggerElectric: methodOp(function(text) { triggerElectric(this, text); }),\n\n      findPosH: function(from, amount, unit, visually) {\n        var dir = 1;\n        if (amount < 0) { dir = -1; amount = -amount; }\n        var cur = clipPos(this.doc, from);\n        for (var i = 0; i < amount; ++i) {\n          cur = findPosH(this.doc, cur, dir, unit, visually);\n          if (cur.hitSide) { break }\n        }\n        return cur\n      },\n\n      moveH: methodOp(function(dir, unit) {\n        var this$1 = this;\n\n        this.extendSelectionsBy(function (range) {\n          if (this$1.display.shift || this$1.doc.extend || range.empty())\n            { return findPosH(this$1.doc, range.head, dir, unit, this$1.options.rtlMoveVisually) }\n          else\n            { return dir < 0 ? range.from() : range.to() }\n        }, sel_move);\n      }),\n\n      deleteH: methodOp(function(dir, unit) {\n        var sel = this.doc.sel, doc = this.doc;\n        if (sel.somethingSelected())\n          { doc.replaceSelection(\"\", null, \"+delete\"); }\n        else\n          { deleteNearSelection(this, function (range) {\n            var other = findPosH(doc, range.head, dir, unit, false);\n            return dir < 0 ? {from: other, to: range.head} : {from: range.head, to: other}\n          }); }\n      }),\n\n      findPosV: function(from, amount, unit, goalColumn) {\n        var dir = 1, x = goalColumn;\n        if (amount < 0) { dir = -1; amount = -amount; }\n        var cur = clipPos(this.doc, from);\n        for (var i = 0; i < amount; ++i) {\n          var coords = cursorCoords(this, cur, \"div\");\n          if (x == null) { x = coords.left; }\n          else { coords.left = x; }\n          cur = findPosV(this, coords, dir, unit);\n          if (cur.hitSide) { break }\n        }\n        return cur\n      },\n\n      moveV: methodOp(function(dir, unit) {\n        var this$1 = this;\n\n        var doc = this.doc, goals = [];\n        var collapse = !this.display.shift && !doc.extend && doc.sel.somethingSelected();\n        doc.extendSelectionsBy(function (range) {\n          if (collapse)\n            { return dir < 0 ? range.from() : range.to() }\n          var headPos = cursorCoords(this$1, range.head, \"div\");\n          if (range.goalColumn != null) { headPos.left = range.goalColumn; }\n          goals.push(headPos.left);\n          var pos = findPosV(this$1, headPos, dir, unit);\n          if (unit == \"page\" && range == doc.sel.primary())\n            { addToScrollTop(this$1, charCoords(this$1, pos, \"div\").top - headPos.top); }\n          return pos\n        }, sel_move);\n        if (goals.length) { for (var i = 0; i < doc.sel.ranges.length; i++)\n          { doc.sel.ranges[i].goalColumn = goals[i]; } }\n      }),\n\n      // Find the word at the given position (as returned by coordsChar).\n      findWordAt: function(pos) {\n        var doc = this.doc, line = getLine(doc, pos.line).text;\n        var start = pos.ch, end = pos.ch;\n        if (line) {\n          var helper = this.getHelper(pos, \"wordChars\");\n          if ((pos.sticky == \"before\" || end == line.length) && start) { --start; } else { ++end; }\n          var startChar = line.charAt(start);\n          var check = isWordChar(startChar, helper)\n            ? function (ch) { return isWordChar(ch, helper); }\n            : /\\s/.test(startChar) ? function (ch) { return /\\s/.test(ch); }\n            : function (ch) { return (!/\\s/.test(ch) && !isWordChar(ch)); };\n          while (start > 0 && check(line.charAt(start - 1))) { --start; }\n          while (end < line.length && check(line.charAt(end))) { ++end; }\n        }\n        return new Range(Pos(pos.line, start), Pos(pos.line, end))\n      },\n\n      toggleOverwrite: function(value) {\n        if (value != null && value == this.state.overwrite) { return }\n        if (this.state.overwrite = !this.state.overwrite)\n          { addClass(this.display.cursorDiv, \"CodeMirror-overwrite\"); }\n        else\n          { rmClass(this.display.cursorDiv, \"CodeMirror-overwrite\"); }\n\n        signal(this, \"overwriteToggle\", this, this.state.overwrite);\n      },\n      hasFocus: function() { return this.display.input.getField() == activeElt(root(this)) },\n      isReadOnly: function() { return !!(this.options.readOnly || this.doc.cantEdit) },\n\n      scrollTo: methodOp(function (x, y) { scrollToCoords(this, x, y); }),\n      getScrollInfo: function() {\n        var scroller = this.display.scroller;\n        return {left: scroller.scrollLeft, top: scroller.scrollTop,\n                height: scroller.scrollHeight - scrollGap(this) - this.display.barHeight,\n                width: scroller.scrollWidth - scrollGap(this) - this.display.barWidth,\n                clientHeight: displayHeight(this), clientWidth: displayWidth(this)}\n      },\n\n      scrollIntoView: methodOp(function(range, margin) {\n        if (range == null) {\n          range = {from: this.doc.sel.primary().head, to: null};\n          if (margin == null) { margin = this.options.cursorScrollMargin; }\n        } else if (typeof range == \"number\") {\n          range = {from: Pos(range, 0), to: null};\n        } else if (range.from == null) {\n          range = {from: range, to: null};\n        }\n        if (!range.to) { range.to = range.from; }\n        range.margin = margin || 0;\n\n        if (range.from.line != null) {\n          scrollToRange(this, range);\n        } else {\n          scrollToCoordsRange(this, range.from, range.to, range.margin);\n        }\n      }),\n\n      setSize: methodOp(function(width, height) {\n        var this$1 = this;\n\n        var interpret = function (val) { return typeof val == \"number\" || /^\\d+$/.test(String(val)) ? val + \"px\" : val; };\n        if (width != null) { this.display.wrapper.style.width = interpret(width); }\n        if (height != null) { this.display.wrapper.style.height = interpret(height); }\n        if (this.options.lineWrapping) { clearLineMeasurementCache(this); }\n        var lineNo = this.display.viewFrom;\n        this.doc.iter(lineNo, this.display.viewTo, function (line) {\n          if (line.widgets) { for (var i = 0; i < line.widgets.length; i++)\n            { if (line.widgets[i].noHScroll) { regLineChange(this$1, lineNo, \"widget\"); break } } }\n          ++lineNo;\n        });\n        this.curOp.forceUpdate = true;\n        signal(this, \"refresh\", this);\n      }),\n\n      operation: function(f){return runInOp(this, f)},\n      startOperation: function(){return startOperation(this)},\n      endOperation: function(){return endOperation(this)},\n\n      refresh: methodOp(function() {\n        var oldHeight = this.display.cachedTextHeight;\n        regChange(this);\n        this.curOp.forceUpdate = true;\n        clearCaches(this);\n        scrollToCoords(this, this.doc.scrollLeft, this.doc.scrollTop);\n        updateGutterSpace(this.display);\n        if (oldHeight == null || Math.abs(oldHeight - textHeight(this.display)) > .5 || this.options.lineWrapping)\n          { estimateLineHeights(this); }\n        signal(this, \"refresh\", this);\n      }),\n\n      swapDoc: methodOp(function(doc) {\n        var old = this.doc;\n        old.cm = null;\n        // Cancel the current text selection if any (#5821)\n        if (this.state.selectingText) { this.state.selectingText(); }\n        attachDoc(this, doc);\n        clearCaches(this);\n        this.display.input.reset();\n        scrollToCoords(this, doc.scrollLeft, doc.scrollTop);\n        this.curOp.forceScroll = true;\n        signalLater(this, \"swapDoc\", this, old);\n        return old\n      }),\n\n      phrase: function(phraseText) {\n        var phrases = this.options.phrases;\n        return phrases && Object.prototype.hasOwnProperty.call(phrases, phraseText) ? phrases[phraseText] : phraseText\n      },\n\n      getInputField: function(){return this.display.input.getField()},\n      getWrapperElement: function(){return this.display.wrapper},\n      getScrollerElement: function(){return this.display.scroller},\n      getGutterElement: function(){return this.display.gutters}\n    };\n    eventMixin(CodeMirror);\n\n    CodeMirror.registerHelper = function(type, name, value) {\n      if (!helpers.hasOwnProperty(type)) { helpers[type] = CodeMirror[type] = {_global: []}; }\n      helpers[type][name] = value;\n    };\n    CodeMirror.registerGlobalHelper = function(type, name, predicate, value) {\n      CodeMirror.registerHelper(type, name, value);\n      helpers[type]._global.push({pred: predicate, val: value});\n    };\n  }\n\n  // Used for horizontal relative motion. Dir is -1 or 1 (left or\n  // right), unit can be \"codepoint\", \"char\", \"column\" (like char, but\n  // doesn't cross line boundaries), \"word\" (across next word), or\n  // \"group\" (to the start of next group of word or\n  // non-word-non-whitespace chars). The visually param controls\n  // whether, in right-to-left text, direction 1 means to move towards\n  // the next index in the string, or towards the character to the right\n  // of the current position. The resulting position will have a\n  // hitSide=true property if it reached the end of the document.\n  function findPosH(doc, pos, dir, unit, visually) {\n    var oldPos = pos;\n    var origDir = dir;\n    var lineObj = getLine(doc, pos.line);\n    var lineDir = visually && doc.direction == \"rtl\" ? -dir : dir;\n    function findNextLine() {\n      var l = pos.line + lineDir;\n      if (l < doc.first || l >= doc.first + doc.size) { return false }\n      pos = new Pos(l, pos.ch, pos.sticky);\n      return lineObj = getLine(doc, l)\n    }\n    function moveOnce(boundToLine) {\n      var next;\n      if (unit == \"codepoint\") {\n        var ch = lineObj.text.charCodeAt(pos.ch + (dir > 0 ? 0 : -1));\n        if (isNaN(ch)) {\n          next = null;\n        } else {\n          var astral = dir > 0 ? ch >= 0xD800 && ch < 0xDC00 : ch >= 0xDC00 && ch < 0xDFFF;\n          next = new Pos(pos.line, Math.max(0, Math.min(lineObj.text.length, pos.ch + dir * (astral ? 2 : 1))), -dir);\n        }\n      } else if (visually) {\n        next = moveVisually(doc.cm, lineObj, pos, dir);\n      } else {\n        next = moveLogically(lineObj, pos, dir);\n      }\n      if (next == null) {\n        if (!boundToLine && findNextLine())\n          { pos = endOfLine(visually, doc.cm, lineObj, pos.line, lineDir); }\n        else\n          { return false }\n      } else {\n        pos = next;\n      }\n      return true\n    }\n\n    if (unit == \"char\" || unit == \"codepoint\") {\n      moveOnce();\n    } else if (unit == \"column\") {\n      moveOnce(true);\n    } else if (unit == \"word\" || unit == \"group\") {\n      var sawType = null, group = unit == \"group\";\n      var helper = doc.cm && doc.cm.getHelper(pos, \"wordChars\");\n      for (var first = true;; first = false) {\n        if (dir < 0 && !moveOnce(!first)) { break }\n        var cur = lineObj.text.charAt(pos.ch) || \"\\n\";\n        var type = isWordChar(cur, helper) ? \"w\"\n          : group && cur == \"\\n\" ? \"n\"\n          : !group || /\\s/.test(cur) ? null\n          : \"p\";\n        if (group && !first && !type) { type = \"s\"; }\n        if (sawType && sawType != type) {\n          if (dir < 0) {dir = 1; moveOnce(); pos.sticky = \"after\";}\n          break\n        }\n\n        if (type) { sawType = type; }\n        if (dir > 0 && !moveOnce(!first)) { break }\n      }\n    }\n    var result = skipAtomic(doc, pos, oldPos, origDir, true);\n    if (equalCursorPos(oldPos, result)) { result.hitSide = true; }\n    return result\n  }\n\n  // For relative vertical movement. Dir may be -1 or 1. Unit can be\n  // \"page\" or \"line\". The resulting position will have a hitSide=true\n  // property if it reached the end of the document.\n  function findPosV(cm, pos, dir, unit) {\n    var doc = cm.doc, x = pos.left, y;\n    if (unit == \"page\") {\n      var pageSize = Math.min(cm.display.wrapper.clientHeight, win(cm).innerHeight || doc(cm).documentElement.clientHeight);\n      var moveAmount = Math.max(pageSize - .5 * textHeight(cm.display), 3);\n      y = (dir > 0 ? pos.bottom : pos.top) + dir * moveAmount;\n\n    } else if (unit == \"line\") {\n      y = dir > 0 ? pos.bottom + 3 : pos.top - 3;\n    }\n    var target;\n    for (;;) {\n      target = coordsChar(cm, x, y);\n      if (!target.outside) { break }\n      if (dir < 0 ? y <= 0 : y >= doc.height) { target.hitSide = true; break }\n      y += dir * 5;\n    }\n    return target\n  }\n\n  // CONTENTEDITABLE INPUT STYLE\n\n  var ContentEditableInput = function(cm) {\n    this.cm = cm;\n    this.lastAnchorNode = this.lastAnchorOffset = this.lastFocusNode = this.lastFocusOffset = null;\n    this.polling = new Delayed();\n    this.composing = null;\n    this.gracePeriod = false;\n    this.readDOMTimeout = null;\n  };\n\n  ContentEditableInput.prototype.init = function (display) {\n      var this$1 = this;\n\n    var input = this, cm = input.cm;\n    var div = input.div = display.lineDiv;\n    div.contentEditable = true;\n    disableBrowserMagic(div, cm.options.spellcheck, cm.options.autocorrect, cm.options.autocapitalize);\n\n    function belongsToInput(e) {\n      for (var t = e.target; t; t = t.parentNode) {\n        if (t == div) { return true }\n        if (/\\bCodeMirror-(?:line)?widget\\b/.test(t.className)) { break }\n      }\n      return false\n    }\n\n    on(div, \"paste\", function (e) {\n      if (!belongsToInput(e) || signalDOMEvent(cm, e) || handlePaste(e, cm)) { return }\n      // IE doesn't fire input events, so we schedule a read for the pasted content in this way\n      if (ie_version <= 11) { setTimeout(operation(cm, function () { return this$1.updateFromDOM(); }), 20); }\n    });\n\n    on(div, \"compositionstart\", function (e) {\n      this$1.composing = {data: e.data, done: false};\n    });\n    on(div, \"compositionupdate\", function (e) {\n      if (!this$1.composing) { this$1.composing = {data: e.data, done: false}; }\n    });\n    on(div, \"compositionend\", function (e) {\n      if (this$1.composing) {\n        if (e.data != this$1.composing.data) { this$1.readFromDOMSoon(); }\n        this$1.composing.done = true;\n      }\n    });\n\n    on(div, \"touchstart\", function () { return input.forceCompositionEnd(); });\n\n    on(div, \"input\", function () {\n      if (!this$1.composing) { this$1.readFromDOMSoon(); }\n    });\n\n    function onCopyCut(e) {\n      if (!belongsToInput(e) || signalDOMEvent(cm, e)) { return }\n      if (cm.somethingSelected()) {\n        setLastCopied({lineWise: false, text: cm.getSelections()});\n        if (e.type == \"cut\") { cm.replaceSelection(\"\", null, \"cut\"); }\n      } else if (!cm.options.lineWiseCopyCut) {\n        return\n      } else {\n        var ranges = copyableRanges(cm);\n        setLastCopied({lineWise: true, text: ranges.text});\n        if (e.type == \"cut\") {\n          cm.operation(function () {\n            cm.setSelections(ranges.ranges, 0, sel_dontScroll);\n            cm.replaceSelection(\"\", null, \"cut\");\n          });\n        }\n      }\n      if (e.clipboardData) {\n        e.clipboardData.clearData();\n        var content = lastCopied.text.join(\"\\n\");\n        // iOS exposes the clipboard API, but seems to discard content inserted into it\n        e.clipboardData.setData(\"Text\", content);\n        if (e.clipboardData.getData(\"Text\") == content) {\n          e.preventDefault();\n          return\n        }\n      }\n      // Old-fashioned briefly-focus-a-textarea hack\n      var kludge = hiddenTextarea(), te = kludge.firstChild;\n      disableBrowserMagic(te);\n      cm.display.lineSpace.insertBefore(kludge, cm.display.lineSpace.firstChild);\n      te.value = lastCopied.text.join(\"\\n\");\n      var hadFocus = activeElt(rootNode(div));\n      selectInput(te);\n      setTimeout(function () {\n        cm.display.lineSpace.removeChild(kludge);\n        hadFocus.focus();\n        if (hadFocus == div) { input.showPrimarySelection(); }\n      }, 50);\n    }\n    on(div, \"copy\", onCopyCut);\n    on(div, \"cut\", onCopyCut);\n  };\n\n  ContentEditableInput.prototype.screenReaderLabelChanged = function (label) {\n    // Label for screenreaders, accessibility\n    if(label) {\n      this.div.setAttribute('aria-label', label);\n    } else {\n      this.div.removeAttribute('aria-label');\n    }\n  };\n\n  ContentEditableInput.prototype.prepareSelection = function () {\n    var result = prepareSelection(this.cm, false);\n    result.focus = activeElt(rootNode(this.div)) == this.div;\n    return result\n  };\n\n  ContentEditableInput.prototype.showSelection = function (info, takeFocus) {\n    if (!info || !this.cm.display.view.length) { return }\n    if (info.focus || takeFocus) { this.showPrimarySelection(); }\n    this.showMultipleSelections(info);\n  };\n\n  ContentEditableInput.prototype.getSelection = function () {\n    return this.cm.display.wrapper.ownerDocument.getSelection()\n  };\n\n  ContentEditableInput.prototype.showPrimarySelection = function () {\n    var sel = this.getSelection(), cm = this.cm, prim = cm.doc.sel.primary();\n    var from = prim.from(), to = prim.to();\n\n    if (cm.display.viewTo == cm.display.viewFrom || from.line >= cm.display.viewTo || to.line < cm.display.viewFrom) {\n      sel.removeAllRanges();\n      return\n    }\n\n    var curAnchor = domToPos(cm, sel.anchorNode, sel.anchorOffset);\n    var curFocus = domToPos(cm, sel.focusNode, sel.focusOffset);\n    if (curAnchor && !curAnchor.bad && curFocus && !curFocus.bad &&\n        cmp(minPos(curAnchor, curFocus), from) == 0 &&\n        cmp(maxPos(curAnchor, curFocus), to) == 0)\n      { return }\n\n    var view = cm.display.view;\n    var start = (from.line >= cm.display.viewFrom && posToDOM(cm, from)) ||\n        {node: view[0].measure.map[2], offset: 0};\n    var end = to.line < cm.display.viewTo && posToDOM(cm, to);\n    if (!end) {\n      var measure = view[view.length - 1].measure;\n      var map = measure.maps ? measure.maps[measure.maps.length - 1] : measure.map;\n      end = {node: map[map.length - 1], offset: map[map.length - 2] - map[map.length - 3]};\n    }\n\n    if (!start || !end) {\n      sel.removeAllRanges();\n      return\n    }\n\n    var old = sel.rangeCount && sel.getRangeAt(0), rng;\n    try { rng = range(start.node, start.offset, end.offset, end.node); }\n    catch(e) {} // Our model of the DOM might be outdated, in which case the range we try to set can be impossible\n    if (rng) {\n      if (!gecko && cm.state.focused) {\n        sel.collapse(start.node, start.offset);\n        if (!rng.collapsed) {\n          sel.removeAllRanges();\n          sel.addRange(rng);\n        }\n      } else {\n        sel.removeAllRanges();\n        sel.addRange(rng);\n      }\n      if (old && sel.anchorNode == null) { sel.addRange(old); }\n      else if (gecko) { this.startGracePeriod(); }\n    }\n    this.rememberSelection();\n  };\n\n  ContentEditableInput.prototype.startGracePeriod = function () {\n      var this$1 = this;\n\n    clearTimeout(this.gracePeriod);\n    this.gracePeriod = setTimeout(function () {\n      this$1.gracePeriod = false;\n      if (this$1.selectionChanged())\n        { this$1.cm.operation(function () { return this$1.cm.curOp.selectionChanged = true; }); }\n    }, 20);\n  };\n\n  ContentEditableInput.prototype.showMultipleSelections = function (info) {\n    removeChildrenAndAdd(this.cm.display.cursorDiv, info.cursors);\n    removeChildrenAndAdd(this.cm.display.selectionDiv, info.selection);\n  };\n\n  ContentEditableInput.prototype.rememberSelection = function () {\n    var sel = this.getSelection();\n    this.lastAnchorNode = sel.anchorNode; this.lastAnchorOffset = sel.anchorOffset;\n    this.lastFocusNode = sel.focusNode; this.lastFocusOffset = sel.focusOffset;\n  };\n\n  ContentEditableInput.prototype.selectionInEditor = function () {\n    var sel = this.getSelection();\n    if (!sel.rangeCount) { return false }\n    var node = sel.getRangeAt(0).commonAncestorContainer;\n    return contains(this.div, node)\n  };\n\n  ContentEditableInput.prototype.focus = function () {\n    if (this.cm.options.readOnly != \"nocursor\") {\n      if (!this.selectionInEditor() || activeElt(rootNode(this.div)) != this.div)\n        { this.showSelection(this.prepareSelection(), true); }\n      this.div.focus();\n    }\n  };\n  ContentEditableInput.prototype.blur = function () { this.div.blur(); };\n  ContentEditableInput.prototype.getField = function () { return this.div };\n\n  ContentEditableInput.prototype.supportsTouch = function () { return true };\n\n  ContentEditableInput.prototype.receivedFocus = function () {\n      var this$1 = this;\n\n    var input = this;\n    if (this.selectionInEditor())\n      { setTimeout(function () { return this$1.pollSelection(); }, 20); }\n    else\n      { runInOp(this.cm, function () { return input.cm.curOp.selectionChanged = true; }); }\n\n    function poll() {\n      if (input.cm.state.focused) {\n        input.pollSelection();\n        input.polling.set(input.cm.options.pollInterval, poll);\n      }\n    }\n    this.polling.set(this.cm.options.pollInterval, poll);\n  };\n\n  ContentEditableInput.prototype.selectionChanged = function () {\n    var sel = this.getSelection();\n    return sel.anchorNode != this.lastAnchorNode || sel.anchorOffset != this.lastAnchorOffset ||\n      sel.focusNode != this.lastFocusNode || sel.focusOffset != this.lastFocusOffset\n  };\n\n  ContentEditableInput.prototype.pollSelection = function () {\n    if (this.readDOMTimeout != null || this.gracePeriod || !this.selectionChanged()) { return }\n    var sel = this.getSelection(), cm = this.cm;\n    // On Android Chrome (version 56, at least), backspacing into an\n    // uneditable block element will put the cursor in that element,\n    // and then, because it's not editable, hide the virtual keyboard.\n    // Because Android doesn't allow us to actually detect backspace\n    // presses in a sane way, this code checks for when that happens\n    // and simulates a backspace press in this case.\n    if (android && chrome && this.cm.display.gutterSpecs.length && isInGutter(sel.anchorNode)) {\n      this.cm.triggerOnKeyDown({type: \"keydown\", keyCode: 8, preventDefault: Math.abs});\n      this.blur();\n      this.focus();\n      return\n    }\n    if (this.composing) { return }\n    this.rememberSelection();\n    var anchor = domToPos(cm, sel.anchorNode, sel.anchorOffset);\n    var head = domToPos(cm, sel.focusNode, sel.focusOffset);\n    if (anchor && head) { runInOp(cm, function () {\n      setSelection(cm.doc, simpleSelection(anchor, head), sel_dontScroll);\n      if (anchor.bad || head.bad) { cm.curOp.selectionChanged = true; }\n    }); }\n  };\n\n  ContentEditableInput.prototype.pollContent = function () {\n    if (this.readDOMTimeout != null) {\n      clearTimeout(this.readDOMTimeout);\n      this.readDOMTimeout = null;\n    }\n\n    var cm = this.cm, display = cm.display, sel = cm.doc.sel.primary();\n    var from = sel.from(), to = sel.to();\n    if (from.ch == 0 && from.line > cm.firstLine())\n      { from = Pos(from.line - 1, getLine(cm.doc, from.line - 1).length); }\n    if (to.ch == getLine(cm.doc, to.line).text.length && to.line < cm.lastLine())\n      { to = Pos(to.line + 1, 0); }\n    if (from.line < display.viewFrom || to.line > display.viewTo - 1) { return false }\n\n    var fromIndex, fromLine, fromNode;\n    if (from.line == display.viewFrom || (fromIndex = findViewIndex(cm, from.line)) == 0) {\n      fromLine = lineNo(display.view[0].line);\n      fromNode = display.view[0].node;\n    } else {\n      fromLine = lineNo(display.view[fromIndex].line);\n      fromNode = display.view[fromIndex - 1].node.nextSibling;\n    }\n    var toIndex = findViewIndex(cm, to.line);\n    var toLine, toNode;\n    if (toIndex == display.view.length - 1) {\n      toLine = display.viewTo - 1;\n      toNode = display.lineDiv.lastChild;\n    } else {\n      toLine = lineNo(display.view[toIndex + 1].line) - 1;\n      toNode = display.view[toIndex + 1].node.previousSibling;\n    }\n\n    if (!fromNode) { return false }\n    var newText = cm.doc.splitLines(domTextBetween(cm, fromNode, toNode, fromLine, toLine));\n    var oldText = getBetween(cm.doc, Pos(fromLine, 0), Pos(toLine, getLine(cm.doc, toLine).text.length));\n    while (newText.length > 1 && oldText.length > 1) {\n      if (lst(newText) == lst(oldText)) { newText.pop(); oldText.pop(); toLine--; }\n      else if (newText[0] == oldText[0]) { newText.shift(); oldText.shift(); fromLine++; }\n      else { break }\n    }\n\n    var cutFront = 0, cutEnd = 0;\n    var newTop = newText[0], oldTop = oldText[0], maxCutFront = Math.min(newTop.length, oldTop.length);\n    while (cutFront < maxCutFront && newTop.charCodeAt(cutFront) == oldTop.charCodeAt(cutFront))\n      { ++cutFront; }\n    var newBot = lst(newText), oldBot = lst(oldText);\n    var maxCutEnd = Math.min(newBot.length - (newText.length == 1 ? cutFront : 0),\n                             oldBot.length - (oldText.length == 1 ? cutFront : 0));\n    while (cutEnd < maxCutEnd &&\n           newBot.charCodeAt(newBot.length - cutEnd - 1) == oldBot.charCodeAt(oldBot.length - cutEnd - 1))\n      { ++cutEnd; }\n    // Try to move start of change to start of selection if ambiguous\n    if (newText.length == 1 && oldText.length == 1 && fromLine == from.line) {\n      while (cutFront && cutFront > from.ch &&\n             newBot.charCodeAt(newBot.length - cutEnd - 1) == oldBot.charCodeAt(oldBot.length - cutEnd - 1)) {\n        cutFront--;\n        cutEnd++;\n      }\n    }\n\n    newText[newText.length - 1] = newBot.slice(0, newBot.length - cutEnd).replace(/^\\u200b+/, \"\");\n    newText[0] = newText[0].slice(cutFront).replace(/\\u200b+$/, \"\");\n\n    var chFrom = Pos(fromLine, cutFront);\n    var chTo = Pos(toLine, oldText.length ? lst(oldText).length - cutEnd : 0);\n    if (newText.length > 1 || newText[0] || cmp(chFrom, chTo)) {\n      replaceRange(cm.doc, newText, chFrom, chTo, \"+input\");\n      return true\n    }\n  };\n\n  ContentEditableInput.prototype.ensurePolled = function () {\n    this.forceCompositionEnd();\n  };\n  ContentEditableInput.prototype.reset = function () {\n    this.forceCompositionEnd();\n  };\n  ContentEditableInput.prototype.forceCompositionEnd = function () {\n    if (!this.composing) { return }\n    clearTimeout(this.readDOMTimeout);\n    this.composing = null;\n    this.updateFromDOM();\n    this.div.blur();\n    this.div.focus();\n  };\n  ContentEditableInput.prototype.readFromDOMSoon = function () {\n      var this$1 = this;\n\n    if (this.readDOMTimeout != null) { return }\n    this.readDOMTimeout = setTimeout(function () {\n      this$1.readDOMTimeout = null;\n      if (this$1.composing) {\n        if (this$1.composing.done) { this$1.composing = null; }\n        else { return }\n      }\n      this$1.updateFromDOM();\n    }, 80);\n  };\n\n  ContentEditableInput.prototype.updateFromDOM = function () {\n      var this$1 = this;\n\n    if (this.cm.isReadOnly() || !this.pollContent())\n      { runInOp(this.cm, function () { return regChange(this$1.cm); }); }\n  };\n\n  ContentEditableInput.prototype.setUneditable = function (node) {\n    node.contentEditable = \"false\";\n  };\n\n  ContentEditableInput.prototype.onKeyPress = function (e) {\n    if (e.charCode == 0 || this.composing) { return }\n    e.preventDefault();\n    if (!this.cm.isReadOnly())\n      { operation(this.cm, applyTextInput)(this.cm, String.fromCharCode(e.charCode == null ? e.keyCode : e.charCode), 0); }\n  };\n\n  ContentEditableInput.prototype.readOnlyChanged = function (val) {\n    this.div.contentEditable = String(val != \"nocursor\");\n  };\n\n  ContentEditableInput.prototype.onContextMenu = function () {};\n  ContentEditableInput.prototype.resetPosition = function () {};\n\n  ContentEditableInput.prototype.needsContentAttribute = true;\n\n  function posToDOM(cm, pos) {\n    var view = findViewForLine(cm, pos.line);\n    if (!view || view.hidden) { return null }\n    var line = getLine(cm.doc, pos.line);\n    var info = mapFromLineView(view, line, pos.line);\n\n    var order = getOrder(line, cm.doc.direction), side = \"left\";\n    if (order) {\n      var partPos = getBidiPartAt(order, pos.ch);\n      side = partPos % 2 ? \"right\" : \"left\";\n    }\n    var result = nodeAndOffsetInLineMap(info.map, pos.ch, side);\n    result.offset = result.collapse == \"right\" ? result.end : result.start;\n    return result\n  }\n\n  function isInGutter(node) {\n    for (var scan = node; scan; scan = scan.parentNode)\n      { if (/CodeMirror-gutter-wrapper/.test(scan.className)) { return true } }\n    return false\n  }\n\n  function badPos(pos, bad) { if (bad) { pos.bad = true; } return pos }\n\n  function domTextBetween(cm, from, to, fromLine, toLine) {\n    var text = \"\", closing = false, lineSep = cm.doc.lineSeparator(), extraLinebreak = false;\n    function recognizeMarker(id) { return function (marker) { return marker.id == id; } }\n    function close() {\n      if (closing) {\n        text += lineSep;\n        if (extraLinebreak) { text += lineSep; }\n        closing = extraLinebreak = false;\n      }\n    }\n    function addText(str) {\n      if (str) {\n        close();\n        text += str;\n      }\n    }\n    function walk(node) {\n      if (node.nodeType == 1) {\n        var cmText = node.getAttribute(\"cm-text\");\n        if (cmText) {\n          addText(cmText);\n          return\n        }\n        var markerID = node.getAttribute(\"cm-marker\"), range;\n        if (markerID) {\n          var found = cm.findMarks(Pos(fromLine, 0), Pos(toLine + 1, 0), recognizeMarker(+markerID));\n          if (found.length && (range = found[0].find(0)))\n            { addText(getBetween(cm.doc, range.from, range.to).join(lineSep)); }\n          return\n        }\n        if (node.getAttribute(\"contenteditable\") == \"false\") { return }\n        var isBlock = /^(pre|div|p|li|table|br)$/i.test(node.nodeName);\n        if (!/^br$/i.test(node.nodeName) && node.textContent.length == 0) { return }\n\n        if (isBlock) { close(); }\n        for (var i = 0; i < node.childNodes.length; i++)\n          { walk(node.childNodes[i]); }\n\n        if (/^(pre|p)$/i.test(node.nodeName)) { extraLinebreak = true; }\n        if (isBlock) { closing = true; }\n      } else if (node.nodeType == 3) {\n        addText(node.nodeValue.replace(/\\u200b/g, \"\").replace(/\\u00a0/g, \" \"));\n      }\n    }\n    for (;;) {\n      walk(from);\n      if (from == to) { break }\n      from = from.nextSibling;\n      extraLinebreak = false;\n    }\n    return text\n  }\n\n  function domToPos(cm, node, offset) {\n    var lineNode;\n    if (node == cm.display.lineDiv) {\n      lineNode = cm.display.lineDiv.childNodes[offset];\n      if (!lineNode) { return badPos(cm.clipPos(Pos(cm.display.viewTo - 1)), true) }\n      node = null; offset = 0;\n    } else {\n      for (lineNode = node;; lineNode = lineNode.parentNode) {\n        if (!lineNode || lineNode == cm.display.lineDiv) { return null }\n        if (lineNode.parentNode && lineNode.parentNode == cm.display.lineDiv) { break }\n      }\n    }\n    for (var i = 0; i < cm.display.view.length; i++) {\n      var lineView = cm.display.view[i];\n      if (lineView.node == lineNode)\n        { return locateNodeInLineView(lineView, node, offset) }\n    }\n  }\n\n  function locateNodeInLineView(lineView, node, offset) {\n    var wrapper = lineView.text.firstChild, bad = false;\n    if (!node || !contains(wrapper, node)) { return badPos(Pos(lineNo(lineView.line), 0), true) }\n    if (node == wrapper) {\n      bad = true;\n      node = wrapper.childNodes[offset];\n      offset = 0;\n      if (!node) {\n        var line = lineView.rest ? lst(lineView.rest) : lineView.line;\n        return badPos(Pos(lineNo(line), line.text.length), bad)\n      }\n    }\n\n    var textNode = node.nodeType == 3 ? node : null, topNode = node;\n    if (!textNode && node.childNodes.length == 1 && node.firstChild.nodeType == 3) {\n      textNode = node.firstChild;\n      if (offset) { offset = textNode.nodeValue.length; }\n    }\n    while (topNode.parentNode != wrapper) { topNode = topNode.parentNode; }\n    var measure = lineView.measure, maps = measure.maps;\n\n    function find(textNode, topNode, offset) {\n      for (var i = -1; i < (maps ? maps.length : 0); i++) {\n        var map = i < 0 ? measure.map : maps[i];\n        for (var j = 0; j < map.length; j += 3) {\n          var curNode = map[j + 2];\n          if (curNode == textNode || curNode == topNode) {\n            var line = lineNo(i < 0 ? lineView.line : lineView.rest[i]);\n            var ch = map[j] + offset;\n            if (offset < 0 || curNode != textNode) { ch = map[j + (offset ? 1 : 0)]; }\n            return Pos(line, ch)\n          }\n        }\n      }\n    }\n    var found = find(textNode, topNode, offset);\n    if (found) { return badPos(found, bad) }\n\n    // FIXME this is all really shaky. might handle the few cases it needs to handle, but likely to cause problems\n    for (var after = topNode.nextSibling, dist = textNode ? textNode.nodeValue.length - offset : 0; after; after = after.nextSibling) {\n      found = find(after, after.firstChild, 0);\n      if (found)\n        { return badPos(Pos(found.line, found.ch - dist), bad) }\n      else\n        { dist += after.textContent.length; }\n    }\n    for (var before = topNode.previousSibling, dist$1 = offset; before; before = before.previousSibling) {\n      found = find(before, before.firstChild, -1);\n      if (found)\n        { return badPos(Pos(found.line, found.ch + dist$1), bad) }\n      else\n        { dist$1 += before.textContent.length; }\n    }\n  }\n\n  // TEXTAREA INPUT STYLE\n\n  var TextareaInput = function(cm) {\n    this.cm = cm;\n    // See input.poll and input.reset\n    this.prevInput = \"\";\n\n    // Flag that indicates whether we expect input to appear real soon\n    // now (after some event like 'keypress' or 'input') and are\n    // polling intensively.\n    this.pollingFast = false;\n    // Self-resetting timeout for the poller\n    this.polling = new Delayed();\n    // Used to work around IE issue with selection being forgotten when focus moves away from textarea\n    this.hasSelection = false;\n    this.composing = null;\n    this.resetting = false;\n  };\n\n  TextareaInput.prototype.init = function (display) {\n      var this$1 = this;\n\n    var input = this, cm = this.cm;\n    this.createField(display);\n    var te = this.textarea;\n\n    display.wrapper.insertBefore(this.wrapper, display.wrapper.firstChild);\n\n    // Needed to hide big blue blinking cursor on Mobile Safari (doesn't seem to work in iOS 8 anymore)\n    if (ios) { te.style.width = \"0px\"; }\n\n    on(te, \"input\", function () {\n      if (ie && ie_version >= 9 && this$1.hasSelection) { this$1.hasSelection = null; }\n      input.poll();\n    });\n\n    on(te, \"paste\", function (e) {\n      if (signalDOMEvent(cm, e) || handlePaste(e, cm)) { return }\n\n      cm.state.pasteIncoming = +new Date;\n      input.fastPoll();\n    });\n\n    function prepareCopyCut(e) {\n      if (signalDOMEvent(cm, e)) { return }\n      if (cm.somethingSelected()) {\n        setLastCopied({lineWise: false, text: cm.getSelections()});\n      } else if (!cm.options.lineWiseCopyCut) {\n        return\n      } else {\n        var ranges = copyableRanges(cm);\n        setLastCopied({lineWise: true, text: ranges.text});\n        if (e.type == \"cut\") {\n          cm.setSelections(ranges.ranges, null, sel_dontScroll);\n        } else {\n          input.prevInput = \"\";\n          te.value = ranges.text.join(\"\\n\");\n          selectInput(te);\n        }\n      }\n      if (e.type == \"cut\") { cm.state.cutIncoming = +new Date; }\n    }\n    on(te, \"cut\", prepareCopyCut);\n    on(te, \"copy\", prepareCopyCut);\n\n    on(display.scroller, \"paste\", function (e) {\n      if (eventInWidget(display, e) || signalDOMEvent(cm, e)) { return }\n      if (!te.dispatchEvent) {\n        cm.state.pasteIncoming = +new Date;\n        input.focus();\n        return\n      }\n\n      // Pass the `paste` event to the textarea so it's handled by its event listener.\n      var event = new Event(\"paste\");\n      event.clipboardData = e.clipboardData;\n      te.dispatchEvent(event);\n    });\n\n    // Prevent normal selection in the editor (we handle our own)\n    on(display.lineSpace, \"selectstart\", function (e) {\n      if (!eventInWidget(display, e)) { e_preventDefault(e); }\n    });\n\n    on(te, \"compositionstart\", function () {\n      var start = cm.getCursor(\"from\");\n      if (input.composing) { input.composing.range.clear(); }\n      input.composing = {\n        start: start,\n        range: cm.markText(start, cm.getCursor(\"to\"), {className: \"CodeMirror-composing\"})\n      };\n    });\n    on(te, \"compositionend\", function () {\n      if (input.composing) {\n        input.poll();\n        input.composing.range.clear();\n        input.composing = null;\n      }\n    });\n  };\n\n  TextareaInput.prototype.createField = function (_display) {\n    // Wraps and hides input textarea\n    this.wrapper = hiddenTextarea();\n    // The semihidden textarea that is focused when the editor is\n    // focused, and receives input.\n    this.textarea = this.wrapper.firstChild;\n    var opts = this.cm.options;\n    disableBrowserMagic(this.textarea, opts.spellcheck, opts.autocorrect, opts.autocapitalize);\n  };\n\n  TextareaInput.prototype.screenReaderLabelChanged = function (label) {\n    // Label for screenreaders, accessibility\n    if(label) {\n      this.textarea.setAttribute('aria-label', label);\n    } else {\n      this.textarea.removeAttribute('aria-label');\n    }\n  };\n\n  TextareaInput.prototype.prepareSelection = function () {\n    // Redraw the selection and/or cursor\n    var cm = this.cm, display = cm.display, doc = cm.doc;\n    var result = prepareSelection(cm);\n\n    // Move the hidden textarea near the cursor to prevent scrolling artifacts\n    if (cm.options.moveInputWithCursor) {\n      var headPos = cursorCoords(cm, doc.sel.primary().head, \"div\");\n      var wrapOff = display.wrapper.getBoundingClientRect(), lineOff = display.lineDiv.getBoundingClientRect();\n      result.teTop = Math.max(0, Math.min(display.wrapper.clientHeight - 10,\n                                          headPos.top + lineOff.top - wrapOff.top));\n      result.teLeft = Math.max(0, Math.min(display.wrapper.clientWidth - 10,\n                                           headPos.left + lineOff.left - wrapOff.left));\n    }\n\n    return result\n  };\n\n  TextareaInput.prototype.showSelection = function (drawn) {\n    var cm = this.cm, display = cm.display;\n    removeChildrenAndAdd(display.cursorDiv, drawn.cursors);\n    removeChildrenAndAdd(display.selectionDiv, drawn.selection);\n    if (drawn.teTop != null) {\n      this.wrapper.style.top = drawn.teTop + \"px\";\n      this.wrapper.style.left = drawn.teLeft + \"px\";\n    }\n  };\n\n  // Reset the input to correspond to the selection (or to be empty,\n  // when not typing and nothing is selected)\n  TextareaInput.prototype.reset = function (typing) {\n    if (this.contextMenuPending || this.composing && typing) { return }\n    var cm = this.cm;\n    this.resetting = true;\n    if (cm.somethingSelected()) {\n      this.prevInput = \"\";\n      var content = cm.getSelection();\n      this.textarea.value = content;\n      if (cm.state.focused) { selectInput(this.textarea); }\n      if (ie && ie_version >= 9) { this.hasSelection = content; }\n    } else if (!typing) {\n      this.prevInput = this.textarea.value = \"\";\n      if (ie && ie_version >= 9) { this.hasSelection = null; }\n    }\n    this.resetting = false;\n  };\n\n  TextareaInput.prototype.getField = function () { return this.textarea };\n\n  TextareaInput.prototype.supportsTouch = function () { return false };\n\n  TextareaInput.prototype.focus = function () {\n    if (this.cm.options.readOnly != \"nocursor\" && (!mobile || activeElt(rootNode(this.textarea)) != this.textarea)) {\n      try { this.textarea.focus(); }\n      catch (e) {} // IE8 will throw if the textarea is display: none or not in DOM\n    }\n  };\n\n  TextareaInput.prototype.blur = function () { this.textarea.blur(); };\n\n  TextareaInput.prototype.resetPosition = function () {\n    this.wrapper.style.top = this.wrapper.style.left = 0;\n  };\n\n  TextareaInput.prototype.receivedFocus = function () { this.slowPoll(); };\n\n  // Poll for input changes, using the normal rate of polling. This\n  // runs as long as the editor is focused.\n  TextareaInput.prototype.slowPoll = function () {\n      var this$1 = this;\n\n    if (this.pollingFast) { return }\n    this.polling.set(this.cm.options.pollInterval, function () {\n      this$1.poll();\n      if (this$1.cm.state.focused) { this$1.slowPoll(); }\n    });\n  };\n\n  // When an event has just come in that is likely to add or change\n  // something in the input textarea, we poll faster, to ensure that\n  // the change appears on the screen quickly.\n  TextareaInput.prototype.fastPoll = function () {\n    var missed = false, input = this;\n    input.pollingFast = true;\n    function p() {\n      var changed = input.poll();\n      if (!changed && !missed) {missed = true; input.polling.set(60, p);}\n      else {input.pollingFast = false; input.slowPoll();}\n    }\n    input.polling.set(20, p);\n  };\n\n  // Read input from the textarea, and update the document to match.\n  // When something is selected, it is present in the textarea, and\n  // selected (unless it is huge, in which case a placeholder is\n  // used). When nothing is selected, the cursor sits after previously\n  // seen text (can be empty), which is stored in prevInput (we must\n  // not reset the textarea when typing, because that breaks IME).\n  TextareaInput.prototype.poll = function () {\n      var this$1 = this;\n\n    var cm = this.cm, input = this.textarea, prevInput = this.prevInput;\n    // Since this is called a *lot*, try to bail out as cheaply as\n    // possible when it is clear that nothing happened. hasSelection\n    // will be the case when there is a lot of text in the textarea,\n    // in which case reading its value would be expensive.\n    if (this.contextMenuPending || this.resetting || !cm.state.focused ||\n        (hasSelection(input) && !prevInput && !this.composing) ||\n        cm.isReadOnly() || cm.options.disableInput || cm.state.keySeq)\n      { return false }\n\n    var text = input.value;\n    // If nothing changed, bail.\n    if (text == prevInput && !cm.somethingSelected()) { return false }\n    // Work around nonsensical selection resetting in IE9/10, and\n    // inexplicable appearance of private area unicode characters on\n    // some key combos in Mac (#2689).\n    if (ie && ie_version >= 9 && this.hasSelection === text ||\n        mac && /[\\uf700-\\uf7ff]/.test(text)) {\n      cm.display.input.reset();\n      return false\n    }\n\n    if (cm.doc.sel == cm.display.selForContextMenu) {\n      var first = text.charCodeAt(0);\n      if (first == 0x200b && !prevInput) { prevInput = \"\\u200b\"; }\n      if (first == 0x21da) { this.reset(); return this.cm.execCommand(\"undo\") }\n    }\n    // Find the part of the input that is actually new\n    var same = 0, l = Math.min(prevInput.length, text.length);\n    while (same < l && prevInput.charCodeAt(same) == text.charCodeAt(same)) { ++same; }\n\n    runInOp(cm, function () {\n      applyTextInput(cm, text.slice(same), prevInput.length - same,\n                     null, this$1.composing ? \"*compose\" : null);\n\n      // Don't leave long text in the textarea, since it makes further polling slow\n      if (text.length > 1000 || text.indexOf(\"\\n\") > -1) { input.value = this$1.prevInput = \"\"; }\n      else { this$1.prevInput = text; }\n\n      if (this$1.composing) {\n        this$1.composing.range.clear();\n        this$1.composing.range = cm.markText(this$1.composing.start, cm.getCursor(\"to\"),\n                                           {className: \"CodeMirror-composing\"});\n      }\n    });\n    return true\n  };\n\n  TextareaInput.prototype.ensurePolled = function () {\n    if (this.pollingFast && this.poll()) { this.pollingFast = false; }\n  };\n\n  TextareaInput.prototype.onKeyPress = function () {\n    if (ie && ie_version >= 9) { this.hasSelection = null; }\n    this.fastPoll();\n  };\n\n  TextareaInput.prototype.onContextMenu = function (e) {\n    var input = this, cm = input.cm, display = cm.display, te = input.textarea;\n    if (input.contextMenuPending) { input.contextMenuPending(); }\n    var pos = posFromMouse(cm, e), scrollPos = display.scroller.scrollTop;\n    if (!pos || presto) { return } // Opera is difficult.\n\n    // Reset the current text selection only if the click is done outside of the selection\n    // and 'resetSelectionOnContextMenu' option is true.\n    var reset = cm.options.resetSelectionOnContextMenu;\n    if (reset && cm.doc.sel.contains(pos) == -1)\n      { operation(cm, setSelection)(cm.doc, simpleSelection(pos), sel_dontScroll); }\n\n    var oldCSS = te.style.cssText, oldWrapperCSS = input.wrapper.style.cssText;\n    var wrapperBox = input.wrapper.offsetParent.getBoundingClientRect();\n    input.wrapper.style.cssText = \"position: static\";\n    te.style.cssText = \"position: absolute; width: 30px; height: 30px;\\n      top: \" + (e.clientY - wrapperBox.top - 5) + \"px; left: \" + (e.clientX - wrapperBox.left - 5) + \"px;\\n      z-index: 1000; background: \" + (ie ? \"rgba(255, 255, 255, .05)\" : \"transparent\") + \";\\n      outline: none; border-width: 0; outline: none; overflow: hidden; opacity: .05; filter: alpha(opacity=5);\";\n    var oldScrollY;\n    if (webkit) { oldScrollY = te.ownerDocument.defaultView.scrollY; } // Work around Chrome issue (#2712)\n    display.input.focus();\n    if (webkit) { te.ownerDocument.defaultView.scrollTo(null, oldScrollY); }\n    display.input.reset();\n    // Adds \"Select all\" to context menu in FF\n    if (!cm.somethingSelected()) { te.value = input.prevInput = \" \"; }\n    input.contextMenuPending = rehide;\n    display.selForContextMenu = cm.doc.sel;\n    clearTimeout(display.detectingSelectAll);\n\n    // Select-all will be greyed out if there's nothing to select, so\n    // this adds a zero-width space so that we can later check whether\n    // it got selected.\n    function prepareSelectAllHack() {\n      if (te.selectionStart != null) {\n        var selected = cm.somethingSelected();\n        var extval = \"\\u200b\" + (selected ? te.value : \"\");\n        te.value = \"\\u21da\"; // Used to catch context-menu undo\n        te.value = extval;\n        input.prevInput = selected ? \"\" : \"\\u200b\";\n        te.selectionStart = 1; te.selectionEnd = extval.length;\n        // Re-set this, in case some other handler touched the\n        // selection in the meantime.\n        display.selForContextMenu = cm.doc.sel;\n      }\n    }\n    function rehide() {\n      if (input.contextMenuPending != rehide) { return }\n      input.contextMenuPending = false;\n      input.wrapper.style.cssText = oldWrapperCSS;\n      te.style.cssText = oldCSS;\n      if (ie && ie_version < 9) { display.scrollbars.setScrollTop(display.scroller.scrollTop = scrollPos); }\n\n      // Try to detect the user choosing select-all\n      if (te.selectionStart != null) {\n        if (!ie || (ie && ie_version < 9)) { prepareSelectAllHack(); }\n        var i = 0, poll = function () {\n          if (display.selForContextMenu == cm.doc.sel && te.selectionStart == 0 &&\n              te.selectionEnd > 0 && input.prevInput == \"\\u200b\") {\n            operation(cm, selectAll)(cm);\n          } else if (i++ < 10) {\n            display.detectingSelectAll = setTimeout(poll, 500);\n          } else {\n            display.selForContextMenu = null;\n            display.input.reset();\n          }\n        };\n        display.detectingSelectAll = setTimeout(poll, 200);\n      }\n    }\n\n    if (ie && ie_version >= 9) { prepareSelectAllHack(); }\n    if (captureRightClick) {\n      e_stop(e);\n      var mouseup = function () {\n        off(window, \"mouseup\", mouseup);\n        setTimeout(rehide, 20);\n      };\n      on(window, \"mouseup\", mouseup);\n    } else {\n      setTimeout(rehide, 50);\n    }\n  };\n\n  TextareaInput.prototype.readOnlyChanged = function (val) {\n    if (!val) { this.reset(); }\n    this.textarea.disabled = val == \"nocursor\";\n    this.textarea.readOnly = !!val;\n  };\n\n  TextareaInput.prototype.setUneditable = function () {};\n\n  TextareaInput.prototype.needsContentAttribute = false;\n\n  function fromTextArea(textarea, options) {\n    options = options ? copyObj(options) : {};\n    options.value = textarea.value;\n    if (!options.tabindex && textarea.tabIndex)\n      { options.tabindex = textarea.tabIndex; }\n    if (!options.placeholder && textarea.placeholder)\n      { options.placeholder = textarea.placeholder; }\n    // Set autofocus to true if this textarea is focused, or if it has\n    // autofocus and no other element is focused.\n    if (options.autofocus == null) {\n      var hasFocus = activeElt(rootNode(textarea));\n      options.autofocus = hasFocus == textarea ||\n        textarea.getAttribute(\"autofocus\") != null && hasFocus == document.body;\n    }\n\n    function save() {textarea.value = cm.getValue();}\n\n    var realSubmit;\n    if (textarea.form) {\n      on(textarea.form, \"submit\", save);\n      // Deplorable hack to make the submit method do the right thing.\n      if (!options.leaveSubmitMethodAlone) {\n        var form = textarea.form;\n        realSubmit = form.submit;\n        try {\n          var wrappedSubmit = form.submit = function () {\n            save();\n            form.submit = realSubmit;\n            form.submit();\n            form.submit = wrappedSubmit;\n          };\n        } catch(e) {}\n      }\n    }\n\n    options.finishInit = function (cm) {\n      cm.save = save;\n      cm.getTextArea = function () { return textarea; };\n      cm.toTextArea = function () {\n        cm.toTextArea = isNaN; // Prevent this from being ran twice\n        save();\n        textarea.parentNode.removeChild(cm.getWrapperElement());\n        textarea.style.display = \"\";\n        if (textarea.form) {\n          off(textarea.form, \"submit\", save);\n          if (!options.leaveSubmitMethodAlone && typeof textarea.form.submit == \"function\")\n            { textarea.form.submit = realSubmit; }\n        }\n      };\n    };\n\n    textarea.style.display = \"none\";\n    var cm = CodeMirror(function (node) { return textarea.parentNode.insertBefore(node, textarea.nextSibling); },\n      options);\n    return cm\n  }\n\n  function addLegacyProps(CodeMirror) {\n    CodeMirror.off = off;\n    CodeMirror.on = on;\n    CodeMirror.wheelEventPixels = wheelEventPixels;\n    CodeMirror.Doc = Doc;\n    CodeMirror.splitLines = splitLinesAuto;\n    CodeMirror.countColumn = countColumn;\n    CodeMirror.findColumn = findColumn;\n    CodeMirror.isWordChar = isWordCharBasic;\n    CodeMirror.Pass = Pass;\n    CodeMirror.signal = signal;\n    CodeMirror.Line = Line;\n    CodeMirror.changeEnd = changeEnd;\n    CodeMirror.scrollbarModel = scrollbarModel;\n    CodeMirror.Pos = Pos;\n    CodeMirror.cmpPos = cmp;\n    CodeMirror.modes = modes;\n    CodeMirror.mimeModes = mimeModes;\n    CodeMirror.resolveMode = resolveMode;\n    CodeMirror.getMode = getMode;\n    CodeMirror.modeExtensions = modeExtensions;\n    CodeMirror.extendMode = extendMode;\n    CodeMirror.copyState = copyState;\n    CodeMirror.startState = startState;\n    CodeMirror.innerMode = innerMode;\n    CodeMirror.commands = commands;\n    CodeMirror.keyMap = keyMap;\n    CodeMirror.keyName = keyName;\n    CodeMirror.isModifierKey = isModifierKey;\n    CodeMirror.lookupKey = lookupKey;\n    CodeMirror.normalizeKeyMap = normalizeKeyMap;\n    CodeMirror.StringStream = StringStream;\n    CodeMirror.SharedTextMarker = SharedTextMarker;\n    CodeMirror.TextMarker = TextMarker;\n    CodeMirror.LineWidget = LineWidget;\n    CodeMirror.e_preventDefault = e_preventDefault;\n    CodeMirror.e_stopPropagation = e_stopPropagation;\n    CodeMirror.e_stop = e_stop;\n    CodeMirror.addClass = addClass;\n    CodeMirror.contains = contains;\n    CodeMirror.rmClass = rmClass;\n    CodeMirror.keyNames = keyNames;\n  }\n\n  // EDITOR CONSTRUCTOR\n\n  defineOptions(CodeMirror);\n\n  addEditorMethods(CodeMirror);\n\n  // Set up methods on CodeMirror's prototype to redirect to the editor's document.\n  var dontDelegate = \"iter insert remove copy getEditor constructor\".split(\" \");\n  for (var prop in Doc.prototype) { if (Doc.prototype.hasOwnProperty(prop) && indexOf(dontDelegate, prop) < 0)\n    { CodeMirror.prototype[prop] = (function(method) {\n      return function() {return method.apply(this.doc, arguments)}\n    })(Doc.prototype[prop]); } }\n\n  eventMixin(Doc);\n  CodeMirror.inputStyles = {\"textarea\": TextareaInput, \"contenteditable\": ContentEditableInput};\n\n  // Extra arguments are stored as the mode's dependencies, which is\n  // used by (legacy) mechanisms like loadmode.js to automatically\n  // load a mode. (Preferred mechanism is the require/define calls.)\n  CodeMirror.defineMode = function(name/*, mode, */) {\n    if (!CodeMirror.defaults.mode && name != \"null\") { CodeMirror.defaults.mode = name; }\n    defineMode.apply(this, arguments);\n  };\n\n  CodeMirror.defineMIME = defineMIME;\n\n  // Minimal default mode.\n  CodeMirror.defineMode(\"null\", function () { return ({token: function (stream) { return stream.skipToEnd(); }}); });\n  CodeMirror.defineMIME(\"text/plain\", \"null\");\n\n  // EXTENSIONS\n\n  CodeMirror.defineExtension = function (name, func) {\n    CodeMirror.prototype[name] = func;\n  };\n  CodeMirror.defineDocExtension = function (name, func) {\n    Doc.prototype[name] = func;\n  };\n\n  CodeMirror.fromTextArea = fromTextArea;\n\n  addLegacyProps(CodeMirror);\n\n  CodeMirror.version = \"5.65.16\";\n\n  return CodeMirror;\n\n})));\n\n\n//# sourceURL=webpack://semanticfinder/./node_modules/codemirror/lib/codemirror.js?");

/***/ }),

/***/ "./node_modules/codemirror/mode/javascript/javascript.js":
/*!***************************************************************!*\
  !*** ./node_modules/codemirror/mode/javascript/javascript.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, __unused_webpack_exports, __webpack_require__) => {

eval("// CodeMirror, copyright (c) by Marijn Haverbeke and others\n// Distributed under an MIT license: https://codemirror.net/5/LICENSE\n\n(function(mod) {\n  if (true) // CommonJS\n    mod(__webpack_require__(/*! ../../lib/codemirror */ \"./node_modules/codemirror/lib/codemirror.js\"));\n  else {}\n})(function(CodeMirror) {\n\"use strict\";\n\nCodeMirror.defineMode(\"javascript\", function(config, parserConfig) {\n  var indentUnit = config.indentUnit;\n  var statementIndent = parserConfig.statementIndent;\n  var jsonldMode = parserConfig.jsonld;\n  var jsonMode = parserConfig.json || jsonldMode;\n  var trackScope = parserConfig.trackScope !== false\n  var isTS = parserConfig.typescript;\n  var wordRE = parserConfig.wordCharacters || /[\\w$\\xa1-\\uffff]/;\n\n  // Tokenizer\n\n  var keywords = function(){\n    function kw(type) {return {type: type, style: \"keyword\"};}\n    var A = kw(\"keyword a\"), B = kw(\"keyword b\"), C = kw(\"keyword c\"), D = kw(\"keyword d\");\n    var operator = kw(\"operator\"), atom = {type: \"atom\", style: \"atom\"};\n\n    return {\n      \"if\": kw(\"if\"), \"while\": A, \"with\": A, \"else\": B, \"do\": B, \"try\": B, \"finally\": B,\n      \"return\": D, \"break\": D, \"continue\": D, \"new\": kw(\"new\"), \"delete\": C, \"void\": C, \"throw\": C,\n      \"debugger\": kw(\"debugger\"), \"var\": kw(\"var\"), \"const\": kw(\"var\"), \"let\": kw(\"var\"),\n      \"function\": kw(\"function\"), \"catch\": kw(\"catch\"),\n      \"for\": kw(\"for\"), \"switch\": kw(\"switch\"), \"case\": kw(\"case\"), \"default\": kw(\"default\"),\n      \"in\": operator, \"typeof\": operator, \"instanceof\": operator,\n      \"true\": atom, \"false\": atom, \"null\": atom, \"undefined\": atom, \"NaN\": atom, \"Infinity\": atom,\n      \"this\": kw(\"this\"), \"class\": kw(\"class\"), \"super\": kw(\"atom\"),\n      \"yield\": C, \"export\": kw(\"export\"), \"import\": kw(\"import\"), \"extends\": C,\n      \"await\": C\n    };\n  }();\n\n  var isOperatorChar = /[+\\-*&%=<>!?|~^@]/;\n  var isJsonldKeyword = /^@(context|id|value|language|type|container|list|set|reverse|index|base|vocab|graph)\"/;\n\n  function readRegexp(stream) {\n    var escaped = false, next, inSet = false;\n    while ((next = stream.next()) != null) {\n      if (!escaped) {\n        if (next == \"/\" && !inSet) return;\n        if (next == \"[\") inSet = true;\n        else if (inSet && next == \"]\") inSet = false;\n      }\n      escaped = !escaped && next == \"\\\\\";\n    }\n  }\n\n  // Used as scratch variables to communicate multiple values without\n  // consing up tons of objects.\n  var type, content;\n  function ret(tp, style, cont) {\n    type = tp; content = cont;\n    return style;\n  }\n  function tokenBase(stream, state) {\n    var ch = stream.next();\n    if (ch == '\"' || ch == \"'\") {\n      state.tokenize = tokenString(ch);\n      return state.tokenize(stream, state);\n    } else if (ch == \".\" && stream.match(/^\\d[\\d_]*(?:[eE][+\\-]?[\\d_]+)?/)) {\n      return ret(\"number\", \"number\");\n    } else if (ch == \".\" && stream.match(\"..\")) {\n      return ret(\"spread\", \"meta\");\n    } else if (/[\\[\\]{}\\(\\),;\\:\\.]/.test(ch)) {\n      return ret(ch);\n    } else if (ch == \"=\" && stream.eat(\">\")) {\n      return ret(\"=>\", \"operator\");\n    } else if (ch == \"0\" && stream.match(/^(?:x[\\dA-Fa-f_]+|o[0-7_]+|b[01_]+)n?/)) {\n      return ret(\"number\", \"number\");\n    } else if (/\\d/.test(ch)) {\n      stream.match(/^[\\d_]*(?:n|(?:\\.[\\d_]*)?(?:[eE][+\\-]?[\\d_]+)?)?/);\n      return ret(\"number\", \"number\");\n    } else if (ch == \"/\") {\n      if (stream.eat(\"*\")) {\n        state.tokenize = tokenComment;\n        return tokenComment(stream, state);\n      } else if (stream.eat(\"/\")) {\n        stream.skipToEnd();\n        return ret(\"comment\", \"comment\");\n      } else if (expressionAllowed(stream, state, 1)) {\n        readRegexp(stream);\n        stream.match(/^\\b(([gimyus])(?![gimyus]*\\2))+\\b/);\n        return ret(\"regexp\", \"string-2\");\n      } else {\n        stream.eat(\"=\");\n        return ret(\"operator\", \"operator\", stream.current());\n      }\n    } else if (ch == \"`\") {\n      state.tokenize = tokenQuasi;\n      return tokenQuasi(stream, state);\n    } else if (ch == \"#\" && stream.peek() == \"!\") {\n      stream.skipToEnd();\n      return ret(\"meta\", \"meta\");\n    } else if (ch == \"#\" && stream.eatWhile(wordRE)) {\n      return ret(\"variable\", \"property\")\n    } else if (ch == \"<\" && stream.match(\"!--\") ||\n               (ch == \"-\" && stream.match(\"->\") && !/\\S/.test(stream.string.slice(0, stream.start)))) {\n      stream.skipToEnd()\n      return ret(\"comment\", \"comment\")\n    } else if (isOperatorChar.test(ch)) {\n      if (ch != \">\" || !state.lexical || state.lexical.type != \">\") {\n        if (stream.eat(\"=\")) {\n          if (ch == \"!\" || ch == \"=\") stream.eat(\"=\")\n        } else if (/[<>*+\\-|&?]/.test(ch)) {\n          stream.eat(ch)\n          if (ch == \">\") stream.eat(ch)\n        }\n      }\n      if (ch == \"?\" && stream.eat(\".\")) return ret(\".\")\n      return ret(\"operator\", \"operator\", stream.current());\n    } else if (wordRE.test(ch)) {\n      stream.eatWhile(wordRE);\n      var word = stream.current()\n      if (state.lastType != \".\") {\n        if (keywords.propertyIsEnumerable(word)) {\n          var kw = keywords[word]\n          return ret(kw.type, kw.style, word)\n        }\n        if (word == \"async\" && stream.match(/^(\\s|\\/\\*([^*]|\\*(?!\\/))*?\\*\\/)*[\\[\\(\\w]/, false))\n          return ret(\"async\", \"keyword\", word)\n      }\n      return ret(\"variable\", \"variable\", word)\n    }\n  }\n\n  function tokenString(quote) {\n    return function(stream, state) {\n      var escaped = false, next;\n      if (jsonldMode && stream.peek() == \"@\" && stream.match(isJsonldKeyword)){\n        state.tokenize = tokenBase;\n        return ret(\"jsonld-keyword\", \"meta\");\n      }\n      while ((next = stream.next()) != null) {\n        if (next == quote && !escaped) break;\n        escaped = !escaped && next == \"\\\\\";\n      }\n      if (!escaped) state.tokenize = tokenBase;\n      return ret(\"string\", \"string\");\n    };\n  }\n\n  function tokenComment(stream, state) {\n    var maybeEnd = false, ch;\n    while (ch = stream.next()) {\n      if (ch == \"/\" && maybeEnd) {\n        state.tokenize = tokenBase;\n        break;\n      }\n      maybeEnd = (ch == \"*\");\n    }\n    return ret(\"comment\", \"comment\");\n  }\n\n  function tokenQuasi(stream, state) {\n    var escaped = false, next;\n    while ((next = stream.next()) != null) {\n      if (!escaped && (next == \"`\" || next == \"$\" && stream.eat(\"{\"))) {\n        state.tokenize = tokenBase;\n        break;\n      }\n      escaped = !escaped && next == \"\\\\\";\n    }\n    return ret(\"quasi\", \"string-2\", stream.current());\n  }\n\n  var brackets = \"([{}])\";\n  // This is a crude lookahead trick to try and notice that we're\n  // parsing the argument patterns for a fat-arrow function before we\n  // actually hit the arrow token. It only works if the arrow is on\n  // the same line as the arguments and there's no strange noise\n  // (comments) in between. Fallback is to only notice when we hit the\n  // arrow, and not declare the arguments as locals for the arrow\n  // body.\n  function findFatArrow(stream, state) {\n    if (state.fatArrowAt) state.fatArrowAt = null;\n    var arrow = stream.string.indexOf(\"=>\", stream.start);\n    if (arrow < 0) return;\n\n    if (isTS) { // Try to skip TypeScript return type declarations after the arguments\n      var m = /:\\s*(?:\\w+(?:<[^>]*>|\\[\\])?|\\{[^}]*\\})\\s*$/.exec(stream.string.slice(stream.start, arrow))\n      if (m) arrow = m.index\n    }\n\n    var depth = 0, sawSomething = false;\n    for (var pos = arrow - 1; pos >= 0; --pos) {\n      var ch = stream.string.charAt(pos);\n      var bracket = brackets.indexOf(ch);\n      if (bracket >= 0 && bracket < 3) {\n        if (!depth) { ++pos; break; }\n        if (--depth == 0) { if (ch == \"(\") sawSomething = true; break; }\n      } else if (bracket >= 3 && bracket < 6) {\n        ++depth;\n      } else if (wordRE.test(ch)) {\n        sawSomething = true;\n      } else if (/[\"'\\/`]/.test(ch)) {\n        for (;; --pos) {\n          if (pos == 0) return\n          var next = stream.string.charAt(pos - 1)\n          if (next == ch && stream.string.charAt(pos - 2) != \"\\\\\") { pos--; break }\n        }\n      } else if (sawSomething && !depth) {\n        ++pos;\n        break;\n      }\n    }\n    if (sawSomething && !depth) state.fatArrowAt = pos;\n  }\n\n  // Parser\n\n  var atomicTypes = {\"atom\": true, \"number\": true, \"variable\": true, \"string\": true,\n                     \"regexp\": true, \"this\": true, \"import\": true, \"jsonld-keyword\": true};\n\n  function JSLexical(indented, column, type, align, prev, info) {\n    this.indented = indented;\n    this.column = column;\n    this.type = type;\n    this.prev = prev;\n    this.info = info;\n    if (align != null) this.align = align;\n  }\n\n  function inScope(state, varname) {\n    if (!trackScope) return false\n    for (var v = state.localVars; v; v = v.next)\n      if (v.name == varname) return true;\n    for (var cx = state.context; cx; cx = cx.prev) {\n      for (var v = cx.vars; v; v = v.next)\n        if (v.name == varname) return true;\n    }\n  }\n\n  function parseJS(state, style, type, content, stream) {\n    var cc = state.cc;\n    // Communicate our context to the combinators.\n    // (Less wasteful than consing up a hundred closures on every call.)\n    cx.state = state; cx.stream = stream; cx.marked = null, cx.cc = cc; cx.style = style;\n\n    if (!state.lexical.hasOwnProperty(\"align\"))\n      state.lexical.align = true;\n\n    while(true) {\n      var combinator = cc.length ? cc.pop() : jsonMode ? expression : statement;\n      if (combinator(type, content)) {\n        while(cc.length && cc[cc.length - 1].lex)\n          cc.pop()();\n        if (cx.marked) return cx.marked;\n        if (type == \"variable\" && inScope(state, content)) return \"variable-2\";\n        return style;\n      }\n    }\n  }\n\n  // Combinator utils\n\n  var cx = {state: null, column: null, marked: null, cc: null};\n  function pass() {\n    for (var i = arguments.length - 1; i >= 0; i--) cx.cc.push(arguments[i]);\n  }\n  function cont() {\n    pass.apply(null, arguments);\n    return true;\n  }\n  function inList(name, list) {\n    for (var v = list; v; v = v.next) if (v.name == name) return true\n    return false;\n  }\n  function register(varname) {\n    var state = cx.state;\n    cx.marked = \"def\";\n    if (!trackScope) return\n    if (state.context) {\n      if (state.lexical.info == \"var\" && state.context && state.context.block) {\n        // FIXME function decls are also not block scoped\n        var newContext = registerVarScoped(varname, state.context)\n        if (newContext != null) {\n          state.context = newContext\n          return\n        }\n      } else if (!inList(varname, state.localVars)) {\n        state.localVars = new Var(varname, state.localVars)\n        return\n      }\n    }\n    // Fall through means this is global\n    if (parserConfig.globalVars && !inList(varname, state.globalVars))\n      state.globalVars = new Var(varname, state.globalVars)\n  }\n  function registerVarScoped(varname, context) {\n    if (!context) {\n      return null\n    } else if (context.block) {\n      var inner = registerVarScoped(varname, context.prev)\n      if (!inner) return null\n      if (inner == context.prev) return context\n      return new Context(inner, context.vars, true)\n    } else if (inList(varname, context.vars)) {\n      return context\n    } else {\n      return new Context(context.prev, new Var(varname, context.vars), false)\n    }\n  }\n\n  function isModifier(name) {\n    return name == \"public\" || name == \"private\" || name == \"protected\" || name == \"abstract\" || name == \"readonly\"\n  }\n\n  // Combinators\n\n  function Context(prev, vars, block) { this.prev = prev; this.vars = vars; this.block = block }\n  function Var(name, next) { this.name = name; this.next = next }\n\n  var defaultVars = new Var(\"this\", new Var(\"arguments\", null))\n  function pushcontext() {\n    cx.state.context = new Context(cx.state.context, cx.state.localVars, false)\n    cx.state.localVars = defaultVars\n  }\n  function pushblockcontext() {\n    cx.state.context = new Context(cx.state.context, cx.state.localVars, true)\n    cx.state.localVars = null\n  }\n  pushcontext.lex = pushblockcontext.lex = true\n  function popcontext() {\n    cx.state.localVars = cx.state.context.vars\n    cx.state.context = cx.state.context.prev\n  }\n  popcontext.lex = true\n  function pushlex(type, info) {\n    var result = function() {\n      var state = cx.state, indent = state.indented;\n      if (state.lexical.type == \"stat\") indent = state.lexical.indented;\n      else for (var outer = state.lexical; outer && outer.type == \")\" && outer.align; outer = outer.prev)\n        indent = outer.indented;\n      state.lexical = new JSLexical(indent, cx.stream.column(), type, null, state.lexical, info);\n    };\n    result.lex = true;\n    return result;\n  }\n  function poplex() {\n    var state = cx.state;\n    if (state.lexical.prev) {\n      if (state.lexical.type == \")\")\n        state.indented = state.lexical.indented;\n      state.lexical = state.lexical.prev;\n    }\n  }\n  poplex.lex = true;\n\n  function expect(wanted) {\n    function exp(type) {\n      if (type == wanted) return cont();\n      else if (wanted == \";\" || type == \"}\" || type == \")\" || type == \"]\") return pass();\n      else return cont(exp);\n    };\n    return exp;\n  }\n\n  function statement(type, value) {\n    if (type == \"var\") return cont(pushlex(\"vardef\", value), vardef, expect(\";\"), poplex);\n    if (type == \"keyword a\") return cont(pushlex(\"form\"), parenExpr, statement, poplex);\n    if (type == \"keyword b\") return cont(pushlex(\"form\"), statement, poplex);\n    if (type == \"keyword d\") return cx.stream.match(/^\\s*$/, false) ? cont() : cont(pushlex(\"stat\"), maybeexpression, expect(\";\"), poplex);\n    if (type == \"debugger\") return cont(expect(\";\"));\n    if (type == \"{\") return cont(pushlex(\"}\"), pushblockcontext, block, poplex, popcontext);\n    if (type == \";\") return cont();\n    if (type == \"if\") {\n      if (cx.state.lexical.info == \"else\" && cx.state.cc[cx.state.cc.length - 1] == poplex)\n        cx.state.cc.pop()();\n      return cont(pushlex(\"form\"), parenExpr, statement, poplex, maybeelse);\n    }\n    if (type == \"function\") return cont(functiondef);\n    if (type == \"for\") return cont(pushlex(\"form\"), pushblockcontext, forspec, statement, popcontext, poplex);\n    if (type == \"class\" || (isTS && value == \"interface\")) {\n      cx.marked = \"keyword\"\n      return cont(pushlex(\"form\", type == \"class\" ? type : value), className, poplex)\n    }\n    if (type == \"variable\") {\n      if (isTS && value == \"declare\") {\n        cx.marked = \"keyword\"\n        return cont(statement)\n      } else if (isTS && (value == \"module\" || value == \"enum\" || value == \"type\") && cx.stream.match(/^\\s*\\w/, false)) {\n        cx.marked = \"keyword\"\n        if (value == \"enum\") return cont(enumdef);\n        else if (value == \"type\") return cont(typename, expect(\"operator\"), typeexpr, expect(\";\"));\n        else return cont(pushlex(\"form\"), pattern, expect(\"{\"), pushlex(\"}\"), block, poplex, poplex)\n      } else if (isTS && value == \"namespace\") {\n        cx.marked = \"keyword\"\n        return cont(pushlex(\"form\"), expression, statement, poplex)\n      } else if (isTS && value == \"abstract\") {\n        cx.marked = \"keyword\"\n        return cont(statement)\n      } else {\n        return cont(pushlex(\"stat\"), maybelabel);\n      }\n    }\n    if (type == \"switch\") return cont(pushlex(\"form\"), parenExpr, expect(\"{\"), pushlex(\"}\", \"switch\"), pushblockcontext,\n                                      block, poplex, poplex, popcontext);\n    if (type == \"case\") return cont(expression, expect(\":\"));\n    if (type == \"default\") return cont(expect(\":\"));\n    if (type == \"catch\") return cont(pushlex(\"form\"), pushcontext, maybeCatchBinding, statement, poplex, popcontext);\n    if (type == \"export\") return cont(pushlex(\"stat\"), afterExport, poplex);\n    if (type == \"import\") return cont(pushlex(\"stat\"), afterImport, poplex);\n    if (type == \"async\") return cont(statement)\n    if (value == \"@\") return cont(expression, statement)\n    return pass(pushlex(\"stat\"), expression, expect(\";\"), poplex);\n  }\n  function maybeCatchBinding(type) {\n    if (type == \"(\") return cont(funarg, expect(\")\"))\n  }\n  function expression(type, value) {\n    return expressionInner(type, value, false);\n  }\n  function expressionNoComma(type, value) {\n    return expressionInner(type, value, true);\n  }\n  function parenExpr(type) {\n    if (type != \"(\") return pass()\n    return cont(pushlex(\")\"), maybeexpression, expect(\")\"), poplex)\n  }\n  function expressionInner(type, value, noComma) {\n    if (cx.state.fatArrowAt == cx.stream.start) {\n      var body = noComma ? arrowBodyNoComma : arrowBody;\n      if (type == \"(\") return cont(pushcontext, pushlex(\")\"), commasep(funarg, \")\"), poplex, expect(\"=>\"), body, popcontext);\n      else if (type == \"variable\") return pass(pushcontext, pattern, expect(\"=>\"), body, popcontext);\n    }\n\n    var maybeop = noComma ? maybeoperatorNoComma : maybeoperatorComma;\n    if (atomicTypes.hasOwnProperty(type)) return cont(maybeop);\n    if (type == \"function\") return cont(functiondef, maybeop);\n    if (type == \"class\" || (isTS && value == \"interface\")) { cx.marked = \"keyword\"; return cont(pushlex(\"form\"), classExpression, poplex); }\n    if (type == \"keyword c\" || type == \"async\") return cont(noComma ? expressionNoComma : expression);\n    if (type == \"(\") return cont(pushlex(\")\"), maybeexpression, expect(\")\"), poplex, maybeop);\n    if (type == \"operator\" || type == \"spread\") return cont(noComma ? expressionNoComma : expression);\n    if (type == \"[\") return cont(pushlex(\"]\"), arrayLiteral, poplex, maybeop);\n    if (type == \"{\") return contCommasep(objprop, \"}\", null, maybeop);\n    if (type == \"quasi\") return pass(quasi, maybeop);\n    if (type == \"new\") return cont(maybeTarget(noComma));\n    return cont();\n  }\n  function maybeexpression(type) {\n    if (type.match(/[;\\}\\)\\],]/)) return pass();\n    return pass(expression);\n  }\n\n  function maybeoperatorComma(type, value) {\n    if (type == \",\") return cont(maybeexpression);\n    return maybeoperatorNoComma(type, value, false);\n  }\n  function maybeoperatorNoComma(type, value, noComma) {\n    var me = noComma == false ? maybeoperatorComma : maybeoperatorNoComma;\n    var expr = noComma == false ? expression : expressionNoComma;\n    if (type == \"=>\") return cont(pushcontext, noComma ? arrowBodyNoComma : arrowBody, popcontext);\n    if (type == \"operator\") {\n      if (/\\+\\+|--/.test(value) || isTS && value == \"!\") return cont(me);\n      if (isTS && value == \"<\" && cx.stream.match(/^([^<>]|<[^<>]*>)*>\\s*\\(/, false))\n        return cont(pushlex(\">\"), commasep(typeexpr, \">\"), poplex, me);\n      if (value == \"?\") return cont(expression, expect(\":\"), expr);\n      return cont(expr);\n    }\n    if (type == \"quasi\") { return pass(quasi, me); }\n    if (type == \";\") return;\n    if (type == \"(\") return contCommasep(expressionNoComma, \")\", \"call\", me);\n    if (type == \".\") return cont(property, me);\n    if (type == \"[\") return cont(pushlex(\"]\"), maybeexpression, expect(\"]\"), poplex, me);\n    if (isTS && value == \"as\") { cx.marked = \"keyword\"; return cont(typeexpr, me) }\n    if (type == \"regexp\") {\n      cx.state.lastType = cx.marked = \"operator\"\n      cx.stream.backUp(cx.stream.pos - cx.stream.start - 1)\n      return cont(expr)\n    }\n  }\n  function quasi(type, value) {\n    if (type != \"quasi\") return pass();\n    if (value.slice(value.length - 2) != \"${\") return cont(quasi);\n    return cont(maybeexpression, continueQuasi);\n  }\n  function continueQuasi(type) {\n    if (type == \"}\") {\n      cx.marked = \"string-2\";\n      cx.state.tokenize = tokenQuasi;\n      return cont(quasi);\n    }\n  }\n  function arrowBody(type) {\n    findFatArrow(cx.stream, cx.state);\n    return pass(type == \"{\" ? statement : expression);\n  }\n  function arrowBodyNoComma(type) {\n    findFatArrow(cx.stream, cx.state);\n    return pass(type == \"{\" ? statement : expressionNoComma);\n  }\n  function maybeTarget(noComma) {\n    return function(type) {\n      if (type == \".\") return cont(noComma ? targetNoComma : target);\n      else if (type == \"variable\" && isTS) return cont(maybeTypeArgs, noComma ? maybeoperatorNoComma : maybeoperatorComma)\n      else return pass(noComma ? expressionNoComma : expression);\n    };\n  }\n  function target(_, value) {\n    if (value == \"target\") { cx.marked = \"keyword\"; return cont(maybeoperatorComma); }\n  }\n  function targetNoComma(_, value) {\n    if (value == \"target\") { cx.marked = \"keyword\"; return cont(maybeoperatorNoComma); }\n  }\n  function maybelabel(type) {\n    if (type == \":\") return cont(poplex, statement);\n    return pass(maybeoperatorComma, expect(\";\"), poplex);\n  }\n  function property(type) {\n    if (type == \"variable\") {cx.marked = \"property\"; return cont();}\n  }\n  function objprop(type, value) {\n    if (type == \"async\") {\n      cx.marked = \"property\";\n      return cont(objprop);\n    } else if (type == \"variable\" || cx.style == \"keyword\") {\n      cx.marked = \"property\";\n      if (value == \"get\" || value == \"set\") return cont(getterSetter);\n      var m // Work around fat-arrow-detection complication for detecting typescript typed arrow params\n      if (isTS && cx.state.fatArrowAt == cx.stream.start && (m = cx.stream.match(/^\\s*:\\s*/, false)))\n        cx.state.fatArrowAt = cx.stream.pos + m[0].length\n      return cont(afterprop);\n    } else if (type == \"number\" || type == \"string\") {\n      cx.marked = jsonldMode ? \"property\" : (cx.style + \" property\");\n      return cont(afterprop);\n    } else if (type == \"jsonld-keyword\") {\n      return cont(afterprop);\n    } else if (isTS && isModifier(value)) {\n      cx.marked = \"keyword\"\n      return cont(objprop)\n    } else if (type == \"[\") {\n      return cont(expression, maybetype, expect(\"]\"), afterprop);\n    } else if (type == \"spread\") {\n      return cont(expressionNoComma, afterprop);\n    } else if (value == \"*\") {\n      cx.marked = \"keyword\";\n      return cont(objprop);\n    } else if (type == \":\") {\n      return pass(afterprop)\n    }\n  }\n  function getterSetter(type) {\n    if (type != \"variable\") return pass(afterprop);\n    cx.marked = \"property\";\n    return cont(functiondef);\n  }\n  function afterprop(type) {\n    if (type == \":\") return cont(expressionNoComma);\n    if (type == \"(\") return pass(functiondef);\n  }\n  function commasep(what, end, sep) {\n    function proceed(type, value) {\n      if (sep ? sep.indexOf(type) > -1 : type == \",\") {\n        var lex = cx.state.lexical;\n        if (lex.info == \"call\") lex.pos = (lex.pos || 0) + 1;\n        return cont(function(type, value) {\n          if (type == end || value == end) return pass()\n          return pass(what)\n        }, proceed);\n      }\n      if (type == end || value == end) return cont();\n      if (sep && sep.indexOf(\";\") > -1) return pass(what)\n      return cont(expect(end));\n    }\n    return function(type, value) {\n      if (type == end || value == end) return cont();\n      return pass(what, proceed);\n    };\n  }\n  function contCommasep(what, end, info) {\n    for (var i = 3; i < arguments.length; i++)\n      cx.cc.push(arguments[i]);\n    return cont(pushlex(end, info), commasep(what, end), poplex);\n  }\n  function block(type) {\n    if (type == \"}\") return cont();\n    return pass(statement, block);\n  }\n  function maybetype(type, value) {\n    if (isTS) {\n      if (type == \":\") return cont(typeexpr);\n      if (value == \"?\") return cont(maybetype);\n    }\n  }\n  function maybetypeOrIn(type, value) {\n    if (isTS && (type == \":\" || value == \"in\")) return cont(typeexpr)\n  }\n  function mayberettype(type) {\n    if (isTS && type == \":\") {\n      if (cx.stream.match(/^\\s*\\w+\\s+is\\b/, false)) return cont(expression, isKW, typeexpr)\n      else return cont(typeexpr)\n    }\n  }\n  function isKW(_, value) {\n    if (value == \"is\") {\n      cx.marked = \"keyword\"\n      return cont()\n    }\n  }\n  function typeexpr(type, value) {\n    if (value == \"keyof\" || value == \"typeof\" || value == \"infer\" || value == \"readonly\") {\n      cx.marked = \"keyword\"\n      return cont(value == \"typeof\" ? expressionNoComma : typeexpr)\n    }\n    if (type == \"variable\" || value == \"void\") {\n      cx.marked = \"type\"\n      return cont(afterType)\n    }\n    if (value == \"|\" || value == \"&\") return cont(typeexpr)\n    if (type == \"string\" || type == \"number\" || type == \"atom\") return cont(afterType);\n    if (type == \"[\") return cont(pushlex(\"]\"), commasep(typeexpr, \"]\", \",\"), poplex, afterType)\n    if (type == \"{\") return cont(pushlex(\"}\"), typeprops, poplex, afterType)\n    if (type == \"(\") return cont(commasep(typearg, \")\"), maybeReturnType, afterType)\n    if (type == \"<\") return cont(commasep(typeexpr, \">\"), typeexpr)\n    if (type == \"quasi\") { return pass(quasiType, afterType); }\n  }\n  function maybeReturnType(type) {\n    if (type == \"=>\") return cont(typeexpr)\n  }\n  function typeprops(type) {\n    if (type.match(/[\\}\\)\\]]/)) return cont()\n    if (type == \",\" || type == \";\") return cont(typeprops)\n    return pass(typeprop, typeprops)\n  }\n  function typeprop(type, value) {\n    if (type == \"variable\" || cx.style == \"keyword\") {\n      cx.marked = \"property\"\n      return cont(typeprop)\n    } else if (value == \"?\" || type == \"number\" || type == \"string\") {\n      return cont(typeprop)\n    } else if (type == \":\") {\n      return cont(typeexpr)\n    } else if (type == \"[\") {\n      return cont(expect(\"variable\"), maybetypeOrIn, expect(\"]\"), typeprop)\n    } else if (type == \"(\") {\n      return pass(functiondecl, typeprop)\n    } else if (!type.match(/[;\\}\\)\\],]/)) {\n      return cont()\n    }\n  }\n  function quasiType(type, value) {\n    if (type != \"quasi\") return pass();\n    if (value.slice(value.length - 2) != \"${\") return cont(quasiType);\n    return cont(typeexpr, continueQuasiType);\n  }\n  function continueQuasiType(type) {\n    if (type == \"}\") {\n      cx.marked = \"string-2\";\n      cx.state.tokenize = tokenQuasi;\n      return cont(quasiType);\n    }\n  }\n  function typearg(type, value) {\n    if (type == \"variable\" && cx.stream.match(/^\\s*[?:]/, false) || value == \"?\") return cont(typearg)\n    if (type == \":\") return cont(typeexpr)\n    if (type == \"spread\") return cont(typearg)\n    return pass(typeexpr)\n  }\n  function afterType(type, value) {\n    if (value == \"<\") return cont(pushlex(\">\"), commasep(typeexpr, \">\"), poplex, afterType)\n    if (value == \"|\" || type == \".\" || value == \"&\") return cont(typeexpr)\n    if (type == \"[\") return cont(typeexpr, expect(\"]\"), afterType)\n    if (value == \"extends\" || value == \"implements\") { cx.marked = \"keyword\"; return cont(typeexpr) }\n    if (value == \"?\") return cont(typeexpr, expect(\":\"), typeexpr)\n  }\n  function maybeTypeArgs(_, value) {\n    if (value == \"<\") return cont(pushlex(\">\"), commasep(typeexpr, \">\"), poplex, afterType)\n  }\n  function typeparam() {\n    return pass(typeexpr, maybeTypeDefault)\n  }\n  function maybeTypeDefault(_, value) {\n    if (value == \"=\") return cont(typeexpr)\n  }\n  function vardef(_, value) {\n    if (value == \"enum\") {cx.marked = \"keyword\"; return cont(enumdef)}\n    return pass(pattern, maybetype, maybeAssign, vardefCont);\n  }\n  function pattern(type, value) {\n    if (isTS && isModifier(value)) { cx.marked = \"keyword\"; return cont(pattern) }\n    if (type == \"variable\") { register(value); return cont(); }\n    if (type == \"spread\") return cont(pattern);\n    if (type == \"[\") return contCommasep(eltpattern, \"]\");\n    if (type == \"{\") return contCommasep(proppattern, \"}\");\n  }\n  function proppattern(type, value) {\n    if (type == \"variable\" && !cx.stream.match(/^\\s*:/, false)) {\n      register(value);\n      return cont(maybeAssign);\n    }\n    if (type == \"variable\") cx.marked = \"property\";\n    if (type == \"spread\") return cont(pattern);\n    if (type == \"}\") return pass();\n    if (type == \"[\") return cont(expression, expect(']'), expect(':'), proppattern);\n    return cont(expect(\":\"), pattern, maybeAssign);\n  }\n  function eltpattern() {\n    return pass(pattern, maybeAssign)\n  }\n  function maybeAssign(_type, value) {\n    if (value == \"=\") return cont(expressionNoComma);\n  }\n  function vardefCont(type) {\n    if (type == \",\") return cont(vardef);\n  }\n  function maybeelse(type, value) {\n    if (type == \"keyword b\" && value == \"else\") return cont(pushlex(\"form\", \"else\"), statement, poplex);\n  }\n  function forspec(type, value) {\n    if (value == \"await\") return cont(forspec);\n    if (type == \"(\") return cont(pushlex(\")\"), forspec1, poplex);\n  }\n  function forspec1(type) {\n    if (type == \"var\") return cont(vardef, forspec2);\n    if (type == \"variable\") return cont(forspec2);\n    return pass(forspec2)\n  }\n  function forspec2(type, value) {\n    if (type == \")\") return cont()\n    if (type == \";\") return cont(forspec2)\n    if (value == \"in\" || value == \"of\") { cx.marked = \"keyword\"; return cont(expression, forspec2) }\n    return pass(expression, forspec2)\n  }\n  function functiondef(type, value) {\n    if (value == \"*\") {cx.marked = \"keyword\"; return cont(functiondef);}\n    if (type == \"variable\") {register(value); return cont(functiondef);}\n    if (type == \"(\") return cont(pushcontext, pushlex(\")\"), commasep(funarg, \")\"), poplex, mayberettype, statement, popcontext);\n    if (isTS && value == \"<\") return cont(pushlex(\">\"), commasep(typeparam, \">\"), poplex, functiondef)\n  }\n  function functiondecl(type, value) {\n    if (value == \"*\") {cx.marked = \"keyword\"; return cont(functiondecl);}\n    if (type == \"variable\") {register(value); return cont(functiondecl);}\n    if (type == \"(\") return cont(pushcontext, pushlex(\")\"), commasep(funarg, \")\"), poplex, mayberettype, popcontext);\n    if (isTS && value == \"<\") return cont(pushlex(\">\"), commasep(typeparam, \">\"), poplex, functiondecl)\n  }\n  function typename(type, value) {\n    if (type == \"keyword\" || type == \"variable\") {\n      cx.marked = \"type\"\n      return cont(typename)\n    } else if (value == \"<\") {\n      return cont(pushlex(\">\"), commasep(typeparam, \">\"), poplex)\n    }\n  }\n  function funarg(type, value) {\n    if (value == \"@\") cont(expression, funarg)\n    if (type == \"spread\") return cont(funarg);\n    if (isTS && isModifier(value)) { cx.marked = \"keyword\"; return cont(funarg); }\n    if (isTS && type == \"this\") return cont(maybetype, maybeAssign)\n    return pass(pattern, maybetype, maybeAssign);\n  }\n  function classExpression(type, value) {\n    // Class expressions may have an optional name.\n    if (type == \"variable\") return className(type, value);\n    return classNameAfter(type, value);\n  }\n  function className(type, value) {\n    if (type == \"variable\") {register(value); return cont(classNameAfter);}\n  }\n  function classNameAfter(type, value) {\n    if (value == \"<\") return cont(pushlex(\">\"), commasep(typeparam, \">\"), poplex, classNameAfter)\n    if (value == \"extends\" || value == \"implements\" || (isTS && type == \",\")) {\n      if (value == \"implements\") cx.marked = \"keyword\";\n      return cont(isTS ? typeexpr : expression, classNameAfter);\n    }\n    if (type == \"{\") return cont(pushlex(\"}\"), classBody, poplex);\n  }\n  function classBody(type, value) {\n    if (type == \"async\" ||\n        (type == \"variable\" &&\n         (value == \"static\" || value == \"get\" || value == \"set\" || (isTS && isModifier(value))) &&\n         cx.stream.match(/^\\s+#?[\\w$\\xa1-\\uffff]/, false))) {\n      cx.marked = \"keyword\";\n      return cont(classBody);\n    }\n    if (type == \"variable\" || cx.style == \"keyword\") {\n      cx.marked = \"property\";\n      return cont(classfield, classBody);\n    }\n    if (type == \"number\" || type == \"string\") return cont(classfield, classBody);\n    if (type == \"[\")\n      return cont(expression, maybetype, expect(\"]\"), classfield, classBody)\n    if (value == \"*\") {\n      cx.marked = \"keyword\";\n      return cont(classBody);\n    }\n    if (isTS && type == \"(\") return pass(functiondecl, classBody)\n    if (type == \";\" || type == \",\") return cont(classBody);\n    if (type == \"}\") return cont();\n    if (value == \"@\") return cont(expression, classBody)\n  }\n  function classfield(type, value) {\n    if (value == \"!\") return cont(classfield)\n    if (value == \"?\") return cont(classfield)\n    if (type == \":\") return cont(typeexpr, maybeAssign)\n    if (value == \"=\") return cont(expressionNoComma)\n    var context = cx.state.lexical.prev, isInterface = context && context.info == \"interface\"\n    return pass(isInterface ? functiondecl : functiondef)\n  }\n  function afterExport(type, value) {\n    if (value == \"*\") { cx.marked = \"keyword\"; return cont(maybeFrom, expect(\";\")); }\n    if (value == \"default\") { cx.marked = \"keyword\"; return cont(expression, expect(\";\")); }\n    if (type == \"{\") return cont(commasep(exportField, \"}\"), maybeFrom, expect(\";\"));\n    return pass(statement);\n  }\n  function exportField(type, value) {\n    if (value == \"as\") { cx.marked = \"keyword\"; return cont(expect(\"variable\")); }\n    if (type == \"variable\") return pass(expressionNoComma, exportField);\n  }\n  function afterImport(type) {\n    if (type == \"string\") return cont();\n    if (type == \"(\") return pass(expression);\n    if (type == \".\") return pass(maybeoperatorComma);\n    return pass(importSpec, maybeMoreImports, maybeFrom);\n  }\n  function importSpec(type, value) {\n    if (type == \"{\") return contCommasep(importSpec, \"}\");\n    if (type == \"variable\") register(value);\n    if (value == \"*\") cx.marked = \"keyword\";\n    return cont(maybeAs);\n  }\n  function maybeMoreImports(type) {\n    if (type == \",\") return cont(importSpec, maybeMoreImports)\n  }\n  function maybeAs(_type, value) {\n    if (value == \"as\") { cx.marked = \"keyword\"; return cont(importSpec); }\n  }\n  function maybeFrom(_type, value) {\n    if (value == \"from\") { cx.marked = \"keyword\"; return cont(expression); }\n  }\n  function arrayLiteral(type) {\n    if (type == \"]\") return cont();\n    return pass(commasep(expressionNoComma, \"]\"));\n  }\n  function enumdef() {\n    return pass(pushlex(\"form\"), pattern, expect(\"{\"), pushlex(\"}\"), commasep(enummember, \"}\"), poplex, poplex)\n  }\n  function enummember() {\n    return pass(pattern, maybeAssign);\n  }\n\n  function isContinuedStatement(state, textAfter) {\n    return state.lastType == \"operator\" || state.lastType == \",\" ||\n      isOperatorChar.test(textAfter.charAt(0)) ||\n      /[,.]/.test(textAfter.charAt(0));\n  }\n\n  function expressionAllowed(stream, state, backUp) {\n    return state.tokenize == tokenBase &&\n      /^(?:operator|sof|keyword [bcd]|case|new|export|default|spread|[\\[{}\\(,;:]|=>)$/.test(state.lastType) ||\n      (state.lastType == \"quasi\" && /\\{\\s*$/.test(stream.string.slice(0, stream.pos - (backUp || 0))))\n  }\n\n  // Interface\n\n  return {\n    startState: function(basecolumn) {\n      var state = {\n        tokenize: tokenBase,\n        lastType: \"sof\",\n        cc: [],\n        lexical: new JSLexical((basecolumn || 0) - indentUnit, 0, \"block\", false),\n        localVars: parserConfig.localVars,\n        context: parserConfig.localVars && new Context(null, null, false),\n        indented: basecolumn || 0\n      };\n      if (parserConfig.globalVars && typeof parserConfig.globalVars == \"object\")\n        state.globalVars = parserConfig.globalVars;\n      return state;\n    },\n\n    token: function(stream, state) {\n      if (stream.sol()) {\n        if (!state.lexical.hasOwnProperty(\"align\"))\n          state.lexical.align = false;\n        state.indented = stream.indentation();\n        findFatArrow(stream, state);\n      }\n      if (state.tokenize != tokenComment && stream.eatSpace()) return null;\n      var style = state.tokenize(stream, state);\n      if (type == \"comment\") return style;\n      state.lastType = type == \"operator\" && (content == \"++\" || content == \"--\") ? \"incdec\" : type;\n      return parseJS(state, style, type, content, stream);\n    },\n\n    indent: function(state, textAfter) {\n      if (state.tokenize == tokenComment || state.tokenize == tokenQuasi) return CodeMirror.Pass;\n      if (state.tokenize != tokenBase) return 0;\n      var firstChar = textAfter && textAfter.charAt(0), lexical = state.lexical, top\n      // Kludge to prevent 'maybelse' from blocking lexical scope pops\n      if (!/^\\s*else\\b/.test(textAfter)) for (var i = state.cc.length - 1; i >= 0; --i) {\n        var c = state.cc[i];\n        if (c == poplex) lexical = lexical.prev;\n        else if (c != maybeelse && c != popcontext) break;\n      }\n      while ((lexical.type == \"stat\" || lexical.type == \"form\") &&\n             (firstChar == \"}\" || ((top = state.cc[state.cc.length - 1]) &&\n                                   (top == maybeoperatorComma || top == maybeoperatorNoComma) &&\n                                   !/^[,\\.=+\\-*:?[\\(]/.test(textAfter))))\n        lexical = lexical.prev;\n      if (statementIndent && lexical.type == \")\" && lexical.prev.type == \"stat\")\n        lexical = lexical.prev;\n      var type = lexical.type, closing = firstChar == type;\n\n      if (type == \"vardef\") return lexical.indented + (state.lastType == \"operator\" || state.lastType == \",\" ? lexical.info.length + 1 : 0);\n      else if (type == \"form\" && firstChar == \"{\") return lexical.indented;\n      else if (type == \"form\") return lexical.indented + indentUnit;\n      else if (type == \"stat\")\n        return lexical.indented + (isContinuedStatement(state, textAfter) ? statementIndent || indentUnit : 0);\n      else if (lexical.info == \"switch\" && !closing && parserConfig.doubleIndentSwitch != false)\n        return lexical.indented + (/^(?:case|default)\\b/.test(textAfter) ? indentUnit : 2 * indentUnit);\n      else if (lexical.align) return lexical.column + (closing ? 0 : 1);\n      else return lexical.indented + (closing ? 0 : indentUnit);\n    },\n\n    electricInput: /^\\s*(?:case .*?:|default:|\\{|\\})$/,\n    blockCommentStart: jsonMode ? null : \"/*\",\n    blockCommentEnd: jsonMode ? null : \"*/\",\n    blockCommentContinue: jsonMode ? null : \" * \",\n    lineComment: jsonMode ? null : \"//\",\n    fold: \"brace\",\n    closeBrackets: \"()[]{}''\\\"\\\"``\",\n\n    helperType: jsonMode ? \"json\" : \"javascript\",\n    jsonldMode: jsonldMode,\n    jsonMode: jsonMode,\n\n    expressionAllowed: expressionAllowed,\n\n    skipExpression: function(state) {\n      parseJS(state, \"atom\", \"atom\", \"true\", new CodeMirror.StringStream(\"\", 2, null))\n    }\n  };\n});\n\nCodeMirror.registerHelper(\"wordChars\", \"javascript\", /[\\w$]/);\n\nCodeMirror.defineMIME(\"text/javascript\", \"javascript\");\nCodeMirror.defineMIME(\"text/ecmascript\", \"javascript\");\nCodeMirror.defineMIME(\"application/javascript\", \"javascript\");\nCodeMirror.defineMIME(\"application/x-javascript\", \"javascript\");\nCodeMirror.defineMIME(\"application/ecmascript\", \"javascript\");\nCodeMirror.defineMIME(\"application/json\", { name: \"javascript\", json: true });\nCodeMirror.defineMIME(\"application/x-json\", { name: \"javascript\", json: true });\nCodeMirror.defineMIME(\"application/manifest+json\", { name: \"javascript\", json: true })\nCodeMirror.defineMIME(\"application/ld+json\", { name: \"javascript\", jsonld: true });\nCodeMirror.defineMIME(\"text/typescript\", { name: \"javascript\", typescript: true });\nCodeMirror.defineMIME(\"application/typescript\", { name: \"javascript\", typescript: true });\n\n});\n\n\n//# sourceURL=webpack://semanticfinder/./node_modules/codemirror/mode/javascript/javascript.js?");

/***/ }),

/***/ "./node_modules/gl-matrix/esm/common.js":
/*!**********************************************!*\
  !*** ./node_modules/gl-matrix/esm/common.js ***!
  \**********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   ARRAY_TYPE: () => (/* binding */ ARRAY_TYPE),\n/* harmony export */   EPSILON: () => (/* binding */ EPSILON),\n/* harmony export */   RANDOM: () => (/* binding */ RANDOM),\n/* harmony export */   equals: () => (/* binding */ equals),\n/* harmony export */   setMatrixArrayType: () => (/* binding */ setMatrixArrayType),\n/* harmony export */   toRadian: () => (/* binding */ toRadian)\n/* harmony export */ });\n/**\n * Common utilities\n * @module glMatrix\n */\n// Configuration Constants\nvar EPSILON = 0.000001;\nvar ARRAY_TYPE = typeof Float32Array !== 'undefined' ? Float32Array : Array;\nvar RANDOM = Math.random;\n/**\n * Sets the type of array used when creating new vectors and matrices\n *\n * @param {Float32ArrayConstructor | ArrayConstructor} type Array type, such as Float32Array or Array\n */\n\nfunction setMatrixArrayType(type) {\n  ARRAY_TYPE = type;\n}\nvar degree = Math.PI / 180;\n/**\n * Convert Degree To Radian\n *\n * @param {Number} a Angle in Degrees\n */\n\nfunction toRadian(a) {\n  return a * degree;\n}\n/**\n * Tests whether or not the arguments have approximately the same value, within an absolute\n * or relative tolerance of glMatrix.EPSILON (an absolute tolerance is used for values less\n * than or equal to 1.0, and a relative tolerance is used for larger values)\n *\n * @param {Number} a The first number to test.\n * @param {Number} b The second number to test.\n * @returns {Boolean} True if the numbers are approximately equal, false otherwise.\n */\n\nfunction equals(a, b) {\n  return Math.abs(a - b) <= EPSILON * Math.max(1.0, Math.abs(a), Math.abs(b));\n}\nif (!Math.hypot) Math.hypot = function () {\n  var y = 0,\n      i = arguments.length;\n\n  while (i--) {\n    y += arguments[i] * arguments[i];\n  }\n\n  return Math.sqrt(y);\n};\n\n//# sourceURL=webpack://semanticfinder/./node_modules/gl-matrix/esm/common.js?");

/***/ }),

/***/ "./node_modules/gl-matrix/esm/mat4.js":
/*!********************************************!*\
  !*** ./node_modules/gl-matrix/esm/mat4.js ***!
  \********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   add: () => (/* binding */ add),\n/* harmony export */   adjoint: () => (/* binding */ adjoint),\n/* harmony export */   clone: () => (/* binding */ clone),\n/* harmony export */   copy: () => (/* binding */ copy),\n/* harmony export */   create: () => (/* binding */ create),\n/* harmony export */   determinant: () => (/* binding */ determinant),\n/* harmony export */   equals: () => (/* binding */ equals),\n/* harmony export */   exactEquals: () => (/* binding */ exactEquals),\n/* harmony export */   frob: () => (/* binding */ frob),\n/* harmony export */   fromQuat: () => (/* binding */ fromQuat),\n/* harmony export */   fromQuat2: () => (/* binding */ fromQuat2),\n/* harmony export */   fromRotation: () => (/* binding */ fromRotation),\n/* harmony export */   fromRotationTranslation: () => (/* binding */ fromRotationTranslation),\n/* harmony export */   fromRotationTranslationScale: () => (/* binding */ fromRotationTranslationScale),\n/* harmony export */   fromRotationTranslationScaleOrigin: () => (/* binding */ fromRotationTranslationScaleOrigin),\n/* harmony export */   fromScaling: () => (/* binding */ fromScaling),\n/* harmony export */   fromTranslation: () => (/* binding */ fromTranslation),\n/* harmony export */   fromValues: () => (/* binding */ fromValues),\n/* harmony export */   fromXRotation: () => (/* binding */ fromXRotation),\n/* harmony export */   fromYRotation: () => (/* binding */ fromYRotation),\n/* harmony export */   fromZRotation: () => (/* binding */ fromZRotation),\n/* harmony export */   frustum: () => (/* binding */ frustum),\n/* harmony export */   getRotation: () => (/* binding */ getRotation),\n/* harmony export */   getScaling: () => (/* binding */ getScaling),\n/* harmony export */   getTranslation: () => (/* binding */ getTranslation),\n/* harmony export */   identity: () => (/* binding */ identity),\n/* harmony export */   invert: () => (/* binding */ invert),\n/* harmony export */   lookAt: () => (/* binding */ lookAt),\n/* harmony export */   mul: () => (/* binding */ mul),\n/* harmony export */   multiply: () => (/* binding */ multiply),\n/* harmony export */   multiplyScalar: () => (/* binding */ multiplyScalar),\n/* harmony export */   multiplyScalarAndAdd: () => (/* binding */ multiplyScalarAndAdd),\n/* harmony export */   ortho: () => (/* binding */ ortho),\n/* harmony export */   orthoNO: () => (/* binding */ orthoNO),\n/* harmony export */   orthoZO: () => (/* binding */ orthoZO),\n/* harmony export */   perspective: () => (/* binding */ perspective),\n/* harmony export */   perspectiveFromFieldOfView: () => (/* binding */ perspectiveFromFieldOfView),\n/* harmony export */   perspectiveNO: () => (/* binding */ perspectiveNO),\n/* harmony export */   perspectiveZO: () => (/* binding */ perspectiveZO),\n/* harmony export */   rotate: () => (/* binding */ rotate),\n/* harmony export */   rotateX: () => (/* binding */ rotateX),\n/* harmony export */   rotateY: () => (/* binding */ rotateY),\n/* harmony export */   rotateZ: () => (/* binding */ rotateZ),\n/* harmony export */   scale: () => (/* binding */ scale),\n/* harmony export */   set: () => (/* binding */ set),\n/* harmony export */   str: () => (/* binding */ str),\n/* harmony export */   sub: () => (/* binding */ sub),\n/* harmony export */   subtract: () => (/* binding */ subtract),\n/* harmony export */   targetTo: () => (/* binding */ targetTo),\n/* harmony export */   translate: () => (/* binding */ translate),\n/* harmony export */   transpose: () => (/* binding */ transpose)\n/* harmony export */ });\n/* harmony import */ var _common_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./common.js */ \"./node_modules/gl-matrix/esm/common.js\");\n\n/**\n * 4x4 Matrix<br>Format: column-major, when typed out it looks like row-major<br>The matrices are being post multiplied.\n * @module mat4\n */\n\n/**\n * Creates a new identity mat4\n *\n * @returns {mat4} a new 4x4 matrix\n */\n\nfunction create() {\n  var out = new _common_js__WEBPACK_IMPORTED_MODULE_0__.ARRAY_TYPE(16);\n\n  if (_common_js__WEBPACK_IMPORTED_MODULE_0__.ARRAY_TYPE != Float32Array) {\n    out[1] = 0;\n    out[2] = 0;\n    out[3] = 0;\n    out[4] = 0;\n    out[6] = 0;\n    out[7] = 0;\n    out[8] = 0;\n    out[9] = 0;\n    out[11] = 0;\n    out[12] = 0;\n    out[13] = 0;\n    out[14] = 0;\n  }\n\n  out[0] = 1;\n  out[5] = 1;\n  out[10] = 1;\n  out[15] = 1;\n  return out;\n}\n/**\n * Creates a new mat4 initialized with values from an existing matrix\n *\n * @param {ReadonlyMat4} a matrix to clone\n * @returns {mat4} a new 4x4 matrix\n */\n\nfunction clone(a) {\n  var out = new _common_js__WEBPACK_IMPORTED_MODULE_0__.ARRAY_TYPE(16);\n  out[0] = a[0];\n  out[1] = a[1];\n  out[2] = a[2];\n  out[3] = a[3];\n  out[4] = a[4];\n  out[5] = a[5];\n  out[6] = a[6];\n  out[7] = a[7];\n  out[8] = a[8];\n  out[9] = a[9];\n  out[10] = a[10];\n  out[11] = a[11];\n  out[12] = a[12];\n  out[13] = a[13];\n  out[14] = a[14];\n  out[15] = a[15];\n  return out;\n}\n/**\n * Copy the values from one mat4 to another\n *\n * @param {mat4} out the receiving matrix\n * @param {ReadonlyMat4} a the source matrix\n * @returns {mat4} out\n */\n\nfunction copy(out, a) {\n  out[0] = a[0];\n  out[1] = a[1];\n  out[2] = a[2];\n  out[3] = a[3];\n  out[4] = a[4];\n  out[5] = a[5];\n  out[6] = a[6];\n  out[7] = a[7];\n  out[8] = a[8];\n  out[9] = a[9];\n  out[10] = a[10];\n  out[11] = a[11];\n  out[12] = a[12];\n  out[13] = a[13];\n  out[14] = a[14];\n  out[15] = a[15];\n  return out;\n}\n/**\n * Create a new mat4 with the given values\n *\n * @param {Number} m00 Component in column 0, row 0 position (index 0)\n * @param {Number} m01 Component in column 0, row 1 position (index 1)\n * @param {Number} m02 Component in column 0, row 2 position (index 2)\n * @param {Number} m03 Component in column 0, row 3 position (index 3)\n * @param {Number} m10 Component in column 1, row 0 position (index 4)\n * @param {Number} m11 Component in column 1, row 1 position (index 5)\n * @param {Number} m12 Component in column 1, row 2 position (index 6)\n * @param {Number} m13 Component in column 1, row 3 position (index 7)\n * @param {Number} m20 Component in column 2, row 0 position (index 8)\n * @param {Number} m21 Component in column 2, row 1 position (index 9)\n * @param {Number} m22 Component in column 2, row 2 position (index 10)\n * @param {Number} m23 Component in column 2, row 3 position (index 11)\n * @param {Number} m30 Component in column 3, row 0 position (index 12)\n * @param {Number} m31 Component in column 3, row 1 position (index 13)\n * @param {Number} m32 Component in column 3, row 2 position (index 14)\n * @param {Number} m33 Component in column 3, row 3 position (index 15)\n * @returns {mat4} A new mat4\n */\n\nfunction fromValues(m00, m01, m02, m03, m10, m11, m12, m13, m20, m21, m22, m23, m30, m31, m32, m33) {\n  var out = new _common_js__WEBPACK_IMPORTED_MODULE_0__.ARRAY_TYPE(16);\n  out[0] = m00;\n  out[1] = m01;\n  out[2] = m02;\n  out[3] = m03;\n  out[4] = m10;\n  out[5] = m11;\n  out[6] = m12;\n  out[7] = m13;\n  out[8] = m20;\n  out[9] = m21;\n  out[10] = m22;\n  out[11] = m23;\n  out[12] = m30;\n  out[13] = m31;\n  out[14] = m32;\n  out[15] = m33;\n  return out;\n}\n/**\n * Set the components of a mat4 to the given values\n *\n * @param {mat4} out the receiving matrix\n * @param {Number} m00 Component in column 0, row 0 position (index 0)\n * @param {Number} m01 Component in column 0, row 1 position (index 1)\n * @param {Number} m02 Component in column 0, row 2 position (index 2)\n * @param {Number} m03 Component in column 0, row 3 position (index 3)\n * @param {Number} m10 Component in column 1, row 0 position (index 4)\n * @param {Number} m11 Component in column 1, row 1 position (index 5)\n * @param {Number} m12 Component in column 1, row 2 position (index 6)\n * @param {Number} m13 Component in column 1, row 3 position (index 7)\n * @param {Number} m20 Component in column 2, row 0 position (index 8)\n * @param {Number} m21 Component in column 2, row 1 position (index 9)\n * @param {Number} m22 Component in column 2, row 2 position (index 10)\n * @param {Number} m23 Component in column 2, row 3 position (index 11)\n * @param {Number} m30 Component in column 3, row 0 position (index 12)\n * @param {Number} m31 Component in column 3, row 1 position (index 13)\n * @param {Number} m32 Component in column 3, row 2 position (index 14)\n * @param {Number} m33 Component in column 3, row 3 position (index 15)\n * @returns {mat4} out\n */\n\nfunction set(out, m00, m01, m02, m03, m10, m11, m12, m13, m20, m21, m22, m23, m30, m31, m32, m33) {\n  out[0] = m00;\n  out[1] = m01;\n  out[2] = m02;\n  out[3] = m03;\n  out[4] = m10;\n  out[5] = m11;\n  out[6] = m12;\n  out[7] = m13;\n  out[8] = m20;\n  out[9] = m21;\n  out[10] = m22;\n  out[11] = m23;\n  out[12] = m30;\n  out[13] = m31;\n  out[14] = m32;\n  out[15] = m33;\n  return out;\n}\n/**\n * Set a mat4 to the identity matrix\n *\n * @param {mat4} out the receiving matrix\n * @returns {mat4} out\n */\n\nfunction identity(out) {\n  out[0] = 1;\n  out[1] = 0;\n  out[2] = 0;\n  out[3] = 0;\n  out[4] = 0;\n  out[5] = 1;\n  out[6] = 0;\n  out[7] = 0;\n  out[8] = 0;\n  out[9] = 0;\n  out[10] = 1;\n  out[11] = 0;\n  out[12] = 0;\n  out[13] = 0;\n  out[14] = 0;\n  out[15] = 1;\n  return out;\n}\n/**\n * Transpose the values of a mat4\n *\n * @param {mat4} out the receiving matrix\n * @param {ReadonlyMat4} a the source matrix\n * @returns {mat4} out\n */\n\nfunction transpose(out, a) {\n  // If we are transposing ourselves we can skip a few steps but have to cache some values\n  if (out === a) {\n    var a01 = a[1],\n        a02 = a[2],\n        a03 = a[3];\n    var a12 = a[6],\n        a13 = a[7];\n    var a23 = a[11];\n    out[1] = a[4];\n    out[2] = a[8];\n    out[3] = a[12];\n    out[4] = a01;\n    out[6] = a[9];\n    out[7] = a[13];\n    out[8] = a02;\n    out[9] = a12;\n    out[11] = a[14];\n    out[12] = a03;\n    out[13] = a13;\n    out[14] = a23;\n  } else {\n    out[0] = a[0];\n    out[1] = a[4];\n    out[2] = a[8];\n    out[3] = a[12];\n    out[4] = a[1];\n    out[5] = a[5];\n    out[6] = a[9];\n    out[7] = a[13];\n    out[8] = a[2];\n    out[9] = a[6];\n    out[10] = a[10];\n    out[11] = a[14];\n    out[12] = a[3];\n    out[13] = a[7];\n    out[14] = a[11];\n    out[15] = a[15];\n  }\n\n  return out;\n}\n/**\n * Inverts a mat4\n *\n * @param {mat4} out the receiving matrix\n * @param {ReadonlyMat4} a the source matrix\n * @returns {mat4} out\n */\n\nfunction invert(out, a) {\n  var a00 = a[0],\n      a01 = a[1],\n      a02 = a[2],\n      a03 = a[3];\n  var a10 = a[4],\n      a11 = a[5],\n      a12 = a[6],\n      a13 = a[7];\n  var a20 = a[8],\n      a21 = a[9],\n      a22 = a[10],\n      a23 = a[11];\n  var a30 = a[12],\n      a31 = a[13],\n      a32 = a[14],\n      a33 = a[15];\n  var b00 = a00 * a11 - a01 * a10;\n  var b01 = a00 * a12 - a02 * a10;\n  var b02 = a00 * a13 - a03 * a10;\n  var b03 = a01 * a12 - a02 * a11;\n  var b04 = a01 * a13 - a03 * a11;\n  var b05 = a02 * a13 - a03 * a12;\n  var b06 = a20 * a31 - a21 * a30;\n  var b07 = a20 * a32 - a22 * a30;\n  var b08 = a20 * a33 - a23 * a30;\n  var b09 = a21 * a32 - a22 * a31;\n  var b10 = a21 * a33 - a23 * a31;\n  var b11 = a22 * a33 - a23 * a32; // Calculate the determinant\n\n  var det = b00 * b11 - b01 * b10 + b02 * b09 + b03 * b08 - b04 * b07 + b05 * b06;\n\n  if (!det) {\n    return null;\n  }\n\n  det = 1.0 / det;\n  out[0] = (a11 * b11 - a12 * b10 + a13 * b09) * det;\n  out[1] = (a02 * b10 - a01 * b11 - a03 * b09) * det;\n  out[2] = (a31 * b05 - a32 * b04 + a33 * b03) * det;\n  out[3] = (a22 * b04 - a21 * b05 - a23 * b03) * det;\n  out[4] = (a12 * b08 - a10 * b11 - a13 * b07) * det;\n  out[5] = (a00 * b11 - a02 * b08 + a03 * b07) * det;\n  out[6] = (a32 * b02 - a30 * b05 - a33 * b01) * det;\n  out[7] = (a20 * b05 - a22 * b02 + a23 * b01) * det;\n  out[8] = (a10 * b10 - a11 * b08 + a13 * b06) * det;\n  out[9] = (a01 * b08 - a00 * b10 - a03 * b06) * det;\n  out[10] = (a30 * b04 - a31 * b02 + a33 * b00) * det;\n  out[11] = (a21 * b02 - a20 * b04 - a23 * b00) * det;\n  out[12] = (a11 * b07 - a10 * b09 - a12 * b06) * det;\n  out[13] = (a00 * b09 - a01 * b07 + a02 * b06) * det;\n  out[14] = (a31 * b01 - a30 * b03 - a32 * b00) * det;\n  out[15] = (a20 * b03 - a21 * b01 + a22 * b00) * det;\n  return out;\n}\n/**\n * Calculates the adjugate of a mat4\n *\n * @param {mat4} out the receiving matrix\n * @param {ReadonlyMat4} a the source matrix\n * @returns {mat4} out\n */\n\nfunction adjoint(out, a) {\n  var a00 = a[0],\n      a01 = a[1],\n      a02 = a[2],\n      a03 = a[3];\n  var a10 = a[4],\n      a11 = a[5],\n      a12 = a[6],\n      a13 = a[7];\n  var a20 = a[8],\n      a21 = a[9],\n      a22 = a[10],\n      a23 = a[11];\n  var a30 = a[12],\n      a31 = a[13],\n      a32 = a[14],\n      a33 = a[15];\n  out[0] = a11 * (a22 * a33 - a23 * a32) - a21 * (a12 * a33 - a13 * a32) + a31 * (a12 * a23 - a13 * a22);\n  out[1] = -(a01 * (a22 * a33 - a23 * a32) - a21 * (a02 * a33 - a03 * a32) + a31 * (a02 * a23 - a03 * a22));\n  out[2] = a01 * (a12 * a33 - a13 * a32) - a11 * (a02 * a33 - a03 * a32) + a31 * (a02 * a13 - a03 * a12);\n  out[3] = -(a01 * (a12 * a23 - a13 * a22) - a11 * (a02 * a23 - a03 * a22) + a21 * (a02 * a13 - a03 * a12));\n  out[4] = -(a10 * (a22 * a33 - a23 * a32) - a20 * (a12 * a33 - a13 * a32) + a30 * (a12 * a23 - a13 * a22));\n  out[5] = a00 * (a22 * a33 - a23 * a32) - a20 * (a02 * a33 - a03 * a32) + a30 * (a02 * a23 - a03 * a22);\n  out[6] = -(a00 * (a12 * a33 - a13 * a32) - a10 * (a02 * a33 - a03 * a32) + a30 * (a02 * a13 - a03 * a12));\n  out[7] = a00 * (a12 * a23 - a13 * a22) - a10 * (a02 * a23 - a03 * a22) + a20 * (a02 * a13 - a03 * a12);\n  out[8] = a10 * (a21 * a33 - a23 * a31) - a20 * (a11 * a33 - a13 * a31) + a30 * (a11 * a23 - a13 * a21);\n  out[9] = -(a00 * (a21 * a33 - a23 * a31) - a20 * (a01 * a33 - a03 * a31) + a30 * (a01 * a23 - a03 * a21));\n  out[10] = a00 * (a11 * a33 - a13 * a31) - a10 * (a01 * a33 - a03 * a31) + a30 * (a01 * a13 - a03 * a11);\n  out[11] = -(a00 * (a11 * a23 - a13 * a21) - a10 * (a01 * a23 - a03 * a21) + a20 * (a01 * a13 - a03 * a11));\n  out[12] = -(a10 * (a21 * a32 - a22 * a31) - a20 * (a11 * a32 - a12 * a31) + a30 * (a11 * a22 - a12 * a21));\n  out[13] = a00 * (a21 * a32 - a22 * a31) - a20 * (a01 * a32 - a02 * a31) + a30 * (a01 * a22 - a02 * a21);\n  out[14] = -(a00 * (a11 * a32 - a12 * a31) - a10 * (a01 * a32 - a02 * a31) + a30 * (a01 * a12 - a02 * a11));\n  out[15] = a00 * (a11 * a22 - a12 * a21) - a10 * (a01 * a22 - a02 * a21) + a20 * (a01 * a12 - a02 * a11);\n  return out;\n}\n/**\n * Calculates the determinant of a mat4\n *\n * @param {ReadonlyMat4} a the source matrix\n * @returns {Number} determinant of a\n */\n\nfunction determinant(a) {\n  var a00 = a[0],\n      a01 = a[1],\n      a02 = a[2],\n      a03 = a[3];\n  var a10 = a[4],\n      a11 = a[5],\n      a12 = a[6],\n      a13 = a[7];\n  var a20 = a[8],\n      a21 = a[9],\n      a22 = a[10],\n      a23 = a[11];\n  var a30 = a[12],\n      a31 = a[13],\n      a32 = a[14],\n      a33 = a[15];\n  var b00 = a00 * a11 - a01 * a10;\n  var b01 = a00 * a12 - a02 * a10;\n  var b02 = a00 * a13 - a03 * a10;\n  var b03 = a01 * a12 - a02 * a11;\n  var b04 = a01 * a13 - a03 * a11;\n  var b05 = a02 * a13 - a03 * a12;\n  var b06 = a20 * a31 - a21 * a30;\n  var b07 = a20 * a32 - a22 * a30;\n  var b08 = a20 * a33 - a23 * a30;\n  var b09 = a21 * a32 - a22 * a31;\n  var b10 = a21 * a33 - a23 * a31;\n  var b11 = a22 * a33 - a23 * a32; // Calculate the determinant\n\n  return b00 * b11 - b01 * b10 + b02 * b09 + b03 * b08 - b04 * b07 + b05 * b06;\n}\n/**\n * Multiplies two mat4s\n *\n * @param {mat4} out the receiving matrix\n * @param {ReadonlyMat4} a the first operand\n * @param {ReadonlyMat4} b the second operand\n * @returns {mat4} out\n */\n\nfunction multiply(out, a, b) {\n  var a00 = a[0],\n      a01 = a[1],\n      a02 = a[2],\n      a03 = a[3];\n  var a10 = a[4],\n      a11 = a[5],\n      a12 = a[6],\n      a13 = a[7];\n  var a20 = a[8],\n      a21 = a[9],\n      a22 = a[10],\n      a23 = a[11];\n  var a30 = a[12],\n      a31 = a[13],\n      a32 = a[14],\n      a33 = a[15]; // Cache only the current line of the second matrix\n\n  var b0 = b[0],\n      b1 = b[1],\n      b2 = b[2],\n      b3 = b[3];\n  out[0] = b0 * a00 + b1 * a10 + b2 * a20 + b3 * a30;\n  out[1] = b0 * a01 + b1 * a11 + b2 * a21 + b3 * a31;\n  out[2] = b0 * a02 + b1 * a12 + b2 * a22 + b3 * a32;\n  out[3] = b0 * a03 + b1 * a13 + b2 * a23 + b3 * a33;\n  b0 = b[4];\n  b1 = b[5];\n  b2 = b[6];\n  b3 = b[7];\n  out[4] = b0 * a00 + b1 * a10 + b2 * a20 + b3 * a30;\n  out[5] = b0 * a01 + b1 * a11 + b2 * a21 + b3 * a31;\n  out[6] = b0 * a02 + b1 * a12 + b2 * a22 + b3 * a32;\n  out[7] = b0 * a03 + b1 * a13 + b2 * a23 + b3 * a33;\n  b0 = b[8];\n  b1 = b[9];\n  b2 = b[10];\n  b3 = b[11];\n  out[8] = b0 * a00 + b1 * a10 + b2 * a20 + b3 * a30;\n  out[9] = b0 * a01 + b1 * a11 + b2 * a21 + b3 * a31;\n  out[10] = b0 * a02 + b1 * a12 + b2 * a22 + b3 * a32;\n  out[11] = b0 * a03 + b1 * a13 + b2 * a23 + b3 * a33;\n  b0 = b[12];\n  b1 = b[13];\n  b2 = b[14];\n  b3 = b[15];\n  out[12] = b0 * a00 + b1 * a10 + b2 * a20 + b3 * a30;\n  out[13] = b0 * a01 + b1 * a11 + b2 * a21 + b3 * a31;\n  out[14] = b0 * a02 + b1 * a12 + b2 * a22 + b3 * a32;\n  out[15] = b0 * a03 + b1 * a13 + b2 * a23 + b3 * a33;\n  return out;\n}\n/**\n * Translate a mat4 by the given vector\n *\n * @param {mat4} out the receiving matrix\n * @param {ReadonlyMat4} a the matrix to translate\n * @param {ReadonlyVec3} v vector to translate by\n * @returns {mat4} out\n */\n\nfunction translate(out, a, v) {\n  var x = v[0],\n      y = v[1],\n      z = v[2];\n  var a00, a01, a02, a03;\n  var a10, a11, a12, a13;\n  var a20, a21, a22, a23;\n\n  if (a === out) {\n    out[12] = a[0] * x + a[4] * y + a[8] * z + a[12];\n    out[13] = a[1] * x + a[5] * y + a[9] * z + a[13];\n    out[14] = a[2] * x + a[6] * y + a[10] * z + a[14];\n    out[15] = a[3] * x + a[7] * y + a[11] * z + a[15];\n  } else {\n    a00 = a[0];\n    a01 = a[1];\n    a02 = a[2];\n    a03 = a[3];\n    a10 = a[4];\n    a11 = a[5];\n    a12 = a[6];\n    a13 = a[7];\n    a20 = a[8];\n    a21 = a[9];\n    a22 = a[10];\n    a23 = a[11];\n    out[0] = a00;\n    out[1] = a01;\n    out[2] = a02;\n    out[3] = a03;\n    out[4] = a10;\n    out[5] = a11;\n    out[6] = a12;\n    out[7] = a13;\n    out[8] = a20;\n    out[9] = a21;\n    out[10] = a22;\n    out[11] = a23;\n    out[12] = a00 * x + a10 * y + a20 * z + a[12];\n    out[13] = a01 * x + a11 * y + a21 * z + a[13];\n    out[14] = a02 * x + a12 * y + a22 * z + a[14];\n    out[15] = a03 * x + a13 * y + a23 * z + a[15];\n  }\n\n  return out;\n}\n/**\n * Scales the mat4 by the dimensions in the given vec3 not using vectorization\n *\n * @param {mat4} out the receiving matrix\n * @param {ReadonlyMat4} a the matrix to scale\n * @param {ReadonlyVec3} v the vec3 to scale the matrix by\n * @returns {mat4} out\n **/\n\nfunction scale(out, a, v) {\n  var x = v[0],\n      y = v[1],\n      z = v[2];\n  out[0] = a[0] * x;\n  out[1] = a[1] * x;\n  out[2] = a[2] * x;\n  out[3] = a[3] * x;\n  out[4] = a[4] * y;\n  out[5] = a[5] * y;\n  out[6] = a[6] * y;\n  out[7] = a[7] * y;\n  out[8] = a[8] * z;\n  out[9] = a[9] * z;\n  out[10] = a[10] * z;\n  out[11] = a[11] * z;\n  out[12] = a[12];\n  out[13] = a[13];\n  out[14] = a[14];\n  out[15] = a[15];\n  return out;\n}\n/**\n * Rotates a mat4 by the given angle around the given axis\n *\n * @param {mat4} out the receiving matrix\n * @param {ReadonlyMat4} a the matrix to rotate\n * @param {Number} rad the angle to rotate the matrix by\n * @param {ReadonlyVec3} axis the axis to rotate around\n * @returns {mat4} out\n */\n\nfunction rotate(out, a, rad, axis) {\n  var x = axis[0],\n      y = axis[1],\n      z = axis[2];\n  var len = Math.hypot(x, y, z);\n  var s, c, t;\n  var a00, a01, a02, a03;\n  var a10, a11, a12, a13;\n  var a20, a21, a22, a23;\n  var b00, b01, b02;\n  var b10, b11, b12;\n  var b20, b21, b22;\n\n  if (len < _common_js__WEBPACK_IMPORTED_MODULE_0__.EPSILON) {\n    return null;\n  }\n\n  len = 1 / len;\n  x *= len;\n  y *= len;\n  z *= len;\n  s = Math.sin(rad);\n  c = Math.cos(rad);\n  t = 1 - c;\n  a00 = a[0];\n  a01 = a[1];\n  a02 = a[2];\n  a03 = a[3];\n  a10 = a[4];\n  a11 = a[5];\n  a12 = a[6];\n  a13 = a[7];\n  a20 = a[8];\n  a21 = a[9];\n  a22 = a[10];\n  a23 = a[11]; // Construct the elements of the rotation matrix\n\n  b00 = x * x * t + c;\n  b01 = y * x * t + z * s;\n  b02 = z * x * t - y * s;\n  b10 = x * y * t - z * s;\n  b11 = y * y * t + c;\n  b12 = z * y * t + x * s;\n  b20 = x * z * t + y * s;\n  b21 = y * z * t - x * s;\n  b22 = z * z * t + c; // Perform rotation-specific matrix multiplication\n\n  out[0] = a00 * b00 + a10 * b01 + a20 * b02;\n  out[1] = a01 * b00 + a11 * b01 + a21 * b02;\n  out[2] = a02 * b00 + a12 * b01 + a22 * b02;\n  out[3] = a03 * b00 + a13 * b01 + a23 * b02;\n  out[4] = a00 * b10 + a10 * b11 + a20 * b12;\n  out[5] = a01 * b10 + a11 * b11 + a21 * b12;\n  out[6] = a02 * b10 + a12 * b11 + a22 * b12;\n  out[7] = a03 * b10 + a13 * b11 + a23 * b12;\n  out[8] = a00 * b20 + a10 * b21 + a20 * b22;\n  out[9] = a01 * b20 + a11 * b21 + a21 * b22;\n  out[10] = a02 * b20 + a12 * b21 + a22 * b22;\n  out[11] = a03 * b20 + a13 * b21 + a23 * b22;\n\n  if (a !== out) {\n    // If the source and destination differ, copy the unchanged last row\n    out[12] = a[12];\n    out[13] = a[13];\n    out[14] = a[14];\n    out[15] = a[15];\n  }\n\n  return out;\n}\n/**\n * Rotates a matrix by the given angle around the X axis\n *\n * @param {mat4} out the receiving matrix\n * @param {ReadonlyMat4} a the matrix to rotate\n * @param {Number} rad the angle to rotate the matrix by\n * @returns {mat4} out\n */\n\nfunction rotateX(out, a, rad) {\n  var s = Math.sin(rad);\n  var c = Math.cos(rad);\n  var a10 = a[4];\n  var a11 = a[5];\n  var a12 = a[6];\n  var a13 = a[7];\n  var a20 = a[8];\n  var a21 = a[9];\n  var a22 = a[10];\n  var a23 = a[11];\n\n  if (a !== out) {\n    // If the source and destination differ, copy the unchanged rows\n    out[0] = a[0];\n    out[1] = a[1];\n    out[2] = a[2];\n    out[3] = a[3];\n    out[12] = a[12];\n    out[13] = a[13];\n    out[14] = a[14];\n    out[15] = a[15];\n  } // Perform axis-specific matrix multiplication\n\n\n  out[4] = a10 * c + a20 * s;\n  out[5] = a11 * c + a21 * s;\n  out[6] = a12 * c + a22 * s;\n  out[7] = a13 * c + a23 * s;\n  out[8] = a20 * c - a10 * s;\n  out[9] = a21 * c - a11 * s;\n  out[10] = a22 * c - a12 * s;\n  out[11] = a23 * c - a13 * s;\n  return out;\n}\n/**\n * Rotates a matrix by the given angle around the Y axis\n *\n * @param {mat4} out the receiving matrix\n * @param {ReadonlyMat4} a the matrix to rotate\n * @param {Number} rad the angle to rotate the matrix by\n * @returns {mat4} out\n */\n\nfunction rotateY(out, a, rad) {\n  var s = Math.sin(rad);\n  var c = Math.cos(rad);\n  var a00 = a[0];\n  var a01 = a[1];\n  var a02 = a[2];\n  var a03 = a[3];\n  var a20 = a[8];\n  var a21 = a[9];\n  var a22 = a[10];\n  var a23 = a[11];\n\n  if (a !== out) {\n    // If the source and destination differ, copy the unchanged rows\n    out[4] = a[4];\n    out[5] = a[5];\n    out[6] = a[6];\n    out[7] = a[7];\n    out[12] = a[12];\n    out[13] = a[13];\n    out[14] = a[14];\n    out[15] = a[15];\n  } // Perform axis-specific matrix multiplication\n\n\n  out[0] = a00 * c - a20 * s;\n  out[1] = a01 * c - a21 * s;\n  out[2] = a02 * c - a22 * s;\n  out[3] = a03 * c - a23 * s;\n  out[8] = a00 * s + a20 * c;\n  out[9] = a01 * s + a21 * c;\n  out[10] = a02 * s + a22 * c;\n  out[11] = a03 * s + a23 * c;\n  return out;\n}\n/**\n * Rotates a matrix by the given angle around the Z axis\n *\n * @param {mat4} out the receiving matrix\n * @param {ReadonlyMat4} a the matrix to rotate\n * @param {Number} rad the angle to rotate the matrix by\n * @returns {mat4} out\n */\n\nfunction rotateZ(out, a, rad) {\n  var s = Math.sin(rad);\n  var c = Math.cos(rad);\n  var a00 = a[0];\n  var a01 = a[1];\n  var a02 = a[2];\n  var a03 = a[3];\n  var a10 = a[4];\n  var a11 = a[5];\n  var a12 = a[6];\n  var a13 = a[7];\n\n  if (a !== out) {\n    // If the source and destination differ, copy the unchanged last row\n    out[8] = a[8];\n    out[9] = a[9];\n    out[10] = a[10];\n    out[11] = a[11];\n    out[12] = a[12];\n    out[13] = a[13];\n    out[14] = a[14];\n    out[15] = a[15];\n  } // Perform axis-specific matrix multiplication\n\n\n  out[0] = a00 * c + a10 * s;\n  out[1] = a01 * c + a11 * s;\n  out[2] = a02 * c + a12 * s;\n  out[3] = a03 * c + a13 * s;\n  out[4] = a10 * c - a00 * s;\n  out[5] = a11 * c - a01 * s;\n  out[6] = a12 * c - a02 * s;\n  out[7] = a13 * c - a03 * s;\n  return out;\n}\n/**\n * Creates a matrix from a vector translation\n * This is equivalent to (but much faster than):\n *\n *     mat4.identity(dest);\n *     mat4.translate(dest, dest, vec);\n *\n * @param {mat4} out mat4 receiving operation result\n * @param {ReadonlyVec3} v Translation vector\n * @returns {mat4} out\n */\n\nfunction fromTranslation(out, v) {\n  out[0] = 1;\n  out[1] = 0;\n  out[2] = 0;\n  out[3] = 0;\n  out[4] = 0;\n  out[5] = 1;\n  out[6] = 0;\n  out[7] = 0;\n  out[8] = 0;\n  out[9] = 0;\n  out[10] = 1;\n  out[11] = 0;\n  out[12] = v[0];\n  out[13] = v[1];\n  out[14] = v[2];\n  out[15] = 1;\n  return out;\n}\n/**\n * Creates a matrix from a vector scaling\n * This is equivalent to (but much faster than):\n *\n *     mat4.identity(dest);\n *     mat4.scale(dest, dest, vec);\n *\n * @param {mat4} out mat4 receiving operation result\n * @param {ReadonlyVec3} v Scaling vector\n * @returns {mat4} out\n */\n\nfunction fromScaling(out, v) {\n  out[0] = v[0];\n  out[1] = 0;\n  out[2] = 0;\n  out[3] = 0;\n  out[4] = 0;\n  out[5] = v[1];\n  out[6] = 0;\n  out[7] = 0;\n  out[8] = 0;\n  out[9] = 0;\n  out[10] = v[2];\n  out[11] = 0;\n  out[12] = 0;\n  out[13] = 0;\n  out[14] = 0;\n  out[15] = 1;\n  return out;\n}\n/**\n * Creates a matrix from a given angle around a given axis\n * This is equivalent to (but much faster than):\n *\n *     mat4.identity(dest);\n *     mat4.rotate(dest, dest, rad, axis);\n *\n * @param {mat4} out mat4 receiving operation result\n * @param {Number} rad the angle to rotate the matrix by\n * @param {ReadonlyVec3} axis the axis to rotate around\n * @returns {mat4} out\n */\n\nfunction fromRotation(out, rad, axis) {\n  var x = axis[0],\n      y = axis[1],\n      z = axis[2];\n  var len = Math.hypot(x, y, z);\n  var s, c, t;\n\n  if (len < _common_js__WEBPACK_IMPORTED_MODULE_0__.EPSILON) {\n    return null;\n  }\n\n  len = 1 / len;\n  x *= len;\n  y *= len;\n  z *= len;\n  s = Math.sin(rad);\n  c = Math.cos(rad);\n  t = 1 - c; // Perform rotation-specific matrix multiplication\n\n  out[0] = x * x * t + c;\n  out[1] = y * x * t + z * s;\n  out[2] = z * x * t - y * s;\n  out[3] = 0;\n  out[4] = x * y * t - z * s;\n  out[5] = y * y * t + c;\n  out[6] = z * y * t + x * s;\n  out[7] = 0;\n  out[8] = x * z * t + y * s;\n  out[9] = y * z * t - x * s;\n  out[10] = z * z * t + c;\n  out[11] = 0;\n  out[12] = 0;\n  out[13] = 0;\n  out[14] = 0;\n  out[15] = 1;\n  return out;\n}\n/**\n * Creates a matrix from the given angle around the X axis\n * This is equivalent to (but much faster than):\n *\n *     mat4.identity(dest);\n *     mat4.rotateX(dest, dest, rad);\n *\n * @param {mat4} out mat4 receiving operation result\n * @param {Number} rad the angle to rotate the matrix by\n * @returns {mat4} out\n */\n\nfunction fromXRotation(out, rad) {\n  var s = Math.sin(rad);\n  var c = Math.cos(rad); // Perform axis-specific matrix multiplication\n\n  out[0] = 1;\n  out[1] = 0;\n  out[2] = 0;\n  out[3] = 0;\n  out[4] = 0;\n  out[5] = c;\n  out[6] = s;\n  out[7] = 0;\n  out[8] = 0;\n  out[9] = -s;\n  out[10] = c;\n  out[11] = 0;\n  out[12] = 0;\n  out[13] = 0;\n  out[14] = 0;\n  out[15] = 1;\n  return out;\n}\n/**\n * Creates a matrix from the given angle around the Y axis\n * This is equivalent to (but much faster than):\n *\n *     mat4.identity(dest);\n *     mat4.rotateY(dest, dest, rad);\n *\n * @param {mat4} out mat4 receiving operation result\n * @param {Number} rad the angle to rotate the matrix by\n * @returns {mat4} out\n */\n\nfunction fromYRotation(out, rad) {\n  var s = Math.sin(rad);\n  var c = Math.cos(rad); // Perform axis-specific matrix multiplication\n\n  out[0] = c;\n  out[1] = 0;\n  out[2] = -s;\n  out[3] = 0;\n  out[4] = 0;\n  out[5] = 1;\n  out[6] = 0;\n  out[7] = 0;\n  out[8] = s;\n  out[9] = 0;\n  out[10] = c;\n  out[11] = 0;\n  out[12] = 0;\n  out[13] = 0;\n  out[14] = 0;\n  out[15] = 1;\n  return out;\n}\n/**\n * Creates a matrix from the given angle around the Z axis\n * This is equivalent to (but much faster than):\n *\n *     mat4.identity(dest);\n *     mat4.rotateZ(dest, dest, rad);\n *\n * @param {mat4} out mat4 receiving operation result\n * @param {Number} rad the angle to rotate the matrix by\n * @returns {mat4} out\n */\n\nfunction fromZRotation(out, rad) {\n  var s = Math.sin(rad);\n  var c = Math.cos(rad); // Perform axis-specific matrix multiplication\n\n  out[0] = c;\n  out[1] = s;\n  out[2] = 0;\n  out[3] = 0;\n  out[4] = -s;\n  out[5] = c;\n  out[6] = 0;\n  out[7] = 0;\n  out[8] = 0;\n  out[9] = 0;\n  out[10] = 1;\n  out[11] = 0;\n  out[12] = 0;\n  out[13] = 0;\n  out[14] = 0;\n  out[15] = 1;\n  return out;\n}\n/**\n * Creates a matrix from a quaternion rotation and vector translation\n * This is equivalent to (but much faster than):\n *\n *     mat4.identity(dest);\n *     mat4.translate(dest, vec);\n *     let quatMat = mat4.create();\n *     quat4.toMat4(quat, quatMat);\n *     mat4.multiply(dest, quatMat);\n *\n * @param {mat4} out mat4 receiving operation result\n * @param {quat4} q Rotation quaternion\n * @param {ReadonlyVec3} v Translation vector\n * @returns {mat4} out\n */\n\nfunction fromRotationTranslation(out, q, v) {\n  // Quaternion math\n  var x = q[0],\n      y = q[1],\n      z = q[2],\n      w = q[3];\n  var x2 = x + x;\n  var y2 = y + y;\n  var z2 = z + z;\n  var xx = x * x2;\n  var xy = x * y2;\n  var xz = x * z2;\n  var yy = y * y2;\n  var yz = y * z2;\n  var zz = z * z2;\n  var wx = w * x2;\n  var wy = w * y2;\n  var wz = w * z2;\n  out[0] = 1 - (yy + zz);\n  out[1] = xy + wz;\n  out[2] = xz - wy;\n  out[3] = 0;\n  out[4] = xy - wz;\n  out[5] = 1 - (xx + zz);\n  out[6] = yz + wx;\n  out[7] = 0;\n  out[8] = xz + wy;\n  out[9] = yz - wx;\n  out[10] = 1 - (xx + yy);\n  out[11] = 0;\n  out[12] = v[0];\n  out[13] = v[1];\n  out[14] = v[2];\n  out[15] = 1;\n  return out;\n}\n/**\n * Creates a new mat4 from a dual quat.\n *\n * @param {mat4} out Matrix\n * @param {ReadonlyQuat2} a Dual Quaternion\n * @returns {mat4} mat4 receiving operation result\n */\n\nfunction fromQuat2(out, a) {\n  var translation = new _common_js__WEBPACK_IMPORTED_MODULE_0__.ARRAY_TYPE(3);\n  var bx = -a[0],\n      by = -a[1],\n      bz = -a[2],\n      bw = a[3],\n      ax = a[4],\n      ay = a[5],\n      az = a[6],\n      aw = a[7];\n  var magnitude = bx * bx + by * by + bz * bz + bw * bw; //Only scale if it makes sense\n\n  if (magnitude > 0) {\n    translation[0] = (ax * bw + aw * bx + ay * bz - az * by) * 2 / magnitude;\n    translation[1] = (ay * bw + aw * by + az * bx - ax * bz) * 2 / magnitude;\n    translation[2] = (az * bw + aw * bz + ax * by - ay * bx) * 2 / magnitude;\n  } else {\n    translation[0] = (ax * bw + aw * bx + ay * bz - az * by) * 2;\n    translation[1] = (ay * bw + aw * by + az * bx - ax * bz) * 2;\n    translation[2] = (az * bw + aw * bz + ax * by - ay * bx) * 2;\n  }\n\n  fromRotationTranslation(out, a, translation);\n  return out;\n}\n/**\n * Returns the translation vector component of a transformation\n *  matrix. If a matrix is built with fromRotationTranslation,\n *  the returned vector will be the same as the translation vector\n *  originally supplied.\n * @param  {vec3} out Vector to receive translation component\n * @param  {ReadonlyMat4} mat Matrix to be decomposed (input)\n * @return {vec3} out\n */\n\nfunction getTranslation(out, mat) {\n  out[0] = mat[12];\n  out[1] = mat[13];\n  out[2] = mat[14];\n  return out;\n}\n/**\n * Returns the scaling factor component of a transformation\n *  matrix. If a matrix is built with fromRotationTranslationScale\n *  with a normalized Quaternion paramter, the returned vector will be\n *  the same as the scaling vector\n *  originally supplied.\n * @param  {vec3} out Vector to receive scaling factor component\n * @param  {ReadonlyMat4} mat Matrix to be decomposed (input)\n * @return {vec3} out\n */\n\nfunction getScaling(out, mat) {\n  var m11 = mat[0];\n  var m12 = mat[1];\n  var m13 = mat[2];\n  var m21 = mat[4];\n  var m22 = mat[5];\n  var m23 = mat[6];\n  var m31 = mat[8];\n  var m32 = mat[9];\n  var m33 = mat[10];\n  out[0] = Math.hypot(m11, m12, m13);\n  out[1] = Math.hypot(m21, m22, m23);\n  out[2] = Math.hypot(m31, m32, m33);\n  return out;\n}\n/**\n * Returns a quaternion representing the rotational component\n *  of a transformation matrix. If a matrix is built with\n *  fromRotationTranslation, the returned quaternion will be the\n *  same as the quaternion originally supplied.\n * @param {quat} out Quaternion to receive the rotation component\n * @param {ReadonlyMat4} mat Matrix to be decomposed (input)\n * @return {quat} out\n */\n\nfunction getRotation(out, mat) {\n  var scaling = new _common_js__WEBPACK_IMPORTED_MODULE_0__.ARRAY_TYPE(3);\n  getScaling(scaling, mat);\n  var is1 = 1 / scaling[0];\n  var is2 = 1 / scaling[1];\n  var is3 = 1 / scaling[2];\n  var sm11 = mat[0] * is1;\n  var sm12 = mat[1] * is2;\n  var sm13 = mat[2] * is3;\n  var sm21 = mat[4] * is1;\n  var sm22 = mat[5] * is2;\n  var sm23 = mat[6] * is3;\n  var sm31 = mat[8] * is1;\n  var sm32 = mat[9] * is2;\n  var sm33 = mat[10] * is3;\n  var trace = sm11 + sm22 + sm33;\n  var S = 0;\n\n  if (trace > 0) {\n    S = Math.sqrt(trace + 1.0) * 2;\n    out[3] = 0.25 * S;\n    out[0] = (sm23 - sm32) / S;\n    out[1] = (sm31 - sm13) / S;\n    out[2] = (sm12 - sm21) / S;\n  } else if (sm11 > sm22 && sm11 > sm33) {\n    S = Math.sqrt(1.0 + sm11 - sm22 - sm33) * 2;\n    out[3] = (sm23 - sm32) / S;\n    out[0] = 0.25 * S;\n    out[1] = (sm12 + sm21) / S;\n    out[2] = (sm31 + sm13) / S;\n  } else if (sm22 > sm33) {\n    S = Math.sqrt(1.0 + sm22 - sm11 - sm33) * 2;\n    out[3] = (sm31 - sm13) / S;\n    out[0] = (sm12 + sm21) / S;\n    out[1] = 0.25 * S;\n    out[2] = (sm23 + sm32) / S;\n  } else {\n    S = Math.sqrt(1.0 + sm33 - sm11 - sm22) * 2;\n    out[3] = (sm12 - sm21) / S;\n    out[0] = (sm31 + sm13) / S;\n    out[1] = (sm23 + sm32) / S;\n    out[2] = 0.25 * S;\n  }\n\n  return out;\n}\n/**\n * Creates a matrix from a quaternion rotation, vector translation and vector scale\n * This is equivalent to (but much faster than):\n *\n *     mat4.identity(dest);\n *     mat4.translate(dest, vec);\n *     let quatMat = mat4.create();\n *     quat4.toMat4(quat, quatMat);\n *     mat4.multiply(dest, quatMat);\n *     mat4.scale(dest, scale)\n *\n * @param {mat4} out mat4 receiving operation result\n * @param {quat4} q Rotation quaternion\n * @param {ReadonlyVec3} v Translation vector\n * @param {ReadonlyVec3} s Scaling vector\n * @returns {mat4} out\n */\n\nfunction fromRotationTranslationScale(out, q, v, s) {\n  // Quaternion math\n  var x = q[0],\n      y = q[1],\n      z = q[2],\n      w = q[3];\n  var x2 = x + x;\n  var y2 = y + y;\n  var z2 = z + z;\n  var xx = x * x2;\n  var xy = x * y2;\n  var xz = x * z2;\n  var yy = y * y2;\n  var yz = y * z2;\n  var zz = z * z2;\n  var wx = w * x2;\n  var wy = w * y2;\n  var wz = w * z2;\n  var sx = s[0];\n  var sy = s[1];\n  var sz = s[2];\n  out[0] = (1 - (yy + zz)) * sx;\n  out[1] = (xy + wz) * sx;\n  out[2] = (xz - wy) * sx;\n  out[3] = 0;\n  out[4] = (xy - wz) * sy;\n  out[5] = (1 - (xx + zz)) * sy;\n  out[6] = (yz + wx) * sy;\n  out[7] = 0;\n  out[8] = (xz + wy) * sz;\n  out[9] = (yz - wx) * sz;\n  out[10] = (1 - (xx + yy)) * sz;\n  out[11] = 0;\n  out[12] = v[0];\n  out[13] = v[1];\n  out[14] = v[2];\n  out[15] = 1;\n  return out;\n}\n/**\n * Creates a matrix from a quaternion rotation, vector translation and vector scale, rotating and scaling around the given origin\n * This is equivalent to (but much faster than):\n *\n *     mat4.identity(dest);\n *     mat4.translate(dest, vec);\n *     mat4.translate(dest, origin);\n *     let quatMat = mat4.create();\n *     quat4.toMat4(quat, quatMat);\n *     mat4.multiply(dest, quatMat);\n *     mat4.scale(dest, scale)\n *     mat4.translate(dest, negativeOrigin);\n *\n * @param {mat4} out mat4 receiving operation result\n * @param {quat4} q Rotation quaternion\n * @param {ReadonlyVec3} v Translation vector\n * @param {ReadonlyVec3} s Scaling vector\n * @param {ReadonlyVec3} o The origin vector around which to scale and rotate\n * @returns {mat4} out\n */\n\nfunction fromRotationTranslationScaleOrigin(out, q, v, s, o) {\n  // Quaternion math\n  var x = q[0],\n      y = q[1],\n      z = q[2],\n      w = q[3];\n  var x2 = x + x;\n  var y2 = y + y;\n  var z2 = z + z;\n  var xx = x * x2;\n  var xy = x * y2;\n  var xz = x * z2;\n  var yy = y * y2;\n  var yz = y * z2;\n  var zz = z * z2;\n  var wx = w * x2;\n  var wy = w * y2;\n  var wz = w * z2;\n  var sx = s[0];\n  var sy = s[1];\n  var sz = s[2];\n  var ox = o[0];\n  var oy = o[1];\n  var oz = o[2];\n  var out0 = (1 - (yy + zz)) * sx;\n  var out1 = (xy + wz) * sx;\n  var out2 = (xz - wy) * sx;\n  var out4 = (xy - wz) * sy;\n  var out5 = (1 - (xx + zz)) * sy;\n  var out6 = (yz + wx) * sy;\n  var out8 = (xz + wy) * sz;\n  var out9 = (yz - wx) * sz;\n  var out10 = (1 - (xx + yy)) * sz;\n  out[0] = out0;\n  out[1] = out1;\n  out[2] = out2;\n  out[3] = 0;\n  out[4] = out4;\n  out[5] = out5;\n  out[6] = out6;\n  out[7] = 0;\n  out[8] = out8;\n  out[9] = out9;\n  out[10] = out10;\n  out[11] = 0;\n  out[12] = v[0] + ox - (out0 * ox + out4 * oy + out8 * oz);\n  out[13] = v[1] + oy - (out1 * ox + out5 * oy + out9 * oz);\n  out[14] = v[2] + oz - (out2 * ox + out6 * oy + out10 * oz);\n  out[15] = 1;\n  return out;\n}\n/**\n * Calculates a 4x4 matrix from the given quaternion\n *\n * @param {mat4} out mat4 receiving operation result\n * @param {ReadonlyQuat} q Quaternion to create matrix from\n *\n * @returns {mat4} out\n */\n\nfunction fromQuat(out, q) {\n  var x = q[0],\n      y = q[1],\n      z = q[2],\n      w = q[3];\n  var x2 = x + x;\n  var y2 = y + y;\n  var z2 = z + z;\n  var xx = x * x2;\n  var yx = y * x2;\n  var yy = y * y2;\n  var zx = z * x2;\n  var zy = z * y2;\n  var zz = z * z2;\n  var wx = w * x2;\n  var wy = w * y2;\n  var wz = w * z2;\n  out[0] = 1 - yy - zz;\n  out[1] = yx + wz;\n  out[2] = zx - wy;\n  out[3] = 0;\n  out[4] = yx - wz;\n  out[5] = 1 - xx - zz;\n  out[6] = zy + wx;\n  out[7] = 0;\n  out[8] = zx + wy;\n  out[9] = zy - wx;\n  out[10] = 1 - xx - yy;\n  out[11] = 0;\n  out[12] = 0;\n  out[13] = 0;\n  out[14] = 0;\n  out[15] = 1;\n  return out;\n}\n/**\n * Generates a frustum matrix with the given bounds\n *\n * @param {mat4} out mat4 frustum matrix will be written into\n * @param {Number} left Left bound of the frustum\n * @param {Number} right Right bound of the frustum\n * @param {Number} bottom Bottom bound of the frustum\n * @param {Number} top Top bound of the frustum\n * @param {Number} near Near bound of the frustum\n * @param {Number} far Far bound of the frustum\n * @returns {mat4} out\n */\n\nfunction frustum(out, left, right, bottom, top, near, far) {\n  var rl = 1 / (right - left);\n  var tb = 1 / (top - bottom);\n  var nf = 1 / (near - far);\n  out[0] = near * 2 * rl;\n  out[1] = 0;\n  out[2] = 0;\n  out[3] = 0;\n  out[4] = 0;\n  out[5] = near * 2 * tb;\n  out[6] = 0;\n  out[7] = 0;\n  out[8] = (right + left) * rl;\n  out[9] = (top + bottom) * tb;\n  out[10] = (far + near) * nf;\n  out[11] = -1;\n  out[12] = 0;\n  out[13] = 0;\n  out[14] = far * near * 2 * nf;\n  out[15] = 0;\n  return out;\n}\n/**\n * Generates a perspective projection matrix with the given bounds.\n * The near/far clip planes correspond to a normalized device coordinate Z range of [-1, 1],\n * which matches WebGL/OpenGL's clip volume.\n * Passing null/undefined/no value for far will generate infinite projection matrix.\n *\n * @param {mat4} out mat4 frustum matrix will be written into\n * @param {number} fovy Vertical field of view in radians\n * @param {number} aspect Aspect ratio. typically viewport width/height\n * @param {number} near Near bound of the frustum\n * @param {number} far Far bound of the frustum, can be null or Infinity\n * @returns {mat4} out\n */\n\nfunction perspectiveNO(out, fovy, aspect, near, far) {\n  var f = 1.0 / Math.tan(fovy / 2),\n      nf;\n  out[0] = f / aspect;\n  out[1] = 0;\n  out[2] = 0;\n  out[3] = 0;\n  out[4] = 0;\n  out[5] = f;\n  out[6] = 0;\n  out[7] = 0;\n  out[8] = 0;\n  out[9] = 0;\n  out[11] = -1;\n  out[12] = 0;\n  out[13] = 0;\n  out[15] = 0;\n\n  if (far != null && far !== Infinity) {\n    nf = 1 / (near - far);\n    out[10] = (far + near) * nf;\n    out[14] = 2 * far * near * nf;\n  } else {\n    out[10] = -1;\n    out[14] = -2 * near;\n  }\n\n  return out;\n}\n/**\n * Alias for {@link mat4.perspectiveNO}\n * @function\n */\n\nvar perspective = perspectiveNO;\n/**\n * Generates a perspective projection matrix suitable for WebGPU with the given bounds.\n * The near/far clip planes correspond to a normalized device coordinate Z range of [0, 1],\n * which matches WebGPU/Vulkan/DirectX/Metal's clip volume.\n * Passing null/undefined/no value for far will generate infinite projection matrix.\n *\n * @param {mat4} out mat4 frustum matrix will be written into\n * @param {number} fovy Vertical field of view in radians\n * @param {number} aspect Aspect ratio. typically viewport width/height\n * @param {number} near Near bound of the frustum\n * @param {number} far Far bound of the frustum, can be null or Infinity\n * @returns {mat4} out\n */\n\nfunction perspectiveZO(out, fovy, aspect, near, far) {\n  var f = 1.0 / Math.tan(fovy / 2),\n      nf;\n  out[0] = f / aspect;\n  out[1] = 0;\n  out[2] = 0;\n  out[3] = 0;\n  out[4] = 0;\n  out[5] = f;\n  out[6] = 0;\n  out[7] = 0;\n  out[8] = 0;\n  out[9] = 0;\n  out[11] = -1;\n  out[12] = 0;\n  out[13] = 0;\n  out[15] = 0;\n\n  if (far != null && far !== Infinity) {\n    nf = 1 / (near - far);\n    out[10] = far * nf;\n    out[14] = far * near * nf;\n  } else {\n    out[10] = -1;\n    out[14] = -near;\n  }\n\n  return out;\n}\n/**\n * Generates a perspective projection matrix with the given field of view.\n * This is primarily useful for generating projection matrices to be used\n * with the still experiemental WebVR API.\n *\n * @param {mat4} out mat4 frustum matrix will be written into\n * @param {Object} fov Object containing the following values: upDegrees, downDegrees, leftDegrees, rightDegrees\n * @param {number} near Near bound of the frustum\n * @param {number} far Far bound of the frustum\n * @returns {mat4} out\n */\n\nfunction perspectiveFromFieldOfView(out, fov, near, far) {\n  var upTan = Math.tan(fov.upDegrees * Math.PI / 180.0);\n  var downTan = Math.tan(fov.downDegrees * Math.PI / 180.0);\n  var leftTan = Math.tan(fov.leftDegrees * Math.PI / 180.0);\n  var rightTan = Math.tan(fov.rightDegrees * Math.PI / 180.0);\n  var xScale = 2.0 / (leftTan + rightTan);\n  var yScale = 2.0 / (upTan + downTan);\n  out[0] = xScale;\n  out[1] = 0.0;\n  out[2] = 0.0;\n  out[3] = 0.0;\n  out[4] = 0.0;\n  out[5] = yScale;\n  out[6] = 0.0;\n  out[7] = 0.0;\n  out[8] = -((leftTan - rightTan) * xScale * 0.5);\n  out[9] = (upTan - downTan) * yScale * 0.5;\n  out[10] = far / (near - far);\n  out[11] = -1.0;\n  out[12] = 0.0;\n  out[13] = 0.0;\n  out[14] = far * near / (near - far);\n  out[15] = 0.0;\n  return out;\n}\n/**\n * Generates a orthogonal projection matrix with the given bounds.\n * The near/far clip planes correspond to a normalized device coordinate Z range of [-1, 1],\n * which matches WebGL/OpenGL's clip volume.\n *\n * @param {mat4} out mat4 frustum matrix will be written into\n * @param {number} left Left bound of the frustum\n * @param {number} right Right bound of the frustum\n * @param {number} bottom Bottom bound of the frustum\n * @param {number} top Top bound of the frustum\n * @param {number} near Near bound of the frustum\n * @param {number} far Far bound of the frustum\n * @returns {mat4} out\n */\n\nfunction orthoNO(out, left, right, bottom, top, near, far) {\n  var lr = 1 / (left - right);\n  var bt = 1 / (bottom - top);\n  var nf = 1 / (near - far);\n  out[0] = -2 * lr;\n  out[1] = 0;\n  out[2] = 0;\n  out[3] = 0;\n  out[4] = 0;\n  out[5] = -2 * bt;\n  out[6] = 0;\n  out[7] = 0;\n  out[8] = 0;\n  out[9] = 0;\n  out[10] = 2 * nf;\n  out[11] = 0;\n  out[12] = (left + right) * lr;\n  out[13] = (top + bottom) * bt;\n  out[14] = (far + near) * nf;\n  out[15] = 1;\n  return out;\n}\n/**\n * Alias for {@link mat4.orthoNO}\n * @function\n */\n\nvar ortho = orthoNO;\n/**\n * Generates a orthogonal projection matrix with the given bounds.\n * The near/far clip planes correspond to a normalized device coordinate Z range of [0, 1],\n * which matches WebGPU/Vulkan/DirectX/Metal's clip volume.\n *\n * @param {mat4} out mat4 frustum matrix will be written into\n * @param {number} left Left bound of the frustum\n * @param {number} right Right bound of the frustum\n * @param {number} bottom Bottom bound of the frustum\n * @param {number} top Top bound of the frustum\n * @param {number} near Near bound of the frustum\n * @param {number} far Far bound of the frustum\n * @returns {mat4} out\n */\n\nfunction orthoZO(out, left, right, bottom, top, near, far) {\n  var lr = 1 / (left - right);\n  var bt = 1 / (bottom - top);\n  var nf = 1 / (near - far);\n  out[0] = -2 * lr;\n  out[1] = 0;\n  out[2] = 0;\n  out[3] = 0;\n  out[4] = 0;\n  out[5] = -2 * bt;\n  out[6] = 0;\n  out[7] = 0;\n  out[8] = 0;\n  out[9] = 0;\n  out[10] = nf;\n  out[11] = 0;\n  out[12] = (left + right) * lr;\n  out[13] = (top + bottom) * bt;\n  out[14] = near * nf;\n  out[15] = 1;\n  return out;\n}\n/**\n * Generates a look-at matrix with the given eye position, focal point, and up axis.\n * If you want a matrix that actually makes an object look at another object, you should use targetTo instead.\n *\n * @param {mat4} out mat4 frustum matrix will be written into\n * @param {ReadonlyVec3} eye Position of the viewer\n * @param {ReadonlyVec3} center Point the viewer is looking at\n * @param {ReadonlyVec3} up vec3 pointing up\n * @returns {mat4} out\n */\n\nfunction lookAt(out, eye, center, up) {\n  var x0, x1, x2, y0, y1, y2, z0, z1, z2, len;\n  var eyex = eye[0];\n  var eyey = eye[1];\n  var eyez = eye[2];\n  var upx = up[0];\n  var upy = up[1];\n  var upz = up[2];\n  var centerx = center[0];\n  var centery = center[1];\n  var centerz = center[2];\n\n  if (Math.abs(eyex - centerx) < _common_js__WEBPACK_IMPORTED_MODULE_0__.EPSILON && Math.abs(eyey - centery) < _common_js__WEBPACK_IMPORTED_MODULE_0__.EPSILON && Math.abs(eyez - centerz) < _common_js__WEBPACK_IMPORTED_MODULE_0__.EPSILON) {\n    return identity(out);\n  }\n\n  z0 = eyex - centerx;\n  z1 = eyey - centery;\n  z2 = eyez - centerz;\n  len = 1 / Math.hypot(z0, z1, z2);\n  z0 *= len;\n  z1 *= len;\n  z2 *= len;\n  x0 = upy * z2 - upz * z1;\n  x1 = upz * z0 - upx * z2;\n  x2 = upx * z1 - upy * z0;\n  len = Math.hypot(x0, x1, x2);\n\n  if (!len) {\n    x0 = 0;\n    x1 = 0;\n    x2 = 0;\n  } else {\n    len = 1 / len;\n    x0 *= len;\n    x1 *= len;\n    x2 *= len;\n  }\n\n  y0 = z1 * x2 - z2 * x1;\n  y1 = z2 * x0 - z0 * x2;\n  y2 = z0 * x1 - z1 * x0;\n  len = Math.hypot(y0, y1, y2);\n\n  if (!len) {\n    y0 = 0;\n    y1 = 0;\n    y2 = 0;\n  } else {\n    len = 1 / len;\n    y0 *= len;\n    y1 *= len;\n    y2 *= len;\n  }\n\n  out[0] = x0;\n  out[1] = y0;\n  out[2] = z0;\n  out[3] = 0;\n  out[4] = x1;\n  out[5] = y1;\n  out[6] = z1;\n  out[7] = 0;\n  out[8] = x2;\n  out[9] = y2;\n  out[10] = z2;\n  out[11] = 0;\n  out[12] = -(x0 * eyex + x1 * eyey + x2 * eyez);\n  out[13] = -(y0 * eyex + y1 * eyey + y2 * eyez);\n  out[14] = -(z0 * eyex + z1 * eyey + z2 * eyez);\n  out[15] = 1;\n  return out;\n}\n/**\n * Generates a matrix that makes something look at something else.\n *\n * @param {mat4} out mat4 frustum matrix will be written into\n * @param {ReadonlyVec3} eye Position of the viewer\n * @param {ReadonlyVec3} center Point the viewer is looking at\n * @param {ReadonlyVec3} up vec3 pointing up\n * @returns {mat4} out\n */\n\nfunction targetTo(out, eye, target, up) {\n  var eyex = eye[0],\n      eyey = eye[1],\n      eyez = eye[2],\n      upx = up[0],\n      upy = up[1],\n      upz = up[2];\n  var z0 = eyex - target[0],\n      z1 = eyey - target[1],\n      z2 = eyez - target[2];\n  var len = z0 * z0 + z1 * z1 + z2 * z2;\n\n  if (len > 0) {\n    len = 1 / Math.sqrt(len);\n    z0 *= len;\n    z1 *= len;\n    z2 *= len;\n  }\n\n  var x0 = upy * z2 - upz * z1,\n      x1 = upz * z0 - upx * z2,\n      x2 = upx * z1 - upy * z0;\n  len = x0 * x0 + x1 * x1 + x2 * x2;\n\n  if (len > 0) {\n    len = 1 / Math.sqrt(len);\n    x0 *= len;\n    x1 *= len;\n    x2 *= len;\n  }\n\n  out[0] = x0;\n  out[1] = x1;\n  out[2] = x2;\n  out[3] = 0;\n  out[4] = z1 * x2 - z2 * x1;\n  out[5] = z2 * x0 - z0 * x2;\n  out[6] = z0 * x1 - z1 * x0;\n  out[7] = 0;\n  out[8] = z0;\n  out[9] = z1;\n  out[10] = z2;\n  out[11] = 0;\n  out[12] = eyex;\n  out[13] = eyey;\n  out[14] = eyez;\n  out[15] = 1;\n  return out;\n}\n/**\n * Returns a string representation of a mat4\n *\n * @param {ReadonlyMat4} a matrix to represent as a string\n * @returns {String} string representation of the matrix\n */\n\nfunction str(a) {\n  return \"mat4(\" + a[0] + \", \" + a[1] + \", \" + a[2] + \", \" + a[3] + \", \" + a[4] + \", \" + a[5] + \", \" + a[6] + \", \" + a[7] + \", \" + a[8] + \", \" + a[9] + \", \" + a[10] + \", \" + a[11] + \", \" + a[12] + \", \" + a[13] + \", \" + a[14] + \", \" + a[15] + \")\";\n}\n/**\n * Returns Frobenius norm of a mat4\n *\n * @param {ReadonlyMat4} a the matrix to calculate Frobenius norm of\n * @returns {Number} Frobenius norm\n */\n\nfunction frob(a) {\n  return Math.hypot(a[0], a[1], a[2], a[3], a[4], a[5], a[6], a[7], a[8], a[9], a[10], a[11], a[12], a[13], a[14], a[15]);\n}\n/**\n * Adds two mat4's\n *\n * @param {mat4} out the receiving matrix\n * @param {ReadonlyMat4} a the first operand\n * @param {ReadonlyMat4} b the second operand\n * @returns {mat4} out\n */\n\nfunction add(out, a, b) {\n  out[0] = a[0] + b[0];\n  out[1] = a[1] + b[1];\n  out[2] = a[2] + b[2];\n  out[3] = a[3] + b[3];\n  out[4] = a[4] + b[4];\n  out[5] = a[5] + b[5];\n  out[6] = a[6] + b[6];\n  out[7] = a[7] + b[7];\n  out[8] = a[8] + b[8];\n  out[9] = a[9] + b[9];\n  out[10] = a[10] + b[10];\n  out[11] = a[11] + b[11];\n  out[12] = a[12] + b[12];\n  out[13] = a[13] + b[13];\n  out[14] = a[14] + b[14];\n  out[15] = a[15] + b[15];\n  return out;\n}\n/**\n * Subtracts matrix b from matrix a\n *\n * @param {mat4} out the receiving matrix\n * @param {ReadonlyMat4} a the first operand\n * @param {ReadonlyMat4} b the second operand\n * @returns {mat4} out\n */\n\nfunction subtract(out, a, b) {\n  out[0] = a[0] - b[0];\n  out[1] = a[1] - b[1];\n  out[2] = a[2] - b[2];\n  out[3] = a[3] - b[3];\n  out[4] = a[4] - b[4];\n  out[5] = a[5] - b[5];\n  out[6] = a[6] - b[6];\n  out[7] = a[7] - b[7];\n  out[8] = a[8] - b[8];\n  out[9] = a[9] - b[9];\n  out[10] = a[10] - b[10];\n  out[11] = a[11] - b[11];\n  out[12] = a[12] - b[12];\n  out[13] = a[13] - b[13];\n  out[14] = a[14] - b[14];\n  out[15] = a[15] - b[15];\n  return out;\n}\n/**\n * Multiply each element of the matrix by a scalar.\n *\n * @param {mat4} out the receiving matrix\n * @param {ReadonlyMat4} a the matrix to scale\n * @param {Number} b amount to scale the matrix's elements by\n * @returns {mat4} out\n */\n\nfunction multiplyScalar(out, a, b) {\n  out[0] = a[0] * b;\n  out[1] = a[1] * b;\n  out[2] = a[2] * b;\n  out[3] = a[3] * b;\n  out[4] = a[4] * b;\n  out[5] = a[5] * b;\n  out[6] = a[6] * b;\n  out[7] = a[7] * b;\n  out[8] = a[8] * b;\n  out[9] = a[9] * b;\n  out[10] = a[10] * b;\n  out[11] = a[11] * b;\n  out[12] = a[12] * b;\n  out[13] = a[13] * b;\n  out[14] = a[14] * b;\n  out[15] = a[15] * b;\n  return out;\n}\n/**\n * Adds two mat4's after multiplying each element of the second operand by a scalar value.\n *\n * @param {mat4} out the receiving vector\n * @param {ReadonlyMat4} a the first operand\n * @param {ReadonlyMat4} b the second operand\n * @param {Number} scale the amount to scale b's elements by before adding\n * @returns {mat4} out\n */\n\nfunction multiplyScalarAndAdd(out, a, b, scale) {\n  out[0] = a[0] + b[0] * scale;\n  out[1] = a[1] + b[1] * scale;\n  out[2] = a[2] + b[2] * scale;\n  out[3] = a[3] + b[3] * scale;\n  out[4] = a[4] + b[4] * scale;\n  out[5] = a[5] + b[5] * scale;\n  out[6] = a[6] + b[6] * scale;\n  out[7] = a[7] + b[7] * scale;\n  out[8] = a[8] + b[8] * scale;\n  out[9] = a[9] + b[9] * scale;\n  out[10] = a[10] + b[10] * scale;\n  out[11] = a[11] + b[11] * scale;\n  out[12] = a[12] + b[12] * scale;\n  out[13] = a[13] + b[13] * scale;\n  out[14] = a[14] + b[14] * scale;\n  out[15] = a[15] + b[15] * scale;\n  return out;\n}\n/**\n * Returns whether or not the matrices have exactly the same elements in the same position (when compared with ===)\n *\n * @param {ReadonlyMat4} a The first matrix.\n * @param {ReadonlyMat4} b The second matrix.\n * @returns {Boolean} True if the matrices are equal, false otherwise.\n */\n\nfunction exactEquals(a, b) {\n  return a[0] === b[0] && a[1] === b[1] && a[2] === b[2] && a[3] === b[3] && a[4] === b[4] && a[5] === b[5] && a[6] === b[6] && a[7] === b[7] && a[8] === b[8] && a[9] === b[9] && a[10] === b[10] && a[11] === b[11] && a[12] === b[12] && a[13] === b[13] && a[14] === b[14] && a[15] === b[15];\n}\n/**\n * Returns whether or not the matrices have approximately the same elements in the same position.\n *\n * @param {ReadonlyMat4} a The first matrix.\n * @param {ReadonlyMat4} b The second matrix.\n * @returns {Boolean} True if the matrices are equal, false otherwise.\n */\n\nfunction equals(a, b) {\n  var a0 = a[0],\n      a1 = a[1],\n      a2 = a[2],\n      a3 = a[3];\n  var a4 = a[4],\n      a5 = a[5],\n      a6 = a[6],\n      a7 = a[7];\n  var a8 = a[8],\n      a9 = a[9],\n      a10 = a[10],\n      a11 = a[11];\n  var a12 = a[12],\n      a13 = a[13],\n      a14 = a[14],\n      a15 = a[15];\n  var b0 = b[0],\n      b1 = b[1],\n      b2 = b[2],\n      b3 = b[3];\n  var b4 = b[4],\n      b5 = b[5],\n      b6 = b[6],\n      b7 = b[7];\n  var b8 = b[8],\n      b9 = b[9],\n      b10 = b[10],\n      b11 = b[11];\n  var b12 = b[12],\n      b13 = b[13],\n      b14 = b[14],\n      b15 = b[15];\n  return Math.abs(a0 - b0) <= _common_js__WEBPACK_IMPORTED_MODULE_0__.EPSILON * Math.max(1.0, Math.abs(a0), Math.abs(b0)) && Math.abs(a1 - b1) <= _common_js__WEBPACK_IMPORTED_MODULE_0__.EPSILON * Math.max(1.0, Math.abs(a1), Math.abs(b1)) && Math.abs(a2 - b2) <= _common_js__WEBPACK_IMPORTED_MODULE_0__.EPSILON * Math.max(1.0, Math.abs(a2), Math.abs(b2)) && Math.abs(a3 - b3) <= _common_js__WEBPACK_IMPORTED_MODULE_0__.EPSILON * Math.max(1.0, Math.abs(a3), Math.abs(b3)) && Math.abs(a4 - b4) <= _common_js__WEBPACK_IMPORTED_MODULE_0__.EPSILON * Math.max(1.0, Math.abs(a4), Math.abs(b4)) && Math.abs(a5 - b5) <= _common_js__WEBPACK_IMPORTED_MODULE_0__.EPSILON * Math.max(1.0, Math.abs(a5), Math.abs(b5)) && Math.abs(a6 - b6) <= _common_js__WEBPACK_IMPORTED_MODULE_0__.EPSILON * Math.max(1.0, Math.abs(a6), Math.abs(b6)) && Math.abs(a7 - b7) <= _common_js__WEBPACK_IMPORTED_MODULE_0__.EPSILON * Math.max(1.0, Math.abs(a7), Math.abs(b7)) && Math.abs(a8 - b8) <= _common_js__WEBPACK_IMPORTED_MODULE_0__.EPSILON * Math.max(1.0, Math.abs(a8), Math.abs(b8)) && Math.abs(a9 - b9) <= _common_js__WEBPACK_IMPORTED_MODULE_0__.EPSILON * Math.max(1.0, Math.abs(a9), Math.abs(b9)) && Math.abs(a10 - b10) <= _common_js__WEBPACK_IMPORTED_MODULE_0__.EPSILON * Math.max(1.0, Math.abs(a10), Math.abs(b10)) && Math.abs(a11 - b11) <= _common_js__WEBPACK_IMPORTED_MODULE_0__.EPSILON * Math.max(1.0, Math.abs(a11), Math.abs(b11)) && Math.abs(a12 - b12) <= _common_js__WEBPACK_IMPORTED_MODULE_0__.EPSILON * Math.max(1.0, Math.abs(a12), Math.abs(b12)) && Math.abs(a13 - b13) <= _common_js__WEBPACK_IMPORTED_MODULE_0__.EPSILON * Math.max(1.0, Math.abs(a13), Math.abs(b13)) && Math.abs(a14 - b14) <= _common_js__WEBPACK_IMPORTED_MODULE_0__.EPSILON * Math.max(1.0, Math.abs(a14), Math.abs(b14)) && Math.abs(a15 - b15) <= _common_js__WEBPACK_IMPORTED_MODULE_0__.EPSILON * Math.max(1.0, Math.abs(a15), Math.abs(b15));\n}\n/**\n * Alias for {@link mat4.multiply}\n * @function\n */\n\nvar mul = multiply;\n/**\n * Alias for {@link mat4.subtract}\n * @function\n */\n\nvar sub = subtract;\n\n//# sourceURL=webpack://semanticfinder/./node_modules/gl-matrix/esm/mat4.js?");

/***/ }),

/***/ "./node_modules/gl-matrix/esm/vec2.js":
/*!********************************************!*\
  !*** ./node_modules/gl-matrix/esm/vec2.js ***!
  \********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   add: () => (/* binding */ add),\n/* harmony export */   angle: () => (/* binding */ angle),\n/* harmony export */   ceil: () => (/* binding */ ceil),\n/* harmony export */   clone: () => (/* binding */ clone),\n/* harmony export */   copy: () => (/* binding */ copy),\n/* harmony export */   create: () => (/* binding */ create),\n/* harmony export */   cross: () => (/* binding */ cross),\n/* harmony export */   dist: () => (/* binding */ dist),\n/* harmony export */   distance: () => (/* binding */ distance),\n/* harmony export */   div: () => (/* binding */ div),\n/* harmony export */   divide: () => (/* binding */ divide),\n/* harmony export */   dot: () => (/* binding */ dot),\n/* harmony export */   equals: () => (/* binding */ equals),\n/* harmony export */   exactEquals: () => (/* binding */ exactEquals),\n/* harmony export */   floor: () => (/* binding */ floor),\n/* harmony export */   forEach: () => (/* binding */ forEach),\n/* harmony export */   fromValues: () => (/* binding */ fromValues),\n/* harmony export */   inverse: () => (/* binding */ inverse),\n/* harmony export */   len: () => (/* binding */ len),\n/* harmony export */   length: () => (/* binding */ length),\n/* harmony export */   lerp: () => (/* binding */ lerp),\n/* harmony export */   max: () => (/* binding */ max),\n/* harmony export */   min: () => (/* binding */ min),\n/* harmony export */   mul: () => (/* binding */ mul),\n/* harmony export */   multiply: () => (/* binding */ multiply),\n/* harmony export */   negate: () => (/* binding */ negate),\n/* harmony export */   normalize: () => (/* binding */ normalize),\n/* harmony export */   random: () => (/* binding */ random),\n/* harmony export */   rotate: () => (/* binding */ rotate),\n/* harmony export */   round: () => (/* binding */ round),\n/* harmony export */   scale: () => (/* binding */ scale),\n/* harmony export */   scaleAndAdd: () => (/* binding */ scaleAndAdd),\n/* harmony export */   set: () => (/* binding */ set),\n/* harmony export */   sqrDist: () => (/* binding */ sqrDist),\n/* harmony export */   sqrLen: () => (/* binding */ sqrLen),\n/* harmony export */   squaredDistance: () => (/* binding */ squaredDistance),\n/* harmony export */   squaredLength: () => (/* binding */ squaredLength),\n/* harmony export */   str: () => (/* binding */ str),\n/* harmony export */   sub: () => (/* binding */ sub),\n/* harmony export */   subtract: () => (/* binding */ subtract),\n/* harmony export */   transformMat2: () => (/* binding */ transformMat2),\n/* harmony export */   transformMat2d: () => (/* binding */ transformMat2d),\n/* harmony export */   transformMat3: () => (/* binding */ transformMat3),\n/* harmony export */   transformMat4: () => (/* binding */ transformMat4),\n/* harmony export */   zero: () => (/* binding */ zero)\n/* harmony export */ });\n/* harmony import */ var _common_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./common.js */ \"./node_modules/gl-matrix/esm/common.js\");\n\n/**\n * 2 Dimensional Vector\n * @module vec2\n */\n\n/**\n * Creates a new, empty vec2\n *\n * @returns {vec2} a new 2D vector\n */\n\nfunction create() {\n  var out = new _common_js__WEBPACK_IMPORTED_MODULE_0__.ARRAY_TYPE(2);\n\n  if (_common_js__WEBPACK_IMPORTED_MODULE_0__.ARRAY_TYPE != Float32Array) {\n    out[0] = 0;\n    out[1] = 0;\n  }\n\n  return out;\n}\n/**\n * Creates a new vec2 initialized with values from an existing vector\n *\n * @param {ReadonlyVec2} a vector to clone\n * @returns {vec2} a new 2D vector\n */\n\nfunction clone(a) {\n  var out = new _common_js__WEBPACK_IMPORTED_MODULE_0__.ARRAY_TYPE(2);\n  out[0] = a[0];\n  out[1] = a[1];\n  return out;\n}\n/**\n * Creates a new vec2 initialized with the given values\n *\n * @param {Number} x X component\n * @param {Number} y Y component\n * @returns {vec2} a new 2D vector\n */\n\nfunction fromValues(x, y) {\n  var out = new _common_js__WEBPACK_IMPORTED_MODULE_0__.ARRAY_TYPE(2);\n  out[0] = x;\n  out[1] = y;\n  return out;\n}\n/**\n * Copy the values from one vec2 to another\n *\n * @param {vec2} out the receiving vector\n * @param {ReadonlyVec2} a the source vector\n * @returns {vec2} out\n */\n\nfunction copy(out, a) {\n  out[0] = a[0];\n  out[1] = a[1];\n  return out;\n}\n/**\n * Set the components of a vec2 to the given values\n *\n * @param {vec2} out the receiving vector\n * @param {Number} x X component\n * @param {Number} y Y component\n * @returns {vec2} out\n */\n\nfunction set(out, x, y) {\n  out[0] = x;\n  out[1] = y;\n  return out;\n}\n/**\n * Adds two vec2's\n *\n * @param {vec2} out the receiving vector\n * @param {ReadonlyVec2} a the first operand\n * @param {ReadonlyVec2} b the second operand\n * @returns {vec2} out\n */\n\nfunction add(out, a, b) {\n  out[0] = a[0] + b[0];\n  out[1] = a[1] + b[1];\n  return out;\n}\n/**\n * Subtracts vector b from vector a\n *\n * @param {vec2} out the receiving vector\n * @param {ReadonlyVec2} a the first operand\n * @param {ReadonlyVec2} b the second operand\n * @returns {vec2} out\n */\n\nfunction subtract(out, a, b) {\n  out[0] = a[0] - b[0];\n  out[1] = a[1] - b[1];\n  return out;\n}\n/**\n * Multiplies two vec2's\n *\n * @param {vec2} out the receiving vector\n * @param {ReadonlyVec2} a the first operand\n * @param {ReadonlyVec2} b the second operand\n * @returns {vec2} out\n */\n\nfunction multiply(out, a, b) {\n  out[0] = a[0] * b[0];\n  out[1] = a[1] * b[1];\n  return out;\n}\n/**\n * Divides two vec2's\n *\n * @param {vec2} out the receiving vector\n * @param {ReadonlyVec2} a the first operand\n * @param {ReadonlyVec2} b the second operand\n * @returns {vec2} out\n */\n\nfunction divide(out, a, b) {\n  out[0] = a[0] / b[0];\n  out[1] = a[1] / b[1];\n  return out;\n}\n/**\n * Math.ceil the components of a vec2\n *\n * @param {vec2} out the receiving vector\n * @param {ReadonlyVec2} a vector to ceil\n * @returns {vec2} out\n */\n\nfunction ceil(out, a) {\n  out[0] = Math.ceil(a[0]);\n  out[1] = Math.ceil(a[1]);\n  return out;\n}\n/**\n * Math.floor the components of a vec2\n *\n * @param {vec2} out the receiving vector\n * @param {ReadonlyVec2} a vector to floor\n * @returns {vec2} out\n */\n\nfunction floor(out, a) {\n  out[0] = Math.floor(a[0]);\n  out[1] = Math.floor(a[1]);\n  return out;\n}\n/**\n * Returns the minimum of two vec2's\n *\n * @param {vec2} out the receiving vector\n * @param {ReadonlyVec2} a the first operand\n * @param {ReadonlyVec2} b the second operand\n * @returns {vec2} out\n */\n\nfunction min(out, a, b) {\n  out[0] = Math.min(a[0], b[0]);\n  out[1] = Math.min(a[1], b[1]);\n  return out;\n}\n/**\n * Returns the maximum of two vec2's\n *\n * @param {vec2} out the receiving vector\n * @param {ReadonlyVec2} a the first operand\n * @param {ReadonlyVec2} b the second operand\n * @returns {vec2} out\n */\n\nfunction max(out, a, b) {\n  out[0] = Math.max(a[0], b[0]);\n  out[1] = Math.max(a[1], b[1]);\n  return out;\n}\n/**\n * Math.round the components of a vec2\n *\n * @param {vec2} out the receiving vector\n * @param {ReadonlyVec2} a vector to round\n * @returns {vec2} out\n */\n\nfunction round(out, a) {\n  out[0] = Math.round(a[0]);\n  out[1] = Math.round(a[1]);\n  return out;\n}\n/**\n * Scales a vec2 by a scalar number\n *\n * @param {vec2} out the receiving vector\n * @param {ReadonlyVec2} a the vector to scale\n * @param {Number} b amount to scale the vector by\n * @returns {vec2} out\n */\n\nfunction scale(out, a, b) {\n  out[0] = a[0] * b;\n  out[1] = a[1] * b;\n  return out;\n}\n/**\n * Adds two vec2's after scaling the second operand by a scalar value\n *\n * @param {vec2} out the receiving vector\n * @param {ReadonlyVec2} a the first operand\n * @param {ReadonlyVec2} b the second operand\n * @param {Number} scale the amount to scale b by before adding\n * @returns {vec2} out\n */\n\nfunction scaleAndAdd(out, a, b, scale) {\n  out[0] = a[0] + b[0] * scale;\n  out[1] = a[1] + b[1] * scale;\n  return out;\n}\n/**\n * Calculates the euclidian distance between two vec2's\n *\n * @param {ReadonlyVec2} a the first operand\n * @param {ReadonlyVec2} b the second operand\n * @returns {Number} distance between a and b\n */\n\nfunction distance(a, b) {\n  var x = b[0] - a[0],\n      y = b[1] - a[1];\n  return Math.hypot(x, y);\n}\n/**\n * Calculates the squared euclidian distance between two vec2's\n *\n * @param {ReadonlyVec2} a the first operand\n * @param {ReadonlyVec2} b the second operand\n * @returns {Number} squared distance between a and b\n */\n\nfunction squaredDistance(a, b) {\n  var x = b[0] - a[0],\n      y = b[1] - a[1];\n  return x * x + y * y;\n}\n/**\n * Calculates the length of a vec2\n *\n * @param {ReadonlyVec2} a vector to calculate length of\n * @returns {Number} length of a\n */\n\nfunction length(a) {\n  var x = a[0],\n      y = a[1];\n  return Math.hypot(x, y);\n}\n/**\n * Calculates the squared length of a vec2\n *\n * @param {ReadonlyVec2} a vector to calculate squared length of\n * @returns {Number} squared length of a\n */\n\nfunction squaredLength(a) {\n  var x = a[0],\n      y = a[1];\n  return x * x + y * y;\n}\n/**\n * Negates the components of a vec2\n *\n * @param {vec2} out the receiving vector\n * @param {ReadonlyVec2} a vector to negate\n * @returns {vec2} out\n */\n\nfunction negate(out, a) {\n  out[0] = -a[0];\n  out[1] = -a[1];\n  return out;\n}\n/**\n * Returns the inverse of the components of a vec2\n *\n * @param {vec2} out the receiving vector\n * @param {ReadonlyVec2} a vector to invert\n * @returns {vec2} out\n */\n\nfunction inverse(out, a) {\n  out[0] = 1.0 / a[0];\n  out[1] = 1.0 / a[1];\n  return out;\n}\n/**\n * Normalize a vec2\n *\n * @param {vec2} out the receiving vector\n * @param {ReadonlyVec2} a vector to normalize\n * @returns {vec2} out\n */\n\nfunction normalize(out, a) {\n  var x = a[0],\n      y = a[1];\n  var len = x * x + y * y;\n\n  if (len > 0) {\n    //TODO: evaluate use of glm_invsqrt here?\n    len = 1 / Math.sqrt(len);\n  }\n\n  out[0] = a[0] * len;\n  out[1] = a[1] * len;\n  return out;\n}\n/**\n * Calculates the dot product of two vec2's\n *\n * @param {ReadonlyVec2} a the first operand\n * @param {ReadonlyVec2} b the second operand\n * @returns {Number} dot product of a and b\n */\n\nfunction dot(a, b) {\n  return a[0] * b[0] + a[1] * b[1];\n}\n/**\n * Computes the cross product of two vec2's\n * Note that the cross product must by definition produce a 3D vector\n *\n * @param {vec3} out the receiving vector\n * @param {ReadonlyVec2} a the first operand\n * @param {ReadonlyVec2} b the second operand\n * @returns {vec3} out\n */\n\nfunction cross(out, a, b) {\n  var z = a[0] * b[1] - a[1] * b[0];\n  out[0] = out[1] = 0;\n  out[2] = z;\n  return out;\n}\n/**\n * Performs a linear interpolation between two vec2's\n *\n * @param {vec2} out the receiving vector\n * @param {ReadonlyVec2} a the first operand\n * @param {ReadonlyVec2} b the second operand\n * @param {Number} t interpolation amount, in the range [0-1], between the two inputs\n * @returns {vec2} out\n */\n\nfunction lerp(out, a, b, t) {\n  var ax = a[0],\n      ay = a[1];\n  out[0] = ax + t * (b[0] - ax);\n  out[1] = ay + t * (b[1] - ay);\n  return out;\n}\n/**\n * Generates a random vector with the given scale\n *\n * @param {vec2} out the receiving vector\n * @param {Number} [scale] Length of the resulting vector. If ommitted, a unit vector will be returned\n * @returns {vec2} out\n */\n\nfunction random(out, scale) {\n  scale = scale || 1.0;\n  var r = _common_js__WEBPACK_IMPORTED_MODULE_0__.RANDOM() * 2.0 * Math.PI;\n  out[0] = Math.cos(r) * scale;\n  out[1] = Math.sin(r) * scale;\n  return out;\n}\n/**\n * Transforms the vec2 with a mat2\n *\n * @param {vec2} out the receiving vector\n * @param {ReadonlyVec2} a the vector to transform\n * @param {ReadonlyMat2} m matrix to transform with\n * @returns {vec2} out\n */\n\nfunction transformMat2(out, a, m) {\n  var x = a[0],\n      y = a[1];\n  out[0] = m[0] * x + m[2] * y;\n  out[1] = m[1] * x + m[3] * y;\n  return out;\n}\n/**\n * Transforms the vec2 with a mat2d\n *\n * @param {vec2} out the receiving vector\n * @param {ReadonlyVec2} a the vector to transform\n * @param {ReadonlyMat2d} m matrix to transform with\n * @returns {vec2} out\n */\n\nfunction transformMat2d(out, a, m) {\n  var x = a[0],\n      y = a[1];\n  out[0] = m[0] * x + m[2] * y + m[4];\n  out[1] = m[1] * x + m[3] * y + m[5];\n  return out;\n}\n/**\n * Transforms the vec2 with a mat3\n * 3rd vector component is implicitly '1'\n *\n * @param {vec2} out the receiving vector\n * @param {ReadonlyVec2} a the vector to transform\n * @param {ReadonlyMat3} m matrix to transform with\n * @returns {vec2} out\n */\n\nfunction transformMat3(out, a, m) {\n  var x = a[0],\n      y = a[1];\n  out[0] = m[0] * x + m[3] * y + m[6];\n  out[1] = m[1] * x + m[4] * y + m[7];\n  return out;\n}\n/**\n * Transforms the vec2 with a mat4\n * 3rd vector component is implicitly '0'\n * 4th vector component is implicitly '1'\n *\n * @param {vec2} out the receiving vector\n * @param {ReadonlyVec2} a the vector to transform\n * @param {ReadonlyMat4} m matrix to transform with\n * @returns {vec2} out\n */\n\nfunction transformMat4(out, a, m) {\n  var x = a[0];\n  var y = a[1];\n  out[0] = m[0] * x + m[4] * y + m[12];\n  out[1] = m[1] * x + m[5] * y + m[13];\n  return out;\n}\n/**\n * Rotate a 2D vector\n * @param {vec2} out The receiving vec2\n * @param {ReadonlyVec2} a The vec2 point to rotate\n * @param {ReadonlyVec2} b The origin of the rotation\n * @param {Number} rad The angle of rotation in radians\n * @returns {vec2} out\n */\n\nfunction rotate(out, a, b, rad) {\n  //Translate point to the origin\n  var p0 = a[0] - b[0],\n      p1 = a[1] - b[1],\n      sinC = Math.sin(rad),\n      cosC = Math.cos(rad); //perform rotation and translate to correct position\n\n  out[0] = p0 * cosC - p1 * sinC + b[0];\n  out[1] = p0 * sinC + p1 * cosC + b[1];\n  return out;\n}\n/**\n * Get the angle between two 2D vectors\n * @param {ReadonlyVec2} a The first operand\n * @param {ReadonlyVec2} b The second operand\n * @returns {Number} The angle in radians\n */\n\nfunction angle(a, b) {\n  var x1 = a[0],\n      y1 = a[1],\n      x2 = b[0],\n      y2 = b[1],\n      // mag is the product of the magnitudes of a and b\n  mag = Math.sqrt(x1 * x1 + y1 * y1) * Math.sqrt(x2 * x2 + y2 * y2),\n      // mag &&.. short circuits if mag == 0\n  cosine = mag && (x1 * x2 + y1 * y2) / mag; // Math.min(Math.max(cosine, -1), 1) clamps the cosine between -1 and 1\n\n  return Math.acos(Math.min(Math.max(cosine, -1), 1));\n}\n/**\n * Set the components of a vec2 to zero\n *\n * @param {vec2} out the receiving vector\n * @returns {vec2} out\n */\n\nfunction zero(out) {\n  out[0] = 0.0;\n  out[1] = 0.0;\n  return out;\n}\n/**\n * Returns a string representation of a vector\n *\n * @param {ReadonlyVec2} a vector to represent as a string\n * @returns {String} string representation of the vector\n */\n\nfunction str(a) {\n  return \"vec2(\" + a[0] + \", \" + a[1] + \")\";\n}\n/**\n * Returns whether or not the vectors exactly have the same elements in the same position (when compared with ===)\n *\n * @param {ReadonlyVec2} a The first vector.\n * @param {ReadonlyVec2} b The second vector.\n * @returns {Boolean} True if the vectors are equal, false otherwise.\n */\n\nfunction exactEquals(a, b) {\n  return a[0] === b[0] && a[1] === b[1];\n}\n/**\n * Returns whether or not the vectors have approximately the same elements in the same position.\n *\n * @param {ReadonlyVec2} a The first vector.\n * @param {ReadonlyVec2} b The second vector.\n * @returns {Boolean} True if the vectors are equal, false otherwise.\n */\n\nfunction equals(a, b) {\n  var a0 = a[0],\n      a1 = a[1];\n  var b0 = b[0],\n      b1 = b[1];\n  return Math.abs(a0 - b0) <= _common_js__WEBPACK_IMPORTED_MODULE_0__.EPSILON * Math.max(1.0, Math.abs(a0), Math.abs(b0)) && Math.abs(a1 - b1) <= _common_js__WEBPACK_IMPORTED_MODULE_0__.EPSILON * Math.max(1.0, Math.abs(a1), Math.abs(b1));\n}\n/**\n * Alias for {@link vec2.length}\n * @function\n */\n\nvar len = length;\n/**\n * Alias for {@link vec2.subtract}\n * @function\n */\n\nvar sub = subtract;\n/**\n * Alias for {@link vec2.multiply}\n * @function\n */\n\nvar mul = multiply;\n/**\n * Alias for {@link vec2.divide}\n * @function\n */\n\nvar div = divide;\n/**\n * Alias for {@link vec2.distance}\n * @function\n */\n\nvar dist = distance;\n/**\n * Alias for {@link vec2.squaredDistance}\n * @function\n */\n\nvar sqrDist = squaredDistance;\n/**\n * Alias for {@link vec2.squaredLength}\n * @function\n */\n\nvar sqrLen = squaredLength;\n/**\n * Perform some operation over an array of vec2s.\n *\n * @param {Array} a the array of vectors to iterate over\n * @param {Number} stride Number of elements between the start of each vec2. If 0 assumes tightly packed\n * @param {Number} offset Number of elements to skip at the beginning of the array\n * @param {Number} count Number of vec2s to iterate over. If 0 iterates over entire array\n * @param {Function} fn Function to call for each vector in the array\n * @param {Object} [arg] additional argument to pass to fn\n * @returns {Array} a\n * @function\n */\n\nvar forEach = function () {\n  var vec = create();\n  return function (a, stride, offset, count, fn, arg) {\n    var i, l;\n\n    if (!stride) {\n      stride = 2;\n    }\n\n    if (!offset) {\n      offset = 0;\n    }\n\n    if (count) {\n      l = Math.min(count * stride + offset, a.length);\n    } else {\n      l = a.length;\n    }\n\n    for (i = offset; i < l; i += stride) {\n      vec[0] = a[i];\n      vec[1] = a[i + 1];\n      fn(vec, vec, arg);\n      a[i] = vec[0];\n      a[i + 1] = vec[1];\n    }\n\n    return a;\n  };\n}();\n\n//# sourceURL=webpack://semanticfinder/./node_modules/gl-matrix/esm/vec2.js?");

/***/ }),

/***/ "./node_modules/gl-matrix/esm/vec3.js":
/*!********************************************!*\
  !*** ./node_modules/gl-matrix/esm/vec3.js ***!
  \********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   add: () => (/* binding */ add),\n/* harmony export */   angle: () => (/* binding */ angle),\n/* harmony export */   bezier: () => (/* binding */ bezier),\n/* harmony export */   ceil: () => (/* binding */ ceil),\n/* harmony export */   clone: () => (/* binding */ clone),\n/* harmony export */   copy: () => (/* binding */ copy),\n/* harmony export */   create: () => (/* binding */ create),\n/* harmony export */   cross: () => (/* binding */ cross),\n/* harmony export */   dist: () => (/* binding */ dist),\n/* harmony export */   distance: () => (/* binding */ distance),\n/* harmony export */   div: () => (/* binding */ div),\n/* harmony export */   divide: () => (/* binding */ divide),\n/* harmony export */   dot: () => (/* binding */ dot),\n/* harmony export */   equals: () => (/* binding */ equals),\n/* harmony export */   exactEquals: () => (/* binding */ exactEquals),\n/* harmony export */   floor: () => (/* binding */ floor),\n/* harmony export */   forEach: () => (/* binding */ forEach),\n/* harmony export */   fromValues: () => (/* binding */ fromValues),\n/* harmony export */   hermite: () => (/* binding */ hermite),\n/* harmony export */   inverse: () => (/* binding */ inverse),\n/* harmony export */   len: () => (/* binding */ len),\n/* harmony export */   length: () => (/* binding */ length),\n/* harmony export */   lerp: () => (/* binding */ lerp),\n/* harmony export */   max: () => (/* binding */ max),\n/* harmony export */   min: () => (/* binding */ min),\n/* harmony export */   mul: () => (/* binding */ mul),\n/* harmony export */   multiply: () => (/* binding */ multiply),\n/* harmony export */   negate: () => (/* binding */ negate),\n/* harmony export */   normalize: () => (/* binding */ normalize),\n/* harmony export */   random: () => (/* binding */ random),\n/* harmony export */   rotateX: () => (/* binding */ rotateX),\n/* harmony export */   rotateY: () => (/* binding */ rotateY),\n/* harmony export */   rotateZ: () => (/* binding */ rotateZ),\n/* harmony export */   round: () => (/* binding */ round),\n/* harmony export */   scale: () => (/* binding */ scale),\n/* harmony export */   scaleAndAdd: () => (/* binding */ scaleAndAdd),\n/* harmony export */   set: () => (/* binding */ set),\n/* harmony export */   sqrDist: () => (/* binding */ sqrDist),\n/* harmony export */   sqrLen: () => (/* binding */ sqrLen),\n/* harmony export */   squaredDistance: () => (/* binding */ squaredDistance),\n/* harmony export */   squaredLength: () => (/* binding */ squaredLength),\n/* harmony export */   str: () => (/* binding */ str),\n/* harmony export */   sub: () => (/* binding */ sub),\n/* harmony export */   subtract: () => (/* binding */ subtract),\n/* harmony export */   transformMat3: () => (/* binding */ transformMat3),\n/* harmony export */   transformMat4: () => (/* binding */ transformMat4),\n/* harmony export */   transformQuat: () => (/* binding */ transformQuat),\n/* harmony export */   zero: () => (/* binding */ zero)\n/* harmony export */ });\n/* harmony import */ var _common_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./common.js */ \"./node_modules/gl-matrix/esm/common.js\");\n\n/**\n * 3 Dimensional Vector\n * @module vec3\n */\n\n/**\n * Creates a new, empty vec3\n *\n * @returns {vec3} a new 3D vector\n */\n\nfunction create() {\n  var out = new _common_js__WEBPACK_IMPORTED_MODULE_0__.ARRAY_TYPE(3);\n\n  if (_common_js__WEBPACK_IMPORTED_MODULE_0__.ARRAY_TYPE != Float32Array) {\n    out[0] = 0;\n    out[1] = 0;\n    out[2] = 0;\n  }\n\n  return out;\n}\n/**\n * Creates a new vec3 initialized with values from an existing vector\n *\n * @param {ReadonlyVec3} a vector to clone\n * @returns {vec3} a new 3D vector\n */\n\nfunction clone(a) {\n  var out = new _common_js__WEBPACK_IMPORTED_MODULE_0__.ARRAY_TYPE(3);\n  out[0] = a[0];\n  out[1] = a[1];\n  out[2] = a[2];\n  return out;\n}\n/**\n * Calculates the length of a vec3\n *\n * @param {ReadonlyVec3} a vector to calculate length of\n * @returns {Number} length of a\n */\n\nfunction length(a) {\n  var x = a[0];\n  var y = a[1];\n  var z = a[2];\n  return Math.hypot(x, y, z);\n}\n/**\n * Creates a new vec3 initialized with the given values\n *\n * @param {Number} x X component\n * @param {Number} y Y component\n * @param {Number} z Z component\n * @returns {vec3} a new 3D vector\n */\n\nfunction fromValues(x, y, z) {\n  var out = new _common_js__WEBPACK_IMPORTED_MODULE_0__.ARRAY_TYPE(3);\n  out[0] = x;\n  out[1] = y;\n  out[2] = z;\n  return out;\n}\n/**\n * Copy the values from one vec3 to another\n *\n * @param {vec3} out the receiving vector\n * @param {ReadonlyVec3} a the source vector\n * @returns {vec3} out\n */\n\nfunction copy(out, a) {\n  out[0] = a[0];\n  out[1] = a[1];\n  out[2] = a[2];\n  return out;\n}\n/**\n * Set the components of a vec3 to the given values\n *\n * @param {vec3} out the receiving vector\n * @param {Number} x X component\n * @param {Number} y Y component\n * @param {Number} z Z component\n * @returns {vec3} out\n */\n\nfunction set(out, x, y, z) {\n  out[0] = x;\n  out[1] = y;\n  out[2] = z;\n  return out;\n}\n/**\n * Adds two vec3's\n *\n * @param {vec3} out the receiving vector\n * @param {ReadonlyVec3} a the first operand\n * @param {ReadonlyVec3} b the second operand\n * @returns {vec3} out\n */\n\nfunction add(out, a, b) {\n  out[0] = a[0] + b[0];\n  out[1] = a[1] + b[1];\n  out[2] = a[2] + b[2];\n  return out;\n}\n/**\n * Subtracts vector b from vector a\n *\n * @param {vec3} out the receiving vector\n * @param {ReadonlyVec3} a the first operand\n * @param {ReadonlyVec3} b the second operand\n * @returns {vec3} out\n */\n\nfunction subtract(out, a, b) {\n  out[0] = a[0] - b[0];\n  out[1] = a[1] - b[1];\n  out[2] = a[2] - b[2];\n  return out;\n}\n/**\n * Multiplies two vec3's\n *\n * @param {vec3} out the receiving vector\n * @param {ReadonlyVec3} a the first operand\n * @param {ReadonlyVec3} b the second operand\n * @returns {vec3} out\n */\n\nfunction multiply(out, a, b) {\n  out[0] = a[0] * b[0];\n  out[1] = a[1] * b[1];\n  out[2] = a[2] * b[2];\n  return out;\n}\n/**\n * Divides two vec3's\n *\n * @param {vec3} out the receiving vector\n * @param {ReadonlyVec3} a the first operand\n * @param {ReadonlyVec3} b the second operand\n * @returns {vec3} out\n */\n\nfunction divide(out, a, b) {\n  out[0] = a[0] / b[0];\n  out[1] = a[1] / b[1];\n  out[2] = a[2] / b[2];\n  return out;\n}\n/**\n * Math.ceil the components of a vec3\n *\n * @param {vec3} out the receiving vector\n * @param {ReadonlyVec3} a vector to ceil\n * @returns {vec3} out\n */\n\nfunction ceil(out, a) {\n  out[0] = Math.ceil(a[0]);\n  out[1] = Math.ceil(a[1]);\n  out[2] = Math.ceil(a[2]);\n  return out;\n}\n/**\n * Math.floor the components of a vec3\n *\n * @param {vec3} out the receiving vector\n * @param {ReadonlyVec3} a vector to floor\n * @returns {vec3} out\n */\n\nfunction floor(out, a) {\n  out[0] = Math.floor(a[0]);\n  out[1] = Math.floor(a[1]);\n  out[2] = Math.floor(a[2]);\n  return out;\n}\n/**\n * Returns the minimum of two vec3's\n *\n * @param {vec3} out the receiving vector\n * @param {ReadonlyVec3} a the first operand\n * @param {ReadonlyVec3} b the second operand\n * @returns {vec3} out\n */\n\nfunction min(out, a, b) {\n  out[0] = Math.min(a[0], b[0]);\n  out[1] = Math.min(a[1], b[1]);\n  out[2] = Math.min(a[2], b[2]);\n  return out;\n}\n/**\n * Returns the maximum of two vec3's\n *\n * @param {vec3} out the receiving vector\n * @param {ReadonlyVec3} a the first operand\n * @param {ReadonlyVec3} b the second operand\n * @returns {vec3} out\n */\n\nfunction max(out, a, b) {\n  out[0] = Math.max(a[0], b[0]);\n  out[1] = Math.max(a[1], b[1]);\n  out[2] = Math.max(a[2], b[2]);\n  return out;\n}\n/**\n * Math.round the components of a vec3\n *\n * @param {vec3} out the receiving vector\n * @param {ReadonlyVec3} a vector to round\n * @returns {vec3} out\n */\n\nfunction round(out, a) {\n  out[0] = Math.round(a[0]);\n  out[1] = Math.round(a[1]);\n  out[2] = Math.round(a[2]);\n  return out;\n}\n/**\n * Scales a vec3 by a scalar number\n *\n * @param {vec3} out the receiving vector\n * @param {ReadonlyVec3} a the vector to scale\n * @param {Number} b amount to scale the vector by\n * @returns {vec3} out\n */\n\nfunction scale(out, a, b) {\n  out[0] = a[0] * b;\n  out[1] = a[1] * b;\n  out[2] = a[2] * b;\n  return out;\n}\n/**\n * Adds two vec3's after scaling the second operand by a scalar value\n *\n * @param {vec3} out the receiving vector\n * @param {ReadonlyVec3} a the first operand\n * @param {ReadonlyVec3} b the second operand\n * @param {Number} scale the amount to scale b by before adding\n * @returns {vec3} out\n */\n\nfunction scaleAndAdd(out, a, b, scale) {\n  out[0] = a[0] + b[0] * scale;\n  out[1] = a[1] + b[1] * scale;\n  out[2] = a[2] + b[2] * scale;\n  return out;\n}\n/**\n * Calculates the euclidian distance between two vec3's\n *\n * @param {ReadonlyVec3} a the first operand\n * @param {ReadonlyVec3} b the second operand\n * @returns {Number} distance between a and b\n */\n\nfunction distance(a, b) {\n  var x = b[0] - a[0];\n  var y = b[1] - a[1];\n  var z = b[2] - a[2];\n  return Math.hypot(x, y, z);\n}\n/**\n * Calculates the squared euclidian distance between two vec3's\n *\n * @param {ReadonlyVec3} a the first operand\n * @param {ReadonlyVec3} b the second operand\n * @returns {Number} squared distance between a and b\n */\n\nfunction squaredDistance(a, b) {\n  var x = b[0] - a[0];\n  var y = b[1] - a[1];\n  var z = b[2] - a[2];\n  return x * x + y * y + z * z;\n}\n/**\n * Calculates the squared length of a vec3\n *\n * @param {ReadonlyVec3} a vector to calculate squared length of\n * @returns {Number} squared length of a\n */\n\nfunction squaredLength(a) {\n  var x = a[0];\n  var y = a[1];\n  var z = a[2];\n  return x * x + y * y + z * z;\n}\n/**\n * Negates the components of a vec3\n *\n * @param {vec3} out the receiving vector\n * @param {ReadonlyVec3} a vector to negate\n * @returns {vec3} out\n */\n\nfunction negate(out, a) {\n  out[0] = -a[0];\n  out[1] = -a[1];\n  out[2] = -a[2];\n  return out;\n}\n/**\n * Returns the inverse of the components of a vec3\n *\n * @param {vec3} out the receiving vector\n * @param {ReadonlyVec3} a vector to invert\n * @returns {vec3} out\n */\n\nfunction inverse(out, a) {\n  out[0] = 1.0 / a[0];\n  out[1] = 1.0 / a[1];\n  out[2] = 1.0 / a[2];\n  return out;\n}\n/**\n * Normalize a vec3\n *\n * @param {vec3} out the receiving vector\n * @param {ReadonlyVec3} a vector to normalize\n * @returns {vec3} out\n */\n\nfunction normalize(out, a) {\n  var x = a[0];\n  var y = a[1];\n  var z = a[2];\n  var len = x * x + y * y + z * z;\n\n  if (len > 0) {\n    //TODO: evaluate use of glm_invsqrt here?\n    len = 1 / Math.sqrt(len);\n  }\n\n  out[0] = a[0] * len;\n  out[1] = a[1] * len;\n  out[2] = a[2] * len;\n  return out;\n}\n/**\n * Calculates the dot product of two vec3's\n *\n * @param {ReadonlyVec3} a the first operand\n * @param {ReadonlyVec3} b the second operand\n * @returns {Number} dot product of a and b\n */\n\nfunction dot(a, b) {\n  return a[0] * b[0] + a[1] * b[1] + a[2] * b[2];\n}\n/**\n * Computes the cross product of two vec3's\n *\n * @param {vec3} out the receiving vector\n * @param {ReadonlyVec3} a the first operand\n * @param {ReadonlyVec3} b the second operand\n * @returns {vec3} out\n */\n\nfunction cross(out, a, b) {\n  var ax = a[0],\n      ay = a[1],\n      az = a[2];\n  var bx = b[0],\n      by = b[1],\n      bz = b[2];\n  out[0] = ay * bz - az * by;\n  out[1] = az * bx - ax * bz;\n  out[2] = ax * by - ay * bx;\n  return out;\n}\n/**\n * Performs a linear interpolation between two vec3's\n *\n * @param {vec3} out the receiving vector\n * @param {ReadonlyVec3} a the first operand\n * @param {ReadonlyVec3} b the second operand\n * @param {Number} t interpolation amount, in the range [0-1], between the two inputs\n * @returns {vec3} out\n */\n\nfunction lerp(out, a, b, t) {\n  var ax = a[0];\n  var ay = a[1];\n  var az = a[2];\n  out[0] = ax + t * (b[0] - ax);\n  out[1] = ay + t * (b[1] - ay);\n  out[2] = az + t * (b[2] - az);\n  return out;\n}\n/**\n * Performs a hermite interpolation with two control points\n *\n * @param {vec3} out the receiving vector\n * @param {ReadonlyVec3} a the first operand\n * @param {ReadonlyVec3} b the second operand\n * @param {ReadonlyVec3} c the third operand\n * @param {ReadonlyVec3} d the fourth operand\n * @param {Number} t interpolation amount, in the range [0-1], between the two inputs\n * @returns {vec3} out\n */\n\nfunction hermite(out, a, b, c, d, t) {\n  var factorTimes2 = t * t;\n  var factor1 = factorTimes2 * (2 * t - 3) + 1;\n  var factor2 = factorTimes2 * (t - 2) + t;\n  var factor3 = factorTimes2 * (t - 1);\n  var factor4 = factorTimes2 * (3 - 2 * t);\n  out[0] = a[0] * factor1 + b[0] * factor2 + c[0] * factor3 + d[0] * factor4;\n  out[1] = a[1] * factor1 + b[1] * factor2 + c[1] * factor3 + d[1] * factor4;\n  out[2] = a[2] * factor1 + b[2] * factor2 + c[2] * factor3 + d[2] * factor4;\n  return out;\n}\n/**\n * Performs a bezier interpolation with two control points\n *\n * @param {vec3} out the receiving vector\n * @param {ReadonlyVec3} a the first operand\n * @param {ReadonlyVec3} b the second operand\n * @param {ReadonlyVec3} c the third operand\n * @param {ReadonlyVec3} d the fourth operand\n * @param {Number} t interpolation amount, in the range [0-1], between the two inputs\n * @returns {vec3} out\n */\n\nfunction bezier(out, a, b, c, d, t) {\n  var inverseFactor = 1 - t;\n  var inverseFactorTimesTwo = inverseFactor * inverseFactor;\n  var factorTimes2 = t * t;\n  var factor1 = inverseFactorTimesTwo * inverseFactor;\n  var factor2 = 3 * t * inverseFactorTimesTwo;\n  var factor3 = 3 * factorTimes2 * inverseFactor;\n  var factor4 = factorTimes2 * t;\n  out[0] = a[0] * factor1 + b[0] * factor2 + c[0] * factor3 + d[0] * factor4;\n  out[1] = a[1] * factor1 + b[1] * factor2 + c[1] * factor3 + d[1] * factor4;\n  out[2] = a[2] * factor1 + b[2] * factor2 + c[2] * factor3 + d[2] * factor4;\n  return out;\n}\n/**\n * Generates a random vector with the given scale\n *\n * @param {vec3} out the receiving vector\n * @param {Number} [scale] Length of the resulting vector. If ommitted, a unit vector will be returned\n * @returns {vec3} out\n */\n\nfunction random(out, scale) {\n  scale = scale || 1.0;\n  var r = _common_js__WEBPACK_IMPORTED_MODULE_0__.RANDOM() * 2.0 * Math.PI;\n  var z = _common_js__WEBPACK_IMPORTED_MODULE_0__.RANDOM() * 2.0 - 1.0;\n  var zScale = Math.sqrt(1.0 - z * z) * scale;\n  out[0] = Math.cos(r) * zScale;\n  out[1] = Math.sin(r) * zScale;\n  out[2] = z * scale;\n  return out;\n}\n/**\n * Transforms the vec3 with a mat4.\n * 4th vector component is implicitly '1'\n *\n * @param {vec3} out the receiving vector\n * @param {ReadonlyVec3} a the vector to transform\n * @param {ReadonlyMat4} m matrix to transform with\n * @returns {vec3} out\n */\n\nfunction transformMat4(out, a, m) {\n  var x = a[0],\n      y = a[1],\n      z = a[2];\n  var w = m[3] * x + m[7] * y + m[11] * z + m[15];\n  w = w || 1.0;\n  out[0] = (m[0] * x + m[4] * y + m[8] * z + m[12]) / w;\n  out[1] = (m[1] * x + m[5] * y + m[9] * z + m[13]) / w;\n  out[2] = (m[2] * x + m[6] * y + m[10] * z + m[14]) / w;\n  return out;\n}\n/**\n * Transforms the vec3 with a mat3.\n *\n * @param {vec3} out the receiving vector\n * @param {ReadonlyVec3} a the vector to transform\n * @param {ReadonlyMat3} m the 3x3 matrix to transform with\n * @returns {vec3} out\n */\n\nfunction transformMat3(out, a, m) {\n  var x = a[0],\n      y = a[1],\n      z = a[2];\n  out[0] = x * m[0] + y * m[3] + z * m[6];\n  out[1] = x * m[1] + y * m[4] + z * m[7];\n  out[2] = x * m[2] + y * m[5] + z * m[8];\n  return out;\n}\n/**\n * Transforms the vec3 with a quat\n * Can also be used for dual quaternions. (Multiply it with the real part)\n *\n * @param {vec3} out the receiving vector\n * @param {ReadonlyVec3} a the vector to transform\n * @param {ReadonlyQuat} q quaternion to transform with\n * @returns {vec3} out\n */\n\nfunction transformQuat(out, a, q) {\n  // benchmarks: https://jsperf.com/quaternion-transform-vec3-implementations-fixed\n  var qx = q[0],\n      qy = q[1],\n      qz = q[2],\n      qw = q[3];\n  var x = a[0],\n      y = a[1],\n      z = a[2]; // var qvec = [qx, qy, qz];\n  // var uv = vec3.cross([], qvec, a);\n\n  var uvx = qy * z - qz * y,\n      uvy = qz * x - qx * z,\n      uvz = qx * y - qy * x; // var uuv = vec3.cross([], qvec, uv);\n\n  var uuvx = qy * uvz - qz * uvy,\n      uuvy = qz * uvx - qx * uvz,\n      uuvz = qx * uvy - qy * uvx; // vec3.scale(uv, uv, 2 * w);\n\n  var w2 = qw * 2;\n  uvx *= w2;\n  uvy *= w2;\n  uvz *= w2; // vec3.scale(uuv, uuv, 2);\n\n  uuvx *= 2;\n  uuvy *= 2;\n  uuvz *= 2; // return vec3.add(out, a, vec3.add(out, uv, uuv));\n\n  out[0] = x + uvx + uuvx;\n  out[1] = y + uvy + uuvy;\n  out[2] = z + uvz + uuvz;\n  return out;\n}\n/**\n * Rotate a 3D vector around the x-axis\n * @param {vec3} out The receiving vec3\n * @param {ReadonlyVec3} a The vec3 point to rotate\n * @param {ReadonlyVec3} b The origin of the rotation\n * @param {Number} rad The angle of rotation in radians\n * @returns {vec3} out\n */\n\nfunction rotateX(out, a, b, rad) {\n  var p = [],\n      r = []; //Translate point to the origin\n\n  p[0] = a[0] - b[0];\n  p[1] = a[1] - b[1];\n  p[2] = a[2] - b[2]; //perform rotation\n\n  r[0] = p[0];\n  r[1] = p[1] * Math.cos(rad) - p[2] * Math.sin(rad);\n  r[2] = p[1] * Math.sin(rad) + p[2] * Math.cos(rad); //translate to correct position\n\n  out[0] = r[0] + b[0];\n  out[1] = r[1] + b[1];\n  out[2] = r[2] + b[2];\n  return out;\n}\n/**\n * Rotate a 3D vector around the y-axis\n * @param {vec3} out The receiving vec3\n * @param {ReadonlyVec3} a The vec3 point to rotate\n * @param {ReadonlyVec3} b The origin of the rotation\n * @param {Number} rad The angle of rotation in radians\n * @returns {vec3} out\n */\n\nfunction rotateY(out, a, b, rad) {\n  var p = [],\n      r = []; //Translate point to the origin\n\n  p[0] = a[0] - b[0];\n  p[1] = a[1] - b[1];\n  p[2] = a[2] - b[2]; //perform rotation\n\n  r[0] = p[2] * Math.sin(rad) + p[0] * Math.cos(rad);\n  r[1] = p[1];\n  r[2] = p[2] * Math.cos(rad) - p[0] * Math.sin(rad); //translate to correct position\n\n  out[0] = r[0] + b[0];\n  out[1] = r[1] + b[1];\n  out[2] = r[2] + b[2];\n  return out;\n}\n/**\n * Rotate a 3D vector around the z-axis\n * @param {vec3} out The receiving vec3\n * @param {ReadonlyVec3} a The vec3 point to rotate\n * @param {ReadonlyVec3} b The origin of the rotation\n * @param {Number} rad The angle of rotation in radians\n * @returns {vec3} out\n */\n\nfunction rotateZ(out, a, b, rad) {\n  var p = [],\n      r = []; //Translate point to the origin\n\n  p[0] = a[0] - b[0];\n  p[1] = a[1] - b[1];\n  p[2] = a[2] - b[2]; //perform rotation\n\n  r[0] = p[0] * Math.cos(rad) - p[1] * Math.sin(rad);\n  r[1] = p[0] * Math.sin(rad) + p[1] * Math.cos(rad);\n  r[2] = p[2]; //translate to correct position\n\n  out[0] = r[0] + b[0];\n  out[1] = r[1] + b[1];\n  out[2] = r[2] + b[2];\n  return out;\n}\n/**\n * Get the angle between two 3D vectors\n * @param {ReadonlyVec3} a The first operand\n * @param {ReadonlyVec3} b The second operand\n * @returns {Number} The angle in radians\n */\n\nfunction angle(a, b) {\n  var ax = a[0],\n      ay = a[1],\n      az = a[2],\n      bx = b[0],\n      by = b[1],\n      bz = b[2],\n      mag1 = Math.sqrt(ax * ax + ay * ay + az * az),\n      mag2 = Math.sqrt(bx * bx + by * by + bz * bz),\n      mag = mag1 * mag2,\n      cosine = mag && dot(a, b) / mag;\n  return Math.acos(Math.min(Math.max(cosine, -1), 1));\n}\n/**\n * Set the components of a vec3 to zero\n *\n * @param {vec3} out the receiving vector\n * @returns {vec3} out\n */\n\nfunction zero(out) {\n  out[0] = 0.0;\n  out[1] = 0.0;\n  out[2] = 0.0;\n  return out;\n}\n/**\n * Returns a string representation of a vector\n *\n * @param {ReadonlyVec3} a vector to represent as a string\n * @returns {String} string representation of the vector\n */\n\nfunction str(a) {\n  return \"vec3(\" + a[0] + \", \" + a[1] + \", \" + a[2] + \")\";\n}\n/**\n * Returns whether or not the vectors have exactly the same elements in the same position (when compared with ===)\n *\n * @param {ReadonlyVec3} a The first vector.\n * @param {ReadonlyVec3} b The second vector.\n * @returns {Boolean} True if the vectors are equal, false otherwise.\n */\n\nfunction exactEquals(a, b) {\n  return a[0] === b[0] && a[1] === b[1] && a[2] === b[2];\n}\n/**\n * Returns whether or not the vectors have approximately the same elements in the same position.\n *\n * @param {ReadonlyVec3} a The first vector.\n * @param {ReadonlyVec3} b The second vector.\n * @returns {Boolean} True if the vectors are equal, false otherwise.\n */\n\nfunction equals(a, b) {\n  var a0 = a[0],\n      a1 = a[1],\n      a2 = a[2];\n  var b0 = b[0],\n      b1 = b[1],\n      b2 = b[2];\n  return Math.abs(a0 - b0) <= _common_js__WEBPACK_IMPORTED_MODULE_0__.EPSILON * Math.max(1.0, Math.abs(a0), Math.abs(b0)) && Math.abs(a1 - b1) <= _common_js__WEBPACK_IMPORTED_MODULE_0__.EPSILON * Math.max(1.0, Math.abs(a1), Math.abs(b1)) && Math.abs(a2 - b2) <= _common_js__WEBPACK_IMPORTED_MODULE_0__.EPSILON * Math.max(1.0, Math.abs(a2), Math.abs(b2));\n}\n/**\n * Alias for {@link vec3.subtract}\n * @function\n */\n\nvar sub = subtract;\n/**\n * Alias for {@link vec3.multiply}\n * @function\n */\n\nvar mul = multiply;\n/**\n * Alias for {@link vec3.divide}\n * @function\n */\n\nvar div = divide;\n/**\n * Alias for {@link vec3.distance}\n * @function\n */\n\nvar dist = distance;\n/**\n * Alias for {@link vec3.squaredDistance}\n * @function\n */\n\nvar sqrDist = squaredDistance;\n/**\n * Alias for {@link vec3.length}\n * @function\n */\n\nvar len = length;\n/**\n * Alias for {@link vec3.squaredLength}\n * @function\n */\n\nvar sqrLen = squaredLength;\n/**\n * Perform some operation over an array of vec3s.\n *\n * @param {Array} a the array of vectors to iterate over\n * @param {Number} stride Number of elements between the start of each vec3. If 0 assumes tightly packed\n * @param {Number} offset Number of elements to skip at the beginning of the array\n * @param {Number} count Number of vec3s to iterate over. If 0 iterates over entire array\n * @param {Function} fn Function to call for each vector in the array\n * @param {Object} [arg] additional argument to pass to fn\n * @returns {Array} a\n * @function\n */\n\nvar forEach = function () {\n  var vec = create();\n  return function (a, stride, offset, count, fn, arg) {\n    var i, l;\n\n    if (!stride) {\n      stride = 3;\n    }\n\n    if (!offset) {\n      offset = 0;\n    }\n\n    if (count) {\n      l = Math.min(count * stride + offset, a.length);\n    } else {\n      l = a.length;\n    }\n\n    for (i = offset; i < l; i += stride) {\n      vec[0] = a[i];\n      vec[1] = a[i + 1];\n      vec[2] = a[i + 2];\n      fn(vec, vec, arg);\n      a[i] = vec[0];\n      a[i + 1] = vec[1];\n      a[i + 2] = vec[2];\n    }\n\n    return a;\n  };\n}();\n\n//# sourceURL=webpack://semanticfinder/./node_modules/gl-matrix/esm/vec3.js?");

/***/ }),

/***/ "./node_modules/gl-matrix/esm/vec4.js":
/*!********************************************!*\
  !*** ./node_modules/gl-matrix/esm/vec4.js ***!
  \********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   add: () => (/* binding */ add),\n/* harmony export */   ceil: () => (/* binding */ ceil),\n/* harmony export */   clone: () => (/* binding */ clone),\n/* harmony export */   copy: () => (/* binding */ copy),\n/* harmony export */   create: () => (/* binding */ create),\n/* harmony export */   cross: () => (/* binding */ cross),\n/* harmony export */   dist: () => (/* binding */ dist),\n/* harmony export */   distance: () => (/* binding */ distance),\n/* harmony export */   div: () => (/* binding */ div),\n/* harmony export */   divide: () => (/* binding */ divide),\n/* harmony export */   dot: () => (/* binding */ dot),\n/* harmony export */   equals: () => (/* binding */ equals),\n/* harmony export */   exactEquals: () => (/* binding */ exactEquals),\n/* harmony export */   floor: () => (/* binding */ floor),\n/* harmony export */   forEach: () => (/* binding */ forEach),\n/* harmony export */   fromValues: () => (/* binding */ fromValues),\n/* harmony export */   inverse: () => (/* binding */ inverse),\n/* harmony export */   len: () => (/* binding */ len),\n/* harmony export */   length: () => (/* binding */ length),\n/* harmony export */   lerp: () => (/* binding */ lerp),\n/* harmony export */   max: () => (/* binding */ max),\n/* harmony export */   min: () => (/* binding */ min),\n/* harmony export */   mul: () => (/* binding */ mul),\n/* harmony export */   multiply: () => (/* binding */ multiply),\n/* harmony export */   negate: () => (/* binding */ negate),\n/* harmony export */   normalize: () => (/* binding */ normalize),\n/* harmony export */   random: () => (/* binding */ random),\n/* harmony export */   round: () => (/* binding */ round),\n/* harmony export */   scale: () => (/* binding */ scale),\n/* harmony export */   scaleAndAdd: () => (/* binding */ scaleAndAdd),\n/* harmony export */   set: () => (/* binding */ set),\n/* harmony export */   sqrDist: () => (/* binding */ sqrDist),\n/* harmony export */   sqrLen: () => (/* binding */ sqrLen),\n/* harmony export */   squaredDistance: () => (/* binding */ squaredDistance),\n/* harmony export */   squaredLength: () => (/* binding */ squaredLength),\n/* harmony export */   str: () => (/* binding */ str),\n/* harmony export */   sub: () => (/* binding */ sub),\n/* harmony export */   subtract: () => (/* binding */ subtract),\n/* harmony export */   transformMat4: () => (/* binding */ transformMat4),\n/* harmony export */   transformQuat: () => (/* binding */ transformQuat),\n/* harmony export */   zero: () => (/* binding */ zero)\n/* harmony export */ });\n/* harmony import */ var _common_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./common.js */ \"./node_modules/gl-matrix/esm/common.js\");\n\n/**\n * 4 Dimensional Vector\n * @module vec4\n */\n\n/**\n * Creates a new, empty vec4\n *\n * @returns {vec4} a new 4D vector\n */\n\nfunction create() {\n  var out = new _common_js__WEBPACK_IMPORTED_MODULE_0__.ARRAY_TYPE(4);\n\n  if (_common_js__WEBPACK_IMPORTED_MODULE_0__.ARRAY_TYPE != Float32Array) {\n    out[0] = 0;\n    out[1] = 0;\n    out[2] = 0;\n    out[3] = 0;\n  }\n\n  return out;\n}\n/**\n * Creates a new vec4 initialized with values from an existing vector\n *\n * @param {ReadonlyVec4} a vector to clone\n * @returns {vec4} a new 4D vector\n */\n\nfunction clone(a) {\n  var out = new _common_js__WEBPACK_IMPORTED_MODULE_0__.ARRAY_TYPE(4);\n  out[0] = a[0];\n  out[1] = a[1];\n  out[2] = a[2];\n  out[3] = a[3];\n  return out;\n}\n/**\n * Creates a new vec4 initialized with the given values\n *\n * @param {Number} x X component\n * @param {Number} y Y component\n * @param {Number} z Z component\n * @param {Number} w W component\n * @returns {vec4} a new 4D vector\n */\n\nfunction fromValues(x, y, z, w) {\n  var out = new _common_js__WEBPACK_IMPORTED_MODULE_0__.ARRAY_TYPE(4);\n  out[0] = x;\n  out[1] = y;\n  out[2] = z;\n  out[3] = w;\n  return out;\n}\n/**\n * Copy the values from one vec4 to another\n *\n * @param {vec4} out the receiving vector\n * @param {ReadonlyVec4} a the source vector\n * @returns {vec4} out\n */\n\nfunction copy(out, a) {\n  out[0] = a[0];\n  out[1] = a[1];\n  out[2] = a[2];\n  out[3] = a[3];\n  return out;\n}\n/**\n * Set the components of a vec4 to the given values\n *\n * @param {vec4} out the receiving vector\n * @param {Number} x X component\n * @param {Number} y Y component\n * @param {Number} z Z component\n * @param {Number} w W component\n * @returns {vec4} out\n */\n\nfunction set(out, x, y, z, w) {\n  out[0] = x;\n  out[1] = y;\n  out[2] = z;\n  out[3] = w;\n  return out;\n}\n/**\n * Adds two vec4's\n *\n * @param {vec4} out the receiving vector\n * @param {ReadonlyVec4} a the first operand\n * @param {ReadonlyVec4} b the second operand\n * @returns {vec4} out\n */\n\nfunction add(out, a, b) {\n  out[0] = a[0] + b[0];\n  out[1] = a[1] + b[1];\n  out[2] = a[2] + b[2];\n  out[3] = a[3] + b[3];\n  return out;\n}\n/**\n * Subtracts vector b from vector a\n *\n * @param {vec4} out the receiving vector\n * @param {ReadonlyVec4} a the first operand\n * @param {ReadonlyVec4} b the second operand\n * @returns {vec4} out\n */\n\nfunction subtract(out, a, b) {\n  out[0] = a[0] - b[0];\n  out[1] = a[1] - b[1];\n  out[2] = a[2] - b[2];\n  out[3] = a[3] - b[3];\n  return out;\n}\n/**\n * Multiplies two vec4's\n *\n * @param {vec4} out the receiving vector\n * @param {ReadonlyVec4} a the first operand\n * @param {ReadonlyVec4} b the second operand\n * @returns {vec4} out\n */\n\nfunction multiply(out, a, b) {\n  out[0] = a[0] * b[0];\n  out[1] = a[1] * b[1];\n  out[2] = a[2] * b[2];\n  out[3] = a[3] * b[3];\n  return out;\n}\n/**\n * Divides two vec4's\n *\n * @param {vec4} out the receiving vector\n * @param {ReadonlyVec4} a the first operand\n * @param {ReadonlyVec4} b the second operand\n * @returns {vec4} out\n */\n\nfunction divide(out, a, b) {\n  out[0] = a[0] / b[0];\n  out[1] = a[1] / b[1];\n  out[2] = a[2] / b[2];\n  out[3] = a[3] / b[3];\n  return out;\n}\n/**\n * Math.ceil the components of a vec4\n *\n * @param {vec4} out the receiving vector\n * @param {ReadonlyVec4} a vector to ceil\n * @returns {vec4} out\n */\n\nfunction ceil(out, a) {\n  out[0] = Math.ceil(a[0]);\n  out[1] = Math.ceil(a[1]);\n  out[2] = Math.ceil(a[2]);\n  out[3] = Math.ceil(a[3]);\n  return out;\n}\n/**\n * Math.floor the components of a vec4\n *\n * @param {vec4} out the receiving vector\n * @param {ReadonlyVec4} a vector to floor\n * @returns {vec4} out\n */\n\nfunction floor(out, a) {\n  out[0] = Math.floor(a[0]);\n  out[1] = Math.floor(a[1]);\n  out[2] = Math.floor(a[2]);\n  out[3] = Math.floor(a[3]);\n  return out;\n}\n/**\n * Returns the minimum of two vec4's\n *\n * @param {vec4} out the receiving vector\n * @param {ReadonlyVec4} a the first operand\n * @param {ReadonlyVec4} b the second operand\n * @returns {vec4} out\n */\n\nfunction min(out, a, b) {\n  out[0] = Math.min(a[0], b[0]);\n  out[1] = Math.min(a[1], b[1]);\n  out[2] = Math.min(a[2], b[2]);\n  out[3] = Math.min(a[3], b[3]);\n  return out;\n}\n/**\n * Returns the maximum of two vec4's\n *\n * @param {vec4} out the receiving vector\n * @param {ReadonlyVec4} a the first operand\n * @param {ReadonlyVec4} b the second operand\n * @returns {vec4} out\n */\n\nfunction max(out, a, b) {\n  out[0] = Math.max(a[0], b[0]);\n  out[1] = Math.max(a[1], b[1]);\n  out[2] = Math.max(a[2], b[2]);\n  out[3] = Math.max(a[3], b[3]);\n  return out;\n}\n/**\n * Math.round the components of a vec4\n *\n * @param {vec4} out the receiving vector\n * @param {ReadonlyVec4} a vector to round\n * @returns {vec4} out\n */\n\nfunction round(out, a) {\n  out[0] = Math.round(a[0]);\n  out[1] = Math.round(a[1]);\n  out[2] = Math.round(a[2]);\n  out[3] = Math.round(a[3]);\n  return out;\n}\n/**\n * Scales a vec4 by a scalar number\n *\n * @param {vec4} out the receiving vector\n * @param {ReadonlyVec4} a the vector to scale\n * @param {Number} b amount to scale the vector by\n * @returns {vec4} out\n */\n\nfunction scale(out, a, b) {\n  out[0] = a[0] * b;\n  out[1] = a[1] * b;\n  out[2] = a[2] * b;\n  out[3] = a[3] * b;\n  return out;\n}\n/**\n * Adds two vec4's after scaling the second operand by a scalar value\n *\n * @param {vec4} out the receiving vector\n * @param {ReadonlyVec4} a the first operand\n * @param {ReadonlyVec4} b the second operand\n * @param {Number} scale the amount to scale b by before adding\n * @returns {vec4} out\n */\n\nfunction scaleAndAdd(out, a, b, scale) {\n  out[0] = a[0] + b[0] * scale;\n  out[1] = a[1] + b[1] * scale;\n  out[2] = a[2] + b[2] * scale;\n  out[3] = a[3] + b[3] * scale;\n  return out;\n}\n/**\n * Calculates the euclidian distance between two vec4's\n *\n * @param {ReadonlyVec4} a the first operand\n * @param {ReadonlyVec4} b the second operand\n * @returns {Number} distance between a and b\n */\n\nfunction distance(a, b) {\n  var x = b[0] - a[0];\n  var y = b[1] - a[1];\n  var z = b[2] - a[2];\n  var w = b[3] - a[3];\n  return Math.hypot(x, y, z, w);\n}\n/**\n * Calculates the squared euclidian distance between two vec4's\n *\n * @param {ReadonlyVec4} a the first operand\n * @param {ReadonlyVec4} b the second operand\n * @returns {Number} squared distance between a and b\n */\n\nfunction squaredDistance(a, b) {\n  var x = b[0] - a[0];\n  var y = b[1] - a[1];\n  var z = b[2] - a[2];\n  var w = b[3] - a[3];\n  return x * x + y * y + z * z + w * w;\n}\n/**\n * Calculates the length of a vec4\n *\n * @param {ReadonlyVec4} a vector to calculate length of\n * @returns {Number} length of a\n */\n\nfunction length(a) {\n  var x = a[0];\n  var y = a[1];\n  var z = a[2];\n  var w = a[3];\n  return Math.hypot(x, y, z, w);\n}\n/**\n * Calculates the squared length of a vec4\n *\n * @param {ReadonlyVec4} a vector to calculate squared length of\n * @returns {Number} squared length of a\n */\n\nfunction squaredLength(a) {\n  var x = a[0];\n  var y = a[1];\n  var z = a[2];\n  var w = a[3];\n  return x * x + y * y + z * z + w * w;\n}\n/**\n * Negates the components of a vec4\n *\n * @param {vec4} out the receiving vector\n * @param {ReadonlyVec4} a vector to negate\n * @returns {vec4} out\n */\n\nfunction negate(out, a) {\n  out[0] = -a[0];\n  out[1] = -a[1];\n  out[2] = -a[2];\n  out[3] = -a[3];\n  return out;\n}\n/**\n * Returns the inverse of the components of a vec4\n *\n * @param {vec4} out the receiving vector\n * @param {ReadonlyVec4} a vector to invert\n * @returns {vec4} out\n */\n\nfunction inverse(out, a) {\n  out[0] = 1.0 / a[0];\n  out[1] = 1.0 / a[1];\n  out[2] = 1.0 / a[2];\n  out[3] = 1.0 / a[3];\n  return out;\n}\n/**\n * Normalize a vec4\n *\n * @param {vec4} out the receiving vector\n * @param {ReadonlyVec4} a vector to normalize\n * @returns {vec4} out\n */\n\nfunction normalize(out, a) {\n  var x = a[0];\n  var y = a[1];\n  var z = a[2];\n  var w = a[3];\n  var len = x * x + y * y + z * z + w * w;\n\n  if (len > 0) {\n    len = 1 / Math.sqrt(len);\n  }\n\n  out[0] = x * len;\n  out[1] = y * len;\n  out[2] = z * len;\n  out[3] = w * len;\n  return out;\n}\n/**\n * Calculates the dot product of two vec4's\n *\n * @param {ReadonlyVec4} a the first operand\n * @param {ReadonlyVec4} b the second operand\n * @returns {Number} dot product of a and b\n */\n\nfunction dot(a, b) {\n  return a[0] * b[0] + a[1] * b[1] + a[2] * b[2] + a[3] * b[3];\n}\n/**\n * Returns the cross-product of three vectors in a 4-dimensional space\n *\n * @param {ReadonlyVec4} result the receiving vector\n * @param {ReadonlyVec4} U the first vector\n * @param {ReadonlyVec4} V the second vector\n * @param {ReadonlyVec4} W the third vector\n * @returns {vec4} result\n */\n\nfunction cross(out, u, v, w) {\n  var A = v[0] * w[1] - v[1] * w[0],\n      B = v[0] * w[2] - v[2] * w[0],\n      C = v[0] * w[3] - v[3] * w[0],\n      D = v[1] * w[2] - v[2] * w[1],\n      E = v[1] * w[3] - v[3] * w[1],\n      F = v[2] * w[3] - v[3] * w[2];\n  var G = u[0];\n  var H = u[1];\n  var I = u[2];\n  var J = u[3];\n  out[0] = H * F - I * E + J * D;\n  out[1] = -(G * F) + I * C - J * B;\n  out[2] = G * E - H * C + J * A;\n  out[3] = -(G * D) + H * B - I * A;\n  return out;\n}\n/**\n * Performs a linear interpolation between two vec4's\n *\n * @param {vec4} out the receiving vector\n * @param {ReadonlyVec4} a the first operand\n * @param {ReadonlyVec4} b the second operand\n * @param {Number} t interpolation amount, in the range [0-1], between the two inputs\n * @returns {vec4} out\n */\n\nfunction lerp(out, a, b, t) {\n  var ax = a[0];\n  var ay = a[1];\n  var az = a[2];\n  var aw = a[3];\n  out[0] = ax + t * (b[0] - ax);\n  out[1] = ay + t * (b[1] - ay);\n  out[2] = az + t * (b[2] - az);\n  out[3] = aw + t * (b[3] - aw);\n  return out;\n}\n/**\n * Generates a random vector with the given scale\n *\n * @param {vec4} out the receiving vector\n * @param {Number} [scale] Length of the resulting vector. If ommitted, a unit vector will be returned\n * @returns {vec4} out\n */\n\nfunction random(out, scale) {\n  scale = scale || 1.0; // Marsaglia, George. Choosing a Point from the Surface of a\n  // Sphere. Ann. Math. Statist. 43 (1972), no. 2, 645--646.\n  // http://projecteuclid.org/euclid.aoms/1177692644;\n\n  var v1, v2, v3, v4;\n  var s1, s2;\n\n  do {\n    v1 = _common_js__WEBPACK_IMPORTED_MODULE_0__.RANDOM() * 2 - 1;\n    v2 = _common_js__WEBPACK_IMPORTED_MODULE_0__.RANDOM() * 2 - 1;\n    s1 = v1 * v1 + v2 * v2;\n  } while (s1 >= 1);\n\n  do {\n    v3 = _common_js__WEBPACK_IMPORTED_MODULE_0__.RANDOM() * 2 - 1;\n    v4 = _common_js__WEBPACK_IMPORTED_MODULE_0__.RANDOM() * 2 - 1;\n    s2 = v3 * v3 + v4 * v4;\n  } while (s2 >= 1);\n\n  var d = Math.sqrt((1 - s1) / s2);\n  out[0] = scale * v1;\n  out[1] = scale * v2;\n  out[2] = scale * v3 * d;\n  out[3] = scale * v4 * d;\n  return out;\n}\n/**\n * Transforms the vec4 with a mat4.\n *\n * @param {vec4} out the receiving vector\n * @param {ReadonlyVec4} a the vector to transform\n * @param {ReadonlyMat4} m matrix to transform with\n * @returns {vec4} out\n */\n\nfunction transformMat4(out, a, m) {\n  var x = a[0],\n      y = a[1],\n      z = a[2],\n      w = a[3];\n  out[0] = m[0] * x + m[4] * y + m[8] * z + m[12] * w;\n  out[1] = m[1] * x + m[5] * y + m[9] * z + m[13] * w;\n  out[2] = m[2] * x + m[6] * y + m[10] * z + m[14] * w;\n  out[3] = m[3] * x + m[7] * y + m[11] * z + m[15] * w;\n  return out;\n}\n/**\n * Transforms the vec4 with a quat\n *\n * @param {vec4} out the receiving vector\n * @param {ReadonlyVec4} a the vector to transform\n * @param {ReadonlyQuat} q quaternion to transform with\n * @returns {vec4} out\n */\n\nfunction transformQuat(out, a, q) {\n  var x = a[0],\n      y = a[1],\n      z = a[2];\n  var qx = q[0],\n      qy = q[1],\n      qz = q[2],\n      qw = q[3]; // calculate quat * vec\n\n  var ix = qw * x + qy * z - qz * y;\n  var iy = qw * y + qz * x - qx * z;\n  var iz = qw * z + qx * y - qy * x;\n  var iw = -qx * x - qy * y - qz * z; // calculate result * inverse quat\n\n  out[0] = ix * qw + iw * -qx + iy * -qz - iz * -qy;\n  out[1] = iy * qw + iw * -qy + iz * -qx - ix * -qz;\n  out[2] = iz * qw + iw * -qz + ix * -qy - iy * -qx;\n  out[3] = a[3];\n  return out;\n}\n/**\n * Set the components of a vec4 to zero\n *\n * @param {vec4} out the receiving vector\n * @returns {vec4} out\n */\n\nfunction zero(out) {\n  out[0] = 0.0;\n  out[1] = 0.0;\n  out[2] = 0.0;\n  out[3] = 0.0;\n  return out;\n}\n/**\n * Returns a string representation of a vector\n *\n * @param {ReadonlyVec4} a vector to represent as a string\n * @returns {String} string representation of the vector\n */\n\nfunction str(a) {\n  return \"vec4(\" + a[0] + \", \" + a[1] + \", \" + a[2] + \", \" + a[3] + \")\";\n}\n/**\n * Returns whether or not the vectors have exactly the same elements in the same position (when compared with ===)\n *\n * @param {ReadonlyVec4} a The first vector.\n * @param {ReadonlyVec4} b The second vector.\n * @returns {Boolean} True if the vectors are equal, false otherwise.\n */\n\nfunction exactEquals(a, b) {\n  return a[0] === b[0] && a[1] === b[1] && a[2] === b[2] && a[3] === b[3];\n}\n/**\n * Returns whether or not the vectors have approximately the same elements in the same position.\n *\n * @param {ReadonlyVec4} a The first vector.\n * @param {ReadonlyVec4} b The second vector.\n * @returns {Boolean} True if the vectors are equal, false otherwise.\n */\n\nfunction equals(a, b) {\n  var a0 = a[0],\n      a1 = a[1],\n      a2 = a[2],\n      a3 = a[3];\n  var b0 = b[0],\n      b1 = b[1],\n      b2 = b[2],\n      b3 = b[3];\n  return Math.abs(a0 - b0) <= _common_js__WEBPACK_IMPORTED_MODULE_0__.EPSILON * Math.max(1.0, Math.abs(a0), Math.abs(b0)) && Math.abs(a1 - b1) <= _common_js__WEBPACK_IMPORTED_MODULE_0__.EPSILON * Math.max(1.0, Math.abs(a1), Math.abs(b1)) && Math.abs(a2 - b2) <= _common_js__WEBPACK_IMPORTED_MODULE_0__.EPSILON * Math.max(1.0, Math.abs(a2), Math.abs(b2)) && Math.abs(a3 - b3) <= _common_js__WEBPACK_IMPORTED_MODULE_0__.EPSILON * Math.max(1.0, Math.abs(a3), Math.abs(b3));\n}\n/**\n * Alias for {@link vec4.subtract}\n * @function\n */\n\nvar sub = subtract;\n/**\n * Alias for {@link vec4.multiply}\n * @function\n */\n\nvar mul = multiply;\n/**\n * Alias for {@link vec4.divide}\n * @function\n */\n\nvar div = divide;\n/**\n * Alias for {@link vec4.distance}\n * @function\n */\n\nvar dist = distance;\n/**\n * Alias for {@link vec4.squaredDistance}\n * @function\n */\n\nvar sqrDist = squaredDistance;\n/**\n * Alias for {@link vec4.length}\n * @function\n */\n\nvar len = length;\n/**\n * Alias for {@link vec4.squaredLength}\n * @function\n */\n\nvar sqrLen = squaredLength;\n/**\n * Perform some operation over an array of vec4s.\n *\n * @param {Array} a the array of vectors to iterate over\n * @param {Number} stride Number of elements between the start of each vec4. If 0 assumes tightly packed\n * @param {Number} offset Number of elements to skip at the beginning of the array\n * @param {Number} count Number of vec4s to iterate over. If 0 iterates over entire array\n * @param {Function} fn Function to call for each vector in the array\n * @param {Object} [arg] additional argument to pass to fn\n * @returns {Array} a\n * @function\n */\n\nvar forEach = function () {\n  var vec = create();\n  return function (a, stride, offset, count, fn, arg) {\n    var i, l;\n\n    if (!stride) {\n      stride = 4;\n    }\n\n    if (!offset) {\n      offset = 0;\n    }\n\n    if (count) {\n      l = Math.min(count * stride + offset, a.length);\n    } else {\n      l = a.length;\n    }\n\n    for (i = offset; i < l; i += stride) {\n      vec[0] = a[i];\n      vec[1] = a[i + 1];\n      vec[2] = a[i + 2];\n      vec[3] = a[i + 3];\n      fn(vec, vec, arg);\n      a[i] = vec[0];\n      a[i + 1] = vec[1];\n      a[i + 2] = vec[2];\n      a[i + 3] = vec[3];\n    }\n\n    return a;\n  };\n}();\n\n//# sourceURL=webpack://semanticfinder/./node_modules/gl-matrix/esm/vec4.js?");

/***/ }),

/***/ "./node_modules/hammerjs/hammer.js":
/*!*****************************************!*\
  !*** ./node_modules/hammerjs/hammer.js ***!
  \*****************************************/
/***/ ((module, exports, __webpack_require__) => {

eval("var __WEBPACK_AMD_DEFINE_RESULT__;/*! Hammer.JS - v2.0.7 - 2016-04-22\n * http://hammerjs.github.io/\n *\n * Copyright (c) 2016 Jorik Tangelder;\n * Licensed under the MIT license */\n(function(window, document, exportName, undefined) {\n  'use strict';\n\nvar VENDOR_PREFIXES = ['', 'webkit', 'Moz', 'MS', 'ms', 'o'];\nvar TEST_ELEMENT = document.createElement('div');\n\nvar TYPE_FUNCTION = 'function';\n\nvar round = Math.round;\nvar abs = Math.abs;\nvar now = Date.now;\n\n/**\n * set a timeout with a given scope\n * @param {Function} fn\n * @param {Number} timeout\n * @param {Object} context\n * @returns {number}\n */\nfunction setTimeoutContext(fn, timeout, context) {\n    return setTimeout(bindFn(fn, context), timeout);\n}\n\n/**\n * if the argument is an array, we want to execute the fn on each entry\n * if it aint an array we don't want to do a thing.\n * this is used by all the methods that accept a single and array argument.\n * @param {*|Array} arg\n * @param {String} fn\n * @param {Object} [context]\n * @returns {Boolean}\n */\nfunction invokeArrayArg(arg, fn, context) {\n    if (Array.isArray(arg)) {\n        each(arg, context[fn], context);\n        return true;\n    }\n    return false;\n}\n\n/**\n * walk objects and arrays\n * @param {Object} obj\n * @param {Function} iterator\n * @param {Object} context\n */\nfunction each(obj, iterator, context) {\n    var i;\n\n    if (!obj) {\n        return;\n    }\n\n    if (obj.forEach) {\n        obj.forEach(iterator, context);\n    } else if (obj.length !== undefined) {\n        i = 0;\n        while (i < obj.length) {\n            iterator.call(context, obj[i], i, obj);\n            i++;\n        }\n    } else {\n        for (i in obj) {\n            obj.hasOwnProperty(i) && iterator.call(context, obj[i], i, obj);\n        }\n    }\n}\n\n/**\n * wrap a method with a deprecation warning and stack trace\n * @param {Function} method\n * @param {String} name\n * @param {String} message\n * @returns {Function} A new function wrapping the supplied method.\n */\nfunction deprecate(method, name, message) {\n    var deprecationMessage = 'DEPRECATED METHOD: ' + name + '\\n' + message + ' AT \\n';\n    return function() {\n        var e = new Error('get-stack-trace');\n        var stack = e && e.stack ? e.stack.replace(/^[^\\(]+?[\\n$]/gm, '')\n            .replace(/^\\s+at\\s+/gm, '')\n            .replace(/^Object.<anonymous>\\s*\\(/gm, '{anonymous}()@') : 'Unknown Stack Trace';\n\n        var log = window.console && (window.console.warn || window.console.log);\n        if (log) {\n            log.call(window.console, deprecationMessage, stack);\n        }\n        return method.apply(this, arguments);\n    };\n}\n\n/**\n * extend object.\n * means that properties in dest will be overwritten by the ones in src.\n * @param {Object} target\n * @param {...Object} objects_to_assign\n * @returns {Object} target\n */\nvar assign;\nif (typeof Object.assign !== 'function') {\n    assign = function assign(target) {\n        if (target === undefined || target === null) {\n            throw new TypeError('Cannot convert undefined or null to object');\n        }\n\n        var output = Object(target);\n        for (var index = 1; index < arguments.length; index++) {\n            var source = arguments[index];\n            if (source !== undefined && source !== null) {\n                for (var nextKey in source) {\n                    if (source.hasOwnProperty(nextKey)) {\n                        output[nextKey] = source[nextKey];\n                    }\n                }\n            }\n        }\n        return output;\n    };\n} else {\n    assign = Object.assign;\n}\n\n/**\n * extend object.\n * means that properties in dest will be overwritten by the ones in src.\n * @param {Object} dest\n * @param {Object} src\n * @param {Boolean} [merge=false]\n * @returns {Object} dest\n */\nvar extend = deprecate(function extend(dest, src, merge) {\n    var keys = Object.keys(src);\n    var i = 0;\n    while (i < keys.length) {\n        if (!merge || (merge && dest[keys[i]] === undefined)) {\n            dest[keys[i]] = src[keys[i]];\n        }\n        i++;\n    }\n    return dest;\n}, 'extend', 'Use `assign`.');\n\n/**\n * merge the values from src in the dest.\n * means that properties that exist in dest will not be overwritten by src\n * @param {Object} dest\n * @param {Object} src\n * @returns {Object} dest\n */\nvar merge = deprecate(function merge(dest, src) {\n    return extend(dest, src, true);\n}, 'merge', 'Use `assign`.');\n\n/**\n * simple class inheritance\n * @param {Function} child\n * @param {Function} base\n * @param {Object} [properties]\n */\nfunction inherit(child, base, properties) {\n    var baseP = base.prototype,\n        childP;\n\n    childP = child.prototype = Object.create(baseP);\n    childP.constructor = child;\n    childP._super = baseP;\n\n    if (properties) {\n        assign(childP, properties);\n    }\n}\n\n/**\n * simple function bind\n * @param {Function} fn\n * @param {Object} context\n * @returns {Function}\n */\nfunction bindFn(fn, context) {\n    return function boundFn() {\n        return fn.apply(context, arguments);\n    };\n}\n\n/**\n * let a boolean value also be a function that must return a boolean\n * this first item in args will be used as the context\n * @param {Boolean|Function} val\n * @param {Array} [args]\n * @returns {Boolean}\n */\nfunction boolOrFn(val, args) {\n    if (typeof val == TYPE_FUNCTION) {\n        return val.apply(args ? args[0] || undefined : undefined, args);\n    }\n    return val;\n}\n\n/**\n * use the val2 when val1 is undefined\n * @param {*} val1\n * @param {*} val2\n * @returns {*}\n */\nfunction ifUndefined(val1, val2) {\n    return (val1 === undefined) ? val2 : val1;\n}\n\n/**\n * addEventListener with multiple events at once\n * @param {EventTarget} target\n * @param {String} types\n * @param {Function} handler\n */\nfunction addEventListeners(target, types, handler) {\n    each(splitStr(types), function(type) {\n        target.addEventListener(type, handler, false);\n    });\n}\n\n/**\n * removeEventListener with multiple events at once\n * @param {EventTarget} target\n * @param {String} types\n * @param {Function} handler\n */\nfunction removeEventListeners(target, types, handler) {\n    each(splitStr(types), function(type) {\n        target.removeEventListener(type, handler, false);\n    });\n}\n\n/**\n * find if a node is in the given parent\n * @method hasParent\n * @param {HTMLElement} node\n * @param {HTMLElement} parent\n * @return {Boolean} found\n */\nfunction hasParent(node, parent) {\n    while (node) {\n        if (node == parent) {\n            return true;\n        }\n        node = node.parentNode;\n    }\n    return false;\n}\n\n/**\n * small indexOf wrapper\n * @param {String} str\n * @param {String} find\n * @returns {Boolean} found\n */\nfunction inStr(str, find) {\n    return str.indexOf(find) > -1;\n}\n\n/**\n * split string on whitespace\n * @param {String} str\n * @returns {Array} words\n */\nfunction splitStr(str) {\n    return str.trim().split(/\\s+/g);\n}\n\n/**\n * find if a array contains the object using indexOf or a simple polyFill\n * @param {Array} src\n * @param {String} find\n * @param {String} [findByKey]\n * @return {Boolean|Number} false when not found, or the index\n */\nfunction inArray(src, find, findByKey) {\n    if (src.indexOf && !findByKey) {\n        return src.indexOf(find);\n    } else {\n        var i = 0;\n        while (i < src.length) {\n            if ((findByKey && src[i][findByKey] == find) || (!findByKey && src[i] === find)) {\n                return i;\n            }\n            i++;\n        }\n        return -1;\n    }\n}\n\n/**\n * convert array-like objects to real arrays\n * @param {Object} obj\n * @returns {Array}\n */\nfunction toArray(obj) {\n    return Array.prototype.slice.call(obj, 0);\n}\n\n/**\n * unique array with objects based on a key (like 'id') or just by the array's value\n * @param {Array} src [{id:1},{id:2},{id:1}]\n * @param {String} [key]\n * @param {Boolean} [sort=False]\n * @returns {Array} [{id:1},{id:2}]\n */\nfunction uniqueArray(src, key, sort) {\n    var results = [];\n    var values = [];\n    var i = 0;\n\n    while (i < src.length) {\n        var val = key ? src[i][key] : src[i];\n        if (inArray(values, val) < 0) {\n            results.push(src[i]);\n        }\n        values[i] = val;\n        i++;\n    }\n\n    if (sort) {\n        if (!key) {\n            results = results.sort();\n        } else {\n            results = results.sort(function sortUniqueArray(a, b) {\n                return a[key] > b[key];\n            });\n        }\n    }\n\n    return results;\n}\n\n/**\n * get the prefixed property\n * @param {Object} obj\n * @param {String} property\n * @returns {String|Undefined} prefixed\n */\nfunction prefixed(obj, property) {\n    var prefix, prop;\n    var camelProp = property[0].toUpperCase() + property.slice(1);\n\n    var i = 0;\n    while (i < VENDOR_PREFIXES.length) {\n        prefix = VENDOR_PREFIXES[i];\n        prop = (prefix) ? prefix + camelProp : property;\n\n        if (prop in obj) {\n            return prop;\n        }\n        i++;\n    }\n    return undefined;\n}\n\n/**\n * get a unique id\n * @returns {number} uniqueId\n */\nvar _uniqueId = 1;\nfunction uniqueId() {\n    return _uniqueId++;\n}\n\n/**\n * get the window object of an element\n * @param {HTMLElement} element\n * @returns {DocumentView|Window}\n */\nfunction getWindowForElement(element) {\n    var doc = element.ownerDocument || element;\n    return (doc.defaultView || doc.parentWindow || window);\n}\n\nvar MOBILE_REGEX = /mobile|tablet|ip(ad|hone|od)|android/i;\n\nvar SUPPORT_TOUCH = ('ontouchstart' in window);\nvar SUPPORT_POINTER_EVENTS = prefixed(window, 'PointerEvent') !== undefined;\nvar SUPPORT_ONLY_TOUCH = SUPPORT_TOUCH && MOBILE_REGEX.test(navigator.userAgent);\n\nvar INPUT_TYPE_TOUCH = 'touch';\nvar INPUT_TYPE_PEN = 'pen';\nvar INPUT_TYPE_MOUSE = 'mouse';\nvar INPUT_TYPE_KINECT = 'kinect';\n\nvar COMPUTE_INTERVAL = 25;\n\nvar INPUT_START = 1;\nvar INPUT_MOVE = 2;\nvar INPUT_END = 4;\nvar INPUT_CANCEL = 8;\n\nvar DIRECTION_NONE = 1;\nvar DIRECTION_LEFT = 2;\nvar DIRECTION_RIGHT = 4;\nvar DIRECTION_UP = 8;\nvar DIRECTION_DOWN = 16;\n\nvar DIRECTION_HORIZONTAL = DIRECTION_LEFT | DIRECTION_RIGHT;\nvar DIRECTION_VERTICAL = DIRECTION_UP | DIRECTION_DOWN;\nvar DIRECTION_ALL = DIRECTION_HORIZONTAL | DIRECTION_VERTICAL;\n\nvar PROPS_XY = ['x', 'y'];\nvar PROPS_CLIENT_XY = ['clientX', 'clientY'];\n\n/**\n * create new input type manager\n * @param {Manager} manager\n * @param {Function} callback\n * @returns {Input}\n * @constructor\n */\nfunction Input(manager, callback) {\n    var self = this;\n    this.manager = manager;\n    this.callback = callback;\n    this.element = manager.element;\n    this.target = manager.options.inputTarget;\n\n    // smaller wrapper around the handler, for the scope and the enabled state of the manager,\n    // so when disabled the input events are completely bypassed.\n    this.domHandler = function(ev) {\n        if (boolOrFn(manager.options.enable, [manager])) {\n            self.handler(ev);\n        }\n    };\n\n    this.init();\n\n}\n\nInput.prototype = {\n    /**\n     * should handle the inputEvent data and trigger the callback\n     * @virtual\n     */\n    handler: function() { },\n\n    /**\n     * bind the events\n     */\n    init: function() {\n        this.evEl && addEventListeners(this.element, this.evEl, this.domHandler);\n        this.evTarget && addEventListeners(this.target, this.evTarget, this.domHandler);\n        this.evWin && addEventListeners(getWindowForElement(this.element), this.evWin, this.domHandler);\n    },\n\n    /**\n     * unbind the events\n     */\n    destroy: function() {\n        this.evEl && removeEventListeners(this.element, this.evEl, this.domHandler);\n        this.evTarget && removeEventListeners(this.target, this.evTarget, this.domHandler);\n        this.evWin && removeEventListeners(getWindowForElement(this.element), this.evWin, this.domHandler);\n    }\n};\n\n/**\n * create new input type manager\n * called by the Manager constructor\n * @param {Hammer} manager\n * @returns {Input}\n */\nfunction createInputInstance(manager) {\n    var Type;\n    var inputClass = manager.options.inputClass;\n\n    if (inputClass) {\n        Type = inputClass;\n    } else if (SUPPORT_POINTER_EVENTS) {\n        Type = PointerEventInput;\n    } else if (SUPPORT_ONLY_TOUCH) {\n        Type = TouchInput;\n    } else if (!SUPPORT_TOUCH) {\n        Type = MouseInput;\n    } else {\n        Type = TouchMouseInput;\n    }\n    return new (Type)(manager, inputHandler);\n}\n\n/**\n * handle input events\n * @param {Manager} manager\n * @param {String} eventType\n * @param {Object} input\n */\nfunction inputHandler(manager, eventType, input) {\n    var pointersLen = input.pointers.length;\n    var changedPointersLen = input.changedPointers.length;\n    var isFirst = (eventType & INPUT_START && (pointersLen - changedPointersLen === 0));\n    var isFinal = (eventType & (INPUT_END | INPUT_CANCEL) && (pointersLen - changedPointersLen === 0));\n\n    input.isFirst = !!isFirst;\n    input.isFinal = !!isFinal;\n\n    if (isFirst) {\n        manager.session = {};\n    }\n\n    // source event is the normalized value of the domEvents\n    // like 'touchstart, mouseup, pointerdown'\n    input.eventType = eventType;\n\n    // compute scale, rotation etc\n    computeInputData(manager, input);\n\n    // emit secret event\n    manager.emit('hammer.input', input);\n\n    manager.recognize(input);\n    manager.session.prevInput = input;\n}\n\n/**\n * extend the data with some usable properties like scale, rotate, velocity etc\n * @param {Object} manager\n * @param {Object} input\n */\nfunction computeInputData(manager, input) {\n    var session = manager.session;\n    var pointers = input.pointers;\n    var pointersLength = pointers.length;\n\n    // store the first input to calculate the distance and direction\n    if (!session.firstInput) {\n        session.firstInput = simpleCloneInputData(input);\n    }\n\n    // to compute scale and rotation we need to store the multiple touches\n    if (pointersLength > 1 && !session.firstMultiple) {\n        session.firstMultiple = simpleCloneInputData(input);\n    } else if (pointersLength === 1) {\n        session.firstMultiple = false;\n    }\n\n    var firstInput = session.firstInput;\n    var firstMultiple = session.firstMultiple;\n    var offsetCenter = firstMultiple ? firstMultiple.center : firstInput.center;\n\n    var center = input.center = getCenter(pointers);\n    input.timeStamp = now();\n    input.deltaTime = input.timeStamp - firstInput.timeStamp;\n\n    input.angle = getAngle(offsetCenter, center);\n    input.distance = getDistance(offsetCenter, center);\n\n    computeDeltaXY(session, input);\n    input.offsetDirection = getDirection(input.deltaX, input.deltaY);\n\n    var overallVelocity = getVelocity(input.deltaTime, input.deltaX, input.deltaY);\n    input.overallVelocityX = overallVelocity.x;\n    input.overallVelocityY = overallVelocity.y;\n    input.overallVelocity = (abs(overallVelocity.x) > abs(overallVelocity.y)) ? overallVelocity.x : overallVelocity.y;\n\n    input.scale = firstMultiple ? getScale(firstMultiple.pointers, pointers) : 1;\n    input.rotation = firstMultiple ? getRotation(firstMultiple.pointers, pointers) : 0;\n\n    input.maxPointers = !session.prevInput ? input.pointers.length : ((input.pointers.length >\n        session.prevInput.maxPointers) ? input.pointers.length : session.prevInput.maxPointers);\n\n    computeIntervalInputData(session, input);\n\n    // find the correct target\n    var target = manager.element;\n    if (hasParent(input.srcEvent.target, target)) {\n        target = input.srcEvent.target;\n    }\n    input.target = target;\n}\n\nfunction computeDeltaXY(session, input) {\n    var center = input.center;\n    var offset = session.offsetDelta || {};\n    var prevDelta = session.prevDelta || {};\n    var prevInput = session.prevInput || {};\n\n    if (input.eventType === INPUT_START || prevInput.eventType === INPUT_END) {\n        prevDelta = session.prevDelta = {\n            x: prevInput.deltaX || 0,\n            y: prevInput.deltaY || 0\n        };\n\n        offset = session.offsetDelta = {\n            x: center.x,\n            y: center.y\n        };\n    }\n\n    input.deltaX = prevDelta.x + (center.x - offset.x);\n    input.deltaY = prevDelta.y + (center.y - offset.y);\n}\n\n/**\n * velocity is calculated every x ms\n * @param {Object} session\n * @param {Object} input\n */\nfunction computeIntervalInputData(session, input) {\n    var last = session.lastInterval || input,\n        deltaTime = input.timeStamp - last.timeStamp,\n        velocity, velocityX, velocityY, direction;\n\n    if (input.eventType != INPUT_CANCEL && (deltaTime > COMPUTE_INTERVAL || last.velocity === undefined)) {\n        var deltaX = input.deltaX - last.deltaX;\n        var deltaY = input.deltaY - last.deltaY;\n\n        var v = getVelocity(deltaTime, deltaX, deltaY);\n        velocityX = v.x;\n        velocityY = v.y;\n        velocity = (abs(v.x) > abs(v.y)) ? v.x : v.y;\n        direction = getDirection(deltaX, deltaY);\n\n        session.lastInterval = input;\n    } else {\n        // use latest velocity info if it doesn't overtake a minimum period\n        velocity = last.velocity;\n        velocityX = last.velocityX;\n        velocityY = last.velocityY;\n        direction = last.direction;\n    }\n\n    input.velocity = velocity;\n    input.velocityX = velocityX;\n    input.velocityY = velocityY;\n    input.direction = direction;\n}\n\n/**\n * create a simple clone from the input used for storage of firstInput and firstMultiple\n * @param {Object} input\n * @returns {Object} clonedInputData\n */\nfunction simpleCloneInputData(input) {\n    // make a simple copy of the pointers because we will get a reference if we don't\n    // we only need clientXY for the calculations\n    var pointers = [];\n    var i = 0;\n    while (i < input.pointers.length) {\n        pointers[i] = {\n            clientX: round(input.pointers[i].clientX),\n            clientY: round(input.pointers[i].clientY)\n        };\n        i++;\n    }\n\n    return {\n        timeStamp: now(),\n        pointers: pointers,\n        center: getCenter(pointers),\n        deltaX: input.deltaX,\n        deltaY: input.deltaY\n    };\n}\n\n/**\n * get the center of all the pointers\n * @param {Array} pointers\n * @return {Object} center contains `x` and `y` properties\n */\nfunction getCenter(pointers) {\n    var pointersLength = pointers.length;\n\n    // no need to loop when only one touch\n    if (pointersLength === 1) {\n        return {\n            x: round(pointers[0].clientX),\n            y: round(pointers[0].clientY)\n        };\n    }\n\n    var x = 0, y = 0, i = 0;\n    while (i < pointersLength) {\n        x += pointers[i].clientX;\n        y += pointers[i].clientY;\n        i++;\n    }\n\n    return {\n        x: round(x / pointersLength),\n        y: round(y / pointersLength)\n    };\n}\n\n/**\n * calculate the velocity between two points. unit is in px per ms.\n * @param {Number} deltaTime\n * @param {Number} x\n * @param {Number} y\n * @return {Object} velocity `x` and `y`\n */\nfunction getVelocity(deltaTime, x, y) {\n    return {\n        x: x / deltaTime || 0,\n        y: y / deltaTime || 0\n    };\n}\n\n/**\n * get the direction between two points\n * @param {Number} x\n * @param {Number} y\n * @return {Number} direction\n */\nfunction getDirection(x, y) {\n    if (x === y) {\n        return DIRECTION_NONE;\n    }\n\n    if (abs(x) >= abs(y)) {\n        return x < 0 ? DIRECTION_LEFT : DIRECTION_RIGHT;\n    }\n    return y < 0 ? DIRECTION_UP : DIRECTION_DOWN;\n}\n\n/**\n * calculate the absolute distance between two points\n * @param {Object} p1 {x, y}\n * @param {Object} p2 {x, y}\n * @param {Array} [props] containing x and y keys\n * @return {Number} distance\n */\nfunction getDistance(p1, p2, props) {\n    if (!props) {\n        props = PROPS_XY;\n    }\n    var x = p2[props[0]] - p1[props[0]],\n        y = p2[props[1]] - p1[props[1]];\n\n    return Math.sqrt((x * x) + (y * y));\n}\n\n/**\n * calculate the angle between two coordinates\n * @param {Object} p1\n * @param {Object} p2\n * @param {Array} [props] containing x and y keys\n * @return {Number} angle\n */\nfunction getAngle(p1, p2, props) {\n    if (!props) {\n        props = PROPS_XY;\n    }\n    var x = p2[props[0]] - p1[props[0]],\n        y = p2[props[1]] - p1[props[1]];\n    return Math.atan2(y, x) * 180 / Math.PI;\n}\n\n/**\n * calculate the rotation degrees between two pointersets\n * @param {Array} start array of pointers\n * @param {Array} end array of pointers\n * @return {Number} rotation\n */\nfunction getRotation(start, end) {\n    return getAngle(end[1], end[0], PROPS_CLIENT_XY) + getAngle(start[1], start[0], PROPS_CLIENT_XY);\n}\n\n/**\n * calculate the scale factor between two pointersets\n * no scale is 1, and goes down to 0 when pinched together, and bigger when pinched out\n * @param {Array} start array of pointers\n * @param {Array} end array of pointers\n * @return {Number} scale\n */\nfunction getScale(start, end) {\n    return getDistance(end[0], end[1], PROPS_CLIENT_XY) / getDistance(start[0], start[1], PROPS_CLIENT_XY);\n}\n\nvar MOUSE_INPUT_MAP = {\n    mousedown: INPUT_START,\n    mousemove: INPUT_MOVE,\n    mouseup: INPUT_END\n};\n\nvar MOUSE_ELEMENT_EVENTS = 'mousedown';\nvar MOUSE_WINDOW_EVENTS = 'mousemove mouseup';\n\n/**\n * Mouse events input\n * @constructor\n * @extends Input\n */\nfunction MouseInput() {\n    this.evEl = MOUSE_ELEMENT_EVENTS;\n    this.evWin = MOUSE_WINDOW_EVENTS;\n\n    this.pressed = false; // mousedown state\n\n    Input.apply(this, arguments);\n}\n\ninherit(MouseInput, Input, {\n    /**\n     * handle mouse events\n     * @param {Object} ev\n     */\n    handler: function MEhandler(ev) {\n        var eventType = MOUSE_INPUT_MAP[ev.type];\n\n        // on start we want to have the left mouse button down\n        if (eventType & INPUT_START && ev.button === 0) {\n            this.pressed = true;\n        }\n\n        if (eventType & INPUT_MOVE && ev.which !== 1) {\n            eventType = INPUT_END;\n        }\n\n        // mouse must be down\n        if (!this.pressed) {\n            return;\n        }\n\n        if (eventType & INPUT_END) {\n            this.pressed = false;\n        }\n\n        this.callback(this.manager, eventType, {\n            pointers: [ev],\n            changedPointers: [ev],\n            pointerType: INPUT_TYPE_MOUSE,\n            srcEvent: ev\n        });\n    }\n});\n\nvar POINTER_INPUT_MAP = {\n    pointerdown: INPUT_START,\n    pointermove: INPUT_MOVE,\n    pointerup: INPUT_END,\n    pointercancel: INPUT_CANCEL,\n    pointerout: INPUT_CANCEL\n};\n\n// in IE10 the pointer types is defined as an enum\nvar IE10_POINTER_TYPE_ENUM = {\n    2: INPUT_TYPE_TOUCH,\n    3: INPUT_TYPE_PEN,\n    4: INPUT_TYPE_MOUSE,\n    5: INPUT_TYPE_KINECT // see https://twitter.com/jacobrossi/status/480596438489890816\n};\n\nvar POINTER_ELEMENT_EVENTS = 'pointerdown';\nvar POINTER_WINDOW_EVENTS = 'pointermove pointerup pointercancel';\n\n// IE10 has prefixed support, and case-sensitive\nif (window.MSPointerEvent && !window.PointerEvent) {\n    POINTER_ELEMENT_EVENTS = 'MSPointerDown';\n    POINTER_WINDOW_EVENTS = 'MSPointerMove MSPointerUp MSPointerCancel';\n}\n\n/**\n * Pointer events input\n * @constructor\n * @extends Input\n */\nfunction PointerEventInput() {\n    this.evEl = POINTER_ELEMENT_EVENTS;\n    this.evWin = POINTER_WINDOW_EVENTS;\n\n    Input.apply(this, arguments);\n\n    this.store = (this.manager.session.pointerEvents = []);\n}\n\ninherit(PointerEventInput, Input, {\n    /**\n     * handle mouse events\n     * @param {Object} ev\n     */\n    handler: function PEhandler(ev) {\n        var store = this.store;\n        var removePointer = false;\n\n        var eventTypeNormalized = ev.type.toLowerCase().replace('ms', '');\n        var eventType = POINTER_INPUT_MAP[eventTypeNormalized];\n        var pointerType = IE10_POINTER_TYPE_ENUM[ev.pointerType] || ev.pointerType;\n\n        var isTouch = (pointerType == INPUT_TYPE_TOUCH);\n\n        // get index of the event in the store\n        var storeIndex = inArray(store, ev.pointerId, 'pointerId');\n\n        // start and mouse must be down\n        if (eventType & INPUT_START && (ev.button === 0 || isTouch)) {\n            if (storeIndex < 0) {\n                store.push(ev);\n                storeIndex = store.length - 1;\n            }\n        } else if (eventType & (INPUT_END | INPUT_CANCEL)) {\n            removePointer = true;\n        }\n\n        // it not found, so the pointer hasn't been down (so it's probably a hover)\n        if (storeIndex < 0) {\n            return;\n        }\n\n        // update the event in the store\n        store[storeIndex] = ev;\n\n        this.callback(this.manager, eventType, {\n            pointers: store,\n            changedPointers: [ev],\n            pointerType: pointerType,\n            srcEvent: ev\n        });\n\n        if (removePointer) {\n            // remove from the store\n            store.splice(storeIndex, 1);\n        }\n    }\n});\n\nvar SINGLE_TOUCH_INPUT_MAP = {\n    touchstart: INPUT_START,\n    touchmove: INPUT_MOVE,\n    touchend: INPUT_END,\n    touchcancel: INPUT_CANCEL\n};\n\nvar SINGLE_TOUCH_TARGET_EVENTS = 'touchstart';\nvar SINGLE_TOUCH_WINDOW_EVENTS = 'touchstart touchmove touchend touchcancel';\n\n/**\n * Touch events input\n * @constructor\n * @extends Input\n */\nfunction SingleTouchInput() {\n    this.evTarget = SINGLE_TOUCH_TARGET_EVENTS;\n    this.evWin = SINGLE_TOUCH_WINDOW_EVENTS;\n    this.started = false;\n\n    Input.apply(this, arguments);\n}\n\ninherit(SingleTouchInput, Input, {\n    handler: function TEhandler(ev) {\n        var type = SINGLE_TOUCH_INPUT_MAP[ev.type];\n\n        // should we handle the touch events?\n        if (type === INPUT_START) {\n            this.started = true;\n        }\n\n        if (!this.started) {\n            return;\n        }\n\n        var touches = normalizeSingleTouches.call(this, ev, type);\n\n        // when done, reset the started state\n        if (type & (INPUT_END | INPUT_CANCEL) && touches[0].length - touches[1].length === 0) {\n            this.started = false;\n        }\n\n        this.callback(this.manager, type, {\n            pointers: touches[0],\n            changedPointers: touches[1],\n            pointerType: INPUT_TYPE_TOUCH,\n            srcEvent: ev\n        });\n    }\n});\n\n/**\n * @this {TouchInput}\n * @param {Object} ev\n * @param {Number} type flag\n * @returns {undefined|Array} [all, changed]\n */\nfunction normalizeSingleTouches(ev, type) {\n    var all = toArray(ev.touches);\n    var changed = toArray(ev.changedTouches);\n\n    if (type & (INPUT_END | INPUT_CANCEL)) {\n        all = uniqueArray(all.concat(changed), 'identifier', true);\n    }\n\n    return [all, changed];\n}\n\nvar TOUCH_INPUT_MAP = {\n    touchstart: INPUT_START,\n    touchmove: INPUT_MOVE,\n    touchend: INPUT_END,\n    touchcancel: INPUT_CANCEL\n};\n\nvar TOUCH_TARGET_EVENTS = 'touchstart touchmove touchend touchcancel';\n\n/**\n * Multi-user touch events input\n * @constructor\n * @extends Input\n */\nfunction TouchInput() {\n    this.evTarget = TOUCH_TARGET_EVENTS;\n    this.targetIds = {};\n\n    Input.apply(this, arguments);\n}\n\ninherit(TouchInput, Input, {\n    handler: function MTEhandler(ev) {\n        var type = TOUCH_INPUT_MAP[ev.type];\n        var touches = getTouches.call(this, ev, type);\n        if (!touches) {\n            return;\n        }\n\n        this.callback(this.manager, type, {\n            pointers: touches[0],\n            changedPointers: touches[1],\n            pointerType: INPUT_TYPE_TOUCH,\n            srcEvent: ev\n        });\n    }\n});\n\n/**\n * @this {TouchInput}\n * @param {Object} ev\n * @param {Number} type flag\n * @returns {undefined|Array} [all, changed]\n */\nfunction getTouches(ev, type) {\n    var allTouches = toArray(ev.touches);\n    var targetIds = this.targetIds;\n\n    // when there is only one touch, the process can be simplified\n    if (type & (INPUT_START | INPUT_MOVE) && allTouches.length === 1) {\n        targetIds[allTouches[0].identifier] = true;\n        return [allTouches, allTouches];\n    }\n\n    var i,\n        targetTouches,\n        changedTouches = toArray(ev.changedTouches),\n        changedTargetTouches = [],\n        target = this.target;\n\n    // get target touches from touches\n    targetTouches = allTouches.filter(function(touch) {\n        return hasParent(touch.target, target);\n    });\n\n    // collect touches\n    if (type === INPUT_START) {\n        i = 0;\n        while (i < targetTouches.length) {\n            targetIds[targetTouches[i].identifier] = true;\n            i++;\n        }\n    }\n\n    // filter changed touches to only contain touches that exist in the collected target ids\n    i = 0;\n    while (i < changedTouches.length) {\n        if (targetIds[changedTouches[i].identifier]) {\n            changedTargetTouches.push(changedTouches[i]);\n        }\n\n        // cleanup removed touches\n        if (type & (INPUT_END | INPUT_CANCEL)) {\n            delete targetIds[changedTouches[i].identifier];\n        }\n        i++;\n    }\n\n    if (!changedTargetTouches.length) {\n        return;\n    }\n\n    return [\n        // merge targetTouches with changedTargetTouches so it contains ALL touches, including 'end' and 'cancel'\n        uniqueArray(targetTouches.concat(changedTargetTouches), 'identifier', true),\n        changedTargetTouches\n    ];\n}\n\n/**\n * Combined touch and mouse input\n *\n * Touch has a higher priority then mouse, and while touching no mouse events are allowed.\n * This because touch devices also emit mouse events while doing a touch.\n *\n * @constructor\n * @extends Input\n */\n\nvar DEDUP_TIMEOUT = 2500;\nvar DEDUP_DISTANCE = 25;\n\nfunction TouchMouseInput() {\n    Input.apply(this, arguments);\n\n    var handler = bindFn(this.handler, this);\n    this.touch = new TouchInput(this.manager, handler);\n    this.mouse = new MouseInput(this.manager, handler);\n\n    this.primaryTouch = null;\n    this.lastTouches = [];\n}\n\ninherit(TouchMouseInput, Input, {\n    /**\n     * handle mouse and touch events\n     * @param {Hammer} manager\n     * @param {String} inputEvent\n     * @param {Object} inputData\n     */\n    handler: function TMEhandler(manager, inputEvent, inputData) {\n        var isTouch = (inputData.pointerType == INPUT_TYPE_TOUCH),\n            isMouse = (inputData.pointerType == INPUT_TYPE_MOUSE);\n\n        if (isMouse && inputData.sourceCapabilities && inputData.sourceCapabilities.firesTouchEvents) {\n            return;\n        }\n\n        // when we're in a touch event, record touches to  de-dupe synthetic mouse event\n        if (isTouch) {\n            recordTouches.call(this, inputEvent, inputData);\n        } else if (isMouse && isSyntheticEvent.call(this, inputData)) {\n            return;\n        }\n\n        this.callback(manager, inputEvent, inputData);\n    },\n\n    /**\n     * remove the event listeners\n     */\n    destroy: function destroy() {\n        this.touch.destroy();\n        this.mouse.destroy();\n    }\n});\n\nfunction recordTouches(eventType, eventData) {\n    if (eventType & INPUT_START) {\n        this.primaryTouch = eventData.changedPointers[0].identifier;\n        setLastTouch.call(this, eventData);\n    } else if (eventType & (INPUT_END | INPUT_CANCEL)) {\n        setLastTouch.call(this, eventData);\n    }\n}\n\nfunction setLastTouch(eventData) {\n    var touch = eventData.changedPointers[0];\n\n    if (touch.identifier === this.primaryTouch) {\n        var lastTouch = {x: touch.clientX, y: touch.clientY};\n        this.lastTouches.push(lastTouch);\n        var lts = this.lastTouches;\n        var removeLastTouch = function() {\n            var i = lts.indexOf(lastTouch);\n            if (i > -1) {\n                lts.splice(i, 1);\n            }\n        };\n        setTimeout(removeLastTouch, DEDUP_TIMEOUT);\n    }\n}\n\nfunction isSyntheticEvent(eventData) {\n    var x = eventData.srcEvent.clientX, y = eventData.srcEvent.clientY;\n    for (var i = 0; i < this.lastTouches.length; i++) {\n        var t = this.lastTouches[i];\n        var dx = Math.abs(x - t.x), dy = Math.abs(y - t.y);\n        if (dx <= DEDUP_DISTANCE && dy <= DEDUP_DISTANCE) {\n            return true;\n        }\n    }\n    return false;\n}\n\nvar PREFIXED_TOUCH_ACTION = prefixed(TEST_ELEMENT.style, 'touchAction');\nvar NATIVE_TOUCH_ACTION = PREFIXED_TOUCH_ACTION !== undefined;\n\n// magical touchAction value\nvar TOUCH_ACTION_COMPUTE = 'compute';\nvar TOUCH_ACTION_AUTO = 'auto';\nvar TOUCH_ACTION_MANIPULATION = 'manipulation'; // not implemented\nvar TOUCH_ACTION_NONE = 'none';\nvar TOUCH_ACTION_PAN_X = 'pan-x';\nvar TOUCH_ACTION_PAN_Y = 'pan-y';\nvar TOUCH_ACTION_MAP = getTouchActionProps();\n\n/**\n * Touch Action\n * sets the touchAction property or uses the js alternative\n * @param {Manager} manager\n * @param {String} value\n * @constructor\n */\nfunction TouchAction(manager, value) {\n    this.manager = manager;\n    this.set(value);\n}\n\nTouchAction.prototype = {\n    /**\n     * set the touchAction value on the element or enable the polyfill\n     * @param {String} value\n     */\n    set: function(value) {\n        // find out the touch-action by the event handlers\n        if (value == TOUCH_ACTION_COMPUTE) {\n            value = this.compute();\n        }\n\n        if (NATIVE_TOUCH_ACTION && this.manager.element.style && TOUCH_ACTION_MAP[value]) {\n            this.manager.element.style[PREFIXED_TOUCH_ACTION] = value;\n        }\n        this.actions = value.toLowerCase().trim();\n    },\n\n    /**\n     * just re-set the touchAction value\n     */\n    update: function() {\n        this.set(this.manager.options.touchAction);\n    },\n\n    /**\n     * compute the value for the touchAction property based on the recognizer's settings\n     * @returns {String} value\n     */\n    compute: function() {\n        var actions = [];\n        each(this.manager.recognizers, function(recognizer) {\n            if (boolOrFn(recognizer.options.enable, [recognizer])) {\n                actions = actions.concat(recognizer.getTouchAction());\n            }\n        });\n        return cleanTouchActions(actions.join(' '));\n    },\n\n    /**\n     * this method is called on each input cycle and provides the preventing of the browser behavior\n     * @param {Object} input\n     */\n    preventDefaults: function(input) {\n        var srcEvent = input.srcEvent;\n        var direction = input.offsetDirection;\n\n        // if the touch action did prevented once this session\n        if (this.manager.session.prevented) {\n            srcEvent.preventDefault();\n            return;\n        }\n\n        var actions = this.actions;\n        var hasNone = inStr(actions, TOUCH_ACTION_NONE) && !TOUCH_ACTION_MAP[TOUCH_ACTION_NONE];\n        var hasPanY = inStr(actions, TOUCH_ACTION_PAN_Y) && !TOUCH_ACTION_MAP[TOUCH_ACTION_PAN_Y];\n        var hasPanX = inStr(actions, TOUCH_ACTION_PAN_X) && !TOUCH_ACTION_MAP[TOUCH_ACTION_PAN_X];\n\n        if (hasNone) {\n            //do not prevent defaults if this is a tap gesture\n\n            var isTapPointer = input.pointers.length === 1;\n            var isTapMovement = input.distance < 2;\n            var isTapTouchTime = input.deltaTime < 250;\n\n            if (isTapPointer && isTapMovement && isTapTouchTime) {\n                return;\n            }\n        }\n\n        if (hasPanX && hasPanY) {\n            // `pan-x pan-y` means browser handles all scrolling/panning, do not prevent\n            return;\n        }\n\n        if (hasNone ||\n            (hasPanY && direction & DIRECTION_HORIZONTAL) ||\n            (hasPanX && direction & DIRECTION_VERTICAL)) {\n            return this.preventSrc(srcEvent);\n        }\n    },\n\n    /**\n     * call preventDefault to prevent the browser's default behavior (scrolling in most cases)\n     * @param {Object} srcEvent\n     */\n    preventSrc: function(srcEvent) {\n        this.manager.session.prevented = true;\n        srcEvent.preventDefault();\n    }\n};\n\n/**\n * when the touchActions are collected they are not a valid value, so we need to clean things up. *\n * @param {String} actions\n * @returns {*}\n */\nfunction cleanTouchActions(actions) {\n    // none\n    if (inStr(actions, TOUCH_ACTION_NONE)) {\n        return TOUCH_ACTION_NONE;\n    }\n\n    var hasPanX = inStr(actions, TOUCH_ACTION_PAN_X);\n    var hasPanY = inStr(actions, TOUCH_ACTION_PAN_Y);\n\n    // if both pan-x and pan-y are set (different recognizers\n    // for different directions, e.g. horizontal pan but vertical swipe?)\n    // we need none (as otherwise with pan-x pan-y combined none of these\n    // recognizers will work, since the browser would handle all panning\n    if (hasPanX && hasPanY) {\n        return TOUCH_ACTION_NONE;\n    }\n\n    // pan-x OR pan-y\n    if (hasPanX || hasPanY) {\n        return hasPanX ? TOUCH_ACTION_PAN_X : TOUCH_ACTION_PAN_Y;\n    }\n\n    // manipulation\n    if (inStr(actions, TOUCH_ACTION_MANIPULATION)) {\n        return TOUCH_ACTION_MANIPULATION;\n    }\n\n    return TOUCH_ACTION_AUTO;\n}\n\nfunction getTouchActionProps() {\n    if (!NATIVE_TOUCH_ACTION) {\n        return false;\n    }\n    var touchMap = {};\n    var cssSupports = window.CSS && window.CSS.supports;\n    ['auto', 'manipulation', 'pan-y', 'pan-x', 'pan-x pan-y', 'none'].forEach(function(val) {\n\n        // If css.supports is not supported but there is native touch-action assume it supports\n        // all values. This is the case for IE 10 and 11.\n        touchMap[val] = cssSupports ? window.CSS.supports('touch-action', val) : true;\n    });\n    return touchMap;\n}\n\n/**\n * Recognizer flow explained; *\n * All recognizers have the initial state of POSSIBLE when a input session starts.\n * The definition of a input session is from the first input until the last input, with all it's movement in it. *\n * Example session for mouse-input: mousedown -> mousemove -> mouseup\n *\n * On each recognizing cycle (see Manager.recognize) the .recognize() method is executed\n * which determines with state it should be.\n *\n * If the recognizer has the state FAILED, CANCELLED or RECOGNIZED (equals ENDED), it is reset to\n * POSSIBLE to give it another change on the next cycle.\n *\n *               Possible\n *                  |\n *            +-----+---------------+\n *            |                     |\n *      +-----+-----+               |\n *      |           |               |\n *   Failed      Cancelled          |\n *                          +-------+------+\n *                          |              |\n *                      Recognized       Began\n *                                         |\n *                                      Changed\n *                                         |\n *                                  Ended/Recognized\n */\nvar STATE_POSSIBLE = 1;\nvar STATE_BEGAN = 2;\nvar STATE_CHANGED = 4;\nvar STATE_ENDED = 8;\nvar STATE_RECOGNIZED = STATE_ENDED;\nvar STATE_CANCELLED = 16;\nvar STATE_FAILED = 32;\n\n/**\n * Recognizer\n * Every recognizer needs to extend from this class.\n * @constructor\n * @param {Object} options\n */\nfunction Recognizer(options) {\n    this.options = assign({}, this.defaults, options || {});\n\n    this.id = uniqueId();\n\n    this.manager = null;\n\n    // default is enable true\n    this.options.enable = ifUndefined(this.options.enable, true);\n\n    this.state = STATE_POSSIBLE;\n\n    this.simultaneous = {};\n    this.requireFail = [];\n}\n\nRecognizer.prototype = {\n    /**\n     * @virtual\n     * @type {Object}\n     */\n    defaults: {},\n\n    /**\n     * set options\n     * @param {Object} options\n     * @return {Recognizer}\n     */\n    set: function(options) {\n        assign(this.options, options);\n\n        // also update the touchAction, in case something changed about the directions/enabled state\n        this.manager && this.manager.touchAction.update();\n        return this;\n    },\n\n    /**\n     * recognize simultaneous with an other recognizer.\n     * @param {Recognizer} otherRecognizer\n     * @returns {Recognizer} this\n     */\n    recognizeWith: function(otherRecognizer) {\n        if (invokeArrayArg(otherRecognizer, 'recognizeWith', this)) {\n            return this;\n        }\n\n        var simultaneous = this.simultaneous;\n        otherRecognizer = getRecognizerByNameIfManager(otherRecognizer, this);\n        if (!simultaneous[otherRecognizer.id]) {\n            simultaneous[otherRecognizer.id] = otherRecognizer;\n            otherRecognizer.recognizeWith(this);\n        }\n        return this;\n    },\n\n    /**\n     * drop the simultaneous link. it doesnt remove the link on the other recognizer.\n     * @param {Recognizer} otherRecognizer\n     * @returns {Recognizer} this\n     */\n    dropRecognizeWith: function(otherRecognizer) {\n        if (invokeArrayArg(otherRecognizer, 'dropRecognizeWith', this)) {\n            return this;\n        }\n\n        otherRecognizer = getRecognizerByNameIfManager(otherRecognizer, this);\n        delete this.simultaneous[otherRecognizer.id];\n        return this;\n    },\n\n    /**\n     * recognizer can only run when an other is failing\n     * @param {Recognizer} otherRecognizer\n     * @returns {Recognizer} this\n     */\n    requireFailure: function(otherRecognizer) {\n        if (invokeArrayArg(otherRecognizer, 'requireFailure', this)) {\n            return this;\n        }\n\n        var requireFail = this.requireFail;\n        otherRecognizer = getRecognizerByNameIfManager(otherRecognizer, this);\n        if (inArray(requireFail, otherRecognizer) === -1) {\n            requireFail.push(otherRecognizer);\n            otherRecognizer.requireFailure(this);\n        }\n        return this;\n    },\n\n    /**\n     * drop the requireFailure link. it does not remove the link on the other recognizer.\n     * @param {Recognizer} otherRecognizer\n     * @returns {Recognizer} this\n     */\n    dropRequireFailure: function(otherRecognizer) {\n        if (invokeArrayArg(otherRecognizer, 'dropRequireFailure', this)) {\n            return this;\n        }\n\n        otherRecognizer = getRecognizerByNameIfManager(otherRecognizer, this);\n        var index = inArray(this.requireFail, otherRecognizer);\n        if (index > -1) {\n            this.requireFail.splice(index, 1);\n        }\n        return this;\n    },\n\n    /**\n     * has require failures boolean\n     * @returns {boolean}\n     */\n    hasRequireFailures: function() {\n        return this.requireFail.length > 0;\n    },\n\n    /**\n     * if the recognizer can recognize simultaneous with an other recognizer\n     * @param {Recognizer} otherRecognizer\n     * @returns {Boolean}\n     */\n    canRecognizeWith: function(otherRecognizer) {\n        return !!this.simultaneous[otherRecognizer.id];\n    },\n\n    /**\n     * You should use `tryEmit` instead of `emit` directly to check\n     * that all the needed recognizers has failed before emitting.\n     * @param {Object} input\n     */\n    emit: function(input) {\n        var self = this;\n        var state = this.state;\n\n        function emit(event) {\n            self.manager.emit(event, input);\n        }\n\n        // 'panstart' and 'panmove'\n        if (state < STATE_ENDED) {\n            emit(self.options.event + stateStr(state));\n        }\n\n        emit(self.options.event); // simple 'eventName' events\n\n        if (input.additionalEvent) { // additional event(panleft, panright, pinchin, pinchout...)\n            emit(input.additionalEvent);\n        }\n\n        // panend and pancancel\n        if (state >= STATE_ENDED) {\n            emit(self.options.event + stateStr(state));\n        }\n    },\n\n    /**\n     * Check that all the require failure recognizers has failed,\n     * if true, it emits a gesture event,\n     * otherwise, setup the state to FAILED.\n     * @param {Object} input\n     */\n    tryEmit: function(input) {\n        if (this.canEmit()) {\n            return this.emit(input);\n        }\n        // it's failing anyway\n        this.state = STATE_FAILED;\n    },\n\n    /**\n     * can we emit?\n     * @returns {boolean}\n     */\n    canEmit: function() {\n        var i = 0;\n        while (i < this.requireFail.length) {\n            if (!(this.requireFail[i].state & (STATE_FAILED | STATE_POSSIBLE))) {\n                return false;\n            }\n            i++;\n        }\n        return true;\n    },\n\n    /**\n     * update the recognizer\n     * @param {Object} inputData\n     */\n    recognize: function(inputData) {\n        // make a new copy of the inputData\n        // so we can change the inputData without messing up the other recognizers\n        var inputDataClone = assign({}, inputData);\n\n        // is is enabled and allow recognizing?\n        if (!boolOrFn(this.options.enable, [this, inputDataClone])) {\n            this.reset();\n            this.state = STATE_FAILED;\n            return;\n        }\n\n        // reset when we've reached the end\n        if (this.state & (STATE_RECOGNIZED | STATE_CANCELLED | STATE_FAILED)) {\n            this.state = STATE_POSSIBLE;\n        }\n\n        this.state = this.process(inputDataClone);\n\n        // the recognizer has recognized a gesture\n        // so trigger an event\n        if (this.state & (STATE_BEGAN | STATE_CHANGED | STATE_ENDED | STATE_CANCELLED)) {\n            this.tryEmit(inputDataClone);\n        }\n    },\n\n    /**\n     * return the state of the recognizer\n     * the actual recognizing happens in this method\n     * @virtual\n     * @param {Object} inputData\n     * @returns {Const} STATE\n     */\n    process: function(inputData) { }, // jshint ignore:line\n\n    /**\n     * return the preferred touch-action\n     * @virtual\n     * @returns {Array}\n     */\n    getTouchAction: function() { },\n\n    /**\n     * called when the gesture isn't allowed to recognize\n     * like when another is being recognized or it is disabled\n     * @virtual\n     */\n    reset: function() { }\n};\n\n/**\n * get a usable string, used as event postfix\n * @param {Const} state\n * @returns {String} state\n */\nfunction stateStr(state) {\n    if (state & STATE_CANCELLED) {\n        return 'cancel';\n    } else if (state & STATE_ENDED) {\n        return 'end';\n    } else if (state & STATE_CHANGED) {\n        return 'move';\n    } else if (state & STATE_BEGAN) {\n        return 'start';\n    }\n    return '';\n}\n\n/**\n * direction cons to string\n * @param {Const} direction\n * @returns {String}\n */\nfunction directionStr(direction) {\n    if (direction == DIRECTION_DOWN) {\n        return 'down';\n    } else if (direction == DIRECTION_UP) {\n        return 'up';\n    } else if (direction == DIRECTION_LEFT) {\n        return 'left';\n    } else if (direction == DIRECTION_RIGHT) {\n        return 'right';\n    }\n    return '';\n}\n\n/**\n * get a recognizer by name if it is bound to a manager\n * @param {Recognizer|String} otherRecognizer\n * @param {Recognizer} recognizer\n * @returns {Recognizer}\n */\nfunction getRecognizerByNameIfManager(otherRecognizer, recognizer) {\n    var manager = recognizer.manager;\n    if (manager) {\n        return manager.get(otherRecognizer);\n    }\n    return otherRecognizer;\n}\n\n/**\n * This recognizer is just used as a base for the simple attribute recognizers.\n * @constructor\n * @extends Recognizer\n */\nfunction AttrRecognizer() {\n    Recognizer.apply(this, arguments);\n}\n\ninherit(AttrRecognizer, Recognizer, {\n    /**\n     * @namespace\n     * @memberof AttrRecognizer\n     */\n    defaults: {\n        /**\n         * @type {Number}\n         * @default 1\n         */\n        pointers: 1\n    },\n\n    /**\n     * Used to check if it the recognizer receives valid input, like input.distance > 10.\n     * @memberof AttrRecognizer\n     * @param {Object} input\n     * @returns {Boolean} recognized\n     */\n    attrTest: function(input) {\n        var optionPointers = this.options.pointers;\n        return optionPointers === 0 || input.pointers.length === optionPointers;\n    },\n\n    /**\n     * Process the input and return the state for the recognizer\n     * @memberof AttrRecognizer\n     * @param {Object} input\n     * @returns {*} State\n     */\n    process: function(input) {\n        var state = this.state;\n        var eventType = input.eventType;\n\n        var isRecognized = state & (STATE_BEGAN | STATE_CHANGED);\n        var isValid = this.attrTest(input);\n\n        // on cancel input and we've recognized before, return STATE_CANCELLED\n        if (isRecognized && (eventType & INPUT_CANCEL || !isValid)) {\n            return state | STATE_CANCELLED;\n        } else if (isRecognized || isValid) {\n            if (eventType & INPUT_END) {\n                return state | STATE_ENDED;\n            } else if (!(state & STATE_BEGAN)) {\n                return STATE_BEGAN;\n            }\n            return state | STATE_CHANGED;\n        }\n        return STATE_FAILED;\n    }\n});\n\n/**\n * Pan\n * Recognized when the pointer is down and moved in the allowed direction.\n * @constructor\n * @extends AttrRecognizer\n */\nfunction PanRecognizer() {\n    AttrRecognizer.apply(this, arguments);\n\n    this.pX = null;\n    this.pY = null;\n}\n\ninherit(PanRecognizer, AttrRecognizer, {\n    /**\n     * @namespace\n     * @memberof PanRecognizer\n     */\n    defaults: {\n        event: 'pan',\n        threshold: 10,\n        pointers: 1,\n        direction: DIRECTION_ALL\n    },\n\n    getTouchAction: function() {\n        var direction = this.options.direction;\n        var actions = [];\n        if (direction & DIRECTION_HORIZONTAL) {\n            actions.push(TOUCH_ACTION_PAN_Y);\n        }\n        if (direction & DIRECTION_VERTICAL) {\n            actions.push(TOUCH_ACTION_PAN_X);\n        }\n        return actions;\n    },\n\n    directionTest: function(input) {\n        var options = this.options;\n        var hasMoved = true;\n        var distance = input.distance;\n        var direction = input.direction;\n        var x = input.deltaX;\n        var y = input.deltaY;\n\n        // lock to axis?\n        if (!(direction & options.direction)) {\n            if (options.direction & DIRECTION_HORIZONTAL) {\n                direction = (x === 0) ? DIRECTION_NONE : (x < 0) ? DIRECTION_LEFT : DIRECTION_RIGHT;\n                hasMoved = x != this.pX;\n                distance = Math.abs(input.deltaX);\n            } else {\n                direction = (y === 0) ? DIRECTION_NONE : (y < 0) ? DIRECTION_UP : DIRECTION_DOWN;\n                hasMoved = y != this.pY;\n                distance = Math.abs(input.deltaY);\n            }\n        }\n        input.direction = direction;\n        return hasMoved && distance > options.threshold && direction & options.direction;\n    },\n\n    attrTest: function(input) {\n        return AttrRecognizer.prototype.attrTest.call(this, input) &&\n            (this.state & STATE_BEGAN || (!(this.state & STATE_BEGAN) && this.directionTest(input)));\n    },\n\n    emit: function(input) {\n\n        this.pX = input.deltaX;\n        this.pY = input.deltaY;\n\n        var direction = directionStr(input.direction);\n\n        if (direction) {\n            input.additionalEvent = this.options.event + direction;\n        }\n        this._super.emit.call(this, input);\n    }\n});\n\n/**\n * Pinch\n * Recognized when two or more pointers are moving toward (zoom-in) or away from each other (zoom-out).\n * @constructor\n * @extends AttrRecognizer\n */\nfunction PinchRecognizer() {\n    AttrRecognizer.apply(this, arguments);\n}\n\ninherit(PinchRecognizer, AttrRecognizer, {\n    /**\n     * @namespace\n     * @memberof PinchRecognizer\n     */\n    defaults: {\n        event: 'pinch',\n        threshold: 0,\n        pointers: 2\n    },\n\n    getTouchAction: function() {\n        return [TOUCH_ACTION_NONE];\n    },\n\n    attrTest: function(input) {\n        return this._super.attrTest.call(this, input) &&\n            (Math.abs(input.scale - 1) > this.options.threshold || this.state & STATE_BEGAN);\n    },\n\n    emit: function(input) {\n        if (input.scale !== 1) {\n            var inOut = input.scale < 1 ? 'in' : 'out';\n            input.additionalEvent = this.options.event + inOut;\n        }\n        this._super.emit.call(this, input);\n    }\n});\n\n/**\n * Press\n * Recognized when the pointer is down for x ms without any movement.\n * @constructor\n * @extends Recognizer\n */\nfunction PressRecognizer() {\n    Recognizer.apply(this, arguments);\n\n    this._timer = null;\n    this._input = null;\n}\n\ninherit(PressRecognizer, Recognizer, {\n    /**\n     * @namespace\n     * @memberof PressRecognizer\n     */\n    defaults: {\n        event: 'press',\n        pointers: 1,\n        time: 251, // minimal time of the pointer to be pressed\n        threshold: 9 // a minimal movement is ok, but keep it low\n    },\n\n    getTouchAction: function() {\n        return [TOUCH_ACTION_AUTO];\n    },\n\n    process: function(input) {\n        var options = this.options;\n        var validPointers = input.pointers.length === options.pointers;\n        var validMovement = input.distance < options.threshold;\n        var validTime = input.deltaTime > options.time;\n\n        this._input = input;\n\n        // we only allow little movement\n        // and we've reached an end event, so a tap is possible\n        if (!validMovement || !validPointers || (input.eventType & (INPUT_END | INPUT_CANCEL) && !validTime)) {\n            this.reset();\n        } else if (input.eventType & INPUT_START) {\n            this.reset();\n            this._timer = setTimeoutContext(function() {\n                this.state = STATE_RECOGNIZED;\n                this.tryEmit();\n            }, options.time, this);\n        } else if (input.eventType & INPUT_END) {\n            return STATE_RECOGNIZED;\n        }\n        return STATE_FAILED;\n    },\n\n    reset: function() {\n        clearTimeout(this._timer);\n    },\n\n    emit: function(input) {\n        if (this.state !== STATE_RECOGNIZED) {\n            return;\n        }\n\n        if (input && (input.eventType & INPUT_END)) {\n            this.manager.emit(this.options.event + 'up', input);\n        } else {\n            this._input.timeStamp = now();\n            this.manager.emit(this.options.event, this._input);\n        }\n    }\n});\n\n/**\n * Rotate\n * Recognized when two or more pointer are moving in a circular motion.\n * @constructor\n * @extends AttrRecognizer\n */\nfunction RotateRecognizer() {\n    AttrRecognizer.apply(this, arguments);\n}\n\ninherit(RotateRecognizer, AttrRecognizer, {\n    /**\n     * @namespace\n     * @memberof RotateRecognizer\n     */\n    defaults: {\n        event: 'rotate',\n        threshold: 0,\n        pointers: 2\n    },\n\n    getTouchAction: function() {\n        return [TOUCH_ACTION_NONE];\n    },\n\n    attrTest: function(input) {\n        return this._super.attrTest.call(this, input) &&\n            (Math.abs(input.rotation) > this.options.threshold || this.state & STATE_BEGAN);\n    }\n});\n\n/**\n * Swipe\n * Recognized when the pointer is moving fast (velocity), with enough distance in the allowed direction.\n * @constructor\n * @extends AttrRecognizer\n */\nfunction SwipeRecognizer() {\n    AttrRecognizer.apply(this, arguments);\n}\n\ninherit(SwipeRecognizer, AttrRecognizer, {\n    /**\n     * @namespace\n     * @memberof SwipeRecognizer\n     */\n    defaults: {\n        event: 'swipe',\n        threshold: 10,\n        velocity: 0.3,\n        direction: DIRECTION_HORIZONTAL | DIRECTION_VERTICAL,\n        pointers: 1\n    },\n\n    getTouchAction: function() {\n        return PanRecognizer.prototype.getTouchAction.call(this);\n    },\n\n    attrTest: function(input) {\n        var direction = this.options.direction;\n        var velocity;\n\n        if (direction & (DIRECTION_HORIZONTAL | DIRECTION_VERTICAL)) {\n            velocity = input.overallVelocity;\n        } else if (direction & DIRECTION_HORIZONTAL) {\n            velocity = input.overallVelocityX;\n        } else if (direction & DIRECTION_VERTICAL) {\n            velocity = input.overallVelocityY;\n        }\n\n        return this._super.attrTest.call(this, input) &&\n            direction & input.offsetDirection &&\n            input.distance > this.options.threshold &&\n            input.maxPointers == this.options.pointers &&\n            abs(velocity) > this.options.velocity && input.eventType & INPUT_END;\n    },\n\n    emit: function(input) {\n        var direction = directionStr(input.offsetDirection);\n        if (direction) {\n            this.manager.emit(this.options.event + direction, input);\n        }\n\n        this.manager.emit(this.options.event, input);\n    }\n});\n\n/**\n * A tap is ecognized when the pointer is doing a small tap/click. Multiple taps are recognized if they occur\n * between the given interval and position. The delay option can be used to recognize multi-taps without firing\n * a single tap.\n *\n * The eventData from the emitted event contains the property `tapCount`, which contains the amount of\n * multi-taps being recognized.\n * @constructor\n * @extends Recognizer\n */\nfunction TapRecognizer() {\n    Recognizer.apply(this, arguments);\n\n    // previous time and center,\n    // used for tap counting\n    this.pTime = false;\n    this.pCenter = false;\n\n    this._timer = null;\n    this._input = null;\n    this.count = 0;\n}\n\ninherit(TapRecognizer, Recognizer, {\n    /**\n     * @namespace\n     * @memberof PinchRecognizer\n     */\n    defaults: {\n        event: 'tap',\n        pointers: 1,\n        taps: 1,\n        interval: 300, // max time between the multi-tap taps\n        time: 250, // max time of the pointer to be down (like finger on the screen)\n        threshold: 9, // a minimal movement is ok, but keep it low\n        posThreshold: 10 // a multi-tap can be a bit off the initial position\n    },\n\n    getTouchAction: function() {\n        return [TOUCH_ACTION_MANIPULATION];\n    },\n\n    process: function(input) {\n        var options = this.options;\n\n        var validPointers = input.pointers.length === options.pointers;\n        var validMovement = input.distance < options.threshold;\n        var validTouchTime = input.deltaTime < options.time;\n\n        this.reset();\n\n        if ((input.eventType & INPUT_START) && (this.count === 0)) {\n            return this.failTimeout();\n        }\n\n        // we only allow little movement\n        // and we've reached an end event, so a tap is possible\n        if (validMovement && validTouchTime && validPointers) {\n            if (input.eventType != INPUT_END) {\n                return this.failTimeout();\n            }\n\n            var validInterval = this.pTime ? (input.timeStamp - this.pTime < options.interval) : true;\n            var validMultiTap = !this.pCenter || getDistance(this.pCenter, input.center) < options.posThreshold;\n\n            this.pTime = input.timeStamp;\n            this.pCenter = input.center;\n\n            if (!validMultiTap || !validInterval) {\n                this.count = 1;\n            } else {\n                this.count += 1;\n            }\n\n            this._input = input;\n\n            // if tap count matches we have recognized it,\n            // else it has began recognizing...\n            var tapCount = this.count % options.taps;\n            if (tapCount === 0) {\n                // no failing requirements, immediately trigger the tap event\n                // or wait as long as the multitap interval to trigger\n                if (!this.hasRequireFailures()) {\n                    return STATE_RECOGNIZED;\n                } else {\n                    this._timer = setTimeoutContext(function() {\n                        this.state = STATE_RECOGNIZED;\n                        this.tryEmit();\n                    }, options.interval, this);\n                    return STATE_BEGAN;\n                }\n            }\n        }\n        return STATE_FAILED;\n    },\n\n    failTimeout: function() {\n        this._timer = setTimeoutContext(function() {\n            this.state = STATE_FAILED;\n        }, this.options.interval, this);\n        return STATE_FAILED;\n    },\n\n    reset: function() {\n        clearTimeout(this._timer);\n    },\n\n    emit: function() {\n        if (this.state == STATE_RECOGNIZED) {\n            this._input.tapCount = this.count;\n            this.manager.emit(this.options.event, this._input);\n        }\n    }\n});\n\n/**\n * Simple way to create a manager with a default set of recognizers.\n * @param {HTMLElement} element\n * @param {Object} [options]\n * @constructor\n */\nfunction Hammer(element, options) {\n    options = options || {};\n    options.recognizers = ifUndefined(options.recognizers, Hammer.defaults.preset);\n    return new Manager(element, options);\n}\n\n/**\n * @const {string}\n */\nHammer.VERSION = '2.0.7';\n\n/**\n * default settings\n * @namespace\n */\nHammer.defaults = {\n    /**\n     * set if DOM events are being triggered.\n     * But this is slower and unused by simple implementations, so disabled by default.\n     * @type {Boolean}\n     * @default false\n     */\n    domEvents: false,\n\n    /**\n     * The value for the touchAction property/fallback.\n     * When set to `compute` it will magically set the correct value based on the added recognizers.\n     * @type {String}\n     * @default compute\n     */\n    touchAction: TOUCH_ACTION_COMPUTE,\n\n    /**\n     * @type {Boolean}\n     * @default true\n     */\n    enable: true,\n\n    /**\n     * EXPERIMENTAL FEATURE -- can be removed/changed\n     * Change the parent input target element.\n     * If Null, then it is being set the to main element.\n     * @type {Null|EventTarget}\n     * @default null\n     */\n    inputTarget: null,\n\n    /**\n     * force an input class\n     * @type {Null|Function}\n     * @default null\n     */\n    inputClass: null,\n\n    /**\n     * Default recognizer setup when calling `Hammer()`\n     * When creating a new Manager these will be skipped.\n     * @type {Array}\n     */\n    preset: [\n        // RecognizerClass, options, [recognizeWith, ...], [requireFailure, ...]\n        [RotateRecognizer, {enable: false}],\n        [PinchRecognizer, {enable: false}, ['rotate']],\n        [SwipeRecognizer, {direction: DIRECTION_HORIZONTAL}],\n        [PanRecognizer, {direction: DIRECTION_HORIZONTAL}, ['swipe']],\n        [TapRecognizer],\n        [TapRecognizer, {event: 'doubletap', taps: 2}, ['tap']],\n        [PressRecognizer]\n    ],\n\n    /**\n     * Some CSS properties can be used to improve the working of Hammer.\n     * Add them to this method and they will be set when creating a new Manager.\n     * @namespace\n     */\n    cssProps: {\n        /**\n         * Disables text selection to improve the dragging gesture. Mainly for desktop browsers.\n         * @type {String}\n         * @default 'none'\n         */\n        userSelect: 'none',\n\n        /**\n         * Disable the Windows Phone grippers when pressing an element.\n         * @type {String}\n         * @default 'none'\n         */\n        touchSelect: 'none',\n\n        /**\n         * Disables the default callout shown when you touch and hold a touch target.\n         * On iOS, when you touch and hold a touch target such as a link, Safari displays\n         * a callout containing information about the link. This property allows you to disable that callout.\n         * @type {String}\n         * @default 'none'\n         */\n        touchCallout: 'none',\n\n        /**\n         * Specifies whether zooming is enabled. Used by IE10>\n         * @type {String}\n         * @default 'none'\n         */\n        contentZooming: 'none',\n\n        /**\n         * Specifies that an entire element should be draggable instead of its contents. Mainly for desktop browsers.\n         * @type {String}\n         * @default 'none'\n         */\n        userDrag: 'none',\n\n        /**\n         * Overrides the highlight color shown when the user taps a link or a JavaScript\n         * clickable element in iOS. This property obeys the alpha value, if specified.\n         * @type {String}\n         * @default 'rgba(0,0,0,0)'\n         */\n        tapHighlightColor: 'rgba(0,0,0,0)'\n    }\n};\n\nvar STOP = 1;\nvar FORCED_STOP = 2;\n\n/**\n * Manager\n * @param {HTMLElement} element\n * @param {Object} [options]\n * @constructor\n */\nfunction Manager(element, options) {\n    this.options = assign({}, Hammer.defaults, options || {});\n\n    this.options.inputTarget = this.options.inputTarget || element;\n\n    this.handlers = {};\n    this.session = {};\n    this.recognizers = [];\n    this.oldCssProps = {};\n\n    this.element = element;\n    this.input = createInputInstance(this);\n    this.touchAction = new TouchAction(this, this.options.touchAction);\n\n    toggleCssProps(this, true);\n\n    each(this.options.recognizers, function(item) {\n        var recognizer = this.add(new (item[0])(item[1]));\n        item[2] && recognizer.recognizeWith(item[2]);\n        item[3] && recognizer.requireFailure(item[3]);\n    }, this);\n}\n\nManager.prototype = {\n    /**\n     * set options\n     * @param {Object} options\n     * @returns {Manager}\n     */\n    set: function(options) {\n        assign(this.options, options);\n\n        // Options that need a little more setup\n        if (options.touchAction) {\n            this.touchAction.update();\n        }\n        if (options.inputTarget) {\n            // Clean up existing event listeners and reinitialize\n            this.input.destroy();\n            this.input.target = options.inputTarget;\n            this.input.init();\n        }\n        return this;\n    },\n\n    /**\n     * stop recognizing for this session.\n     * This session will be discarded, when a new [input]start event is fired.\n     * When forced, the recognizer cycle is stopped immediately.\n     * @param {Boolean} [force]\n     */\n    stop: function(force) {\n        this.session.stopped = force ? FORCED_STOP : STOP;\n    },\n\n    /**\n     * run the recognizers!\n     * called by the inputHandler function on every movement of the pointers (touches)\n     * it walks through all the recognizers and tries to detect the gesture that is being made\n     * @param {Object} inputData\n     */\n    recognize: function(inputData) {\n        var session = this.session;\n        if (session.stopped) {\n            return;\n        }\n\n        // run the touch-action polyfill\n        this.touchAction.preventDefaults(inputData);\n\n        var recognizer;\n        var recognizers = this.recognizers;\n\n        // this holds the recognizer that is being recognized.\n        // so the recognizer's state needs to be BEGAN, CHANGED, ENDED or RECOGNIZED\n        // if no recognizer is detecting a thing, it is set to `null`\n        var curRecognizer = session.curRecognizer;\n\n        // reset when the last recognizer is recognized\n        // or when we're in a new session\n        if (!curRecognizer || (curRecognizer && curRecognizer.state & STATE_RECOGNIZED)) {\n            curRecognizer = session.curRecognizer = null;\n        }\n\n        var i = 0;\n        while (i < recognizers.length) {\n            recognizer = recognizers[i];\n\n            // find out if we are allowed try to recognize the input for this one.\n            // 1.   allow if the session is NOT forced stopped (see the .stop() method)\n            // 2.   allow if we still haven't recognized a gesture in this session, or the this recognizer is the one\n            //      that is being recognized.\n            // 3.   allow if the recognizer is allowed to run simultaneous with the current recognized recognizer.\n            //      this can be setup with the `recognizeWith()` method on the recognizer.\n            if (session.stopped !== FORCED_STOP && ( // 1\n                    !curRecognizer || recognizer == curRecognizer || // 2\n                    recognizer.canRecognizeWith(curRecognizer))) { // 3\n                recognizer.recognize(inputData);\n            } else {\n                recognizer.reset();\n            }\n\n            // if the recognizer has been recognizing the input as a valid gesture, we want to store this one as the\n            // current active recognizer. but only if we don't already have an active recognizer\n            if (!curRecognizer && recognizer.state & (STATE_BEGAN | STATE_CHANGED | STATE_ENDED)) {\n                curRecognizer = session.curRecognizer = recognizer;\n            }\n            i++;\n        }\n    },\n\n    /**\n     * get a recognizer by its event name.\n     * @param {Recognizer|String} recognizer\n     * @returns {Recognizer|Null}\n     */\n    get: function(recognizer) {\n        if (recognizer instanceof Recognizer) {\n            return recognizer;\n        }\n\n        var recognizers = this.recognizers;\n        for (var i = 0; i < recognizers.length; i++) {\n            if (recognizers[i].options.event == recognizer) {\n                return recognizers[i];\n            }\n        }\n        return null;\n    },\n\n    /**\n     * add a recognizer to the manager\n     * existing recognizers with the same event name will be removed\n     * @param {Recognizer} recognizer\n     * @returns {Recognizer|Manager}\n     */\n    add: function(recognizer) {\n        if (invokeArrayArg(recognizer, 'add', this)) {\n            return this;\n        }\n\n        // remove existing\n        var existing = this.get(recognizer.options.event);\n        if (existing) {\n            this.remove(existing);\n        }\n\n        this.recognizers.push(recognizer);\n        recognizer.manager = this;\n\n        this.touchAction.update();\n        return recognizer;\n    },\n\n    /**\n     * remove a recognizer by name or instance\n     * @param {Recognizer|String} recognizer\n     * @returns {Manager}\n     */\n    remove: function(recognizer) {\n        if (invokeArrayArg(recognizer, 'remove', this)) {\n            return this;\n        }\n\n        recognizer = this.get(recognizer);\n\n        // let's make sure this recognizer exists\n        if (recognizer) {\n            var recognizers = this.recognizers;\n            var index = inArray(recognizers, recognizer);\n\n            if (index !== -1) {\n                recognizers.splice(index, 1);\n                this.touchAction.update();\n            }\n        }\n\n        return this;\n    },\n\n    /**\n     * bind event\n     * @param {String} events\n     * @param {Function} handler\n     * @returns {EventEmitter} this\n     */\n    on: function(events, handler) {\n        if (events === undefined) {\n            return;\n        }\n        if (handler === undefined) {\n            return;\n        }\n\n        var handlers = this.handlers;\n        each(splitStr(events), function(event) {\n            handlers[event] = handlers[event] || [];\n            handlers[event].push(handler);\n        });\n        return this;\n    },\n\n    /**\n     * unbind event, leave emit blank to remove all handlers\n     * @param {String} events\n     * @param {Function} [handler]\n     * @returns {EventEmitter} this\n     */\n    off: function(events, handler) {\n        if (events === undefined) {\n            return;\n        }\n\n        var handlers = this.handlers;\n        each(splitStr(events), function(event) {\n            if (!handler) {\n                delete handlers[event];\n            } else {\n                handlers[event] && handlers[event].splice(inArray(handlers[event], handler), 1);\n            }\n        });\n        return this;\n    },\n\n    /**\n     * emit event to the listeners\n     * @param {String} event\n     * @param {Object} data\n     */\n    emit: function(event, data) {\n        // we also want to trigger dom events\n        if (this.options.domEvents) {\n            triggerDomEvent(event, data);\n        }\n\n        // no handlers, so skip it all\n        var handlers = this.handlers[event] && this.handlers[event].slice();\n        if (!handlers || !handlers.length) {\n            return;\n        }\n\n        data.type = event;\n        data.preventDefault = function() {\n            data.srcEvent.preventDefault();\n        };\n\n        var i = 0;\n        while (i < handlers.length) {\n            handlers[i](data);\n            i++;\n        }\n    },\n\n    /**\n     * destroy the manager and unbinds all events\n     * it doesn't unbind dom events, that is the user own responsibility\n     */\n    destroy: function() {\n        this.element && toggleCssProps(this, false);\n\n        this.handlers = {};\n        this.session = {};\n        this.input.destroy();\n        this.element = null;\n    }\n};\n\n/**\n * add/remove the css properties as defined in manager.options.cssProps\n * @param {Manager} manager\n * @param {Boolean} add\n */\nfunction toggleCssProps(manager, add) {\n    var element = manager.element;\n    if (!element.style) {\n        return;\n    }\n    var prop;\n    each(manager.options.cssProps, function(value, name) {\n        prop = prefixed(element.style, name);\n        if (add) {\n            manager.oldCssProps[prop] = element.style[prop];\n            element.style[prop] = value;\n        } else {\n            element.style[prop] = manager.oldCssProps[prop] || '';\n        }\n    });\n    if (!add) {\n        manager.oldCssProps = {};\n    }\n}\n\n/**\n * trigger dom event\n * @param {String} event\n * @param {Object} data\n */\nfunction triggerDomEvent(event, data) {\n    var gestureEvent = document.createEvent('Event');\n    gestureEvent.initEvent(event, true, true);\n    gestureEvent.gesture = data;\n    data.target.dispatchEvent(gestureEvent);\n}\n\nassign(Hammer, {\n    INPUT_START: INPUT_START,\n    INPUT_MOVE: INPUT_MOVE,\n    INPUT_END: INPUT_END,\n    INPUT_CANCEL: INPUT_CANCEL,\n\n    STATE_POSSIBLE: STATE_POSSIBLE,\n    STATE_BEGAN: STATE_BEGAN,\n    STATE_CHANGED: STATE_CHANGED,\n    STATE_ENDED: STATE_ENDED,\n    STATE_RECOGNIZED: STATE_RECOGNIZED,\n    STATE_CANCELLED: STATE_CANCELLED,\n    STATE_FAILED: STATE_FAILED,\n\n    DIRECTION_NONE: DIRECTION_NONE,\n    DIRECTION_LEFT: DIRECTION_LEFT,\n    DIRECTION_RIGHT: DIRECTION_RIGHT,\n    DIRECTION_UP: DIRECTION_UP,\n    DIRECTION_DOWN: DIRECTION_DOWN,\n    DIRECTION_HORIZONTAL: DIRECTION_HORIZONTAL,\n    DIRECTION_VERTICAL: DIRECTION_VERTICAL,\n    DIRECTION_ALL: DIRECTION_ALL,\n\n    Manager: Manager,\n    Input: Input,\n    TouchAction: TouchAction,\n\n    TouchInput: TouchInput,\n    MouseInput: MouseInput,\n    PointerEventInput: PointerEventInput,\n    TouchMouseInput: TouchMouseInput,\n    SingleTouchInput: SingleTouchInput,\n\n    Recognizer: Recognizer,\n    AttrRecognizer: AttrRecognizer,\n    Tap: TapRecognizer,\n    Pan: PanRecognizer,\n    Swipe: SwipeRecognizer,\n    Pinch: PinchRecognizer,\n    Rotate: RotateRecognizer,\n    Press: PressRecognizer,\n\n    on: addEventListeners,\n    off: removeEventListeners,\n    each: each,\n    merge: merge,\n    extend: extend,\n    assign: assign,\n    inherit: inherit,\n    bindFn: bindFn,\n    prefixed: prefixed\n});\n\n// this prevents errors when Hammer is loaded in the presence of an AMD\n//  style loader but by script tag, not by the loader.\nvar freeGlobal = (typeof window !== 'undefined' ? window : (typeof self !== 'undefined' ? self : {})); // jshint ignore:line\nfreeGlobal.Hammer = Hammer;\n\nif (true) {\n    !(__WEBPACK_AMD_DEFINE_RESULT__ = (function() {\n        return Hammer;\n    }).call(exports, __webpack_require__, exports, module),\n\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n} else {}\n\n})(window, document, 'Hammer');\n\n\n//# sourceURL=webpack://semanticfinder/./node_modules/hammerjs/hammer.js?");

/***/ }),

/***/ "./node_modules/bootstrap/dist/css/bootstrap.min.css":
/*!***********************************************************!*\
  !*** ./node_modules/bootstrap/dist/css/bootstrap.min.css ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n// extracted by mini-css-extract-plugin\n\n\n//# sourceURL=webpack://semanticfinder/./node_modules/bootstrap/dist/css/bootstrap.min.css?");

/***/ }),

/***/ "./node_modules/codemirror/lib/codemirror.css":
/*!****************************************************!*\
  !*** ./node_modules/codemirror/lib/codemirror.css ***!
  \****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n// extracted by mini-css-extract-plugin\n\n\n//# sourceURL=webpack://semanticfinder/./node_modules/codemirror/lib/codemirror.css?");

/***/ }),

/***/ "./src/css/styles.css":
/*!****************************!*\
  !*** ./src/css/styles.css ***!
  \****************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n// extracted by mini-css-extract-plugin\n\n\n//# sourceURL=webpack://semanticfinder/./src/css/styles.css?");

/***/ }),

/***/ "./node_modules/mjolnir.js/dist/esm/constants.js":
/*!*******************************************************!*\
  !*** ./node_modules/mjolnir.js/dist/esm/constants.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   BASIC_EVENT_ALIASES: () => (/* binding */ BASIC_EVENT_ALIASES),\n/* harmony export */   EVENT_RECOGNIZER_MAP: () => (/* binding */ EVENT_RECOGNIZER_MAP),\n/* harmony export */   GESTURE_EVENT_ALIASES: () => (/* binding */ GESTURE_EVENT_ALIASES),\n/* harmony export */   INPUT_EVENT_TYPES: () => (/* binding */ INPUT_EVENT_TYPES),\n/* harmony export */   RECOGNIZERS: () => (/* binding */ RECOGNIZERS),\n/* harmony export */   RECOGNIZER_COMPATIBLE_MAP: () => (/* binding */ RECOGNIZER_COMPATIBLE_MAP),\n/* harmony export */   RECOGNIZER_FALLBACK_MAP: () => (/* binding */ RECOGNIZER_FALLBACK_MAP)\n/* harmony export */ });\n/* harmony import */ var _utils_hammer__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./utils/hammer */ \"./node_modules/mjolnir.js/dist/esm/utils/hammer.browser.js\");\n\n// This module contains constants that must be conditionally required\n// due to `window`/`document` references downstream.\nconst RECOGNIZERS = _utils_hammer__WEBPACK_IMPORTED_MODULE_0__[\"default\"]\n    ? [\n        [_utils_hammer__WEBPACK_IMPORTED_MODULE_0__[\"default\"].Pan, { event: 'tripan', pointers: 3, threshold: 0, enable: false }],\n        [_utils_hammer__WEBPACK_IMPORTED_MODULE_0__[\"default\"].Rotate, { enable: false }],\n        [_utils_hammer__WEBPACK_IMPORTED_MODULE_0__[\"default\"].Pinch, { enable: false }],\n        [_utils_hammer__WEBPACK_IMPORTED_MODULE_0__[\"default\"].Swipe, { enable: false }],\n        [_utils_hammer__WEBPACK_IMPORTED_MODULE_0__[\"default\"].Pan, { threshold: 0, enable: false }],\n        [_utils_hammer__WEBPACK_IMPORTED_MODULE_0__[\"default\"].Press, { enable: false }],\n        [_utils_hammer__WEBPACK_IMPORTED_MODULE_0__[\"default\"].Tap, { event: 'doubletap', taps: 2, enable: false }],\n        // TODO - rename to 'tap' and 'singletap' in the next major release\n        [_utils_hammer__WEBPACK_IMPORTED_MODULE_0__[\"default\"].Tap, { event: 'anytap', enable: false }],\n        [_utils_hammer__WEBPACK_IMPORTED_MODULE_0__[\"default\"].Tap, { enable: false }]\n    ]\n    : null;\n// Recognize the following gestures even if a given recognizer succeeds\nconst RECOGNIZER_COMPATIBLE_MAP = {\n    tripan: ['rotate', 'pinch', 'pan'],\n    rotate: ['pinch'],\n    pinch: ['pan'],\n    pan: ['press', 'doubletap', 'anytap', 'tap'],\n    doubletap: ['anytap'],\n    anytap: ['tap']\n};\n// Recognize the folling gestures only if a given recognizer fails\nconst RECOGNIZER_FALLBACK_MAP = {\n    doubletap: ['tap']\n};\n/**\n * Only one set of basic input events will be fired by Hammer.js:\n * either pointer, touch, or mouse, depending on system support.\n * In order to enable an application to be agnostic of system support,\n * alias basic input events into \"classes\" of events: down, move, and up.\n * See `_onBasicInput()` for usage of these aliases.\n */\nconst BASIC_EVENT_ALIASES = {\n    pointerdown: 'pointerdown',\n    pointermove: 'pointermove',\n    pointerup: 'pointerup',\n    touchstart: 'pointerdown',\n    touchmove: 'pointermove',\n    touchend: 'pointerup',\n    mousedown: 'pointerdown',\n    mousemove: 'pointermove',\n    mouseup: 'pointerup'\n};\nconst INPUT_EVENT_TYPES = {\n    KEY_EVENTS: ['keydown', 'keyup'],\n    MOUSE_EVENTS: ['mousedown', 'mousemove', 'mouseup', 'mouseover', 'mouseout', 'mouseleave'],\n    WHEEL_EVENTS: [\n        // Chrome, Safari\n        'wheel',\n        // IE\n        'mousewheel'\n    ]\n};\n/**\n * \"Gestural\" events are those that have semantic meaning beyond the basic input event,\n * e.g. a click or tap is a sequence of `down` and `up` events with no `move` event in between.\n * Hammer.js handles these with its Recognizer system;\n * this block maps event names to the Recognizers required to detect the events.\n */\nconst EVENT_RECOGNIZER_MAP = {\n    tap: 'tap',\n    anytap: 'anytap',\n    doubletap: 'doubletap',\n    press: 'press',\n    pinch: 'pinch',\n    pinchin: 'pinch',\n    pinchout: 'pinch',\n    pinchstart: 'pinch',\n    pinchmove: 'pinch',\n    pinchend: 'pinch',\n    pinchcancel: 'pinch',\n    rotate: 'rotate',\n    rotatestart: 'rotate',\n    rotatemove: 'rotate',\n    rotateend: 'rotate',\n    rotatecancel: 'rotate',\n    tripan: 'tripan',\n    tripanstart: 'tripan',\n    tripanmove: 'tripan',\n    tripanup: 'tripan',\n    tripandown: 'tripan',\n    tripanleft: 'tripan',\n    tripanright: 'tripan',\n    tripanend: 'tripan',\n    tripancancel: 'tripan',\n    pan: 'pan',\n    panstart: 'pan',\n    panmove: 'pan',\n    panup: 'pan',\n    pandown: 'pan',\n    panleft: 'pan',\n    panright: 'pan',\n    panend: 'pan',\n    pancancel: 'pan',\n    swipe: 'swipe',\n    swipeleft: 'swipe',\n    swiperight: 'swipe',\n    swipeup: 'swipe',\n    swipedown: 'swipe'\n};\n/**\n * Map gestural events typically provided by browsers\n * that are not reported in 'hammer.input' events\n * to corresponding Hammer.js gestures.\n */\nconst GESTURE_EVENT_ALIASES = {\n    click: 'tap',\n    anyclick: 'anytap',\n    dblclick: 'doubletap',\n    mousedown: 'pointerdown',\n    mousemove: 'pointermove',\n    mouseup: 'pointerup',\n    mouseover: 'pointerover',\n    mouseout: 'pointerout',\n    mouseleave: 'pointerleave'\n};\n//# sourceMappingURL=constants.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/mjolnir.js/dist/esm/constants.js?");

/***/ }),

/***/ "./node_modules/mjolnir.js/dist/esm/event-manager.js":
/*!***********************************************************!*\
  !*** ./node_modules/mjolnir.js/dist/esm/event-manager.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ EventManager)\n/* harmony export */ });\n/* harmony import */ var _utils_hammer__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./utils/hammer */ \"./node_modules/mjolnir.js/dist/esm/utils/hammer.browser.js\");\n/* harmony import */ var _inputs_wheel_input__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./inputs/wheel-input */ \"./node_modules/mjolnir.js/dist/esm/inputs/wheel-input.js\");\n/* harmony import */ var _inputs_move_input__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./inputs/move-input */ \"./node_modules/mjolnir.js/dist/esm/inputs/move-input.js\");\n/* harmony import */ var _inputs_key_input__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./inputs/key-input */ \"./node_modules/mjolnir.js/dist/esm/inputs/key-input.js\");\n/* harmony import */ var _inputs_contextmenu_input__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./inputs/contextmenu-input */ \"./node_modules/mjolnir.js/dist/esm/inputs/contextmenu-input.js\");\n/* harmony import */ var _utils_event_registrar__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./utils/event-registrar */ \"./node_modules/mjolnir.js/dist/esm/utils/event-registrar.js\");\n/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./constants */ \"./node_modules/mjolnir.js/dist/esm/constants.js\");\n\n\n\n\n\n\n\nconst DEFAULT_OPTIONS = {\n    // event handlers\n    events: null,\n    // custom recognizers\n    recognizers: null,\n    recognizerOptions: {},\n    // Manager class\n    Manager: _utils_hammer__WEBPACK_IMPORTED_MODULE_0__.Manager,\n    // allow browser default touch action\n    // https://github.com/uber/react-map-gl/issues/506\n    touchAction: 'none',\n    tabIndex: 0\n};\n// Unified API for subscribing to events about both\n// basic input events (e.g. 'mousemove', 'touchstart', 'wheel')\n// and gestural input (e.g. 'click', 'tap', 'panstart').\n// Delegates gesture related event registration and handling to Hammer.js.\nclass EventManager {\n    constructor(element = null, options) {\n        /**\n         * Handle basic events using the 'hammer.input' Hammer.js API:\n         * Before running Recognizers, Hammer emits a 'hammer.input' event\n         * with the basic event info. This function emits all basic events\n         * aliased to the \"class\" of event received.\n         * See constants.BASIC_EVENT_CLASSES basic event class definitions.\n         */\n        this._onBasicInput = (event) => {\n            const { srcEvent } = event;\n            const alias = _constants__WEBPACK_IMPORTED_MODULE_6__.BASIC_EVENT_ALIASES[srcEvent.type];\n            if (alias) {\n                // fire all events aliased to srcEvent.type\n                this.manager.emit(alias, event);\n            }\n        };\n        /**\n         * Handle events not supported by Hammer.js,\n         * and pipe back out through same (Hammer) channel used by other events.\n         */\n        this._onOtherEvent = (event) => {\n            // console.log('onotherevent', event.type, event)\n            this.manager.emit(event.type, event);\n        };\n        this.options = { ...DEFAULT_OPTIONS, ...options };\n        this.events = new Map();\n        this.setElement(element);\n        // Register all passed events.\n        const { events } = this.options;\n        if (events) {\n            this.on(events);\n        }\n    }\n    getElement() {\n        return this.element;\n    }\n    setElement(element) {\n        if (this.element) {\n            // unregister all events\n            this.destroy();\n        }\n        this.element = element;\n        if (!element) {\n            return;\n        }\n        const { options } = this;\n        const ManagerClass = options.Manager;\n        this.manager = new ManagerClass(element, {\n            touchAction: options.touchAction,\n            recognizers: options.recognizers || _constants__WEBPACK_IMPORTED_MODULE_6__.RECOGNIZERS\n        }).on('hammer.input', this._onBasicInput);\n        if (!options.recognizers) {\n            // Set default recognize withs\n            // http://hammerjs.github.io/recognize-with/\n            Object.keys(_constants__WEBPACK_IMPORTED_MODULE_6__.RECOGNIZER_COMPATIBLE_MAP).forEach(name => {\n                const recognizer = this.manager.get(name);\n                if (recognizer) {\n                    _constants__WEBPACK_IMPORTED_MODULE_6__.RECOGNIZER_COMPATIBLE_MAP[name].forEach(otherName => {\n                        recognizer.recognizeWith(otherName);\n                    });\n                }\n            });\n        }\n        // Set recognizer options\n        for (const recognizerName in options.recognizerOptions) {\n            const recognizer = this.manager.get(recognizerName);\n            if (recognizer) {\n                const recognizerOption = options.recognizerOptions[recognizerName];\n                // `enable` is managed by the event registrations\n                delete recognizerOption.enable;\n                recognizer.set(recognizerOption);\n            }\n        }\n        // Handle events not handled by Hammer.js:\n        // - mouse wheel\n        // - pointer/touch/mouse move\n        this.wheelInput = new _inputs_wheel_input__WEBPACK_IMPORTED_MODULE_1__[\"default\"](element, this._onOtherEvent, {\n            enable: false\n        });\n        this.moveInput = new _inputs_move_input__WEBPACK_IMPORTED_MODULE_2__[\"default\"](element, this._onOtherEvent, {\n            enable: false\n        });\n        this.keyInput = new _inputs_key_input__WEBPACK_IMPORTED_MODULE_3__[\"default\"](element, this._onOtherEvent, {\n            enable: false,\n            tabIndex: options.tabIndex\n        });\n        this.contextmenuInput = new _inputs_contextmenu_input__WEBPACK_IMPORTED_MODULE_4__[\"default\"](element, this._onOtherEvent, {\n            enable: false\n        });\n        // Register all existing events\n        for (const [eventAlias, eventRegistrar] of this.events) {\n            if (!eventRegistrar.isEmpty()) {\n                // Enable recognizer for this event.\n                this._toggleRecognizer(eventRegistrar.recognizerName, true);\n                this.manager.on(eventAlias, eventRegistrar.handleEvent);\n            }\n        }\n    }\n    // Tear down internal event management implementations.\n    destroy() {\n        if (this.element) {\n            // wheelInput etc. are created in setElement() and therefore\n            // cannot exist if there is no element\n            this.wheelInput.destroy();\n            this.moveInput.destroy();\n            this.keyInput.destroy();\n            this.contextmenuInput.destroy();\n            this.manager.destroy();\n            this.wheelInput = null;\n            this.moveInput = null;\n            this.keyInput = null;\n            this.contextmenuInput = null;\n            this.manager = null;\n            this.element = null;\n        }\n    }\n    /** Register an event handler function to be called on `event` */\n    on(event, handler, opts) {\n        this._addEventHandler(event, handler, opts, false);\n    }\n    once(event, handler, opts) {\n        this._addEventHandler(event, handler, opts, true);\n    }\n    watch(event, handler, opts) {\n        this._addEventHandler(event, handler, opts, false, true);\n    }\n    off(event, handler) {\n        this._removeEventHandler(event, handler);\n    }\n    /*\n     * Enable/disable recognizer for the given event\n     */\n    _toggleRecognizer(name, enabled) {\n        const { manager } = this;\n        if (!manager) {\n            return;\n        }\n        const recognizer = manager.get(name);\n        // @ts-ignore\n        if (recognizer && recognizer.options.enable !== enabled) {\n            recognizer.set({ enable: enabled });\n            const fallbackRecognizers = _constants__WEBPACK_IMPORTED_MODULE_6__.RECOGNIZER_FALLBACK_MAP[name];\n            if (fallbackRecognizers && !this.options.recognizers) {\n                // Set default require failures\n                // http://hammerjs.github.io/require-failure/\n                fallbackRecognizers.forEach(otherName => {\n                    const otherRecognizer = manager.get(otherName);\n                    if (enabled) {\n                        // Wait for this recognizer to fail\n                        otherRecognizer.requireFailure(name);\n                        /**\n                         * This seems to be a bug in hammerjs:\n                         * requireFailure() adds both ways\n                         * dropRequireFailure() only drops one way\n                         * https://github.com/hammerjs/hammer.js/blob/master/src/recognizerjs/\n                           recognizer-constructor.js#L136\n                         */\n                        recognizer.dropRequireFailure(otherName);\n                    }\n                    else {\n                        // Do not wait for this recognizer to fail\n                        otherRecognizer.dropRequireFailure(name);\n                    }\n                });\n            }\n        }\n        this.wheelInput.enableEventType(name, enabled);\n        this.moveInput.enableEventType(name, enabled);\n        this.keyInput.enableEventType(name, enabled);\n        this.contextmenuInput.enableEventType(name, enabled);\n    }\n    /**\n     * Process the event registration for a single event + handler.\n     */\n    _addEventHandler(event, handler, opts, once, passive) {\n        if (typeof event !== 'string') {\n            // @ts-ignore\n            opts = handler;\n            // If `event` is a map, call `on()` for each entry.\n            for (const eventName in event) {\n                this._addEventHandler(eventName, event[eventName], opts, once, passive);\n            }\n            return;\n        }\n        const { manager, events } = this;\n        // Alias to a recognized gesture as necessary.\n        const eventAlias = _constants__WEBPACK_IMPORTED_MODULE_6__.GESTURE_EVENT_ALIASES[event] || event;\n        let eventRegistrar = events.get(eventAlias);\n        if (!eventRegistrar) {\n            eventRegistrar = new _utils_event_registrar__WEBPACK_IMPORTED_MODULE_5__[\"default\"](this);\n            events.set(eventAlias, eventRegistrar);\n            // Enable recognizer for this event.\n            eventRegistrar.recognizerName = _constants__WEBPACK_IMPORTED_MODULE_6__.EVENT_RECOGNIZER_MAP[eventAlias] || eventAlias;\n            // Listen to the event\n            if (manager) {\n                manager.on(eventAlias, eventRegistrar.handleEvent);\n            }\n        }\n        eventRegistrar.add(event, handler, opts, once, passive);\n        if (!eventRegistrar.isEmpty()) {\n            this._toggleRecognizer(eventRegistrar.recognizerName, true);\n        }\n    }\n    /**\n     * Process the event deregistration for a single event + handler.\n     */\n    _removeEventHandler(event, handler) {\n        if (typeof event !== 'string') {\n            // If `event` is a map, call `off()` for each entry.\n            for (const eventName in event) {\n                this._removeEventHandler(eventName, event[eventName]);\n            }\n            return;\n        }\n        const { events } = this;\n        // Alias to a recognized gesture as necessary.\n        const eventAlias = _constants__WEBPACK_IMPORTED_MODULE_6__.GESTURE_EVENT_ALIASES[event] || event;\n        const eventRegistrar = events.get(eventAlias);\n        if (!eventRegistrar) {\n            return;\n        }\n        eventRegistrar.remove(event, handler);\n        if (eventRegistrar.isEmpty()) {\n            const { recognizerName } = eventRegistrar;\n            // Disable recognizer if no more handlers are attached to its events\n            let isRecognizerUsed = false;\n            for (const eh of events.values()) {\n                if (eh.recognizerName === recognizerName && !eh.isEmpty()) {\n                    isRecognizerUsed = true;\n                    break;\n                }\n            }\n            if (!isRecognizerUsed) {\n                this._toggleRecognizer(recognizerName, false);\n            }\n        }\n    }\n}\n//# sourceMappingURL=event-manager.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/mjolnir.js/dist/esm/event-manager.js?");

/***/ }),

/***/ "./node_modules/mjolnir.js/dist/esm/index.js":
/*!***************************************************!*\
  !*** ./node_modules/mjolnir.js/dist/esm/index.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   EventManager: () => (/* reexport safe */ _event_manager__WEBPACK_IMPORTED_MODULE_0__[\"default\"])\n/* harmony export */ });\n/* harmony import */ var _event_manager__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./event-manager */ \"./node_modules/mjolnir.js/dist/esm/event-manager.js\");\n\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/mjolnir.js/dist/esm/index.js?");

/***/ }),

/***/ "./node_modules/mjolnir.js/dist/esm/inputs/contextmenu-input.js":
/*!**********************************************************************!*\
  !*** ./node_modules/mjolnir.js/dist/esm/inputs/contextmenu-input.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ ContextmenuInput)\n/* harmony export */ });\n/* harmony import */ var _input__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./input */ \"./node_modules/mjolnir.js/dist/esm/inputs/input.js\");\n\nconst EVENT_TYPE = 'contextmenu';\nclass ContextmenuInput extends _input__WEBPACK_IMPORTED_MODULE_0__[\"default\"] {\n    constructor(element, callback, options) {\n        super(element, callback, options);\n        this.handleEvent = (event) => {\n            if (!this.options.enable) {\n                return;\n            }\n            this.callback({\n                type: EVENT_TYPE,\n                center: {\n                    x: event.clientX,\n                    y: event.clientY\n                },\n                srcEvent: event,\n                pointerType: 'mouse',\n                target: event.target\n            });\n        };\n        element.addEventListener('contextmenu', this.handleEvent);\n    }\n    destroy() {\n        this.element.removeEventListener('contextmenu', this.handleEvent);\n    }\n    /**\n     * Enable this input (begin processing events)\n     * if the specified event type is among those handled by this input.\n     */\n    enableEventType(eventType, enabled) {\n        if (eventType === EVENT_TYPE) {\n            this.options.enable = enabled;\n        }\n    }\n}\n//# sourceMappingURL=contextmenu-input.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/mjolnir.js/dist/esm/inputs/contextmenu-input.js?");

/***/ }),

/***/ "./node_modules/mjolnir.js/dist/esm/inputs/input.js":
/*!**********************************************************!*\
  !*** ./node_modules/mjolnir.js/dist/esm/inputs/input.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Input)\n/* harmony export */ });\nclass Input {\n    constructor(element, callback, options) {\n        this.element = element;\n        this.callback = callback;\n        this.options = { enable: true, ...options };\n    }\n}\n//# sourceMappingURL=input.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/mjolnir.js/dist/esm/inputs/input.js?");

/***/ }),

/***/ "./node_modules/mjolnir.js/dist/esm/inputs/key-input.js":
/*!**************************************************************!*\
  !*** ./node_modules/mjolnir.js/dist/esm/inputs/key-input.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ KeyInput)\n/* harmony export */ });\n/* harmony import */ var _input__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./input */ \"./node_modules/mjolnir.js/dist/esm/inputs/input.js\");\n/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../constants */ \"./node_modules/mjolnir.js/dist/esm/constants.js\");\n\n\nconst { KEY_EVENTS } = _constants__WEBPACK_IMPORTED_MODULE_1__.INPUT_EVENT_TYPES;\nconst DOWN_EVENT_TYPE = 'keydown';\nconst UP_EVENT_TYPE = 'keyup';\nclass KeyInput extends _input__WEBPACK_IMPORTED_MODULE_0__[\"default\"] {\n    constructor(element, callback, options) {\n        super(element, callback, options);\n        this.handleEvent = (event) => {\n            // Ignore if focused on text input\n            const targetElement = (event.target || event.srcElement);\n            if ((targetElement.tagName === 'INPUT' && targetElement.type === 'text') ||\n                targetElement.tagName === 'TEXTAREA') {\n                return;\n            }\n            if (this.enableDownEvent && event.type === 'keydown') {\n                this.callback({\n                    type: DOWN_EVENT_TYPE,\n                    srcEvent: event,\n                    key: event.key,\n                    target: event.target\n                });\n            }\n            if (this.enableUpEvent && event.type === 'keyup') {\n                this.callback({\n                    type: UP_EVENT_TYPE,\n                    srcEvent: event,\n                    key: event.key,\n                    target: event.target\n                });\n            }\n        };\n        this.enableDownEvent = this.options.enable;\n        this.enableUpEvent = this.options.enable;\n        this.events = (this.options.events || []).concat(KEY_EVENTS);\n        element.tabIndex = this.options.tabIndex || 0;\n        element.style.outline = 'none';\n        this.events.forEach(event => element.addEventListener(event, this.handleEvent));\n    }\n    destroy() {\n        this.events.forEach(event => this.element.removeEventListener(event, this.handleEvent));\n    }\n    /**\n     * Enable this input (begin processing events)\n     * if the specified event type is among those handled by this input.\n     */\n    enableEventType(eventType, enabled) {\n        if (eventType === DOWN_EVENT_TYPE) {\n            this.enableDownEvent = enabled;\n        }\n        if (eventType === UP_EVENT_TYPE) {\n            this.enableUpEvent = enabled;\n        }\n    }\n}\n//# sourceMappingURL=key-input.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/mjolnir.js/dist/esm/inputs/key-input.js?");

/***/ }),

/***/ "./node_modules/mjolnir.js/dist/esm/inputs/move-input.js":
/*!***************************************************************!*\
  !*** ./node_modules/mjolnir.js/dist/esm/inputs/move-input.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ MoveInput)\n/* harmony export */ });\n/* harmony import */ var _input__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./input */ \"./node_modules/mjolnir.js/dist/esm/inputs/input.js\");\n/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../constants */ \"./node_modules/mjolnir.js/dist/esm/constants.js\");\n\n\nconst { MOUSE_EVENTS } = _constants__WEBPACK_IMPORTED_MODULE_1__.INPUT_EVENT_TYPES;\nconst MOVE_EVENT_TYPE = 'pointermove';\nconst OVER_EVENT_TYPE = 'pointerover';\nconst OUT_EVENT_TYPE = 'pointerout';\nconst ENTER_EVENT_TYPE = 'pointerenter';\nconst LEAVE_EVENT_TYPE = 'pointerleave';\n/**\n * Hammer.js swallows 'move' events (for pointer/touch/mouse)\n * when the pointer is not down. This class sets up a handler\n * specifically for these events to work around this limitation.\n * Note that this could be extended to more intelligently handle\n * move events across input types, e.g. storing multiple simultaneous\n * pointer/touch events, calculating speed/direction, etc.\n */\nclass MoveInput extends _input__WEBPACK_IMPORTED_MODULE_0__[\"default\"] {\n    constructor(element, callback, options) {\n        super(element, callback, options);\n        this.handleEvent = (event) => {\n            this.handleOverEvent(event);\n            this.handleOutEvent(event);\n            this.handleEnterEvent(event);\n            this.handleLeaveEvent(event);\n            this.handleMoveEvent(event);\n        };\n        this.pressed = false;\n        const { enable } = this.options;\n        this.enableMoveEvent = enable;\n        this.enableLeaveEvent = enable;\n        this.enableEnterEvent = enable;\n        this.enableOutEvent = enable;\n        this.enableOverEvent = enable;\n        this.events = (this.options.events || []).concat(MOUSE_EVENTS);\n        this.events.forEach(event => element.addEventListener(event, this.handleEvent));\n    }\n    destroy() {\n        this.events.forEach(event => this.element.removeEventListener(event, this.handleEvent));\n    }\n    /**\n     * Enable this input (begin processing events)\n     * if the specified event type is among those handled by this input.\n     */\n    enableEventType(eventType, enabled) {\n        if (eventType === MOVE_EVENT_TYPE) {\n            this.enableMoveEvent = enabled;\n        }\n        if (eventType === OVER_EVENT_TYPE) {\n            this.enableOverEvent = enabled;\n        }\n        if (eventType === OUT_EVENT_TYPE) {\n            this.enableOutEvent = enabled;\n        }\n        if (eventType === ENTER_EVENT_TYPE) {\n            this.enableEnterEvent = enabled;\n        }\n        if (eventType === LEAVE_EVENT_TYPE) {\n            this.enableLeaveEvent = enabled;\n        }\n    }\n    handleOverEvent(event) {\n        if (this.enableOverEvent) {\n            if (event.type === 'mouseover') {\n                this._emit(OVER_EVENT_TYPE, event);\n            }\n        }\n    }\n    handleOutEvent(event) {\n        if (this.enableOutEvent) {\n            if (event.type === 'mouseout') {\n                this._emit(OUT_EVENT_TYPE, event);\n            }\n        }\n    }\n    handleEnterEvent(event) {\n        if (this.enableEnterEvent) {\n            if (event.type === 'mouseenter') {\n                this._emit(ENTER_EVENT_TYPE, event);\n            }\n        }\n    }\n    handleLeaveEvent(event) {\n        if (this.enableLeaveEvent) {\n            if (event.type === 'mouseleave') {\n                this._emit(LEAVE_EVENT_TYPE, event);\n            }\n        }\n    }\n    handleMoveEvent(event) {\n        if (this.enableMoveEvent) {\n            switch (event.type) {\n                case 'mousedown':\n                    if (event.button >= 0) {\n                        // Button is down\n                        this.pressed = true;\n                    }\n                    break;\n                case 'mousemove':\n                    // Move events use `which` to track the button being pressed\n                    if (event.which === 0) {\n                        // Button is not down\n                        this.pressed = false;\n                    }\n                    if (!this.pressed) {\n                        // Drag events are emitted by hammer already\n                        // we just need to emit the move event on hover\n                        this._emit(MOVE_EVENT_TYPE, event);\n                    }\n                    break;\n                case 'mouseup':\n                    this.pressed = false;\n                    break;\n                default:\n            }\n        }\n    }\n    _emit(type, event) {\n        this.callback({\n            type,\n            center: {\n                x: event.clientX,\n                y: event.clientY\n            },\n            srcEvent: event,\n            pointerType: 'mouse',\n            target: event.target\n        });\n    }\n}\n//# sourceMappingURL=move-input.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/mjolnir.js/dist/esm/inputs/move-input.js?");

/***/ }),

/***/ "./node_modules/mjolnir.js/dist/esm/inputs/wheel-input.js":
/*!****************************************************************!*\
  !*** ./node_modules/mjolnir.js/dist/esm/inputs/wheel-input.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ WheelInput)\n/* harmony export */ });\n/* harmony import */ var _input__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./input */ \"./node_modules/mjolnir.js/dist/esm/inputs/input.js\");\n/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../constants */ \"./node_modules/mjolnir.js/dist/esm/constants.js\");\n/* harmony import */ var _utils_globals__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/globals */ \"./node_modules/mjolnir.js/dist/esm/utils/globals.js\");\n\n\n\nconst firefox = _utils_globals__WEBPACK_IMPORTED_MODULE_2__.userAgent.indexOf('firefox') !== -1;\nconst { WHEEL_EVENTS } = _constants__WEBPACK_IMPORTED_MODULE_1__.INPUT_EVENT_TYPES;\nconst EVENT_TYPE = 'wheel';\n// Constants for normalizing input delta\nconst WHEEL_DELTA_MAGIC_SCALER = 4.000244140625;\nconst WHEEL_DELTA_PER_LINE = 40;\n// Slow down zoom if shift key is held for more precise zooming\nconst SHIFT_MULTIPLIER = 0.25;\nclass WheelInput extends _input__WEBPACK_IMPORTED_MODULE_0__[\"default\"] {\n    constructor(element, callback, options) {\n        super(element, callback, options);\n        /* eslint-disable complexity, max-statements */\n        this.handleEvent = (event) => {\n            if (!this.options.enable) {\n                return;\n            }\n            let value = event.deltaY;\n            if (_utils_globals__WEBPACK_IMPORTED_MODULE_2__.window.WheelEvent) {\n                // Firefox doubles the values on retina screens...\n                if (firefox && event.deltaMode === _utils_globals__WEBPACK_IMPORTED_MODULE_2__.window.WheelEvent.DOM_DELTA_PIXEL) {\n                    value /= _utils_globals__WEBPACK_IMPORTED_MODULE_2__.window.devicePixelRatio;\n                }\n                if (event.deltaMode === _utils_globals__WEBPACK_IMPORTED_MODULE_2__.window.WheelEvent.DOM_DELTA_LINE) {\n                    value *= WHEEL_DELTA_PER_LINE;\n                }\n            }\n            if (value !== 0 && value % WHEEL_DELTA_MAGIC_SCALER === 0) {\n                // This one is definitely a mouse wheel event.\n                // Normalize this value to match trackpad.\n                value = Math.floor(value / WHEEL_DELTA_MAGIC_SCALER);\n            }\n            if (event.shiftKey && value) {\n                value = value * SHIFT_MULTIPLIER;\n            }\n            this.callback({\n                type: EVENT_TYPE,\n                center: {\n                    x: event.clientX,\n                    y: event.clientY\n                },\n                delta: -value,\n                srcEvent: event,\n                pointerType: 'mouse',\n                target: event.target\n            });\n        };\n        this.events = (this.options.events || []).concat(WHEEL_EVENTS);\n        this.events.forEach(event => element.addEventListener(event, this.handleEvent, _utils_globals__WEBPACK_IMPORTED_MODULE_2__.passiveSupported ? { passive: false } : false));\n    }\n    destroy() {\n        this.events.forEach(event => this.element.removeEventListener(event, this.handleEvent));\n    }\n    /**\n     * Enable this input (begin processing events)\n     * if the specified event type is among those handled by this input.\n     */\n    enableEventType(eventType, enabled) {\n        if (eventType === EVENT_TYPE) {\n            this.options.enable = enabled;\n        }\n    }\n}\n//# sourceMappingURL=wheel-input.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/mjolnir.js/dist/esm/inputs/wheel-input.js?");

/***/ }),

/***/ "./node_modules/mjolnir.js/dist/esm/utils/event-registrar.js":
/*!*******************************************************************!*\
  !*** ./node_modules/mjolnir.js/dist/esm/utils/event-registrar.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ EventRegistrar)\n/* harmony export */ });\n/* harmony import */ var _event_utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./event-utils */ \"./node_modules/mjolnir.js/dist/esm/utils/event-utils.js\");\n\nconst DEFAULT_OPTIONS = {\n    srcElement: 'root',\n    priority: 0\n};\nclass EventRegistrar {\n    constructor(eventManager) {\n        /**\n         * Handles hammerjs event\n         */\n        this.handleEvent = (event) => {\n            if (this.isEmpty()) {\n                return;\n            }\n            const mjolnirEvent = this._normalizeEvent(event);\n            let target = event.srcEvent.target;\n            while (target && target !== mjolnirEvent.rootElement) {\n                this._emit(mjolnirEvent, target);\n                if (mjolnirEvent.handled) {\n                    return;\n                }\n                target = target.parentNode;\n            }\n            this._emit(mjolnirEvent, 'root');\n        };\n        this.eventManager = eventManager;\n        this.handlers = [];\n        // Element -> handler map\n        this.handlersByElement = new Map();\n        this._active = false;\n    }\n    // Returns true if there are no non-passive handlers\n    isEmpty() {\n        return !this._active;\n    }\n    add(type, handler, options, once = false, passive = false) {\n        const { handlers, handlersByElement } = this;\n        let opts = DEFAULT_OPTIONS;\n        if (typeof options === 'string' || (options && options.addEventListener)) {\n            // is DOM element, backward compatibility\n            // @ts-ignore\n            opts = { ...DEFAULT_OPTIONS, srcElement: options };\n        }\n        else if (options) {\n            opts = { ...DEFAULT_OPTIONS, ...options };\n        }\n        let entries = handlersByElement.get(opts.srcElement);\n        if (!entries) {\n            entries = [];\n            handlersByElement.set(opts.srcElement, entries);\n        }\n        const entry = {\n            type,\n            handler,\n            srcElement: opts.srcElement,\n            priority: opts.priority\n        };\n        if (once) {\n            entry.once = true;\n        }\n        if (passive) {\n            entry.passive = true;\n        }\n        handlers.push(entry);\n        this._active = this._active || !entry.passive;\n        // Sort handlers by descending priority\n        // Handlers with the same priority are excuted in the order of registration\n        let insertPosition = entries.length - 1;\n        while (insertPosition >= 0) {\n            if (entries[insertPosition].priority >= entry.priority) {\n                break;\n            }\n            insertPosition--;\n        }\n        entries.splice(insertPosition + 1, 0, entry);\n    }\n    remove(type, handler) {\n        const { handlers, handlersByElement } = this;\n        for (let i = handlers.length - 1; i >= 0; i--) {\n            const entry = handlers[i];\n            if (entry.type === type && entry.handler === handler) {\n                handlers.splice(i, 1);\n                const entries = handlersByElement.get(entry.srcElement);\n                entries.splice(entries.indexOf(entry), 1);\n                if (entries.length === 0) {\n                    handlersByElement.delete(entry.srcElement);\n                }\n            }\n        }\n        this._active = handlers.some(entry => !entry.passive);\n    }\n    /**\n     * Invoke handlers on a particular element\n     */\n    _emit(event, srcElement) {\n        const entries = this.handlersByElement.get(srcElement);\n        if (entries) {\n            let immediatePropagationStopped = false;\n            // Prevents the current event from bubbling up\n            const stopPropagation = () => {\n                event.handled = true;\n            };\n            // Prevent any remaining listeners from being called\n            const stopImmediatePropagation = () => {\n                event.handled = true;\n                immediatePropagationStopped = true;\n            };\n            const entriesToRemove = [];\n            for (let i = 0; i < entries.length; i++) {\n                const { type, handler, once } = entries[i];\n                handler({\n                    ...event,\n                    // @ts-ignore\n                    type,\n                    stopPropagation,\n                    stopImmediatePropagation\n                });\n                if (once) {\n                    entriesToRemove.push(entries[i]);\n                }\n                if (immediatePropagationStopped) {\n                    break;\n                }\n            }\n            for (let i = 0; i < entriesToRemove.length; i++) {\n                const { type, handler } = entriesToRemove[i];\n                this.remove(type, handler);\n            }\n        }\n    }\n    /**\n     * Normalizes hammerjs and custom events to have predictable fields.\n     */\n    _normalizeEvent(event) {\n        const rootElement = this.eventManager.getElement();\n        return {\n            ...event,\n            ...(0,_event_utils__WEBPACK_IMPORTED_MODULE_0__.whichButtons)(event),\n            ...(0,_event_utils__WEBPACK_IMPORTED_MODULE_0__.getOffsetPosition)(event, rootElement),\n            preventDefault: () => {\n                event.srcEvent.preventDefault();\n            },\n            stopImmediatePropagation: null,\n            stopPropagation: null,\n            handled: false,\n            rootElement\n        };\n    }\n}\n//# sourceMappingURL=event-registrar.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/mjolnir.js/dist/esm/utils/event-registrar.js?");

/***/ }),

/***/ "./node_modules/mjolnir.js/dist/esm/utils/event-utils.js":
/*!***************************************************************!*\
  !*** ./node_modules/mjolnir.js/dist/esm/utils/event-utils.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getOffsetPosition: () => (/* binding */ getOffsetPosition),\n/* harmony export */   whichButtons: () => (/* binding */ whichButtons)\n/* harmony export */ });\n/* Constants */\nconst DOWN_EVENT = 1;\nconst MOVE_EVENT = 2;\nconst UP_EVENT = 4;\nconst MOUSE_EVENTS = {\n    pointerdown: DOWN_EVENT,\n    pointermove: MOVE_EVENT,\n    pointerup: UP_EVENT,\n    mousedown: DOWN_EVENT,\n    mousemove: MOVE_EVENT,\n    mouseup: UP_EVENT\n};\n// MouseEvent.which https://developer.mozilla.org/en-US/docs/Web/API/MouseEvent/which\nconst MOUSE_EVENT_WHICH_LEFT = 1;\nconst MOUSE_EVENT_WHICH_MIDDLE = 2;\nconst MOUSE_EVENT_WHICH_RIGHT = 3;\n// MouseEvent.button https://developer.mozilla.org/en-US/docs/Web/API/MouseEvent/button\nconst MOUSE_EVENT_BUTTON_LEFT = 0;\nconst MOUSE_EVENT_BUTTON_MIDDLE = 1;\nconst MOUSE_EVENT_BUTTON_RIGHT = 2;\n// MouseEvent.buttons https://developer.mozilla.org/en-US/docs/Web/API/MouseEvent/buttons\nconst MOUSE_EVENT_BUTTONS_LEFT_MASK = 1;\nconst MOUSE_EVENT_BUTTONS_RIGHT_MASK = 2;\nconst MOUSE_EVENT_BUTTONS_MIDDLE_MASK = 4;\n/**\n * Extract the involved mouse button\n */\nfunction whichButtons(event) {\n    const eventType = MOUSE_EVENTS[event.srcEvent.type];\n    if (!eventType) {\n        // Not a mouse evet\n        return null;\n    }\n    const { buttons, button, which } = event.srcEvent;\n    let leftButton = false;\n    let middleButton = false;\n    let rightButton = false;\n    if (\n    // button is up, need to find out which one was pressed before\n    eventType === UP_EVENT ||\n        // moving but does not support `buttons` API\n        (eventType === MOVE_EVENT && !Number.isFinite(buttons))) {\n        leftButton = which === MOUSE_EVENT_WHICH_LEFT;\n        middleButton = which === MOUSE_EVENT_WHICH_MIDDLE;\n        rightButton = which === MOUSE_EVENT_WHICH_RIGHT;\n    }\n    else if (eventType === MOVE_EVENT) {\n        leftButton = Boolean(buttons & MOUSE_EVENT_BUTTONS_LEFT_MASK);\n        middleButton = Boolean(buttons & MOUSE_EVENT_BUTTONS_MIDDLE_MASK);\n        rightButton = Boolean(buttons & MOUSE_EVENT_BUTTONS_RIGHT_MASK);\n    }\n    else if (eventType === DOWN_EVENT) {\n        leftButton = button === MOUSE_EVENT_BUTTON_LEFT;\n        middleButton = button === MOUSE_EVENT_BUTTON_MIDDLE;\n        rightButton = button === MOUSE_EVENT_BUTTON_RIGHT;\n    }\n    return { leftButton, middleButton, rightButton };\n}\n/**\n * Calculate event position relative to the root element\n */\nfunction getOffsetPosition(event, rootElement) {\n    const center = event.center;\n    // `center` is a hammer.js event property\n    if (!center) {\n        // Not a gestural event\n        return null;\n    }\n    const rect = rootElement.getBoundingClientRect();\n    // Fix scale for map affected by a CSS transform.\n    // See https://stackoverflow.com/a/26893663/3528533\n    const scaleX = rect.width / rootElement.offsetWidth || 1;\n    const scaleY = rect.height / rootElement.offsetHeight || 1;\n    // Calculate center relative to the root element\n    const offsetCenter = {\n        x: (center.x - rect.left - rootElement.clientLeft) / scaleX,\n        y: (center.y - rect.top - rootElement.clientTop) / scaleY\n    };\n    return { center, offsetCenter };\n}\n//# sourceMappingURL=event-utils.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/mjolnir.js/dist/esm/utils/event-utils.js?");

/***/ }),

/***/ "./node_modules/mjolnir.js/dist/esm/utils/globals.js":
/*!***********************************************************!*\
  !*** ./node_modules/mjolnir.js/dist/esm/utils/globals.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   document: () => (/* binding */ document_),\n/* harmony export */   global: () => (/* binding */ global_),\n/* harmony export */   passiveSupported: () => (/* binding */ passiveSupported),\n/* harmony export */   userAgent: () => (/* binding */ userAgent),\n/* harmony export */   window: () => (/* binding */ window_)\n/* harmony export */ });\n// Purpose: include this in your module to avoids adding dependencies on\n// micro modules like 'global'\n/* global window, global, document, navigator */\nconst userAgent = typeof navigator !== 'undefined' && navigator.userAgent ? navigator.userAgent.toLowerCase() : '';\nconst window_ = typeof window !== 'undefined' ? window : __webpack_require__.g;\nconst global_ = typeof __webpack_require__.g !== 'undefined' ? __webpack_require__.g : window;\nconst document_ = typeof document !== 'undefined' ? document : {};\n\n/*\n * Detect whether passive option is supported by the current browser.\n * https://developer.mozilla.org/en-US/docs/Web/API/EventTarget/addEventListener\n   #Safely_detecting_option_support\n */\nlet passiveSupported = false;\n/* eslint-disable accessor-pairs, no-empty */\ntry {\n    const options = {\n        // This function will be called when the browser\n        // attempts to access the passive property.\n        get passive() {\n            passiveSupported = true;\n            return true;\n        }\n    };\n    window_.addEventListener('test', null, options);\n    window_.removeEventListener('test', null);\n}\ncatch (err) {\n    passiveSupported = false;\n}\n\n//# sourceMappingURL=globals.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/mjolnir.js/dist/esm/utils/globals.js?");

/***/ }),

/***/ "./node_modules/mjolnir.js/dist/esm/utils/hammer-overrides.js":
/*!********************************************************************!*\
  !*** ./node_modules/mjolnir.js/dist/esm/utils/hammer-overrides.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   enhanceMouseInput: () => (/* binding */ enhanceMouseInput),\n/* harmony export */   enhancePointerEventInput: () => (/* binding */ enhancePointerEventInput)\n/* harmony export */ });\n/**\n * This file contains overrides the default\n * hammer.js functions to add our own utility\n */\n/* eslint-disable */\n/* Hammer.js constants */\nconst INPUT_START = 1;\nconst INPUT_MOVE = 2;\nconst INPUT_END = 4;\nconst MOUSE_INPUT_MAP = {\n    mousedown: INPUT_START,\n    mousemove: INPUT_MOVE,\n    mouseup: INPUT_END\n};\n/**\n * Helper function that returns true if any element in an array meets given criteria.\n * Because older browsers do not support `Array.prototype.some`\n * @params array {Array}\n * @params predict {Function}\n */\nfunction some(array, predict) {\n    for (let i = 0; i < array.length; i++) {\n        if (predict(array[i])) {\n            return true;\n        }\n    }\n    return false;\n}\n/* eslint-disable no-invalid-this */\nfunction enhancePointerEventInput(PointerEventInput) {\n    const oldHandler = PointerEventInput.prototype.handler;\n    // overrides PointerEventInput.handler to accept right mouse button\n    PointerEventInput.prototype.handler = function handler(ev) {\n        const store = this.store;\n        // Allow non-left mouse buttons through\n        if (ev.button > 0 && ev.type === 'pointerdown') {\n            if (!some(store, e => e.pointerId === ev.pointerId)) {\n                store.push(ev);\n            }\n        }\n        oldHandler.call(this, ev);\n    };\n}\n// overrides MouseInput.handler to accept right mouse button\nfunction enhanceMouseInput(MouseInput) {\n    MouseInput.prototype.handler = function handler(ev) {\n        let eventType = MOUSE_INPUT_MAP[ev.type];\n        // on start we want to have the mouse button down\n        if (eventType & INPUT_START && ev.button >= 0) {\n            this.pressed = true;\n        }\n        if (eventType & INPUT_MOVE && ev.which === 0) {\n            eventType = INPUT_END;\n        }\n        // mouse must be down\n        if (!this.pressed) {\n            return;\n        }\n        if (eventType & INPUT_END) {\n            this.pressed = false;\n        }\n        this.callback(this.manager, eventType, {\n            pointers: [ev],\n            changedPointers: [ev],\n            pointerType: 'mouse',\n            srcEvent: ev\n        });\n    };\n}\n//# sourceMappingURL=hammer-overrides.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/mjolnir.js/dist/esm/utils/hammer-overrides.js?");

/***/ }),

/***/ "./node_modules/mjolnir.js/dist/esm/utils/hammer.browser.js":
/*!******************************************************************!*\
  !*** ./node_modules/mjolnir.js/dist/esm/utils/hammer.browser.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Manager: () => (/* binding */ Manager),\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var hammerjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! hammerjs */ \"./node_modules/hammerjs/hammer.js\");\n/* harmony import */ var hammerjs__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(hammerjs__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _hammer_overrides__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./hammer-overrides */ \"./node_modules/mjolnir.js/dist/esm/utils/hammer-overrides.js\");\n\n\n(0,_hammer_overrides__WEBPACK_IMPORTED_MODULE_1__.enhancePointerEventInput)(hammerjs__WEBPACK_IMPORTED_MODULE_0__.PointerEventInput);\n(0,_hammer_overrides__WEBPACK_IMPORTED_MODULE_1__.enhanceMouseInput)(hammerjs__WEBPACK_IMPORTED_MODULE_0__.MouseInput);\nconst Manager = hammerjs__WEBPACK_IMPORTED_MODULE_0__.Manager;\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (hammerjs__WEBPACK_IMPORTED_MODULE_0__);\n//# sourceMappingURL=hammer.browser.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/mjolnir.js/dist/esm/utils/hammer.browser.js?");

/***/ }),

/***/ "./node_modules/onnxruntime-common/dist/lib/backend-impl.js":
/*!******************************************************************!*\
  !*** ./node_modules/onnxruntime-common/dist/lib/backend-impl.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   registerBackend: () => (/* binding */ registerBackend),\n/* harmony export */   resolveBackend: () => (/* binding */ resolveBackend)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\nconst backends = {};\nconst backendsSortedByPriority = [];\n/**\n * Register a backend.\n *\n * @param name - the name as a key to lookup as an execution provider.\n * @param backend - the backend object.\n * @param priority - an integer indicating the priority of the backend. Higher number means higher priority. if priority\n * < 0, it will be considered as a 'beta' version and will not be used as a fallback backend by default.\n *\n * @internal\n */\nconst registerBackend = (name, backend, priority) => {\n    if (backend && typeof backend.init === 'function' && typeof backend.createSessionHandler === 'function') {\n        const currentBackend = backends[name];\n        if (currentBackend === undefined) {\n            backends[name] = { backend, priority };\n        }\n        else if (currentBackend.priority > priority) {\n            // same name is already registered with a higher priority. skip registeration.\n            return;\n        }\n        else if (currentBackend.priority === priority) {\n            if (currentBackend.backend !== backend) {\n                throw new Error(`cannot register backend \"${name}\" using priority ${priority}`);\n            }\n        }\n        if (priority >= 0) {\n            const i = backendsSortedByPriority.indexOf(name);\n            if (i !== -1) {\n                backendsSortedByPriority.splice(i, 1);\n            }\n            for (let i = 0; i < backendsSortedByPriority.length; i++) {\n                if (backends[backendsSortedByPriority[i]].priority <= priority) {\n                    backendsSortedByPriority.splice(i, 0, name);\n                    return;\n                }\n            }\n            backendsSortedByPriority.push(name);\n        }\n        return;\n    }\n    throw new TypeError('not a valid backend');\n};\n/**\n * Resolve backend by specified hints.\n *\n * @param backendHints - a list of execution provider names to lookup. If omitted use registered backends as list.\n * @returns a promise that resolves to the backend.\n *\n * @internal\n */\nconst resolveBackend = async (backendHints) => {\n    const backendNames = backendHints.length === 0 ? backendsSortedByPriority : backendHints;\n    const errors = [];\n    for (const backendName of backendNames) {\n        const backendInfo = backends[backendName];\n        if (backendInfo) {\n            if (backendInfo.initialized) {\n                return backendInfo.backend;\n            }\n            else if (backendInfo.aborted) {\n                continue; // current backend is unavailable; try next\n            }\n            const isInitializing = !!backendInfo.initPromise;\n            try {\n                if (!isInitializing) {\n                    backendInfo.initPromise = backendInfo.backend.init();\n                }\n                await backendInfo.initPromise;\n                backendInfo.initialized = true;\n                return backendInfo.backend;\n            }\n            catch (e) {\n                if (!isInitializing) {\n                    errors.push({ name: backendName, err: e });\n                }\n                backendInfo.aborted = true;\n            }\n            finally {\n                delete backendInfo.initPromise;\n            }\n        }\n    }\n    throw new Error(`no available backend found. ERR: ${errors.map(e => `[${e.name}] ${e.err}`).join(', ')}`);\n};\n//# sourceMappingURL=backend-impl.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/onnxruntime-common/dist/lib/backend-impl.js?");

/***/ }),

/***/ "./node_modules/onnxruntime-common/dist/lib/backend.js":
/*!*************************************************************!*\
  !*** ./node_modules/onnxruntime-common/dist/lib/backend.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   registerBackend: () => (/* reexport safe */ _backend_impl__WEBPACK_IMPORTED_MODULE_0__.registerBackend)\n/* harmony export */ });\n/* harmony import */ var _backend_impl__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./backend-impl */ \"./node_modules/onnxruntime-common/dist/lib/backend-impl.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n//# sourceMappingURL=backend.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/onnxruntime-common/dist/lib/backend.js?");

/***/ }),

/***/ "./node_modules/onnxruntime-common/dist/lib/env-impl.js":
/*!**************************************************************!*\
  !*** ./node_modules/onnxruntime-common/dist/lib/env-impl.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   EnvImpl: () => (/* binding */ EnvImpl)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\nclass EnvImpl {\n    constructor() {\n        this.wasm = {};\n        this.webgl = {};\n        this.logLevelInternal = 'warning';\n    }\n    // TODO standadize the getter and setter convention in env for other fields.\n    set logLevel(value) {\n        if (value === undefined) {\n            return;\n        }\n        if (typeof value !== 'string' || ['verbose', 'info', 'warning', 'error', 'fatal'].indexOf(value) === -1) {\n            throw new Error(`Unsupported logging level: ${value}`);\n        }\n        this.logLevelInternal = value;\n    }\n    get logLevel() {\n        return this.logLevelInternal;\n    }\n}\n//# sourceMappingURL=env-impl.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/onnxruntime-common/dist/lib/env-impl.js?");

/***/ }),

/***/ "./node_modules/onnxruntime-common/dist/lib/env.js":
/*!*********************************************************!*\
  !*** ./node_modules/onnxruntime-common/dist/lib/env.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   env: () => (/* binding */ env)\n/* harmony export */ });\n/* harmony import */ var _env_impl__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./env-impl */ \"./node_modules/onnxruntime-common/dist/lib/env-impl.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n/**\n * Represent a set of flags as a global singleton.\n */\nconst env = new _env_impl__WEBPACK_IMPORTED_MODULE_0__.EnvImpl();\n//# sourceMappingURL=env.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/onnxruntime-common/dist/lib/env.js?");

/***/ }),

/***/ "./node_modules/onnxruntime-common/dist/lib/index.js":
/*!***********************************************************!*\
  !*** ./node_modules/onnxruntime-common/dist/lib/index.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   InferenceSession: () => (/* reexport safe */ _inference_session__WEBPACK_IMPORTED_MODULE_2__.InferenceSession),\n/* harmony export */   Tensor: () => (/* reexport safe */ _tensor__WEBPACK_IMPORTED_MODULE_3__.Tensor),\n/* harmony export */   env: () => (/* reexport safe */ _env__WEBPACK_IMPORTED_MODULE_1__.env),\n/* harmony export */   registerBackend: () => (/* reexport safe */ _backend__WEBPACK_IMPORTED_MODULE_0__.registerBackend)\n/* harmony export */ });\n/* harmony import */ var _backend__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./backend */ \"./node_modules/onnxruntime-common/dist/lib/backend.js\");\n/* harmony import */ var _env__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./env */ \"./node_modules/onnxruntime-common/dist/lib/env.js\");\n/* harmony import */ var _inference_session__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./inference-session */ \"./node_modules/onnxruntime-common/dist/lib/inference-session.js\");\n/* harmony import */ var _tensor__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./tensor */ \"./node_modules/onnxruntime-common/dist/lib/tensor.js\");\n/* harmony import */ var _onnx_value__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./onnx-value */ \"./node_modules/onnxruntime-common/dist/lib/onnx-value.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n/**\n * # ONNX Runtime JavaScript API\n *\n * ONNX Runtime JavaScript API is a unified API for all JavaScript usages, including the following NPM packages:\n *\n * - [onnxruntime-node](https://www.npmjs.com/package/onnxruntime-node)\n * - [onnxruntime-web](https://www.npmjs.com/package/onnxruntime-web)\n * - [onnxruntime-react-native](https://www.npmjs.com/package/onnxruntime-react-native)\n *\n * See also:\n * - [Get Started](https://onnxruntime.ai/docs/get-started/with-javascript.html)\n * - [Inference examples](https://github.com/microsoft/onnxruntime-inference-examples/tree/main/js)\n *\n * @packageDocumentation\n */\n\n\n\n\n\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/onnxruntime-common/dist/lib/index.js?");

/***/ }),

/***/ "./node_modules/onnxruntime-common/dist/lib/inference-session-impl.js":
/*!****************************************************************************!*\
  !*** ./node_modules/onnxruntime-common/dist/lib/inference-session-impl.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   InferenceSession: () => (/* binding */ InferenceSession)\n/* harmony export */ });\n/* harmony import */ var _backend_impl__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./backend-impl */ \"./node_modules/onnxruntime-common/dist/lib/backend-impl.js\");\n/* harmony import */ var _tensor__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./tensor */ \"./node_modules/onnxruntime-common/dist/lib/tensor.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n\nclass InferenceSession {\n    constructor(handler) {\n        this.handler = handler;\n    }\n    async run(feeds, arg1, arg2) {\n        const fetches = {};\n        let options = {};\n        // check inputs\n        if (typeof feeds !== 'object' || feeds === null || feeds instanceof _tensor__WEBPACK_IMPORTED_MODULE_1__.Tensor || Array.isArray(feeds)) {\n            throw new TypeError('\\'feeds\\' must be an object that use input names as keys and OnnxValue as corresponding values.');\n        }\n        let isFetchesEmpty = true;\n        // determine which override is being used\n        if (typeof arg1 === 'object') {\n            if (arg1 === null) {\n                throw new TypeError('Unexpected argument[1]: cannot be null.');\n            }\n            if (arg1 instanceof _tensor__WEBPACK_IMPORTED_MODULE_1__.Tensor) {\n                throw new TypeError('\\'fetches\\' cannot be a Tensor');\n            }\n            if (Array.isArray(arg1)) {\n                if (arg1.length === 0) {\n                    throw new TypeError('\\'fetches\\' cannot be an empty array.');\n                }\n                isFetchesEmpty = false;\n                // output names\n                for (const name of arg1) {\n                    if (typeof name !== 'string') {\n                        throw new TypeError('\\'fetches\\' must be a string array or an object.');\n                    }\n                    if (this.outputNames.indexOf(name) === -1) {\n                        throw new RangeError(`'fetches' contains invalid output name: ${name}.`);\n                    }\n                    fetches[name] = null;\n                }\n                if (typeof arg2 === 'object' && arg2 !== null) {\n                    options = arg2;\n                }\n                else if (typeof arg2 !== 'undefined') {\n                    throw new TypeError('\\'options\\' must be an object.');\n                }\n            }\n            else {\n                // decide whether arg1 is fetches or options\n                // if any output name is present and its value is valid OnnxValue, we consider it fetches\n                let isFetches = false;\n                const arg1Keys = Object.getOwnPropertyNames(arg1);\n                for (const name of this.outputNames) {\n                    if (arg1Keys.indexOf(name) !== -1) {\n                        const v = arg1[name];\n                        if (v === null || v instanceof _tensor__WEBPACK_IMPORTED_MODULE_1__.Tensor) {\n                            isFetches = true;\n                            isFetchesEmpty = false;\n                            fetches[name] = v;\n                        }\n                    }\n                }\n                if (isFetches) {\n                    if (typeof arg2 === 'object' && arg2 !== null) {\n                        options = arg2;\n                    }\n                    else if (typeof arg2 !== 'undefined') {\n                        throw new TypeError('\\'options\\' must be an object.');\n                    }\n                }\n                else {\n                    options = arg1;\n                }\n            }\n        }\n        else if (typeof arg1 !== 'undefined') {\n            throw new TypeError('Unexpected argument[1]: must be \\'fetches\\' or \\'options\\'.');\n        }\n        // check if all inputs are in feed\n        for (const name of this.inputNames) {\n            if (typeof feeds[name] === 'undefined') {\n                throw new Error(`input '${name}' is missing in 'feeds'.`);\n            }\n        }\n        // if no fetches is specified, we use the full output names list\n        if (isFetchesEmpty) {\n            for (const name of this.outputNames) {\n                fetches[name] = null;\n            }\n        }\n        // feeds, fetches and options are prepared\n        const results = await this.handler.run(feeds, fetches, options);\n        const returnValue = {};\n        for (const key in results) {\n            if (Object.hasOwnProperty.call(results, key)) {\n                returnValue[key] = new _tensor__WEBPACK_IMPORTED_MODULE_1__.Tensor(results[key].type, results[key].data, results[key].dims);\n            }\n        }\n        return returnValue;\n    }\n    static async create(arg0, arg1, arg2, arg3) {\n        // either load from a file or buffer\n        let filePathOrUint8Array;\n        let options = {};\n        if (typeof arg0 === 'string') {\n            filePathOrUint8Array = arg0;\n            if (typeof arg1 === 'object' && arg1 !== null) {\n                options = arg1;\n            }\n            else if (typeof arg1 !== 'undefined') {\n                throw new TypeError('\\'options\\' must be an object.');\n            }\n        }\n        else if (arg0 instanceof Uint8Array) {\n            filePathOrUint8Array = arg0;\n            if (typeof arg1 === 'object' && arg1 !== null) {\n                options = arg1;\n            }\n            else if (typeof arg1 !== 'undefined') {\n                throw new TypeError('\\'options\\' must be an object.');\n            }\n        }\n        else if (arg0 instanceof ArrayBuffer ||\n            (typeof SharedArrayBuffer !== 'undefined' && arg0 instanceof SharedArrayBuffer)) {\n            const buffer = arg0;\n            let byteOffset = 0;\n            let byteLength = arg0.byteLength;\n            if (typeof arg1 === 'object' && arg1 !== null) {\n                options = arg1;\n            }\n            else if (typeof arg1 === 'number') {\n                byteOffset = arg1;\n                if (!Number.isSafeInteger(byteOffset)) {\n                    throw new RangeError('\\'byteOffset\\' must be an integer.');\n                }\n                if (byteOffset < 0 || byteOffset >= buffer.byteLength) {\n                    throw new RangeError(`'byteOffset' is out of range [0, ${buffer.byteLength}).`);\n                }\n                byteLength = arg0.byteLength - byteOffset;\n                if (typeof arg2 === 'number') {\n                    byteLength = arg2;\n                    if (!Number.isSafeInteger(byteLength)) {\n                        throw new RangeError('\\'byteLength\\' must be an integer.');\n                    }\n                    if (byteLength <= 0 || byteOffset + byteLength > buffer.byteLength) {\n                        throw new RangeError(`'byteLength' is out of range (0, ${buffer.byteLength - byteOffset}].`);\n                    }\n                    if (typeof arg3 === 'object' && arg3 !== null) {\n                        options = arg3;\n                    }\n                    else if (typeof arg3 !== 'undefined') {\n                        throw new TypeError('\\'options\\' must be an object.');\n                    }\n                }\n                else if (typeof arg2 !== 'undefined') {\n                    throw new TypeError('\\'byteLength\\' must be a number.');\n                }\n            }\n            else if (typeof arg1 !== 'undefined') {\n                throw new TypeError('\\'options\\' must be an object.');\n            }\n            filePathOrUint8Array = new Uint8Array(buffer, byteOffset, byteLength);\n        }\n        else {\n            throw new TypeError('Unexpected argument[0]: must be \\'path\\' or \\'buffer\\'.');\n        }\n        // get backend hints\n        const eps = options.executionProviders || [];\n        const backendHints = eps.map(i => typeof i === 'string' ? i : i.name);\n        const backend = await (0,_backend_impl__WEBPACK_IMPORTED_MODULE_0__.resolveBackend)(backendHints);\n        const handler = await backend.createSessionHandler(filePathOrUint8Array, options);\n        return new InferenceSession(handler);\n    }\n    startProfiling() {\n        this.handler.startProfiling();\n    }\n    endProfiling() {\n        this.handler.endProfiling();\n    }\n    get inputNames() {\n        return this.handler.inputNames;\n    }\n    get outputNames() {\n        return this.handler.outputNames;\n    }\n}\n//# sourceMappingURL=inference-session-impl.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/onnxruntime-common/dist/lib/inference-session-impl.js?");

/***/ }),

/***/ "./node_modules/onnxruntime-common/dist/lib/inference-session.js":
/*!***********************************************************************!*\
  !*** ./node_modules/onnxruntime-common/dist/lib/inference-session.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   InferenceSession: () => (/* binding */ InferenceSession)\n/* harmony export */ });\n/* harmony import */ var _inference_session_impl__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./inference-session-impl */ \"./node_modules/onnxruntime-common/dist/lib/inference-session-impl.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nconst InferenceSession = _inference_session_impl__WEBPACK_IMPORTED_MODULE_0__.InferenceSession;\n//# sourceMappingURL=inference-session.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/onnxruntime-common/dist/lib/inference-session.js?");

/***/ }),

/***/ "./node_modules/onnxruntime-common/dist/lib/onnx-value.js":
/*!****************************************************************!*\
  !*** ./node_modules/onnxruntime-common/dist/lib/onnx-value.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n//# sourceMappingURL=onnx-value.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/onnxruntime-common/dist/lib/onnx-value.js?");

/***/ }),

/***/ "./node_modules/onnxruntime-common/dist/lib/tensor-impl.js":
/*!*****************************************************************!*\
  !*** ./node_modules/onnxruntime-common/dist/lib/tensor-impl.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Tensor: () => (/* binding */ Tensor)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\nconst isBigInt64ArrayAvailable = typeof BigInt64Array !== 'undefined' && typeof BigInt64Array.from === 'function';\nconst isBigUint64ArrayAvailable = typeof BigUint64Array !== 'undefined' && typeof BigUint64Array.from === 'function';\n// a runtime map that maps type string to TypedArray constructor. Should match Tensor.DataTypeMap.\nconst NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP = new Map([\n    ['float32', Float32Array],\n    ['uint8', Uint8Array],\n    ['int8', Int8Array],\n    ['uint16', Uint16Array],\n    ['int16', Int16Array],\n    ['int32', Int32Array],\n    ['bool', Uint8Array],\n    ['float64', Float64Array],\n    ['uint32', Uint32Array],\n]);\n// a runtime map that maps type string to TypedArray constructor. Should match Tensor.DataTypeMap.\nconst NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP = new Map([\n    [Float32Array, 'float32'],\n    [Uint8Array, 'uint8'],\n    [Int8Array, 'int8'],\n    [Uint16Array, 'uint16'],\n    [Int16Array, 'int16'],\n    [Int32Array, 'int32'],\n    [Float64Array, 'float64'],\n    [Uint32Array, 'uint32'],\n]);\nif (isBigInt64ArrayAvailable) {\n    NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('int64', BigInt64Array);\n    NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigInt64Array, 'int64');\n}\nif (isBigUint64ArrayAvailable) {\n    NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('uint64', BigUint64Array);\n    NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigUint64Array, 'uint64');\n}\n/**\n * calculate size from dims.\n *\n * @param dims the dims array. May be an illegal input.\n */\nconst calculateSize = (dims) => {\n    let size = 1;\n    for (let i = 0; i < dims.length; i++) {\n        const dim = dims[i];\n        if (typeof dim !== 'number' || !Number.isSafeInteger(dim)) {\n            throw new TypeError(`dims[${i}] must be an integer, got: ${dim}`);\n        }\n        if (dim < 0) {\n            throw new RangeError(`dims[${i}] must be a non-negative integer, got: ${dim}`);\n        }\n        size *= dim;\n    }\n    return size;\n};\nclass Tensor {\n    constructor(arg0, arg1, arg2) {\n        let type;\n        let data;\n        let dims;\n        // check whether arg0 is type or data\n        if (typeof arg0 === 'string') {\n            //\n            // Override: constructor(type, data, ...)\n            //\n            type = arg0;\n            dims = arg2;\n            if (arg0 === 'string') {\n                // string tensor\n                if (!Array.isArray(arg1)) {\n                    throw new TypeError('A string tensor\\'s data must be a string array.');\n                }\n                // we don't check whether every element in the array is string; this is too slow. we assume it's correct and\n                // error will be populated at inference\n                data = arg1;\n            }\n            else {\n                // numeric tensor\n                const typedArrayConstructor = NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(arg0);\n                if (typedArrayConstructor === undefined) {\n                    throw new TypeError(`Unsupported tensor type: ${arg0}.`);\n                }\n                if (Array.isArray(arg1)) {\n                    // use 'as any' here because TypeScript's check on type of 'SupportedTypedArrayConstructors.from()' produces\n                    // incorrect results.\n                    // 'typedArrayConstructor' should be one of the typed array prototype objects.\n                    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n                    data = typedArrayConstructor.from(arg1);\n                }\n                else if (arg1 instanceof typedArrayConstructor) {\n                    data = arg1;\n                }\n                else {\n                    throw new TypeError(`A ${type} tensor's data must be type of ${typedArrayConstructor}`);\n                }\n            }\n        }\n        else {\n            //\n            // Override: constructor(data, ...)\n            //\n            dims = arg1;\n            if (Array.isArray(arg0)) {\n                // only boolean[] and string[] is supported\n                if (arg0.length === 0) {\n                    throw new TypeError('Tensor type cannot be inferred from an empty array.');\n                }\n                const firstElementType = typeof arg0[0];\n                if (firstElementType === 'string') {\n                    type = 'string';\n                    data = arg0;\n                }\n                else if (firstElementType === 'boolean') {\n                    type = 'bool';\n                    // 'arg0' is of type 'boolean[]'. Uint8Array.from(boolean[]) actually works, but typescript thinks this is\n                    // wrong type. We use 'as any' to make it happy.\n                    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n                    data = Uint8Array.from(arg0);\n                }\n                else {\n                    throw new TypeError(`Invalid element type of data array: ${firstElementType}.`);\n                }\n            }\n            else {\n                // get tensor type from TypedArray\n                const mappedType = NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.get(arg0.constructor);\n                if (mappedType === undefined) {\n                    throw new TypeError(`Unsupported type for tensor data: ${arg0.constructor}.`);\n                }\n                type = mappedType;\n                data = arg0;\n            }\n        }\n        // type and data is processed, now processing dims\n        if (dims === undefined) {\n            // assume 1-D tensor if dims omitted\n            dims = [data.length];\n        }\n        else if (!Array.isArray(dims)) {\n            throw new TypeError('A tensor\\'s dims must be a number array');\n        }\n        // perform check\n        const size = calculateSize(dims);\n        if (size !== data.length) {\n            throw new Error(`Tensor's size(${size}) does not match data length(${data.length}).`);\n        }\n        this.dims = dims;\n        this.type = type;\n        this.data = data;\n        this.size = size;\n    }\n    // #endregion\n    /**\n     * Create a new tensor object from image object\n     *\n     * @param buffer - Extracted image buffer data - assuming RGBA format\n     * @param imageFormat - input image configuration - required configurations height, width, format\n     * @param tensorFormat - output tensor configuration - Default is RGB format\n     */\n    static bufferToTensor(buffer, options) {\n        if (buffer === undefined) {\n            throw new Error('Image buffer must be defined');\n        }\n        if (options.height === undefined || options.width === undefined) {\n            throw new Error('Image height and width must be defined');\n        }\n        const { height, width } = options;\n        const norm = options.norm;\n        let normMean;\n        let normBias;\n        if (norm === undefined || norm.mean === undefined) {\n            normMean = 255;\n        }\n        else {\n            normMean = norm.mean;\n        }\n        if (norm === undefined || norm.bias === undefined) {\n            normBias = 0;\n        }\n        else {\n            normBias = norm.bias;\n        }\n        const inputformat = options.bitmapFormat !== undefined ? options.bitmapFormat : 'RGBA';\n        // default value is RGBA since imagedata and HTMLImageElement uses it\n        const outputformat = options.tensorFormat !== undefined ?\n            (options.tensorFormat !== undefined ? options.tensorFormat : 'RGB') :\n            'RGB';\n        const offset = height * width;\n        const float32Data = outputformat === 'RGBA' ? new Float32Array(offset * 4) : new Float32Array(offset * 3);\n        // Default pointer assignments\n        let step = 4, rImagePointer = 0, gImagePointer = 1, bImagePointer = 2, aImagePointer = 3;\n        let rTensorPointer = 0, gTensorPointer = offset, bTensorPointer = offset * 2, aTensorPointer = -1;\n        // Updating the pointer assignments based on the input image format\n        if (inputformat === 'RGB') {\n            step = 3;\n            rImagePointer = 0;\n            gImagePointer = 1;\n            bImagePointer = 2;\n            aImagePointer = -1;\n        }\n        // Updating the pointer assignments based on the output tensor format\n        if (outputformat === 'RGBA') {\n            aTensorPointer = offset * 3;\n        }\n        else if (outputformat === 'RBG') {\n            rTensorPointer = 0;\n            bTensorPointer = offset;\n            gTensorPointer = offset * 2;\n        }\n        else if (outputformat === 'BGR') {\n            bTensorPointer = 0;\n            gTensorPointer = offset;\n            rTensorPointer = offset * 2;\n        }\n        for (let i = 0; i < offset; i++, rImagePointer += step, bImagePointer += step, gImagePointer += step, aImagePointer += step) {\n            float32Data[rTensorPointer++] = (buffer[rImagePointer] + normBias) / normMean;\n            float32Data[gTensorPointer++] = (buffer[gImagePointer] + normBias) / normMean;\n            float32Data[bTensorPointer++] = (buffer[bImagePointer] + normBias) / normMean;\n            if (aTensorPointer !== -1 && aImagePointer !== -1) {\n                float32Data[aTensorPointer++] = (buffer[aImagePointer] + normBias) / normMean;\n            }\n        }\n        // Float32Array -> ort.Tensor\n        const outputTensor = outputformat === 'RGBA' ? new Tensor('float32', float32Data, [1, 4, height, width]) :\n            new Tensor('float32', float32Data, [1, 3, height, width]);\n        return outputTensor;\n    }\n    static async fromImage(image, options) {\n        // checking the type of image object\n        const isHTMLImageEle = typeof (HTMLImageElement) !== 'undefined' && image instanceof HTMLImageElement;\n        const isImageDataEle = typeof (ImageData) !== 'undefined' && image instanceof ImageData;\n        const isImageBitmap = typeof (ImageBitmap) !== 'undefined' && image instanceof ImageBitmap;\n        const isURL = typeof (String) !== 'undefined' && (image instanceof String || typeof image === 'string');\n        let data;\n        let tensorConfig = {};\n        // filling and checking image configuration options\n        if (isHTMLImageEle) {\n            // HTMLImageElement - image object - format is RGBA by default\n            const canvas = document.createElement('canvas');\n            const pixels2DContext = canvas.getContext('2d');\n            if (pixels2DContext != null) {\n                let height = image.naturalHeight;\n                let width = image.naturalWidth;\n                if (options !== undefined && options.resizedHeight !== undefined && options.resizedWidth !== undefined) {\n                    height = options.resizedHeight;\n                    width = options.resizedWidth;\n                }\n                if (options !== undefined) {\n                    tensorConfig = options;\n                    if (options.tensorFormat !== undefined) {\n                        throw new Error('Image input config format must be RGBA for HTMLImageElement');\n                    }\n                    else {\n                        tensorConfig.tensorFormat = 'RGBA';\n                    }\n                    if (options.height !== undefined && options.height !== height) {\n                        throw new Error('Image input config height doesn\\'t match HTMLImageElement height');\n                    }\n                    else {\n                        tensorConfig.height = height;\n                    }\n                    if (options.width !== undefined && options.width !== width) {\n                        throw new Error('Image input config width doesn\\'t match HTMLImageElement width');\n                    }\n                    else {\n                        tensorConfig.width = width;\n                    }\n                }\n                else {\n                    tensorConfig.tensorFormat = 'RGBA';\n                    tensorConfig.height = height;\n                    tensorConfig.width = width;\n                }\n                canvas.width = width;\n                canvas.height = height;\n                pixels2DContext.drawImage(image, 0, 0, width, height);\n                data = pixels2DContext.getImageData(0, 0, width, height).data;\n            }\n            else {\n                throw new Error('Can not access image data');\n            }\n        }\n        else if (isImageDataEle) {\n            // ImageData - image object - format is RGBA by default\n            const format = 'RGBA';\n            let height;\n            let width;\n            if (options !== undefined && options.resizedWidth !== undefined && options.resizedHeight !== undefined) {\n                height = options.resizedHeight;\n                width = options.resizedWidth;\n            }\n            else {\n                height = image.height;\n                width = image.width;\n            }\n            if (options !== undefined) {\n                tensorConfig = options;\n                if (options.bitmapFormat !== undefined && options.bitmapFormat !== format) {\n                    throw new Error('Image input config format must be RGBA for ImageData');\n                }\n                else {\n                    tensorConfig.bitmapFormat = 'RGBA';\n                }\n            }\n            else {\n                tensorConfig.bitmapFormat = 'RGBA';\n            }\n            tensorConfig.height = height;\n            tensorConfig.width = width;\n            if (options !== undefined) {\n                const tempCanvas = document.createElement('canvas');\n                tempCanvas.width = width;\n                tempCanvas.height = height;\n                const pixels2DContext = tempCanvas.getContext('2d');\n                if (pixels2DContext != null) {\n                    pixels2DContext.putImageData(image, 0, 0);\n                    data = pixels2DContext.getImageData(0, 0, width, height).data;\n                }\n                else {\n                    throw new Error('Can not access image data');\n                }\n            }\n            else {\n                data = image.data;\n            }\n        }\n        else if (isImageBitmap) {\n            // ImageBitmap - image object - format must be provided by user\n            if (options === undefined) {\n                throw new Error('Please provide image config with format for Imagebitmap');\n            }\n            if (options.bitmapFormat !== undefined) {\n                throw new Error('Image input config format must be defined for ImageBitmap');\n            }\n            const pixels2DContext = document.createElement('canvas').getContext('2d');\n            if (pixels2DContext != null) {\n                const height = image.height;\n                const width = image.width;\n                pixels2DContext.drawImage(image, 0, 0, width, height);\n                data = pixels2DContext.getImageData(0, 0, width, height).data;\n                if (options !== undefined) {\n                    // using square brackets to avoid TS error - type 'never'\n                    if (options.height !== undefined && options.height !== height) {\n                        throw new Error('Image input config height doesn\\'t match ImageBitmap height');\n                    }\n                    else {\n                        tensorConfig.height = height;\n                    }\n                    // using square brackets to avoid TS error - type 'never'\n                    if (options.width !== undefined && options.width !== width) {\n                        throw new Error('Image input config width doesn\\'t match ImageBitmap width');\n                    }\n                    else {\n                        tensorConfig.width = width;\n                    }\n                }\n                else {\n                    tensorConfig.height = height;\n                    tensorConfig.width = width;\n                }\n                return Tensor.bufferToTensor(data, tensorConfig);\n            }\n            else {\n                throw new Error('Can not access image data');\n            }\n        }\n        else if (isURL) {\n            return new Promise((resolve, reject) => {\n                const canvas = document.createElement('canvas');\n                const context = canvas.getContext('2d');\n                if (!image || !context) {\n                    return reject();\n                }\n                const newImage = new Image();\n                newImage.crossOrigin = 'Anonymous';\n                newImage.src = image;\n                newImage.onload = () => {\n                    canvas.width = newImage.width;\n                    canvas.height = newImage.height;\n                    context.drawImage(newImage, 0, 0, canvas.width, canvas.height);\n                    const img = context.getImageData(0, 0, canvas.width, canvas.height);\n                    if (options !== undefined) {\n                        // using square brackets to avoid TS error - type 'never'\n                        if (options.height !== undefined && options.height !== canvas.height) {\n                            throw new Error('Image input config height doesn\\'t match ImageBitmap height');\n                        }\n                        else {\n                            tensorConfig.height = canvas.height;\n                        }\n                        // using square brackets to avoid TS error - type 'never'\n                        if (options.width !== undefined && options.width !== canvas.width) {\n                            throw new Error('Image input config width doesn\\'t match ImageBitmap width');\n                        }\n                        else {\n                            tensorConfig.width = canvas.width;\n                        }\n                    }\n                    else {\n                        tensorConfig.height = canvas.height;\n                        tensorConfig.width = canvas.width;\n                    }\n                    resolve(Tensor.bufferToTensor(img.data, tensorConfig));\n                };\n            });\n        }\n        else {\n            throw new Error('Input data provided is not supported - aborted tensor creation');\n        }\n        if (data !== undefined) {\n            return Tensor.bufferToTensor(data, tensorConfig);\n        }\n        else {\n            throw new Error('Input data provided is not supported - aborted tensor creation');\n        }\n    }\n    toImageData(options) {\n        var _a, _b;\n        const pixels2DContext = document.createElement('canvas').getContext('2d');\n        let image;\n        if (pixels2DContext != null) {\n            // Default values for height and width & format\n            const width = this.dims[3];\n            const height = this.dims[2];\n            const channels = this.dims[1];\n            const inputformat = options !== undefined ? (options.format !== undefined ? options.format : 'RGB') : 'RGB';\n            const normMean = options !== undefined ? (((_a = options.norm) === null || _a === void 0 ? void 0 : _a.mean) !== undefined ? options.norm.mean : 255) : 255;\n            const normBias = options !== undefined ? (((_b = options.norm) === null || _b === void 0 ? void 0 : _b.bias) !== undefined ? options.norm.bias : 0) : 0;\n            const offset = height * width;\n            if (options !== undefined) {\n                if (options.height !== undefined && options.height !== height) {\n                    throw new Error('Image output config height doesn\\'t match tensor height');\n                }\n                if (options.width !== undefined && options.width !== width) {\n                    throw new Error('Image output config width doesn\\'t match tensor width');\n                }\n                if (options.format !== undefined && (channels === 4 && options.format !== 'RGBA') ||\n                    (channels === 3 && (options.format !== 'RGB' && options.format !== 'BGR'))) {\n                    throw new Error('Tensor format doesn\\'t match input tensor dims');\n                }\n            }\n            // Default pointer assignments\n            const step = 4;\n            let rImagePointer = 0, gImagePointer = 1, bImagePointer = 2, aImagePointer = 3;\n            let rTensorPointer = 0, gTensorPointer = offset, bTensorPointer = offset * 2, aTensorPointer = -1;\n            // Updating the pointer assignments based on the input image format\n            if (inputformat === 'RGBA') {\n                rTensorPointer = 0;\n                gTensorPointer = offset;\n                bTensorPointer = offset * 2;\n                aTensorPointer = offset * 3;\n            }\n            else if (inputformat === 'RGB') {\n                rTensorPointer = 0;\n                gTensorPointer = offset;\n                bTensorPointer = offset * 2;\n            }\n            else if (inputformat === 'RBG') {\n                rTensorPointer = 0;\n                bTensorPointer = offset;\n                gTensorPointer = offset * 2;\n            }\n            image = pixels2DContext.createImageData(width, height);\n            for (let i = 0; i < height * width; rImagePointer += step, gImagePointer += step, bImagePointer += step, aImagePointer += step, i++) {\n                image.data[rImagePointer] = (this.data[rTensorPointer++] - normBias) * normMean; // R value\n                image.data[gImagePointer] = (this.data[gTensorPointer++] - normBias) * normMean; // G value\n                image.data[bImagePointer] = (this.data[bTensorPointer++] - normBias) * normMean; // B value\n                image.data[aImagePointer] =\n                    aTensorPointer === -1 ? 255 : (this.data[aTensorPointer++] - normBias) * normMean; // A value\n            }\n        }\n        else {\n            throw new Error('Can not access image data');\n        }\n        return image;\n    }\n    // #endregion\n    // #region tensor utilities\n    reshape(dims) {\n        return new Tensor(this.type, this.data, dims);\n    }\n}\n//# sourceMappingURL=tensor-impl.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/onnxruntime-common/dist/lib/tensor-impl.js?");

/***/ }),

/***/ "./node_modules/onnxruntime-common/dist/lib/tensor.js":
/*!************************************************************!*\
  !*** ./node_modules/onnxruntime-common/dist/lib/tensor.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Tensor: () => (/* binding */ Tensor)\n/* harmony export */ });\n/* harmony import */ var _tensor_impl__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./tensor-impl */ \"./node_modules/onnxruntime-common/dist/lib/tensor-impl.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nconst Tensor = _tensor_impl__WEBPACK_IMPORTED_MODULE_0__.Tensor;\n//# sourceMappingURL=tensor.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/onnxruntime-common/dist/lib/tensor.js?");

/***/ }),

/***/ "./node_modules/onnxruntime-web/dist/ort-web.min.js":
/*!**********************************************************!*\
  !*** ./node_modules/onnxruntime-web/dist/ort-web.min.js ***!
  \**********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/*!\n* ONNX Runtime Web v1.14.0\n* Copyright (c) Microsoft Corporation. All rights reserved.\n* Licensed under the MIT License.\n*/\n!function(t,e){if(true)module.exports=e(__webpack_require__(/*! onnxruntime-common */ \"./node_modules/onnxruntime-common/dist/lib/index.js\"));else { var r, n; }}(self,(__WEBPACK_EXTERNAL_MODULE__1670__=>(()=>{var __webpack_modules__={3474:(t,e,n)=>{var _scriptDir,r=(_scriptDir=(_scriptDir=\"undefined\"!=typeof document&&document.currentScript?document.currentScript.src:void 0)||\"/index.js\",function(t){function e(){return $.buffer!=C&&H($.buffer),F}function r(){return $.buffer!=C&&H($.buffer),N}function i(){return $.buffer!=C&&H($.buffer),L}function o(){return $.buffer!=C&&H($.buffer),R}function a(){return $.buffer!=C&&H($.buffer),j}var s,u,c;t=t||{},s||(s=void 0!==t?t:{}),s.ready=new Promise((function(t,e){u=t,c=e}));var l,p,f,d,h,g,b=Object.assign({},s),m=\"./this.program\",y=(t,e)=>{throw e},_=\"object\"==typeof window,v=\"function\"==typeof importScripts,w=\"object\"==typeof process&&\"object\"==typeof process.versions&&\"string\"==typeof process.versions.node,x=s.ENVIRONMENT_IS_PTHREAD||!1,T=\"\";function S(t){return s.locateFile?s.locateFile(t,T):T+t}if(w){let e;T=v?n(908).dirname(T)+\"/\":\"//\",g=()=>{h||(d=n(1384),h=n(908))},l=function(t,e){return g(),t=h.normalize(t),d.readFileSync(t,e?void 0:\"utf8\")},f=t=>((t=l(t,!0)).buffer||(t=new Uint8Array(t)),t),p=(t,e,n)=>{g(),t=h.normalize(t),d.readFile(t,(function(t,r){t?n(t):e(r.buffer)}))},1<process.argv.length&&(m=process.argv[1].replace(/\\\\/g,\"/\")),process.argv.slice(2),process.on(\"uncaughtException\",(function(t){if(!(t instanceof ut))throw t})),process.on(\"unhandledRejection\",(function(t){throw t})),y=(t,e)=>{if(J())throw process.exitCode=t,e;e instanceof ut||P(\"exiting due to exception: \"+e),process.exit(t)},s.inspect=function(){return\"[Emscripten Module object]\"};try{e=n(9925)}catch(t){throw console.error('The \"worker_threads\" module is not supported in this node.js build - perhaps a newer version is needed?'),t}n.g.Worker=e.Worker}else(_||v)&&(v?T=self.location.href:\"undefined\"!=typeof document&&document.currentScript&&(T=document.currentScript.src),_scriptDir&&(T=_scriptDir),T=0!==T.indexOf(\"blob:\")?T.substr(0,T.replace(/[?#].*/,\"\").lastIndexOf(\"/\")+1):\"\",w||(l=t=>{var e=new XMLHttpRequest;return e.open(\"GET\",t,!1),e.send(null),e.responseText},v&&(f=t=>{var e=new XMLHttpRequest;return e.open(\"GET\",t,!1),e.responseType=\"arraybuffer\",e.send(null),new Uint8Array(e.response)}),p=(t,e,n)=>{var r=new XMLHttpRequest;r.open(\"GET\",t,!0),r.responseType=\"arraybuffer\",r.onload=()=>{200==r.status||0==r.status&&r.response?e(r.response):n()},r.onerror=n,r.send(null)}));w&&\"undefined\"==typeof performance&&(n.g.performance=n(6953).performance);var O=console.log.bind(console),A=console.warn.bind(console);w&&(g(),O=t=>d.writeSync(1,t+\"\\n\"),A=t=>d.writeSync(2,t+\"\\n\"));var E,I=s.print||O,P=s.printErr||A;Object.assign(s,b),b=null,s.thisProgram&&(m=s.thisProgram),s.quit&&(y=s.quit),s.wasmBinary&&(E=s.wasmBinary);var D=s.noExitRuntime||!1;\"object\"!=typeof WebAssembly&&it(\"no native wasm support detected\");var $,k,C,F,N,L,R,j,M=!1,U=\"undefined\"!=typeof TextDecoder?new TextDecoder(\"utf8\"):void 0;function V(t,e,n){var r=(e>>>=0)+n;for(n=e;t[n]&&!(n>=r);)++n;if(16<n-e&&t.buffer&&U)return U.decode(t.buffer instanceof SharedArrayBuffer?t.slice(e,n):t.subarray(e,n));for(r=\"\";e<n;){var i=t[e++];if(128&i){var o=63&t[e++];if(192==(224&i))r+=String.fromCharCode((31&i)<<6|o);else{var a=63&t[e++];65536>(i=224==(240&i)?(15&i)<<12|o<<6|a:(7&i)<<18|o<<12|a<<6|63&t[e++])?r+=String.fromCharCode(i):(i-=65536,r+=String.fromCharCode(55296|i>>10,56320|1023&i))}}else r+=String.fromCharCode(i)}return r}function B(t,e){return(t>>>=0)?V(r(),t,e):\"\"}function z(t,e,n,r){if(!(0<r))return 0;var i=n>>>=0;r=n+r-1;for(var o=0;o<t.length;++o){var a=t.charCodeAt(o);if(55296<=a&&57343>=a&&(a=65536+((1023&a)<<10)|1023&t.charCodeAt(++o)),127>=a){if(n>=r)break;e[n++>>>0]=a}else{if(2047>=a){if(n+1>=r)break;e[n++>>>0]=192|a>>6}else{if(65535>=a){if(n+2>=r)break;e[n++>>>0]=224|a>>12}else{if(n+3>=r)break;e[n++>>>0]=240|a>>18,e[n++>>>0]=128|a>>12&63}e[n++>>>0]=128|a>>6&63}e[n++>>>0]=128|63&a}}return e[n>>>0]=0,n-i}function G(t){for(var e=0,n=0;n<t.length;++n){var r=t.charCodeAt(n);127>=r?e++:2047>=r?e+=2:55296<=r&&57343>=r?(e+=4,++n):e+=3}return e}function H(t){C=t,s.HEAP8=F=new Int8Array(t),s.HEAP16=new Int16Array(t),s.HEAP32=L=new Int32Array(t),s.HEAPU8=N=new Uint8Array(t),s.HEAPU16=new Uint16Array(t),s.HEAPU32=R=new Uint32Array(t),s.HEAPF32=new Float32Array(t),s.HEAPF64=j=new Float64Array(t)}x&&(C=s.buffer);var W=s.INITIAL_MEMORY||16777216;if(x)$=s.wasmMemory,C=s.buffer;else if(s.wasmMemory)$=s.wasmMemory;else if(!(($=new WebAssembly.Memory({initial:W/65536,maximum:65536,shared:!0})).buffer instanceof SharedArrayBuffer))throw P(\"requested a shared WebAssembly.Memory but the returned buffer is not a SharedArrayBuffer, indicating that while the browser has SharedArrayBuffer it does not have WebAssembly threads support - you may need to set a flag\"),w&&console.log(\"(on node you may need: --experimental-wasm-threads --experimental-wasm-bulk-memory and also use a recent version)\"),Error(\"bad memory\");$&&(C=$.buffer),W=C.byteLength,H(C);var q,X=[],Y=[],K=[],Z=[];function J(){return D||!1}function Q(){var t=s.preRun.shift();X.unshift(t)}var tt,et=0,nt=null,rt=null;function it(t){throw x?postMessage({cmd:\"onAbort\",arg:t}):s.onAbort&&s.onAbort(t),P(t=\"Aborted(\"+t+\")\"),M=!0,t=new WebAssembly.RuntimeError(t+\". Build with -sASSERTIONS for more info.\"),c(t),t}function ot(){return tt.startsWith(\"data:application/octet-stream;base64,\")}function at(){var t=tt;try{if(t==tt&&E)return new Uint8Array(E);if(f)return f(t);throw\"both async and sync fetching of the wasm failed\"}catch(t){it(t)}}tt=\"ort-wasm-threaded.wasm\",ot()||(tt=S(tt));var st={};function ut(t){this.name=\"ExitStatus\",this.message=\"Program terminated with exit(\"+t+\")\",this.status=t}function ct(t){(t=dt.Vb[t])||it(),dt.mc(t)}function lt(t){var e=dt.Cc();if(!e)return 6;dt.ac.push(e),dt.Vb[t.Ub]=e,e.Ub=t.Ub;var n={cmd:\"run\",start_routine:t.Ic,arg:t.zc,pthread_ptr:t.Ub};return e.$b=()=>{n.time=performance.now(),e.postMessage(n,t.Nc)},e.loaded&&(e.$b(),delete e.$b),0}function pt(t){if(x)return qt(1,1,t);J()||(dt.oc(),s.onExit&&s.onExit(t),M=!0),y(t,new ut(t))}function ft(t,e){if(!e&&x)throw bt(t),\"unwind\";J()||x||(me(),ht(K),be(0),re[1].length&&ie(1,10),re[2].length&&ie(2,10),dt.oc()),pt(t)}var dt={Yb:[],ac:[],qc:[],Vb:{},fc:function(){x&&dt.Ec()},Pc:function(){},Ec:function(){dt.receiveObjectTransfer=dt.Gc,dt.threadInitTLS=dt.pc,dt.setExitStatus=dt.nc,D=!1},nc:function(){},oc:function(){for(var t of Object.values(dt.Vb))dt.mc(t);for(t of dt.Yb)t.terminate();dt.Yb=[]},mc:function(t){var e=t.Ub;delete dt.Vb[e],dt.Yb.push(t),dt.ac.splice(dt.ac.indexOf(t),1),t.Ub=0,xe(e)},Gc:function(){},pc:function(){dt.qc.forEach((t=>t()))},Fc:function(t,e){t.onmessage=n=>{var r=(n=n.data).cmd;if(t.Ub&&(dt.Bc=t.Ub),n.targetThread&&n.targetThread!=de()){var i=dt.Vb[n.Qc];i?i.postMessage(n,n.transferList):P('Internal error! Worker sent a message \"'+r+'\" to target pthread '+n.targetThread+\", but that thread no longer exists!\")}else\"processProxyingQueue\"===r?Vt(n.queue):\"spawnThread\"===r?lt(n):\"cleanupThread\"===r?ct(n.thread):\"killThread\"===r?(n=n.thread,r=dt.Vb[n],delete dt.Vb[n],r.terminate(),xe(n),dt.ac.splice(dt.ac.indexOf(r),1),r.Ub=0):\"cancelThread\"===r?dt.Vb[n.thread].postMessage({cmd:\"cancel\"}):\"loaded\"===r?(t.loaded=!0,e&&e(t),t.$b&&(t.$b(),delete t.$b)):\"print\"===r?I(\"Thread \"+n.threadId+\": \"+n.text):\"printErr\"===r?P(\"Thread \"+n.threadId+\": \"+n.text):\"alert\"===r?alert(\"Thread \"+n.threadId+\": \"+n.text):\"setimmediate\"===n.target?t.postMessage(n):\"onAbort\"===r?s.onAbort&&s.onAbort(n.arg):r&&P(\"worker sent an unknown command \"+r);dt.Bc=void 0},t.onerror=t=>{throw P(\"worker sent an error! \"+t.filename+\":\"+t.lineno+\": \"+t.message),t},w&&(t.on(\"message\",(function(e){t.onmessage({data:e})})),t.on(\"error\",(function(e){t.onerror(e)})),t.on(\"detachedExit\",(function(){}))),t.postMessage({cmd:\"load\",urlOrBlob:s.mainScriptUrlOrBlob||_scriptDir,wasmMemory:$,wasmModule:k})},yc:function(){var t=S(\"ort-wasm-threaded.worker.js\");dt.Yb.push(new Worker(t))},Cc:function(){return 0==dt.Yb.length&&(dt.yc(),dt.Fc(dt.Yb[0])),dt.Yb.pop()}};function ht(t){for(;0<t.length;)t.shift()(s)}function gt(t){var e=Ae();return t=t(),Ee(e),t}function bt(t){if(x)return qt(2,0,t);try{ft(t)}catch(t){t instanceof ut||\"unwind\"==t||y(1,t)}}s.PThread=dt,s.establishStackSpace=function(){var t=de(),e=i()[t+44>>2>>>0];t=i()[t+48>>2>>>0],Oe(e,e-t),Ee(e)};var mt=[];function yt(t){var e=mt[t];return e||(t>=mt.length&&(mt.length=t+1),mt[t]=e=q.get(t)),e}s.invokeEntryPoint=function(t,e){t=yt(t)(e),J()?dt.nc(t):Te(t)};var _t,vt,wt=[],xt=0,Tt=0;function St(t){this.Zb=t,this.Sb=t-24,this.xc=function(t){o()[this.Sb+4>>2>>>0]=t},this.bc=function(){return o()[this.Sb+4>>2>>>0]},this.wc=function(t){o()[this.Sb+8>>2>>>0]=t},this.Dc=function(){return o()[this.Sb+8>>2>>>0]},this.rc=function(){i()[this.Sb>>2>>>0]=0},this.hc=function(t){t=t?1:0,e()[this.Sb+12>>0>>>0]=t},this.uc=function(){return 0!=e()[this.Sb+12>>0>>>0]},this.ic=function(t){t=t?1:0,e()[this.Sb+13>>0>>>0]=t},this.kc=function(){return 0!=e()[this.Sb+13>>0>>>0]},this.fc=function(t,e){this.cc(0),this.xc(t),this.wc(e),this.rc(),this.hc(!1),this.ic(!1)},this.sc=function(){Atomics.add(i(),this.Sb>>2,1)},this.Hc=function(){return 1===Atomics.sub(i(),this.Sb>>2,1)},this.cc=function(t){o()[this.Sb+16>>2>>>0]=t},this.tc=function(){return o()[this.Sb+16>>2>>>0]},this.vc=function(){if(De(this.bc()))return o()[this.Zb>>2>>>0];var t=this.tc();return 0!==t?t:this.Zb}}function Ot(t){return ge(new St(t).Sb)}function At(t,e,n,r){return x?qt(3,1,t,e,n,r):Et(t,e,n,r)}function Et(t,e,n,r){if(\"undefined\"==typeof SharedArrayBuffer)return P(\"Current environment does not support SharedArrayBuffer, pthreads are not available!\"),6;var i=[];return x&&0===i.length?At(t,e,n,r):(t={Ic:n,Ub:t,zc:r,Nc:i},x?(t.Oc=\"spawnThread\",postMessage(t,i),0):lt(t))}function It(t,e,n){return x?qt(4,1,t,e,n):0}function Pt(t,e){if(x)return qt(5,1,t,e)}function Dt(t,e){if(x)return qt(6,1,t,e)}function $t(t,e,n){if(x)return qt(7,1,t,e,n)}function kt(t,e,n){return x?qt(8,1,t,e,n):0}function Ct(t,e){if(x)return qt(9,1,t,e)}function Ft(t,e,n){if(x)return qt(10,1,t,e,n)}function Nt(t,e,n,r){if(x)return qt(11,1,t,e,n,r)}function Lt(t,e,n,r){if(x)return qt(12,1,t,e,n,r)}function Rt(t,e,n,r){if(x)return qt(13,1,t,e,n,r)}function jt(t){if(x)return qt(14,1,t)}function Mt(t,e){if(x)return qt(15,1,t,e)}function Ut(t,e,n){if(x)return qt(16,1,t,e,n)}function Vt(t){Atomics.store(i(),t>>2,1),de()&&we(t),Atomics.compareExchange(i(),t>>2,1,0)}function Bt(t){return o()[t>>>2]+4294967296*i()[t+4>>>2]}function zt(t,e,n,r,i,o){return x?qt(17,1,t,e,n,r,i,o):-52}function Gt(t,e,n,r,i,o){if(x)return qt(18,1,t,e,n,r,i,o)}function Ht(t){var n=G(t)+1,r=he(n);return r&&z(t,e(),r,n),r}function Wt(t,e,n){function r(t){return(t=t.toTimeString().match(/\\(([A-Za-z ]+)\\)$/))?t[1]:\"GMT\"}if(x)return qt(19,1,t,e,n);var a=(new Date).getFullYear(),s=new Date(a,0,1),u=new Date(a,6,1);a=s.getTimezoneOffset();var c=u.getTimezoneOffset(),l=Math.max(a,c);i()[t>>2>>>0]=60*l,i()[e>>2>>>0]=Number(a!=c),t=r(s),e=r(u),t=Ht(t),e=Ht(e),c<a?(o()[n>>2>>>0]=t,o()[n+4>>2>>>0]=e):(o()[n>>2>>>0]=e,o()[n+4>>2>>>0]=t)}function qt(t,e){var n=arguments.length-2,r=arguments;return gt((()=>{for(var i=Ie(8*n),o=i>>3,s=0;s<n;s++){var u=r[2+s];a()[o+s>>>0]=u}return ve(t,n,i,e)}))}s.executeNotifiedProxyingQueue=Vt,vt=w?()=>{var t=process.hrtime();return 1e3*t[0]+t[1]/1e6}:x?()=>performance.now()-s.__performance_now_clock_drift:()=>performance.now();var Xt,Yt=[],Kt={};function Zt(){if(!Xt){var t,e={USER:\"web_user\",LOGNAME:\"web_user\",PATH:\"/\",PWD:\"/\",HOME:\"/home/web_user\",LANG:(\"object\"==typeof navigator&&navigator.languages&&navigator.languages[0]||\"C\").replace(\"-\",\"_\")+\".UTF-8\",_:m||\"./this.program\"};for(t in Kt)void 0===Kt[t]?delete e[t]:e[t]=Kt[t];var n=[];for(t in e)n.push(t+\"=\"+e[t]);Xt=n}return Xt}function Jt(t,n){if(x)return qt(20,1,t,n);var r=0;return Zt().forEach((function(i,a){var s=n+r;for(a=o()[t+4*a>>2>>>0]=s,s=0;s<i.length;++s)e()[a++>>0>>>0]=i.charCodeAt(s);e()[a>>0>>>0]=0,r+=i.length+1})),0}function Qt(t,e){if(x)return qt(21,1,t,e);var n=Zt();o()[t>>2>>>0]=n.length;var r=0;return n.forEach((function(t){r+=t.length+1})),o()[e>>2>>>0]=r,0}function te(t){return x?qt(22,1,t):52}function ee(t,e,n,r){return x?qt(23,1,t,e,n,r):52}function ne(t,e,n,r,i){return x?qt(24,1,t,e,n,r,i):70}var re=[null,[],[]];function ie(t,e){var n=re[t];0===e||10===e?((1===t?I:P)(V(n,0)),n.length=0):n.push(e)}function oe(t,e,n,i){if(x)return qt(25,1,t,e,n,i);for(var a=0,s=0;s<n;s++){var u=o()[e>>2>>>0],c=o()[e+4>>2>>>0];e+=8;for(var l=0;l<c;l++)ie(t,r()[u+l>>>0]);a+=c}return o()[i>>2>>>0]=a,0}var ae=0;function se(t){return 0==t%4&&(0!=t%100||0==t%400)}var ue=[31,29,31,30,31,30,31,31,30,31,30,31],ce=[31,28,31,30,31,30,31,31,30,31,30,31];function le(t,n,r,o){function a(t,e,n){for(t=\"number\"==typeof t?t.toString():t||\"\";t.length<e;)t=n[0]+t;return t}function s(t,e){return a(t,e,\"0\")}function u(t,e){function n(t){return 0>t?-1:0<t?1:0}var r;return 0===(r=n(t.getFullYear()-e.getFullYear()))&&0===(r=n(t.getMonth()-e.getMonth()))&&(r=n(t.getDate()-e.getDate())),r}function c(t){switch(t.getDay()){case 0:return new Date(t.getFullYear()-1,11,29);case 1:return t;case 2:return new Date(t.getFullYear(),0,3);case 3:return new Date(t.getFullYear(),0,2);case 4:return new Date(t.getFullYear(),0,1);case 5:return new Date(t.getFullYear()-1,11,31);case 6:return new Date(t.getFullYear()-1,11,30)}}function l(t){var e=t.Wb;for(t=new Date(new Date(t.Xb+1900,0,1).getTime());0<e;){var n=t.getMonth(),r=(se(t.getFullYear())?ue:ce)[n];if(!(e>r-t.getDate())){t.setDate(t.getDate()+e);break}e-=r-t.getDate()+1,t.setDate(1),11>n?t.setMonth(n+1):(t.setMonth(0),t.setFullYear(t.getFullYear()+1))}return n=new Date(t.getFullYear()+1,0,4),e=c(new Date(t.getFullYear(),0,4)),n=c(n),0>=u(e,t)?0>=u(n,t)?t.getFullYear()+1:t.getFullYear():t.getFullYear()-1}var p=i()[o+40>>2>>>0];for(var f in o={Lc:i()[o>>2>>>0],Kc:i()[o+4>>2>>>0],dc:i()[o+8>>2>>>0],jc:i()[o+12>>2>>>0],ec:i()[o+16>>2>>>0],Xb:i()[o+20>>2>>>0],Tb:i()[o+24>>2>>>0],Wb:i()[o+28>>2>>>0],Rc:i()[o+32>>2>>>0],Jc:i()[o+36>>2>>>0],Mc:p?B(p):\"\"},r=B(r),p={\"%c\":\"%a %b %d %H:%M:%S %Y\",\"%D\":\"%m/%d/%y\",\"%F\":\"%Y-%m-%d\",\"%h\":\"%b\",\"%r\":\"%I:%M:%S %p\",\"%R\":\"%H:%M\",\"%T\":\"%H:%M:%S\",\"%x\":\"%m/%d/%y\",\"%X\":\"%H:%M:%S\",\"%Ec\":\"%c\",\"%EC\":\"%C\",\"%Ex\":\"%m/%d/%y\",\"%EX\":\"%H:%M:%S\",\"%Ey\":\"%y\",\"%EY\":\"%Y\",\"%Od\":\"%d\",\"%Oe\":\"%e\",\"%OH\":\"%H\",\"%OI\":\"%I\",\"%Om\":\"%m\",\"%OM\":\"%M\",\"%OS\":\"%S\",\"%Ou\":\"%u\",\"%OU\":\"%U\",\"%OV\":\"%V\",\"%Ow\":\"%w\",\"%OW\":\"%W\",\"%Oy\":\"%y\"})r=r.replace(new RegExp(f,\"g\"),p[f]);var d=\"Sunday Monday Tuesday Wednesday Thursday Friday Saturday\".split(\" \"),h=\"January February March April May June July August September October November December\".split(\" \");for(f in p={\"%a\":function(t){return d[t.Tb].substring(0,3)},\"%A\":function(t){return d[t.Tb]},\"%b\":function(t){return h[t.ec].substring(0,3)},\"%B\":function(t){return h[t.ec]},\"%C\":function(t){return s((t.Xb+1900)/100|0,2)},\"%d\":function(t){return s(t.jc,2)},\"%e\":function(t){return a(t.jc,2,\" \")},\"%g\":function(t){return l(t).toString().substring(2)},\"%G\":function(t){return l(t)},\"%H\":function(t){return s(t.dc,2)},\"%I\":function(t){return 0==(t=t.dc)?t=12:12<t&&(t-=12),s(t,2)},\"%j\":function(t){for(var e=0,n=0;n<=t.ec-1;e+=(se(t.Xb+1900)?ue:ce)[n++]);return s(t.jc+e,3)},\"%m\":function(t){return s(t.ec+1,2)},\"%M\":function(t){return s(t.Kc,2)},\"%n\":function(){return\"\\n\"},\"%p\":function(t){return 0<=t.dc&&12>t.dc?\"AM\":\"PM\"},\"%S\":function(t){return s(t.Lc,2)},\"%t\":function(){return\"\\t\"},\"%u\":function(t){return t.Tb||7},\"%U\":function(t){return s(Math.floor((t.Wb+7-t.Tb)/7),2)},\"%V\":function(t){var e=Math.floor((t.Wb+7-(t.Tb+6)%7)/7);if(2>=(t.Tb+371-t.Wb-2)%7&&e++,e)53==e&&(4==(n=(t.Tb+371-t.Wb)%7)||3==n&&se(t.Xb)||(e=1));else{e=52;var n=(t.Tb+7-t.Wb-1)%7;(4==n||5==n&&se(t.Xb%400-1))&&e++}return s(e,2)},\"%w\":function(t){return t.Tb},\"%W\":function(t){return s(Math.floor((t.Wb+7-(t.Tb+6)%7)/7),2)},\"%y\":function(t){return(t.Xb+1900).toString().substring(2)},\"%Y\":function(t){return t.Xb+1900},\"%z\":function(t){var e=0<=(t=t.Jc);return t=Math.abs(t)/60,(e?\"+\":\"-\")+String(\"0000\"+(t/60*100+t%60)).slice(-4)},\"%Z\":function(t){return t.Mc},\"%%\":function(){return\"%\"}},r=r.replace(/%%/g,\"\\0\\0\"),p)r.includes(f)&&(r=r.replace(new RegExp(f,\"g\"),p[f](o)));return f=function(t){var e=Array(G(t)+1);return z(t,e,0,e.length),e}(r=r.replace(/\\0\\0/g,\"%\")),f.length>n?0:(function(t,n){e().set(t,n>>>0)}(f,t),f.length-1)}dt.fc();var pe=[null,pt,bt,At,It,Pt,Dt,$t,kt,Ct,Ft,Nt,Lt,Rt,jt,Mt,Ut,zt,Gt,Wt,Jt,Qt,te,ee,ne,oe],fe={b:function(t){return he(t+24)+24},n:function(t){return(t=new St(t)).uc()||(t.hc(!0),xt--),t.ic(!1),wt.push(t),t.sc(),t.vc()},ma:function(t){throw P(\"Unexpected exception thrown, this is not properly supported - aborting\"),M=!0,t},x:function(){Se(0);var t=wt.pop();if(t.Hc()&&!t.kc()){var e=t.Dc();e&&yt(e)(t.Zb),Ot(t.Zb)}Tt=0},e:function(){var t=Tt;if(!t)return ae=0;var e=new St(t);e.cc(t);var n=e.bc();if(!n)return ae=0,t;for(var r=Array.prototype.slice.call(arguments),i=0;i<r.length;i++){var o=r[i];if(0===o||o===n)break;if(Pe(o,n,e.Sb+16))return ae=o,t}return ae=n,t},l:function(){var t=Tt;if(!t)return ae=0;var e=new St(t);e.cc(t);var n=e.bc();if(!n)return ae=0,t;for(var r=Array.prototype.slice.call(arguments),i=0;i<r.length;i++){var o=r[i];if(0===o||o===n)break;if(Pe(o,n,e.Sb+16))return ae=o,t}return ae=n,t},h:function(){var t=Tt;if(!t)return ae=0;var e=new St(t);e.cc(t);var n=e.bc();if(!n)return ae=0,t;for(var r=Array.prototype.slice.call(arguments),i=0;i<r.length;i++){var o=r[i];if(0===o||o===n)break;if(Pe(o,n,e.Sb+16))return ae=o,t}return ae=n,t},t:Ot,M:function(){var t=wt.pop();t||it(\"no exception to throw\");var e=t.Zb;throw t.kc()||(wt.push(t),t.ic(!0),t.hc(!1),xt++),Tt=e,e},c:function(t,e,n){throw new St(t).fc(e,n),Tt=t,xt++,t},pa:function(){return xt},Fa:function(t){ye(t,!v,1,!_),dt.pc()},T:function(t){x?postMessage({cmd:\"cleanupThread\",thread:t}):ct(t)},xa:Et,j:function(t){throw Tt||(Tt=t),t},H:It,Ma:Pt,ua:Dt,wa:$t,oa:kt,Ka:Ct,Ca:Ft,Ja:Nt,V:Lt,va:Rt,sa:jt,La:Mt,ta:Ut,Ta:function(){},X:function(){it(\"To use dlopen, you need enable dynamic linking, see https://github.com/emscripten-core/emscripten/wiki/Linking\")},Ua:function(){it(\"To use dlopen, you need enable dynamic linking, see https://github.com/emscripten-core/emscripten/wiki/Linking\")},W:function(){return Date.now()},ya:function(){return 2097152},Oa:function(){return!0},za:function(t,e,n,r){if(t==e)setTimeout((()=>Vt(r)));else if(x)postMessage({targetThread:t,cmd:\"processProxyingQueue\",queue:r});else{if(!(t=dt.Vb[t]))return;t.postMessage({cmd:\"processProxyingQueue\",queue:r})}return 1},Ea:function(){return-1},Pa:function(t,e){t=new Date(1e3*Bt(t)),i()[e>>2>>>0]=t.getUTCSeconds(),i()[e+4>>2>>>0]=t.getUTCMinutes(),i()[e+8>>2>>>0]=t.getUTCHours(),i()[e+12>>2>>>0]=t.getUTCDate(),i()[e+16>>2>>>0]=t.getUTCMonth(),i()[e+20>>2>>>0]=t.getUTCFullYear()-1900,i()[e+24>>2>>>0]=t.getUTCDay(),t=(t.getTime()-Date.UTC(t.getUTCFullYear(),0,1,0,0,0,0))/864e5|0,i()[e+28>>2>>>0]=t},Qa:function(t,e){t=new Date(1e3*Bt(t)),i()[e>>2>>>0]=t.getSeconds(),i()[e+4>>2>>>0]=t.getMinutes(),i()[e+8>>2>>>0]=t.getHours(),i()[e+12>>2>>>0]=t.getDate(),i()[e+16>>2>>>0]=t.getMonth(),i()[e+20>>2>>>0]=t.getFullYear()-1900,i()[e+24>>2>>>0]=t.getDay();var n=new Date(t.getFullYear(),0,1),r=(t.getTime()-n.getTime())/864e5|0;i()[e+28>>2>>>0]=r,i()[e+36>>2>>>0]=-60*t.getTimezoneOffset(),r=new Date(t.getFullYear(),6,1).getTimezoneOffset(),t=0|(r!=(n=n.getTimezoneOffset())&&t.getTimezoneOffset()==Math.min(n,r)),i()[e+32>>2>>>0]=t},Ra:function(t){var e=new Date(i()[t+20>>2>>>0]+1900,i()[t+16>>2>>>0],i()[t+12>>2>>>0],i()[t+8>>2>>>0],i()[t+4>>2>>>0],i()[t>>2>>>0],0),n=i()[t+32>>2>>>0],r=e.getTimezoneOffset(),o=new Date(e.getFullYear(),0,1),a=new Date(e.getFullYear(),6,1).getTimezoneOffset(),s=o.getTimezoneOffset(),u=Math.min(s,a);return 0>n?i()[t+32>>2>>>0]=Number(a!=s&&u==r):0<n!=(u==r)&&(a=Math.max(s,a),e.setTime(e.getTime()+6e4*((0<n?u:a)-r))),i()[t+24>>2>>>0]=e.getDay(),n=(e.getTime()-o.getTime())/864e5|0,i()[t+28>>2>>>0]=n,i()[t>>2>>>0]=e.getSeconds(),i()[t+4>>2>>>0]=e.getMinutes(),i()[t+8>>2>>>0]=e.getHours(),i()[t+12>>2>>>0]=e.getDate(),i()[t+16>>2>>>0]=e.getMonth(),e.getTime()/1e3|0},Aa:zt,Ba:Gt,Sa:function t(e,n,r){t.Ac||(t.Ac=!0,Wt(e,n,r))},y:function(){it(\"\")},U:function(){if(!w&&!v){var t=\"Blocking on the main thread is very dangerous, see https://emscripten.org/docs/porting/pthreads.html#blocking-on-the-main-browser-thread\";_t||(_t={}),_t[t]||(_t[t]=1,w&&(t=\"warning: \"+t),P(t))}},ra:function(){return 4294901760},B:vt,Ia:function(t,e,n){r().copyWithin(t>>>0,e>>>0,e+n>>>0)},F:function(){return w?n(3993).cpus().length:navigator.hardwareConcurrency},Da:function(t,e,n){Yt.length=e,n>>=3;for(var r=0;r<e;r++)Yt[r]=a()[n+r>>>0];return(0>t?st[-t-1]:pe[t]).apply(null,Yt)},qa:function(t){var e=r().length;if((t>>>=0)<=e||4294901760<t)return!1;for(var n=1;4>=n;n*=2){var i=e*(1+.2/n);i=Math.min(i,t+100663296);var o=Math;i=Math.max(t,i),o=o.min.call(o,4294901760,i+(65536-i%65536)%65536);t:{try{$.grow(o-C.byteLength+65535>>>16),H($.buffer);var a=1;break t}catch(t){}a=void 0}if(a)return!0}return!1},Na:function(){throw\"unwind\"},Ga:Jt,Ha:Qt,J:ft,I:te,S:ee,ga:ne,R:oe,d:function(){return ae},na:function t(r,i){t.lc||(t.lc=function(){if(\"object\"==typeof crypto&&\"function\"==typeof crypto.getRandomValues){var t=new Uint8Array(1);return()=>(crypto.getRandomValues(t),t[0])}if(w)try{var e=n(Object(function(){var t=new Error(\"Cannot find module 'crypto'\");throw t.code=\"MODULE_NOT_FOUND\",t}()));return()=>e.randomBytes(1)[0]}catch(t){}return()=>it(\"randomDevice\")}());for(var o=0;o<i;o++)e()[r+o>>0>>>0]=t.lc();return 0},ia:function(t,e,n){var r=Ae();try{return yt(t)(e,n)}catch(t){if(Ee(r),t!==t+0)throw t;Se(1,0)}},ja:function(t,e,n){var r=Ae();try{return yt(t)(e,n)}catch(t){if(Ee(r),t!==t+0)throw t;Se(1,0)}},K:function(t){var e=Ae();try{return yt(t)()}catch(t){if(Ee(e),t!==t+0)throw t;Se(1,0)}},f:function(t,e){var n=Ae();try{return yt(t)(e)}catch(t){if(Ee(n),t!==t+0)throw t;Se(1,0)}},P:function(t,e,n){var r=Ae();try{return yt(t)(e,n)}catch(t){if(Ee(r),t!==t+0)throw t;Se(1,0)}},Q:function(t,e,n){var r=Ae();try{return yt(t)(e,n)}catch(t){if(Ee(r),t!==t+0)throw t;Se(1,0)}},k:function(t,e,n){var r=Ae();try{return yt(t)(e,n)}catch(t){if(Ee(r),t!==t+0)throw t;Se(1,0)}},p:function(t,e,n,r){var i=Ae();try{return yt(t)(e,n,r)}catch(t){if(Ee(i),t!==t+0)throw t;Se(1,0)}},q:function(t,e,n,r,i){var o=Ae();try{return yt(t)(e,n,r,i)}catch(t){if(Ee(o),t!==t+0)throw t;Se(1,0)}},N:function(t,e,n,r,i,o){var a=Ae();try{return yt(t)(e,n,r,i,o)}catch(t){if(Ee(a),t!==t+0)throw t;Se(1,0)}},s:function(t,e,n,r,i,o){var a=Ae();try{return yt(t)(e,n,r,i,o)}catch(t){if(Ee(a),t!==t+0)throw t;Se(1,0)}},w:function(t,e,n,r,i,o,a){var s=Ae();try{return yt(t)(e,n,r,i,o,a)}catch(t){if(Ee(s),t!==t+0)throw t;Se(1,0)}},L:function(t,e,n,r,i,o,a,s){var u=Ae();try{return yt(t)(e,n,r,i,o,a,s)}catch(t){if(Ee(u),t!==t+0)throw t;Se(1,0)}},E:function(t,e,n,r,i,o,a,s,u,c,l,p){var f=Ae();try{return yt(t)(e,n,r,i,o,a,s,u,c,l,p)}catch(t){if(Ee(f),t!==t+0)throw t;Se(1,0)}},aa:function(t,e,n,r,i,o,a,s){var u=Ae();try{return Me(t,e,n,r,i,o,a,s)}catch(t){if(Ee(u),t!==t+0)throw t;Se(1,0)}},_:function(t,e,n,r,i,o,a){var s=Ae();try{return ke(t,e,n,r,i,o,a)}catch(t){if(Ee(s),t!==t+0)throw t;Se(1,0)}},Z:function(t,e,n,r,i){var o=Ae();try{return Ue(t,e,n,r,i)}catch(t){if(Ee(o),t!==t+0)throw t;Se(1,0)}},ca:function(t,e,n,r){var i=Ae();try{return Re(t,e,n,r)}catch(t){if(Ee(i),t!==t+0)throw t;Se(1,0)}},$:function(t){var e=Ae();try{return $e(t)}catch(t){if(Ee(e),t!==t+0)throw t;Se(1,0)}},ba:function(t,e){var n=Ae();try{return je(t,e)}catch(t){if(Ee(n),t!==t+0)throw t;Se(1,0)}},Y:function(t,e,n){var r=Ae();try{return Ce(t,e,n)}catch(t){if(Ee(r),t!==t+0)throw t;Se(1,0)}},g:function(t){var e=Ae();try{yt(t)()}catch(t){if(Ee(e),t!==t+0)throw t;Se(1,0)}},r:function(t,e){var n=Ae();try{yt(t)(e)}catch(t){if(Ee(n),t!==t+0)throw t;Se(1,0)}},i:function(t,e,n){var r=Ae();try{yt(t)(e,n)}catch(t){if(Ee(r),t!==t+0)throw t;Se(1,0)}},ha:function(t,e,n,r){var i=Ae();try{yt(t)(e,n,r)}catch(t){if(Ee(i),t!==t+0)throw t;Se(1,0)}},m:function(t,e,n,r){var i=Ae();try{yt(t)(e,n,r)}catch(t){if(Ee(i),t!==t+0)throw t;Se(1,0)}},v:function(t,e,n,r,i){var o=Ae();try{yt(t)(e,n,r,i)}catch(t){if(Ee(o),t!==t+0)throw t;Se(1,0)}},u:function(t,e,n,r,i,o){var a=Ae();try{yt(t)(e,n,r,i,o)}catch(t){if(Ee(a),t!==t+0)throw t;Se(1,0)}},O:function(t,e,n,r,i,o,a){var s=Ae();try{yt(t)(e,n,r,i,o,a)}catch(t){if(Ee(s),t!==t+0)throw t;Se(1,0)}},A:function(t,e,n,r,i,o,a,s){var u=Ae();try{yt(t)(e,n,r,i,o,a,s)}catch(t){if(Ee(u),t!==t+0)throw t;Se(1,0)}},ka:function(t,e,n,r,i,o,a,s,u){var c=Ae();try{yt(t)(e,n,r,i,o,a,s,u)}catch(t){if(Ee(c),t!==t+0)throw t;Se(1,0)}},C:function(t,e,n,r,i,o,a,s,u,c,l){var p=Ae();try{yt(t)(e,n,r,i,o,a,s,u,c,l)}catch(t){if(Ee(p),t!==t+0)throw t;Se(1,0)}},D:function(t,e,n,r,i,o,a,s,u,c,l,p,f,d,h,g){var b=Ae();try{yt(t)(e,n,r,i,o,a,s,u,c,l,p,f,d,h,g)}catch(t){if(Ee(b),t!==t+0)throw t;Se(1,0)}},fa:function(t,e,n,r,i,o,a,s){var u=Ae();try{Fe(t,e,n,r,i,o,a,s)}catch(t){if(Ee(u),t!==t+0)throw t;Se(1,0)}},da:function(t,e,n,r,i,o,a,s,u,c,l,p){var f=Ae();try{Le(t,e,n,r,i,o,a,s,u,c,l,p)}catch(t){if(Ee(f),t!==t+0)throw t;Se(1,0)}},ea:function(t,e,n,r,i,o){var a=Ae();try{Ne(t,e,n,r,i,o)}catch(t){if(Ee(a),t!==t+0)throw t;Se(1,0)}},o:function(t){return t},a:$||s.wasmMemory,G:function(t){ae=t},la:le,z:function(t,e,n,r){return le(t,e,n,r)}};!function(){function t(t,e){s.asm=t.exports,dt.qc.push(s.asm.sb),q=s.asm.ub,Y.unshift(s.asm.Va),k=e,x||(et--,s.monitorRunDependencies&&s.monitorRunDependencies(et),0==et&&(null!==nt&&(clearInterval(nt),nt=null),rt&&(t=rt,rt=null,t())))}function e(e){t(e.instance,e.module)}function n(t){return function(){if(!E&&(_||v)){if(\"function\"==typeof fetch&&!tt.startsWith(\"file://\"))return fetch(tt,{credentials:\"same-origin\"}).then((function(t){if(!t.ok)throw\"failed to load wasm binary file at '\"+tt+\"'\";return t.arrayBuffer()})).catch((function(){return at()}));if(p)return new Promise((function(t,e){p(tt,(function(e){t(new Uint8Array(e))}),e)}))}return Promise.resolve().then((function(){return at()}))}().then((function(t){return WebAssembly.instantiate(t,r)})).then((function(t){return t})).then(t,(function(t){P(\"failed to asynchronously prepare wasm: \"+t),it(t)}))}var r={a:fe};if(x||(et++,s.monitorRunDependencies&&s.monitorRunDependencies(et)),s.instantiateWasm)try{return s.instantiateWasm(r,t)}catch(t){return P(\"Module.instantiateWasm callback failed with error: \"+t),!1}(E||\"function\"!=typeof WebAssembly.instantiateStreaming||ot()||tt.startsWith(\"file://\")||w||\"function\"!=typeof fetch?n(e):fetch(tt,{credentials:\"same-origin\"}).then((function(t){return WebAssembly.instantiateStreaming(t,r).then(e,(function(t){return P(\"wasm streaming compile failed: \"+t),P(\"falling back to ArrayBuffer instantiation\"),n(e)}))}))).catch(c)}(),s.___wasm_call_ctors=function(){return(s.___wasm_call_ctors=s.asm.Va).apply(null,arguments)},s._OrtInit=function(){return(s._OrtInit=s.asm.Wa).apply(null,arguments)},s._OrtCreateSessionOptions=function(){return(s._OrtCreateSessionOptions=s.asm.Xa).apply(null,arguments)},s._OrtAppendExecutionProvider=function(){return(s._OrtAppendExecutionProvider=s.asm.Ya).apply(null,arguments)},s._OrtAddSessionConfigEntry=function(){return(s._OrtAddSessionConfigEntry=s.asm.Za).apply(null,arguments)},s._OrtReleaseSessionOptions=function(){return(s._OrtReleaseSessionOptions=s.asm._a).apply(null,arguments)},s._OrtCreateSession=function(){return(s._OrtCreateSession=s.asm.$a).apply(null,arguments)},s._OrtReleaseSession=function(){return(s._OrtReleaseSession=s.asm.ab).apply(null,arguments)},s._OrtGetInputCount=function(){return(s._OrtGetInputCount=s.asm.bb).apply(null,arguments)},s._OrtGetOutputCount=function(){return(s._OrtGetOutputCount=s.asm.cb).apply(null,arguments)},s._OrtGetInputName=function(){return(s._OrtGetInputName=s.asm.db).apply(null,arguments)},s._OrtGetOutputName=function(){return(s._OrtGetOutputName=s.asm.eb).apply(null,arguments)},s._OrtFree=function(){return(s._OrtFree=s.asm.fb).apply(null,arguments)},s._OrtCreateTensor=function(){return(s._OrtCreateTensor=s.asm.gb).apply(null,arguments)},s._OrtGetTensorData=function(){return(s._OrtGetTensorData=s.asm.hb).apply(null,arguments)},s._OrtReleaseTensor=function(){return(s._OrtReleaseTensor=s.asm.ib).apply(null,arguments)},s._OrtCreateRunOptions=function(){return(s._OrtCreateRunOptions=s.asm.jb).apply(null,arguments)},s._OrtAddRunConfigEntry=function(){return(s._OrtAddRunConfigEntry=s.asm.kb).apply(null,arguments)},s._OrtReleaseRunOptions=function(){return(s._OrtReleaseRunOptions=s.asm.lb).apply(null,arguments)},s._OrtRun=function(){return(s._OrtRun=s.asm.mb).apply(null,arguments)},s._OrtEndProfiling=function(){return(s._OrtEndProfiling=s.asm.nb).apply(null,arguments)};var de=s._pthread_self=function(){return(de=s._pthread_self=s.asm.ob).apply(null,arguments)},he=s._malloc=function(){return(he=s._malloc=s.asm.pb).apply(null,arguments)},ge=s._free=function(){return(ge=s._free=s.asm.qb).apply(null,arguments)},be=s._fflush=function(){return(be=s._fflush=s.asm.rb).apply(null,arguments)};s.__emscripten_tls_init=function(){return(s.__emscripten_tls_init=s.asm.sb).apply(null,arguments)};var me=s.___funcs_on_exit=function(){return(me=s.___funcs_on_exit=s.asm.tb).apply(null,arguments)},ye=s.__emscripten_thread_init=function(){return(ye=s.__emscripten_thread_init=s.asm.vb).apply(null,arguments)};s.__emscripten_thread_crashed=function(){return(s.__emscripten_thread_crashed=s.asm.wb).apply(null,arguments)};var _e,ve=s._emscripten_run_in_main_runtime_thread_js=function(){return(ve=s._emscripten_run_in_main_runtime_thread_js=s.asm.xb).apply(null,arguments)},we=s.__emscripten_proxy_execute_task_queue=function(){return(we=s.__emscripten_proxy_execute_task_queue=s.asm.yb).apply(null,arguments)},xe=s.__emscripten_thread_free_data=function(){return(xe=s.__emscripten_thread_free_data=s.asm.zb).apply(null,arguments)},Te=s.__emscripten_thread_exit=function(){return(Te=s.__emscripten_thread_exit=s.asm.Ab).apply(null,arguments)},Se=s._setThrew=function(){return(Se=s._setThrew=s.asm.Bb).apply(null,arguments)},Oe=s._emscripten_stack_set_limits=function(){return(Oe=s._emscripten_stack_set_limits=s.asm.Cb).apply(null,arguments)},Ae=s.stackSave=function(){return(Ae=s.stackSave=s.asm.Db).apply(null,arguments)},Ee=s.stackRestore=function(){return(Ee=s.stackRestore=s.asm.Eb).apply(null,arguments)},Ie=s.stackAlloc=function(){return(Ie=s.stackAlloc=s.asm.Fb).apply(null,arguments)},Pe=s.___cxa_can_catch=function(){return(Pe=s.___cxa_can_catch=s.asm.Gb).apply(null,arguments)},De=s.___cxa_is_pointer_type=function(){return(De=s.___cxa_is_pointer_type=s.asm.Hb).apply(null,arguments)},$e=s.dynCall_j=function(){return($e=s.dynCall_j=s.asm.Ib).apply(null,arguments)},ke=s.dynCall_iiiiij=function(){return(ke=s.dynCall_iiiiij=s.asm.Jb).apply(null,arguments)},Ce=s.dynCall_jii=function(){return(Ce=s.dynCall_jii=s.asm.Kb).apply(null,arguments)},Fe=s.dynCall_viiiiij=function(){return(Fe=s.dynCall_viiiiij=s.asm.Lb).apply(null,arguments)},Ne=s.dynCall_vjji=function(){return(Ne=s.dynCall_vjji=s.asm.Mb).apply(null,arguments)},Le=s.dynCall_viiijjjii=function(){return(Le=s.dynCall_viiijjjii=s.asm.Nb).apply(null,arguments)},Re=s.dynCall_iij=function(){return(Re=s.dynCall_iij=s.asm.Ob).apply(null,arguments)},je=s.dynCall_ji=function(){return(je=s.dynCall_ji=s.asm.Pb).apply(null,arguments)},Me=s.dynCall_iiiiiij=function(){return(Me=s.dynCall_iiiiiij=s.asm.Qb).apply(null,arguments)},Ue=s.dynCall_iiij=function(){return(Ue=s.dynCall_iiij=s.asm.Rb).apply(null,arguments)};function Ve(){function t(){if(!_e&&(_e=!0,s.calledRun=!0,!M)&&(x||ht(Y),u(s),s.onRuntimeInitialized&&s.onRuntimeInitialized(),!x)){if(s.postRun)for(\"function\"==typeof s.postRun&&(s.postRun=[s.postRun]);s.postRun.length;){var t=s.postRun.shift();Z.unshift(t)}ht(Z)}}if(!(0<et))if(x)u(s),x||ht(Y),postMessage({cmd:\"loaded\"});else{if(s.preRun)for(\"function\"==typeof s.preRun&&(s.preRun=[s.preRun]);s.preRun.length;)Q();ht(X),0<et||(s.setStatus?(s.setStatus(\"Running...\"),setTimeout((function(){setTimeout((function(){s.setStatus(\"\")}),1),t()}),1)):t())}}if(s.UTF8ToString=B,s.stringToUTF8=function(t,e,n){return z(t,r(),e,n)},s.lengthBytesUTF8=G,s.keepRuntimeAlive=J,s.wasmMemory=$,s.stackSave=Ae,s.stackRestore=Ee,s.stackAlloc=Ie,s.ExitStatus=ut,s.PThread=dt,rt=function t(){_e||Ve(),_e||(rt=t)},s.preInit)for(\"function\"==typeof s.preInit&&(s.preInit=[s.preInit]);0<s.preInit.length;)s.preInit.pop()();return Ve(),t.ready});t.exports=r},932:(t,e,n)=>{var _scriptDir,r=(_scriptDir=(_scriptDir=\"undefined\"!=typeof document&&document.currentScript?document.currentScript.src:void 0)||\"/index.js\",function(t){var e,r,i;t=t||{},e||(e=void 0!==t?t:{}),e.ready=new Promise((function(t,e){r=t,i=e}));var o,a,s,u,c,l,p=Object.assign({},e),f=\"./this.program\",d=(t,e)=>{throw e},h=\"object\"==typeof window,g=\"function\"==typeof importScripts,b=\"object\"==typeof process&&\"object\"==typeof process.versions&&\"string\"==typeof process.versions.node,m=\"\";b?(m=g?n(908).dirname(m)+\"/\":\"//\",l=()=>{c||(u=n(1384),c=n(908))},o=function(t,e){return l(),t=c.normalize(t),u.readFileSync(t,e?void 0:\"utf8\")},s=t=>((t=o(t,!0)).buffer||(t=new Uint8Array(t)),t),a=(t,e,n)=>{l(),t=c.normalize(t),u.readFile(t,(function(t,r){t?n(t):e(r.buffer)}))},1<process.argv.length&&(f=process.argv[1].replace(/\\\\/g,\"/\")),process.argv.slice(2),process.on(\"uncaughtException\",(function(t){if(!(t instanceof K))throw t})),process.on(\"unhandledRejection\",(function(t){throw t})),d=(t,e)=>{if(w||0<U)throw process.exitCode=t,e;e instanceof K||v(\"exiting due to exception: \"+e),process.exit(t)},e.inspect=function(){return\"[Emscripten Module object]\"}):(h||g)&&(g?m=self.location.href:\"undefined\"!=typeof document&&document.currentScript&&(m=document.currentScript.src),_scriptDir&&(m=_scriptDir),m=0!==m.indexOf(\"blob:\")?m.substr(0,m.replace(/[?#].*/,\"\").lastIndexOf(\"/\")+1):\"\",o=t=>{var e=new XMLHttpRequest;return e.open(\"GET\",t,!1),e.send(null),e.responseText},g&&(s=t=>{var e=new XMLHttpRequest;return e.open(\"GET\",t,!1),e.responseType=\"arraybuffer\",e.send(null),new Uint8Array(e.response)}),a=(t,e,n)=>{var r=new XMLHttpRequest;r.open(\"GET\",t,!0),r.responseType=\"arraybuffer\",r.onload=()=>{200==r.status||0==r.status&&r.response?e(r.response):n()},r.onerror=n,r.send(null)});var y,_=e.print||console.log.bind(console),v=e.printErr||console.warn.bind(console);Object.assign(e,p),p=null,e.thisProgram&&(f=e.thisProgram),e.quit&&(d=e.quit),e.wasmBinary&&(y=e.wasmBinary);var w=e.noExitRuntime||!1;\"object\"!=typeof WebAssembly&&W(\"no native wasm support detected\");var x,T,S,O,A,E,I=!1,P=\"undefined\"!=typeof TextDecoder?new TextDecoder(\"utf8\"):void 0;function D(t,e,n){var r=(e>>>=0)+n;for(n=e;t[n]&&!(n>=r);)++n;if(16<n-e&&t.buffer&&P)return P.decode(t.subarray(e,n));for(r=\"\";e<n;){var i=t[e++];if(128&i){var o=63&t[e++];if(192==(224&i))r+=String.fromCharCode((31&i)<<6|o);else{var a=63&t[e++];65536>(i=224==(240&i)?(15&i)<<12|o<<6|a:(7&i)<<18|o<<12|a<<6|63&t[e++])?r+=String.fromCharCode(i):(i-=65536,r+=String.fromCharCode(55296|i>>10,56320|1023&i))}}else r+=String.fromCharCode(i)}return r}function $(t,e){return(t>>>=0)?D(O,t,e):\"\"}function k(t,e,n,r){if(!(0<r))return 0;var i=n>>>=0;r=n+r-1;for(var o=0;o<t.length;++o){var a=t.charCodeAt(o);if(55296<=a&&57343>=a&&(a=65536+((1023&a)<<10)|1023&t.charCodeAt(++o)),127>=a){if(n>=r)break;e[n++>>>0]=a}else{if(2047>=a){if(n+1>=r)break;e[n++>>>0]=192|a>>6}else{if(65535>=a){if(n+2>=r)break;e[n++>>>0]=224|a>>12}else{if(n+3>=r)break;e[n++>>>0]=240|a>>18,e[n++>>>0]=128|a>>12&63}e[n++>>>0]=128|a>>6&63}e[n++>>>0]=128|63&a}}return e[n>>>0]=0,n-i}function C(t){for(var e=0,n=0;n<t.length;++n){var r=t.charCodeAt(n);127>=r?e++:2047>=r?e+=2:55296<=r&&57343>=r?(e+=4,++n):e+=3}return e}function F(){var t=x.buffer;T=t,e.HEAP8=S=new Int8Array(t),e.HEAP16=new Int16Array(t),e.HEAP32=A=new Int32Array(t),e.HEAPU8=O=new Uint8Array(t),e.HEAPU16=new Uint16Array(t),e.HEAPU32=E=new Uint32Array(t),e.HEAPF32=new Float32Array(t),e.HEAPF64=new Float64Array(t)}var N,L=[],R=[],j=[],M=[],U=0;function V(){var t=e.preRun.shift();L.unshift(t)}var B,z=0,G=null,H=null;function W(t){throw e.onAbort&&e.onAbort(t),v(t=\"Aborted(\"+t+\")\"),I=!0,t=new WebAssembly.RuntimeError(t+\". Build with -sASSERTIONS for more info.\"),i(t),t}function q(){return B.startsWith(\"data:application/octet-stream;base64,\")}if(B=\"ort-wasm.wasm\",!q()){var X=B;B=e.locateFile?e.locateFile(X,m):m+X}function Y(){var t=B;try{if(t==B&&y)return new Uint8Array(y);if(s)return s(t);throw\"both async and sync fetching of the wasm failed\"}catch(t){W(t)}}function K(t){this.name=\"ExitStatus\",this.message=\"Program terminated with exit(\"+t+\")\",this.status=t}function Z(t){for(;0<t.length;)t.shift()(e)}var J=[],Q=0,tt=0;function et(t){this.Db=t,this.zb=t-24,this.Ub=function(t){E[this.zb+4>>2>>>0]=t},this.Eb=function(){return E[this.zb+4>>2>>>0]},this.Sb=function(t){E[this.zb+8>>2>>>0]=t},this.Wb=function(){return E[this.zb+8>>2>>>0]},this.Tb=function(){A[this.zb>>2>>>0]=0},this.Ib=function(t){S[this.zb+12>>0>>>0]=t?1:0},this.Pb=function(){return 0!=S[this.zb+12>>0>>>0]},this.Jb=function(t){S[this.zb+13>>0>>>0]=t?1:0},this.Lb=function(){return 0!=S[this.zb+13>>0>>>0]},this.Rb=function(t,e){this.Fb(0),this.Ub(t),this.Sb(e),this.Tb(),this.Ib(!1),this.Jb(!1)},this.Nb=function(){A[this.zb>>2>>>0]+=1},this.Xb=function(){var t=A[this.zb>>2>>>0];return A[this.zb>>2>>>0]=t-1,1===t},this.Fb=function(t){E[this.zb+16>>2>>>0]=t},this.Ob=function(){return E[this.zb+16>>2>>>0]},this.Qb=function(){if(Et(this.Eb()))return E[this.Db>>2>>>0];var t=this.Ob();return 0!==t?t:this.Db}}function nt(t){return _t(new et(t).zb)}var rt=[];function it(t){var e=rt[t];return e||(t>=rt.length&&(rt.length=t+1),rt[t]=e=N.get(t)),e}function ot(t){var e=C(t)+1,n=yt(e);return n&&k(t,S,n,e),n}var at={};function st(){if(!ut){var t,e={USER:\"web_user\",LOGNAME:\"web_user\",PATH:\"/\",PWD:\"/\",HOME:\"/home/web_user\",LANG:(\"object\"==typeof navigator&&navigator.languages&&navigator.languages[0]||\"C\").replace(\"-\",\"_\")+\".UTF-8\",_:f||\"./this.program\"};for(t in at)void 0===at[t]?delete e[t]:e[t]=at[t];var n=[];for(t in e)n.push(t+\"=\"+e[t]);ut=n}return ut}var ut,ct=[null,[],[]];function lt(t,e){var n=ct[t];0===e||10===e?((1===t?_:v)(D(n,0)),n.length=0):n.push(e)}var pt=0;function ft(t){return 0==t%4&&(0!=t%100||0==t%400)}var dt=[31,29,31,30,31,30,31,31,30,31,30,31],ht=[31,28,31,30,31,30,31,31,30,31,30,31];function gt(t,e,n,r){function i(t,e,n){for(t=\"number\"==typeof t?t.toString():t||\"\";t.length<e;)t=n[0]+t;return t}function o(t,e){return i(t,e,\"0\")}function a(t,e){function n(t){return 0>t?-1:0<t?1:0}var r;return 0===(r=n(t.getFullYear()-e.getFullYear()))&&0===(r=n(t.getMonth()-e.getMonth()))&&(r=n(t.getDate()-e.getDate())),r}function s(t){switch(t.getDay()){case 0:return new Date(t.getFullYear()-1,11,29);case 1:return t;case 2:return new Date(t.getFullYear(),0,3);case 3:return new Date(t.getFullYear(),0,2);case 4:return new Date(t.getFullYear(),0,1);case 5:return new Date(t.getFullYear()-1,11,31);case 6:return new Date(t.getFullYear()-1,11,30)}}function u(t){var e=t.Bb;for(t=new Date(new Date(t.Cb+1900,0,1).getTime());0<e;){var n=t.getMonth(),r=(ft(t.getFullYear())?dt:ht)[n];if(!(e>r-t.getDate())){t.setDate(t.getDate()+e);break}e-=r-t.getDate()+1,t.setDate(1),11>n?t.setMonth(n+1):(t.setMonth(0),t.setFullYear(t.getFullYear()+1))}return n=new Date(t.getFullYear()+1,0,4),e=s(new Date(t.getFullYear(),0,4)),n=s(n),0>=a(e,t)?0>=a(n,t)?t.getFullYear()+1:t.getFullYear():t.getFullYear()-1}var c=A[r+40>>2>>>0];for(var l in r={$b:A[r>>2>>>0],Zb:A[r+4>>2>>>0],Gb:A[r+8>>2>>>0],Kb:A[r+12>>2>>>0],Hb:A[r+16>>2>>>0],Cb:A[r+20>>2>>>0],Ab:A[r+24>>2>>>0],Bb:A[r+28>>2>>>0],bc:A[r+32>>2>>>0],Yb:A[r+36>>2>>>0],ac:c?$(c):\"\"},n=$(n),c={\"%c\":\"%a %b %d %H:%M:%S %Y\",\"%D\":\"%m/%d/%y\",\"%F\":\"%Y-%m-%d\",\"%h\":\"%b\",\"%r\":\"%I:%M:%S %p\",\"%R\":\"%H:%M\",\"%T\":\"%H:%M:%S\",\"%x\":\"%m/%d/%y\",\"%X\":\"%H:%M:%S\",\"%Ec\":\"%c\",\"%EC\":\"%C\",\"%Ex\":\"%m/%d/%y\",\"%EX\":\"%H:%M:%S\",\"%Ey\":\"%y\",\"%EY\":\"%Y\",\"%Od\":\"%d\",\"%Oe\":\"%e\",\"%OH\":\"%H\",\"%OI\":\"%I\",\"%Om\":\"%m\",\"%OM\":\"%M\",\"%OS\":\"%S\",\"%Ou\":\"%u\",\"%OU\":\"%U\",\"%OV\":\"%V\",\"%Ow\":\"%w\",\"%OW\":\"%W\",\"%Oy\":\"%y\"})n=n.replace(new RegExp(l,\"g\"),c[l]);var p=\"Sunday Monday Tuesday Wednesday Thursday Friday Saturday\".split(\" \"),f=\"January February March April May June July August September October November December\".split(\" \");for(l in c={\"%a\":function(t){return p[t.Ab].substring(0,3)},\"%A\":function(t){return p[t.Ab]},\"%b\":function(t){return f[t.Hb].substring(0,3)},\"%B\":function(t){return f[t.Hb]},\"%C\":function(t){return o((t.Cb+1900)/100|0,2)},\"%d\":function(t){return o(t.Kb,2)},\"%e\":function(t){return i(t.Kb,2,\" \")},\"%g\":function(t){return u(t).toString().substring(2)},\"%G\":function(t){return u(t)},\"%H\":function(t){return o(t.Gb,2)},\"%I\":function(t){return 0==(t=t.Gb)?t=12:12<t&&(t-=12),o(t,2)},\"%j\":function(t){for(var e=0,n=0;n<=t.Hb-1;e+=(ft(t.Cb+1900)?dt:ht)[n++]);return o(t.Kb+e,3)},\"%m\":function(t){return o(t.Hb+1,2)},\"%M\":function(t){return o(t.Zb,2)},\"%n\":function(){return\"\\n\"},\"%p\":function(t){return 0<=t.Gb&&12>t.Gb?\"AM\":\"PM\"},\"%S\":function(t){return o(t.$b,2)},\"%t\":function(){return\"\\t\"},\"%u\":function(t){return t.Ab||7},\"%U\":function(t){return o(Math.floor((t.Bb+7-t.Ab)/7),2)},\"%V\":function(t){var e=Math.floor((t.Bb+7-(t.Ab+6)%7)/7);if(2>=(t.Ab+371-t.Bb-2)%7&&e++,e)53==e&&(4==(n=(t.Ab+371-t.Bb)%7)||3==n&&ft(t.Cb)||(e=1));else{e=52;var n=(t.Ab+7-t.Bb-1)%7;(4==n||5==n&&ft(t.Cb%400-1))&&e++}return o(e,2)},\"%w\":function(t){return t.Ab},\"%W\":function(t){return o(Math.floor((t.Bb+7-(t.Ab+6)%7)/7),2)},\"%y\":function(t){return(t.Cb+1900).toString().substring(2)},\"%Y\":function(t){return t.Cb+1900},\"%z\":function(t){var e=0<=(t=t.Yb);return t=Math.abs(t)/60,(e?\"+\":\"-\")+String(\"0000\"+(t/60*100+t%60)).slice(-4)},\"%Z\":function(t){return t.ac},\"%%\":function(){return\"%\"}},n=n.replace(/%%/g,\"\\0\\0\"),c)n.includes(l)&&(n=n.replace(new RegExp(l,\"g\"),c[l](r)));return l=function(t){var e=Array(C(t)+1);return k(t,e,0,e.length),e}(n=n.replace(/\\0\\0/g,\"%\")),l.length>e?0:(S.set(l,t>>>0),l.length-1)}var bt={a:function(t){return yt(t+24)+24},m:function(t){return(t=new et(t)).Pb()||(t.Ib(!0),Q--),t.Jb(!1),J.push(t),t.Nb(),t.Qb()},ia:function(t){throw v(\"Unexpected exception thrown, this is not properly supported - aborting\"),I=!0,t},w:function(){xt(0);var t=J.pop();if(t.Xb()&&!t.Lb()){var e=t.Wb();e&&it(e)(t.Db),nt(t.Db)}tt=0},d:function(){var t=tt;if(!t)return pt=0;var e=new et(t);e.Fb(t);var n=e.Eb();if(!n)return pt=0,t;for(var r=Array.prototype.slice.call(arguments),i=0;i<r.length;i++){var o=r[i];if(0===o||o===n)break;if(At(o,n,e.zb+16))return pt=o,t}return pt=n,t},k:function(){var t=tt;if(!t)return pt=0;var e=new et(t);e.Fb(t);var n=e.Eb();if(!n)return pt=0,t;for(var r=Array.prototype.slice.call(arguments),i=0;i<r.length;i++){var o=r[i];if(0===o||o===n)break;if(At(o,n,e.zb+16))return pt=o,t}return pt=n,t},g:function(){var t=tt;if(!t)return pt=0;var e=new et(t);e.Fb(t);var n=e.Eb();if(!n)return pt=0,t;for(var r=Array.prototype.slice.call(arguments),i=0;i<r.length;i++){var o=r[i];if(0===o||o===n)break;if(At(o,n,e.zb+16))return pt=o,t}return pt=n,t},s:nt,L:function(){var t=J.pop();t||W(\"no exception to throw\");var e=t.Db;throw t.Lb()||(J.push(t),t.Jb(!0),t.Ib(!1),Q++),tt=e,e},b:function(t,e,n){throw new et(t).Rb(e,n),tt=t,Q++,t},la:function(){return Q},i:function(t){throw tt||(tt=t),t},H:function(){return 0},Ba:function(){},pa:function(){},ra:function(){},ka:function(){return 0},za:function(){},ua:function(){},ya:function(){},R:function(){},qa:function(){},na:function(){},Aa:function(){},oa:function(){},Ha:function(){},Ja:function(){W(\"To use dlopen, you need enable dynamic linking, see https://github.com/emscripten-core/emscripten/wiki/Linking\")},Ia:function(){W(\"To use dlopen, you need enable dynamic linking, see https://github.com/emscripten-core/emscripten/wiki/Linking\")},S:function(){return Date.now()},Ca:function(){return!0},Da:function(t,e){t=new Date(1e3*(E[t>>>2]+4294967296*A[t+4>>>2])),A[e>>2>>>0]=t.getUTCSeconds(),A[e+4>>2>>>0]=t.getUTCMinutes(),A[e+8>>2>>>0]=t.getUTCHours(),A[e+12>>2>>>0]=t.getUTCDate(),A[e+16>>2>>>0]=t.getUTCMonth(),A[e+20>>2>>>0]=t.getUTCFullYear()-1900,A[e+24>>2>>>0]=t.getUTCDay(),A[e+28>>2>>>0]=(t.getTime()-Date.UTC(t.getUTCFullYear(),0,1,0,0,0,0))/864e5|0},Ea:function(t,e){t=new Date(1e3*(E[t>>>2]+4294967296*A[t+4>>>2])),A[e>>2>>>0]=t.getSeconds(),A[e+4>>2>>>0]=t.getMinutes(),A[e+8>>2>>>0]=t.getHours(),A[e+12>>2>>>0]=t.getDate(),A[e+16>>2>>>0]=t.getMonth(),A[e+20>>2>>>0]=t.getFullYear()-1900,A[e+24>>2>>>0]=t.getDay();var n=new Date(t.getFullYear(),0,1);A[e+28>>2>>>0]=(t.getTime()-n.getTime())/864e5|0,A[e+36>>2>>>0]=-60*t.getTimezoneOffset();var r=new Date(t.getFullYear(),6,1).getTimezoneOffset();n=n.getTimezoneOffset(),A[e+32>>2>>>0]=0|(r!=n&&t.getTimezoneOffset()==Math.min(n,r))},Fa:function(t){var e=new Date(A[t+20>>2>>>0]+1900,A[t+16>>2>>>0],A[t+12>>2>>>0],A[t+8>>2>>>0],A[t+4>>2>>>0],A[t>>2>>>0],0),n=A[t+32>>2>>>0],r=e.getTimezoneOffset(),i=new Date(e.getFullYear(),0,1),o=new Date(e.getFullYear(),6,1).getTimezoneOffset(),a=i.getTimezoneOffset(),s=Math.min(a,o);return 0>n?A[t+32>>2>>>0]=Number(o!=a&&s==r):0<n!=(s==r)&&(o=Math.max(a,o),e.setTime(e.getTime()+6e4*((0<n?s:o)-r))),A[t+24>>2>>>0]=e.getDay(),A[t+28>>2>>>0]=(e.getTime()-i.getTime())/864e5|0,A[t>>2>>>0]=e.getSeconds(),A[t+4>>2>>>0]=e.getMinutes(),A[t+8>>2>>>0]=e.getHours(),A[t+12>>2>>>0]=e.getDate(),A[t+16>>2>>>0]=e.getMonth(),e.getTime()/1e3|0},sa:function(){return-52},ta:function(){},Ga:function t(e,n,r){t.Vb||(t.Vb=!0,function(t,e,n){function r(t){return(t=t.toTimeString().match(/\\(([A-Za-z ]+)\\)$/))?t[1]:\"GMT\"}var i=(new Date).getFullYear(),o=new Date(i,0,1),a=new Date(i,6,1);i=o.getTimezoneOffset();var s=a.getTimezoneOffset();A[t>>2>>>0]=60*Math.max(i,s),A[e>>2>>>0]=Number(i!=s),t=r(o),e=r(a),t=ot(t),e=ot(e),s<i?(E[n>>2>>>0]=t,E[n+4>>2>>>0]=e):(E[n>>2>>>0]=e,E[n+4>>2>>>0]=t)}(e,n,r))},B:function(){W(\"\")},ma:function(){return 4294901760},I:b?()=>{var t=process.hrtime();return 1e3*t[0]+t[1]/1e6}:()=>performance.now(),xa:function(t,e,n){O.copyWithin(t>>>0,e>>>0,e+n>>>0)},G:function(t){var e=O.length;if(4294901760<(t>>>=0))return!1;for(var n=1;4>=n;n*=2){var r=e*(1+.2/n);r=Math.min(r,t+100663296);var i=Math;r=Math.max(t,r),i=i.min.call(i,4294901760,r+(65536-r%65536)%65536);t:{try{x.grow(i-T.byteLength+65535>>>16),F();var o=1;break t}catch(t){}o=void 0}if(o)return!0}return!1},va:function(t,e){var n=0;return st().forEach((function(r,i){var o=e+n;for(i=E[t+4*i>>2>>>0]=o,o=0;o<r.length;++o)S[i++>>0>>>0]=r.charCodeAt(o);S[i>>0>>>0]=0,n+=r.length+1})),0},wa:function(t,e){var n=st();E[t>>2>>>0]=n.length;var r=0;return n.forEach((function(t){r+=t.length+1})),E[e>>2>>>0]=r,0},ba:function(t){w||0<U||(wt(),Z(j),vt(0),ct[1].length&&lt(1,10),ct[2].length&&lt(2,10)),w||0<U||(e.onExit&&e.onExit(t),I=!0),d(t,new K(t))},E:function(){return 52},Q:function(){return 52},ca:function(){return 70},P:function(t,e,n,r){for(var i=0,o=0;o<n;o++){var a=E[e>>2>>>0],s=E[e+4>>2>>>0];e+=8;for(var u=0;u<s;u++)lt(t,O[a+u>>>0]);i+=s}return E[r>>2>>>0]=i,0},c:function(){return pt},ja:function t(e,r){t.Mb||(t.Mb=function(){if(\"object\"==typeof crypto&&\"function\"==typeof crypto.getRandomValues){var t=new Uint8Array(1);return()=>(crypto.getRandomValues(t),t[0])}if(b)try{var e=n(Object(function(){var t=new Error(\"Cannot find module 'crypto'\");throw t.code=\"MODULE_NOT_FOUND\",t}()));return()=>e.randomBytes(1)[0]}catch(t){}return()=>W(\"randomDevice\")}());for(var i=0;i<r;i++)S[e+i>>0>>>0]=t.Mb();return 0},ea:function(t,e,n){var r=Tt();try{return it(t)(e,n)}catch(t){if(St(r),t!==t+0)throw t;xt(1,0)}},fa:function(t,e,n){var r=Tt();try{return it(t)(e,n)}catch(t){if(St(r),t!==t+0)throw t;xt(1,0)}},J:function(t){var e=Tt();try{return it(t)()}catch(t){if(St(e),t!==t+0)throw t;xt(1,0)}},e:function(t,e){var n=Tt();try{return it(t)(e)}catch(t){if(St(n),t!==t+0)throw t;xt(1,0)}},N:function(t,e,n){var r=Tt();try{return it(t)(e,n)}catch(t){if(St(r),t!==t+0)throw t;xt(1,0)}},O:function(t,e,n){var r=Tt();try{return it(t)(e,n)}catch(t){if(St(r),t!==t+0)throw t;xt(1,0)}},j:function(t,e,n){var r=Tt();try{return it(t)(e,n)}catch(t){if(St(r),t!==t+0)throw t;xt(1,0)}},o:function(t,e,n,r){var i=Tt();try{return it(t)(e,n,r)}catch(t){if(St(i),t!==t+0)throw t;xt(1,0)}},p:function(t,e,n,r,i){var o=Tt();try{return it(t)(e,n,r,i)}catch(t){if(St(o),t!==t+0)throw t;xt(1,0)}},M:function(t,e,n,r,i,o){var a=Tt();try{return it(t)(e,n,r,i,o)}catch(t){if(St(a),t!==t+0)throw t;xt(1,0)}},r:function(t,e,n,r,i,o){var a=Tt();try{return it(t)(e,n,r,i,o)}catch(t){if(St(a),t!==t+0)throw t;xt(1,0)}},v:function(t,e,n,r,i,o,a){var s=Tt();try{return it(t)(e,n,r,i,o,a)}catch(t){if(St(s),t!==t+0)throw t;xt(1,0)}},K:function(t,e,n,r,i,o,a,s){var u=Tt();try{return it(t)(e,n,r,i,o,a,s)}catch(t){if(St(u),t!==t+0)throw t;xt(1,0)}},D:function(t,e,n,r,i,o,a,s,u,c,l,p){var f=Tt();try{return it(t)(e,n,r,i,o,a,s,u,c,l,p)}catch(t){if(St(f),t!==t+0)throw t;xt(1,0)}},X:function(t,e,n,r,i,o,a,s){var u=Tt();try{return Lt(t,e,n,r,i,o,a,s)}catch(t){if(St(u),t!==t+0)throw t;xt(1,0)}},V:function(t,e,n,r,i,o,a){var s=Tt();try{return Pt(t,e,n,r,i,o,a)}catch(t){if(St(s),t!==t+0)throw t;xt(1,0)}},U:function(t,e,n,r,i){var o=Tt();try{return Rt(t,e,n,r,i)}catch(t){if(St(o),t!==t+0)throw t;xt(1,0)}},Z:function(t,e,n,r){var i=Tt();try{return Ft(t,e,n,r)}catch(t){if(St(i),t!==t+0)throw t;xt(1,0)}},W:function(t){var e=Tt();try{return It(t)}catch(t){if(St(e),t!==t+0)throw t;xt(1,0)}},Y:function(t,e){var n=Tt();try{return Nt(t,e)}catch(t){if(St(n),t!==t+0)throw t;xt(1,0)}},T:function(t,e,n){var r=Tt();try{return Dt(t,e,n)}catch(t){if(St(r),t!==t+0)throw t;xt(1,0)}},f:function(t){var e=Tt();try{it(t)()}catch(t){if(St(e),t!==t+0)throw t;xt(1,0)}},q:function(t,e){var n=Tt();try{it(t)(e)}catch(t){if(St(n),t!==t+0)throw t;xt(1,0)}},h:function(t,e,n){var r=Tt();try{it(t)(e,n)}catch(t){if(St(r),t!==t+0)throw t;xt(1,0)}},da:function(t,e,n,r){var i=Tt();try{it(t)(e,n,r)}catch(t){if(St(i),t!==t+0)throw t;xt(1,0)}},l:function(t,e,n,r){var i=Tt();try{it(t)(e,n,r)}catch(t){if(St(i),t!==t+0)throw t;xt(1,0)}},t:function(t,e,n,r,i){var o=Tt();try{it(t)(e,n,r,i)}catch(t){if(St(o),t!==t+0)throw t;xt(1,0)}},u:function(t,e,n,r,i,o){var a=Tt();try{it(t)(e,n,r,i,o)}catch(t){if(St(a),t!==t+0)throw t;xt(1,0)}},x:function(t,e,n,r,i,o,a){var s=Tt();try{it(t)(e,n,r,i,o,a)}catch(t){if(St(s),t!==t+0)throw t;xt(1,0)}},z:function(t,e,n,r,i,o,a,s){var u=Tt();try{it(t)(e,n,r,i,o,a,s)}catch(t){if(St(u),t!==t+0)throw t;xt(1,0)}},ga:function(t,e,n,r,i,o,a,s,u){var c=Tt();try{it(t)(e,n,r,i,o,a,s,u)}catch(t){if(St(c),t!==t+0)throw t;xt(1,0)}},A:function(t,e,n,r,i,o,a,s,u,c,l){var p=Tt();try{it(t)(e,n,r,i,o,a,s,u,c,l)}catch(t){if(St(p),t!==t+0)throw t;xt(1,0)}},C:function(t,e,n,r,i,o,a,s,u,c,l,p,f,d,h,g){var b=Tt();try{it(t)(e,n,r,i,o,a,s,u,c,l,p,f,d,h,g)}catch(t){if(St(b),t!==t+0)throw t;xt(1,0)}},aa:function(t,e,n,r,i,o,a,s){var u=Tt();try{$t(t,e,n,r,i,o,a,s)}catch(t){if(St(u),t!==t+0)throw t;xt(1,0)}},_:function(t,e,n,r,i,o,a,s,u,c,l,p){var f=Tt();try{Ct(t,e,n,r,i,o,a,s,u,c,l,p)}catch(t){if(St(f),t!==t+0)throw t;xt(1,0)}},$:function(t,e,n,r,i,o){var a=Tt();try{kt(t,e,n,r,i,o)}catch(t){if(St(a),t!==t+0)throw t;xt(1,0)}},n:function(t){return t},F:function(t){pt=t},ha:gt,y:function(t,e,n,r){return gt(t,e,n,r)}};!function(){function t(t){e.asm=t.exports,x=e.asm.Ka,F(),N=e.asm.ib,R.unshift(e.asm.La),z--,e.monitorRunDependencies&&e.monitorRunDependencies(z),0==z&&(null!==G&&(clearInterval(G),G=null),H&&(t=H,H=null,t()))}function n(e){t(e.instance)}function r(t){return function(){if(!y&&(h||g)){if(\"function\"==typeof fetch&&!B.startsWith(\"file://\"))return fetch(B,{credentials:\"same-origin\"}).then((function(t){if(!t.ok)throw\"failed to load wasm binary file at '\"+B+\"'\";return t.arrayBuffer()})).catch((function(){return Y()}));if(a)return new Promise((function(t,e){a(B,(function(e){t(new Uint8Array(e))}),e)}))}return Promise.resolve().then((function(){return Y()}))}().then((function(t){return WebAssembly.instantiate(t,o)})).then((function(t){return t})).then(t,(function(t){v(\"failed to asynchronously prepare wasm: \"+t),W(t)}))}var o={a:bt};if(z++,e.monitorRunDependencies&&e.monitorRunDependencies(z),e.instantiateWasm)try{return e.instantiateWasm(o,t)}catch(t){return v(\"Module.instantiateWasm callback failed with error: \"+t),!1}(y||\"function\"!=typeof WebAssembly.instantiateStreaming||q()||B.startsWith(\"file://\")||b||\"function\"!=typeof fetch?r(n):fetch(B,{credentials:\"same-origin\"}).then((function(t){return WebAssembly.instantiateStreaming(t,o).then(n,(function(t){return v(\"wasm streaming compile failed: \"+t),v(\"falling back to ArrayBuffer instantiation\"),r(n)}))}))).catch(i)}(),e.___wasm_call_ctors=function(){return(e.___wasm_call_ctors=e.asm.La).apply(null,arguments)},e._OrtInit=function(){return(e._OrtInit=e.asm.Ma).apply(null,arguments)},e._OrtCreateSessionOptions=function(){return(e._OrtCreateSessionOptions=e.asm.Na).apply(null,arguments)},e._OrtAppendExecutionProvider=function(){return(e._OrtAppendExecutionProvider=e.asm.Oa).apply(null,arguments)},e._OrtAddSessionConfigEntry=function(){return(e._OrtAddSessionConfigEntry=e.asm.Pa).apply(null,arguments)},e._OrtReleaseSessionOptions=function(){return(e._OrtReleaseSessionOptions=e.asm.Qa).apply(null,arguments)},e._OrtCreateSession=function(){return(e._OrtCreateSession=e.asm.Ra).apply(null,arguments)},e._OrtReleaseSession=function(){return(e._OrtReleaseSession=e.asm.Sa).apply(null,arguments)},e._OrtGetInputCount=function(){return(e._OrtGetInputCount=e.asm.Ta).apply(null,arguments)},e._OrtGetOutputCount=function(){return(e._OrtGetOutputCount=e.asm.Ua).apply(null,arguments)},e._OrtGetInputName=function(){return(e._OrtGetInputName=e.asm.Va).apply(null,arguments)},e._OrtGetOutputName=function(){return(e._OrtGetOutputName=e.asm.Wa).apply(null,arguments)},e._OrtFree=function(){return(e._OrtFree=e.asm.Xa).apply(null,arguments)},e._OrtCreateTensor=function(){return(e._OrtCreateTensor=e.asm.Ya).apply(null,arguments)},e._OrtGetTensorData=function(){return(e._OrtGetTensorData=e.asm.Za).apply(null,arguments)},e._OrtReleaseTensor=function(){return(e._OrtReleaseTensor=e.asm._a).apply(null,arguments)},e._OrtCreateRunOptions=function(){return(e._OrtCreateRunOptions=e.asm.$a).apply(null,arguments)},e._OrtAddRunConfigEntry=function(){return(e._OrtAddRunConfigEntry=e.asm.ab).apply(null,arguments)},e._OrtReleaseRunOptions=function(){return(e._OrtReleaseRunOptions=e.asm.bb).apply(null,arguments)},e._OrtRun=function(){return(e._OrtRun=e.asm.cb).apply(null,arguments)},e._OrtEndProfiling=function(){return(e._OrtEndProfiling=e.asm.db).apply(null,arguments)};var mt,yt=e._malloc=function(){return(yt=e._malloc=e.asm.eb).apply(null,arguments)},_t=e._free=function(){return(_t=e._free=e.asm.fb).apply(null,arguments)},vt=e._fflush=function(){return(vt=e._fflush=e.asm.gb).apply(null,arguments)},wt=e.___funcs_on_exit=function(){return(wt=e.___funcs_on_exit=e.asm.hb).apply(null,arguments)},xt=e._setThrew=function(){return(xt=e._setThrew=e.asm.jb).apply(null,arguments)},Tt=e.stackSave=function(){return(Tt=e.stackSave=e.asm.kb).apply(null,arguments)},St=e.stackRestore=function(){return(St=e.stackRestore=e.asm.lb).apply(null,arguments)},Ot=e.stackAlloc=function(){return(Ot=e.stackAlloc=e.asm.mb).apply(null,arguments)},At=e.___cxa_can_catch=function(){return(At=e.___cxa_can_catch=e.asm.nb).apply(null,arguments)},Et=e.___cxa_is_pointer_type=function(){return(Et=e.___cxa_is_pointer_type=e.asm.ob).apply(null,arguments)},It=e.dynCall_j=function(){return(It=e.dynCall_j=e.asm.pb).apply(null,arguments)},Pt=e.dynCall_iiiiij=function(){return(Pt=e.dynCall_iiiiij=e.asm.qb).apply(null,arguments)},Dt=e.dynCall_jii=function(){return(Dt=e.dynCall_jii=e.asm.rb).apply(null,arguments)},$t=e.dynCall_viiiiij=function(){return($t=e.dynCall_viiiiij=e.asm.sb).apply(null,arguments)},kt=e.dynCall_vjji=function(){return(kt=e.dynCall_vjji=e.asm.tb).apply(null,arguments)},Ct=e.dynCall_viiijjjii=function(){return(Ct=e.dynCall_viiijjjii=e.asm.ub).apply(null,arguments)},Ft=e.dynCall_iij=function(){return(Ft=e.dynCall_iij=e.asm.vb).apply(null,arguments)},Nt=e.dynCall_ji=function(){return(Nt=e.dynCall_ji=e.asm.wb).apply(null,arguments)},Lt=e.dynCall_iiiiiij=function(){return(Lt=e.dynCall_iiiiiij=e.asm.xb).apply(null,arguments)},Rt=e.dynCall_iiij=function(){return(Rt=e.dynCall_iiij=e.asm.yb).apply(null,arguments)};function jt(){function t(){if(!mt&&(mt=!0,e.calledRun=!0,!I)){if(Z(R),r(e),e.onRuntimeInitialized&&e.onRuntimeInitialized(),e.postRun)for(\"function\"==typeof e.postRun&&(e.postRun=[e.postRun]);e.postRun.length;){var t=e.postRun.shift();M.unshift(t)}Z(M)}}if(!(0<z)){if(e.preRun)for(\"function\"==typeof e.preRun&&(e.preRun=[e.preRun]);e.preRun.length;)V();Z(L),0<z||(e.setStatus?(e.setStatus(\"Running...\"),setTimeout((function(){setTimeout((function(){e.setStatus(\"\")}),1),t()}),1)):t())}}if(e.UTF8ToString=$,e.stringToUTF8=function(t,e,n){return k(t,O,e,n)},e.lengthBytesUTF8=C,e.stackSave=Tt,e.stackRestore=St,e.stackAlloc=Ot,H=function t(){mt||jt(),mt||(H=t)},e.preInit)for(\"function\"==typeof e.preInit&&(e.preInit=[e.preInit]);0<e.preInit.length;)e.preInit.pop()();return jt(),t.ready});t.exports=r},4537:t=>{\"use strict\";t.exports=function(t,e){for(var n=new Array(arguments.length-1),r=0,i=2,o=!0;i<arguments.length;)n[r++]=arguments[i++];return new Promise((function(i,a){n[r]=function(t){if(o)if(o=!1,t)a(t);else{for(var e=new Array(arguments.length-1),n=0;n<e.length;)e[n++]=arguments[n];i.apply(null,e)}};try{t.apply(e||null,n)}catch(t){o&&(o=!1,a(t))}}))}},7419:(t,e)=>{\"use strict\";var n=e;n.length=function(t){var e=t.length;if(!e)return 0;for(var n=0;--e%4>1&&\"=\"===t.charAt(e);)++n;return Math.ceil(3*t.length)/4-n};for(var r=new Array(64),i=new Array(123),o=0;o<64;)i[r[o]=o<26?o+65:o<52?o+71:o<62?o-4:o-59|43]=o++;n.encode=function(t,e,n){for(var i,o=null,a=[],s=0,u=0;e<n;){var c=t[e++];switch(u){case 0:a[s++]=r[c>>2],i=(3&c)<<4,u=1;break;case 1:a[s++]=r[i|c>>4],i=(15&c)<<2,u=2;break;case 2:a[s++]=r[i|c>>6],a[s++]=r[63&c],u=0}s>8191&&((o||(o=[])).push(String.fromCharCode.apply(String,a)),s=0)}return u&&(a[s++]=r[i],a[s++]=61,1===u&&(a[s++]=61)),o?(s&&o.push(String.fromCharCode.apply(String,a.slice(0,s))),o.join(\"\")):String.fromCharCode.apply(String,a.slice(0,s))};var a=\"invalid encoding\";n.decode=function(t,e,n){for(var r,o=n,s=0,u=0;u<t.length;){var c=t.charCodeAt(u++);if(61===c&&s>1)break;if(void 0===(c=i[c]))throw Error(a);switch(s){case 0:r=c,s=1;break;case 1:e[n++]=r<<2|(48&c)>>4,r=c,s=2;break;case 2:e[n++]=(15&r)<<4|(60&c)>>2,r=c,s=3;break;case 3:e[n++]=(3&r)<<6|c,s=0}}if(1===s)throw Error(a);return n-o},n.test=function(t){return/^(?:[A-Za-z0-9+/]{4})*(?:[A-Za-z0-9+/]{2}==|[A-Za-z0-9+/]{3}=)?$/.test(t)}},9211:t=>{\"use strict\";function e(){this._listeners={}}t.exports=e,e.prototype.on=function(t,e,n){return(this._listeners[t]||(this._listeners[t]=[])).push({fn:e,ctx:n||this}),this},e.prototype.off=function(t,e){if(void 0===t)this._listeners={};else if(void 0===e)this._listeners[t]=[];else for(var n=this._listeners[t],r=0;r<n.length;)n[r].fn===e?n.splice(r,1):++r;return this},e.prototype.emit=function(t){var e=this._listeners[t];if(e){for(var n=[],r=1;r<arguments.length;)n.push(arguments[r++]);for(r=0;r<e.length;)e[r].fn.apply(e[r++].ctx,n)}return this}},945:t=>{\"use strict\";function e(t){return\"undefined\"!=typeof Float32Array?function(){var e=new Float32Array([-0]),n=new Uint8Array(e.buffer),r=128===n[3];function i(t,r,i){e[0]=t,r[i]=n[0],r[i+1]=n[1],r[i+2]=n[2],r[i+3]=n[3]}function o(t,r,i){e[0]=t,r[i]=n[3],r[i+1]=n[2],r[i+2]=n[1],r[i+3]=n[0]}function a(t,r){return n[0]=t[r],n[1]=t[r+1],n[2]=t[r+2],n[3]=t[r+3],e[0]}function s(t,r){return n[3]=t[r],n[2]=t[r+1],n[1]=t[r+2],n[0]=t[r+3],e[0]}t.writeFloatLE=r?i:o,t.writeFloatBE=r?o:i,t.readFloatLE=r?a:s,t.readFloatBE=r?s:a}():function(){function e(t,e,n,r){var i=e<0?1:0;if(i&&(e=-e),0===e)t(1/e>0?0:2147483648,n,r);else if(isNaN(e))t(2143289344,n,r);else if(e>34028234663852886e22)t((i<<31|2139095040)>>>0,n,r);else if(e<11754943508222875e-54)t((i<<31|Math.round(e/1401298464324817e-60))>>>0,n,r);else{var o=Math.floor(Math.log(e)/Math.LN2);t((i<<31|o+127<<23|8388607&Math.round(e*Math.pow(2,-o)*8388608))>>>0,n,r)}}function a(t,e,n){var r=t(e,n),i=2*(r>>31)+1,o=r>>>23&255,a=8388607&r;return 255===o?a?NaN:i*(1/0):0===o?1401298464324817e-60*i*a:i*Math.pow(2,o-150)*(a+8388608)}t.writeFloatLE=e.bind(null,n),t.writeFloatBE=e.bind(null,r),t.readFloatLE=a.bind(null,i),t.readFloatBE=a.bind(null,o)}(),\"undefined\"!=typeof Float64Array?function(){var e=new Float64Array([-0]),n=new Uint8Array(e.buffer),r=128===n[7];function i(t,r,i){e[0]=t,r[i]=n[0],r[i+1]=n[1],r[i+2]=n[2],r[i+3]=n[3],r[i+4]=n[4],r[i+5]=n[5],r[i+6]=n[6],r[i+7]=n[7]}function o(t,r,i){e[0]=t,r[i]=n[7],r[i+1]=n[6],r[i+2]=n[5],r[i+3]=n[4],r[i+4]=n[3],r[i+5]=n[2],r[i+6]=n[1],r[i+7]=n[0]}function a(t,r){return n[0]=t[r],n[1]=t[r+1],n[2]=t[r+2],n[3]=t[r+3],n[4]=t[r+4],n[5]=t[r+5],n[6]=t[r+6],n[7]=t[r+7],e[0]}function s(t,r){return n[7]=t[r],n[6]=t[r+1],n[5]=t[r+2],n[4]=t[r+3],n[3]=t[r+4],n[2]=t[r+5],n[1]=t[r+6],n[0]=t[r+7],e[0]}t.writeDoubleLE=r?i:o,t.writeDoubleBE=r?o:i,t.readDoubleLE=r?a:s,t.readDoubleBE=r?s:a}():function(){function e(t,e,n,r,i,o){var a=r<0?1:0;if(a&&(r=-r),0===r)t(0,i,o+e),t(1/r>0?0:2147483648,i,o+n);else if(isNaN(r))t(0,i,o+e),t(2146959360,i,o+n);else if(r>17976931348623157e292)t(0,i,o+e),t((a<<31|2146435072)>>>0,i,o+n);else{var s;if(r<22250738585072014e-324)t((s=r/5e-324)>>>0,i,o+e),t((a<<31|s/4294967296)>>>0,i,o+n);else{var u=Math.floor(Math.log(r)/Math.LN2);1024===u&&(u=1023),t(4503599627370496*(s=r*Math.pow(2,-u))>>>0,i,o+e),t((a<<31|u+1023<<20|1048576*s&1048575)>>>0,i,o+n)}}}function a(t,e,n,r,i){var o=t(r,i+e),a=t(r,i+n),s=2*(a>>31)+1,u=a>>>20&2047,c=4294967296*(1048575&a)+o;return 2047===u?c?NaN:s*(1/0):0===u?5e-324*s*c:s*Math.pow(2,u-1075)*(c+4503599627370496)}t.writeDoubleLE=e.bind(null,n,0,4),t.writeDoubleBE=e.bind(null,r,4,0),t.readDoubleLE=a.bind(null,i,0,4),t.readDoubleBE=a.bind(null,o,4,0)}(),t}function n(t,e,n){e[n]=255&t,e[n+1]=t>>>8&255,e[n+2]=t>>>16&255,e[n+3]=t>>>24}function r(t,e,n){e[n]=t>>>24,e[n+1]=t>>>16&255,e[n+2]=t>>>8&255,e[n+3]=255&t}function i(t,e){return(t[e]|t[e+1]<<8|t[e+2]<<16|t[e+3]<<24)>>>0}function o(t,e){return(t[e]<<24|t[e+1]<<16|t[e+2]<<8|t[e+3])>>>0}t.exports=e(e)},7199:module=>{\"use strict\";function inquire(moduleName){try{var mod=eval(\"quire\".replace(/^/,\"re\"))(moduleName);if(mod&&(mod.length||Object.keys(mod).length))return mod}catch(t){}return null}module.exports=inquire},6662:t=>{\"use strict\";t.exports=function(t,e,n){var r=n||8192,i=r>>>1,o=null,a=r;return function(n){if(n<1||n>i)return t(n);a+n>r&&(o=t(r),a=0);var s=e.call(o,a,a+=n);return 7&a&&(a=1+(7|a)),s}}},4997:(t,e)=>{\"use strict\";var n=e;n.length=function(t){for(var e=0,n=0,r=0;r<t.length;++r)(n=t.charCodeAt(r))<128?e+=1:n<2048?e+=2:55296==(64512&n)&&56320==(64512&t.charCodeAt(r+1))?(++r,e+=4):e+=3;return e},n.read=function(t,e,n){if(n-e<1)return\"\";for(var r,i=null,o=[],a=0;e<n;)(r=t[e++])<128?o[a++]=r:r>191&&r<224?o[a++]=(31&r)<<6|63&t[e++]:r>239&&r<365?(r=((7&r)<<18|(63&t[e++])<<12|(63&t[e++])<<6|63&t[e++])-65536,o[a++]=55296+(r>>10),o[a++]=56320+(1023&r)):o[a++]=(15&r)<<12|(63&t[e++])<<6|63&t[e++],a>8191&&((i||(i=[])).push(String.fromCharCode.apply(String,o)),a=0);return i?(a&&i.push(String.fromCharCode.apply(String,o.slice(0,a))),i.join(\"\")):String.fromCharCode.apply(String,o.slice(0,a))},n.write=function(t,e,n){for(var r,i,o=n,a=0;a<t.length;++a)(r=t.charCodeAt(a))<128?e[n++]=r:r<2048?(e[n++]=r>>6|192,e[n++]=63&r|128):55296==(64512&r)&&56320==(64512&(i=t.charCodeAt(a+1)))?(r=65536+((1023&r)<<10)+(1023&i),++a,e[n++]=r>>18|240,e[n++]=r>>12&63|128,e[n++]=r>>6&63|128,e[n++]=63&r|128):(e[n++]=r>>12|224,e[n++]=r>>6&63|128,e[n++]=63&r|128);return n-o}},3442:(t,e)=>{\"use strict\";e.__esModule=!0;var n=function(){function t(e){if(!e)throw new TypeError(\"Invalid argument; `value` has no value.\");this.value=t.EMPTY,e&&t.isGuid(e)&&(this.value=e)}return t.isGuid=function(e){var n=e.toString();return e&&(e instanceof t||t.validator.test(n))},t.create=function(){return new t([t.gen(2),t.gen(1),t.gen(1),t.gen(1),t.gen(3)].join(\"-\"))},t.createEmpty=function(){return new t(\"emptyguid\")},t.parse=function(e){return new t(e)},t.raw=function(){return[t.gen(2),t.gen(1),t.gen(1),t.gen(1),t.gen(3)].join(\"-\")},t.gen=function(t){for(var e=\"\",n=0;n<t;n++)e+=(65536*(1+Math.random())|0).toString(16).substring(1);return e},t.prototype.equals=function(e){return t.isGuid(e)&&this.value===e.toString()},t.prototype.isEmpty=function(){return this.value===t.EMPTY},t.prototype.toString=function(){return this.value},t.prototype.toJSON=function(){return{value:this.value}},t.validator=new RegExp(\"^[a-z0-9]{8}-[a-z0-9]{4}-[a-z0-9]{4}-[a-z0-9]{4}-[a-z0-9]{12}$\",\"i\"),t.EMPTY=\"00000000-0000-0000-0000-000000000000\",t}();e.Guid=n},3720:t=>{t.exports=n;var e=null;try{e=new WebAssembly.Instance(new WebAssembly.Module(new Uint8Array([0,97,115,109,1,0,0,0,1,13,2,96,0,1,127,96,4,127,127,127,127,1,127,3,7,6,0,1,1,1,1,1,6,6,1,127,1,65,0,11,7,50,6,3,109,117,108,0,1,5,100,105,118,95,115,0,2,5,100,105,118,95,117,0,3,5,114,101,109,95,115,0,4,5,114,101,109,95,117,0,5,8,103,101,116,95,104,105,103,104,0,0,10,191,1,6,4,0,35,0,11,36,1,1,126,32,0,173,32,1,173,66,32,134,132,32,2,173,32,3,173,66,32,134,132,126,34,4,66,32,135,167,36,0,32,4,167,11,36,1,1,126,32,0,173,32,1,173,66,32,134,132,32,2,173,32,3,173,66,32,134,132,127,34,4,66,32,135,167,36,0,32,4,167,11,36,1,1,126,32,0,173,32,1,173,66,32,134,132,32,2,173,32,3,173,66,32,134,132,128,34,4,66,32,135,167,36,0,32,4,167,11,36,1,1,126,32,0,173,32,1,173,66,32,134,132,32,2,173,32,3,173,66,32,134,132,129,34,4,66,32,135,167,36,0,32,4,167,11,36,1,1,126,32,0,173,32,1,173,66,32,134,132,32,2,173,32,3,173,66,32,134,132,130,34,4,66,32,135,167,36,0,32,4,167,11])),{}).exports}catch(t){}function n(t,e,n){this.low=0|t,this.high=0|e,this.unsigned=!!n}function r(t){return!0===(t&&t.__isLong__)}n.prototype.__isLong__,Object.defineProperty(n.prototype,\"__isLong__\",{value:!0}),n.isLong=r;var i={},o={};function a(t,e){var n,r,a;return e?(a=0<=(t>>>=0)&&t<256)&&(r=o[t])?r:(n=u(t,(0|t)<0?-1:0,!0),a&&(o[t]=n),n):(a=-128<=(t|=0)&&t<128)&&(r=i[t])?r:(n=u(t,t<0?-1:0,!1),a&&(i[t]=n),n)}function s(t,e){if(isNaN(t))return e?m:b;if(e){if(t<0)return m;if(t>=d)return x}else{if(t<=-h)return T;if(t+1>=h)return w}return t<0?s(-t,e).neg():u(t%f|0,t/f|0,e)}function u(t,e,r){return new n(t,e,r)}n.fromInt=a,n.fromNumber=s,n.fromBits=u;var c=Math.pow;function l(t,e,n){if(0===t.length)throw Error(\"empty string\");if(\"NaN\"===t||\"Infinity\"===t||\"+Infinity\"===t||\"-Infinity\"===t)return b;if(\"number\"==typeof e?(n=e,e=!1):e=!!e,(n=n||10)<2||36<n)throw RangeError(\"radix\");var r;if((r=t.indexOf(\"-\"))>0)throw Error(\"interior hyphen\");if(0===r)return l(t.substring(1),e,n).neg();for(var i=s(c(n,8)),o=b,a=0;a<t.length;a+=8){var u=Math.min(8,t.length-a),p=parseInt(t.substring(a,a+u),n);if(u<8){var f=s(c(n,u));o=o.mul(f).add(s(p))}else o=(o=o.mul(i)).add(s(p))}return o.unsigned=e,o}function p(t,e){return\"number\"==typeof t?s(t,e):\"string\"==typeof t?l(t,e):u(t.low,t.high,\"boolean\"==typeof e?e:t.unsigned)}n.fromString=l,n.fromValue=p;var f=4294967296,d=f*f,h=d/2,g=a(1<<24),b=a(0);n.ZERO=b;var m=a(0,!0);n.UZERO=m;var y=a(1);n.ONE=y;var _=a(1,!0);n.UONE=_;var v=a(-1);n.NEG_ONE=v;var w=u(-1,2147483647,!1);n.MAX_VALUE=w;var x=u(-1,-1,!0);n.MAX_UNSIGNED_VALUE=x;var T=u(0,-2147483648,!1);n.MIN_VALUE=T;var S=n.prototype;S.toInt=function(){return this.unsigned?this.low>>>0:this.low},S.toNumber=function(){return this.unsigned?(this.high>>>0)*f+(this.low>>>0):this.high*f+(this.low>>>0)},S.toString=function(t){if((t=t||10)<2||36<t)throw RangeError(\"radix\");if(this.isZero())return\"0\";if(this.isNegative()){if(this.eq(T)){var e=s(t),n=this.div(e),r=n.mul(e).sub(this);return n.toString(t)+r.toInt().toString(t)}return\"-\"+this.neg().toString(t)}for(var i=s(c(t,6),this.unsigned),o=this,a=\"\";;){var u=o.div(i),l=(o.sub(u.mul(i)).toInt()>>>0).toString(t);if((o=u).isZero())return l+a;for(;l.length<6;)l=\"0\"+l;a=\"\"+l+a}},S.getHighBits=function(){return this.high},S.getHighBitsUnsigned=function(){return this.high>>>0},S.getLowBits=function(){return this.low},S.getLowBitsUnsigned=function(){return this.low>>>0},S.getNumBitsAbs=function(){if(this.isNegative())return this.eq(T)?64:this.neg().getNumBitsAbs();for(var t=0!=this.high?this.high:this.low,e=31;e>0&&0==(t&1<<e);e--);return 0!=this.high?e+33:e+1},S.isZero=function(){return 0===this.high&&0===this.low},S.eqz=S.isZero,S.isNegative=function(){return!this.unsigned&&this.high<0},S.isPositive=function(){return this.unsigned||this.high>=0},S.isOdd=function(){return 1==(1&this.low)},S.isEven=function(){return 0==(1&this.low)},S.equals=function(t){return r(t)||(t=p(t)),(this.unsigned===t.unsigned||this.high>>>31!=1||t.high>>>31!=1)&&this.high===t.high&&this.low===t.low},S.eq=S.equals,S.notEquals=function(t){return!this.eq(t)},S.neq=S.notEquals,S.ne=S.notEquals,S.lessThan=function(t){return this.comp(t)<0},S.lt=S.lessThan,S.lessThanOrEqual=function(t){return this.comp(t)<=0},S.lte=S.lessThanOrEqual,S.le=S.lessThanOrEqual,S.greaterThan=function(t){return this.comp(t)>0},S.gt=S.greaterThan,S.greaterThanOrEqual=function(t){return this.comp(t)>=0},S.gte=S.greaterThanOrEqual,S.ge=S.greaterThanOrEqual,S.compare=function(t){if(r(t)||(t=p(t)),this.eq(t))return 0;var e=this.isNegative(),n=t.isNegative();return e&&!n?-1:!e&&n?1:this.unsigned?t.high>>>0>this.high>>>0||t.high===this.high&&t.low>>>0>this.low>>>0?-1:1:this.sub(t).isNegative()?-1:1},S.comp=S.compare,S.negate=function(){return!this.unsigned&&this.eq(T)?T:this.not().add(y)},S.neg=S.negate,S.add=function(t){r(t)||(t=p(t));var e=this.high>>>16,n=65535&this.high,i=this.low>>>16,o=65535&this.low,a=t.high>>>16,s=65535&t.high,c=t.low>>>16,l=0,f=0,d=0,h=0;return d+=(h+=o+(65535&t.low))>>>16,f+=(d+=i+c)>>>16,l+=(f+=n+s)>>>16,l+=e+a,u((d&=65535)<<16|(h&=65535),(l&=65535)<<16|(f&=65535),this.unsigned)},S.subtract=function(t){return r(t)||(t=p(t)),this.add(t.neg())},S.sub=S.subtract,S.multiply=function(t){if(this.isZero())return b;if(r(t)||(t=p(t)),e)return u(e.mul(this.low,this.high,t.low,t.high),e.get_high(),this.unsigned);if(t.isZero())return b;if(this.eq(T))return t.isOdd()?T:b;if(t.eq(T))return this.isOdd()?T:b;if(this.isNegative())return t.isNegative()?this.neg().mul(t.neg()):this.neg().mul(t).neg();if(t.isNegative())return this.mul(t.neg()).neg();if(this.lt(g)&&t.lt(g))return s(this.toNumber()*t.toNumber(),this.unsigned);var n=this.high>>>16,i=65535&this.high,o=this.low>>>16,a=65535&this.low,c=t.high>>>16,l=65535&t.high,f=t.low>>>16,d=65535&t.low,h=0,m=0,y=0,_=0;return y+=(_+=a*d)>>>16,m+=(y+=o*d)>>>16,y&=65535,m+=(y+=a*f)>>>16,h+=(m+=i*d)>>>16,m&=65535,h+=(m+=o*f)>>>16,m&=65535,h+=(m+=a*l)>>>16,h+=n*d+i*f+o*l+a*c,u((y&=65535)<<16|(_&=65535),(h&=65535)<<16|(m&=65535),this.unsigned)},S.mul=S.multiply,S.divide=function(t){if(r(t)||(t=p(t)),t.isZero())throw Error(\"division by zero\");var n,i,o;if(e)return this.unsigned||-2147483648!==this.high||-1!==t.low||-1!==t.high?u((this.unsigned?e.div_u:e.div_s)(this.low,this.high,t.low,t.high),e.get_high(),this.unsigned):this;if(this.isZero())return this.unsigned?m:b;if(this.unsigned){if(t.unsigned||(t=t.toUnsigned()),t.gt(this))return m;if(t.gt(this.shru(1)))return _;o=m}else{if(this.eq(T))return t.eq(y)||t.eq(v)?T:t.eq(T)?y:(n=this.shr(1).div(t).shl(1)).eq(b)?t.isNegative()?y:v:(i=this.sub(t.mul(n)),o=n.add(i.div(t)));if(t.eq(T))return this.unsigned?m:b;if(this.isNegative())return t.isNegative()?this.neg().div(t.neg()):this.neg().div(t).neg();if(t.isNegative())return this.div(t.neg()).neg();o=b}for(i=this;i.gte(t);){n=Math.max(1,Math.floor(i.toNumber()/t.toNumber()));for(var a=Math.ceil(Math.log(n)/Math.LN2),l=a<=48?1:c(2,a-48),f=s(n),d=f.mul(t);d.isNegative()||d.gt(i);)d=(f=s(n-=l,this.unsigned)).mul(t);f.isZero()&&(f=y),o=o.add(f),i=i.sub(d)}return o},S.div=S.divide,S.modulo=function(t){return r(t)||(t=p(t)),e?u((this.unsigned?e.rem_u:e.rem_s)(this.low,this.high,t.low,t.high),e.get_high(),this.unsigned):this.sub(this.div(t).mul(t))},S.mod=S.modulo,S.rem=S.modulo,S.not=function(){return u(~this.low,~this.high,this.unsigned)},S.and=function(t){return r(t)||(t=p(t)),u(this.low&t.low,this.high&t.high,this.unsigned)},S.or=function(t){return r(t)||(t=p(t)),u(this.low|t.low,this.high|t.high,this.unsigned)},S.xor=function(t){return r(t)||(t=p(t)),u(this.low^t.low,this.high^t.high,this.unsigned)},S.shiftLeft=function(t){return r(t)&&(t=t.toInt()),0==(t&=63)?this:t<32?u(this.low<<t,this.high<<t|this.low>>>32-t,this.unsigned):u(0,this.low<<t-32,this.unsigned)},S.shl=S.shiftLeft,S.shiftRight=function(t){return r(t)&&(t=t.toInt()),0==(t&=63)?this:t<32?u(this.low>>>t|this.high<<32-t,this.high>>t,this.unsigned):u(this.high>>t-32,this.high>=0?0:-1,this.unsigned)},S.shr=S.shiftRight,S.shiftRightUnsigned=function(t){if(r(t)&&(t=t.toInt()),0==(t&=63))return this;var e=this.high;return t<32?u(this.low>>>t|e<<32-t,e>>>t,this.unsigned):u(32===t?e:e>>>t-32,0,this.unsigned)},S.shru=S.shiftRightUnsigned,S.shr_u=S.shiftRightUnsigned,S.toSigned=function(){return this.unsigned?u(this.low,this.high,!1):this},S.toUnsigned=function(){return this.unsigned?this:u(this.low,this.high,!0)},S.toBytes=function(t){return t?this.toBytesLE():this.toBytesBE()},S.toBytesLE=function(){var t=this.high,e=this.low;return[255&e,e>>>8&255,e>>>16&255,e>>>24,255&t,t>>>8&255,t>>>16&255,t>>>24]},S.toBytesBE=function(){var t=this.high,e=this.low;return[t>>>24,t>>>16&255,t>>>8&255,255&t,e>>>24,e>>>16&255,e>>>8&255,255&e]},n.fromBytes=function(t,e,r){return r?n.fromBytesLE(t,e):n.fromBytesBE(t,e)},n.fromBytesLE=function(t,e){return new n(t[0]|t[1]<<8|t[2]<<16|t[3]<<24,t[4]|t[5]<<8|t[6]<<16|t[7]<<24,e)},n.fromBytesBE=function(t,e){return new n(t[4]<<24|t[5]<<16|t[6]<<8|t[7],t[0]<<24|t[1]<<16|t[2]<<8|t[3],e)}},1446:(t,e,n)=>{\"use strict\";var r,i,o,a=n(2100),s=a.Reader,u=a.Writer,c=a.util,l=a.roots.default||(a.roots.default={});l.onnx=((o={}).Version=(r={},(i=Object.create(r))[r[0]=\"_START_VERSION\"]=0,i[r[1]=\"IR_VERSION_2017_10_10\"]=1,i[r[2]=\"IR_VERSION_2017_10_30\"]=2,i[r[3]=\"IR_VERSION_2017_11_3\"]=3,i[r[4]=\"IR_VERSION_2019_1_22\"]=4,i[r[5]=\"IR_VERSION\"]=5,i),o.AttributeProto=function(){function t(t){if(this.floats=[],this.ints=[],this.strings=[],this.tensors=[],this.graphs=[],t)for(var e=Object.keys(t),n=0;n<e.length;++n)null!=t[e[n]]&&(this[e[n]]=t[e[n]])}return t.prototype.name=\"\",t.prototype.refAttrName=\"\",t.prototype.docString=\"\",t.prototype.type=0,t.prototype.f=0,t.prototype.i=c.Long?c.Long.fromBits(0,0,!1):0,t.prototype.s=c.newBuffer([]),t.prototype.t=null,t.prototype.g=null,t.prototype.floats=c.emptyArray,t.prototype.ints=c.emptyArray,t.prototype.strings=c.emptyArray,t.prototype.tensors=c.emptyArray,t.prototype.graphs=c.emptyArray,t.create=function(e){return new t(e)},t.encode=function(t,e){if(e||(e=u.create()),null!=t.name&&t.hasOwnProperty(\"name\")&&e.uint32(10).string(t.name),null!=t.f&&t.hasOwnProperty(\"f\")&&e.uint32(21).float(t.f),null!=t.i&&t.hasOwnProperty(\"i\")&&e.uint32(24).int64(t.i),null!=t.s&&t.hasOwnProperty(\"s\")&&e.uint32(34).bytes(t.s),null!=t.t&&t.hasOwnProperty(\"t\")&&l.onnx.TensorProto.encode(t.t,e.uint32(42).fork()).ldelim(),null!=t.g&&t.hasOwnProperty(\"g\")&&l.onnx.GraphProto.encode(t.g,e.uint32(50).fork()).ldelim(),null!=t.floats&&t.floats.length){e.uint32(58).fork();for(var n=0;n<t.floats.length;++n)e.float(t.floats[n]);e.ldelim()}if(null!=t.ints&&t.ints.length){for(e.uint32(66).fork(),n=0;n<t.ints.length;++n)e.int64(t.ints[n]);e.ldelim()}if(null!=t.strings&&t.strings.length)for(n=0;n<t.strings.length;++n)e.uint32(74).bytes(t.strings[n]);if(null!=t.tensors&&t.tensors.length)for(n=0;n<t.tensors.length;++n)l.onnx.TensorProto.encode(t.tensors[n],e.uint32(82).fork()).ldelim();if(null!=t.graphs&&t.graphs.length)for(n=0;n<t.graphs.length;++n)l.onnx.GraphProto.encode(t.graphs[n],e.uint32(90).fork()).ldelim();return null!=t.docString&&t.hasOwnProperty(\"docString\")&&e.uint32(106).string(t.docString),null!=t.type&&t.hasOwnProperty(\"type\")&&e.uint32(160).int32(t.type),null!=t.refAttrName&&t.hasOwnProperty(\"refAttrName\")&&e.uint32(170).string(t.refAttrName),e},t.encodeDelimited=function(t,e){return this.encode(t,e).ldelim()},t.decode=function(t,e){t instanceof s||(t=s.create(t));for(var n=void 0===e?t.len:t.pos+e,r=new l.onnx.AttributeProto;t.pos<n;){var i=t.uint32();switch(i>>>3){case 1:r.name=t.string();break;case 21:r.refAttrName=t.string();break;case 13:r.docString=t.string();break;case 20:r.type=t.int32();break;case 2:r.f=t.float();break;case 3:r.i=t.int64();break;case 4:r.s=t.bytes();break;case 5:r.t=l.onnx.TensorProto.decode(t,t.uint32());break;case 6:r.g=l.onnx.GraphProto.decode(t,t.uint32());break;case 7:if(r.floats&&r.floats.length||(r.floats=[]),2==(7&i))for(var o=t.uint32()+t.pos;t.pos<o;)r.floats.push(t.float());else r.floats.push(t.float());break;case 8:if(r.ints&&r.ints.length||(r.ints=[]),2==(7&i))for(o=t.uint32()+t.pos;t.pos<o;)r.ints.push(t.int64());else r.ints.push(t.int64());break;case 9:r.strings&&r.strings.length||(r.strings=[]),r.strings.push(t.bytes());break;case 10:r.tensors&&r.tensors.length||(r.tensors=[]),r.tensors.push(l.onnx.TensorProto.decode(t,t.uint32()));break;case 11:r.graphs&&r.graphs.length||(r.graphs=[]),r.graphs.push(l.onnx.GraphProto.decode(t,t.uint32()));break;default:t.skipType(7&i)}}return r},t.decodeDelimited=function(t){return t instanceof s||(t=new s(t)),this.decode(t,t.uint32())},t.verify=function(t){if(\"object\"!=typeof t||null===t)return\"object expected\";if(null!=t.name&&t.hasOwnProperty(\"name\")&&!c.isString(t.name))return\"name: string expected\";if(null!=t.refAttrName&&t.hasOwnProperty(\"refAttrName\")&&!c.isString(t.refAttrName))return\"refAttrName: string expected\";if(null!=t.docString&&t.hasOwnProperty(\"docString\")&&!c.isString(t.docString))return\"docString: string expected\";if(null!=t.type&&t.hasOwnProperty(\"type\"))switch(t.type){default:return\"type: enum value expected\";case 0:case 1:case 2:case 3:case 4:case 5:case 6:case 7:case 8:case 9:case 10:}if(null!=t.f&&t.hasOwnProperty(\"f\")&&\"number\"!=typeof t.f)return\"f: number expected\";if(null!=t.i&&t.hasOwnProperty(\"i\")&&!(c.isInteger(t.i)||t.i&&c.isInteger(t.i.low)&&c.isInteger(t.i.high)))return\"i: integer|Long expected\";if(null!=t.s&&t.hasOwnProperty(\"s\")&&!(t.s&&\"number\"==typeof t.s.length||c.isString(t.s)))return\"s: buffer expected\";if(null!=t.t&&t.hasOwnProperty(\"t\")&&(n=l.onnx.TensorProto.verify(t.t)))return\"t.\"+n;if(null!=t.g&&t.hasOwnProperty(\"g\")&&(n=l.onnx.GraphProto.verify(t.g)))return\"g.\"+n;if(null!=t.floats&&t.hasOwnProperty(\"floats\")){if(!Array.isArray(t.floats))return\"floats: array expected\";for(var e=0;e<t.floats.length;++e)if(\"number\"!=typeof t.floats[e])return\"floats: number[] expected\"}if(null!=t.ints&&t.hasOwnProperty(\"ints\")){if(!Array.isArray(t.ints))return\"ints: array expected\";for(e=0;e<t.ints.length;++e)if(!(c.isInteger(t.ints[e])||t.ints[e]&&c.isInteger(t.ints[e].low)&&c.isInteger(t.ints[e].high)))return\"ints: integer|Long[] expected\"}if(null!=t.strings&&t.hasOwnProperty(\"strings\")){if(!Array.isArray(t.strings))return\"strings: array expected\";for(e=0;e<t.strings.length;++e)if(!(t.strings[e]&&\"number\"==typeof t.strings[e].length||c.isString(t.strings[e])))return\"strings: buffer[] expected\"}if(null!=t.tensors&&t.hasOwnProperty(\"tensors\")){if(!Array.isArray(t.tensors))return\"tensors: array expected\";for(e=0;e<t.tensors.length;++e)if(n=l.onnx.TensorProto.verify(t.tensors[e]))return\"tensors.\"+n}if(null!=t.graphs&&t.hasOwnProperty(\"graphs\")){if(!Array.isArray(t.graphs))return\"graphs: array expected\";for(e=0;e<t.graphs.length;++e){var n;if(n=l.onnx.GraphProto.verify(t.graphs[e]))return\"graphs.\"+n}}return null},t.fromObject=function(t){if(t instanceof l.onnx.AttributeProto)return t;var e=new l.onnx.AttributeProto;switch(null!=t.name&&(e.name=String(t.name)),null!=t.refAttrName&&(e.refAttrName=String(t.refAttrName)),null!=t.docString&&(e.docString=String(t.docString)),t.type){case\"UNDEFINED\":case 0:e.type=0;break;case\"FLOAT\":case 1:e.type=1;break;case\"INT\":case 2:e.type=2;break;case\"STRING\":case 3:e.type=3;break;case\"TENSOR\":case 4:e.type=4;break;case\"GRAPH\":case 5:e.type=5;break;case\"FLOATS\":case 6:e.type=6;break;case\"INTS\":case 7:e.type=7;break;case\"STRINGS\":case 8:e.type=8;break;case\"TENSORS\":case 9:e.type=9;break;case\"GRAPHS\":case 10:e.type=10}if(null!=t.f&&(e.f=Number(t.f)),null!=t.i&&(c.Long?(e.i=c.Long.fromValue(t.i)).unsigned=!1:\"string\"==typeof t.i?e.i=parseInt(t.i,10):\"number\"==typeof t.i?e.i=t.i:\"object\"==typeof t.i&&(e.i=new c.LongBits(t.i.low>>>0,t.i.high>>>0).toNumber())),null!=t.s&&(\"string\"==typeof t.s?c.base64.decode(t.s,e.s=c.newBuffer(c.base64.length(t.s)),0):t.s.length&&(e.s=t.s)),null!=t.t){if(\"object\"!=typeof t.t)throw TypeError(\".onnx.AttributeProto.t: object expected\");e.t=l.onnx.TensorProto.fromObject(t.t)}if(null!=t.g){if(\"object\"!=typeof t.g)throw TypeError(\".onnx.AttributeProto.g: object expected\");e.g=l.onnx.GraphProto.fromObject(t.g)}if(t.floats){if(!Array.isArray(t.floats))throw TypeError(\".onnx.AttributeProto.floats: array expected\");e.floats=[];for(var n=0;n<t.floats.length;++n)e.floats[n]=Number(t.floats[n])}if(t.ints){if(!Array.isArray(t.ints))throw TypeError(\".onnx.AttributeProto.ints: array expected\");for(e.ints=[],n=0;n<t.ints.length;++n)c.Long?(e.ints[n]=c.Long.fromValue(t.ints[n])).unsigned=!1:\"string\"==typeof t.ints[n]?e.ints[n]=parseInt(t.ints[n],10):\"number\"==typeof t.ints[n]?e.ints[n]=t.ints[n]:\"object\"==typeof t.ints[n]&&(e.ints[n]=new c.LongBits(t.ints[n].low>>>0,t.ints[n].high>>>0).toNumber())}if(t.strings){if(!Array.isArray(t.strings))throw TypeError(\".onnx.AttributeProto.strings: array expected\");for(e.strings=[],n=0;n<t.strings.length;++n)\"string\"==typeof t.strings[n]?c.base64.decode(t.strings[n],e.strings[n]=c.newBuffer(c.base64.length(t.strings[n])),0):t.strings[n].length&&(e.strings[n]=t.strings[n])}if(t.tensors){if(!Array.isArray(t.tensors))throw TypeError(\".onnx.AttributeProto.tensors: array expected\");for(e.tensors=[],n=0;n<t.tensors.length;++n){if(\"object\"!=typeof t.tensors[n])throw TypeError(\".onnx.AttributeProto.tensors: object expected\");e.tensors[n]=l.onnx.TensorProto.fromObject(t.tensors[n])}}if(t.graphs){if(!Array.isArray(t.graphs))throw TypeError(\".onnx.AttributeProto.graphs: array expected\");for(e.graphs=[],n=0;n<t.graphs.length;++n){if(\"object\"!=typeof t.graphs[n])throw TypeError(\".onnx.AttributeProto.graphs: object expected\");e.graphs[n]=l.onnx.GraphProto.fromObject(t.graphs[n])}}return e},t.toObject=function(t,e){e||(e={});var n={};if((e.arrays||e.defaults)&&(n.floats=[],n.ints=[],n.strings=[],n.tensors=[],n.graphs=[]),e.defaults){if(n.name=\"\",n.f=0,c.Long){var r=new c.Long(0,0,!1);n.i=e.longs===String?r.toString():e.longs===Number?r.toNumber():r}else n.i=e.longs===String?\"0\":0;e.bytes===String?n.s=\"\":(n.s=[],e.bytes!==Array&&(n.s=c.newBuffer(n.s))),n.t=null,n.g=null,n.docString=\"\",n.type=e.enums===String?\"UNDEFINED\":0,n.refAttrName=\"\"}if(null!=t.name&&t.hasOwnProperty(\"name\")&&(n.name=t.name),null!=t.f&&t.hasOwnProperty(\"f\")&&(n.f=e.json&&!isFinite(t.f)?String(t.f):t.f),null!=t.i&&t.hasOwnProperty(\"i\")&&(\"number\"==typeof t.i?n.i=e.longs===String?String(t.i):t.i:n.i=e.longs===String?c.Long.prototype.toString.call(t.i):e.longs===Number?new c.LongBits(t.i.low>>>0,t.i.high>>>0).toNumber():t.i),null!=t.s&&t.hasOwnProperty(\"s\")&&(n.s=e.bytes===String?c.base64.encode(t.s,0,t.s.length):e.bytes===Array?Array.prototype.slice.call(t.s):t.s),null!=t.t&&t.hasOwnProperty(\"t\")&&(n.t=l.onnx.TensorProto.toObject(t.t,e)),null!=t.g&&t.hasOwnProperty(\"g\")&&(n.g=l.onnx.GraphProto.toObject(t.g,e)),t.floats&&t.floats.length){n.floats=[];for(var i=0;i<t.floats.length;++i)n.floats[i]=e.json&&!isFinite(t.floats[i])?String(t.floats[i]):t.floats[i]}if(t.ints&&t.ints.length)for(n.ints=[],i=0;i<t.ints.length;++i)\"number\"==typeof t.ints[i]?n.ints[i]=e.longs===String?String(t.ints[i]):t.ints[i]:n.ints[i]=e.longs===String?c.Long.prototype.toString.call(t.ints[i]):e.longs===Number?new c.LongBits(t.ints[i].low>>>0,t.ints[i].high>>>0).toNumber():t.ints[i];if(t.strings&&t.strings.length)for(n.strings=[],i=0;i<t.strings.length;++i)n.strings[i]=e.bytes===String?c.base64.encode(t.strings[i],0,t.strings[i].length):e.bytes===Array?Array.prototype.slice.call(t.strings[i]):t.strings[i];if(t.tensors&&t.tensors.length)for(n.tensors=[],i=0;i<t.tensors.length;++i)n.tensors[i]=l.onnx.TensorProto.toObject(t.tensors[i],e);if(t.graphs&&t.graphs.length)for(n.graphs=[],i=0;i<t.graphs.length;++i)n.graphs[i]=l.onnx.GraphProto.toObject(t.graphs[i],e);return null!=t.docString&&t.hasOwnProperty(\"docString\")&&(n.docString=t.docString),null!=t.type&&t.hasOwnProperty(\"type\")&&(n.type=e.enums===String?l.onnx.AttributeProto.AttributeType[t.type]:t.type),null!=t.refAttrName&&t.hasOwnProperty(\"refAttrName\")&&(n.refAttrName=t.refAttrName),n},t.prototype.toJSON=function(){return this.constructor.toObject(this,a.util.toJSONOptions)},t.AttributeType=function(){var t={},e=Object.create(t);return e[t[0]=\"UNDEFINED\"]=0,e[t[1]=\"FLOAT\"]=1,e[t[2]=\"INT\"]=2,e[t[3]=\"STRING\"]=3,e[t[4]=\"TENSOR\"]=4,e[t[5]=\"GRAPH\"]=5,e[t[6]=\"FLOATS\"]=6,e[t[7]=\"INTS\"]=7,e[t[8]=\"STRINGS\"]=8,e[t[9]=\"TENSORS\"]=9,e[t[10]=\"GRAPHS\"]=10,e}(),t}(),o.ValueInfoProto=function(){function t(t){if(t)for(var e=Object.keys(t),n=0;n<e.length;++n)null!=t[e[n]]&&(this[e[n]]=t[e[n]])}return t.prototype.name=\"\",t.prototype.type=null,t.prototype.docString=\"\",t.create=function(e){return new t(e)},t.encode=function(t,e){return e||(e=u.create()),null!=t.name&&t.hasOwnProperty(\"name\")&&e.uint32(10).string(t.name),null!=t.type&&t.hasOwnProperty(\"type\")&&l.onnx.TypeProto.encode(t.type,e.uint32(18).fork()).ldelim(),null!=t.docString&&t.hasOwnProperty(\"docString\")&&e.uint32(26).string(t.docString),e},t.encodeDelimited=function(t,e){return this.encode(t,e).ldelim()},t.decode=function(t,e){t instanceof s||(t=s.create(t));for(var n=void 0===e?t.len:t.pos+e,r=new l.onnx.ValueInfoProto;t.pos<n;){var i=t.uint32();switch(i>>>3){case 1:r.name=t.string();break;case 2:r.type=l.onnx.TypeProto.decode(t,t.uint32());break;case 3:r.docString=t.string();break;default:t.skipType(7&i)}}return r},t.decodeDelimited=function(t){return t instanceof s||(t=new s(t)),this.decode(t,t.uint32())},t.verify=function(t){if(\"object\"!=typeof t||null===t)return\"object expected\";if(null!=t.name&&t.hasOwnProperty(\"name\")&&!c.isString(t.name))return\"name: string expected\";if(null!=t.type&&t.hasOwnProperty(\"type\")){var e=l.onnx.TypeProto.verify(t.type);if(e)return\"type.\"+e}return null!=t.docString&&t.hasOwnProperty(\"docString\")&&!c.isString(t.docString)?\"docString: string expected\":null},t.fromObject=function(t){if(t instanceof l.onnx.ValueInfoProto)return t;var e=new l.onnx.ValueInfoProto;if(null!=t.name&&(e.name=String(t.name)),null!=t.type){if(\"object\"!=typeof t.type)throw TypeError(\".onnx.ValueInfoProto.type: object expected\");e.type=l.onnx.TypeProto.fromObject(t.type)}return null!=t.docString&&(e.docString=String(t.docString)),e},t.toObject=function(t,e){e||(e={});var n={};return e.defaults&&(n.name=\"\",n.type=null,n.docString=\"\"),null!=t.name&&t.hasOwnProperty(\"name\")&&(n.name=t.name),null!=t.type&&t.hasOwnProperty(\"type\")&&(n.type=l.onnx.TypeProto.toObject(t.type,e)),null!=t.docString&&t.hasOwnProperty(\"docString\")&&(n.docString=t.docString),n},t.prototype.toJSON=function(){return this.constructor.toObject(this,a.util.toJSONOptions)},t}(),o.NodeProto=function(){function t(t){if(this.input=[],this.output=[],this.attribute=[],t)for(var e=Object.keys(t),n=0;n<e.length;++n)null!=t[e[n]]&&(this[e[n]]=t[e[n]])}return t.prototype.input=c.emptyArray,t.prototype.output=c.emptyArray,t.prototype.name=\"\",t.prototype.opType=\"\",t.prototype.domain=\"\",t.prototype.attribute=c.emptyArray,t.prototype.docString=\"\",t.create=function(e){return new t(e)},t.encode=function(t,e){if(e||(e=u.create()),null!=t.input&&t.input.length)for(var n=0;n<t.input.length;++n)e.uint32(10).string(t.input[n]);if(null!=t.output&&t.output.length)for(n=0;n<t.output.length;++n)e.uint32(18).string(t.output[n]);if(null!=t.name&&t.hasOwnProperty(\"name\")&&e.uint32(26).string(t.name),null!=t.opType&&t.hasOwnProperty(\"opType\")&&e.uint32(34).string(t.opType),null!=t.attribute&&t.attribute.length)for(n=0;n<t.attribute.length;++n)l.onnx.AttributeProto.encode(t.attribute[n],e.uint32(42).fork()).ldelim();return null!=t.docString&&t.hasOwnProperty(\"docString\")&&e.uint32(50).string(t.docString),null!=t.domain&&t.hasOwnProperty(\"domain\")&&e.uint32(58).string(t.domain),e},t.encodeDelimited=function(t,e){return this.encode(t,e).ldelim()},t.decode=function(t,e){t instanceof s||(t=s.create(t));for(var n=void 0===e?t.len:t.pos+e,r=new l.onnx.NodeProto;t.pos<n;){var i=t.uint32();switch(i>>>3){case 1:r.input&&r.input.length||(r.input=[]),r.input.push(t.string());break;case 2:r.output&&r.output.length||(r.output=[]),r.output.push(t.string());break;case 3:r.name=t.string();break;case 4:r.opType=t.string();break;case 7:r.domain=t.string();break;case 5:r.attribute&&r.attribute.length||(r.attribute=[]),r.attribute.push(l.onnx.AttributeProto.decode(t,t.uint32()));break;case 6:r.docString=t.string();break;default:t.skipType(7&i)}}return r},t.decodeDelimited=function(t){return t instanceof s||(t=new s(t)),this.decode(t,t.uint32())},t.verify=function(t){if(\"object\"!=typeof t||null===t)return\"object expected\";if(null!=t.input&&t.hasOwnProperty(\"input\")){if(!Array.isArray(t.input))return\"input: array expected\";for(var e=0;e<t.input.length;++e)if(!c.isString(t.input[e]))return\"input: string[] expected\"}if(null!=t.output&&t.hasOwnProperty(\"output\")){if(!Array.isArray(t.output))return\"output: array expected\";for(e=0;e<t.output.length;++e)if(!c.isString(t.output[e]))return\"output: string[] expected\"}if(null!=t.name&&t.hasOwnProperty(\"name\")&&!c.isString(t.name))return\"name: string expected\";if(null!=t.opType&&t.hasOwnProperty(\"opType\")&&!c.isString(t.opType))return\"opType: string expected\";if(null!=t.domain&&t.hasOwnProperty(\"domain\")&&!c.isString(t.domain))return\"domain: string expected\";if(null!=t.attribute&&t.hasOwnProperty(\"attribute\")){if(!Array.isArray(t.attribute))return\"attribute: array expected\";for(e=0;e<t.attribute.length;++e){var n=l.onnx.AttributeProto.verify(t.attribute[e]);if(n)return\"attribute.\"+n}}return null!=t.docString&&t.hasOwnProperty(\"docString\")&&!c.isString(t.docString)?\"docString: string expected\":null},t.fromObject=function(t){if(t instanceof l.onnx.NodeProto)return t;var e=new l.onnx.NodeProto;if(t.input){if(!Array.isArray(t.input))throw TypeError(\".onnx.NodeProto.input: array expected\");e.input=[];for(var n=0;n<t.input.length;++n)e.input[n]=String(t.input[n])}if(t.output){if(!Array.isArray(t.output))throw TypeError(\".onnx.NodeProto.output: array expected\");for(e.output=[],n=0;n<t.output.length;++n)e.output[n]=String(t.output[n])}if(null!=t.name&&(e.name=String(t.name)),null!=t.opType&&(e.opType=String(t.opType)),null!=t.domain&&(e.domain=String(t.domain)),t.attribute){if(!Array.isArray(t.attribute))throw TypeError(\".onnx.NodeProto.attribute: array expected\");for(e.attribute=[],n=0;n<t.attribute.length;++n){if(\"object\"!=typeof t.attribute[n])throw TypeError(\".onnx.NodeProto.attribute: object expected\");e.attribute[n]=l.onnx.AttributeProto.fromObject(t.attribute[n])}}return null!=t.docString&&(e.docString=String(t.docString)),e},t.toObject=function(t,e){e||(e={});var n={};if((e.arrays||e.defaults)&&(n.input=[],n.output=[],n.attribute=[]),e.defaults&&(n.name=\"\",n.opType=\"\",n.docString=\"\",n.domain=\"\"),t.input&&t.input.length){n.input=[];for(var r=0;r<t.input.length;++r)n.input[r]=t.input[r]}if(t.output&&t.output.length)for(n.output=[],r=0;r<t.output.length;++r)n.output[r]=t.output[r];if(null!=t.name&&t.hasOwnProperty(\"name\")&&(n.name=t.name),null!=t.opType&&t.hasOwnProperty(\"opType\")&&(n.opType=t.opType),t.attribute&&t.attribute.length)for(n.attribute=[],r=0;r<t.attribute.length;++r)n.attribute[r]=l.onnx.AttributeProto.toObject(t.attribute[r],e);return null!=t.docString&&t.hasOwnProperty(\"docString\")&&(n.docString=t.docString),null!=t.domain&&t.hasOwnProperty(\"domain\")&&(n.domain=t.domain),n},t.prototype.toJSON=function(){return this.constructor.toObject(this,a.util.toJSONOptions)},t}(),o.ModelProto=function(){function t(t){if(this.opsetImport=[],this.metadataProps=[],t)for(var e=Object.keys(t),n=0;n<e.length;++n)null!=t[e[n]]&&(this[e[n]]=t[e[n]])}return t.prototype.irVersion=c.Long?c.Long.fromBits(0,0,!1):0,t.prototype.opsetImport=c.emptyArray,t.prototype.producerName=\"\",t.prototype.producerVersion=\"\",t.prototype.domain=\"\",t.prototype.modelVersion=c.Long?c.Long.fromBits(0,0,!1):0,t.prototype.docString=\"\",t.prototype.graph=null,t.prototype.metadataProps=c.emptyArray,t.create=function(e){return new t(e)},t.encode=function(t,e){if(e||(e=u.create()),null!=t.irVersion&&t.hasOwnProperty(\"irVersion\")&&e.uint32(8).int64(t.irVersion),null!=t.producerName&&t.hasOwnProperty(\"producerName\")&&e.uint32(18).string(t.producerName),null!=t.producerVersion&&t.hasOwnProperty(\"producerVersion\")&&e.uint32(26).string(t.producerVersion),null!=t.domain&&t.hasOwnProperty(\"domain\")&&e.uint32(34).string(t.domain),null!=t.modelVersion&&t.hasOwnProperty(\"modelVersion\")&&e.uint32(40).int64(t.modelVersion),null!=t.docString&&t.hasOwnProperty(\"docString\")&&e.uint32(50).string(t.docString),null!=t.graph&&t.hasOwnProperty(\"graph\")&&l.onnx.GraphProto.encode(t.graph,e.uint32(58).fork()).ldelim(),null!=t.opsetImport&&t.opsetImport.length)for(var n=0;n<t.opsetImport.length;++n)l.onnx.OperatorSetIdProto.encode(t.opsetImport[n],e.uint32(66).fork()).ldelim();if(null!=t.metadataProps&&t.metadataProps.length)for(n=0;n<t.metadataProps.length;++n)l.onnx.StringStringEntryProto.encode(t.metadataProps[n],e.uint32(114).fork()).ldelim();return e},t.encodeDelimited=function(t,e){return this.encode(t,e).ldelim()},t.decode=function(t,e){t instanceof s||(t=s.create(t));for(var n=void 0===e?t.len:t.pos+e,r=new l.onnx.ModelProto;t.pos<n;){var i=t.uint32();switch(i>>>3){case 1:r.irVersion=t.int64();break;case 8:r.opsetImport&&r.opsetImport.length||(r.opsetImport=[]),r.opsetImport.push(l.onnx.OperatorSetIdProto.decode(t,t.uint32()));break;case 2:r.producerName=t.string();break;case 3:r.producerVersion=t.string();break;case 4:r.domain=t.string();break;case 5:r.modelVersion=t.int64();break;case 6:r.docString=t.string();break;case 7:r.graph=l.onnx.GraphProto.decode(t,t.uint32());break;case 14:r.metadataProps&&r.metadataProps.length||(r.metadataProps=[]),r.metadataProps.push(l.onnx.StringStringEntryProto.decode(t,t.uint32()));break;default:t.skipType(7&i)}}return r},t.decodeDelimited=function(t){return t instanceof s||(t=new s(t)),this.decode(t,t.uint32())},t.verify=function(t){if(\"object\"!=typeof t||null===t)return\"object expected\";if(null!=t.irVersion&&t.hasOwnProperty(\"irVersion\")&&!(c.isInteger(t.irVersion)||t.irVersion&&c.isInteger(t.irVersion.low)&&c.isInteger(t.irVersion.high)))return\"irVersion: integer|Long expected\";if(null!=t.opsetImport&&t.hasOwnProperty(\"opsetImport\")){if(!Array.isArray(t.opsetImport))return\"opsetImport: array expected\";for(var e=0;e<t.opsetImport.length;++e)if(n=l.onnx.OperatorSetIdProto.verify(t.opsetImport[e]))return\"opsetImport.\"+n}if(null!=t.producerName&&t.hasOwnProperty(\"producerName\")&&!c.isString(t.producerName))return\"producerName: string expected\";if(null!=t.producerVersion&&t.hasOwnProperty(\"producerVersion\")&&!c.isString(t.producerVersion))return\"producerVersion: string expected\";if(null!=t.domain&&t.hasOwnProperty(\"domain\")&&!c.isString(t.domain))return\"domain: string expected\";if(null!=t.modelVersion&&t.hasOwnProperty(\"modelVersion\")&&!(c.isInteger(t.modelVersion)||t.modelVersion&&c.isInteger(t.modelVersion.low)&&c.isInteger(t.modelVersion.high)))return\"modelVersion: integer|Long expected\";if(null!=t.docString&&t.hasOwnProperty(\"docString\")&&!c.isString(t.docString))return\"docString: string expected\";if(null!=t.graph&&t.hasOwnProperty(\"graph\")&&(n=l.onnx.GraphProto.verify(t.graph)))return\"graph.\"+n;if(null!=t.metadataProps&&t.hasOwnProperty(\"metadataProps\")){if(!Array.isArray(t.metadataProps))return\"metadataProps: array expected\";for(e=0;e<t.metadataProps.length;++e){var n;if(n=l.onnx.StringStringEntryProto.verify(t.metadataProps[e]))return\"metadataProps.\"+n}}return null},t.fromObject=function(t){if(t instanceof l.onnx.ModelProto)return t;var e=new l.onnx.ModelProto;if(null!=t.irVersion&&(c.Long?(e.irVersion=c.Long.fromValue(t.irVersion)).unsigned=!1:\"string\"==typeof t.irVersion?e.irVersion=parseInt(t.irVersion,10):\"number\"==typeof t.irVersion?e.irVersion=t.irVersion:\"object\"==typeof t.irVersion&&(e.irVersion=new c.LongBits(t.irVersion.low>>>0,t.irVersion.high>>>0).toNumber())),t.opsetImport){if(!Array.isArray(t.opsetImport))throw TypeError(\".onnx.ModelProto.opsetImport: array expected\");e.opsetImport=[];for(var n=0;n<t.opsetImport.length;++n){if(\"object\"!=typeof t.opsetImport[n])throw TypeError(\".onnx.ModelProto.opsetImport: object expected\");e.opsetImport[n]=l.onnx.OperatorSetIdProto.fromObject(t.opsetImport[n])}}if(null!=t.producerName&&(e.producerName=String(t.producerName)),null!=t.producerVersion&&(e.producerVersion=String(t.producerVersion)),null!=t.domain&&(e.domain=String(t.domain)),null!=t.modelVersion&&(c.Long?(e.modelVersion=c.Long.fromValue(t.modelVersion)).unsigned=!1:\"string\"==typeof t.modelVersion?e.modelVersion=parseInt(t.modelVersion,10):\"number\"==typeof t.modelVersion?e.modelVersion=t.modelVersion:\"object\"==typeof t.modelVersion&&(e.modelVersion=new c.LongBits(t.modelVersion.low>>>0,t.modelVersion.high>>>0).toNumber())),null!=t.docString&&(e.docString=String(t.docString)),null!=t.graph){if(\"object\"!=typeof t.graph)throw TypeError(\".onnx.ModelProto.graph: object expected\");e.graph=l.onnx.GraphProto.fromObject(t.graph)}if(t.metadataProps){if(!Array.isArray(t.metadataProps))throw TypeError(\".onnx.ModelProto.metadataProps: array expected\");for(e.metadataProps=[],n=0;n<t.metadataProps.length;++n){if(\"object\"!=typeof t.metadataProps[n])throw TypeError(\".onnx.ModelProto.metadataProps: object expected\");e.metadataProps[n]=l.onnx.StringStringEntryProto.fromObject(t.metadataProps[n])}}return e},t.toObject=function(t,e){e||(e={});var n={};if((e.arrays||e.defaults)&&(n.opsetImport=[],n.metadataProps=[]),e.defaults){if(c.Long){var r=new c.Long(0,0,!1);n.irVersion=e.longs===String?r.toString():e.longs===Number?r.toNumber():r}else n.irVersion=e.longs===String?\"0\":0;n.producerName=\"\",n.producerVersion=\"\",n.domain=\"\",c.Long?(r=new c.Long(0,0,!1),n.modelVersion=e.longs===String?r.toString():e.longs===Number?r.toNumber():r):n.modelVersion=e.longs===String?\"0\":0,n.docString=\"\",n.graph=null}if(null!=t.irVersion&&t.hasOwnProperty(\"irVersion\")&&(\"number\"==typeof t.irVersion?n.irVersion=e.longs===String?String(t.irVersion):t.irVersion:n.irVersion=e.longs===String?c.Long.prototype.toString.call(t.irVersion):e.longs===Number?new c.LongBits(t.irVersion.low>>>0,t.irVersion.high>>>0).toNumber():t.irVersion),null!=t.producerName&&t.hasOwnProperty(\"producerName\")&&(n.producerName=t.producerName),null!=t.producerVersion&&t.hasOwnProperty(\"producerVersion\")&&(n.producerVersion=t.producerVersion),null!=t.domain&&t.hasOwnProperty(\"domain\")&&(n.domain=t.domain),null!=t.modelVersion&&t.hasOwnProperty(\"modelVersion\")&&(\"number\"==typeof t.modelVersion?n.modelVersion=e.longs===String?String(t.modelVersion):t.modelVersion:n.modelVersion=e.longs===String?c.Long.prototype.toString.call(t.modelVersion):e.longs===Number?new c.LongBits(t.modelVersion.low>>>0,t.modelVersion.high>>>0).toNumber():t.modelVersion),null!=t.docString&&t.hasOwnProperty(\"docString\")&&(n.docString=t.docString),null!=t.graph&&t.hasOwnProperty(\"graph\")&&(n.graph=l.onnx.GraphProto.toObject(t.graph,e)),t.opsetImport&&t.opsetImport.length){n.opsetImport=[];for(var i=0;i<t.opsetImport.length;++i)n.opsetImport[i]=l.onnx.OperatorSetIdProto.toObject(t.opsetImport[i],e)}if(t.metadataProps&&t.metadataProps.length)for(n.metadataProps=[],i=0;i<t.metadataProps.length;++i)n.metadataProps[i]=l.onnx.StringStringEntryProto.toObject(t.metadataProps[i],e);return n},t.prototype.toJSON=function(){return this.constructor.toObject(this,a.util.toJSONOptions)},t}(),o.StringStringEntryProto=function(){function t(t){if(t)for(var e=Object.keys(t),n=0;n<e.length;++n)null!=t[e[n]]&&(this[e[n]]=t[e[n]])}return t.prototype.key=\"\",t.prototype.value=\"\",t.create=function(e){return new t(e)},t.encode=function(t,e){return e||(e=u.create()),null!=t.key&&t.hasOwnProperty(\"key\")&&e.uint32(10).string(t.key),null!=t.value&&t.hasOwnProperty(\"value\")&&e.uint32(18).string(t.value),e},t.encodeDelimited=function(t,e){return this.encode(t,e).ldelim()},t.decode=function(t,e){t instanceof s||(t=s.create(t));for(var n=void 0===e?t.len:t.pos+e,r=new l.onnx.StringStringEntryProto;t.pos<n;){var i=t.uint32();switch(i>>>3){case 1:r.key=t.string();break;case 2:r.value=t.string();break;default:t.skipType(7&i)}}return r},t.decodeDelimited=function(t){return t instanceof s||(t=new s(t)),this.decode(t,t.uint32())},t.verify=function(t){return\"object\"!=typeof t||null===t?\"object expected\":null!=t.key&&t.hasOwnProperty(\"key\")&&!c.isString(t.key)?\"key: string expected\":null!=t.value&&t.hasOwnProperty(\"value\")&&!c.isString(t.value)?\"value: string expected\":null},t.fromObject=function(t){if(t instanceof l.onnx.StringStringEntryProto)return t;var e=new l.onnx.StringStringEntryProto;return null!=t.key&&(e.key=String(t.key)),null!=t.value&&(e.value=String(t.value)),e},t.toObject=function(t,e){e||(e={});var n={};return e.defaults&&(n.key=\"\",n.value=\"\"),null!=t.key&&t.hasOwnProperty(\"key\")&&(n.key=t.key),null!=t.value&&t.hasOwnProperty(\"value\")&&(n.value=t.value),n},t.prototype.toJSON=function(){return this.constructor.toObject(this,a.util.toJSONOptions)},t}(),o.TensorAnnotation=function(){function t(t){if(this.quantParameterTensorNames=[],t)for(var e=Object.keys(t),n=0;n<e.length;++n)null!=t[e[n]]&&(this[e[n]]=t[e[n]])}return t.prototype.tensorName=\"\",t.prototype.quantParameterTensorNames=c.emptyArray,t.create=function(e){return new t(e)},t.encode=function(t,e){if(e||(e=u.create()),null!=t.tensorName&&t.hasOwnProperty(\"tensorName\")&&e.uint32(10).string(t.tensorName),null!=t.quantParameterTensorNames&&t.quantParameterTensorNames.length)for(var n=0;n<t.quantParameterTensorNames.length;++n)l.onnx.StringStringEntryProto.encode(t.quantParameterTensorNames[n],e.uint32(18).fork()).ldelim();return e},t.encodeDelimited=function(t,e){return this.encode(t,e).ldelim()},t.decode=function(t,e){t instanceof s||(t=s.create(t));for(var n=void 0===e?t.len:t.pos+e,r=new l.onnx.TensorAnnotation;t.pos<n;){var i=t.uint32();switch(i>>>3){case 1:r.tensorName=t.string();break;case 2:r.quantParameterTensorNames&&r.quantParameterTensorNames.length||(r.quantParameterTensorNames=[]),r.quantParameterTensorNames.push(l.onnx.StringStringEntryProto.decode(t,t.uint32()));break;default:t.skipType(7&i)}}return r},t.decodeDelimited=function(t){return t instanceof s||(t=new s(t)),this.decode(t,t.uint32())},t.verify=function(t){if(\"object\"!=typeof t||null===t)return\"object expected\";if(null!=t.tensorName&&t.hasOwnProperty(\"tensorName\")&&!c.isString(t.tensorName))return\"tensorName: string expected\";if(null!=t.quantParameterTensorNames&&t.hasOwnProperty(\"quantParameterTensorNames\")){if(!Array.isArray(t.quantParameterTensorNames))return\"quantParameterTensorNames: array expected\";for(var e=0;e<t.quantParameterTensorNames.length;++e){var n=l.onnx.StringStringEntryProto.verify(t.quantParameterTensorNames[e]);if(n)return\"quantParameterTensorNames.\"+n}}return null},t.fromObject=function(t){if(t instanceof l.onnx.TensorAnnotation)return t;var e=new l.onnx.TensorAnnotation;if(null!=t.tensorName&&(e.tensorName=String(t.tensorName)),t.quantParameterTensorNames){if(!Array.isArray(t.quantParameterTensorNames))throw TypeError(\".onnx.TensorAnnotation.quantParameterTensorNames: array expected\");e.quantParameterTensorNames=[];for(var n=0;n<t.quantParameterTensorNames.length;++n){if(\"object\"!=typeof t.quantParameterTensorNames[n])throw TypeError(\".onnx.TensorAnnotation.quantParameterTensorNames: object expected\");e.quantParameterTensorNames[n]=l.onnx.StringStringEntryProto.fromObject(t.quantParameterTensorNames[n])}}return e},t.toObject=function(t,e){e||(e={});var n={};if((e.arrays||e.defaults)&&(n.quantParameterTensorNames=[]),e.defaults&&(n.tensorName=\"\"),null!=t.tensorName&&t.hasOwnProperty(\"tensorName\")&&(n.tensorName=t.tensorName),t.quantParameterTensorNames&&t.quantParameterTensorNames.length){n.quantParameterTensorNames=[];for(var r=0;r<t.quantParameterTensorNames.length;++r)n.quantParameterTensorNames[r]=l.onnx.StringStringEntryProto.toObject(t.quantParameterTensorNames[r],e)}return n},t.prototype.toJSON=function(){return this.constructor.toObject(this,a.util.toJSONOptions)},t}(),o.GraphProto=function(){function t(t){if(this.node=[],this.initializer=[],this.input=[],this.output=[],this.valueInfo=[],this.quantizationAnnotation=[],t)for(var e=Object.keys(t),n=0;n<e.length;++n)null!=t[e[n]]&&(this[e[n]]=t[e[n]])}return t.prototype.node=c.emptyArray,t.prototype.name=\"\",t.prototype.initializer=c.emptyArray,t.prototype.docString=\"\",t.prototype.input=c.emptyArray,t.prototype.output=c.emptyArray,t.prototype.valueInfo=c.emptyArray,t.prototype.quantizationAnnotation=c.emptyArray,t.create=function(e){return new t(e)},t.encode=function(t,e){if(e||(e=u.create()),null!=t.node&&t.node.length)for(var n=0;n<t.node.length;++n)l.onnx.NodeProto.encode(t.node[n],e.uint32(10).fork()).ldelim();if(null!=t.name&&t.hasOwnProperty(\"name\")&&e.uint32(18).string(t.name),null!=t.initializer&&t.initializer.length)for(n=0;n<t.initializer.length;++n)l.onnx.TensorProto.encode(t.initializer[n],e.uint32(42).fork()).ldelim();if(null!=t.docString&&t.hasOwnProperty(\"docString\")&&e.uint32(82).string(t.docString),null!=t.input&&t.input.length)for(n=0;n<t.input.length;++n)l.onnx.ValueInfoProto.encode(t.input[n],e.uint32(90).fork()).ldelim();if(null!=t.output&&t.output.length)for(n=0;n<t.output.length;++n)l.onnx.ValueInfoProto.encode(t.output[n],e.uint32(98).fork()).ldelim();if(null!=t.valueInfo&&t.valueInfo.length)for(n=0;n<t.valueInfo.length;++n)l.onnx.ValueInfoProto.encode(t.valueInfo[n],e.uint32(106).fork()).ldelim();if(null!=t.quantizationAnnotation&&t.quantizationAnnotation.length)for(n=0;n<t.quantizationAnnotation.length;++n)l.onnx.TensorAnnotation.encode(t.quantizationAnnotation[n],e.uint32(114).fork()).ldelim();return e},t.encodeDelimited=function(t,e){return this.encode(t,e).ldelim()},t.decode=function(t,e){t instanceof s||(t=s.create(t));for(var n=void 0===e?t.len:t.pos+e,r=new l.onnx.GraphProto;t.pos<n;){var i=t.uint32();switch(i>>>3){case 1:r.node&&r.node.length||(r.node=[]),r.node.push(l.onnx.NodeProto.decode(t,t.uint32()));break;case 2:r.name=t.string();break;case 5:r.initializer&&r.initializer.length||(r.initializer=[]),r.initializer.push(l.onnx.TensorProto.decode(t,t.uint32()));break;case 10:r.docString=t.string();break;case 11:r.input&&r.input.length||(r.input=[]),r.input.push(l.onnx.ValueInfoProto.decode(t,t.uint32()));break;case 12:r.output&&r.output.length||(r.output=[]),r.output.push(l.onnx.ValueInfoProto.decode(t,t.uint32()));break;case 13:r.valueInfo&&r.valueInfo.length||(r.valueInfo=[]),r.valueInfo.push(l.onnx.ValueInfoProto.decode(t,t.uint32()));break;case 14:r.quantizationAnnotation&&r.quantizationAnnotation.length||(r.quantizationAnnotation=[]),r.quantizationAnnotation.push(l.onnx.TensorAnnotation.decode(t,t.uint32()));break;default:t.skipType(7&i)}}return r},t.decodeDelimited=function(t){return t instanceof s||(t=new s(t)),this.decode(t,t.uint32())},t.verify=function(t){if(\"object\"!=typeof t||null===t)return\"object expected\";if(null!=t.node&&t.hasOwnProperty(\"node\")){if(!Array.isArray(t.node))return\"node: array expected\";for(var e=0;e<t.node.length;++e)if(n=l.onnx.NodeProto.verify(t.node[e]))return\"node.\"+n}if(null!=t.name&&t.hasOwnProperty(\"name\")&&!c.isString(t.name))return\"name: string expected\";if(null!=t.initializer&&t.hasOwnProperty(\"initializer\")){if(!Array.isArray(t.initializer))return\"initializer: array expected\";for(e=0;e<t.initializer.length;++e)if(n=l.onnx.TensorProto.verify(t.initializer[e]))return\"initializer.\"+n}if(null!=t.docString&&t.hasOwnProperty(\"docString\")&&!c.isString(t.docString))return\"docString: string expected\";if(null!=t.input&&t.hasOwnProperty(\"input\")){if(!Array.isArray(t.input))return\"input: array expected\";for(e=0;e<t.input.length;++e)if(n=l.onnx.ValueInfoProto.verify(t.input[e]))return\"input.\"+n}if(null!=t.output&&t.hasOwnProperty(\"output\")){if(!Array.isArray(t.output))return\"output: array expected\";for(e=0;e<t.output.length;++e)if(n=l.onnx.ValueInfoProto.verify(t.output[e]))return\"output.\"+n}if(null!=t.valueInfo&&t.hasOwnProperty(\"valueInfo\")){if(!Array.isArray(t.valueInfo))return\"valueInfo: array expected\";for(e=0;e<t.valueInfo.length;++e)if(n=l.onnx.ValueInfoProto.verify(t.valueInfo[e]))return\"valueInfo.\"+n}if(null!=t.quantizationAnnotation&&t.hasOwnProperty(\"quantizationAnnotation\")){if(!Array.isArray(t.quantizationAnnotation))return\"quantizationAnnotation: array expected\";for(e=0;e<t.quantizationAnnotation.length;++e){var n;if(n=l.onnx.TensorAnnotation.verify(t.quantizationAnnotation[e]))return\"quantizationAnnotation.\"+n}}return null},t.fromObject=function(t){if(t instanceof l.onnx.GraphProto)return t;var e=new l.onnx.GraphProto;if(t.node){if(!Array.isArray(t.node))throw TypeError(\".onnx.GraphProto.node: array expected\");e.node=[];for(var n=0;n<t.node.length;++n){if(\"object\"!=typeof t.node[n])throw TypeError(\".onnx.GraphProto.node: object expected\");e.node[n]=l.onnx.NodeProto.fromObject(t.node[n])}}if(null!=t.name&&(e.name=String(t.name)),t.initializer){if(!Array.isArray(t.initializer))throw TypeError(\".onnx.GraphProto.initializer: array expected\");for(e.initializer=[],n=0;n<t.initializer.length;++n){if(\"object\"!=typeof t.initializer[n])throw TypeError(\".onnx.GraphProto.initializer: object expected\");e.initializer[n]=l.onnx.TensorProto.fromObject(t.initializer[n])}}if(null!=t.docString&&(e.docString=String(t.docString)),t.input){if(!Array.isArray(t.input))throw TypeError(\".onnx.GraphProto.input: array expected\");for(e.input=[],n=0;n<t.input.length;++n){if(\"object\"!=typeof t.input[n])throw TypeError(\".onnx.GraphProto.input: object expected\");e.input[n]=l.onnx.ValueInfoProto.fromObject(t.input[n])}}if(t.output){if(!Array.isArray(t.output))throw TypeError(\".onnx.GraphProto.output: array expected\");for(e.output=[],n=0;n<t.output.length;++n){if(\"object\"!=typeof t.output[n])throw TypeError(\".onnx.GraphProto.output: object expected\");e.output[n]=l.onnx.ValueInfoProto.fromObject(t.output[n])}}if(t.valueInfo){if(!Array.isArray(t.valueInfo))throw TypeError(\".onnx.GraphProto.valueInfo: array expected\");for(e.valueInfo=[],n=0;n<t.valueInfo.length;++n){if(\"object\"!=typeof t.valueInfo[n])throw TypeError(\".onnx.GraphProto.valueInfo: object expected\");e.valueInfo[n]=l.onnx.ValueInfoProto.fromObject(t.valueInfo[n])}}if(t.quantizationAnnotation){if(!Array.isArray(t.quantizationAnnotation))throw TypeError(\".onnx.GraphProto.quantizationAnnotation: array expected\");for(e.quantizationAnnotation=[],n=0;n<t.quantizationAnnotation.length;++n){if(\"object\"!=typeof t.quantizationAnnotation[n])throw TypeError(\".onnx.GraphProto.quantizationAnnotation: object expected\");e.quantizationAnnotation[n]=l.onnx.TensorAnnotation.fromObject(t.quantizationAnnotation[n])}}return e},t.toObject=function(t,e){e||(e={});var n={};if((e.arrays||e.defaults)&&(n.node=[],n.initializer=[],n.input=[],n.output=[],n.valueInfo=[],n.quantizationAnnotation=[]),e.defaults&&(n.name=\"\",n.docString=\"\"),t.node&&t.node.length){n.node=[];for(var r=0;r<t.node.length;++r)n.node[r]=l.onnx.NodeProto.toObject(t.node[r],e)}if(null!=t.name&&t.hasOwnProperty(\"name\")&&(n.name=t.name),t.initializer&&t.initializer.length)for(n.initializer=[],r=0;r<t.initializer.length;++r)n.initializer[r]=l.onnx.TensorProto.toObject(t.initializer[r],e);if(null!=t.docString&&t.hasOwnProperty(\"docString\")&&(n.docString=t.docString),t.input&&t.input.length)for(n.input=[],r=0;r<t.input.length;++r)n.input[r]=l.onnx.ValueInfoProto.toObject(t.input[r],e);if(t.output&&t.output.length)for(n.output=[],r=0;r<t.output.length;++r)n.output[r]=l.onnx.ValueInfoProto.toObject(t.output[r],e);if(t.valueInfo&&t.valueInfo.length)for(n.valueInfo=[],r=0;r<t.valueInfo.length;++r)n.valueInfo[r]=l.onnx.ValueInfoProto.toObject(t.valueInfo[r],e);if(t.quantizationAnnotation&&t.quantizationAnnotation.length)for(n.quantizationAnnotation=[],r=0;r<t.quantizationAnnotation.length;++r)n.quantizationAnnotation[r]=l.onnx.TensorAnnotation.toObject(t.quantizationAnnotation[r],e);return n},t.prototype.toJSON=function(){return this.constructor.toObject(this,a.util.toJSONOptions)},t}(),o.TensorProto=function(){function t(t){if(this.dims=[],this.floatData=[],this.int32Data=[],this.stringData=[],this.int64Data=[],this.externalData=[],this.doubleData=[],this.uint64Data=[],t)for(var e=Object.keys(t),n=0;n<e.length;++n)null!=t[e[n]]&&(this[e[n]]=t[e[n]])}return t.prototype.dims=c.emptyArray,t.prototype.dataType=0,t.prototype.segment=null,t.prototype.floatData=c.emptyArray,t.prototype.int32Data=c.emptyArray,t.prototype.stringData=c.emptyArray,t.prototype.int64Data=c.emptyArray,t.prototype.name=\"\",t.prototype.docString=\"\",t.prototype.rawData=c.newBuffer([]),t.prototype.externalData=c.emptyArray,t.prototype.dataLocation=0,t.prototype.doubleData=c.emptyArray,t.prototype.uint64Data=c.emptyArray,t.create=function(e){return new t(e)},t.encode=function(t,e){if(e||(e=u.create()),null!=t.dims&&t.dims.length){e.uint32(10).fork();for(var n=0;n<t.dims.length;++n)e.int64(t.dims[n]);e.ldelim()}if(null!=t.dataType&&t.hasOwnProperty(\"dataType\")&&e.uint32(16).int32(t.dataType),null!=t.segment&&t.hasOwnProperty(\"segment\")&&l.onnx.TensorProto.Segment.encode(t.segment,e.uint32(26).fork()).ldelim(),null!=t.floatData&&t.floatData.length){for(e.uint32(34).fork(),n=0;n<t.floatData.length;++n)e.float(t.floatData[n]);e.ldelim()}if(null!=t.int32Data&&t.int32Data.length){for(e.uint32(42).fork(),n=0;n<t.int32Data.length;++n)e.int32(t.int32Data[n]);e.ldelim()}if(null!=t.stringData&&t.stringData.length)for(n=0;n<t.stringData.length;++n)e.uint32(50).bytes(t.stringData[n]);if(null!=t.int64Data&&t.int64Data.length){for(e.uint32(58).fork(),n=0;n<t.int64Data.length;++n)e.int64(t.int64Data[n]);e.ldelim()}if(null!=t.name&&t.hasOwnProperty(\"name\")&&e.uint32(66).string(t.name),null!=t.rawData&&t.hasOwnProperty(\"rawData\")&&e.uint32(74).bytes(t.rawData),null!=t.doubleData&&t.doubleData.length){for(e.uint32(82).fork(),n=0;n<t.doubleData.length;++n)e.double(t.doubleData[n]);e.ldelim()}if(null!=t.uint64Data&&t.uint64Data.length){for(e.uint32(90).fork(),n=0;n<t.uint64Data.length;++n)e.uint64(t.uint64Data[n]);e.ldelim()}if(null!=t.docString&&t.hasOwnProperty(\"docString\")&&e.uint32(98).string(t.docString),null!=t.externalData&&t.externalData.length)for(n=0;n<t.externalData.length;++n)l.onnx.StringStringEntryProto.encode(t.externalData[n],e.uint32(106).fork()).ldelim();return null!=t.dataLocation&&t.hasOwnProperty(\"dataLocation\")&&e.uint32(112).int32(t.dataLocation),e},t.encodeDelimited=function(t,e){return this.encode(t,e).ldelim()},t.decode=function(t,e){t instanceof s||(t=s.create(t));for(var n=void 0===e?t.len:t.pos+e,r=new l.onnx.TensorProto;t.pos<n;){var i=t.uint32();switch(i>>>3){case 1:if(r.dims&&r.dims.length||(r.dims=[]),2==(7&i))for(var o=t.uint32()+t.pos;t.pos<o;)r.dims.push(t.int64());else r.dims.push(t.int64());break;case 2:r.dataType=t.int32();break;case 3:r.segment=l.onnx.TensorProto.Segment.decode(t,t.uint32());break;case 4:if(r.floatData&&r.floatData.length||(r.floatData=[]),2==(7&i))for(o=t.uint32()+t.pos;t.pos<o;)r.floatData.push(t.float());else r.floatData.push(t.float());break;case 5:if(r.int32Data&&r.int32Data.length||(r.int32Data=[]),2==(7&i))for(o=t.uint32()+t.pos;t.pos<o;)r.int32Data.push(t.int32());else r.int32Data.push(t.int32());break;case 6:r.stringData&&r.stringData.length||(r.stringData=[]),r.stringData.push(t.bytes());break;case 7:if(r.int64Data&&r.int64Data.length||(r.int64Data=[]),2==(7&i))for(o=t.uint32()+t.pos;t.pos<o;)r.int64Data.push(t.int64());else r.int64Data.push(t.int64());break;case 8:r.name=t.string();break;case 12:r.docString=t.string();break;case 9:r.rawData=t.bytes();break;case 13:r.externalData&&r.externalData.length||(r.externalData=[]),r.externalData.push(l.onnx.StringStringEntryProto.decode(t,t.uint32()));break;case 14:r.dataLocation=t.int32();break;case 10:if(r.doubleData&&r.doubleData.length||(r.doubleData=[]),2==(7&i))for(o=t.uint32()+t.pos;t.pos<o;)r.doubleData.push(t.double());else r.doubleData.push(t.double());break;case 11:if(r.uint64Data&&r.uint64Data.length||(r.uint64Data=[]),2==(7&i))for(o=t.uint32()+t.pos;t.pos<o;)r.uint64Data.push(t.uint64());else r.uint64Data.push(t.uint64());break;default:t.skipType(7&i)}}return r},t.decodeDelimited=function(t){return t instanceof s||(t=new s(t)),this.decode(t,t.uint32())},t.verify=function(t){if(\"object\"!=typeof t||null===t)return\"object expected\";if(null!=t.dims&&t.hasOwnProperty(\"dims\")){if(!Array.isArray(t.dims))return\"dims: array expected\";for(var e=0;e<t.dims.length;++e)if(!(c.isInteger(t.dims[e])||t.dims[e]&&c.isInteger(t.dims[e].low)&&c.isInteger(t.dims[e].high)))return\"dims: integer|Long[] expected\"}if(null!=t.dataType&&t.hasOwnProperty(\"dataType\")&&!c.isInteger(t.dataType))return\"dataType: integer expected\";if(null!=t.segment&&t.hasOwnProperty(\"segment\")&&(n=l.onnx.TensorProto.Segment.verify(t.segment)))return\"segment.\"+n;if(null!=t.floatData&&t.hasOwnProperty(\"floatData\")){if(!Array.isArray(t.floatData))return\"floatData: array expected\";for(e=0;e<t.floatData.length;++e)if(\"number\"!=typeof t.floatData[e])return\"floatData: number[] expected\"}if(null!=t.int32Data&&t.hasOwnProperty(\"int32Data\")){if(!Array.isArray(t.int32Data))return\"int32Data: array expected\";for(e=0;e<t.int32Data.length;++e)if(!c.isInteger(t.int32Data[e]))return\"int32Data: integer[] expected\"}if(null!=t.stringData&&t.hasOwnProperty(\"stringData\")){if(!Array.isArray(t.stringData))return\"stringData: array expected\";for(e=0;e<t.stringData.length;++e)if(!(t.stringData[e]&&\"number\"==typeof t.stringData[e].length||c.isString(t.stringData[e])))return\"stringData: buffer[] expected\"}if(null!=t.int64Data&&t.hasOwnProperty(\"int64Data\")){if(!Array.isArray(t.int64Data))return\"int64Data: array expected\";for(e=0;e<t.int64Data.length;++e)if(!(c.isInteger(t.int64Data[e])||t.int64Data[e]&&c.isInteger(t.int64Data[e].low)&&c.isInteger(t.int64Data[e].high)))return\"int64Data: integer|Long[] expected\"}if(null!=t.name&&t.hasOwnProperty(\"name\")&&!c.isString(t.name))return\"name: string expected\";if(null!=t.docString&&t.hasOwnProperty(\"docString\")&&!c.isString(t.docString))return\"docString: string expected\";if(null!=t.rawData&&t.hasOwnProperty(\"rawData\")&&!(t.rawData&&\"number\"==typeof t.rawData.length||c.isString(t.rawData)))return\"rawData: buffer expected\";if(null!=t.externalData&&t.hasOwnProperty(\"externalData\")){if(!Array.isArray(t.externalData))return\"externalData: array expected\";for(e=0;e<t.externalData.length;++e){var n;if(n=l.onnx.StringStringEntryProto.verify(t.externalData[e]))return\"externalData.\"+n}}if(null!=t.dataLocation&&t.hasOwnProperty(\"dataLocation\"))switch(t.dataLocation){default:return\"dataLocation: enum value expected\";case 0:case 1:}if(null!=t.doubleData&&t.hasOwnProperty(\"doubleData\")){if(!Array.isArray(t.doubleData))return\"doubleData: array expected\";for(e=0;e<t.doubleData.length;++e)if(\"number\"!=typeof t.doubleData[e])return\"doubleData: number[] expected\"}if(null!=t.uint64Data&&t.hasOwnProperty(\"uint64Data\")){if(!Array.isArray(t.uint64Data))return\"uint64Data: array expected\";for(e=0;e<t.uint64Data.length;++e)if(!(c.isInteger(t.uint64Data[e])||t.uint64Data[e]&&c.isInteger(t.uint64Data[e].low)&&c.isInteger(t.uint64Data[e].high)))return\"uint64Data: integer|Long[] expected\"}return null},t.fromObject=function(t){if(t instanceof l.onnx.TensorProto)return t;var e=new l.onnx.TensorProto;if(t.dims){if(!Array.isArray(t.dims))throw TypeError(\".onnx.TensorProto.dims: array expected\");e.dims=[];for(var n=0;n<t.dims.length;++n)c.Long?(e.dims[n]=c.Long.fromValue(t.dims[n])).unsigned=!1:\"string\"==typeof t.dims[n]?e.dims[n]=parseInt(t.dims[n],10):\"number\"==typeof t.dims[n]?e.dims[n]=t.dims[n]:\"object\"==typeof t.dims[n]&&(e.dims[n]=new c.LongBits(t.dims[n].low>>>0,t.dims[n].high>>>0).toNumber())}if(null!=t.dataType&&(e.dataType=0|t.dataType),null!=t.segment){if(\"object\"!=typeof t.segment)throw TypeError(\".onnx.TensorProto.segment: object expected\");e.segment=l.onnx.TensorProto.Segment.fromObject(t.segment)}if(t.floatData){if(!Array.isArray(t.floatData))throw TypeError(\".onnx.TensorProto.floatData: array expected\");for(e.floatData=[],n=0;n<t.floatData.length;++n)e.floatData[n]=Number(t.floatData[n])}if(t.int32Data){if(!Array.isArray(t.int32Data))throw TypeError(\".onnx.TensorProto.int32Data: array expected\");for(e.int32Data=[],n=0;n<t.int32Data.length;++n)e.int32Data[n]=0|t.int32Data[n]}if(t.stringData){if(!Array.isArray(t.stringData))throw TypeError(\".onnx.TensorProto.stringData: array expected\");for(e.stringData=[],n=0;n<t.stringData.length;++n)\"string\"==typeof t.stringData[n]?c.base64.decode(t.stringData[n],e.stringData[n]=c.newBuffer(c.base64.length(t.stringData[n])),0):t.stringData[n].length&&(e.stringData[n]=t.stringData[n])}if(t.int64Data){if(!Array.isArray(t.int64Data))throw TypeError(\".onnx.TensorProto.int64Data: array expected\");for(e.int64Data=[],n=0;n<t.int64Data.length;++n)c.Long?(e.int64Data[n]=c.Long.fromValue(t.int64Data[n])).unsigned=!1:\"string\"==typeof t.int64Data[n]?e.int64Data[n]=parseInt(t.int64Data[n],10):\"number\"==typeof t.int64Data[n]?e.int64Data[n]=t.int64Data[n]:\"object\"==typeof t.int64Data[n]&&(e.int64Data[n]=new c.LongBits(t.int64Data[n].low>>>0,t.int64Data[n].high>>>0).toNumber())}if(null!=t.name&&(e.name=String(t.name)),null!=t.docString&&(e.docString=String(t.docString)),null!=t.rawData&&(\"string\"==typeof t.rawData?c.base64.decode(t.rawData,e.rawData=c.newBuffer(c.base64.length(t.rawData)),0):t.rawData.length&&(e.rawData=t.rawData)),t.externalData){if(!Array.isArray(t.externalData))throw TypeError(\".onnx.TensorProto.externalData: array expected\");for(e.externalData=[],n=0;n<t.externalData.length;++n){if(\"object\"!=typeof t.externalData[n])throw TypeError(\".onnx.TensorProto.externalData: object expected\");e.externalData[n]=l.onnx.StringStringEntryProto.fromObject(t.externalData[n])}}switch(t.dataLocation){case\"DEFAULT\":case 0:e.dataLocation=0;break;case\"EXTERNAL\":case 1:e.dataLocation=1}if(t.doubleData){if(!Array.isArray(t.doubleData))throw TypeError(\".onnx.TensorProto.doubleData: array expected\");for(e.doubleData=[],n=0;n<t.doubleData.length;++n)e.doubleData[n]=Number(t.doubleData[n])}if(t.uint64Data){if(!Array.isArray(t.uint64Data))throw TypeError(\".onnx.TensorProto.uint64Data: array expected\");for(e.uint64Data=[],n=0;n<t.uint64Data.length;++n)c.Long?(e.uint64Data[n]=c.Long.fromValue(t.uint64Data[n])).unsigned=!0:\"string\"==typeof t.uint64Data[n]?e.uint64Data[n]=parseInt(t.uint64Data[n],10):\"number\"==typeof t.uint64Data[n]?e.uint64Data[n]=t.uint64Data[n]:\"object\"==typeof t.uint64Data[n]&&(e.uint64Data[n]=new c.LongBits(t.uint64Data[n].low>>>0,t.uint64Data[n].high>>>0).toNumber(!0))}return e},t.toObject=function(t,e){e||(e={});var n={};if((e.arrays||e.defaults)&&(n.dims=[],n.floatData=[],n.int32Data=[],n.stringData=[],n.int64Data=[],n.doubleData=[],n.uint64Data=[],n.externalData=[]),e.defaults&&(n.dataType=0,n.segment=null,n.name=\"\",e.bytes===String?n.rawData=\"\":(n.rawData=[],e.bytes!==Array&&(n.rawData=c.newBuffer(n.rawData))),n.docString=\"\",n.dataLocation=e.enums===String?\"DEFAULT\":0),t.dims&&t.dims.length){n.dims=[];for(var r=0;r<t.dims.length;++r)\"number\"==typeof t.dims[r]?n.dims[r]=e.longs===String?String(t.dims[r]):t.dims[r]:n.dims[r]=e.longs===String?c.Long.prototype.toString.call(t.dims[r]):e.longs===Number?new c.LongBits(t.dims[r].low>>>0,t.dims[r].high>>>0).toNumber():t.dims[r]}if(null!=t.dataType&&t.hasOwnProperty(\"dataType\")&&(n.dataType=t.dataType),null!=t.segment&&t.hasOwnProperty(\"segment\")&&(n.segment=l.onnx.TensorProto.Segment.toObject(t.segment,e)),t.floatData&&t.floatData.length)for(n.floatData=[],r=0;r<t.floatData.length;++r)n.floatData[r]=e.json&&!isFinite(t.floatData[r])?String(t.floatData[r]):t.floatData[r];if(t.int32Data&&t.int32Data.length)for(n.int32Data=[],r=0;r<t.int32Data.length;++r)n.int32Data[r]=t.int32Data[r];if(t.stringData&&t.stringData.length)for(n.stringData=[],r=0;r<t.stringData.length;++r)n.stringData[r]=e.bytes===String?c.base64.encode(t.stringData[r],0,t.stringData[r].length):e.bytes===Array?Array.prototype.slice.call(t.stringData[r]):t.stringData[r];if(t.int64Data&&t.int64Data.length)for(n.int64Data=[],r=0;r<t.int64Data.length;++r)\"number\"==typeof t.int64Data[r]?n.int64Data[r]=e.longs===String?String(t.int64Data[r]):t.int64Data[r]:n.int64Data[r]=e.longs===String?c.Long.prototype.toString.call(t.int64Data[r]):e.longs===Number?new c.LongBits(t.int64Data[r].low>>>0,t.int64Data[r].high>>>0).toNumber():t.int64Data[r];if(null!=t.name&&t.hasOwnProperty(\"name\")&&(n.name=t.name),null!=t.rawData&&t.hasOwnProperty(\"rawData\")&&(n.rawData=e.bytes===String?c.base64.encode(t.rawData,0,t.rawData.length):e.bytes===Array?Array.prototype.slice.call(t.rawData):t.rawData),t.doubleData&&t.doubleData.length)for(n.doubleData=[],r=0;r<t.doubleData.length;++r)n.doubleData[r]=e.json&&!isFinite(t.doubleData[r])?String(t.doubleData[r]):t.doubleData[r];if(t.uint64Data&&t.uint64Data.length)for(n.uint64Data=[],r=0;r<t.uint64Data.length;++r)\"number\"==typeof t.uint64Data[r]?n.uint64Data[r]=e.longs===String?String(t.uint64Data[r]):t.uint64Data[r]:n.uint64Data[r]=e.longs===String?c.Long.prototype.toString.call(t.uint64Data[r]):e.longs===Number?new c.LongBits(t.uint64Data[r].low>>>0,t.uint64Data[r].high>>>0).toNumber(!0):t.uint64Data[r];if(null!=t.docString&&t.hasOwnProperty(\"docString\")&&(n.docString=t.docString),t.externalData&&t.externalData.length)for(n.externalData=[],r=0;r<t.externalData.length;++r)n.externalData[r]=l.onnx.StringStringEntryProto.toObject(t.externalData[r],e);return null!=t.dataLocation&&t.hasOwnProperty(\"dataLocation\")&&(n.dataLocation=e.enums===String?l.onnx.TensorProto.DataLocation[t.dataLocation]:t.dataLocation),n},t.prototype.toJSON=function(){return this.constructor.toObject(this,a.util.toJSONOptions)},t.DataType=function(){var t={},e=Object.create(t);return e[t[0]=\"UNDEFINED\"]=0,e[t[1]=\"FLOAT\"]=1,e[t[2]=\"UINT8\"]=2,e[t[3]=\"INT8\"]=3,e[t[4]=\"UINT16\"]=4,e[t[5]=\"INT16\"]=5,e[t[6]=\"INT32\"]=6,e[t[7]=\"INT64\"]=7,e[t[8]=\"STRING\"]=8,e[t[9]=\"BOOL\"]=9,e[t[10]=\"FLOAT16\"]=10,e[t[11]=\"DOUBLE\"]=11,e[t[12]=\"UINT32\"]=12,e[t[13]=\"UINT64\"]=13,e[t[14]=\"COMPLEX64\"]=14,e[t[15]=\"COMPLEX128\"]=15,e[t[16]=\"BFLOAT16\"]=16,e}(),t.Segment=function(){function t(t){if(t)for(var e=Object.keys(t),n=0;n<e.length;++n)null!=t[e[n]]&&(this[e[n]]=t[e[n]])}return t.prototype.begin=c.Long?c.Long.fromBits(0,0,!1):0,t.prototype.end=c.Long?c.Long.fromBits(0,0,!1):0,t.create=function(e){return new t(e)},t.encode=function(t,e){return e||(e=u.create()),null!=t.begin&&t.hasOwnProperty(\"begin\")&&e.uint32(8).int64(t.begin),null!=t.end&&t.hasOwnProperty(\"end\")&&e.uint32(16).int64(t.end),e},t.encodeDelimited=function(t,e){return this.encode(t,e).ldelim()},t.decode=function(t,e){t instanceof s||(t=s.create(t));for(var n=void 0===e?t.len:t.pos+e,r=new l.onnx.TensorProto.Segment;t.pos<n;){var i=t.uint32();switch(i>>>3){case 1:r.begin=t.int64();break;case 2:r.end=t.int64();break;default:t.skipType(7&i)}}return r},t.decodeDelimited=function(t){return t instanceof s||(t=new s(t)),this.decode(t,t.uint32())},t.verify=function(t){return\"object\"!=typeof t||null===t?\"object expected\":null!=t.begin&&t.hasOwnProperty(\"begin\")&&!(c.isInteger(t.begin)||t.begin&&c.isInteger(t.begin.low)&&c.isInteger(t.begin.high))?\"begin: integer|Long expected\":null!=t.end&&t.hasOwnProperty(\"end\")&&!(c.isInteger(t.end)||t.end&&c.isInteger(t.end.low)&&c.isInteger(t.end.high))?\"end: integer|Long expected\":null},t.fromObject=function(t){if(t instanceof l.onnx.TensorProto.Segment)return t;var e=new l.onnx.TensorProto.Segment;return null!=t.begin&&(c.Long?(e.begin=c.Long.fromValue(t.begin)).unsigned=!1:\"string\"==typeof t.begin?e.begin=parseInt(t.begin,10):\"number\"==typeof t.begin?e.begin=t.begin:\"object\"==typeof t.begin&&(e.begin=new c.LongBits(t.begin.low>>>0,t.begin.high>>>0).toNumber())),null!=t.end&&(c.Long?(e.end=c.Long.fromValue(t.end)).unsigned=!1:\"string\"==typeof t.end?e.end=parseInt(t.end,10):\"number\"==typeof t.end?e.end=t.end:\"object\"==typeof t.end&&(e.end=new c.LongBits(t.end.low>>>0,t.end.high>>>0).toNumber())),e},t.toObject=function(t,e){e||(e={});var n={};if(e.defaults){if(c.Long){var r=new c.Long(0,0,!1);n.begin=e.longs===String?r.toString():e.longs===Number?r.toNumber():r}else n.begin=e.longs===String?\"0\":0;c.Long?(r=new c.Long(0,0,!1),n.end=e.longs===String?r.toString():e.longs===Number?r.toNumber():r):n.end=e.longs===String?\"0\":0}return null!=t.begin&&t.hasOwnProperty(\"begin\")&&(\"number\"==typeof t.begin?n.begin=e.longs===String?String(t.begin):t.begin:n.begin=e.longs===String?c.Long.prototype.toString.call(t.begin):e.longs===Number?new c.LongBits(t.begin.low>>>0,t.begin.high>>>0).toNumber():t.begin),null!=t.end&&t.hasOwnProperty(\"end\")&&(\"number\"==typeof t.end?n.end=e.longs===String?String(t.end):t.end:n.end=e.longs===String?c.Long.prototype.toString.call(t.end):e.longs===Number?new c.LongBits(t.end.low>>>0,t.end.high>>>0).toNumber():t.end),n},t.prototype.toJSON=function(){return this.constructor.toObject(this,a.util.toJSONOptions)},t}(),t.DataLocation=function(){var t={},e=Object.create(t);return e[t[0]=\"DEFAULT\"]=0,e[t[1]=\"EXTERNAL\"]=1,e}(),t}(),o.TensorShapeProto=function(){function t(t){if(this.dim=[],t)for(var e=Object.keys(t),n=0;n<e.length;++n)null!=t[e[n]]&&(this[e[n]]=t[e[n]])}return t.prototype.dim=c.emptyArray,t.create=function(e){return new t(e)},t.encode=function(t,e){if(e||(e=u.create()),null!=t.dim&&t.dim.length)for(var n=0;n<t.dim.length;++n)l.onnx.TensorShapeProto.Dimension.encode(t.dim[n],e.uint32(10).fork()).ldelim();return e},t.encodeDelimited=function(t,e){return this.encode(t,e).ldelim()},t.decode=function(t,e){t instanceof s||(t=s.create(t));for(var n=void 0===e?t.len:t.pos+e,r=new l.onnx.TensorShapeProto;t.pos<n;){var i=t.uint32();i>>>3==1?(r.dim&&r.dim.length||(r.dim=[]),r.dim.push(l.onnx.TensorShapeProto.Dimension.decode(t,t.uint32()))):t.skipType(7&i)}return r},t.decodeDelimited=function(t){return t instanceof s||(t=new s(t)),this.decode(t,t.uint32())},t.verify=function(t){if(\"object\"!=typeof t||null===t)return\"object expected\";if(null!=t.dim&&t.hasOwnProperty(\"dim\")){if(!Array.isArray(t.dim))return\"dim: array expected\";for(var e=0;e<t.dim.length;++e){var n=l.onnx.TensorShapeProto.Dimension.verify(t.dim[e]);if(n)return\"dim.\"+n}}return null},t.fromObject=function(t){if(t instanceof l.onnx.TensorShapeProto)return t;var e=new l.onnx.TensorShapeProto;if(t.dim){if(!Array.isArray(t.dim))throw TypeError(\".onnx.TensorShapeProto.dim: array expected\");e.dim=[];for(var n=0;n<t.dim.length;++n){if(\"object\"!=typeof t.dim[n])throw TypeError(\".onnx.TensorShapeProto.dim: object expected\");e.dim[n]=l.onnx.TensorShapeProto.Dimension.fromObject(t.dim[n])}}return e},t.toObject=function(t,e){e||(e={});var n={};if((e.arrays||e.defaults)&&(n.dim=[]),t.dim&&t.dim.length){n.dim=[];for(var r=0;r<t.dim.length;++r)n.dim[r]=l.onnx.TensorShapeProto.Dimension.toObject(t.dim[r],e)}return n},t.prototype.toJSON=function(){return this.constructor.toObject(this,a.util.toJSONOptions)},t.Dimension=function(){function t(t){if(t)for(var e=Object.keys(t),n=0;n<e.length;++n)null!=t[e[n]]&&(this[e[n]]=t[e[n]])}var e;return t.prototype.dimValue=c.Long?c.Long.fromBits(0,0,!1):0,t.prototype.dimParam=\"\",t.prototype.denotation=\"\",Object.defineProperty(t.prototype,\"value\",{get:c.oneOfGetter(e=[\"dimValue\",\"dimParam\"]),set:c.oneOfSetter(e)}),t.create=function(e){return new t(e)},t.encode=function(t,e){return e||(e=u.create()),null!=t.dimValue&&t.hasOwnProperty(\"dimValue\")&&e.uint32(8).int64(t.dimValue),null!=t.dimParam&&t.hasOwnProperty(\"dimParam\")&&e.uint32(18).string(t.dimParam),null!=t.denotation&&t.hasOwnProperty(\"denotation\")&&e.uint32(26).string(t.denotation),e},t.encodeDelimited=function(t,e){return this.encode(t,e).ldelim()},t.decode=function(t,e){t instanceof s||(t=s.create(t));for(var n=void 0===e?t.len:t.pos+e,r=new l.onnx.TensorShapeProto.Dimension;t.pos<n;){var i=t.uint32();switch(i>>>3){case 1:r.dimValue=t.int64();break;case 2:r.dimParam=t.string();break;case 3:r.denotation=t.string();break;default:t.skipType(7&i)}}return r},t.decodeDelimited=function(t){return t instanceof s||(t=new s(t)),this.decode(t,t.uint32())},t.verify=function(t){if(\"object\"!=typeof t||null===t)return\"object expected\";var e={};if(null!=t.dimValue&&t.hasOwnProperty(\"dimValue\")&&(e.value=1,!(c.isInteger(t.dimValue)||t.dimValue&&c.isInteger(t.dimValue.low)&&c.isInteger(t.dimValue.high))))return\"dimValue: integer|Long expected\";if(null!=t.dimParam&&t.hasOwnProperty(\"dimParam\")){if(1===e.value)return\"value: multiple values\";if(e.value=1,!c.isString(t.dimParam))return\"dimParam: string expected\"}return null!=t.denotation&&t.hasOwnProperty(\"denotation\")&&!c.isString(t.denotation)?\"denotation: string expected\":null},t.fromObject=function(t){if(t instanceof l.onnx.TensorShapeProto.Dimension)return t;var e=new l.onnx.TensorShapeProto.Dimension;return null!=t.dimValue&&(c.Long?(e.dimValue=c.Long.fromValue(t.dimValue)).unsigned=!1:\"string\"==typeof t.dimValue?e.dimValue=parseInt(t.dimValue,10):\"number\"==typeof t.dimValue?e.dimValue=t.dimValue:\"object\"==typeof t.dimValue&&(e.dimValue=new c.LongBits(t.dimValue.low>>>0,t.dimValue.high>>>0).toNumber())),null!=t.dimParam&&(e.dimParam=String(t.dimParam)),null!=t.denotation&&(e.denotation=String(t.denotation)),e},t.toObject=function(t,e){e||(e={});var n={};return e.defaults&&(n.denotation=\"\"),null!=t.dimValue&&t.hasOwnProperty(\"dimValue\")&&(\"number\"==typeof t.dimValue?n.dimValue=e.longs===String?String(t.dimValue):t.dimValue:n.dimValue=e.longs===String?c.Long.prototype.toString.call(t.dimValue):e.longs===Number?new c.LongBits(t.dimValue.low>>>0,t.dimValue.high>>>0).toNumber():t.dimValue,e.oneofs&&(n.value=\"dimValue\")),null!=t.dimParam&&t.hasOwnProperty(\"dimParam\")&&(n.dimParam=t.dimParam,e.oneofs&&(n.value=\"dimParam\")),null!=t.denotation&&t.hasOwnProperty(\"denotation\")&&(n.denotation=t.denotation),n},t.prototype.toJSON=function(){return this.constructor.toObject(this,a.util.toJSONOptions)},t}(),t}(),o.TypeProto=function(){function t(t){if(t)for(var e=Object.keys(t),n=0;n<e.length;++n)null!=t[e[n]]&&(this[e[n]]=t[e[n]])}var e;return t.prototype.tensorType=null,t.prototype.denotation=\"\",Object.defineProperty(t.prototype,\"value\",{get:c.oneOfGetter(e=[\"tensorType\"]),set:c.oneOfSetter(e)}),t.create=function(e){return new t(e)},t.encode=function(t,e){return e||(e=u.create()),null!=t.tensorType&&t.hasOwnProperty(\"tensorType\")&&l.onnx.TypeProto.Tensor.encode(t.tensorType,e.uint32(10).fork()).ldelim(),null!=t.denotation&&t.hasOwnProperty(\"denotation\")&&e.uint32(50).string(t.denotation),e},t.encodeDelimited=function(t,e){return this.encode(t,e).ldelim()},t.decode=function(t,e){t instanceof s||(t=s.create(t));for(var n=void 0===e?t.len:t.pos+e,r=new l.onnx.TypeProto;t.pos<n;){var i=t.uint32();switch(i>>>3){case 1:r.tensorType=l.onnx.TypeProto.Tensor.decode(t,t.uint32());break;case 6:r.denotation=t.string();break;default:t.skipType(7&i)}}return r},t.decodeDelimited=function(t){return t instanceof s||(t=new s(t)),this.decode(t,t.uint32())},t.verify=function(t){if(\"object\"!=typeof t||null===t)return\"object expected\";if(null!=t.tensorType&&t.hasOwnProperty(\"tensorType\")){var e=l.onnx.TypeProto.Tensor.verify(t.tensorType);if(e)return\"tensorType.\"+e}return null!=t.denotation&&t.hasOwnProperty(\"denotation\")&&!c.isString(t.denotation)?\"denotation: string expected\":null},t.fromObject=function(t){if(t instanceof l.onnx.TypeProto)return t;var e=new l.onnx.TypeProto;if(null!=t.tensorType){if(\"object\"!=typeof t.tensorType)throw TypeError(\".onnx.TypeProto.tensorType: object expected\");e.tensorType=l.onnx.TypeProto.Tensor.fromObject(t.tensorType)}return null!=t.denotation&&(e.denotation=String(t.denotation)),e},t.toObject=function(t,e){e||(e={});var n={};return e.defaults&&(n.denotation=\"\"),null!=t.tensorType&&t.hasOwnProperty(\"tensorType\")&&(n.tensorType=l.onnx.TypeProto.Tensor.toObject(t.tensorType,e),e.oneofs&&(n.value=\"tensorType\")),null!=t.denotation&&t.hasOwnProperty(\"denotation\")&&(n.denotation=t.denotation),n},t.prototype.toJSON=function(){return this.constructor.toObject(this,a.util.toJSONOptions)},t.Tensor=function(){function t(t){if(t)for(var e=Object.keys(t),n=0;n<e.length;++n)null!=t[e[n]]&&(this[e[n]]=t[e[n]])}return t.prototype.elemType=0,t.prototype.shape=null,t.create=function(e){return new t(e)},t.encode=function(t,e){return e||(e=u.create()),null!=t.elemType&&t.hasOwnProperty(\"elemType\")&&e.uint32(8).int32(t.elemType),null!=t.shape&&t.hasOwnProperty(\"shape\")&&l.onnx.TensorShapeProto.encode(t.shape,e.uint32(18).fork()).ldelim(),e},t.encodeDelimited=function(t,e){return this.encode(t,e).ldelim()},t.decode=function(t,e){t instanceof s||(t=s.create(t));for(var n=void 0===e?t.len:t.pos+e,r=new l.onnx.TypeProto.Tensor;t.pos<n;){var i=t.uint32();switch(i>>>3){case 1:r.elemType=t.int32();break;case 2:r.shape=l.onnx.TensorShapeProto.decode(t,t.uint32());break;default:t.skipType(7&i)}}return r},t.decodeDelimited=function(t){return t instanceof s||(t=new s(t)),this.decode(t,t.uint32())},t.verify=function(t){if(\"object\"!=typeof t||null===t)return\"object expected\";if(null!=t.elemType&&t.hasOwnProperty(\"elemType\")&&!c.isInteger(t.elemType))return\"elemType: integer expected\";if(null!=t.shape&&t.hasOwnProperty(\"shape\")){var e=l.onnx.TensorShapeProto.verify(t.shape);if(e)return\"shape.\"+e}return null},t.fromObject=function(t){if(t instanceof l.onnx.TypeProto.Tensor)return t;var e=new l.onnx.TypeProto.Tensor;if(null!=t.elemType&&(e.elemType=0|t.elemType),null!=t.shape){if(\"object\"!=typeof t.shape)throw TypeError(\".onnx.TypeProto.Tensor.shape: object expected\");e.shape=l.onnx.TensorShapeProto.fromObject(t.shape)}return e},t.toObject=function(t,e){e||(e={});var n={};return e.defaults&&(n.elemType=0,n.shape=null),null!=t.elemType&&t.hasOwnProperty(\"elemType\")&&(n.elemType=t.elemType),null!=t.shape&&t.hasOwnProperty(\"shape\")&&(n.shape=l.onnx.TensorShapeProto.toObject(t.shape,e)),n},t.prototype.toJSON=function(){return this.constructor.toObject(this,a.util.toJSONOptions)},t}(),t}(),o.OperatorSetIdProto=function(){function t(t){if(t)for(var e=Object.keys(t),n=0;n<e.length;++n)null!=t[e[n]]&&(this[e[n]]=t[e[n]])}return t.prototype.domain=\"\",t.prototype.version=c.Long?c.Long.fromBits(0,0,!1):0,t.create=function(e){return new t(e)},t.encode=function(t,e){return e||(e=u.create()),null!=t.domain&&t.hasOwnProperty(\"domain\")&&e.uint32(10).string(t.domain),null!=t.version&&t.hasOwnProperty(\"version\")&&e.uint32(16).int64(t.version),e},t.encodeDelimited=function(t,e){return this.encode(t,e).ldelim()},t.decode=function(t,e){t instanceof s||(t=s.create(t));for(var n=void 0===e?t.len:t.pos+e,r=new l.onnx.OperatorSetIdProto;t.pos<n;){var i=t.uint32();switch(i>>>3){case 1:r.domain=t.string();break;case 2:r.version=t.int64();break;default:t.skipType(7&i)}}return r},t.decodeDelimited=function(t){return t instanceof s||(t=new s(t)),this.decode(t,t.uint32())},t.verify=function(t){return\"object\"!=typeof t||null===t?\"object expected\":null!=t.domain&&t.hasOwnProperty(\"domain\")&&!c.isString(t.domain)?\"domain: string expected\":null!=t.version&&t.hasOwnProperty(\"version\")&&!(c.isInteger(t.version)||t.version&&c.isInteger(t.version.low)&&c.isInteger(t.version.high))?\"version: integer|Long expected\":null},t.fromObject=function(t){if(t instanceof l.onnx.OperatorSetIdProto)return t;var e=new l.onnx.OperatorSetIdProto;return null!=t.domain&&(e.domain=String(t.domain)),null!=t.version&&(c.Long?(e.version=c.Long.fromValue(t.version)).unsigned=!1:\"string\"==typeof t.version?e.version=parseInt(t.version,10):\"number\"==typeof t.version?e.version=t.version:\"object\"==typeof t.version&&(e.version=new c.LongBits(t.version.low>>>0,t.version.high>>>0).toNumber())),e},t.toObject=function(t,e){e||(e={});var n={};if(e.defaults)if(n.domain=\"\",c.Long){var r=new c.Long(0,0,!1);n.version=e.longs===String?r.toString():e.longs===Number?r.toNumber():r}else n.version=e.longs===String?\"0\":0;return null!=t.domain&&t.hasOwnProperty(\"domain\")&&(n.domain=t.domain),null!=t.version&&t.hasOwnProperty(\"version\")&&(\"number\"==typeof t.version?n.version=e.longs===String?String(t.version):t.version:n.version=e.longs===String?c.Long.prototype.toString.call(t.version):e.longs===Number?new c.LongBits(t.version.low>>>0,t.version.high>>>0).toNumber():t.version),n},t.prototype.toJSON=function(){return this.constructor.toObject(this,a.util.toJSONOptions)},t}(),o),t.exports=l},2100:(t,e,n)=>{\"use strict\";t.exports=n(9482)},9482:(t,e,n)=>{\"use strict\";var r=e;function i(){r.util._configure(),r.Writer._configure(r.BufferWriter),r.Reader._configure(r.BufferReader)}r.build=\"minimal\",r.Writer=n(1173),r.BufferWriter=n(3155),r.Reader=n(1408),r.BufferReader=n(593),r.util=n(9693),r.rpc=n(5994),r.roots=n(5054),r.configure=i,i()},1408:(t,e,n)=>{\"use strict\";t.exports=u;var r,i=n(9693),o=i.LongBits,a=i.utf8;function s(t,e){return RangeError(\"index out of range: \"+t.pos+\" + \"+(e||1)+\" > \"+t.len)}function u(t){this.buf=t,this.pos=0,this.len=t.length}var c,l=\"undefined\"!=typeof Uint8Array?function(t){if(t instanceof Uint8Array||Array.isArray(t))return new u(t);throw Error(\"illegal buffer\")}:function(t){if(Array.isArray(t))return new u(t);throw Error(\"illegal buffer\")},p=function(){return i.Buffer?function(t){return(u.create=function(t){return i.Buffer.isBuffer(t)?new r(t):l(t)})(t)}:l};function f(){var t=new o(0,0),e=0;if(!(this.len-this.pos>4)){for(;e<3;++e){if(this.pos>=this.len)throw s(this);if(t.lo=(t.lo|(127&this.buf[this.pos])<<7*e)>>>0,this.buf[this.pos++]<128)return t}return t.lo=(t.lo|(127&this.buf[this.pos++])<<7*e)>>>0,t}for(;e<4;++e)if(t.lo=(t.lo|(127&this.buf[this.pos])<<7*e)>>>0,this.buf[this.pos++]<128)return t;if(t.lo=(t.lo|(127&this.buf[this.pos])<<28)>>>0,t.hi=(t.hi|(127&this.buf[this.pos])>>4)>>>0,this.buf[this.pos++]<128)return t;if(e=0,this.len-this.pos>4){for(;e<5;++e)if(t.hi=(t.hi|(127&this.buf[this.pos])<<7*e+3)>>>0,this.buf[this.pos++]<128)return t}else for(;e<5;++e){if(this.pos>=this.len)throw s(this);if(t.hi=(t.hi|(127&this.buf[this.pos])<<7*e+3)>>>0,this.buf[this.pos++]<128)return t}throw Error(\"invalid varint encoding\")}function d(t,e){return(t[e-4]|t[e-3]<<8|t[e-2]<<16|t[e-1]<<24)>>>0}function h(){if(this.pos+8>this.len)throw s(this,8);return new o(d(this.buf,this.pos+=4),d(this.buf,this.pos+=4))}u.create=p(),u.prototype._slice=i.Array.prototype.subarray||i.Array.prototype.slice,u.prototype.uint32=(c=4294967295,function(){if(c=(127&this.buf[this.pos])>>>0,this.buf[this.pos++]<128)return c;if(c=(c|(127&this.buf[this.pos])<<7)>>>0,this.buf[this.pos++]<128)return c;if(c=(c|(127&this.buf[this.pos])<<14)>>>0,this.buf[this.pos++]<128)return c;if(c=(c|(127&this.buf[this.pos])<<21)>>>0,this.buf[this.pos++]<128)return c;if(c=(c|(15&this.buf[this.pos])<<28)>>>0,this.buf[this.pos++]<128)return c;if((this.pos+=5)>this.len)throw this.pos=this.len,s(this,10);return c}),u.prototype.int32=function(){return 0|this.uint32()},u.prototype.sint32=function(){var t=this.uint32();return t>>>1^-(1&t)|0},u.prototype.bool=function(){return 0!==this.uint32()},u.prototype.fixed32=function(){if(this.pos+4>this.len)throw s(this,4);return d(this.buf,this.pos+=4)},u.prototype.sfixed32=function(){if(this.pos+4>this.len)throw s(this,4);return 0|d(this.buf,this.pos+=4)},u.prototype.float=function(){if(this.pos+4>this.len)throw s(this,4);var t=i.float.readFloatLE(this.buf,this.pos);return this.pos+=4,t},u.prototype.double=function(){if(this.pos+8>this.len)throw s(this,4);var t=i.float.readDoubleLE(this.buf,this.pos);return this.pos+=8,t},u.prototype.bytes=function(){var t=this.uint32(),e=this.pos,n=this.pos+t;if(n>this.len)throw s(this,t);return this.pos+=t,Array.isArray(this.buf)?this.buf.slice(e,n):e===n?new this.buf.constructor(0):this._slice.call(this.buf,e,n)},u.prototype.string=function(){var t=this.bytes();return a.read(t,0,t.length)},u.prototype.skip=function(t){if(\"number\"==typeof t){if(this.pos+t>this.len)throw s(this,t);this.pos+=t}else do{if(this.pos>=this.len)throw s(this)}while(128&this.buf[this.pos++]);return this},u.prototype.skipType=function(t){switch(t){case 0:this.skip();break;case 1:this.skip(8);break;case 2:this.skip(this.uint32());break;case 3:for(;4!=(t=7&this.uint32());)this.skipType(t);break;case 5:this.skip(4);break;default:throw Error(\"invalid wire type \"+t+\" at offset \"+this.pos)}return this},u._configure=function(t){r=t,u.create=p(),r._configure();var e=i.Long?\"toLong\":\"toNumber\";i.merge(u.prototype,{int64:function(){return f.call(this)[e](!1)},uint64:function(){return f.call(this)[e](!0)},sint64:function(){return f.call(this).zzDecode()[e](!1)},fixed64:function(){return h.call(this)[e](!0)},sfixed64:function(){return h.call(this)[e](!1)}})}},593:(t,e,n)=>{\"use strict\";t.exports=o;var r=n(1408);(o.prototype=Object.create(r.prototype)).constructor=o;var i=n(9693);function o(t){r.call(this,t)}o._configure=function(){i.Buffer&&(o.prototype._slice=i.Buffer.prototype.slice)},o.prototype.string=function(){var t=this.uint32();return this.buf.utf8Slice?this.buf.utf8Slice(this.pos,this.pos=Math.min(this.pos+t,this.len)):this.buf.toString(\"utf-8\",this.pos,this.pos=Math.min(this.pos+t,this.len))},o._configure()},5054:t=>{\"use strict\";t.exports={}},5994:(t,e,n)=>{\"use strict\";e.Service=n(7948)},7948:(t,e,n)=>{\"use strict\";t.exports=i;var r=n(9693);function i(t,e,n){if(\"function\"!=typeof t)throw TypeError(\"rpcImpl must be a function\");r.EventEmitter.call(this),this.rpcImpl=t,this.requestDelimited=Boolean(e),this.responseDelimited=Boolean(n)}(i.prototype=Object.create(r.EventEmitter.prototype)).constructor=i,i.prototype.rpcCall=function t(e,n,i,o,a){if(!o)throw TypeError(\"request must be specified\");var s=this;if(!a)return r.asPromise(t,s,e,n,i,o);if(s.rpcImpl)try{return s.rpcImpl(e,n[s.requestDelimited?\"encodeDelimited\":\"encode\"](o).finish(),(function(t,n){if(t)return s.emit(\"error\",t,e),a(t);if(null!==n){if(!(n instanceof i))try{n=i[s.responseDelimited?\"decodeDelimited\":\"decode\"](n)}catch(t){return s.emit(\"error\",t,e),a(t)}return s.emit(\"data\",n,e),a(null,n)}s.end(!0)}))}catch(t){return s.emit(\"error\",t,e),void setTimeout((function(){a(t)}),0)}else setTimeout((function(){a(Error(\"already ended\"))}),0)},i.prototype.end=function(t){return this.rpcImpl&&(t||this.rpcImpl(null,null,null),this.rpcImpl=null,this.emit(\"end\").off()),this}},1945:(t,e,n)=>{\"use strict\";t.exports=i;var r=n(9693);function i(t,e){this.lo=t>>>0,this.hi=e>>>0}var o=i.zero=new i(0,0);o.toNumber=function(){return 0},o.zzEncode=o.zzDecode=function(){return this},o.length=function(){return 1};var a=i.zeroHash=\"\\0\\0\\0\\0\\0\\0\\0\\0\";i.fromNumber=function(t){if(0===t)return o;var e=t<0;e&&(t=-t);var n=t>>>0,r=(t-n)/4294967296>>>0;return e&&(r=~r>>>0,n=~n>>>0,++n>4294967295&&(n=0,++r>4294967295&&(r=0))),new i(n,r)},i.from=function(t){if(\"number\"==typeof t)return i.fromNumber(t);if(r.isString(t)){if(!r.Long)return i.fromNumber(parseInt(t,10));t=r.Long.fromString(t)}return t.low||t.high?new i(t.low>>>0,t.high>>>0):o},i.prototype.toNumber=function(t){if(!t&&this.hi>>>31){var e=1+~this.lo>>>0,n=~this.hi>>>0;return e||(n=n+1>>>0),-(e+4294967296*n)}return this.lo+4294967296*this.hi},i.prototype.toLong=function(t){return r.Long?new r.Long(0|this.lo,0|this.hi,Boolean(t)):{low:0|this.lo,high:0|this.hi,unsigned:Boolean(t)}};var s=String.prototype.charCodeAt;i.fromHash=function(t){return t===a?o:new i((s.call(t,0)|s.call(t,1)<<8|s.call(t,2)<<16|s.call(t,3)<<24)>>>0,(s.call(t,4)|s.call(t,5)<<8|s.call(t,6)<<16|s.call(t,7)<<24)>>>0)},i.prototype.toHash=function(){return String.fromCharCode(255&this.lo,this.lo>>>8&255,this.lo>>>16&255,this.lo>>>24,255&this.hi,this.hi>>>8&255,this.hi>>>16&255,this.hi>>>24)},i.prototype.zzEncode=function(){var t=this.hi>>31;return this.hi=((this.hi<<1|this.lo>>>31)^t)>>>0,this.lo=(this.lo<<1^t)>>>0,this},i.prototype.zzDecode=function(){var t=-(1&this.lo);return this.lo=((this.lo>>>1|this.hi<<31)^t)>>>0,this.hi=(this.hi>>>1^t)>>>0,this},i.prototype.length=function(){var t=this.lo,e=(this.lo>>>28|this.hi<<4)>>>0,n=this.hi>>>24;return 0===n?0===e?t<16384?t<128?1:2:t<2097152?3:4:e<16384?e<128?5:6:e<2097152?7:8:n<128?9:10}},9693:function(t,e,n){\"use strict\";var r=e;function i(t,e,n){for(var r=Object.keys(e),i=0;i<r.length;++i)void 0!==t[r[i]]&&n||(t[r[i]]=e[r[i]]);return t}function o(t){function e(t,n){if(!(this instanceof e))return new e(t,n);Object.defineProperty(this,\"message\",{get:function(){return t}}),Error.captureStackTrace?Error.captureStackTrace(this,e):Object.defineProperty(this,\"stack\",{value:(new Error).stack||\"\"}),n&&i(this,n)}return(e.prototype=Object.create(Error.prototype)).constructor=e,Object.defineProperty(e.prototype,\"name\",{get:function(){return t}}),e.prototype.toString=function(){return this.name+\": \"+this.message},e}r.asPromise=n(4537),r.base64=n(7419),r.EventEmitter=n(9211),r.float=n(945),r.inquire=n(7199),r.utf8=n(4997),r.pool=n(6662),r.LongBits=n(1945),r.isNode=Boolean(void 0!==n.g&&n.g&&n.g.process&&n.g.process.versions&&n.g.process.versions.node),r.global=r.isNode&&n.g||\"undefined\"!=typeof window&&window||\"undefined\"!=typeof self&&self||this,r.emptyArray=Object.freeze?Object.freeze([]):[],r.emptyObject=Object.freeze?Object.freeze({}):{},r.isInteger=Number.isInteger||function(t){return\"number\"==typeof t&&isFinite(t)&&Math.floor(t)===t},r.isString=function(t){return\"string\"==typeof t||t instanceof String},r.isObject=function(t){return t&&\"object\"==typeof t},r.isset=r.isSet=function(t,e){var n=t[e];return!(null==n||!t.hasOwnProperty(e))&&(\"object\"!=typeof n||(Array.isArray(n)?n.length:Object.keys(n).length)>0)},r.Buffer=function(){try{var t=r.inquire(\"buffer\").Buffer;return t.prototype.utf8Write?t:null}catch(t){return null}}(),r._Buffer_from=null,r._Buffer_allocUnsafe=null,r.newBuffer=function(t){return\"number\"==typeof t?r.Buffer?r._Buffer_allocUnsafe(t):new r.Array(t):r.Buffer?r._Buffer_from(t):\"undefined\"==typeof Uint8Array?t:new Uint8Array(t)},r.Array=\"undefined\"!=typeof Uint8Array?Uint8Array:Array,r.Long=r.global.dcodeIO&&r.global.dcodeIO.Long||r.global.Long||r.inquire(\"long\"),r.key2Re=/^true|false|0|1$/,r.key32Re=/^-?(?:0|[1-9][0-9]*)$/,r.key64Re=/^(?:[\\\\x00-\\\\xff]{8}|-?(?:0|[1-9][0-9]*))$/,r.longToHash=function(t){return t?r.LongBits.from(t).toHash():r.LongBits.zeroHash},r.longFromHash=function(t,e){var n=r.LongBits.fromHash(t);return r.Long?r.Long.fromBits(n.lo,n.hi,e):n.toNumber(Boolean(e))},r.merge=i,r.lcFirst=function(t){return t.charAt(0).toLowerCase()+t.substring(1)},r.newError=o,r.ProtocolError=o(\"ProtocolError\"),r.oneOfGetter=function(t){for(var e={},n=0;n<t.length;++n)e[t[n]]=1;return function(){for(var t=Object.keys(this),n=t.length-1;n>-1;--n)if(1===e[t[n]]&&void 0!==this[t[n]]&&null!==this[t[n]])return t[n]}},r.oneOfSetter=function(t){return function(e){for(var n=0;n<t.length;++n)t[n]!==e&&delete this[t[n]]}},r.toJSONOptions={longs:String,enums:String,bytes:String,json:!0},r._configure=function(){var t=r.Buffer;t?(r._Buffer_from=t.from!==Uint8Array.from&&t.from||function(e,n){return new t(e,n)},r._Buffer_allocUnsafe=t.allocUnsafe||function(e){return new t(e)}):r._Buffer_from=r._Buffer_allocUnsafe=null}},1173:(t,e,n)=>{\"use strict\";t.exports=p;var r,i=n(9693),o=i.LongBits,a=i.base64,s=i.utf8;function u(t,e,n){this.fn=t,this.len=e,this.next=void 0,this.val=n}function c(){}function l(t){this.head=t.head,this.tail=t.tail,this.len=t.len,this.next=t.states}function p(){this.len=0,this.head=new u(c,0,0),this.tail=this.head,this.states=null}var f=function(){return i.Buffer?function(){return(p.create=function(){return new r})()}:function(){return new p}};function d(t,e,n){e[n]=255&t}function h(t,e){this.len=t,this.next=void 0,this.val=e}function g(t,e,n){for(;t.hi;)e[n++]=127&t.lo|128,t.lo=(t.lo>>>7|t.hi<<25)>>>0,t.hi>>>=7;for(;t.lo>127;)e[n++]=127&t.lo|128,t.lo=t.lo>>>7;e[n++]=t.lo}function b(t,e,n){e[n]=255&t,e[n+1]=t>>>8&255,e[n+2]=t>>>16&255,e[n+3]=t>>>24}p.create=f(),p.alloc=function(t){return new i.Array(t)},i.Array!==Array&&(p.alloc=i.pool(p.alloc,i.Array.prototype.subarray)),p.prototype._push=function(t,e,n){return this.tail=this.tail.next=new u(t,e,n),this.len+=e,this},h.prototype=Object.create(u.prototype),h.prototype.fn=function(t,e,n){for(;t>127;)e[n++]=127&t|128,t>>>=7;e[n]=t},p.prototype.uint32=function(t){return this.len+=(this.tail=this.tail.next=new h((t>>>=0)<128?1:t<16384?2:t<2097152?3:t<268435456?4:5,t)).len,this},p.prototype.int32=function(t){return t<0?this._push(g,10,o.fromNumber(t)):this.uint32(t)},p.prototype.sint32=function(t){return this.uint32((t<<1^t>>31)>>>0)},p.prototype.uint64=function(t){var e=o.from(t);return this._push(g,e.length(),e)},p.prototype.int64=p.prototype.uint64,p.prototype.sint64=function(t){var e=o.from(t).zzEncode();return this._push(g,e.length(),e)},p.prototype.bool=function(t){return this._push(d,1,t?1:0)},p.prototype.fixed32=function(t){return this._push(b,4,t>>>0)},p.prototype.sfixed32=p.prototype.fixed32,p.prototype.fixed64=function(t){var e=o.from(t);return this._push(b,4,e.lo)._push(b,4,e.hi)},p.prototype.sfixed64=p.prototype.fixed64,p.prototype.float=function(t){return this._push(i.float.writeFloatLE,4,t)},p.prototype.double=function(t){return this._push(i.float.writeDoubleLE,8,t)};var m=i.Array.prototype.set?function(t,e,n){e.set(t,n)}:function(t,e,n){for(var r=0;r<t.length;++r)e[n+r]=t[r]};p.prototype.bytes=function(t){var e=t.length>>>0;if(!e)return this._push(d,1,0);if(i.isString(t)){var n=p.alloc(e=a.length(t));a.decode(t,n,0),t=n}return this.uint32(e)._push(m,e,t)},p.prototype.string=function(t){var e=s.length(t);return e?this.uint32(e)._push(s.write,e,t):this._push(d,1,0)},p.prototype.fork=function(){return this.states=new l(this),this.head=this.tail=new u(c,0,0),this.len=0,this},p.prototype.reset=function(){return this.states?(this.head=this.states.head,this.tail=this.states.tail,this.len=this.states.len,this.states=this.states.next):(this.head=this.tail=new u(c,0,0),this.len=0),this},p.prototype.ldelim=function(){var t=this.head,e=this.tail,n=this.len;return this.reset().uint32(n),n&&(this.tail.next=t.next,this.tail=e,this.len+=n),this},p.prototype.finish=function(){for(var t=this.head.next,e=this.constructor.alloc(this.len),n=0;t;)t.fn(t.val,e,n),n+=t.len,t=t.next;return e},p._configure=function(t){r=t,p.create=f(),r._configure()}},3155:(t,e,n)=>{\"use strict\";t.exports=o;var r=n(1173);(o.prototype=Object.create(r.prototype)).constructor=o;var i=n(9693);function o(){r.call(this)}function a(t,e,n){t.length<40?i.utf8.write(t,e,n):e.utf8Write?e.utf8Write(t,n):e.write(t,n)}o._configure=function(){o.alloc=i._Buffer_allocUnsafe,o.writeBytesBuffer=i.Buffer&&i.Buffer.prototype instanceof Uint8Array&&\"set\"===i.Buffer.prototype.set.name?function(t,e,n){e.set(t,n)}:function(t,e,n){if(t.copy)t.copy(e,n,0,t.length);else for(var r=0;r<t.length;)e[n++]=t[r++]}},o.prototype.bytes=function(t){i.isString(t)&&(t=i._Buffer_from(t,\"base64\"));var e=t.length>>>0;return this.uint32(e),e&&this._push(o.writeBytesBuffer,e,t),this},o.prototype.string=function(t){var e=i.Buffer.byteLength(t);return this.uint32(e),e&&this._push(a,e,t),this},o._configure()},7714:(t,e,n)=>{\"use strict\";e.R=void 0;const r=n(6919),i=n(7448);e.R=new class{async init(){}async createSessionHandler(t,e){const n=new r.Session(e);return await n.loadModel(t),new i.OnnxjsSessionHandler(n)}}},4200:(t,e,n)=>{\"use strict\";e.c8=e.rX=void 0;const r=n(1670),i=n(5381),o=n(2157),a=n(2306);e.rX=()=>{if((\"number\"!=typeof r.env.wasm.initTimeout||r.env.wasm.initTimeout<0)&&(r.env.wasm.initTimeout=0),\"boolean\"!=typeof r.env.wasm.simd&&(r.env.wasm.simd=!0),\"boolean\"!=typeof r.env.wasm.proxy&&(r.env.wasm.proxy=!1),\"number\"!=typeof r.env.wasm.numThreads||!Number.isInteger(r.env.wasm.numThreads)||r.env.wasm.numThreads<=0){const t=\"undefined\"==typeof navigator?(0,i.cpus)().length:navigator.hardwareConcurrency;r.env.wasm.numThreads=Math.min(4,Math.ceil((t||1)/2))}},e.c8=new class{async init(){(0,e.rX)(),await(0,o.initWasm)()}async createSessionHandler(t,e){const n=new a.OnnxruntimeWebAssemblySessionHandler;return await n.loadModel(t,e),Promise.resolve(n)}}},6018:function(t,e,n){\"use strict\";var r=this&&this.__createBinding||(Object.create?function(t,e,n,r){void 0===r&&(r=n);var i=Object.getOwnPropertyDescriptor(e,n);i&&!(\"get\"in i?!e.__esModule:i.writable||i.configurable)||(i={enumerable:!0,get:function(){return e[n]}}),Object.defineProperty(t,r,i)}:function(t,e,n,r){void 0===r&&(r=n),t[r]=e[n]}),i=this&&this.__exportStar||function(t,e){for(var n in t)\"default\"===n||Object.prototype.hasOwnProperty.call(e,n)||r(e,t,n)};Object.defineProperty(e,\"__esModule\",{value:!0}),i(n(1670),e);const o=n(1670);{const t=n(7714).R;(0,o.registerBackend)(\"webgl\",t,-10)}{const t=n(4200).c8;(0,o.registerBackend)(\"cpu\",t,10),(0,o.registerBackend)(\"wasm\",t,10),(0,o.registerBackend)(\"xnnpack\",t,9)}},246:(t,e)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.createAttributeWithCacheKey=void 0;class n{constructor(t){Object.assign(this,t)}get cacheKey(){return this._cacheKey||(this._cacheKey=Object.getOwnPropertyNames(this).sort().map((t=>`${this[t]}`)).join(\";\")),this._cacheKey}}e.createAttributeWithCacheKey=t=>new n(t)},7778:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.Attribute=void 0;const r=n(1446),i=n(9395),o=n(9162),a=n(2517);var s=i.onnxruntime.experimental.fbs;class u{constructor(t){if(this._attributes=new Map,null!=t){for(const e of t)e instanceof r.onnx.AttributeProto?this._attributes.set(e.name,[u.getValue(e),u.getType(e)]):e instanceof s.Attribute&&this._attributes.set(e.name(),[u.getValue(e),u.getType(e)]);if(this._attributes.size<t.length)throw new Error(\"duplicated attribute names\")}}set(t,e,n){this._attributes.set(t,[n,e])}delete(t){this._attributes.delete(t)}getFloat(t,e){return this.get(t,\"float\",e)}getInt(t,e){return this.get(t,\"int\",e)}getString(t,e){return this.get(t,\"string\",e)}getTensor(t,e){return this.get(t,\"tensor\",e)}getFloats(t,e){return this.get(t,\"floats\",e)}getInts(t,e){return this.get(t,\"ints\",e)}getStrings(t,e){return this.get(t,\"strings\",e)}getTensors(t,e){return this.get(t,\"tensors\",e)}get(t,e,n){const r=this._attributes.get(t);if(void 0===r){if(void 0!==n)return n;throw new Error(`required attribute not found: ${t}`)}if(r[1]!==e)throw new Error(`type mismatch: expected ${e} but got ${r[1]}`);return r[0]}static getType(t){const e=t instanceof r.onnx.AttributeProto?t.type:t.type();switch(e){case r.onnx.AttributeProto.AttributeType.FLOAT:return\"float\";case r.onnx.AttributeProto.AttributeType.INT:return\"int\";case r.onnx.AttributeProto.AttributeType.STRING:return\"string\";case r.onnx.AttributeProto.AttributeType.TENSOR:return\"tensor\";case r.onnx.AttributeProto.AttributeType.FLOATS:return\"floats\";case r.onnx.AttributeProto.AttributeType.INTS:return\"ints\";case r.onnx.AttributeProto.AttributeType.STRINGS:return\"strings\";case r.onnx.AttributeProto.AttributeType.TENSORS:return\"tensors\";default:throw new Error(`attribute type is not supported yet: ${r.onnx.AttributeProto.AttributeType[e]}`)}}static getValue(t){const e=t instanceof r.onnx.AttributeProto?t.type:t.type();if(e===r.onnx.AttributeProto.AttributeType.GRAPH||e===r.onnx.AttributeProto.AttributeType.GRAPHS)throw new Error(\"graph attribute is not supported yet\");const n=this.getValueNoCheck(t);if(e===r.onnx.AttributeProto.AttributeType.INT&&a.LongUtil.isLong(n))return a.LongUtil.longToNumber(n);if(e===r.onnx.AttributeProto.AttributeType.INTS){const t=n,e=new Array(t.length);for(let n=0;n<t.length;n++){const r=t[n];e[n]=a.LongUtil.longToNumber(r)}return e}if(e===r.onnx.AttributeProto.AttributeType.TENSOR)return t instanceof r.onnx.AttributeProto?o.Tensor.fromProto(n):o.Tensor.fromOrtTensor(n);if(e===r.onnx.AttributeProto.AttributeType.TENSORS){if(t instanceof r.onnx.AttributeProto)return n.map((t=>o.Tensor.fromProto(t)));if(t instanceof s.Attribute)return n.map((t=>o.Tensor.fromOrtTensor(t)))}if(e===r.onnx.AttributeProto.AttributeType.STRING&&t instanceof r.onnx.AttributeProto){const t=n;return(0,a.decodeUtf8String)(t)}return e===r.onnx.AttributeProto.AttributeType.STRINGS&&t instanceof r.onnx.AttributeProto?n.map(a.decodeUtf8String):n}static getValueNoCheck(t){return t instanceof r.onnx.AttributeProto?this.getValueNoCheckFromOnnxFormat(t):this.getValueNoCheckFromOrtFormat(t)}static getValueNoCheckFromOnnxFormat(t){switch(t.type){case r.onnx.AttributeProto.AttributeType.FLOAT:return t.f;case r.onnx.AttributeProto.AttributeType.INT:return t.i;case r.onnx.AttributeProto.AttributeType.STRING:return t.s;case r.onnx.AttributeProto.AttributeType.TENSOR:return t.t;case r.onnx.AttributeProto.AttributeType.GRAPH:return t.g;case r.onnx.AttributeProto.AttributeType.FLOATS:return t.floats;case r.onnx.AttributeProto.AttributeType.INTS:return t.ints;case r.onnx.AttributeProto.AttributeType.STRINGS:return t.strings;case r.onnx.AttributeProto.AttributeType.TENSORS:return t.tensors;case r.onnx.AttributeProto.AttributeType.GRAPHS:return t.graphs;default:throw new Error(`unsupported attribute type: ${r.onnx.AttributeProto.AttributeType[t.type]}`)}}static getValueNoCheckFromOrtFormat(t){switch(t.type()){case s.AttributeType.FLOAT:return t.f();case s.AttributeType.INT:return t.i();case s.AttributeType.STRING:return t.s();case s.AttributeType.TENSOR:return t.t();case s.AttributeType.GRAPH:return t.g();case s.AttributeType.FLOATS:return t.floatsArray();case s.AttributeType.INTS:{const e=[];for(let n=0;n<t.intsLength();n++)e.push(t.ints(n));return e}case s.AttributeType.STRINGS:{const e=[];for(let n=0;n<t.stringsLength();n++)e.push(t.strings(n));return e}case s.AttributeType.TENSORS:{const e=[];for(let n=0;n<t.tensorsLength();n++)e.push(t.tensors(n));return e}default:throw new Error(`unsupported attribute type: ${s.AttributeType[t.type()]}`)}}}e.Attribute=u},7091:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.resolveBackend=e.backend=void 0;const r=n(5038),i=new Map;async function o(t){const n=e.backend;if(void 0!==n[t]&&function(t){const e=t;return\"initialize\"in e&&\"function\"==typeof e.initialize&&\"createSessionHandler\"in e&&\"function\"==typeof e.createSessionHandler&&\"dispose\"in e&&\"function\"==typeof e.dispose}(n[t])){const e=n[t];let r=e.initialize();if(\"object\"==typeof r&&\"then\"in r&&(r=await r),r)return i.set(t,e),e}}e.backend={webgl:new r.WebGLBackend},e.resolveBackend=async function t(e){if(!e)return t([\"webgl\"]);{const t=\"string\"==typeof e?[e]:e;for(const e of t){const t=i.get(e);if(t)return t;const n=await o(e);if(n)return n}}throw new Error(\"no available backend to use\")}},5038:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.WebGLBackend=void 0;const r=n(1670),i=n(6231),o=n(6416),a=n(7305);e.WebGLBackend=class{get contextId(){return r.env.webgl.contextId}set contextId(t){r.env.webgl.contextId=t}get matmulMaxBatchSize(){return r.env.webgl.matmulMaxBatchSize}set matmulMaxBatchSize(t){r.env.webgl.matmulMaxBatchSize=t}get textureCacheMode(){return r.env.webgl.textureCacheMode}set textureCacheMode(t){r.env.webgl.textureCacheMode=t}get pack(){return r.env.webgl.pack}set pack(t){r.env.webgl.pack=t}get async(){return r.env.webgl.async}set async(t){r.env.webgl.async=t}initialize(){try{return this.glContext=(0,a.createWebGLContext)(this.contextId),\"number\"!=typeof this.matmulMaxBatchSize&&(this.matmulMaxBatchSize=16),\"string\"!=typeof this.textureCacheMode&&(this.textureCacheMode=\"full\"),\"boolean\"!=typeof this.pack&&(this.pack=!1),\"boolean\"!=typeof this.async&&(this.async=!1),i.Logger.setWithEnv(r.env),i.Logger.verbose(\"WebGLBackend\",`Created WebGLContext: ${typeof this.glContext} with matmulMaxBatchSize: ${this.matmulMaxBatchSize}; textureCacheMode: ${this.textureCacheMode}; pack: ${this.pack}; async: ${this.async}.`),!0}catch(t){return i.Logger.warning(\"WebGLBackend\",`Unable to initialize WebGLBackend. ${t}`),!1}}createSessionHandler(t){return new o.WebGLSessionHandler(this,t)}dispose(){this.glContext.dispose()}}},5107:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.CoordsGlslLib=void 0;const r=n(2517),i=n(8520),o=n(5060),a=n(7859),s=n(9390);class u extends i.GlslLib{constructor(t){super(t)}getFunctions(){return Object.assign(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign({},this.offsetToCoords()),this.coordsToOffset()),this.toVec()),this.valueFrom()),this.getCommonUtilFuncs()),this.getInputsSamplingSnippets()),this.getOutputSamplingSnippet())}getCustomTypes(){return{}}offsetToCoords(){return{offsetToCoords:new i.GlslLibRoutine(\"\\n      vec2 offsetToCoords(int offset, int width, int height) {\\n        int t = offset / width;\\n        int s = offset - t*width;\\n        vec2 coords = (vec2(s,t) + vec2(0.5,0.5)) / vec2(width, height);\\n        return coords;\\n      }\\n      \")}}coordsToOffset(){return{coordsToOffset:new i.GlslLibRoutine(\"\\n      int coordsToOffset(vec2 coords, int width, int height) {\\n        float s = coords.s * float(width);\\n        float t = coords.t * float(height);\\n        int offset = int(t) * width + int(s);\\n        return offset;\\n      }\\n      \")}}getOutputSamplingSnippet(){const t=this.context.outputTextureLayout;return t.isPacked?this.getPackedOutputSamplingSnippet(t):this.getUnpackedOutputSamplingSnippet(t)}getPackedOutputSamplingSnippet(t){const e=t.unpackedShape,n=[t.width,t.height],r={},a=\"getOutputCoords\";switch(e.length){case 0:r[a]=this.getOutputScalarCoords();break;case 1:r[a]=this.getOutputPacked1DCoords(e,n);break;case 2:r[a]=this.getOutputPacked2DCoords(e,n);break;case 3:r[a]=this.getOutputPacked3DCoords(e,n);break;default:r[a]=this.getOutputPackedNDCoords(e,n)}const s=`\\n      void setOutput(vec4 val) {\\n        ${(0,o.getGlsl)(this.context.glContext.version).output} = val;\\n      }\\n    `;return r.floatTextureSetRGBA=new i.GlslLibRoutine(s),r}getUnpackedOutputSamplingSnippet(t){const e=t.unpackedShape,n=[t.width,t.height],r={},a=\"getOutputCoords\";switch(e.length){case 0:r[a]=this.getOutputScalarCoords();break;case 1:r[a]=this.getOutputUnpacked1DCoords(e,n);break;case 2:r[a]=this.getOutputUnpacked2DCoords(e,n);break;case 3:r[a]=this.getOutputUnpacked3DCoords(e,n);break;case 4:r[a]=this.getOutputUnpacked4DCoords(e,n);break;case 5:r[a]=this.getOutputUnpacked5DCoords(e,n);break;case 6:r[a]=this.getOutputUnpacked6DCoords(e,n);break;default:throw new Error(`Unsupported output dimensionality: ${e.length}`)}const s=`\\n        void setOutput(float val) {\\n          ${(0,o.getGlsl)(this.context.glContext.version).output} = vec4(val, 0, 0, 0);\\n        }\\n    `;return r.floatTextureSetR=new i.GlslLibRoutine(s),r}getOutputScalarCoords(){return new i.GlslLibRoutine(\"\\n      int getOutputCoords() {\\n        return 0;\\n      }\\n    \")}getOutputPacked1DCoords(t,e){const n=e;let r=\"\";return 1===n[0]?(r=`\\n          int getOutputCoords() {\\n            return 2 * int(TexCoords.y * ${n[1]}.0);\\n          }\\n        `,new i.GlslLibRoutine(r)):1===n[1]?(r=`\\n          int getOutputCoords() {\\n            return 2 * int(TexCoords.x * ${n[0]}.0);\\n          }\\n        `,new i.GlslLibRoutine(r)):(r=`\\n        int getOutputCoords() {\\n          ivec2 resTexRC = ivec2(TexCoords.xy *\\n                                 vec2(${n[0]}, ${n[1]}));\\n          return 2 * (resTexRC.y * ${n[0]} + resTexRC.x);\\n        }\\n      `,new i.GlslLibRoutine(r))}getOutputPacked2DCoords(t,e){let n=\"\";if(r.ArrayUtil.arraysEqual(t,e))return n=`\\n        ivec2 getOutputCoords() {\\n          return 2 * ivec2(TexCoords.xy * vec2(${e[0]}, ${e[1]}));\\n        }\\n      `,new i.GlslLibRoutine(n);const o=e,a=Math.ceil(t[1]/2);return n=`\\n        ivec2 getOutputCoords() {\\n          ivec2 resTexRC = ivec2(TexCoords.xy *\\n                                vec2(${o[0]}, ${o[1]}));\\n\\n          int index = resTexRC.y * ${o[0]} + resTexRC.x;\\n\\n          // reverse r and c order for packed texture\\n          int r = imod(index, ${a}) * 2;\\n          int c = 2 * (index / ${a});\\n\\n          return ivec2(r, c);\\n        }\\n      `,new i.GlslLibRoutine(n)}getOutputPacked3DCoords(t,e){const n=[e[0],e[1]],r=Math.ceil(t[2]/2),o=r*Math.ceil(t[1]/2),a=`\\n        ivec3 getOutputCoords() {\\n          ivec2 resTexRC = ivec2(TexCoords.xy *\\n                                vec2(${n[0]}, ${n[1]}));\\n          int index = resTexRC.y * ${n[0]} + resTexRC.x;\\n\\n          int b = index / ${o};\\n          index -= b * ${o};\\n\\n          // reverse r and c order for packed texture\\n          int r = imod(index, ${r}) * 2;\\n          int c = 2 * (index / ${r});\\n\\n          return ivec3(b, r, c);\\n        }\\n      `;return new i.GlslLibRoutine(a)}getOutputPackedNDCoords(t,e){const n=[e[0],e[1]],r=Math.ceil(t[t.length-1]/2),o=r*Math.ceil(t[t.length-2]/2);let a=o,s=\"\",u=\"b, r, c\";for(let e=2;e<t.length-1;e++)a*=t[t.length-e-1],s=`\\n      int b${e} = index / ${a};\\n      index -= b${e} * ${a};\\n    `+s,u=`b${e}, `+u;const c=`\\n      ivec${t.length} getOutputCoords() {\\n        ivec2 resTexRC = ivec2(TexCoords.xy *\\n                              vec2(${n[0]}, ${n[1]}));\\n        int index = resTexRC.y * ${n[0]} + resTexRC.x;\\n\\n        ${s}\\n\\n        int b = index / ${o};\\n        index -= b * ${o};\\n\\n        // reverse r and c order for packed texture\\n        int r = imod(index, ${r}) * 2;\\n        int c = 2 * (index / ${r});\\n\\n        return ivec${t.length}(${u});\\n      }\\n    `;return new i.GlslLibRoutine(c)}getOutputUnpacked1DCoords(t,e){const n=`\\n        int getOutputCoords() {\\n          ivec2 resTexRC = ivec2(TexCoords.xy *\\n                                vec2(${e[0]}, ${e[1]}));\\n          return resTexRC.y * ${e[0]} + resTexRC.x;\\n        }\\n      `;return new i.GlslLibRoutine(n)}getOutputUnpacked2DCoords(t,e){const n=`\\n        ivec2 getOutputCoords() {\\n          ivec2 resTexRC = ivec2(TexCoords.xy *\\n                                vec2(${e[0]}, ${e[1]}));\\n          int index = resTexRC.y * ${e[0]} + resTexRC.x;\\n          int r = index / ${t[1]};\\n          int c = index - r * ${t[1]};\\n          return ivec2(r, c);\\n        }\\n      `;return new i.GlslLibRoutine(n)}getOutputUnpacked3DCoords(t,e){let n=\"\";const r=t.length;let o=null;r<2&&(o=[]),o=new Array(r-1),o[r-2]=t[r-1];for(let e=r-3;e>=0;--e)o[e]=o[e+1]*t[e+1];const a=[\"r\",\"c\",\"d\"],s=o.map(((t,e)=>`int ${a[e]} = index / ${t}; ${e===o.length-1?`int ${a[e+1]} = index - ${a[e]} * ${t}`:`index -= ${a[e]} * ${t}`};`)).join(\"\");return n=`\\n        ivec3 getOutputCoords() {\\n          ivec2 resTexRC = ivec2(TexCoords.xy *\\n                                vec2(${e[0]}, ${e[1]}));\\n          int index = resTexRC.y * ${e[0]} + resTexRC.x;\\n          ${s}\\n          return ivec3(r, c, d);\\n        }\\n      `,new i.GlslLibRoutine(n)}getOutputUnpacked4DCoords(t,e){let n=\"\";const r=t.length;let o=null;r<2&&(o=[]),o=new Array(r-1),o[r-2]=t[r-1];for(let e=r-3;e>=0;--e)o[e]=o[e+1]*t[e+1];const a=[\"r\",\"c\",\"d\",\"d2\"],s=o.map(((t,e)=>`int ${a[e]} = index / ${t}; ${e===o.length-1?`int ${a[e+1]} = index - ${a[e]} * ${t}`:`index -= ${a[e]} * ${t}`};`)).join(\"\");return n=`\\n      ivec4 getOutputCoords() {\\n          ivec2 resTexRC = ivec2(TexCoords.xy *\\n                                vec2(${e[0]}, ${e[1]}));\\n          int index = resTexRC.y * ${e[0]} + resTexRC.x;\\n          ${s}\\n          return ivec4(r, c, d, d2);\\n        }\\n      `,new i.GlslLibRoutine(n)}getOutputUnpacked5DCoords(t,e){let n=\"\";const r=t.length;let o=null;r<2&&(o=[]),o=new Array(r-1),o[r-2]=t[r-1];for(let e=r-3;e>=0;--e)o[e]=o[e+1]*t[e+1];const a=[\"r\",\"c\",\"d\",\"d2\",\"d3\"],s=o.map(((t,e)=>`int ${a[e]} = index / ${t}; ${e===o.length-1?`int ${a[e+1]} = index - ${a[e]} * ${t}`:`index -= ${a[e]} * ${t}`};`)).join(\"\");return n=`\\n      ivec5 getOutputCoords() {\\n          ivec2 resTexRC = ivec2(TexCoords.xy *\\n                                vec2(${e[0]}, ${e[1]}));\\n          int index = resTexRC.y * ${e[0]} + resTexRC.x;\\n          ${s}\\n          return ivec5(r, c, d, d2, d3);\\n        }\\n      `,new i.GlslLibRoutine(n)}getOutputUnpacked6DCoords(t,e){let n=\"\";const r=t.length;let o=null;r<2&&(o=[]),o=new Array(r-1),o[r-2]=t[r-1];for(let e=r-3;e>=0;--e)o[e]=o[e+1]*t[e+1];const a=[\"r\",\"c\",\"d\",\"d2\",\"d3\",\"d4\"],s=o.map(((t,e)=>`int ${a[e]} = index / ${t}; ${e===o.length-1?`int ${a[e+1]} = index - ${a[e]} * ${t}`:`index -= ${a[e]} * ${t}`};`)).join(\"\");return n=`\\n     ivec6 getOutputCoords() {\\n         ivec2 resTexRC = ivec2(TexCoords.xy *\\n                               vec2(${e[0]}, ${e[1]}));\\n         int index = resTexRC.y * ${e[0]} + resTexRC.x;\\n         ${s}\\n         return ivec6(r, c, d, d2, d3, d4);\\n       }\\n     `,new i.GlslLibRoutine(n)}getCommonUtilFuncs(){const t={};let e=\"uvFromFlat\";t[e]=new i.GlslLibRoutine(\"\\n    vec2 uvFromFlat(int texNumR, int texNumC, int index) {\\n      int texC = index / texNumR;\\n      int texR = index - texC * texNumR;\\n      // TODO: swap texR, texC order in following function so row is corresponding to u and column is corresponding to\\n      //       v.\\n      return (vec2(texR, texC) + halfCR) / vec2(texNumR, texNumC);\\n    }\\n    \"),e=\"packedUVfrom1D\",t[e]=new i.GlslLibRoutine(\"\\n      vec2 packedUVfrom1D(int texNumR, int texNumC, int index) {\\n        int texelIndex = index / 2;\\n        int texR = texelIndex / texNumC;\\n        int texC = texelIndex - texR * texNumC;\\n        return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\\n      }\\n      \"),e=\"packedUVfrom2D\",t[e]=new i.GlslLibRoutine(\"\\n      vec2 packedUVfrom2D(int texNumR, int texNumC, int texelsInLogicalRow, int row, int col) {\\n        int texelIndex = (row / 2) * texelsInLogicalRow + (col / 2);\\n        int texR = texelIndex / texNumC;\\n        int texC = texelIndex - texR * texNumC;\\n        return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\\n      }\\n      \"),e=\"packedUVfrom3D\",t[e]=new i.GlslLibRoutine(\"\\n      vec2 packedUVfrom3D(int texNumR, int texNumC,\\n          int texelsInBatch, int texelsInLogicalRow, int b,\\n          int row, int col) {\\n        int index = b * texelsInBatch + (row / 2) * texelsInLogicalRow + (col / 2);\\n        int texR = index / texNumC;\\n        int texC = index - texR * texNumC;\\n        return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\\n      }\\n      \"),e=\"sampleTexture\";const n=(0,o.getGlsl)(this.context.glContext.version);return t[e]=new i.GlslLibRoutine(`\\n        float sampleTexture(sampler2D textureSampler, vec2 uv) {\\n            return ${n.texture2D}(textureSampler, uv).r;\\n        }`),t}getInputsSamplingSnippets(){const t={},e=this.context.outputTextureLayout;return this.context.programInfo.inputNames.forEach(((n,r)=>{const i=this.context.inputTextureLayouts[r],o=(0,s.generateShaderFuncNameFromInputSamplerName)(n);i.isPacked?t[o]=this.getPackedSamplerFromInput(o,n,i):t[o]=this.getUnpackedSamplerFromInput(o,n,i);const a=(0,s.generateShaderFuncNameFromInputSamplerNameAtOutCoords)(n);i.unpackedShape.length<=e.unpackedShape.length&&(i.isPacked?t[a]=this.getPackedSamplerAtOutputCoords(a,i,e,n):t[a]=this.getUnpackedSamplerAtOutputCoords(a,i,e,n))})),t}getPackedSamplerAtOutputCoords(t,e,n,o){const a=e.unpackedShape,u=n.unpackedShape,c=o,l=(0,s.generateShaderFuncNameFromInputSamplerName)(c),p=a.length,f=u.length,d=r.BroadcastUtil.getBroadcastDims(a,u),h=(0,s.getCoordsDataType)(f),g=f-p;let b;const m=(0,s.getGlChannels)();b=0===p?\"\":f<2&&d.length>=1?\"coords = 0;\":d.map((t=>`coords.${m[t+g]} = 0;`)).join(\"\\n\");let y=\"\";y=f<2&&p>0?\"coords\":a.map(((t,e)=>`coords.${m[e+g]}`)).join(\", \");let _=\"return outputValue;\";const v=1===r.ShapeUtil.size(a),w=1===r.ShapeUtil.size(u);if(1!==p||v||w){if(v&&!w)_=1===f?\"\\n          return vec4(outputValue.x, outputValue.x, 0., 0.);\\n        \":\"\\n          return vec4(outputValue.x);\\n        \";else if(d.length){const t=p-2,e=p-1;d.indexOf(t)>-1&&d.indexOf(e)>-1?_=\"return vec4(outputValue.x);\":d.indexOf(t)>-1?_=\"return vec4(outputValue.x, outputValue.y, outputValue.x, outputValue.y);\":d.indexOf(e)>-1&&(_=\"return vec4(outputValue.xx, outputValue.zz);\")}}else _=\"\\n        return vec4(outputValue.xy, outputValue.xy);\\n      \";const x=`\\n      vec4 ${t}() {\\n        ${h} coords = getOutputCoords();\\n        \\n        int lastDim = coords.${m[f-1]};\\n        coords.${m[f-1]} = coords.${m[f-2]};\\n        coords.${m[f-2]} = lastDim;\\n      \\n        ${b}\\n        vec4 outputValue = ${l}(${y});\\n        ${_}\\n      }\\n    `;return new i.GlslLibRoutine(x,[\"coordinates.getOutputCoords\"])}getUnpackedSamplerAtOutputCoords(t,e,n,o){const a=[n.width,n.height],u=[e.width,e.height],c=e.unpackedShape.length,l=n.unpackedShape.length,p=e.unpackedShape,f=n.unpackedShape,d=(0,s.generateShaderFuncNameFromInputSamplerName)(o);if(c===l&&r.ArrayUtil.arraysEqual(u,a)){const e=`\\n          float ${t}() {\\n            return sampleTexture(${o}, TexCoords);\\n          }\\n        `;return new i.GlslLibRoutine(e,[\"coordinates.sampleTexture\"])}const h=(0,s.getCoordsDataType)(l),g=r.BroadcastUtil.getBroadcastDims(p,f),b=l-c;let m;const y=(0,s.getGlChannels)();m=0===c?\"\":l<2&&g.length>=1?\"coords = 0;\":g.map((t=>`coords.${y[t+b]} = 0;`)).join(\"\\n\");let _=\"\";_=l<2&&c>0?\"coords\":e.unpackedShape.map(((t,e)=>`coords.${y[e+b]}`)).join(\", \");const v=`\\n        float ${t}() {\\n          ${h} coords = getOutputCoords();\\n          ${m}\\n          return ${d}(${_});\\n        }\\n      `;return new i.GlslLibRoutine(v,[\"coordinates.getOutputCoords\"])}getPackedSamplerFromInput(t,e,n){switch(n.unpackedShape.length){case 0:return this.getPackedSamplerScalar(t,e);case 1:return this.getPackedSampler1D(t,e,n);case 2:return this.getPackedSampler2D(t,e,n);case 3:return this.getPackedSampler3D(t,e,n);default:return this.getPackedSamplerND(t,e,n)}}getUnpackedSamplerFromInput(t,e,n){const r=n.unpackedShape;switch(r.length){case 0:return this.getUnpackedSamplerScalar(t,e,n);case 1:return this.getUnpackedSampler1D(t,e,n);case 2:return this.getUnpackedSampler2D(t,e,n);case 3:return this.getUnpackedSampler3D(t,e,n);case 4:return this.getUnpackedSampler4D(t,e,n);case 5:return this.getUnpackedSampler5D(t,e,n);case 6:return this.getUnpackedSampler6D(t,e,n);default:throw new Error(`Unsupported dimension ${r.length}-D`)}}getPackedSamplerScalar(t,e){const n=`\\n          vec4 ${t}() {\\n            return ${(0,o.getGlsl)(this.context.glContext.version).texture2D}(${e}, halfCR);\\n          }\\n        `;return new i.GlslLibRoutine(n)}getPackedSampler1D(t,e,n){const r=[n.width,n.height],a=[r[1],r[0]],s=(0,o.getGlsl)(this.context.glContext.version),u=`vec4 ${t}(int index) {\\n      vec2 uv = packedUVfrom1D(\\n      ${a[0]}, ${a[1]}, index);\\n      return ${s.texture2D}(${e}, uv);\\n    }`;return new i.GlslLibRoutine(u,[\"coordinates.packedUVfrom1D\"])}getPackedSampler2D(t,e,n){const a=n.unpackedShape,s=[n.width,n.height],u=(0,o.getGlsl)(this.context.glContext.version),c=s[0],l=s[1];if(null!=s&&r.ArrayUtil.arraysEqual(a,s)){const n=`vec4 ${t}(int row, int col) {\\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(${l}.0, ${c}.0);\\n        return ${u.texture2D}(${e}, uv);\\n      }`;return new i.GlslLibRoutine(n)}const p=s,f=Math.ceil(a[1]/2),d=`vec4 ${t}(int row, int col) {\\n      vec2 uv = packedUVfrom2D(${p[1]}, ${p[0]}, ${f}, row, col);\\n      return ${u.texture2D}(${e}, uv);\\n    }`;return new i.GlslLibRoutine(d,[\"coordinates.packedUVfrom2D\"])}getPackedSampler3D(t,e,n){const r=n.unpackedShape,a=[n.width,n.height],u=[a[0],a[1]],c=(0,o.getGlsl)(this.context.glContext.version);if(1===r[0]){const o=r.slice(1),a=[1,2],u=(0,s.squeezeInputShape)(r,o),c=[\"b\",\"row\",\"col\"],l=JSON.parse(JSON.stringify(n));l.unpackedShape=u;const p=this.getPackedSamplerFromInput(t,e,l),f=`${p.routineBody}\\n      vec4 ${t}(int b, int row, int col) {\\n        return ${t}(${(0,s.getSqueezedParams)(c,a)});\\n      } `;return new i.GlslLibRoutine(f,p.dependencies)}const l=u[0],p=u[1],f=Math.ceil(r[2]/2),d=`vec4 ${t}(int b, int row, int col) {\\n      vec2 uv = packedUVfrom3D(\\n        ${p}, ${l}, ${f*Math.ceil(r[1]/2)}, ${f}, b, row, col);\\n      return ${c.texture2D}(${e}, uv);}`;return new i.GlslLibRoutine(d,[\"coordinates.packedUVfrom3D\"])}getPackedSamplerND(t,e,n){const r=n.unpackedShape,a=r.length,s=[n.width,n.height],u=(0,o.getGlsl)(this.context.glContext.version),c=[s[0],s[1]],l=c[1],p=c[0],f=Math.ceil(r[a-1]/2);let d=f*Math.ceil(r[a-2]/2),h=\"int b, int row, int col\",g=`b * ${d} + (row / 2) * ${f} + (col / 2)`;for(let t=2;t<a-1;t++)h=`int b${t}, `+h,d*=r[a-t-1],g=`b${t} * ${d} + `+g;const b=`vec4 ${t}(${h}) {\\n      int index = ${g};\\n      int texR = index / ${p};\\n      int texC = index - texR * ${p};\\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${p}, ${l});\\n      return ${u.texture2D}(${e}, uv);\\n    }`;return new i.GlslLibRoutine(b)}getUnpackedSamplerScalar(t,e,n){const[r,o]=[n.width,n.height];if(1===r&&1===o){const n=`\\n          float ${t}() {\\n            return sampleTexture(${e}, halfCR);\\n          }\\n        `;return new i.GlslLibRoutine(n,[\"coordinates.sampleTexture\"])}const a=`\\n        float ${t}() {\\n          int offset_${e} = coordsToOffset(TexCoords, ${r}, ${o});\\n          vec2 uv = uvFromFlat(${r}, ${o}, offset_${e});\\n          return sampleTexture(${e}, uv);\\n        }\\n      `;return new i.GlslLibRoutine(a,[\"coordinates.uvFromFlat\",\"coordinates.sampleTexture\",\"coordinates.coordsToOffset\"])}getUnpackedSampler1D(t,e,n){const r=n.width,o=n.height;if(1===o&&1===r){const n=`\\n        float ${t}(int index) {\\n          return sampleTexture(${e}, halfCR);\\n        }\\n      `;return new i.GlslLibRoutine(n,[\"coordinates.sampleTexture\"])}if(1===o){const n=`\\n          float ${t}(int index) {\\n            vec2 uv = vec2((float(index) + 0.5) / ${r}.0, 0.5);\\n            return sampleTexture(${e}, uv);\\n          }\\n        `;return new i.GlslLibRoutine(n,[\"coordinates.sampleTexture\"])}if(1===r){const n=`\\n          float ${t}(int index) {\\n            vec2 uv = vec2(0.5, (float(index) + 0.5) / ${o}.0);\\n            return sampleTexture(${e}, uv);\\n          }\\n        `;return new i.GlslLibRoutine(n,[\"coordinates.sampleTexture\"])}const a=`\\n        float ${t}(int index) {\\n          vec2 uv = uvFromFlat(${r}, ${o}, index);\\n          return sampleTexture(${e}, uv);\\n        }\\n      `;return new i.GlslLibRoutine(a,[\"coordinates.uvFromFlat\",\"coordinates.sampleTexture\"])}getUnpackedSampler2D(t,e,n){const o=n.unpackedShape,u=[n.height,n.width];if(null!=u&&r.ArrayUtil.arraysEqual(o,u)){const n=`\\n          float ${t}(int row, int col) {\\n            vec2 uv = (vec2(row, col) + halfCR) / vec2(${u[1]}.0, ${u[0]}.0);\\n            return sampleTexture(${e}, uv);\\n          }\\n        `;return new i.GlslLibRoutine(n,[\"coordinates.sampleTexture\"])}const{newShape:c,keptDims:l}=(0,a.squeezeShape)(o),p=c;if(p.length<o.length){const r=(0,s.squeezeInputShape)(o,p),a=JSON.parse(JSON.stringify(n));a.unpackedShape=r;const u=[\"col\",\"row\"],c=`\\n          ${this.getUnpackedSamplerFromInput(t,e,a).routineBody}\\n          float ${t}(int row, int col) {\\n            return ${t}(${(0,s.getSqueezedParams)(u,l)});\\n          }\\n        `;return new i.GlslLibRoutine(c,[\"coordinates.sampleTexture\"])}const f=u[1],d=u[0];if(1===d){const n=`\\n          float ${t}(int row, int col) {\\n            int offset_${e} = coordsToOffset(TexCoords, ${f}, ${d});\\n            float index = dot(vec3(row, col, offset_${e}), vec3(${o[1]}, 1, 1));\\n            vec2 uv = vec2(0.5, (index + 0.5) / ${f}.0);\\n            return sampleTexture(${e}, uv);\\n          }\\n        `;return new i.GlslLibRoutine(n,[\"coordinates.sampleTexture\",\"coordinates.coordsToOffset\"])}if(1===f){const n=`\\n          float ${t}(int row, int col) {\\n            int offset_${e} = coordsToOffset(TexCoords, ${f}, ${d});\\n            float index = dot(vec3(row, col, offset_${e}), vec3(${o[1]}, 1, 1));\\n            vec2 uv = vec2((index + 0.5) / ${d}.0, 0.5);\\n            return sampleTexture(${e}, uv);\\n          }\\n        `;return new i.GlslLibRoutine(n,[\"coordinates.sampleTexture\",\"coordinates.coordsToOffset\"])}const h=`\\n        float ${t}(int row, int col) {\\n          int index = col * ${o[1]} + row;\\n          vec2 uv = uvFromFlat(${f}, ${d}, index);\\n          return sampleTexture(${e}, uv);\\n        }\\n      `;return new i.GlslLibRoutine(h,[\"coordinates.uvFromFlat\",\"coordinates.sampleTexture\",\"coordinates.coordsToOffset\"])}getUnpackedSampler3D(t,e,n){const r=n.unpackedShape,o=r[1]*r[2],u=r[2],{newShape:c,keptDims:l}=(0,a.squeezeShape)(r),p=c;if(p.length<r.length){const o=(0,s.squeezeInputShape)(r,p),a=[\"batch\",\"col\",\"row\"],u=JSON.parse(JSON.stringify(n));u.unpackedShape=o;const c=this.getUnpackedSamplerFromInput(t,e,u),f=l.reverse(),d=`\\n          ${c.routineBody}\\n          float ${t}(int batch, int row, int col) {\\n            return ${t}(${(0,s.getSqueezedParams)(a,f)});\\n          }\\n        `;return new i.GlslLibRoutine(d,c.dependencies)}const f=`\\n          float ${t}(int depth, int row, int col) {\\n            // Explicitly use integer operations as dot() only works on floats.\\n            int index = depth * ${o} + col * ${u} + row;\\n            vec2 uv = uvFromFlat(${n.width}, ${n.height}, index);\\n            return sampleTexture(${e}, uv);\\n          }\\n      `;return new i.GlslLibRoutine(f,[\"coordinates.uvFromFlat\",\"coordinates.sampleTexture\",\"coordinates.coordsToOffset\"])}getUnpackedSampler4D(t,e,n){const r=n.unpackedShape,o=r[3],a=r[2]*o,s=`\\n        float ${t}(int row, int col, int depth, int depth2) {\\n          int index = row * ${r[1]*a} + col * ${a} +\\n              depth2 * ${o} + depth;\\n          vec2 uv = uvFromFlat(${n.width}, ${n.height}, index);\\n          return sampleTexture(${e}, uv);\\n        }\\n      `;return new i.GlslLibRoutine(s,[\"coordinates.uvFromFlat\",\"coordinates.sampleTexture\"])}getUnpackedSampler5D(t,e,n){const r=n.unpackedShape,o=r[4],u=r[3]*o,c=r[2]*u,l=r[1]*c,{newShape:p,keptDims:f}=(0,a.squeezeShape)(r);if(p.length<r.length){const o=(0,s.squeezeInputShape)(r,p),a=[\"row\",\"col\",\"depth\",\"depth2\",\"depth3\"],u=JSON.parse(JSON.stringify(n));u.unpackedShape=o;const c=`\\n          ${this.getUnpackedSamplerFromInput(t,e,u).routineBody}\\n          float ${t}(int row, int col, int depth, int depth2, int depth3) {\\n            return ${t}(${(0,s.getSqueezedParams)(a,f)});\\n          }\\n        `;return new i.GlslLibRoutine(c,[\"coordinates.sampleTexture\",\"coordinates.uvFromFlat\"])}const d=`\\n        float ${t}(int row, int col, int depth, int depth2, int depth3) {\\n          int index = row * ${l} + col * ${c} + depth * ${u} +\\n          depth3 * ${o} + depth2;\\n          vec2 uv = uvFromFlat(${n.width}, ${n.height}, index);\\n          return sampleTexture(${e}, uv);\\n        }\\n      `;return new i.GlslLibRoutine(d,[\"coordinates.sampleTexture\",\"coordinates.uvFromFlat\"])}getUnpackedSampler6D(t,e,n){const r=n.unpackedShape,o=r[5],u=r[4]*o,c=r[3]*u,l=r[2]*c,p=r[1]*l,{newShape:f,keptDims:d}=(0,a.squeezeShape)(r);if(f.length<r.length){const o=(0,s.squeezeInputShape)(r,f),a=[\"row\",\"col\",\"depth\",\"depth2\",\"depth3\",\"depth4\"],u=JSON.parse(JSON.stringify(n));u.unpackedShape=o;const c=`\\n            ${this.getUnpackedSamplerFromInput(t,e,u).routineBody}\\n            float ${t}(int row, int col, int depth,\\n              int depth2, int depth3, int depth4) {\\n              return ${t}(${(0,s.getSqueezedParams)(a,d)});\\n            }\\n          `;return new i.GlslLibRoutine(c,[\"coordinates.sampleTexture\",\"coordinates.uvFromFlat\"])}const h=`\\n          float ${t}(int row, int col, int depth,\\n            int depth2, int depth3, int depth4) {\\n            int index = row * ${p} + col * ${l} + depth * ${c} +\\n            depth2 * ${u} + depth3 * ${o} + depth4;\\n            vec2 uv = uvFromFlat(${n.width}, ${n.height}, index);\\n            return sampleTexture(${e}, uv);\\n          }\\n        `;return new i.GlslLibRoutine(h,[\"coordinates.uvFromFlat\",\"coordinates.sampleTexture\",\"coordinates.coordsToOffset\"])}toVec(){const t=this.context.outputTextureLayout,e=t.shape.length,n=t.strides,r=t.width,o=t.height,a=[];for(let t=0;t<e-1;++t)a.push(`\\n        c[${t}] = offset / ${n[t]};`),a.push(`\\n        offset -= c[${t}] * ${n[t]};`);a.push(`\\n        c[${e-1}] = offset;`);const s=`\\n      void toVec(vec2 texCoords, out int c[${e}]) {\\n        int offset = coordsToOffset(texCoords, ${r}, ${o});\\n        ${a.join(\"\")}\\n      }\\n      void toVec(int offset, out int c[${e}]) {\\n        ${a.join(\"\")}\\n      }\\n    `;return{toVec:new i.GlslLibRoutine(s,[\"coordinates.coordsToOffset\"])}}valueFrom(){const t={};return this.context.programInfo.inputNames.forEach(((e,n)=>{const r=this.context.inputTextureLayouts[n],o=(r.unpackedShape.length>0?r.unpackedShape:r.shape).length;let a=`_${e}`;t[a]=new i.GlslLibRoutine(this.getValueFromSingle(e,o,r.width,r.height,!1),[`shapeUtils.indicesToOffset${a}`,\"coordinates.offsetToCoords\",\"fragcolor.getColorAsFloat\"]),a+=\"_T\",t[a]=new i.GlslLibRoutine(this.getValueFromSingle(e,o,r.width,r.height,!0),[`shapeUtils.indicesToOffset${a}`,\"coordinates.offsetToCoords\",\"fragcolor.getColorAsFloat\"])})),t}getValueFromSingle(t,e,n,r,i){let a=`_${t}`;return i&&(a+=\"_T\"),`\\n        float ${a}(int m[${e}]) {\\n          int offset = indicesToOffset${a}(m);\\n          vec2 coords = offsetToCoords(offset, ${n}, ${r});\\n          float value = getColorAsFloat(${(0,o.getGlsl)(this.context.glContext.version).texture2D}(${t}, coords));\\n          return value;\\n        }\\n        `}getPackedValueFrom(t,e,n,r,i){let a=`_${t}_Pack`;return i&&(a+=\"_T\"),`\\n        vec4 ${a}(int m[${e}]) {\\n          int offset = indicesToOffset_${t}(m);\\n          vec2 coords = offsetToCoords(offset, ${n}, ${r});\\n          return ${(0,o.getGlsl)(this.context.glContext.version).texture2D}(${t}, coords);\\n        }\\n        `}}e.CoordsGlslLib=u},8520:(t,e)=>{\"use strict\";var n;Object.defineProperty(e,\"__esModule\",{value:!0}),e.TopologicalSortGlslRoutines=e.GlslLibRoutineNode=e.GlslLibRoutine=e.GlslLib=e.GlslContext=e.FunctionType=void 0,(n=e.FunctionType||(e.FunctionType={}))[n.ValueBased=0]=\"ValueBased\",n[n.Positional=1]=\"Positional\",e.GlslContext=class{constructor(t,e,n,r){this.glContext=t,this.programInfo=e,this.inputTextureLayouts=n,this.outputTextureLayout=r}},e.GlslLib=class{constructor(t){this.context=t}},e.GlslLibRoutine=class{constructor(t,e){this.routineBody=t,this.dependencies=e}},e.GlslLibRoutineNode=class{constructor(t,e,n){this.name=t,this.dependencies=n||[],e&&(this.routineBody=e)}addDependency(t){t&&this.dependencies.push(t)}},e.TopologicalSortGlslRoutines=class{static returnOrderedNodes(t){if(!t||0===t.length)return[];if(1===t.length)return t;const e=new Set,n=new Set,r=new Array;return this.createOrderedNodes(t,e,n,r),r}static createOrderedNodes(t,e,n,r){for(let i=0;i<t.length;++i)this.dfsTraverse(t[i],e,n,r)}static dfsTraverse(t,e,n,r){if(!t||n.has(t.name))return;if(e.has(t.name))throw new Error(\"Cyclic dependency detected. Can't topologically sort routines needed for shader.\");e.add(t.name);const i=t.dependencies;if(i&&i.length>0)for(let t=0;t<i.length;++t)this.dfsTraverse(i[t],e,n,r);r.push(t),n.add(t.name),e.delete(t.name)}}},7341:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.EncodingGlslLib=void 0;const r=n(8520);class i extends r.GlslLib{constructor(t){super(t)}getFunctions(){return Object.assign(Object.assign({},this.encodeFloat32()),this.decodeFloat32())}getCustomTypes(){return{}}encodeFloat32(){return{encode:new r.GlslLibRoutine(\"highp vec4 encode(highp float f) {\\n        return vec4(f, 0.0, 0.0, 0.0);\\n      }\\n        \")}}decodeFloat32(){return{decode:new r.GlslLibRoutine(\"highp float decode(highp vec4 rgba) {\\n        return rgba.r;\\n      }\\n        \")}}encodeUint8(){const t=i.isLittleEndian()?\"rgba.rgba=rgba.abgr;\":\"\";return{encode:new r.GlslLibRoutine(`\\n      highp vec4 encode(highp float f) {\\n        highp float F = abs(f);\\n        highp float Sign = step(0.0,-f);\\n        highp float Exponent = floor(log2(F));\\n        highp float Mantissa = (exp2(- Exponent) * F);\\n        Exponent = floor(log2(F) + 127.0) + floor(log2(Mantissa));\\n        highp vec4 rgba;\\n        rgba[0] = 128.0 * Sign  + floor(Exponent*exp2(-1.0));\\n        rgba[1] = 128.0 * mod(Exponent,2.0) + mod(floor(Mantissa*128.0),128.0);\\n        rgba[2] = floor(mod(floor(Mantissa*exp2(23.0 -8.0)),exp2(8.0)));\\n        rgba[3] = floor(exp2(23.0)*mod(Mantissa,exp2(-15.0)));\\n        ${t}\\n        rgba = rgba / 255.0; // values need to be normalized to [0,1]\\n        return rgba;\\n    }\\n        `)}}decodeUint8(){const t=i.isLittleEndian()?\"rgba.rgba=rgba.abgr;\":\"\";return{decode:new r.GlslLibRoutine(`\\n        highp float decode(highp vec4 rgba) {\\n          rgba = rgba * 255.0; // values need to be de-normalized from [0,1] to [0,255]\\n          ${t}\\n          highp float Sign = 1.0 - step(128.0,rgba[0])*2.0;\\n          highp float Exponent = 2.0 * mod(rgba[0],128.0) + step(128.0,rgba[1]) - 127.0;\\n          highp float Mantissa = mod(rgba[1],128.0)*65536.0 + rgba[2]*256.0 +rgba[3] + float(0x800000);\\n          highp float Result =  Sign * exp2(Exponent) * (Mantissa * exp2(-23.0 ));\\n          return Result;\\n      }\\n        `)}}static isLittleEndian(){const t=new ArrayBuffer(4),e=new Uint32Array(t),n=new Uint8Array(t);if(e[0]=3735928559,239===n[0])return!0;if(222===n[0])return!1;throw new Error(\"unknown endianness\")}}e.EncodingGlslLib=i},9894:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.FragColorGlslLib=void 0;const r=n(8520),i=n(5060);class o extends r.GlslLib{constructor(t){super(t)}getFunctions(){return Object.assign(Object.assign({},this.setFragColor()),this.getColorAsFloat())}getCustomTypes(){return{}}setFragColor(){const t=(0,i.getGlsl)(this.context.glContext.version);return{setFragColor:new r.GlslLibRoutine(`\\n        void setFragColor(float value) {\\n            ${t.output} = encode(value);\\n        }\\n        `,[\"encoding.encode\"])}}getColorAsFloat(){return{getColorAsFloat:new r.GlslLibRoutine(\"\\n        float getColorAsFloat(vec4 color) {\\n            return decode(color);\\n        }\\n        \",[\"encoding.decode\"])}}}e.FragColorGlslLib=o},2848:(t,e)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.replaceInlines=void 0;const n=/@inline[\\s\\n\\r]+(\\w+)[\\s\\n\\r]+([0-9a-zA-Z_]+)\\s*\\(([^)]*)\\)\\s*{(([^}]|[\\n\\r])*)}/gm;e.replaceInlines=function(t){const e={};let r;for(;null!==(r=n.exec(t));){const t=r[3].split(\",\").map((t=>{const e=t.trim().split(\" \");return e&&2===e.length?{type:e[0],name:e[1]}:null})).filter((t=>null!==t));e[r[2]]={params:t,body:r[4]}}for(const n in e){const i=\"(\\\\w+)?\\\\s+([_0-9a-zA-Z]+)\\\\s+=\\\\s+__FUNC__\\\\((.*)\\\\)\\\\s*;\".replace(\"__FUNC__\",n),o=new RegExp(i,\"gm\");for(;null!==(r=o.exec(t));){const i=r[1],o=r[2],a=r[3].split(\",\"),s=i?`${i} ${o};`:\"\";let u=e[n].body,c=\"\";e[n].params.forEach(((t,e)=>{t&&(c+=`${t.type} ${t.name} = ${a[e]};\\n`)})),u=`${c}\\n ${u}`,u=u.replace(\"return\",`${o} = `);const l=`\\n      ${s}\\n      {\\n        ${u}\\n      }\\n      `;t=t.replace(r[0],l)}}return t.replace(n,\"\")}},8879:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.GlslPreprocessor=void 0;const r=n(8520),i=n(2848),o=n(5483),a=n(5060);e.GlslPreprocessor=class{constructor(t,e,n,i){this.libs={},this.glslLibRoutineDependencyGraph={},this.context=new r.GlslContext(t,e,n,i),Object.keys(o.glslRegistry).forEach((t=>{const e=new o.glslRegistry[t](this.context);this.libs[t]=e}));const a=this.glslLibRoutineDependencyGraph;for(const t in this.libs){const e=this.libs[t].getFunctions();for(const n in e){const i=t+\".\"+n;let o;a[i]?(o=a[i],o.routineBody=e[n].routineBody):(o=new r.GlslLibRoutineNode(i,e[n].routineBody),a[i]=o);const s=e[n].dependencies;if(s)for(let t=0;t<s.length;++t)if(a[s[t]])o.addDependency(a[s[t]]);else{const e=new r.GlslLibRoutineNode(s[t]);a[s[t]]=e,o.addDependency(e)}}}}preprocess(){const t=this.context.programInfo;let e=t.shaderSource;return this.context.programInfo.hasMain||(e=`${e}\\n      ${(0,a.getDefaultFragShaderMain)(this.context.glContext.version,this.context.outputTextureLayout.shape.length)}`),e=(0,i.replaceInlines)(e),`${(0,a.getFragShaderPreamble)(this.context.glContext.version)}\\n    ${this.getUniforms(t.inputNames,t.variables)}\\n    ${this.getImports(e)}\\n    ${e}`}getImports(t){const e=this.selectGlslLibRoutinesToBeIncluded(t);if(0===e.length)return\"\";let n=\"\";for(let t=0;t<e.length;++t){if(!e[t].routineBody)throw new Error(`Missing body for the Glsl Library routine: ${e[t].name}`);n+=e[t].routineBody+\"\\n\"}return n}selectGlslLibRoutinesToBeIncluded(t){const e=[];return Object.keys(this.glslLibRoutineDependencyGraph).forEach((n=>{const r=n.split(\".\")[1];-1!==t.indexOf(r)&&e.push(this.glslLibRoutineDependencyGraph[n])})),r.TopologicalSortGlslRoutines.returnOrderedNodes(e)}getUniforms(t,e){const n=[];if(t)for(const e of t)n.push(`uniform sampler2D ${e};`);if(e)for(const t of e)n.push(`uniform ${t.type} ${t.name}${t.arrayLength?`[${t.arrayLength}]`:\"\"};`);return n.join(\"\\n\")}}},5483:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.glslRegistry=void 0;const r=n(5107),i=n(7341),o=n(9894),a=n(2655),s=n(3891);e.glslRegistry={encoding:i.EncodingGlslLib,fragcolor:o.FragColorGlslLib,vec:s.VecGlslLib,shapeUtils:a.ShapeUtilsGlslLib,coordinates:r.CoordsGlslLib}},2655:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.ShapeUtilsGlslLib=void 0;const r=n(8520);class i extends r.GlslLib{constructor(t){super(t)}getFunctions(){return Object.assign(Object.assign(Object.assign(Object.assign(Object.assign({},this.bcastIndex()),this.bcastMatmulIndex()),this.offsetToIndices()),this.indicesToOffset()),this.incrementIndices())}getCustomTypes(){return{}}bcastIndex(){const t=this.context.outputTextureLayout.shape.length,e={};return this.context.programInfo.inputNames.forEach(((n,i)=>{const o=this.context.inputTextureLayouts[i].unpackedShape;if(o.length<=t){const i=o.length,a=t-i,s=`bcastIndices_${n}`;let u=\"\";for(let t=0;t<i;++t)u+=`\\n          realIndices[${t}] = int( mod(float(bcastedIndices[${a+t}]), ${o[t]}.0) );\\n          `;const c=`\\n        void ${s} (int bcastedIndices[${t}], out int realIndices[${i}]) {\\n          ${u}\\n        }\\n        `;e[s]=new r.GlslLibRoutine(c)}})),e}bcastMatmulIndex(){const t=this.context.outputTextureLayout.shape.length,e={};return this.context.programInfo.inputNames.forEach(((n,i)=>{const o=this.context.inputTextureLayouts[i].shape;if(!(o.length<2||o.length>t)){const i=o.length,a=t-i,s=`bcastMatmulIndices_${n}`;let u=\"\";for(let t=0;t<i-2;++t)u+=`\\n          realIndices[${t}] = int( mod(float(bcastedIndices[${a+t}]), ${o[t]}.0) );\\n          `;const c=`\\n        void ${s}(int bcastedIndices[${t}], out int realIndices[${i}]) {\\n          ${u}\\n          realIndices[${i-1}] = bcastedIndices[${t-1}];\\n          realIndices[${i-2}] = bcastedIndices[${t-2}];\\n        }\\n        `;e[s]=new r.GlslLibRoutine(c)}})),e}indicesToOffset(){const t={};return this.context.programInfo.inputNames.forEach(((e,n)=>{const o=this.context.inputTextureLayouts[n].shape,a=this.context.inputTextureLayouts[n].strides,s=o.length;let u=`indicesToOffset_${e}`;t[u]=new r.GlslLibRoutine(i.indexToOffsetSingle(u,s,a)),u=`indicesToOffset_${e}_T`,t[u]=new r.GlslLibRoutine(i.indexToOffsetSingle(u,s,a.slice().reverse()))})),t}static indexToOffsetSingle(t,e,n){let r=\"\";for(let t=e-1;t>=0;--t)r+=`\\n        offset += indices[${t}] * ${n[t]};\\n        `;return`\\n      int ${t}(int indices[${e}]) {\\n        int offset = 0;\\n        ${r}\\n        return offset;\\n      }\\n      `}offsetToIndices(){const t={};return this.context.programInfo.inputNames.forEach(((e,n)=>{const o=this.context.inputTextureLayouts[n].shape,a=this.context.inputTextureLayouts[n].strides,s=o.length;let u=`offsetToIndices_${e}`;t[u]=new r.GlslLibRoutine(i.offsetToIndicesSingle(u,s,a)),u=`offsetToIndices_${e}_T`,t[u]=new r.GlslLibRoutine(i.offsetToIndicesSingle(u,s,a.slice().reverse()))})),t}static offsetToIndicesSingle(t,e,n){const r=[];for(let t=0;t<e-1;++t)r.push(`\\n      indices[${t}] = offset / ${n[t]};`),r.push(`\\n        offset -= indices[${t}] * ${n[t]};`);return r.push(`\\n      indices[${e-1}] = offset;`),`\\n      void ${t}(int offset, out int indices[${e}]) {\\n        ${r.join(\"\")}\\n      }\\n      `}incrementIndices(){const t={};return this.context.programInfo.inputNames.forEach(((e,n)=>{const i=this.context.inputTextureLayouts[n].shape,o=i.length,a=`incrementIndices_${e}`;let s=\"\";for(let t=0;t<o;++t)s+=`\\n        shape[${t}] = ${i[t]};`;const u=`\\n        void ${a}(int axis, out int indices[${o}]) {\\n          int shape[${o}];\\n          ${s};\\n          for(int i = ${o} -1 ; i >= 0; --i) {\\n            if(i > axis) continue;\\n            indices[i] += 1;\\n            if(indices[i] < shape[i]) {\\n              break;\\n            }\\n            indices[i] = 0;\\n          }\\n        }\\n        `;t[a]=new r.GlslLibRoutine(u)})),t}}e.ShapeUtilsGlslLib=i},5060:(t,e)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.getDefaultFragShaderMain=e.getFragShaderPreamble=e.getVertexShaderSource=e.getGlsl=void 0;const n={version:\"\",attribute:\"attribute\",varyingVertex:\"varying\",varyingFrag:\"varying\",texture2D:\"texture2D\",output:\"gl_FragColor\",outputDeclaration:\"\"},r={version:\"#version 300 es\",attribute:\"in\",varyingVertex:\"out\",varyingFrag:\"in\",texture2D:\"texture\",output:\"outputColor\",outputDeclaration:\"out vec4 outputColor;\"};function i(t){return 1===t?n:r}e.getGlsl=i,e.getVertexShaderSource=function(t){const e=i(t);return`${e.version}\\n      precision highp float;\\n      ${e.attribute} vec3 position;\\n      ${e.attribute} vec2 textureCoord;\\n\\n      ${e.varyingVertex} vec2 TexCoords;\\n\\n      void main()\\n      {\\n          gl_Position = vec4(position, 1.0);\\n          TexCoords = textureCoord;\\n      }`},e.getFragShaderPreamble=function(t){const e=i(t);return`${e.version}\\n    precision highp float;\\n    precision highp int;\\n    precision highp sampler2D;\\n    ${e.varyingFrag} vec2 TexCoords;\\n    ${e.outputDeclaration}\\n    const vec2 halfCR = vec2(0.5, 0.5);\\n\\n    // Custom vector types to handle higher dimenalities.\\n    struct ivec5\\n    {\\n      int x;\\n      int y;\\n      int z;\\n      int w;\\n      int u;\\n    };\\n\\n    struct ivec6\\n    {\\n      int x;\\n      int y;\\n      int z;\\n      int w;\\n      int u;\\n      int v;\\n    };\\n\\n    int imod(int x, int y) {\\n      return x - y * (x / y);\\n    }\\n\\n    `},e.getDefaultFragShaderMain=function(t,e){return`\\n  void main() {\\n    int indices[${e}];\\n    toVec(TexCoords, indices);\\n    vec4 result = vec4(process(indices));\\n    ${i(t).output} = result;\\n  }\\n  `}},3891:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.VecGlslLib=void 0;const r=n(8520);class i extends r.GlslLib{constructor(t){super(t)}getCustomTypes(){return{}}getFunctions(){return Object.assign(Object.assign(Object.assign(Object.assign({},this.binaryVecFunctions()),this.copyVec()),this.setVecItem()),this.getVecItem())}binaryVecFunctions(){const t=this.context.outputTextureLayout.shape.length,e={add:\"+=\",sub:\"-=\",mul:\"*=\",div:\"/=\"},n={};for(const i in e){const o=`${i}Vec`;let a=\"\";for(let n=0;n<t;++n)a+=`\\n          dest[${n}] ${e[i]} src[${n}];\\n          `;const s=`\\n        void ${o}(int src[${t}], out int dest[${t}]) {\\n          ${a}\\n        }\\n        `;n[o]=new r.GlslLibRoutine(s)}return n}copyVec(){const t=this.context.outputTextureLayout.shape.length;let e=\"\";for(let n=0;n<t;++n)e+=`\\n        dest[${n}] = src[${n}];\\n        `;const n=`\\n      void copyVec(int src[${t}], out int dest[${t}]) {\\n        ${e}\\n      }\\n      `;return{copyVec:new r.GlslLibRoutine(n)}}setVecItem(){const t=this.context.outputTextureLayout.shape.length;let e=`\\n        if(index < 0)\\n            index =${t} + index;\\n        if (index == 0)\\n            m[0] = value;\\n        `;for(let n=1;n<t-1;++n)e+=`\\n        else if (index == ${n})\\n            m[${n}] = value;\\n            `;e+=`\\n        else\\n            m[${t-1}] = value;\\n        `;const n=`\\n      void setVecItem(out int m[${t}], int index, int value) {\\n        ${e}\\n      }\\n        `;return{setVecItem:new r.GlslLibRoutine(n)}}getVecItem(){const t=this.context.outputTextureLayout.shape.length;let e=`\\n        if(index < 0)\\n            index = ${t} + index;\\n        if (index == 0)\\n            return m[0];\\n      `;for(let n=1;n<t-1;++n)e+=`\\n        else if (index == ${n})\\n            return m[${n}];\\n      `;e+=`\\n        else\\n            return m[${t-1}];\\n        `;const n=`\\n      int getVecItem(int m[${t}], int index) {\\n        ${e}\\n      }\\n    `;return{getVecItem:new r.GlslLibRoutine(n)}}}e.VecGlslLib=i},8316:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.WebGLInferenceHandler=void 0;const r=n(6231),i=n(9162),o=n(2517),a=n(2403),s=n(7019),u=n(8710),c=n(5611),l=n(4057),p=n(2039);e.WebGLInferenceHandler=class{constructor(t){this.session=t,this.packedTextureDataCache=new Map,this.unpackedTextureDataCache=new Map}calculateTextureWidthAndHeight(t,e){return(0,l.calculateTextureWidthAndHeight)(this.session.layoutStrategy,t,e)}executeProgram(t,e){if(e.length<t.inputNames.length)throw new Error(`Input size mustn't be less than ${t.inputNames.length}.`);if(t.inputNames.length!==t.inputTypes.length)throw new Error(\"input names size does not match input types\");const n=[];for(let r=0;r<t.inputNames.length;++r)n[r]=this.getOrCreateTextureData(e[r],t.inputTypes[r]);const r=((t,e)=>{const n=e.map((t=>`${t.unpackedShape.join(\",\")};${t.width}x${t.height}`)).join(\"_\");let r=t.name;return t.cacheHint&&(r+=\"[\"+t.cacheHint+\"]\"),r+=\":\"+n,r})(t,n);let i=this.session.programManager.getArtifact(r);const o=i?i.programInfo:\"function\"==typeof t.get?t.get():t,a=(0,l.createTextureLayoutFromTextureType)(this.session.layoutStrategy,o.output.dims,o.output.textureType),s=this.createTextureData(a,o.output.type);return i||(i=this.session.programManager.build(o,n,s),this.session.programManager.setArtifact(r,i)),this.runProgram(i,n,s),s}run(t,e){return this.executeProgram(t,e).tensor}runProgram(t,e,n){for(let n=0;n<e.length;++n)if(!!e[n].isPacked!=(t.programInfo.inputTypes[n]===p.TextureType.packed))throw new Error(`input[${n}] property packed inconsistent`);if(!!n.isPacked!=(t.programInfo.output.textureType===p.TextureType.packed))throw new Error(\"output property packed inconsistent\");this.session.programManager.run(t,e,n)}getOrCreateTextureData(t,e){let n=this.getTextureData(t.dataId,e===p.TextureType.packed);if(!n&&(n=this.getTextureData(t.dataId,e!==p.TextureType.packed),n))return e===p.TextureType.packed?this.pack(n):this.unpack(n);if(!n){const r=(0,l.createTextureLayoutFromTextureType)(this.session.layoutStrategy,t.dims,e);if(e===p.TextureType.packedLastDimension){const n=1,r=4,i=t.dims;if(4===i.length){const o=[i[0],Math.ceil(i[1]*i[2]*i[3]/r)],a=(0,l.createTextureLayoutFromTextureType)(this.session.layoutStrategy,o,e);let s=t.numberData;if(i[1]*i[2]*i[3]%r!=0){const e=i[0],o=i[1]*i[2]*i[3],a=Math.ceil(o*n/r)*r;s=new Float32Array(e*a);for(let r=0;r<e;++r){const e=r*o,i=r*a+r%n*o;s.set(t.numberData.subarray(e,e+o),i)}}return this.createTextureData(a,t.type,s,t,1)}}if(e===p.TextureType.packed){const e=(0,l.createTextureLayoutFromShape)(this.session.layoutStrategy,t.dims,1,[],{reverseWH:!0}),r=this.createTextureData(e,t.type,t.numberData,t,1);n=this.pack(r)}else n=this.createTextureData(r,t.type,t.numberData,t,1)}return n}createTextureDataFromLayoutBindTensor(t,e,n,r){return this.createTextureData(t,e,n,r,1)}createTextureData(t,e,n,i,o){r.Logger.verbose(\"InferenceHandler\",`Creating TextureData: layout:[${JSON.stringify(t)}]`);const a=this.session.textureManager.createTextureFromLayout(e,t,n,o);return this.createTextureDataFromTexture(t,e,a,i)}reshapeUnpacked(t,e){const n=this.getOrCreateTextureData(t,p.TextureType.unpacked),r={channels:n.channels,height:n.height,width:n.width,shape:0!==e.length?e:[1],strides:o.ShapeUtil.computeStrides(e),unpackedShape:e};return this.createTextureDataFromTexture(r,t.type,n.texture).tensor}reshapePacked(t,e){const n=this.getOrCreateTextureData(t,p.TextureType.packed);if((0,s.isReshapeCheap)(t.dims,e)){const r={channels:n.channels,height:n.height,width:n.width,shape:0!==e.length?e:[1],strides:o.ShapeUtil.computeStrides(e),unpackedShape:e,isPacked:!0};return this.createTextureDataFromTexture(r,t.type,n.texture).tensor}const r=(0,s.processDims3D)(t.dims),i=(0,s.processDims3D)(e),a=this.reshapePacked(t,r),u=this.run((0,s.createPackedReshape3DProgramInfoLoader)(this,a,i),[a]);return this.reshapePacked(u,e)}cast(t,e){const n=this.getOrCreateTextureData(t,p.TextureType.unpacked);return this.createTextureDataFromTexture(n,e,n.texture).tensor}createTextureDataFromTexture(t,e,n,r,o){const a=Object.assign(Object.assign({},t),{tensor:r||new i.Tensor(t.unpackedShape,e,(t=>this.readTexture(a)),(async t=>this.readTextureAsync(a)),void 0,o),texture:n});return this.setTextureData(a.tensor.dataId,a,t.isPacked),a}getTextureData(t,e=!1){return this.session.isInitializer(t)?this.session.getTextureData(t,e):e?this.packedTextureDataCache.get(t):this.unpackedTextureDataCache.get(t)}setTextureData(t,e,n=!1){this.session.isInitializer(t)?this.session.setTextureData(t,e,n):(n?this.packedTextureDataCache:this.unpackedTextureDataCache).set(t,e)}isTextureLayoutCached(t,e=!1){return!!this.getTextureData(t.dataId,e)}dispose(){this.session.textureManager.clearActiveTextures(),this.packedTextureDataCache.forEach((t=>this.session.textureManager.releaseTexture(t))),this.packedTextureDataCache=new Map,this.unpackedTextureDataCache.forEach((t=>this.session.textureManager.releaseTexture(t))),this.unpackedTextureDataCache=new Map}readTexture(t){return t.isPacked?this.readTexture(this.unpack(t)):this.session.backend.glContext.isFloat32DownloadSupported?this.session.textureManager.readTexture(t,t.tensor.type,t.channels):this.session.textureManager.readUint8TextureAsFloat((0,u.encodeAsUint8)(this,t))}async readTextureAsync(t){return t.isPacked?this.readTextureAsync(this.unpack(t)):this.session.backend.glContext.isFloat32DownloadSupported?this.session.textureManager.readTextureAsync(t,t.tensor.type,t.channels):this.session.textureManager.readUint8TextureAsFloat((0,u.encodeAsUint8)(this,t))}pack(t){return this.executeProgram((0,a.createPackProgramInfoLoader)(this,t.tensor),[t.tensor])}unpack(t){return this.executeProgram((0,c.createUnpackProgramInfoLoader)(this,t.tensor),[t.tensor])}}},1640:function(t,e,n){\"use strict\";var r=this&&this.__createBinding||(Object.create?function(t,e,n,r){void 0===r&&(r=n);var i=Object.getOwnPropertyDescriptor(e,n);i&&!(\"get\"in i?!e.__esModule:i.writable||i.configurable)||(i={enumerable:!0,get:function(){return e[n]}}),Object.defineProperty(t,r,i)}:function(t,e,n,r){void 0===r&&(r=n),t[r]=e[n]}),i=this&&this.__setModuleDefault||(Object.create?function(t,e){Object.defineProperty(t,\"default\",{enumerable:!0,value:e})}:function(t,e){t.default=e}),o=this&&this.__importStar||function(t){if(t&&t.__esModule)return t;var e={};if(null!=t)for(var n in t)\"default\"!==n&&Object.prototype.hasOwnProperty.call(t,n)&&r(e,t,n);return i(e,t),e};Object.defineProperty(e,\"__esModule\",{value:!0}),e.WEBGL_OP_RESOLVE_RULES=void 0;const a=n(2898),s=o(n(7839)),u=n(4196),c=n(2069),l=n(8138),p=n(9663),f=n(5193),d=n(7992),h=n(1253),g=n(4776),b=n(6572),m=n(3346),y=n(5623),_=n(2870),v=n(2143),w=n(4939),x=n(718),T=n(2268),S=n(8117),O=n(2278),A=n(5524),E=n(5975),I=n(3933),P=n(6558),D=n(5723),$=n(3738),k=o(n(4909)),C=n(8428),F=n(9793);e.WEBGL_OP_RESOLVE_RULES=[[\"Abs\",\"\",\"6+\",k.abs],[\"Acos\",\"\",\"7+\",k.acos],[\"Add\",\"\",\"7+\",s.add],[\"And\",\"\",\"7+\",s.and],[\"Asin\",\"\",\"7+\",k.asin],[\"Atan\",\"\",\"7+\",k.atan],[\"AveragePool\",\"\",\"7+\",v.averagePool,v.parseAveragePoolAttributes],[\"BatchNormalization\",\"\",\"7+\",a.batchNormalization,a.parseBatchNormalizationAttributes],[\"Cast\",\"\",\"6+\",u.cast,u.parseCastAttributes],[\"Ceil\",\"\",\"6+\",k.ceil],[\"Clip\",\"\",\"6-10\",k.clip,k.parseClipAttributes],[\"Clip\",\"\",\"11+\",k.clipV11],[\"Concat\",\"\",\"4+\",c.concat,c.parseConcatAttributes],[\"Conv\",\"\",\"1+\",l.conv,l.parseConvAttributes],[\"ConvTranspose\",\"\",\"1+\",p.convTranspose,p.parseConvTransposeAttributes],[\"Cos\",\"\",\"7+\",k.cos],[\"Div\",\"\",\"7+\",s.div],[\"Dropout\",\"\",\"7+\",k.identity],[\"DepthToSpace\",\"\",\"1+\",f.depthToSpace,f.parseDepthToSpaceAttributes],[\"Equal\",\"\",\"7+\",s.equal],[\"Elu\",\"\",\"6+\",k.elu,k.parseEluAttributes],[\"Exp\",\"\",\"6+\",k.exp],[\"Flatten\",\"\",\"1+\",d.flatten,d.parseFlattenAttributes],[\"Floor\",\"\",\"6+\",k.floor],[\"FusedConv\",\"com.microsoft\",\"1+\",l.conv,l.parseConvAttributes],[\"Gather\",\"\",\"1+\",h.gather,h.parseGatherAttributes],[\"Gemm\",\"\",\"7-10\",g.gemm,g.parseGemmAttributesV7],[\"Gemm\",\"\",\"11+\",g.gemm,g.parseGemmAttributesV11],[\"GlobalAveragePool\",\"\",\"1+\",v.globalAveragePool,v.parseGlobalAveragePoolAttributes],[\"GlobalMaxPool\",\"\",\"1+\",v.globalMaxPool],[\"Greater\",\"\",\"7+\",s.greater],[\"Identity\",\"\",\"1+\",k.identity],[\"ImageScaler\",\"\",\"1+\",b.imageScaler,b.parseImageScalerAttributes],[\"InstanceNormalization\",\"\",\"6+\",m.instanceNormalization,m.parseInstanceNormalizationAttributes],[\"LeakyRelu\",\"\",\"6+\",k.leakyRelu,k.parseLeakyReluAttributes],[\"Less\",\"\",\"7+\",s.less],[\"Log\",\"\",\"6+\",k.log],[\"MatMul\",\"\",\"1+\",y.matMul,y.parseMatMulAttributes],[\"MaxPool\",\"\",\"1+\",v.maxPool,v.parseMaxPoolAttributes],[\"Mul\",\"\",\"7+\",s.mul],[\"Neg\",\"\",\"6+\",k.neg],[\"Not\",\"\",\"1+\",k.not],[\"Or\",\"\",\"7+\",s.or],[\"Pad\",\"\",\"2-10\",_.padV2,_.parsePadAttributesV2],[\"Pad\",\"\",\"11+\",_.padV11,_.parsePadAttributesV11],[\"Pow\",\"\",\"7+\",s.pow],[\"PRelu\",\"\",\"7+\",s.pRelu],[\"ReduceLogSum\",\"\",\"1+\",w.reduceLogSum,w.parseReduceAttributes],[\"ReduceMax\",\"\",\"1+\",w.reduceMax,w.parseReduceAttributes],[\"ReduceMean\",\"\",\"1+\",w.reduceMean,w.parseReduceAttributes],[\"ReduceMin\",\"\",\"1+\",w.reduceMin,w.parseReduceAttributes],[\"ReduceProd\",\"\",\"1+\",w.reduceProd,w.parseReduceAttributes],[\"ReduceSum\",\"\",\"1-12\",w.reduceSum,w.parseReduceAttributes],[\"ReduceSumSquare\",\"\",\"1+\",w.reduceLogSumSquare,w.parseReduceAttributes],[\"Relu\",\"\",\"6+\",k.relu],[\"Reshape\",\"\",\"5+\",x.reshape],[\"Resize\",\"\",\"10\",T.resize,T.parseResizeAttributesV10],[\"Resize\",\"\",\"11+\",T.resize,T.parseResizeAttributesV11],[\"Shape\",\"\",\"1+\",S.shape],[\"Sigmoid\",\"\",\"6+\",k.sigmoid],[\"Sin\",\"\",\"7+\",k.sin],[\"Slice\",\"\",\"10+\",O.sliceV10],[\"Slice\",\"\",\"1-9\",O.slice,O.parseSliceAttributes],[\"Softmax\",\"\",\"1-12\",A.softmax,A.parseSoftmaxAttributes],[\"Softmax\",\"\",\"13+\",A.softmaxV13,A.parseSoftmaxAttributesV13],[\"Split\",\"\",\"2-12\",E.split,E.parseSplitAttributes],[\"Sqrt\",\"\",\"6+\",k.sqrt],[\"Squeeze\",\"\",\"1-12\",I.squeeze,I.parseSqueezeAttributes],[\"Squeeze\",\"\",\"13+\",I.squeezeV13],[\"Sub\",\"\",\"7+\",s.sub],[\"Sum\",\"\",\"6+\",P.sum],[\"Tan\",\"\",\"7+\",k.tan],[\"Tanh\",\"\",\"6+\",k.tanh],[\"Tile\",\"\",\"6+\",D.tile],[\"Transpose\",\"\",\"1+\",$.transpose,$.parseTransposeAttributes],[\"Upsample\",\"\",\"7-8\",F.upsample,F.parseUpsampleAttributesV7],[\"Upsample\",\"\",\"9\",F.upsample,F.parseUpsampleAttributesV9],[\"Unsqueeze\",\"\",\"1-12\",C.unsqueeze,C.parseUnsqueezeAttributes],[\"Unsqueeze\",\"\",\"13+\",C.unsqueezeV13],[\"Xor\",\"\",\"7+\",s.xor]]},2898:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.parseBatchNormalizationAttributes=e.batchNormalization=void 0;const r=n(246),i=n(5060),o=n(2039),a={name:\"BatchNormalization\",inputNames:[\"A\",\"Scale\",\"B\",\"Mean\",\"Variance\"],inputTypes:[o.TextureType.unpacked,o.TextureType.unpacked,o.TextureType.unpacked,o.TextureType.unpacked,o.TextureType.unpacked]};e.batchNormalization=(t,e,n)=>(u(e),[t.run(Object.assign(Object.assign({},a),{cacheHint:n.cacheKey,get:()=>s(t,e,n)}),e)]),e.parseBatchNormalizationAttributes=t=>{const e=t.attributes.getFloat(\"epsilon\",1e-5),n=t.attributes.getFloat(\"momentum\",.9),i=t.attributes.getInt(\"spatial\",1);return(0,r.createAttributeWithCacheKey)({epsilon:e,momentum:n,spatial:i})};const s=(t,e,n)=>{const r=(0,i.getGlsl)(t.session.backend.glContext.version),s=e[0].dims.length,[u,c]=t.calculateTextureWidthAndHeight(e[1].dims,o.TextureType.unpacked),l=`\\n  float process(int[${s}] indices) {\\n    vec2 position = offsetToCoords(indices[1], ${u}, ${c});\\n    float scale = getColorAsFloat(${r.texture2D}(Scale, position));\\n    float mean = getColorAsFloat(${r.texture2D}(Mean, position));\\n    float variance = getColorAsFloat(${r.texture2D}(Variance, position));\\n    float b = getColorAsFloat(${r.texture2D}(B, position));\\n\\n    return scale * ( (_A(indices) - mean) / sqrt(variance + float(${n.epsilon})) ) + b;\\n  }`;return Object.assign(Object.assign({},a),{output:{dims:e[0].dims,type:e[0].type,textureType:o.TextureType.unpacked},shaderSource:l})},u=t=>{if(!t||5!==t.length)throw new Error(\"BatchNormalization requires 5 inputs.\");const e=t[0],n=t[1],r=t[2],i=t[3],o=t[4];if(e.dims.length<3||1!==n.dims.length||1!==r.dims.length||1!==i.dims.length||1!==o.dims.length)throw new Error(\"invalid input shape.\");if(n.dims[0]!==e.dims[1]||r.dims[0]!==e.dims[1]||i.dims[0]!==e.dims[1]||o.dims[0]!==e.dims[1])throw new Error(\"invalid input shape.\");if(\"float32\"!==e.type&&\"float64\"!==e.type||\"float32\"!==n.type&&\"float64\"!==n.type||\"float32\"!==r.type&&\"float64\"!==r.type||\"float32\"!==i.type&&\"float64\"!==i.type||\"float32\"!==o.type&&\"float64\"!==o.type)throw new Error(\"invalid input tensor types.\")}},7839:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.xor=e.sub=e.pRelu=e.pow=e.or=e.mul=e.less=e.greater=e.equal=e.div=e.and=e.add=e.glslPRelu=e.glslPow=e.glslXor=e.glslOr=e.glslAnd=e.glslLess=e.glslGreater=e.glslEqual=e.glslSub=e.glslMul=e.glslDiv=e.glslAdd=void 0;const r=n(2517),i=n(8520),o=n(5060),a=n(2039);function s(){const t=\"add_\";return{body:`\\n  float ${t}(float a, float b) {\\n    return a + b;\\n  }\\n  vec4 ${t}(vec4 v1, vec4 v2) {\\n    return v1 + v2;\\n  }\\n  `,name:t,type:i.FunctionType.ValueBased}}function u(){const t=\"div_\";return{body:`\\n  float ${t}(float a, float b) {\\n    return a / b;\\n  }\\n  vec4 ${t}(vec4 v1, vec4 v2) {\\n    return v1 / v2;\\n  }\\n  `,name:t,type:i.FunctionType.ValueBased}}function c(){const t=\"mul_\";return{body:`\\n  float ${t}(float a, float b) {\\n    return a * b;\\n  }\\n  vec4 ${t}(vec4 v1, vec4 v2) {\\n    return v1 * v2;\\n  }\\n  `,name:t,type:i.FunctionType.ValueBased}}function l(){const t=\"sub_\";return{body:`\\n  float ${t}(float a, float b) {\\n    return a - b;\\n  }\\n  vec4 ${t}(vec4 v1, vec4 v2) {\\n    return v1 - v2;\\n  }\\n  `,name:t,type:i.FunctionType.ValueBased}}function p(){const t=\"equal_\";return{body:`\\n  float ${t}(float a, float b) {\\n    return float(a == b);\\n  }\\n  vec4 ${t}(vec4 v1, vec4 v2) {\\n    return vec4(equal(v1, v2));\\n  }\\n  `,name:t,type:i.FunctionType.ValueBased}}function f(){const t=\"greater_\";return{body:`\\n  float ${t}(float a, float b) {\\n    return float(a > b);\\n  }\\n  vec4 ${t}(vec4 v1, vec4 v2) {\\n    return vec4( v1.r > v2.r ,\\n      v1.g > v2.g,\\n      v1.b > v2.b,\\n      v1.a > v2.a );\\n  }\\n  `,name:t,type:i.FunctionType.ValueBased}}function d(){const t=\"less_\";return{body:`\\n  float ${t}(float a, float b) {\\n    return float(a < b);\\n  }\\n  vec4 ${t}(vec4 v1, vec4 v2) {\\n    return vec4( v1.r < v2.r ,\\n                v1.g < v2.g,\\n                v1.b < v2.b,\\n                v1.a < v2.a );\\n  }\\n  `,name:t,type:i.FunctionType.ValueBased}}function h(){const t=\"and_\";return{body:`\\n  float ${t}(float a, float b) {\\n    return float( bool(a) && bool(b) );\\n  }\\n  vec4 ${t}(vec4 v1, vec4 v2) {\\n    bvec4 b1 = bvec4(v1);\\n    bvec4 b2 = bvec4(v2);\\n    return vec4( b1.r && b2.r ,\\n                b1.g && b2.g,\\n                b1.b && b2.b,\\n                b1.a && b2.a );\\n  }\\n  `,name:t,type:i.FunctionType.ValueBased}}function g(){const t=\"or_\";return{body:`\\n  float ${t}(float a, float b) {\\n    return float( bool(a) || bool(b) );\\n  }\\n  vec4 ${t}(vec4 v1, vec4 v2) {\\n    bvec4 b1 = bvec4(v1);\\n    bvec4 b2 = bvec4(v2);\\n    return vec4( b1.r || b2.r ,\\n                b1.g || b2.g,\\n                b1.b || b2.b,\\n                b1.a || b2.a );\\n  }\\n  `,name:t,type:i.FunctionType.ValueBased}}function b(){const t=\"xor_\";return{body:`\\n  float ${t}(float a, float b) {\\n    return float( bool(a) ^^ bool(b) );\\n  }\\n  vec4 ${t}(vec4 v1, vec4 v2) {\\n    bvec4 b1 = bvec4(v1);\\n    bvec4 b2 = bvec4(v2);\\n    return vec4( b1.r ^^ b2.r ,\\n                b1.g ^^ b2.g,\\n                b1.b ^^ b2.b,\\n                b1.a ^^ b2.a );\\n  }\\n  `,name:t,type:i.FunctionType.ValueBased}}function m(){return function(t){const e=`${t}_`;return{body:`\\n  float ${e}(float a, float b) {\\n    return ${t}(a, b);\\n  }\\n  vec4 ${e}(vec4 v1, vec4 v2) {\\n    return ${t}(v1, v2);\\n  }\\n  `,name:e,type:i.FunctionType.ValueBased}}(\"pow\")}function y(){const t=\"prelu_\";return{body:`\\n  float ${t}(float a, float b) {\\n    return a < 0.0 ? a * b: a;\\n  }\\n  vec4 ${t}(vec4 v1, vec4 v2) {\\n    return vec4(\\n      v1.r < 0.0 ? v1.r * v2.r: v1.r,\\n      v1.g < 0.0 ? v1.g * v2.g: v1.g,\\n      v1.b < 0.0 ? v1.b * v2.b: v1.b,\\n      v1.a < 0.0 ? v1.a * v2.a: v1.a\\n      );\\n  }\\n  `,name:t,type:i.FunctionType.ValueBased}}e.glslAdd=s,e.glslDiv=u,e.glslMul=c,e.glslSub=l,e.glslEqual=p,e.glslGreater=f,e.glslLess=d,e.glslAnd=h,e.glslOr=g,e.glslXor=b,e.glslPow=m,e.glslPRelu=y;const _=(t,e,n,r=e[0].type,i)=>{const o=t.session.pack?a.TextureType.packed:a.TextureType.unpacked;return{name:n.name,inputNames:[\"A\",\"B\"],inputTypes:[o,o],cacheHint:i,get:()=>v(t,e,n,r)}},v=(t,e,n,i=e[0].type)=>{const s=t.session.pack?a.TextureType.packed:a.TextureType.unpacked,u=!r.ShapeUtil.areEqual(e[0].dims,e[1].dims);let c=e[0].dims;const l=t.session.pack;if(u){const a=r.BroadcastUtil.calcShape(e[0].dims,e[1].dims,!1);if(!a)throw new Error(\"Can't perform binary op on the given tensors\");c=a;const u=c.length,p=0!==e[0].dims.length?e[0].dims.length:1,f=0!==e[1].dims.length?e[1].dims.length:1,d=0!==e[0].dims.length?\"bcastIndices_A(indices, aindices);\":\"aindices[0] = 0;\",h=0!==e[1].dims.length?\"bcastIndices_B(indices, bindices);\":\"bindices[0] = 0;\",g=(0,o.getGlsl)(t.session.backend.glContext.version),b=l?`\\n      ${n.body}\\n      void main() {\\n        vec4 a = getAAtOutCoords();\\n        vec4 b = getBAtOutCoords();\\n        vec4 result = ${n.name}(a, b);\\n        ${g.output} = result;\\n      }`:`\\n      ${n.body}\\n      float process(int indices[${u}]) {\\n        int aindices[${p}];\\n        int bindices[${f}];\\n        ${d}\\n        ${h}\\n        return ${n.name}(_A(aindices), _B(bindices));\\n      }`;return{name:n.name,inputNames:[\"A\",\"B\"],inputTypes:[s,s],output:{dims:c,type:i,textureType:s},shaderSource:b,hasMain:l}}const p=(0,o.getGlsl)(t.session.backend.glContext.version),f=`\\n    ${n.body}\\n    void main() {\\n      vec4 v1 = ${p.texture2D}(A, TexCoords);\\n      vec4 v2 = ${p.texture2D}(B, TexCoords);\\n      vec4 result = ${n.name}(v1, v2);\\n      ${p.output} = result;\\n    }\\n    `;return{name:n.name,inputNames:[\"A\",\"B\"],inputTypes:[s,s],output:{dims:e[0].dims,type:i,textureType:s},shaderSource:f,hasMain:!0}};e.add=(t,e)=>[t.run(_(t,e,s()),e)],e.and=(t,e)=>[t.run(_(t,e,h(),\"bool\"),e)],e.div=(t,e)=>[t.run(_(t,e,u()),e)],e.equal=(t,e)=>[t.run(_(t,e,p(),\"bool\"),e)],e.greater=(t,e)=>[t.run(_(t,e,f(),\"bool\"),e)],e.less=(t,e)=>[t.run(_(t,e,d(),\"bool\"),e)],e.mul=(t,e)=>[t.run(_(t,e,c()),e)],e.or=(t,e)=>[t.run(_(t,e,g(),\"bool\"),e)],e.pow=(t,e)=>[t.run(_(t,e,m()),e)],e.pRelu=(t,e)=>[t.run(_(t,e,y()),e)],e.sub=(t,e)=>[t.run(_(t,e,l()),e)],e.xor=(t,e)=>[t.run(_(t,e,b(),\"bool\"),e)]},4196:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.parseCastAttributes=e.cast=void 0;const r=n(2517);e.cast=(t,e,n)=>(i(e),[t.cast(e[0],n)]),e.parseCastAttributes=t=>r.ProtoUtil.tensorDataTypeFromProto(t.attributes.getInt(\"to\"));const i=t=>{if(!t||1!==t.length)throw new Error(\"Cast requires 1 input.\");if(\"string\"===t[0].type)throw new Error(\"Invalid input type.\")}},1163:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.createPackedConcatProgramInfoLoader=void 0;const r=n(5060),i=n(2039),o=n(9390),a=n(2827);e.createPackedConcatProgramInfoLoader=(t,e,n)=>{const u=(c=e.length,l=n.cacheKey,{name:\"Concat (packed)\",inputNames:Array.from({length:c},((t,e)=>`X${e}`)),inputTypes:Array(c).fill(i.TextureType.packed),cacheHint:l});var c,l;return Object.assign(Object.assign({},u),{get:()=>((t,e,n,u)=>{const c=n[0].dims.slice();if(u>=c.length||u<-1*c.length)throw new Error(\"axis specified for concat doesn't match input dimensionality\");u<0&&(u=c.length+u);const l=c.slice(0);for(let t=1;t<n.length;t++){const e=n[t].dims.slice();for(let t=0;t<c.length;t++)if(t===u)l[u]+=e[t];else if(c[t]!==e[t])throw new Error(\"non concat dimensions must match\")}const p=l.length,f=(0,a.getChannels)(\"coords\",p),d=(0,o.getCoordsDataType)(p),h=(0,a.unpackFromChannel)(),g=n.map((t=>t.dims)),b=(0,o.getGlChannels)(p),m=new Array(g.length-1);m[0]=g[0][u];for(let t=1;t<m.length;t++)m[t]=m[t-1]+g[t][u];const y=b[u],_=b.slice(-2),v=b.join();let w=`if (${y} < ${m[0]}) {\\n        return getChannel(\\n            getX0(${v}), vec2(${_.join()}));\\n        }`;for(let t=1;t<m.length;t++){const e=m[t-1];w+=`\\n            if (${y} < ${m[t]}  && ${y} >= ${m[t-1]}) {\\n              return getChannel(\\n                getX${t}(${s(b,y,e)}),\\n                vec2(${s(_,y,e)}));\\n            }`}const x=m.length,T=m[m.length-1];w+=`\\n            return getChannel(\\n              getX${x}(${s(b,y,T)}),\\n              vec2(${s(_,y,T)}));`;const S=(0,r.getGlsl)(t.session.backend.glContext.version),O=`\\n          ${h}\\n          float getValue(${b.map((t=>\"int \"+t))}) {\\n            ${w}\\n          }\\n\\n          void main() {\\n            ${d} coords = getOutputCoords();\\n            int lastDim = coords.${b[p-1]};\\n            coords.${b[p-1]} = coords.${b[p-2]};\\n            coords.${b[p-2]} = lastDim;\\n\\n            vec4 result = vec4(getValue(${f}), 0., 0., 0.);\\n\\n            ${f[p-1]} = ${f[p-1]} + 1;\\n            if (${f[p-1]} < ${l[p-1]}) {\\n              result.g = getValue(${f});\\n            }\\n\\n            ${f[p-2]} = ${f[p-2]} + 1;\\n            if (${f[p-2]} < ${l[p-2]}) {\\n              result.a = getValue(${f});\\n            }\\n\\n            ${f[p-1]} = ${f[p-1]} - 1;\\n            if (${f[p-2]} < ${l[p-2]} &&\\n                ${f[p-1]} < ${l[p-1]}) {\\n              result.b = getValue(${f});\\n            }\\n            ${S.output} = result;\\n          }\\n        `;return Object.assign(Object.assign({},e),{output:{dims:l,type:n[0].type,textureType:i.TextureType.packed},shaderSource:O,hasMain:!0})})(t,u,e,n.axis)})};const s=(t,e,n)=>{const r=t.indexOf(e);return t.map(((t,e)=>e===r?`${t} - ${n}`:t)).join()}},2069:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.parseConcatAttributes=e.concat=void 0;const r=n(246),i=n(2039),o=n(1163);e.concat=(t,e,n)=>(p(e),t.session.pack&&e[0].dims.length>1?[t.run((0,o.createPackedConcatProgramInfoLoader)(t,e,n),e)]:[t.run(a(t,e,n),e)]);const a=(t,e,n)=>{const r=(o=e.length,a=n.cacheKey,{name:\"Concat\",inputNames:Array.from({length:o},((t,e)=>`X${e}`)),inputTypes:Array(o).fill(i.TextureType.unpacked),cacheHint:a});var o,a;return Object.assign(Object.assign({},r),{get:()=>((t,e,n,r)=>{const o=n[0].dims.slice();if(r>=o.length||r<-1*o.length)throw new Error(\"axis specified for concat doesn't match input dimensionality\");r<0&&(r=o.length+r);const a=o.slice(0);for(let t=1;t<n.length;t++){const e=n[t].dims.slice();for(let t=0;t<o.length;t++)if(t===r)a[r]+=e[t];else if(o[t]!==e[t])throw new Error(\"non concat dimensions must match\")}const p=a.length,f=new Array(n.length);let d=0;for(let t=0;t<f.length;++t)d+=n[t].dims[r],f[t]=d;let h=\"\";h=n.length<5?s(f):u(f);const g=`\\n        ${c(n.length,p)}\\n        ${l(f)}\\n        ${h}\\n        float process(int indices[${p}]) {\\n          int textureIndex = getTextureWhereDataResides (indices[${r}]);\\n\\n          if(textureIndex != 0) {\\n            indices[${r}] = indices[${r}] - int(getSizeInConcatAxisValueFromIndex(textureIndex-int(1)));\\n          }\\n\\n          return fetchDataFromCorrectTexture(textureIndex, indices);\\n        }`;return Object.assign(Object.assign({},e),{output:{dims:a,type:n[0].type,textureType:i.TextureType.unpacked},shaderSource:g})})(0,r,e,n.axis)})},s=t=>`int getTextureWhereDataResides(int index) {\\n      ${t.map(((t,e)=>`if(index<${t}) {return ${e};}\\n`)).join(\"\")}\\n    }`,u=t=>s(t),c=(t,e)=>{const n=[`float fetchDataFromCorrectTexture(int textureIndex, int indices[${e}]) {`];for(let e=0;e<t;++e)0===e?n.push(`\\tif (textureIndex == ${e}) { return _X${e}(indices); }`):e===t-1?n.push(`\\telse { return _X${e}(indices); }`):n.push(`\\telse if (textureIndex == ${e}) { return _X${e}(indices); }`);return n.push(\"\\t}\"),n.join(\"\\n\")},l=t=>{const e=[\"int getSizeInConcatAxisValueFromIndex(int index) {\"];for(let n=0;n<t.length;++n)0===n?e.push(`\\tif (index == ${n}) { return ${t[n]}; }`):n===t.length-1?e.push(`\\telse { return ${t[n]}; }`):e.push(`\\telse if (index == ${n}) { return ${t[n]}; }`);return e.push(\"\\t}\"),e.join(\"\\n\")};e.parseConcatAttributes=t=>(0,r.createAttributeWithCacheKey)({axis:t.attributes.getInt(\"axis\")});const p=t=>{if(!t||t.length<1)throw new Error(\"too few inputs\");const e=t[0].type,n=t[0].dims.length;if(\"string\"===e)throw new Error(\"string tensor is not supported yet\");for(const r of t){if(r.type!==e)throw new Error(\"input tensors should be one type\");if(r.dims.length!==n)throw new Error(\"input tensors should have the same shape\")}}},4770:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.createUnpackedGroupedConvProgramInfoLoader=void 0;const r=n(6231),i=n(5060),o=n(2039),a=n(8138),s=n(2823);e.createUnpackedGroupedConvProgramInfoLoader=(t,e,n)=>{const u=(c=e.length>2,l=n.cacheKey,{name:\"GroupedConv\",inputNames:c?[\"X\",\"W\",\"Bias\"]:[\"X\",\"W\"],inputTypes:c?[o.TextureType.unpacked,o.TextureType.unpacked,o.TextureType.unpacked]:[o.TextureType.unpacked,o.TextureType.unpacked],cacheHint:l});var c,l;return Object.assign(Object.assign({},u),{get:()=>((t,e,n,u)=>{const c=e.length>2?\"value += getBias(output_channel);\":\"\",l=e[0].dims.slice(),p=e[1].dims.slice(),f=p[0]/u.group;r.Logger.verbose(\"GroupedConv\",`autpPad:${u.autoPad}, dilations:${u.dilations}, group:${u.group}, kernelShape:${u.kernelShape}, pads:${u.pads}, strides:${u.strides}`);const d=(0,a.calculateOutputShape)(l,p,u.dilations,u.pads,u.strides),h=(0,i.getGlsl)(t.session.backend.glContext.version),{activationFunction:g,applyActivation:b}=(0,s.getActivationSnippet)(u),m=`\\n  const ivec2 strides = ivec2(${u.strides[0]}, ${u.strides[1]});\\n  const ivec2 pads = ivec2(${u.pads[0]}, ${u.pads[1]});\\n  ${g}\\n  void main() {\\n    ivec4 coords = getOutputCoords();\\n    int batch = coords.x;\\n    int output_channel = coords.y;\\n    ivec2 xRCCorner = coords.zw * strides - pads;\\n    int group_id = output_channel / ${f};\\n\\n    float value = 0.0;\\n    for (int wInChannel = 0; wInChannel < ${p[1]}; wInChannel++) {\\n      int input_channel = group_id * ${p[1]} + wInChannel;\\n      for (int wHeight = 0; wHeight < ${p[2]}; wHeight++) {\\n        int xHeight = xRCCorner.x + wHeight * ${u.dilations[0]};\\n\\n        if (xHeight < 0 || xHeight >= ${l[2]}) {\\n          continue;\\n        }\\n\\n        for (int wWidth = 0; wWidth < ${p[3]}; wWidth++) {\\n          int xWidth = xRCCorner.y + wWidth * ${u.dilations[1]};\\n          if (xWidth < 0 || xWidth >= ${l[3]}) {\\n            continue;\\n          }\\n\\n          float xVal = getX(batch, input_channel, xWidth, xHeight);\\n          float wVal = getW(output_channel, wInChannel, wWidth, wHeight);\\n          value += xVal*wVal;\\n        }\\n      }\\n    }\\n    ${c}\\n    ${b}\\n    ${h.output} = vec4(value, .0, .0, .0);\\n  }\\n`;return Object.assign(Object.assign({},n),{output:{dims:d,type:e[0].type,textureType:o.TextureType.unpacked},shaderSource:m,hasMain:!0})})(t,e,u,n)})}},1386:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.conv2DPacked=e.conv2DPackedPointwise=void 0;const r=n(8138),i=n(8555),o=n(708);e.conv2DPackedPointwise=(t,e,n)=>{const i=e[0].dims,a=e[1].dims,s=(0,r.calculateOutputShape)(i,a,n.dilations,n.pads,n.strides),u=t.reshapePacked(e[0],[i[1],i[2]*i[3]]),c=t.reshapePacked(e[1],[a[0],a[1]]),l=e.length>2?[c,u,e[2]]:[c,u],p=t.run((0,o.createPackedMatmulProgramInfoLoader)(t,l,n),l);return t.reshapePacked(p,s)},e.conv2DPacked=(t,e,n)=>{const a=e[0].dims,s=e[1].dims,u=(0,r.calculateOutputShape)(a,s,n.dilations,n.pads,n.strides),c=t.run((0,i.createPackedIm2ColProgramInfoLoader)(t,e[0],e[1],u,n),[e[0]]),l=t.reshapePacked(e[1],[s[0],s[1]*s[2]*s[3]]),p=3===e.length?[l,c,e[2]]:[l,c],f=t.run((0,o.createPackedMatmulProgramInfoLoader)(t,p,n),p);return t.reshapePacked(f,u)}},9663:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.parseConvTransposeAttributes=e.convTranspose=void 0;const r=n(246),i=n(5060),o=n(2039),a=n(2823),s=(t,e,n,r,i,o)=>(t-1)*e+n+(r-1)*i+1-o,u=(t,e,n,r,i)=>{const o=Math.floor(t/2);\"SAME_UPPER\"===e?(n[r]=o,n[i]=t-o):\"SAME_LOWER\"===e&&(n[r]=t-o,n[i]=o)};e.convTranspose=(t,e,n)=>(f(e,n),c(t,e,n));const c=(t,e,n)=>{const r=p(n,e);return[l(t,e,r)]},l=(t,e,n)=>t.run(((t,e,n)=>{const r=(s=e.length>2,u=n.cacheKey,{name:\"ConvTranspose\",inputNames:s?[\"X\",\"W\",\"B\"]:[\"X\",\"W\"],inputTypes:s?[o.TextureType.unpacked,o.TextureType.unpacked,o.TextureType.unpacked]:[o.TextureType.unpacked,o.TextureType.unpacked],cacheHint:u});var s,u;return Object.assign(Object.assign({},r),{get:()=>((t,e,n,r)=>{const s=e.length>2?\"getB(output_channel)\":\"0.0\",u=e[0].dims,c=e[1].dims,l=c[1],p=c[0]/r.group,f=[e[0].dims[0],e[1].dims[1]*r.group,...r.outputShape],d=(0,i.getGlsl)(t.session.backend.glContext.version),{activationFunction:h,applyActivation:g}=(0,a.getActivationSnippet)(r),b=`\\n  const ivec2 strides = ivec2(${r.strides[0]}, ${r.strides[1]});\\n  const ivec2 pads = ivec2(${r.pads[0]}, ${r.pads[1]});\\n  ${h}\\n  void main() {\\n    ivec4 coords = getOutputCoords();\\n    int batch = coords.x;\\n    int output_channel = coords.y;\\n\\n    ivec2 loc = coords.zw + pads;\\n\\n    int group_id = output_channel / ${l};\\n    int wOutChannel = output_channel - group_id * ${l};\\n\\n    float value = ${s};\\n    for (int inChannelOffset = 0; inChannelOffset < ${p}; inChannelOffset++) {\\n      int input_channel = group_id * ${p} + inChannelOffset;\\n      for (int wWOff = 0; wWOff < ${c[2]}; wWOff++) {\\n        for (int wHOff = 0; wHOff < ${c[3]}; wHOff++) {\\n          ivec2 wOff = ivec2(wWOff * ${r.dilations[0]}, wHOff * ${r.dilations[1]});\\n          ivec2 wLoc = loc - wOff;\\n          ivec2 wLocIn = wLoc / strides;\\n          if (\\n            wLocIn * strides == wLoc &&\\n            wLocIn.x >= 0 && wLocIn.x < ${u[2]} &&\\n            wLocIn.y >= 0 && wLocIn.y < ${u[3]}\\n          ) {\\n            float xVal = getX(batch, input_channel, wLocIn.y, wLocIn.x);\\n            float wVal = getW(input_channel, wOutChannel, wHOff, wWOff);\\n            value += xVal * wVal;\\n          }\\n        }\\n      }\\n    }\\n    ${g}\\n    ${d.output} = vec4(value, .0, .0, .0);\\n  }\\n`;return Object.assign(Object.assign({},n),{output:{dims:f,type:e[0].type,textureType:o.TextureType.unpacked},shaderSource:b,hasMain:!0})})(t,e,r,n)})})(t,e,n),e),p=(t,e)=>{const n=t.kernelShape.slice();if(0===t.kernelShape.length)for(let t=2;t<e[1].dims.length;++t)n.push(e[1].dims[t]);const r=t.pads.slice(),i=t.outputShape.slice();((t,e,n,r,i,o,a,c)=>{const l=t.length-2,p=0===c.length;for(let f=0;f<l;++f){const d=p?t[f+2]*o[f]:c[f],h=s(t[f+2],o[f],i[f],e[f],n[f],d);u(h,r,i,f,f+l),p&&c.push(o[f]*(t[f+2]-1)+a[f]+(e[f]-1)*n[f]+1-i[f]-i[f+l])}})(e[0].dims,n,t.dilations,t.autoPad,r,t.strides,t.outputPadding,i);const o=Object.assign({},t);return Object.assign(o,{kernelShape:n,pads:r,outputShape:i,cacheKey:t.cacheKey}),o};e.parseConvTransposeAttributes=t=>{const e=t.attributes,n=(0,a.parseInternalActivationAttributes)(e),i=e.getString(\"auto_pad\",\"NOTSET\"),o=e.getInts(\"dilations\",[1,1]),s=e.getInt(\"group\",1),u=e.getInts(\"kernel_shape\",[]),c=e.getInts(\"output_padding\",[0,0]),l=e.getInts(\"output_shape\",[]),p=e.getInts(\"pads\",[0,0,0,0]),f=e.getInts(\"strides\",[1,1]);return(0,r.createAttributeWithCacheKey)(Object.assign({autoPad:i,dilations:o,group:s,kernelShape:u,outputPadding:c,outputShape:l,pads:p,strides:f},n))};const f=(t,e)=>{if(!t||2!==t.length&&3!==t.length)throw new Error(\"Conv requires 2 or 3 inputs\");if(4!==t[0].dims.length||4!==t[1].dims.length)throw new Error(\"currently only support 2-dimensional conv\");if(t[0].dims[1]!==t[1].dims[0])throw new Error(\"FILTER_IN_CHANNEL should be equal to DATA_CHANNEL\");const n=t[1].dims[1]*e.group;if(3===t.length&&(1!==t[2].dims.length||t[2].dims[0]!==n))throw new Error(\"invalid bias\");const r=t[0].dims.length-2;if(e.dilations.length!==r)throw new Error(`dilations should be ${r}D`);if(e.strides.length!==r)throw new Error(`strides should be ${r}D`);if(e.pads.length!==2*r)throw new Error(`pads should be ${2*r}D`);if(e.outputPadding.length!==r)throw new Error(`output_padding should be ${r}D`);if(0!==e.kernelShape.length&&e.kernelShape.length!==t[1].dims.length-2)throw new Error(\"invalid kernel shape\");if(0!==e.outputShape.length&&e.outputShape.length!==t[0].dims.length-2)throw new Error(\"invalid output shape\");if(\"float32\"!==t[0].type||\"float32\"!==t[1].type)throw new Error(\"ConvTranspose input(X,W) should be float tensor\");if(3===t.length&&\"float32\"!==t[2].type)throw new Error(\"ConvTranspose input(bias) should be float tensor\")}},8138:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.parseConvAttributes=e.conv=e.calculateOutputShape=void 0;const r=n(246),i=n(2517),o=n(4770),a=n(1386),s=n(9828),u=n(2823),c=n(3248),l=n(5623);e.calculateOutputShape=(t,e,n,r,i)=>{const o=t[0],a=t.slice(2),s=a.length,u=e[0],c=e.slice(2).map(((t,e)=>t+(t-1)*(n[e]-1))),l=a.map(((t,e)=>t+r[e]+r[e+s])).map(((t,e)=>Math.floor((t-c[e]+i[e])/i[e])));return[o,u].concat(...l)},e.conv=(t,e,n)=>(g(e,n),p(t,e,n));const p=(t,e,n)=>{const r=h(n,e),i=t.session.pack,s=1===r.kernelShape[0]&&1===r.kernelShape[1];return r.group>1?[t.run((0,o.createUnpackedGroupedConvProgramInfoLoader)(t,e,r),e)]:s&&i?[f(t,e,r)]:i&&4===e[0].dims.length&&1===e[0].dims[0]&&!s?[(0,a.conv2DPacked)(t,e,r)]:[d(t,e,r)]},f=(t,n,r)=>{const i=n[0].dims,o=n[1].dims,a=(0,e.calculateOutputShape)(i,o,r.dilations,r.pads,r.strides),s=t.reshapeUnpacked(n[0],[i[1],i[2]*i[3]]),u=t.reshapeUnpacked(n[1],[o[0],o[1]]),c=n.length>2?[u,s,n[2]]:[u,s],p=t.run((0,l.createMatmulProgramInfoLoader)(c,r),c);return t.reshapeUnpacked(p,a)},d=(t,n,r)=>{const i=n[0].dims,o=n[1].dims,a=(0,e.calculateOutputShape)(i,o,r.dilations,r.pads,r.strides),u=t.run((0,c.createIm2ColProgramInfoLoader)(t,n[0],n[1],a,r),[n[0]]),l=3===n.length?[u,n[1],n[2]]:[u,n[1]];return t.run((0,s.createDotProductProgramInfoLoader)(t,n,a,r),l)},h=(t,e)=>{const n=t.kernelShape.slice();if(0===t.kernelShape.length)for(let t=2;t<e[1].dims.length;++t)n.push(e[1].dims[t]);const r=t.pads.slice();i.PoolConvUtil.adjustPadsBasedOnAutoPad(e[0].dims,t.strides,t.dilations,n,r,t.autoPad);const o=Object.assign({},t);return Object.assign(o,{kernelShape:n,pads:r,cacheKey:t.cacheKey}),o};e.parseConvAttributes=t=>{const e=t.attributes,n=(0,u.parseInternalActivationAttributes)(e),i=e.getString(\"auto_pad\",\"NOTSET\"),o=e.getInts(\"dilations\",[1,1]),a=e.getInt(\"group\",1),s=e.getInts(\"kernel_shape\",[]),c=e.getInts(\"pads\",[0,0,0,0]),l=e.getInts(\"strides\",[1,1]);return(0,r.createAttributeWithCacheKey)(Object.assign({autoPad:i,dilations:o,group:a,kernelShape:s,pads:c,strides:l},n))};const g=(t,e)=>{if(!t||2!==t.length&&3!==t.length)throw new Error(\"Conv requires 2 or 3 inputs\");if(4!==t[0].dims.length||4!==t[1].dims.length)throw new Error(\"currently only support 2-dimensional conv\");if(t[0].dims[1]!==t[1].dims[1]*e.group)throw new Error(\"FILTER_IN_CHANNEL should be equal to DATA_CHANNEL\");if(3===t.length&&(1!==t[2].dims.length||t[1].dims[0]!==t[2].dims[0]))throw new Error(\"invalid bias\");const n=t[0].dims.length-2;if(e.dilations.length!==n)throw new Error(`dilations should be ${n}D`);if(e.strides.length!==n)throw new Error(`strides should be ${n}D`);if(e.pads.length!==2*n)throw new Error(`pads should be ${2*n}D`);if(0!==e.kernelShape.length&&e.kernelShape.length!==t[1].dims.length-2)throw new Error(\"invalid kernel shape\");if(\"float32\"!==t[0].type||\"float32\"!==t[1].type)throw new Error(\"Conv input(X,W) should be float tensor\");if(3===t.length&&\"float32\"!==t[2].type)throw new Error(\"Conv input(bias) should be float tensor\")}},5193:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.parseDepthToSpaceAttributes=e.depthToSpace=void 0;const r=n(3738);e.depthToSpace=(t,e,n)=>{i(e);const o=n.blocksize,a=o*o,s=\"DCR\"===n.mode?[0,3,4,1,5,2]:[0,1,4,2,5,3],u=\"DCR\"===n.mode?[e[0].dims[0],o,o,e[0].dims[1]/a,e[0].dims[2],e[0].dims[3]]:[e[0].dims[0],e[0].dims[1]/a,o,o,e[0].dims[2],e[0].dims[3]],c=t.reshapeUnpacked(e[0],u),l={perm:s,cacheKey:`${s}`},[p]=(0,r.transpose)(t,[c],l),f=[e[0].dims[0],e[0].dims[1]/a,e[0].dims[2]*o,e[0].dims[3]*o];return[t.reshapeUnpacked(p,f)]},e.parseDepthToSpaceAttributes=t=>{const e=t.attributes.getInt(\"blocksize\");if(e<1)throw new Error(`blocksize must be >= 1, but got : ${e} for DepthToSpace`);const n=t.attributes.getString(\"mode\",\"DCR\");if(\"DCR\"!==n&&\"CRD\"!==n)throw new Error(`unrecognized mode: ${n} for DepthToSpace`);return{mode:n,blocksize:e}};const i=t=>{if(1!==t.length)throw new Error(`DepthToSpace expect 1 inputs, but got ${t.length}`);if(\"string\"===t[0].type||4!==t[0].dims.length)throw new TypeError(\"DepthToSpace input should be a 4-D numeric tensor\")}},9828:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.createDotProductProgramInfoLoader=void 0;const r=n(2517),i=n(5060),o=n(2039),a=n(2823),s=n(3248);e.createDotProductProgramInfoLoader=(t,e,n,u)=>{const c=((t,e)=>({name:\"ConvDotProduct\",inputNames:t?[\"Im2Col\",\"K\",\"B\"]:[\"Im2Col\",\"K\"],inputTypes:t?[o.TextureType.unpacked,o.TextureType.packedLastDimension,o.TextureType.unpacked]:[o.TextureType.unpacked,o.TextureType.packedLastDimension],cacheKey:e.activationCacheKey}))(e.length>2,u);return Object.assign(Object.assign({},c),{get:()=>((t,e,n,u,c)=>{const l=n[0].dims,p=n[1].dims,f=[p[0],Math.ceil(l[1]*p[2]*p[3]/4)],d=(0,s.calculateIm2ColDims)(l,p,u),[h,g]=t.calculateTextureWidthAndHeight(f,o.TextureType.packedLastDimension),b=r.ShapeUtil.computeStrides(d),[m,y]=t.calculateTextureWidthAndHeight(d,o.TextureType.packedLastDimension),_=u.length,v=n.length<3?\"0.0\":\"_B(b)\",w=Math.ceil(l[1]*p[2]*p[3]/4),{activationFunction:x,applyActivation:T}=(0,a.getActivationSnippet)(c),S=(0,i.getGlsl)(t.session.backend.glContext.version),O=`\\n${x}\\nfloat process(int indices[${_}]) {\\n  int b[1];\\n  b[0] = indices[1];\\n  int im2col[4];\\n  im2col[0] = indices[0];\\n  im2col[1] = indices[2];\\n  im2col[2] = indices[3];\\n  int im2colOffset = im2col[0] * ${b[0]} + im2col[1] * ${b[1]} + im2col[2] * ${b[2]};\\n  int kernelOffset = indices[1] * ${f[1]};\\n  float value = ${v};\\n  for (int i = 0; i < ${w}; ++i) {\\n    vec2 im2colCoords = offsetToCoords(im2colOffset, ${m}, ${y});\\n    vec2 kernelCoords = offsetToCoords(kernelOffset, ${h}, ${g});\\n    value += dot(${S.texture2D}(Im2Col, im2colCoords), ${S.texture2D}(K, kernelCoords));\\n    ++im2colOffset;\\n    ++kernelOffset;\\n  }\\n  ${T}\\n  return value;\\n}`;return Object.assign(Object.assign({},e),{output:{dims:u,type:n[0].type,textureType:o.TextureType.unpacked},shaderSource:O})})(t,c,e,n,u)})}},7992:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.parseFlattenAttributes=e.flatten=void 0;const r=n(2517);e.flatten=(t,e,n)=>{i(e,n);const o=r.ShapeUtil.flattenShape(e[0].dims,n);return[t.reshapeUnpacked(e[0],o)]},e.parseFlattenAttributes=t=>t.attributes.getInt(\"axis\",1);const i=(t,e)=>{if(!t||1!==t.length)throw new Error(\"Flatten requires 1 input.\");const n=t[0].dims.length;if(0===n)throw new Error(\"scalar tensor is not supported.\");if(e<-n||e>n)throw new Error(\"Invalid axis\");if(\"string\"===t[0].type)throw new Error(\"string tensor is not supported.\")}},2823:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.parseInternalActivationAttributes=e.getActivationSnippet=void 0;const r=n(2517),i=n(4909);e.getActivationSnippet=function(t){let e;switch(t.activation){case\"Relu\":e=(0,i.glslRelu)();break;case\"Sigmoid\":e=(0,i.glslSigmoid)();break;case\"Clip\":e=(0,i.glslClip)(t.clipMin,t.clipMax);break;default:return{activationFunction:\"\",applyActivation:\"\"}}const n=e.name;return{activationFunction:e.body,applyActivation:`value = ${n}_(value);`}},e.parseInternalActivationAttributes=t=>{const e=t.getString(\"activation\",\"\");if(\"Clip\"===e){const[n,i]=t.getFloats(\"activation_params\",[r.MIN_CLIP,r.MAX_CLIP]);return{activation:e,clipMax:i,clipMin:n,activationCacheKey:`${e}:${n},${i}`}}return{activation:e,activationCacheKey:e}}},1253:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.parseGatherAttributes=e.gather=void 0;const r=n(246),i=n(782),o=n(2517),a=n(2039);e.gather=(t,e,n)=>(c(e,n.axis),[t.run(u(t,e,n),e)]),e.parseGatherAttributes=t=>(0,r.createAttributeWithCacheKey)({axis:t.attributes.getInt(\"axis\",0)});const s={name:\"Gather\",inputNames:[\"A\",\"B\"],inputTypes:[a.TextureType.unpacked,a.TextureType.unpacked]},u=(t,e,n)=>{const r=Object.assign(Object.assign({},s),{cacheHint:n.cacheKey});return Object.assign(Object.assign({},r),{get:()=>((t,e,n,r)=>{const i=n[0].dims.slice(),s=n[1].dims.slice(),u=new Array(i.length+s.length-1);r=o.ShapeUtil.normalizeAxis(r,i.length);const c=[];for(let t=0;t<u.length;t++)t<r?(u[t]=i[t],c.push(`inputIdx[${t}] = outputIdx[${t}];`)):t<r+s.length?(u[t]=s[t-r],c.push(`indexDataIdx[${t-r}] = outputIdx[${t}];`)):(u[t]=i[t-s.length+1],c.push(`inputIdx[${t-s.length+1}] = outputIdx[${t}];`));const l=`\\n      float process(int outputIdx[${u.length||1}]) {\\n        int inputIdx[${i.length}];\\n        int indexDataIdx[${s.length||1}];\\n        indexDataIdx[0] = 0;\\n        ${c.join(\"\\n        \")}\\n        int idx = int(_B(indexDataIdx));\\n        inputIdx[${r}] = idx < 0 ? idx + ${i[r]} : idx;\\n        return _A(inputIdx);\\n      }`;return Object.assign(Object.assign({},e),{output:{dims:u,type:n[0].type,textureType:a.TextureType.unpacked},shaderSource:l})})(0,r,e,n.axis)})},c=(t,e)=>{if(!t||2!==t.length)throw new Error(\"Gather requires 2 inputs.\");const n=t[0].dims.length;if(n<1)throw new Error(\"Invalid input shape.\");if(e<-n||e>n-1)throw new Error(\"Invalid axis.\");if(-1===i.NUMBER_TYPES.indexOf(t[0].type))throw new Error(\"Invaid input type.\");if(\"int32\"!==t[1].type&&\"int16\"!==t[1].type)throw new Error(\"Invaid input type.\")}},4776:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.parseGemmAttributesV11=e.parseGemmAttributesV7=e.gemm=void 0;const r=n(246),i=n(2517),o=n(2039);e.gemm=(t,e,n)=>(c(e,n),[t.run(s(e,n),e)]);const a=(t,e)=>{const n=0!==t.attributes.getInt(\"transA\",0),i=0!==t.attributes.getInt(\"transB\",0),o=t.attributes.getFloat(\"alpha\",1),a=t.attributes.getFloat(\"beta\",1);return(0,r.createAttributeWithCacheKey)({transA:n,transB:i,alpha:o,beta:a,isOptionalC:e})};e.parseGemmAttributesV7=t=>a(t,!1),e.parseGemmAttributesV11=t=>a(t,!0);const s=(t,e)=>{const n={name:\"Gemm\",inputNames:3===t.length?[\"A\",\"B\",\"C\"]:[\"A\",\"B\"],inputTypes:3===t.length?[o.TextureType.unpacked,o.TextureType.unpacked,o.TextureType.unpacked]:[o.TextureType.unpacked,o.TextureType.unpacked],key:e.cacheKey};return Object.assign(Object.assign({},n),{get:()=>u(n,t,e)})},u=(t,e,n)=>{const r=e[0].dims.slice(),a=e[1].dims.slice(),[s,u]=i.GemmUtil.getShapeOfGemmResult(r,n.transA,a,n.transB,3===e.length?e[2].dims:void 0),c=[s,u];if(!c)throw new Error(\"Can't use gemm on the given tensors\");let l=r[r.length-1],p=\"\";n.transA&&(l=r[0]),n.transA&&n.transB?p=\"value += _A_T(a) * _B_T(b);\":n.transA&&!n.transB?p=\"value += _A_T(a) * _B(b);\":!n.transA&&n.transB?p=\"value += _A(a) * _B_T(b);\":n.transA||n.transB||(p=\"value += _A(a) * _B(b);\");const f=c.length,d=`\\n      float process(int indices[${f}]) {\\n          int a[${f}];\\n          int b[${f}];\\n          ${3===e.length?`int c[${e[2].dims.length}];`:\"\"}\\n\\n          copyVec(indices, a);\\n          copyVec(indices, b);\\n          ${3===e.length?\"bcastIndices_C(indices, c);\":\"\"}\\n\\n          float value = 0.0;\\n          for (int k=0; k<${l}; ++k) {\\n              a[${f-1}] = k;\\n              b[${f-2}] = k;\\n              ${p}\\n          }\\n\\n          value = value * alpha;\\n          ${3===e.length?\"value += beta * _C(c);\":\"\"}\\n          return value;\\n      }`;return Object.assign(Object.assign({},t),{output:{dims:c,type:e[0].type,textureType:o.TextureType.unpacked},variables:[{name:\"alpha\",type:\"float\",data:n.alpha},{name:\"beta\",type:\"float\",data:n.beta}],shaderSource:d})},c=(t,e)=>{if(!t)throw new Error(\"Input is missing\");if(e.isOptionalC&&(t.length<2||t.length>3))throw new Error(\"Invaid input shape.\");if(!e.isOptionalC&&3!==t.length)throw new Error(\"Gemm requires 3 inputs\");if(3===t.length&&1!==t[2].dims.length&&2!==t[2].dims.length)throw new Error(\"Invalid input shape of C\");if(\"float32\"!==t[0].type&&\"float64\"!==t[0].type||\"float32\"!==t[1].type&&\"float64\"!==t[1].type||3===t.length&&\"float32\"!==t[2].type&&\"float64\"!==t[2].type)throw new Error(\"Invalid input type.\");if(t[0].type!==t[1].type||3===t.length&&t[0].type!==t[2].type)throw new Error(\"Input types are mismatched\")}},8555:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.createPackedIm2ColProgramInfoLoader=void 0;const r=n(5060),i=n(2039),o=n(2827);e.createPackedIm2ColProgramInfoLoader=(t,e,n,a,s)=>{const u=(c=s.cacheKey,{name:\"Im2Col (packed)\",inputNames:[\"A\"],inputTypes:[i.TextureType.packed],cacheHint:c});var c;return Object.assign(Object.assign({},u),{get:()=>((t,e,n,a,s,u)=>{const c=n.dims,l=a.dims,p=s.length,f=[l[1]*l[2]*l[3],s[2]*s[3]],d=l[2]*l[3],h=(0,o.unpackFromChannel)(),g=(0,r.getGlsl)(t.session.backend.glContext.version);let b=\"\";for(let t=0;t<=1;t++)for(let e=0;e<=1;e++)b+=`\\n            blockIndex = rc.x + ${e};\\n            pos = rc.y + ${t};\\n\\n            if(blockIndex < ${f[1]} && pos < ${f[0]}) {\\n              offsetY = int(blockIndex / (${s[p-1]})) * ${u.strides[0]} -\\n                ${u.pads[0]};\\n              d0 = offsetY + ${u.dilations[0]} * (imod(pos, ${d}) / ${l[2]});\\n\\n              if(d0 < ${c[2]} && d0 >= 0) {\\n                offsetX = imod(blockIndex, ${s[p-1]}) * ${u.strides[1]} -\\n                  ${u.pads[1]};\\n                d1 = offsetX + ${u.dilations[1]} * imod(imod(pos, ${d}), ${l[2]});\\n\\n                if(d1 < ${c[3]} && d1 >= 0) {\\n\\n                  ch = int(float(pos)/ ${d}.);\\n                    innerDims = vec2(d0, d1);\\n                    result[${2*t+e}] = getChannel(\\n                      getA(0, ch, int(innerDims.x),\\n                      int(innerDims.y)), innerDims);\\n                }\\n              }\\n            }\\n\\n          `;const m=`\\n      ${h}\\n\\n      void main() {\\n        ivec2 rc = getOutputCoords();\\n          vec4 result = vec4(0.0);\\n          int blockIndex, pos, offsetY, d0, offsetX, d1, ch;\\n          vec2 innerDims;\\n          ${b}\\n          ${g.output} = result;\\n      }\\n            `;return Object.assign(Object.assign({},e),{output:{dims:f,type:n.type,textureType:i.TextureType.packed},shaderSource:m,hasMain:!0})})(t,u,e,n,a,s)})}},3248:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.calculateIm2ColDims=e.createIm2ColProgramInfoLoader=void 0;const r=n(2039);e.createIm2ColProgramInfoLoader=(t,n,i,o,a)=>{const s=(u=a.cacheKey,{name:\"Im2Col\",inputNames:[\"X\"],inputTypes:[r.TextureType.unpacked],cacheHint:u});var u;return Object.assign(Object.assign({},s),{get:()=>((t,n,i,o,a,s)=>{const u=i.dims,c=o.dims,l=a.length,p=(0,e.calculateIm2ColDims)(u,c,a,4),f=`\\n        const int XC = ${u[1]};\\n        const int XH = ${u[2]};\\n        const int XW = ${u[3]};\\n        const int KH = ${s.kernelShape[0]};\\n        const int KW = ${s.kernelShape[1]};\\n        const int dilationH = ${s.dilations[0]};\\n        const int dilationW = ${s.dilations[1]};\\n        const int strideH = ${s.strides[0]};\\n        const int strideW = ${s.strides[1]};\\n        const int padH = ${s.pads[0]};\\n        const int padW = ${s.pads[1]};\\n        const int KHKW = KH*KW;\\n        const int XCKHKW = XC * KHKW;\\n        const int outputChannels = 4;\\n        vec4 process(int indices[${l}]) {\\n          int b  = indices[0]; // batch size\\n          int oh = indices[1] * strideH - padH; //output height\\n          int ow = indices[2] * strideW - padW; //output width\\n          int p = indices[3] * outputChannels; //patch\\n          vec4 value = vec4(0.0);\\n          for(int i=0; i < outputChannels; ++i) {\\n            if(p < XCKHKW) {\\n              int patchC = p / KHKW;\\n              int patchH = (p - patchC*KHKW) / KW;\\n              int patchW = (p - patchC*KHKW) - patchH * KW;\\n              int xh2 = oh + patchH * dilationH;\\n              int xw2 = ow + patchW * dilationW;\\n              int x[${u.length}];\\n              x[0] = b;\\n              x[1] = patchC;\\n              x[2] = xh2;\\n              x[3] = xw2;\\n              if(xh2 >= 0 &&\\n                  xh2 < XH &&\\n                  xw2 >= 0 &&\\n                  xw2 < XW) {\\n                value[i] = _X(x);\\n              }\\n            }\\n            ++p;\\n          }\\n          return value;\\n        }\\n        `;return Object.assign(Object.assign({},n),{output:{dims:p,type:i.type,textureType:r.TextureType.packedLastDimension},shaderSource:f})})(0,s,n,i,o,a)})},e.calculateIm2ColDims=(t,e,n,r=4)=>[n[0],n[2],n[3],Math.ceil(t[1]*e[2]*e[3]/r)]},6572:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.parseImageScalerAttributes=e.imageScaler=void 0;const r=n(246),i=n(2039);e.imageScaler=(t,e,n)=>(u(e),[t.run(a(t,e,n),e)]),e.parseImageScalerAttributes=t=>{const e=t.attributes.getFloat(\"scale\"),n=t.attributes.getFloats(\"bias\");return(0,r.createAttributeWithCacheKey)({scale:e,bias:n})};const o={name:\"ImageScaler\",inputNames:[\"X\"],inputTypes:[i.TextureType.unpacked]},a=(t,e,n)=>{const r=Object.assign(Object.assign({},o),{cacheHint:n.cacheKey});return Object.assign(Object.assign({},r),{get:()=>((t,e,n,r)=>{const o=n[0].dims.slice(),a=o.length,u=`\\n      ${s(r.bias.length)}\\n      float process(int indices[${a}]) {\\n        return _X(indices) * scale + getBias(bias, indices[1]);\\n      }`;return Object.assign(Object.assign({},e),{output:{dims:o,type:n[0].type,textureType:i.TextureType.unpacked},variables:[{name:\"bias\",type:\"float\",arrayLength:r.bias.length,data:r.bias},{name:\"scale\",type:\"float\",data:r.scale}],shaderSource:u})})(0,r,e,n)})},s=t=>{const e=[`float getBias(float bias[${t}], int channel) {`];for(let n=0;n<t;++n)0===n?e.push(`\\tif (channel == ${n}) { return bias[${n}]; }`):n===t-1?e.push(`\\telse { return bias[${n}]; }`):e.push(`\\telse if (channel == ${n}) { return bias[${n}]; }`);return e.push(\"\\t}\"),e.join(\"\\n\")},u=t=>{if(!t||1!==t.length)throw new Error(\"ImageScaler requires 1 input.\");if(4!==t[0].dims.length)throw new Error(\"Invalid input shape.\");if(\"float32\"!==t[0].type&&\"float64\"!==t[0].type)throw new Error(\"Invalid input type.\")}},3346:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.parseInstanceNormalizationAttributes=e.instanceNormalization=void 0;const r=n(5060),i=n(2039);e.instanceNormalization=(t,e,n)=>{c(e);const r=t.run(a(e[0]),e);return[t.run(u(t,e[0],n,r.dims),[e[0],r,e[1],e[2]])]},e.parseInstanceNormalizationAttributes=t=>t.attributes.getFloat(\"epsilon\",1e-5);const o={name:\"InstanceNormalization_MeanAndVariance\",inputNames:[\"X\"],inputTypes:[i.TextureType.unpacked]},a=t=>Object.assign(Object.assign({},o),{get:()=>((t,e)=>{const n=e.dims.slice(),r=n[1],o=n[2]*n[3],a=[n[0],r],s=`\\n      vec4 process(int[2] indices) {\\n        vec4 v = vec4(0.0);\\n        int a[4];\\n        a[0] = indices[0];\\n        a[1] = indices[1];\\n        float temp = 0.0;\\n        for(int a2=0; a2<${n[2]}; a2++) {\\n          a[2] = a2;\\n          for(int a3=0; a3<${n[3]}; a3++) {\\n            a[3] = a3;\\n            float x = _X(a);\\n            temp += x;\\n          }\\n        }\\n        float mean = temp / float(${o});\\n        temp = 0.0;\\n        for(int a2=0; a2<${n[2]}; a2++) {\\n          a[2] = a2;\\n          for(int a3=0; a3<${n[3]}; a3++) {\\n            a[3] = a3;\\n            float x = _X(a);\\n            temp += (x - mean) * (x - mean);\\n          }\\n        }\\n        v.r = mean;\\n        v.g = temp / float(${o});\\n\\n        return v;\\n      }`;return Object.assign(Object.assign({},t),{output:{dims:a,type:e.type,textureType:i.TextureType.packedLastDimension},shaderSource:s})})(o,t)}),s={name:\"InstanceNormalization_ComputeOutput\",inputNames:[\"X\",\"MeanAndVariance\",\"Scale\",\"B\"],inputTypes:[i.TextureType.unpacked,i.TextureType.packedLastDimension,i.TextureType.unpacked,i.TextureType.unpacked]},u=(t,e,n,o)=>{const a=Object.assign(Object.assign({},s),{cacheHint:`${n}`});return Object.assign(Object.assign({},a),{get:()=>((t,e,n,o,a)=>{const s=(0,r.getGlsl)(t.session.backend.glContext.version),[u,c]=t.calculateTextureWidthAndHeight(a,i.TextureType.packedLastDimension),[l,p]=[u/4,c],f=`\\n      vec4 get_MeanAndVariance(int[2] mv) {\\n        int offset = indicesToOffset_MeanAndVariance(mv);\\n        vec2 coords = offsetToCoords(offset, ${l}, ${p});\\n        return ${s.texture2D}(MeanAndVariance, coords);\\n      }\\n\\n      float process(int[4] indices) {\\n        int mv[2];\\n        mv[0] = indices[0];\\n        mv[1] = indices[1];\\n        vec4 mean_and_variance = get_MeanAndVariance(mv);\\n        float mean = mean_and_variance.r;\\n        float variance = mean_and_variance.g;\\n\\n        int sb[1];\\n        sb[0] = indices[1];\\n        float scale = _Scale(sb);\\n        float b = _B(sb);\\n\\n        return scale * (_X(indices) - mean) / sqrt(variance + epsilon) + b;\\n      }`;return Object.assign(Object.assign({},e),{output:{dims:n.dims,type:n.type,textureType:i.TextureType.unpacked},variables:[{name:\"epsilon\",type:\"float\",data:o}],shaderSource:f})})(t,a,e,n,o)})},c=t=>{if(!t||3!==t.length)throw new Error(\"InstanceNormalization requires 3 inputs.\");const e=t[0],n=t[1],r=t[2];if(e.dims.length<3||1!==n.dims.length||1!==r.dims.length)throw new Error(\"Invalid input shape.\");if(n.dims[0]!==e.dims[1]||r.dims[0]!==e.dims[1])throw new Error(\"Input shapes are mismatched.\");if(\"float32\"!==e.type&&\"float64\"!==e.type||\"float32\"!==n.type&&\"float64\"!==n.type||\"float32\"!==r.type&&\"float64\"!==r.type)throw new Error(\"Invalid input type.\");if(4!==t[0].dims.length)throw new Error(\"Only support 4-D input shape.\")}},708:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.createPackedMatmulProgramInfoLoader=void 0;const r=n(2517),i=n(5060),o=n(2039),a=n(9390),s=n(2823),u=n(5623);e.createPackedMatmulProgramInfoLoader=(t,e,n)=>{const c=(l=e.length>2,p=n.activationCacheKey,{name:\"MatMul (packed)\",inputNames:l?[\"A\",\"B\",\"Bias\"]:[\"A\",\"B\"],inputTypes:l?[o.TextureType.packed,o.TextureType.packed,o.TextureType.packed]:[o.TextureType.packed,o.TextureType.packed],cacheHint:p});var l,p;return Object.assign(Object.assign({},c),{get:()=>((t,e,n,c)=>{const l=n.length>2,p=l?\"value += getBiasForMatmul();\":\"\",f=n[0].dims,d=n[1].dims,h=r.BroadcastUtil.calcShape(f,d,!0),g=!r.ShapeUtil.areEqual(n[0].dims,n[1].dims);if(!h)throw new Error(\"Can't use matmul on the given tensors\");const b=f[f.length-1],m=Math.ceil(b/2),y=f.length,_=d.length,v=(0,i.getGlsl)(t.session.backend.glContext.version),w=(0,a.getCoordsDataType)(h.length),x=h.length,T=(0,a.getGlChannels)(),{activationFunction:S,applyActivation:O}=(0,s.getActivationSnippet)(c),A=l?`${(0,u.getBiasForMatmul)(w,T,n[2].dims,h,!0)}`:\"\",E=g?`${function(t,e,n,i){let o=[],a=[];const s=n[0].dims,u=n[1].dims,c=s.length,l=u.length,p=i.length,f=p-c,d=p-l;o=s.map(((t,n)=>`coords.${e[n+f]}`)),o[c-1]=\"i*2\",o.join(\", \"),a=u.map(((t,n)=>`coords.${e[n+d]}`)),a[l-2]=\"i*2\",a.join(\", \");const h=r.BroadcastUtil.getBroadcastDims(s,i),g=r.BroadcastUtil.getBroadcastDims(u,i),b=h.map((t=>`coords.${e[t+f]} = 0;`)).join(\"\\n\"),m=g.map((t=>`coords.${e[t+d]} = 0;`)).join(\"\\n\"),y=`int lastDim = coords.${e[p-1]};\\n  coords.${e[p-1]} = coords.${e[p-2]};\\n  coords.${e[p-2]} = lastDim;`;return`\\nvec4 getAAtOutCoordsMatmul(int i) {\\n  ${t} coords = getOutputCoords();\\n  ${y}\\n  ${b}\\n  vec4 outputValue = getA(${o});\\n  return outputValue;\\n}\\n\\nvec4 getBAtOutCoordsMatmul(int i) {\\n  ${t} coords = getOutputCoords();\\n  ${y}\\n  ${m}\\n  vec4 outputValue = getB(${a});\\n  return outputValue;\\n}`}(w,T,n,h)}`:\"\",I=g?\"getAAtOutCoordsMatmul(i)\":`getA(${function(t,e){let n=\"\";for(let r=0;r<e-2;r++)n+=`rc.${t[r]}, `;return n+=`rc.${t[e-2]}, i*2`,n}(T,y)})`,P=g?\"getBAtOutCoordsMatmul(i)\":`getB(${function(t,e){let n=\"\";for(let r=0;r<e-2;r++)n+=`rc.${t[r]}, `;return n+=`i*2, rc.${t[e-1]}`,n}(T,_)})`,D=`\\n            ${E}\\n            ${A}\\n            ${S}\\n            void main() {\\n              ${g?\"\":`${w} rc =\\n          getOutputCoords(); int lastDim = rc.${T[x-1]}; rc.${T[x-1]} =\\n          rc.${T[x-2]}; rc.${T[x-2]} = lastDim;\\n      `}\\n\\n              vec4 value = vec4(0);\\n              for (int i = 0; i < ${m}; i++) {\\n                vec4 a = ${I};\\n                vec4 b = ${P};\\n\\n                value += (a.rrbb * b.rgrg);\\n                value += (a.ggaa * b.baba);\\n              }\\n              ${p}\\n              ${O}\\n              ${v.output} = value;\\n            }`;return Object.assign(Object.assign({},e),{output:{dims:h,type:n[0].type,textureType:o.TextureType.packed},shaderSource:D,hasMain:!0})})(t,c,e,n)})}},5623:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.getBiasForMatmul=e.createMatmulProgramInfoLoader=e.parseMatMulAttributes=e.matMul=void 0;const r=n(2517),i=n(2039),o=n(9390),a=n(2823),s=n(708);function u(t,e){const n=(s=t.length>2,u=e.activationCacheKey,{name:\"MatMul\",inputNames:s?[\"A\",\"B\",\"Bias\"]:[\"A\",\"B\"],inputTypes:s?[i.TextureType.unpacked,i.TextureType.unpacked,i.TextureType.unpacked]:[i.TextureType.unpacked,i.TextureType.unpacked],cacheHint:u});var s,u;return Object.assign(Object.assign({},n),{get:()=>function(t,e,n){const s=e[0].dims,u=e[1].dims,c=r.BroadcastUtil.calcShape(s,u,!0);if(!c)throw new Error(\"Can't use matmul on the given tensors\");const p=(0,o.getCoordsDataType)(c.length),f=(0,o.getGlChannels)(),{activationFunction:d,applyActivation:h}=(0,a.getActivationSnippet)(n),g=e.length>2,b=g?\"value += getBiasForMatmul();\":\"\",m=g?`${l(p,f,e[2].dims,c,!1)}`:\"\",y=c.length,_=s.length,v=u.length,w=`\\n    ${d}\\n    ${m}\\n    float process(int indices[${y}]) {\\n        int a[${_}];\\n        int b[${v}];\\n        bcastMatmulIndices_A(indices, a);\\n        bcastMatmulIndices_B(indices, b);\\n\\n        float value;\\n        for (int k=0; k<${s[s.length-1]}; ++k) {\\n            a[${_-1}] = k;\\n            b[${v-2}] = k;\\n            value += _A(a) * _B(b);\\n        }\\n        ${b}\\n        ${h}\\n        return value;\\n    }`;return Object.assign(Object.assign({},t),{output:{dims:c,type:e[0].type,textureType:i.TextureType.unpacked},shaderSource:w})}(n,t,e)})}e.matMul=(t,e,n)=>(c(e),t.session.pack?[t.run((0,s.createPackedMatmulProgramInfoLoader)(t,e,n),e)]:[t.run(u(e,n),e)]),e.parseMatMulAttributes=t=>(0,a.parseInternalActivationAttributes)(t.attributes),e.createMatmulProgramInfoLoader=u;const c=t=>{if(!t||2!==t.length)throw new Error(\"MatMul requires 2 inputs.\");if(t[0].dims[t[0].dims.length-1]!==t[1].dims[t[1].dims.length-2])throw new Error(\"shared dimension does not match.\");if(\"float32\"!==t[0].type&&\"float64\"!==t[0].type||\"float32\"!==t[1].type&&\"float64\"!==t[1].type)throw new Error(\"inputs should be float type\");if(t[0].type!==t[1].type)throw new Error(\"inputs types should match\")};function l(t,e,n,i,o){let a=\"\";const s=n.length,u=i.length,c=u-s;a=u<2&&s>0?\"coords\":n.map(((t,n)=>`coords.${e[n+c]}`)).join(\", \");const l=r.BroadcastUtil.getBroadcastDims(n,i).map((t=>`coords.${e[t+c]} = 0;`)).join(\"\\n\");let p=\"vec4(outputValue.xx, outputValue.yy)\";return 1===r.ShapeUtil.size(n)&&(p=\"vec4(outputValue.x)\"),o?`\\nvec4 getBiasForMatmul() {\\n  ${t} coords = getOutputCoords();\\n  ${l}\\n  vec4 outputValue = getBias(${a});\\n  return ${p};\\n}`:`\\nfloat getBiasForMatmul() {\\n  ${t} coords = getOutputCoords();\\n  ${l}\\n  return getBias(coords.x);\\n}`}e.getBiasForMatmul=l},2403:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.createPackProgramInfoLoader=void 0;const r=n(5060),i=n(2039),o=n(9390),a=n(2827),s={name:\"pack\",inputNames:[\"A\"],inputTypes:[i.TextureType.unpackedReversed]};e.createPackProgramInfoLoader=(t,e)=>Object.assign(Object.assign({},s),{get:()=>((t,e)=>{const n=(0,r.getGlsl)(t.session.backend.glContext.version),u=e.dims,c=u.length,l=e.dims.length,p=(0,o.getCoordsDataType)(l),f=(0,a.getChannels)(\"rc\",l),d=(h=l,g=f,b=u[u.length-2],m=u[u.length-1],0===h||1===h?\"\":`\\n    int r = ${g[h-2]};\\n    int c = ${g[h-1]};\\n    int rp1 = ${g[h-2]} + 1;\\n    int cp1 = ${g[h-1]} + 1;\\n    bool rEdge = rp1 >= ${m};\\n    bool cEdge = cp1 >= ${b};\\n    `);var h,g,b,m;let y;y=0===c?[1,1]:1===c?[u[0],1]:[u[l-1],u[l-2]];const _=function(t,e,n){if(0===t)return\"false\";if(1===t)return`rc > ${e[0]}`;let r=\"\";for(let i=t-2;i<t;i++)r+=`${n[i]} >= ${e[i-t+2]}`,i<t-1&&(r+=\"||\");return r}(l,y,f),v=function(t,e){const n=t.length;if(0===n)return\"getA(), 0, 0, 0\";if(1===n)return`getA(rc),\\n            rc + 1 >= ${t[0]} ? 0. : getA(rc + 1),\\n            0, 0`;let r=\"\";if(n>2)for(let t=0;t<n-2;++t)r+=`${e[t]},`;return`getA(${r}r, c),\\n          rEdge ? 0. : getA(${r}rp1, c),\\n          cEdge ? 0. : getA(${r}r, cp1),\\n          rEdge || cEdge ? 0. : getA(${r}rp1, cp1)`}(u,f),w=`\\n        void main() {\\n          ${p} rc = getOutputCoords();\\n\\n          if(${_}) {\\n            ${n.output} = vec4(0);\\n          } else {\\n            ${d}\\n\\n            ${n.output} = vec4(${v});\\n          }\\n        }\\n      `;return Object.assign(Object.assign({},s),{hasMain:!0,output:{dims:e.dims,type:e.type,textureType:i.TextureType.packed},shaderSource:w})})(t,e)})},2827:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.unpackFromChannel=e.getChannels=e.getVecChannels=void 0;const r=n(9390);function i(t,e){return(0,r.getGlChannels)(e).map((e=>`${t}.${e}`))}e.getVecChannels=i,e.getChannels=function(t,e){return 1===e?[t]:i(t,e)},e.unpackFromChannel=function(){return\"\\n    float getChannel(vec4 frag, int dim) {\\n      int modCoord = imod(dim, 2);\\n      return modCoord == 0 ? frag.r : frag.g;\\n    }\\n\\n    float getChannel(vec4 frag, vec2 innerDims) {\\n      vec2 modCoord = mod(innerDims, 2.);\\n      return modCoord.x == 0. ?\\n        (modCoord.y == 0. ? frag.r : frag.g) :\\n        (modCoord.y == 0. ? frag.b : frag.a);\\n    }\\n  \"}},2870:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.parsePadAttributesV11=e.padV11=e.parsePadAttributesV2=e.padV2=void 0;const r=n(246),i=n(2517),o=n(5060),a=n(2039),s={name:\"Pad\",inputNames:[\"A\"],inputTypes:[a.TextureType.unpacked]};e.padV2=(t,e,n)=>(l(e),[t.run(Object.assign(Object.assign({},s),{cacheHint:n.cacheKey,get:()=>c(t,e[0],n)}),e)]),e.parsePadAttributesV2=t=>{const e=t.attributes.getString(\"mode\",\"constant\"),n=t.attributes.getFloat(\"value\",0),i=t.attributes.getInts(\"pads\");return(0,r.createAttributeWithCacheKey)({mode:e,value:n,pads:i})},e.padV11=(t,n,r)=>{p(n);const i=u(t,n,r);return(0,e.padV2)(t,[n[0]],i)},e.parsePadAttributesV11=t=>t.attributes.getString(\"mode\",\"constant\");const u=(t,e,n)=>{if(!t.session.isInitializer(e[1].dataId)||e.length>=3&&!t.session.isInitializer(e[2].dataId))throw new Error(\"dynamic pad attributes are not allowed\");const i=Array.from(e[1].integerData),o=e.length>=3?e[2].floatData[0]:0;return(0,r.createAttributeWithCacheKey)({mode:n,pads:i,value:o})},c=(t,e,n)=>{const r=i.ShapeUtil.padShape(e.dims.slice(),n.pads),o=r.length,s=`\\n      ${f(t,e,n)}\\n      float process(int[${o}] indices) {\\n          return padA(indices);\\n      }`;return{name:\"Pad\",inputNames:[\"A\"],inputTypes:[a.TextureType.unpacked],output:{dims:r,type:e.type,textureType:a.TextureType.unpacked},shaderSource:s}},l=t=>{if(!t||1!==t.length)throw new Error(\"Pad requires 1 input\");if(\"float32\"!==t[0].type&&\"float64\"!==t[0].type)throw new Error(\"Invalid input type.\")},p=t=>{if(!t||2!==t.length&&3!==t.length)throw new Error(\"Pad requires 2 or 3 inputs\");if(\"int32\"!==t[1].type)throw new Error(\"Invalid input type.\");if(t.length>=3&&\"string\"===t[2].type)throw new Error(\"Invalid input type.\")},f=(t,e,n)=>{const r=(0,o.getGlsl)(t.session.backend.glContext.version),[s,u]=t.calculateTextureWidthAndHeight(e.dims,a.TextureType.unpacked),c=i.ShapeUtil.computeStrides(e.dims);switch(n.mode){case\"constant\":return d(r,e.dims,c,s,u,n.pads,n.value);case\"reflect\":return h(r,e.dims,c,s,u,n.pads);case\"edge\":return g(r,e.dims,c,s,u,n.pads);default:throw new Error(\"Invalid mode\")}},d=(t,e,n,r,i,o,a)=>{const s=e.length;let u=\"\";for(let t=s-1;t>=0;--t)u+=`\\n        k = m[${t}] - ${o[t]};\\n        if (k < 0)  return constant;\\n        if (k >= ${e[t]}) return constant;\\n        offset += k * ${n[t]};\\n        `;return`\\n      float padA(int m[${s}]) {\\n        const float constant = float(${a});\\n        int offset = 0;\\n        int k = 0;\\n        ${u}\\n        vec2 coords = offsetToCoords(offset, ${r}, ${i});\\n        float value = getColorAsFloat(${t.texture2D}(A, coords));\\n        return value;\\n      }\\n      `},h=(t,e,n,r,i,o)=>{const a=e.length;let s=\"\";for(let t=a-1;t>=0;--t)s+=`\\n        k = m[${t}] - ${o[t]};\\n        if (k < 0) { k = -k; }\\n        {\\n          const int _2n_1 = ${2*(e[t]-1)};\\n          k = int( mod( float(k), float(_2n_1) ) ) ;\\n          if(k >= ${e[t]}) { k = _2n_1 - k; }\\n        }\\n        offset += k * ${n[t]};\\n        `;return`\\n      float padA(int m[${a}]) {\\n        int offset = 0;\\n        int k = 0;\\n        ${s}\\n        vec2 coords = offsetToCoords(offset, ${r}, ${i});\\n        float value = getColorAsFloat(${t.texture2D}(A, coords));\\n        return value;\\n      }\\n      `},g=(t,e,n,r,i,o)=>{const a=e.length;let s=\"\";for(let t=a-1;t>=0;--t)s+=`\\n        k = m[${t}] - ${o[t]};\\n        if (k < 0)  k = 0;\\n        if (k >= ${e[t]}) k = ${e[t]-1};\\n        offset += k * ${n[t]};\\n      `;return`\\n      float padA(int m[${a}]) {\\n        int offset = 0;\\n        int k = 0;\\n        ${s}\\n        vec2 coords = offsetToCoords(offset, ${r}, ${i});\\n        float value = getColorAsFloat(${t.texture2D}(A, coords));\\n        return value;\\n      }\\n      `}},2143:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.globalMaxPool=e.parseMaxPoolAttributes=e.maxPool=e.parseGlobalAveragePoolAttributes=e.globalAveragePool=e.parseAveragePoolAttributes=e.averagePool=void 0;const r=n(246),i=n(2517),o=n(2039);e.averagePool=(t,e,n)=>{p(e);const r={name:\"AveragePool\",inputNames:[\"X\"],inputTypes:[o.TextureType.unpacked],cacheHint:n.cacheKey};return[t.run(Object.assign(Object.assign({},r),{get:()=>a(e,r,!1,n)}),e)]},e.parseAveragePoolAttributes=t=>{const e=t.attributes.getString(\"auto_pad\",\"NOTSET\"),n=t.attributes.getInt(\"ceil_mode\",0),i=0!==t.attributes.getInt(\"count_include_pad\",0),o=t.attributes.getInts(\"kernel_shape\"),a=t.attributes.getInts(\"strides\",[]),s=t.attributes.getInts(\"pads\",[]);if(0!==n)throw new Error(\"using ceil() in shape computation is not yet supported for AveragePool\");return(0,r.createAttributeWithCacheKey)({autoPad:e,ceilMode:n,countIncludePad:i,kernelShape:o,strides:a,pads:s})};const a=(t,e,n,r)=>{const[a,s]=u(t,r,n),c=i.ShapeUtil.size(a.kernelShape);let l=\"\";a.countIncludePad?l+=`value /= float(${c});`:l+=`value /= float(${c} - pad);`;const p=`\\n        ${f(t[0].dims,a,\"value += _X(x);\",l,\"0.0\")}\\n      `;return Object.assign(Object.assign({},e),{output:{dims:s,type:t[0].type,textureType:o.TextureType.unpacked},shaderSource:p})};e.globalAveragePool=(t,e,n)=>{p(e);const r={name:\"GlobalAveragePool\",inputNames:[\"X\"],inputTypes:[o.TextureType.unpacked],cacheHint:`${n.countIncludePad}`};return[t.run(Object.assign(Object.assign({},r),{get:()=>a(e,r,!0,n)}),e)]},e.parseGlobalAveragePoolAttributes=t=>{const e=0!==t.attributes.getInt(\"count_include_pad\",0);return(0,r.createAttributeWithCacheKey)({autoPad:\"\",ceilMode:0,countIncludePad:e,kernelShape:[],strides:[],pads:[]})},e.maxPool=(t,e,n)=>{p(e);const r={name:\"MaxPool\",inputNames:[\"X\"],inputTypes:[o.TextureType.unpacked],cacheHint:n.cacheKey};return[t.run(Object.assign(Object.assign({},r),{get:()=>s(e,r,!1,n)}),e)]},e.parseMaxPoolAttributes=t=>{const e=t.attributes.getString(\"auto_pad\",\"NOTSET\"),n=t.attributes.getInt(\"ceil_mode\",0),i=t.attributes.getInts(\"kernel_shape\"),o=t.attributes.getInts(\"strides\",[]),a=t.attributes.getInts(\"pads\",[]),s=t.attributes.getInt(\"storage_order\",0),u=t.attributes.getInts(\"dilations\",[]);if(0!==s)throw new Error(\"column major storage order is not yet supported for MaxPool\");if(0!==n)throw new Error(\"using ceil() in shape computation is not yet supported for MaxPool\");return(0,r.createAttributeWithCacheKey)({autoPad:e,ceilMode:n,countIncludePad:!1,kernelShape:i,strides:o,pads:a,storageOrder:s,dilations:u})};const s=(t,e,n,r)=>{const[i,a]=u(t,r,n),s=`\\n      ${f(t[0].dims,i,\"\\n      value = max(_X(x), value);\\n    \",\"\",\"-1e5\")}\\n    `;return Object.assign(Object.assign({},e),{output:{dims:a,type:t[0].type,textureType:o.TextureType.unpacked},shaderSource:s})},u=(t,e,n)=>{const r=t[0].dims.slice(),o=Object.hasOwnProperty.call(e,\"dilations\"),a=e.kernelShape.slice(),s=e.strides.slice(),u=o?e.dilations.slice():[],c=e.pads.slice();i.PoolConvUtil.adjustPoolAttributes(n,r,a,s,u,c);const l=i.PoolConvUtil.computePoolOutputShape(n,r,s,u,a,c,e.autoPad),p=Object.assign({},e);return o?Object.assign(p,{kernelShape:a,strides:s,pads:c,dilations:u,cacheKey:e.cacheKey}):Object.assign(p,{kernelShape:a,strides:s,pads:c,cacheKey:e.cacheKey}),[p,l]},c={autoPad:\"\",ceilMode:0,countIncludePad:!1,kernelShape:[],strides:[],pads:[],storageOrder:0,dilations:[],cacheKey:\"\"},l={name:\"GlobalMaxPool\",inputNames:[\"X\"],inputTypes:[o.TextureType.unpacked]};e.globalMaxPool=(t,e)=>(p(e),[t.run(Object.assign(Object.assign({},l),{get:()=>s(e,l,!0,c)}),e)]);const p=t=>{if(!t||1!==t.length)throw new Error(\"Pool ops requires 1 input.\");if(\"float32\"!==t[0].type&&\"float64\"!==t[0].type)throw new Error(\"Invalid input type.\")},f=(t,e,n,r,o)=>{const a=t.length;if(e.kernelShape.length<=2){const i=e.kernelShape[e.kernelShape.length-1],s=e.strides[e.strides.length-1],u=e.pads[e.pads.length/2-1],c=e.pads[e.pads.length-1],l=t[a-1];let p=\"\",f=\"\",d=\"\";if(p=u+c!==0?`\\n          for (int i = 0; i < ${i}; i++) {\\n            x[${a} - 1] = indices[${a} - 1] * ${s} - ${u} + i;\\n            if (x[${a} - 1] < 0 || x[${a} - 1] >= ${l}) {\\n              pad++;\\n              continue;\\n            }\\n            ${n}\\n          }`:`\\n          for (int i = 0; i < ${i}; i++) {\\n            x[${a} - 1] = indices[${a} - 1] * ${s} - ${u} + i;\\n            ${n}\\n          }`,2===e.kernelShape.length){const n=e.kernelShape[e.kernelShape.length-2],r=e.strides[e.strides.length-2],o=e.pads[e.pads.length/2-2],s=e.pads[e.pads.length-2],u=t[a-2];f=o+s!==0?`\\n            for (int j = 0; j < ${n}; j++) {\\n              x[${a} - 2] = indices[${a} - 2] * ${r} - ${o} + j;\\n              if (x[${a} - 2] < 0 || x[${a} - 2] >= ${u}) {\\n                pad+= ${i};\\n                continue;\\n              }\\n          `:`\\n            for (int j = 0; j < ${n}; j++) {\\n              x[${a} - 2] = indices[${a} - 2] * ${r} - ${o} + j;\\n            `,d=\"\\n          }\\n        \"}return`\\n        float process(int indices[${a}]) {\\n          int x[${a}];\\n          copyVec(indices, x);\\n\\n          float value = ${o};\\n          int pad = 0;\\n          ${f}\\n          ${p}\\n          ${d}\\n          ${r}\\n          return value;\\n        }\\n      `}{const s=i.ShapeUtil.size(e.kernelShape),u=i.ShapeUtil.computeStrides(e.kernelShape),c=u.length,l=e.pads.length,p=h(c),f=d(t,\"inputDims\"),g=d(e.pads,\"pads\"),b=d(u,\"kernelStrides\"),m=d(e.strides,\"strides\");let y=\"\";return y=e.pads.reduce(((t,e)=>t+e))?`\\n            if (x[j] >= inputDims[j] || x[j] < 0) {\\n              pad++;\\n              isPad = true;\\n              break;\\n            }\\n          }\\n          if (!isPad) {\\n            ${n}\\n          }`:`\\n          }\\n          ${n}\\n        `,`\\n        ${p}\\n        float process(int indices[${a}]) {\\n          int x[${a}];\\n          copyVec(indices, x);\\n          int offset[${c}];\\n          int pads[${l}];\\n          int inputDims[${a}];\\n          int kernelStrides[${c}];\\n          int strides[${c}];\\n          ${g}\\n          ${f}\\n          ${m}\\n          ${b}\\n\\n          float value = ${o};\\n          int pad = 0;\\n          bool isPad = false;\\n          for (int i = 0; i < ${s}; i++) {\\n            offsetToIndices(i, kernelStrides, offset);\\n            isPad = false;\\n            for (int j = ${a} - ${c}; j < ${a}; j++) {\\n              x[j] = indices[j] * strides[j - ${a} + ${c}]\\n                + offset[j - ${a} + ${c}] - pads[j - 2];\\n              ${y}\\n          }\\n          ${r}\\n\\n          return value;\\n        }\\n      `}},d=(t,e)=>{let n=\"\";for(let r=0;r<t.length;r++)n+=`\\n      ${e}[${r}] = ${t[r]};\\n    `;return n},h=t=>`\\n  void offsetToIndices(int offset, int[${t}] strides, out int[${t}] indices) {\\n    if (${t} == 0) {\\n      return;\\n    }\\n    for (int i = 0; i < ${t} - 1; ++i) {\\n      indices[i] = offset / strides[i];\\n      offset -= indices[i] * strides[i];\\n    }\\n    indices[${t} - 1] = offset;\\n  }`},4939:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.reduceLogSumSquare=e.reduceLogSum=e.reduceProd=e.reduceMin=e.reduceMax=e.reduceMean=e.reduceSum=e.parseReduceAttributes=void 0;const r=n(246),i=n(782),o=n(2517),a=n(2039),s=(t,e,n,r,i)=>{c(e);const o={name:r,inputNames:[\"A\"],inputTypes:[a.TextureType.unpacked]};return[t.run(Object.assign(Object.assign({},o),{cacheHint:n.cacheKey,get:()=>u(t,e,n,r,i,o)}),e)]};e.parseReduceAttributes=t=>{const e=t.attributes.getInts(\"axes\",[]),n=1===t.attributes.getInt(\"keepdims\",1);return(0,r.createAttributeWithCacheKey)({axes:e,keepDims:n})};const u=(t,e,n,r,i,s)=>{const u=[],c=e[0].dims.length||1,l=[],p=o.ShapeUtil.normalizeAxes(n.axes,e[0].dims.length),f=i(e,p);let d=f[1];for(let t=0;t<e[0].dims.length;t++)p.indexOf(t)>=0||0===p.length?(n.keepDims&&u.push(1),d=`\\n          for(int j${t} = 0; j${t} < ${e[0].dims[t]}; j${t}++) {\\n            inputIdx[${t}] = j${t};\\n            ${d}\\n          }`):(l.push(`inputIdx[${t}] = outputIdx[${u.length}];`),u.push(e[0].dims[t]));const h=`\\n      float process(int outputIdx[${u.length||1}]) {\\n        float value;                 // final result\\n        int inputIdx[${c}];      // addressing input data\\n        ${l.join(\"\\n\")}\\n        ${f[0]}       // init ops for reduce max/min\\n        ${d}\\n        ${f[2]}       // final computation for reduce mean\\n        return value;\\n      }`;return Object.assign(Object.assign({},s),{output:{dims:u,type:e[0].type,textureType:a.TextureType.unpacked},shaderSource:h})},c=t=>{if(!t||1!==t.length)throw new Error(\"Reduce op requires 1 input.\");if(-1===i.NUMBER_TYPES.indexOf(t[0].type))throw new Error(\"Invalid input type.\")};e.reduceSum=(t,e,n)=>s(t,e,n,\"ReduceSum\",(()=>[\"value = 0.0;\",\"value += _A(inputIdx);\",\"\"])),e.reduceMean=(t,e,n)=>s(t,e,n,\"ReduceMean\",((t,e)=>{let n=1;for(let r=0;r<t[0].dims.length;r++)(e.indexOf(r)>=0||0===e.length)&&(n*=t[0].dims[r]);return[\"value = 0.0;\",\"value += _A(inputIdx);\",`value /= ${n}.;`]})),e.reduceMax=(t,e,n)=>s(t,e,n,\"ReduceMax\",((t,e)=>{const n=[];for(let r=0;r<t[0].dims.length;r++)(e.indexOf(r)>=0||0===e.length)&&n.push(`inputIdx[${r}] = 0;`);return[`${n.join(\"\\n\")}\\nvalue = _A(inputIdx);`,\"value = max(value, _A(inputIdx));\",\"\"]})),e.reduceMin=(t,e,n)=>s(t,e,n,\"ReduceMin\",((t,e)=>{const n=[];for(let r=0;r<t[0].dims.length;r++)(e.indexOf(r)>=0||0===e.length)&&n.push(`inputIdx[${r}] = 0;`);return[`${n.join(\"\\n\")}\\nvalue = _A(inputIdx);`,\"value = min(value, _A(inputIdx));\",\"\"]})),e.reduceProd=(t,e,n)=>s(t,e,n,\"ReduceProd\",(()=>[\"value = 1.0;\",\"value *= _A(inputIdx);\",\"\"])),e.reduceLogSum=(t,e,n)=>s(t,e,n,\"ReduceLogSum\",(()=>[\"value = 0.0;\",\"value += _A(inputIdx);\",\"value = log(value);\"])),e.reduceLogSumSquare=(t,e,n)=>s(t,e,n,\"ReduceLogSumSquare\",(()=>[\"float t; value = 0.0;\",\"t = _A(inputIdx); value += t * t;\",\"\"]))},7019:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.isReshapeCheap=e.processDims3D=e.createPackedReshape3DProgramInfoLoader=void 0;const r=n(2517),i=n(5060),o=n(2039),a=n(2827);e.createPackedReshape3DProgramInfoLoader=(t,e,n)=>{const s=(t=>({name:\"Reshape (packed)\",inputTypes:[o.TextureType.packed],inputNames:[\"A\"],cacheHint:`${t}`}))(n);return Object.assign(Object.assign({},s),{get:()=>((t,e,n,s)=>{const u=e.dims,c=s;let l=\"\";for(let t=0;t<4;t++){let e=\"\";switch(t){case 0:e=\"outputCoords = rc;\";break;case 1:e=\"outputCoords = ivec3(rc.x, rc.y+1, rc.z);\";break;case 2:e=\"outputCoords = ivec3(rc.x, rc.y, rc.z+1);\";break;case 3:e=\"outputCoords = ivec3(rc.x, rc.y+1, rc.z+1);\";break;default:throw new Error}l+=`\\n        ${e}\\n        ${t>0?\"if(outputCoords.y < rows && outputCoords.z < cols){\":\"\"}\\n          int flattenedIndex = getFlattenedIndex(outputCoords);\\n\\n          ivec3 inputRC = inputCoordsFromReshapedOutCoords(flattenedIndex);\\n          vec2 innerDims = vec2(float(inputRC.y),float(inputRC.z));\\n\\n          result[${t}] = getChannel(getA(inputRC.x, inputRC.y, inputRC.z), innerDims);\\n\\n        ${t>0?\"}\":\"\"}\\n      `}const p=(0,i.getGlsl)(t.session.backend.glContext.version),f=`\\n      ${function(t){const e=r.ShapeUtil.computeStrides(t),n=[\"b\",\"r\",\"c\"],i=\"index\";return`\\n    ivec3 inputCoordsFromReshapedOutCoords(int index) {\\n      ${e.map(((t,r)=>`int ${n[r]} = ${i} / ${t}; ${r===e.length-1?`int ${n[r+1]} = ${i} - ${n[r]} * ${t}`:`index -= ${n[r]} * ${t}`};`)).join(\"\")}\\n      return ivec3(b, r, c);\\n    }\\n  `}(u)}\\n      ${function(t){const e=r.ShapeUtil.computeStrides(t);return`\\n  int getFlattenedIndex(ivec3 coords) {\\n    // reverse y, z order\\n    return coords.x * ${e[0]} + coords.z * ${e[1]} + coords.y;\\n  }\\n`}(c)}\\n      ${(0,a.unpackFromChannel)()}\\n\\n      void main() {\\n        ivec3 rc = getOutputCoords();\\n\\n        vec4 result = vec4(0.0);\\n\\n        ivec3 outputCoords;\\n        int rows = ${c[2]};\\n        int cols = ${c[1]};\\n\\n        ${l}\\n        ${p.output} = result;\\n      }\\n    `;return Object.assign(Object.assign({},n),{output:{dims:c,type:e.type,textureType:o.TextureType.packed},shaderSource:f,hasMain:!0})})(t,e,s,n)})},e.processDims3D=function(t){if(0===t.length)return[1,1,1];let e=1;for(let n=0;n<t.length-2;++n)e*=t[n];return[e,t.length>1?t[t.length-2]:1,t[t.length-1]]},e.isReshapeCheap=function(t,e){let n=!1;return n=0===t.length||0===e.length||(t.length<2||e.length<2?t[t.length-1]===e[e.length-1]:t[t.length-1]===e[e.length-1]&&t[t.length-2]===e[e.length-2]),n}},718:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.reshape=void 0;const r=n(2517);e.reshape=(t,e)=>{const n=r.ShapeUtil.calculateReshapedDims(e[0].dims,e[1].integerData);return t.session.pack?[t.reshapePacked(e[0],n)]:[t.reshapeUnpacked(e[0],n)]}},2268:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.parseResizeAttributesV11=e.parseResizeAttributesV10=e.resize=void 0;const r=n(5060),i=n(2039),o=n(9390),a=n(2827),s=n(9793),u={name:\"Resize\",inputNames:[\"A\"],inputTypes:[i.TextureType.packed]};e.resize=(t,e,n)=>((0,s.validateInputs)(e,n),[t.run(Object.assign(Object.assign({},u),{cacheHint:n.cacheKey,get:()=>c(t,e,n)}),e)]),e.parseResizeAttributesV10=t=>(0,s.parseUpsampleAttributes)(t,10),e.parseResizeAttributesV11=t=>(0,s.parseUpsampleAttributes)(t,11);const c=(t,e,n)=>{const s=(0,r.getGlsl)(t.session.backend.glContext.version),[c,p]=l(e,n);if(c.every((t=>1===t))&&\"tf_crop_and_resize\"!==n.coordinateTransformMode)return Object.assign(Object.assign({},u),{output:{dims:p,type:e[0].type,textureType:i.TextureType.packed},hasMain:!0,shaderSource:`void main() {\\n                    vec4 v = ${s.texture2D}(X, TexCoords);\\n                    ${s.output} = v;\\n                }`});const f=p.length;if(f<2)throw new Error(`output dimension should be at least 2, but got ${f}`);const d=p[f-2],h=p[f-1],g=e[0].dims;if(f!==g.length)throw new Error(`output dimension should match input ${g.length}, but got ${f}`);const b=g[f-2],m=g[f-1],y=c[f-2],_=c[f-1];let v=\"\";if(\"linear\"!==n.mode)throw new Error(`resize (packed) does not support mode: '${n.mode}'`);switch(n.coordinateTransformMode){case\"asymmetric\":v=\"\\n                    vec4 getSourceFracIndex(ivec4 coords) {\\n                        return vec4(coords) / scaleWHWH;\\n                    }\\n                \";break;case\"half_pixel\":v=\"\\n                    vec4 getSourceFracIndex(ivec4 coords) {\\n                        return (vec4(coords) + 0.5) / scaleWHWH - 0.5;\\n                    }\\n                \";break;case\"pytorch_half_pixel\":v=`\\n                    vec4 getSourceFracIndex(ivec4 coords) {\\n                        vec4 fcoords = vec4(coords);\\n                        return vec4(\\n                            ${h}.0 > 1.0 ? (fcoords.x + 0.5) / scaleWHWH.x - 0.5 : 0.0,\\n                            ${d}.0 > 1.0 ? (fcoords.y + 0.5) / scaleWHWH.y - 0.5 : 0.0,\\n                            ${h}.0 > 1.0 ? (fcoords.z + 0.5) / scaleWHWH.z - 0.5 : 0.0,\\n                            ${d}.0 > 1.0 ? (fcoords.w + 0.5) / scaleWHWH.w - 0.5 : 0.0\\n                          );\\n                    }\\n                `;break;case\"align_corners\":v=`\\n                    vec4 getSourceFracIndex(ivec4 coords) {\\n                        vec4 resized = vec4(${h}.0 - 1.0, ${d}.0 - 1.0, ${h}.0 - 1.0,\\n                            ${d}.0 - 1.0);\\n                        vec4 original = vec4(${m}.0 - 1.0, ${b}.0 - 1.0, ${m}.0 - 1.0,\\n                            ${b}.0 - 1.0);\\n                        vec4 new_scale = original / resized;\\n                        return vec4(coords) * new_scale;\\n                    }\\n                `;break;default:throw new Error(`resize (packed) does not support coordinateTransformMode:                                 '${n.coordinateTransformMode}'`)}const w=(0,o.getCoordsDataType)(f),x=`\\n            const vec2 inputWH = vec2(${b}.0, ${m}.0);\\n            const vec4 scaleWHWH = vec4(float(${y}), float(${_}), float(${y}), float(${_}));\\n            ${(0,a.unpackFromChannel)()}\\n            ${v}\\n            float getAValue(int x10, int r, int c, int d) {\\n                return getChannel(getA(x10, r, c, d), vec2(c, d));\\n            }\\n            void main() {\\n                ${w} rc = getOutputCoords();\\n\\n                int batch = rc[0];\\n                int depth = rc[1];\\n\\n                // retrieve the 4 coordinates that is used in the 4 packed output values.\\n                ivec4 coords = ivec4(rc.wz, rc.w + 1, rc.z + 1);\\n\\n                // calculate the source index in fraction\\n                vec4 sourceFrac = getSourceFracIndex(coords);\\n\\n                // get the lower and upper bound of the 4 values that will be packed into one texel.\\n                ivec4 x00 = ivec4(max(sourceFrac.xy, vec2(0.0)), min(inputWH - 1.0, ceil(sourceFrac.xy)));\\n                ivec4 x01 = ivec4(max(sourceFrac.xw, vec2(0.0)), min(inputWH - 1.0, ceil(sourceFrac.xw)));\\n                ivec4 x10 = ivec4(max(sourceFrac.zy, vec2(0.0)), min(inputWH - 1.0, ceil(sourceFrac.zy)));\\n                ivec4 x11 = ivec4(max(sourceFrac.zw, vec2(0.0)), min(inputWH - 1.0, ceil(sourceFrac.zw)));\\n\\n                bool hasNextRow = rc.w < ${d-1};\\n                bool hasNextCol = rc.z < ${h-1};\\n\\n                // pack x00, x01, x10, x11's top-left corner into one vec4 structure\\n                vec4 topLeft = vec4(\\n                    getAValue(batch, depth, x00.x, x00.y),\\n                    hasNextCol ? getAValue(batch, depth, x01.x, x01.y) : 0.0,\\n                    hasNextRow ? getAValue(batch, depth, x10.x, x10.y) : 0.0,\\n                    (hasNextRow && hasNextCol) ? getAValue(batch, depth, x11.x, x11.y) : 0.0);\\n\\n                // pack x00, x01, x10, x11's top-right corner into one vec4 structure\\n                vec4 topRight = vec4(\\n                    getAValue(batch, depth, x00.x, x00.w),\\n                    hasNextCol ? getAValue(batch, depth, x01.x, x01.w) : 0.0,\\n                    hasNextRow ? getAValue(batch, depth, x10.x, x10.w) : 0.0,\\n                    (hasNextRow && hasNextCol) ? getAValue(batch, depth, x11.x, x11.w) : 0.0);\\n\\n                // pack x00, x01, x10, x11's bottom-left corner into one vec4 structure\\n                vec4 bottomLeft = vec4(\\n                    getAValue(batch, depth, x00.z, x00.y),\\n                    hasNextCol ? getAValue(batch, depth, x01.z, x01.y) : 0.0,\\n                    hasNextRow ? getAValue(batch, depth, x10.z, x10.y) : 0.0,\\n                    (hasNextRow && hasNextCol) ? getAValue(batch, depth, x11.z, x11.y) : 0.0);\\n\\n                // pack x00, x01, x10, x11's bottom-right corner into one vec4 structure\\n                vec4 bottomRight = vec4(\\n                    getAValue(batch, depth, x00.z, x00.w),\\n                    hasNextCol ? getAValue(batch, depth, x01.z, x01.w) : 0.0,\\n                    hasNextRow ? getAValue(batch, depth, x10.z, x10.w) : 0.0,\\n                    (hasNextRow && hasNextCol) ? getAValue(batch, depth, x11.z, x11.w) : 0.0);\\n\\n                // calculate the interpolation fraction on u and v direction\\n                vec4 frac = vec4(sourceFrac) - floor(sourceFrac);\\n                vec4 clampFrac = clamp(frac, vec4(0.0), vec4(1.0));\\n\\n                vec4 top = mix(topLeft, topRight, clampFrac.ywyw);\\n                vec4 bottom = mix(bottomLeft, bottomRight, clampFrac.ywyw);\\n                vec4 newValue = mix(top, bottom, clampFrac.xxzz);\\n\\n                ${s.output} = vec4(newValue);\\n            }\\n        `;return Object.assign(Object.assign({},u),{output:{dims:p,type:e[0].type,textureType:i.TextureType.packed},hasMain:!0,shaderSource:x})},l=(t,e)=>{const n=t[0].dims;let r,i=e.scales;if(0===i.length){const o=t[e.scalesInputIdx];if(o&&0!==o.size){if(t[e.sizesInputIdx])throw new Error(\"Only one of scales or sizes must be provided as input.\");i=p(o,e.mode,e.isResize)}else{const o=t[e.sizesInputIdx];if(!o||0===o.size)throw new Error(\"Either scales or sizes MUST be provided as input.\");r=Array.from(o.integerData),i=f(r,n,e.mode,e.isResize)}}else if(t[e.sizesInputIdx])throw new Error(\"Only one of scales or sizes must be provided as input.\");const o=r||n.map(((t,e)=>Math.floor(t*i[e])));return[i,o]},p=(t,e,n)=>{const r=Array.from(t.floatData);return(0,s.scalesValidation)(r,e,n),r},f=(t,e,n,r)=>{const i=e.length,o=new Array(i);for(let n=0,r=i;n<r;n++)if(0===e[n]){if(0!==t[n])throw new Error(\"Input dim is zero but required output dim is non-zero.\");o[n]=1}else o[n]=t[n]/e[n];return(0,s.scalesValidation)(o,n,r),o}},8117:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.shape=void 0;const r=n(9162);e.shape=(t,e)=>(i(e),[new r.Tensor([e[0].dims.length],\"int32\",void 0,void 0,new Int32Array(e[0].dims))]);const i=t=>{if(!t||1!==t.length)throw new Error(\"Shape requires 1 input.\")}},2278:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.sliceV10=e.parseSliceAttributes=e.slice=void 0;const r=n(246),i=n(782),o=n(2517),a=n(2039),s={name:\"Slice\",inputNames:[\"A\"],inputTypes:[a.TextureType.unpacked]};e.slice=(t,e,n)=>(c(e),[t.run(Object.assign(Object.assign({},s),{cacheHint:n.cacheKey,get:()=>u(t,e[0],n)}),e)]),e.parseSliceAttributes=t=>{const e=t.attributes.getInts(\"starts\"),n=t.attributes.getInts(\"ends\"),i=t.attributes.getInts(\"axes\",[]);return(0,r.createAttributeWithCacheKey)({starts:e,ends:n,axes:i})};const u=(t,e,n)=>{const r=0===n.axes.length?e.dims.slice(0).map(((t,e)=>e)):n.axes,i=o.ShapeUtil.normalizeAxes(r,e.dims.length),u=n.starts.map(((t,n)=>t>e.dims[i[n]]-1?e.dims[i[n]]:o.ShapeUtil.normalizeAxis(t,e.dims[i[n]]))),c=n.ends.map(((t,n)=>t>e.dims[i[n]]-1?e.dims[i[n]]:o.ShapeUtil.normalizeAxis(t,e.dims[i[n]]))),l=e.dims.slice(),p=[];for(let t=0;t<i.length;t++)l[i[t]]=c[t]-u[t],u[t]>0&&p.push(`outputIdx[${i[t]}] += ${u[t]};`);const f=`\\n      float process(int outputIdx[${l.length}]) {\\n        ${p.join(\"\\n      \")}\\n        return _A(outputIdx);\\n      }`;return Object.assign(Object.assign({},s),{output:{dims:l,type:e.type,textureType:a.TextureType.unpacked},shaderSource:f})},c=t=>{if(!t||1!==t.length)throw new Error(\"Slice requires 1 input.\");if(-1===i.NUMBER_TYPES.indexOf(t[0].type))throw new Error(\"Invalid input type.\")};e.sliceV10=(t,e)=>{p(e);const n=l(t,e);return[t.run(Object.assign(Object.assign({},s),{cacheHint:n.cacheKey,get:()=>u(t,e[0],n)}),[e[0]])]};const l=(t,e)=>{if(!t.session.isInitializer(e[1].dataId)||!t.session.isInitializer(e[2].dataId)||e.length>=4&&!t.session.isInitializer(e[3].dataId)||e.length>=5&&!t.session.isInitializer(e[4].dataId))throw new Error(\"dynamic slice attributes are not allowed\");if(e.length>=5&&e[4].integerData.some((t=>1!==t)))throw new Error(\"currently non-1 steps is not supported for Slice\");const n=Array.from(e[1].integerData),r=Array.from(e[2].integerData),i=e.length>=4?Array.from(e[3].integerData):[];return{starts:n,ends:r,axes:i,cacheKey:`${i};${n};${r}`}},p=t=>{if(!t||t.length<3||t.length>5)throw new Error(\"Invalid input number.\");if(\"int32\"!==t[1].type||1!==t[1].dims.length)throw new Error(\"Invalid input type.\");if(\"int32\"!==t[2].type||1!==t[2].dims.length)throw new Error(\"Invalid input type.\");if(t.length>=4&&(\"int32\"!==t[3].type||1!==t[3].dims.length))throw new Error(\"Invalid input type.\");if(t.length>=5&&(\"int32\"!==t[4].type||1!==t[4].dims.length))throw new Error(\"Invalid input type.\")}},5524:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.softmaxV13=e.parseSoftmaxAttributesV13=e.parseSoftmaxAttributes=e.softmax=void 0;const r=n(246),i=n(2517),o=n(5060),a=n(2039),s=n(3738),u={name:\"SoftmaxComputeMax\",inputNames:[\"A\"],inputTypes:[a.TextureType.unpacked]},c={name:\"SoftmaxComputeScale\",inputNames:[\"A\",\"Max\"],inputTypes:[a.TextureType.unpacked,a.TextureType.unpacked]},l={name:\"SoftMax\",inputNames:[\"A\",\"Max\",\"Norm\"],inputTypes:[a.TextureType.unpacked,a.TextureType.unpacked,a.TextureType.unpacked]};e.softmax=(t,e,n)=>{g(e);const r=e[0].dims.slice(),o=i.ShapeUtil.normalizeAxis(n.axis,r.length),a=i.ShapeUtil.sizeToDimension(r,o),s=i.ShapeUtil.sizeFromDimension(r,o);return p(t,e,n,a,s)},e.parseSoftmaxAttributes=t=>(0,r.createAttributeWithCacheKey)({axis:t.attributes.getInt(\"axis\",1)}),e.parseSoftmaxAttributesV13=t=>(0,r.createAttributeWithCacheKey)({axis:t.attributes.getInt(\"axis\",-1)}),e.softmaxV13=(t,e,n)=>{g(e);const o=e[0].dims.slice(),a=i.ShapeUtil.normalizeAxis(n.axis,o.length),u=o.length,c=a!==u-1,l=[];let f,d=[],h=[];c&&(d=Array.from({length:u}).map(((t,e)=>e)),d[a]=u-1,d[u-1]=a,d.map((t=>l.push(o[t]))),f=(0,r.createAttributeWithCacheKey)({perm:d}),h=(0,s.transpose)(t,e,f));const b=c?i.ShapeUtil.sizeToDimension(l,u-1):i.ShapeUtil.sizeToDimension(o,u-1),m=c?i.ShapeUtil.sizeFromDimension(l,u-1):i.ShapeUtil.sizeFromDimension(o,u-1),y=p(t,c?h:e,n,b,m);return c?(0,s.transpose)(t,y,f):y};const p=(t,e,n,r,i)=>{const o=f(t,e[0],r,i,[r]),a=t.run(Object.assign(Object.assign({},u),{cacheHint:n.cacheKey,get:()=>o}),e),s=d(t,e[0],r,i,o.output.dims,[r]),p=t.run(Object.assign(Object.assign({},c),{cacheHint:n.cacheKey,get:()=>s}),[e[0],a]),g=h(t,e[0],r,i,o.output.dims,s.output.dims);return[t.run(Object.assign(Object.assign({},l),{cacheHint:n.cacheKey,get:()=>g}),[e[0],a,p])]},f=(t,e,n,r,i)=>{const[s,c]=t.calculateTextureWidthAndHeight(e.dims,a.TextureType.unpacked),l=i.length;if(n<1||r<1)throw new Error(\"Logical row count N and feature count D must be greater than or equal to 1\");if(1!==i.length)throw new Error(\"Dimensionality of the output should be 1\");if(i[0]!==n)throw new Error(\"Shape of the output should be equal to logical row count\");const p=(0,o.getGlsl)(t.session.backend.glContext.version),f=`\\n      float process(int[${l}] indices) {\\n        int logical_row_start_offset = indices[0] * ${r};\\n\\n        float max = getColorAsFloat(${p.texture2D}(A, offsetToCoords(logical_row_start_offset, ${s},\\n        ${c} )));\\n        for(int i=1; i<${r}; ++i)\\n        {\\n          float current = getColorAsFloat(${p.texture2D}(A, offsetToCoords(logical_row_start_offset + i,\\n            ${s}, ${c})));\\n          if(current > max)\\n          max = current;\\n        }\\n\\n        return max;\\n      }`;return Object.assign(Object.assign({},u),{output:{dims:i,type:e.type,textureType:a.TextureType.unpacked},shaderSource:f})},d=(t,e,n,r,i,s)=>{const[u,l]=t.calculateTextureWidthAndHeight(e.dims,a.TextureType.unpacked),p=s.length;if(n<1||r<1)throw new Error(\"Logical row count N and feature count D must be greater than or equal to 1\");if(1!==s.length)throw new Error(\"Dimensionality of the output should be 1\");if(s[0]!==n)throw new Error(\"Shape of the output should be equal to logical row count\");if(1!==i.length)throw new Error(\"Dimensionality of the intermediate results should be 1\");if(i[0]!==n)throw new Error(\"Shape of the intermediate results should be equal to logical row count\");const f=`\\n      float process(int[${p}] indices) {\\n        int logical_row_start_offset = indices[0] * ${r};\\n\\n        float norm_factor = 0.0;\\n        float max = _Max(indices);\\n        for(int i=0; i<${r}; ++i)\\n        {\\n          norm_factor += exp(getColorAsFloat(${(0,o.getGlsl)(t.session.backend.glContext.version).texture2D}(A, offsetToCoords(logical_row_start_offset + i,\\n            ${u}, ${l}))) - max);\\n        }\\n\\n        return norm_factor;\\n      }`;return Object.assign(Object.assign({},c),{output:{dims:s,type:e.type,textureType:a.TextureType.unpacked},shaderSource:f})},h=(t,e,n,r,i,o)=>{const[s,u]=t.calculateTextureWidthAndHeight(e.dims,a.TextureType.unpacked),c=e.dims.length;if(n<1||r<1)throw new Error(\"Logical row count N and feature count D must be greater than or equal to 1\");if(1!==i.length||1!==o.length)throw new Error(\"Dimensionality of the intermediate results should be 1\");if(i[0]!==n||o[0]!==n)throw new Error(\"Shape of the intermediate results should be equal to logical row count\");const p=`\\n      float process(int[${c}] indices) {\\n\\n      // get offset of current logical tensor index from the 2-D texture coordinates (TexCoords)\\n      int offset = coordsToOffset(TexCoords, ${s}, ${u});\\n\\n      //determine the logical row for this index\\n      int logical_row_index[1];\\n      logical_row_index[0] = offset / ${r};\\n\\n      float norm_factor = _Norm(logical_row_index);\\n\\n      // avoid possible division by 0\\n      // if norm_facor is 0, all elements are zero\\n      // if so, return 0\\n      if(norm_factor == 0.0)\\n        return 0.0;\\n\\n      return exp(_A(indices) - _Max(logical_row_index)) / norm_factor;\\n    }`;return Object.assign(Object.assign({},l),{output:{dims:e.dims,type:e.type,textureType:a.TextureType.unpacked},shaderSource:p})},g=t=>{if(!t||1!==t.length)throw new Error(\"Softmax requires 1 input.\");if(\"float32\"!==t[0].type&&\"float64\"!==t[0].type)throw new Error(\"Invalid input type\")}},5975:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.parseSplitAttributes=e.split=void 0;const r=n(246),i=n(2517),o=n(2039),a={name:\"Split\",inputNames:[\"A\"],inputTypes:[o.TextureType.unpacked]};e.split=(t,e,n)=>{c(e);const r=i.ShapeUtil.normalizeAxis(n.axis,e[0].dims.length),o=s(t,e,r,n),l=[];for(let i=0;i<o;++i)l.push(t.run(Object.assign(Object.assign({},a),{cacheHint:`${n.cacheKey};${i}`,get:()=>u(t,e[0],n,r,i)}),e));return l},e.parseSplitAttributes=t=>{const e=t.attributes.getInt(\"axis\",0),n=t.attributes.getInts(\"split\",[]),i=t.outputs.length;return(0,r.createAttributeWithCacheKey)({axis:e,split:n,numOutputs:i})};const s=(t,e,n,r)=>{const[,o]=i.SplitUtil.splitShape(e[0].dims,n,r.split,r.numOutputs);return o.length},u=(t,e,n,r,s)=>{const[u,c]=i.SplitUtil.splitShape(e.dims,r,n.split,n.numOutputs),l=c[s],p=u[s],f=`\\n      float process(int indices[${p.length}]) {\\n        indices[${r}] += ${l};\\n        return _A(indices);\\n      }\\n    `;return Object.assign(Object.assign({},a),{cacheHint:`${n.cacheKey}:${s}`,output:{dims:p,type:e.type,textureType:o.TextureType.unpacked},shaderSource:f})},c=t=>{if(!t||1!==t.length)throw new Error(\"Split requires one input.\");if(\"int8\"!==t[0].type&&\"uint8\"!==t[0].type&&\"int16\"!==t[0].type&&\"uint16\"!==t[0].type&&\"int32\"!==t[0].type&&\"uint32\"!==t[0].type&&\"float32\"!==t[0].type&&\"float64\"!==t[0].type&&\"bool\"!==t[0].type)throw new Error(\"Invalid input type.\")}},3933:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.parseSqueezeAttributes=e.squeezeV13=e.squeeze=void 0;const r=n(2517);e.squeeze=(t,e,n)=>{i(e);const o=r.ShapeUtil.squeezeShape(e[0].dims,n);return[t.reshapeUnpacked(e[0],o)]},e.squeezeV13=(t,n)=>(o(n),(0,e.squeeze)(t,[n[0]],Array.from(n[1].integerData))),e.parseSqueezeAttributes=t=>t.attributes.getInts(\"axes\");const i=t=>{if(!t||1!==t.length)throw new Error(\"Squeeze requires 1 input.\");if(\"string\"===t[0].type)throw new Error(\"invalid input tensor types.\")},o=t=>{if(!t||2!==t.length)throw new Error(\"Squeeze requires 2 inputs.\");if(\"int32\"!==t[1].type)throw new Error(\"Invalid input type.\")}},6558:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.sum=void 0;const r=n(5060),i=n(2039);e.sum=(t,e)=>{a(e);const n={name:\"Sum\",inputNames:e.map(((t,e)=>`X${e}`)),inputTypes:new Array(e.length).fill(i.TextureType.unpacked)};return[t.run(Object.assign(Object.assign({},n),{get:()=>o(t,e,n)}),e)]};const o=(t,e,n)=>{const o=(0,r.getGlsl)(t.session.backend.glContext.version),a=e[0].dims.slice(),s=`\\n      void main() {\\n        vec4 result = ${e.map(((t,e)=>`${o.texture2D}(X${e},TexCoords)`)).join(\" + \")};\\n        ${o.output} = result;\\n      }\\n    `;return Object.assign(Object.assign({},n),{output:{dims:a,type:e[0].type,textureType:i.TextureType.unpacked},hasMain:!0,shaderSource:s})},a=t=>{if(!t||0===t.length)throw new Error(\"Sum requires inputs.\");const e=t[0].dims.length;for(let n=1;n<t.length;n++){if(e!==t[n].dims.length)throw new Error(\"Input shapes are mismatched.\");for(let r=0;r<e;r++)if(t[0].dims[r]!==t[n].dims[r])throw new Error(\"Input shapes are not matched.\")}if(\"float32\"!==t[0].type&&\"float64\"!==t[0].type)throw new Error(\"Invalid input type.\");for(let e=1;e<t.length;e++)if(t[0].type!==t[e].type)throw new Error(\"Input types are not matched.\")}},5723:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.tile=void 0;const r=n(782),i=n(2039);e.tile=(t,e)=>{a(e);const n={name:\"Tile\",inputNames:[\"A\"],inputTypes:[i.TextureType.unpacked]};return[t.run(Object.assign(Object.assign({},n),{get:()=>o(t,e,n)}),e)]};const o=(t,e,n)=>{const r=e[0].dims.slice(),o=new Array(r.length),a=[];for(let t=0;t<r.length;t++)o[t]=r[t]*e[1].numberData[t],a.push(`inputIdx[${t}] = int(mod(float(outputIdx[${t}]), ${r[t]}.));`);const s=o.length,u=`\\n      float process(int outputIdx[${s}]) {\\n        int inputIdx[${s}];\\n        ${a.join(\"\\n\")}\\n        return _A(inputIdx);\\n      }\\n    `;return Object.assign(Object.assign({},n),{output:{dims:o,type:e[0].type,textureType:i.TextureType.unpacked},shaderSource:u})},a=t=>{if(!t||2!==t.length)throw new Error(\"Tile requires 2 input.\");if(1!==t[1].dims.length)throw new Error(\"The second input shape must 1 dimension.\");if(t[1].dims[0]!==t[0].dims.length)throw new Error(\"Invalid input shape.\");if(-1===r.NUMBER_TYPES.indexOf(t[0].type))throw new Error(\"Invalid input type.\");if(\"int32\"!==t[1].type&&\"int16\"!==t[1].type)throw new Error(\"Invalid repeat type.\")}},3738:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.parseTransposeAttributes=e.transpose=void 0;const r=n(246),i=n(2517),o=n(2039),a={name:\"Transpose\",inputNames:[\"A\"],inputTypes:[o.TextureType.unpacked]};e.transpose=(t,e,n)=>(p(e),[t.run(Object.assign(Object.assign({},a),{cacheHint:n.cacheKey,get:()=>s(t,e[0],n.perm)}),e)]),e.parseTransposeAttributes=t=>(0,r.createAttributeWithCacheKey)({perm:t.attributes.getInts(\"perm\",[])});const s=(t,e,n)=>{const r=e.dims;n=u(r,n);const i=c(r,n),s=r.length,p=`\\n      ${l(\"perm\",n,s)}\\n      float process(int indices[${s}]) {\\n        int a[${s}];\\n        perm(a, indices);\\n        return _A(a);\\n      }`;return Object.assign(Object.assign({},a),{output:{dims:i,type:e.type,textureType:o.TextureType.unpacked},shaderSource:p})},u=(t,e)=>(e&&e.length!==t.length&&(e=[...t.keys()].reverse()),e),c=(t,e)=>(e=u(t,e),i.ShapeUtil.sortBasedOnPerm(t,e)),l=(t,e,n)=>{const r=[];r.push(`void ${t}(out int a[${n}], int src[${n}]) {`);for(let t=0;t<n;++t)r.push(`\\ta[${e[t]}]=src[${t}];`);return r.push(\"\\t}\"),r.join(\"\\n\")},p=t=>{if(!t||1!==t.length)throw new Error(\"Transpose requires 1 input.\");if(\"float32\"!==t[0].type&&\"float64\"!==t[0].type)throw new Error(\"input should be float tensor\")}},8710:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.encodeAsUint8=void 0;const r=n(5060),i=n(2039);e.encodeAsUint8=(t,e)=>{const n=e.shape,o=(0,r.getGlsl)(t.session.backend.glContext.version),a=`\\n    const float FLOAT_MAX = 1.70141184e38;\\n    const float FLOAT_MIN = 1.17549435e-38;\\n\\n    bool isNaN(float val) {\\n      return (val < 1.0 || 0.0 < val || val == 0.0) ? false : true;\\n    }\\n\\n    highp vec4 encodeAsUint8(highp float v) {\\n      if (isNaN(v)) {\\n        return vec4(255, 255, 255, 255);\\n      }\\n\\n      highp float av = abs(v);\\n\\n      if(av < FLOAT_MIN) {\\n        return vec4(0.0, 0.0, 0.0, 0.0);\\n      } else if(v > FLOAT_MAX) {\\n        return vec4(0.0, 0.0, 128.0, 127.0) / 255.0;\\n      } else if(v < -FLOAT_MAX) {\\n        return vec4(0.0, 0.0,  128.0, 255.0) / 255.0;\\n      }\\n\\n      highp vec4 c = vec4(0,0,0,0);\\n\\n      highp float e = floor(log2(av));\\n      highp float m = exp2(fract(log2(av))) - 1.0;\\n\\n      c[2] = floor(128.0 * m);\\n      m -= c[2] / 128.0;\\n      c[1] = floor(32768.0 * m);\\n      m -= c[1] / 32768.0;\\n      c[0] = floor(8388608.0 * m);\\n\\n      highp float ebias = e + 127.0;\\n      c[3] = floor(ebias / 2.0);\\n      ebias -= c[3] * 2.0;\\n      c[2] += floor(ebias) * 128.0;\\n\\n      c[3] += 128.0 * step(0.0, -v);\\n\\n      return c / 255.0;\\n    }\\n\\n    void main() {\\n      float value = ${o.texture2D}(X,TexCoords).r;\\n      ${o.output} = encodeAsUint8(value);\\n    }`,s={name:\"Uint8Encode\",inputTypes:[i.TextureType.unpacked],inputNames:[\"X\"],output:{dims:n,type:e.tensor.type,textureType:i.TextureType.downloadUint8AsFloat},shaderSource:a,hasMain:!0};return t.executeProgram(s,[e.tensor])}},4909:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.tanh=e.tan=e.sqrt=e.sin=e.sigmoid=e.relu=e.not=e.neg=e.log=e.parseLeakyReluAttributes=e.leakyRelu=e.identity=e.floor=e.exp=e.parseEluAttributes=e.elu=e.cos=e.ceil=e.clipV11=e.parseClipAttributes=e.clip=e.atan=e.asin=e.acos=e.abs=e.glslTanh=e.glslTan=e.glslSqrt=e.glslSigmoid=e.glslRelu=e.glslSin=e.glslNot=e.glslNeg=e.glslLog=e.glslLeakyRelu=e.glslIdentity=e.glslClip=e.glslFloor=e.glslExp=e.glslElu=e.glslCos=e.glslCeil=e.glslAtan=e.glslAsin=e.glslAcos=e.glslAbs=void 0;const r=n(246),i=n(2517),o=n(8520),a=n(5060),s=n(2039);function u(){return P(\"abs\")}function c(){return P(\"acos\")}function l(){return P(\"asin\")}function p(){return P(\"atan\")}function f(){return P(\"ceil\")}function d(){return P(\"cos\")}function h(t){const e=\"elu\";return{body:`\\n  const float alpha = float(${t});\\n\\n  float ${e}_(float a) {\\n    return a >= 0.0 ? a: (exp(a) - 1.0) * alpha;\\n  }\\n  vec4 ${e}_(vec4 v) {\\n    return vec4(${e}_(v.x), ${e}_(v.y), ${e}_(v.z), ${e}_(v.w));\\n  }\\n  `,name:e,type:o.FunctionType.ValueBased}}function g(){return P(\"exp\")}function b(){return P(\"floor\")}function m(t,e){const n=\"clip\";return{body:`\\n  const float min = float(${t});\\n  const float max = float(${e});\\n\\n  float ${n}_(float a) {\\n    return clamp(a, min, max);\\n  }\\n  vec4 ${n}_(vec4 v) {\\n    return clamp(v, min, max);\\n  }\\n  `,name:n,type:o.FunctionType.ValueBased}}function y(){const t=\"indentity\";return{body:`\\n  float ${t}_(float a) {\\n    return a;\\n  }\\n  vec4 ${t}_(vec4 v) {\\n    return v;\\n  }\\n  `,name:t,type:o.FunctionType.ValueBased}}function _(t){const e=\"leakyRelu\";return{body:`\\n  const float alpha = float(${t});\\n\\n  float ${e}_(float a) {\\n    return a < 0.0 ? a * alpha : a;\\n  }\\n  vec4 ${e}_(vec4 v) {\\n    return vec4(${e}_(v.x), ${e}_(v.y), ${e}_(v.z), ${e}_(v.w));\\n  }\\n  `,name:e,type:o.FunctionType.ValueBased}}function v(){return P(\"log\")}function w(){const t=\"neg\";return{body:`\\n  float ${t}_(float a) {\\n    return -a;\\n  }\\n  vec4 ${t}_(vec4 v) {\\n    return -v;\\n  }\\n  `,name:t,type:o.FunctionType.ValueBased}}function x(){const t=\"not\";return{body:`\\n  float ${t}_(float a) {\\n    return float( ! bool(a) );\\n  }\\n  bool ${t}_(bool a) {\\n    return !a;\\n  }\\n  vec4 ${t}_(vec4 v) {\\n    return vec4(!bool(v.x), !bool(v.y), !bool(v.z), !bool(v.w));\\n  }\\n  bvec4 ${t}_(bvec4 v) {\\n    return bvec4(!v.x, !v.y, !v.z, !v.w);\\n  }\\n  `,name:t,type:o.FunctionType.ValueBased}}function T(){return P(\"sin\")}function S(){const t=\"relu\";return{body:`\\n  float ${t}_(float a) {\\n    return max( a, 0.0 );\\n  }\\n  vec4 ${t}_(vec4 v) {\\n    return max( v, 0.0 );\\n  }\\n  `,name:t,type:o.FunctionType.ValueBased}}function O(){const t=\"sigmoid\";return{body:`\\n  float ${t}_(float a) {\\n    return 1.0 / (1.0 + exp(-a));\\n  }\\n  vec4 ${t}_(vec4 v) {\\n    return 1.0 / (1.0 + exp(-v));\\n  }\\n  `,name:t,type:o.FunctionType.ValueBased}}function A(){return P(\"sqrt\")}function E(){return P(\"tan\")}function I(){const t=\"tanh\";return{body:`\\n  float ${t}_(float a) {\\n    a = clamp(a, -10., 10.);\\n    a = exp(2.*a);\\n    return (a - 1.) / (a + 1.);\\n  }\\n  vec4 ${t}_(vec4 v) {\\n    v = clamp(v, -10., 10.);\\n    v = exp(2.*v);\\n    return (v - 1.) / (v + 1.);\\n  }\\n  `,name:t,type:o.FunctionType.ValueBased}}function P(t){return{body:`\\n  float ${t}_(float a) {\\n    return ${t}(a);\\n  }\\n  vec4 ${t}_(vec4 v) {\\n    return ${t}(v);\\n  }\\n  `,name:t,type:o.FunctionType.ValueBased}}e.glslAbs=u,e.glslAcos=c,e.glslAsin=l,e.glslAtan=p,e.glslCeil=f,e.glslCos=d,e.glslElu=h,e.glslExp=g,e.glslFloor=b,e.glslClip=m,e.glslIdentity=y,e.glslLeakyRelu=_,e.glslLog=v,e.glslNeg=w,e.glslNot=x,e.glslSin=T,e.glslRelu=S,e.glslSigmoid=O,e.glslSqrt=A,e.glslTan=E,e.glslTanh=I;const D=(t,e,n,r)=>{const i=t.session.pack?s.TextureType.packed:s.TextureType.unpacked,o={name:n.name,inputTypes:[i],inputNames:[\"A\"],cacheHint:r};return Object.assign(Object.assign({},o),{get:()=>((t,e,n,r)=>{const i=t.session.pack?s.TextureType.packed:s.TextureType.unpacked,o=(0,a.getGlsl)(t.session.backend.glContext.version);return Object.assign(Object.assign({},e),{output:{dims:n.dims,type:n.type,textureType:i},shaderSource:`\\n     ${r.body}\\n     void main() {\\n       vec4 v = ${o.texture2D}(A, TexCoords);\\n       v = ${r.name}_(v);\\n       ${o.output} = v;\\n     }\\n     `,hasMain:!0})})(t,o,e,n)})};e.abs=(t,e)=>[t.run(D(t,e[0],u()),e)],e.acos=(t,e)=>[t.run(D(t,e[0],c()),e)],e.asin=(t,e)=>[t.run(D(t,e[0],l()),e)],e.atan=(t,e)=>[t.run(D(t,e[0],p()),e)],e.clip=(t,e,n)=>[t.run(D(t,e[0],m(n.min,n.max),n.cacheKey),e)],e.parseClipAttributes=t=>(0,r.createAttributeWithCacheKey)({min:t.attributes.getFloat(\"min\",i.MIN_CLIP),max:t.attributes.getFloat(\"max\",i.MAX_CLIP)}),e.clipV11=(t,n)=>{const r=$(t,n);return(0,e.clip)(t,[n[0]],r)};const $=(t,e)=>{if(e.length>=3&&(!t.session.isInitializer(e[1].dataId)||!t.session.isInitializer(e[2].dataId)))throw new Error(\"dynamic clip attributes are not allowed\");const n=e.length>=3?e[1].numberData[0]:i.MIN_CLIP,o=e.length>=3?e[2].numberData[0]:i.MAX_CLIP;return(0,r.createAttributeWithCacheKey)({min:n,max:o})};e.ceil=(t,e)=>[t.run(D(t,e[0],f()),e)],e.cos=(t,e)=>[t.run(D(t,e[0],d()),e)],e.elu=(t,e,n)=>[t.run(D(t,e[0],h(n.alpha),n.cacheKey),e)],e.parseEluAttributes=t=>(0,r.createAttributeWithCacheKey)({alpha:t.attributes.getFloat(\"alpha\",1)}),e.exp=(t,e)=>[t.run(D(t,e[0],g()),e)],e.floor=(t,e)=>[t.run(D(t,e[0],b()),e)],e.identity=(t,e)=>[t.run(D(t,e[0],y()),e)],e.leakyRelu=(t,e,n)=>[t.run(D(t,e[0],_(n.alpha),n.cacheKey),e)],e.parseLeakyReluAttributes=t=>(0,r.createAttributeWithCacheKey)({alpha:t.attributes.getFloat(\"alpha\",.01)}),e.log=(t,e)=>[t.run(D(t,e[0],v()),e)],e.neg=(t,e)=>[t.run(D(t,e[0],w()),e)],e.not=(t,e)=>[t.run(D(t,e[0],x()),e)],e.relu=(t,e)=>[t.run(D(t,e[0],S()),e)],e.sigmoid=(t,e)=>[t.run(D(t,e[0],O()),e)],e.sin=(t,e)=>[t.run(D(t,e[0],T()),e)],e.sqrt=(t,e)=>[t.run(D(t,e[0],A()),e)],e.tan=(t,e)=>[t.run(D(t,e[0],E()),e)],e.tanh=(t,e)=>[t.run(D(t,e[0],I()),e)]},5611:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.createUnpackProgramInfoLoader=e.createUnpackProgramInfo=void 0;const r=n(5060),i=n(2039),o=n(9390),a=n(2827),s={name:\"unpack\",inputNames:[\"A\"],inputTypes:[i.TextureType.packed]};e.createUnpackProgramInfo=(t,e)=>{const n=e.dims.length,u=(0,a.getChannels)(\"rc\",n),c=u.slice(-2),l=(0,o.getCoordsDataType)(n),p=(0,a.unpackFromChannel)(),f=0===e.dims.length?\"\":function(t,e){if(1===t)return\"rc\";let n=\"\";for(let r=0;r<t;r++)n+=e[r],r<t-1&&(n+=\",\");return n}(n,u),d=n<=1?\"rc\":`vec2(${c.join(\",\")})`,h=`\\n    ${p}\\n    void main() {\\n      ${l} rc = getOutputCoords();\\n\\n       // Sample the texture with the coords to get the rgba channel value.\\n       vec4 packedInput = getA(${f});\\n\\n       ${(0,r.getGlsl)(t.session.backend.glContext.version).output} = vec4(getChannel(packedInput, ${d}), 0, 0, 0);\\n     }\\n   `;return Object.assign(Object.assign({},s),{hasMain:!0,output:{dims:e.dims,type:e.type,textureType:i.TextureType.unpacked},shaderSource:h})},e.createUnpackProgramInfoLoader=(t,n)=>Object.assign(Object.assign({},s),{get:()=>(0,e.createUnpackProgramInfo)(t,n)})},8428:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.parseUnsqueezeAttributes=e.unsqueezeV13=e.unsqueeze=void 0;const r=n(2517);e.unsqueeze=(t,e,n)=>{i(e);const o=r.ShapeUtil.unsqueezeShape(e[0].dims,n);return[t.reshapeUnpacked(e[0],o)]},e.unsqueezeV13=(t,n)=>(o(n),(0,e.unsqueeze)(t,[n[0]],Array.from(n[1].integerData))),e.parseUnsqueezeAttributes=t=>t.attributes.getInts(\"axes\");const i=t=>{if(!t||1!==t.length)throw new Error(\"Unsqueeze requires 1 input.\");if(\"string\"===t[0].type)throw new Error(\"invalid input tensor types.\")},o=t=>{if(!t||2!==t.length)throw new Error(\"Unsqueeze requires 2 inputs.\");if(\"int32\"!==t[1].type)throw new Error(\"Invalid input type.\")}},9793:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.scalesValidation=e.validateInputs=e.parseUpsampleAttributes=e.parseUpsampleAttributesV9=e.parseUpsampleAttributesV7=e.upsample=void 0;const r=n(246),i=n(5060),o=n(2039),a={name:\"Upsample\",inputNames:[\"X\"],inputTypes:[o.TextureType.unpacked]};e.upsample=(t,n,r)=>((0,e.validateInputs)(n,r),[t.run(Object.assign(Object.assign({},a),{cacheHint:r.cacheKey,get:()=>s(t,n,r)}),n)]),e.parseUpsampleAttributesV7=t=>(0,e.parseUpsampleAttributes)(t,7),e.parseUpsampleAttributesV9=t=>(0,e.parseUpsampleAttributes)(t,9),e.parseUpsampleAttributes=(t,n)=>{const i=n>=10,o=t.attributes.getString(\"mode\",\"nearest\");if(\"nearest\"!==o&&\"linear\"!==o&&(n<11||\"cubic\"!==o))throw new Error(`unrecognized mode: ${o}`);let a=[];n<9&&(a=t.attributes.getFloats(\"scales\"),(0,e.scalesValidation)(a,o,i));const s=t.attributes.getFloat(\"extrapolation_value\",0),u=n>10?t.attributes.getString(\"coordinate_transformation_mode\",\"half_pixel\"):\"asymmetric\";if(-1===[\"asymmetric\",\"pytorch_half_pixel\",\"tf_half_pixel_for_nn\",\"align_corners\",\"tf_crop_and_resize\",\"half_pixel\"].indexOf(u))throw new Error(`coordinate_transform_mode '${u}' is not supported`);const c=\"tf_crop_and_resize\"===u,l=c,p=\"nearest\"===o&&n>=11?t.attributes.getString(\"nearest_mode\",\"round_prefer_floor\"):\"\";if(-1===[\"round_prefer_floor\",\"round_prefer_ceil\",\"floor\",\"ceil\",\"\"].indexOf(p))throw new Error(`nearest_mode '${p}' is not supported`);const f=t.attributes.getFloat(\"cubic_coeff_a\",-.75),d=0!==t.attributes.getInt(\"exclude_outside\",0);if(d&&\"cubic\"!==o)throw new Error(\"exclude_outside can be set to 1 only when mode is CUBIC.\");const h=n<11||\"nearest\"===o&&\"asymmetric\"===u&&\"floor\"===p;let g=0,b=0,m=0;return n>10?t.inputs.length>2?(g=1,b=2,m=3):(b=1,m=2):9===n&&(b=1),(0,r.createAttributeWithCacheKey)({opset:n,isResize:i,mode:o,scales:a,extrapolationValue:s,coordinateTransformMode:u,useExtrapolation:l,needRoiInput:c,nearestMode:p,cubicCoefficientA:f,excludeOutside:d,useNearest2xOptimization:h,roiInputIdx:g,scalesInputIdx:b,sizesInputIdx:m})};const s=(t,e,n)=>{const r=(0,i.getGlsl)(t.session.backend.glContext.version),[s,u]=t.calculateTextureWidthAndHeight(e[0].dims,o.TextureType.unpacked),c=e[0].dims.map(((t,e)=>Math.floor(t*n.scales[e]))),[l,p]=t.calculateTextureWidthAndHeight(c,o.TextureType.unpacked),f=c.length,d=new Array(f),h=new Array(f);let g=`\\n      int output_pitches[${f}];\\n      int input_pitches[${f}];\\n      `;for(let t=f-1;t>=0;t--)d[t]=t===f-1?1:d[t+1]*c[t+1],h[t]=t===f-1?1:h[t+1]*e[0].dims[t+1],g+=`\\n        output_pitches[${t}] = ${d[t]};\\n        input_pitches[${t}] = ${h[t]};\\n        `;const b=`\\n      float getInputFloat(int index) {\\n        vec2 coords = offsetToCoords(index, ${s}, ${u});\\n        float value = getColorAsFloat(${r.texture2D}(X, coords));\\n        return value;\\n      }\\n      `,m=\"nearest\"===n.mode?`\\n    ${b}\\n    float process(int indices[${f}]) {\\n      int input_index = 0;\\n      int output_index = coordsToOffset(TexCoords, ${l}, ${p});\\n\\n      ${g}\\n\\n      int d, m;\\n      for (int dim = 0; dim < ${f}; ++dim) {\\n        d = output_index / output_pitches[dim];\\n        m = output_index - d * output_pitches[dim];\\n        output_index = m;\\n\\n        if (scales[dim] != 1 && d > 0) {\\n          int d2 = d / scales[dim];\\n          m = d - d2 * scales[dim];\\n          d = d2;\\n        }\\n        input_index += input_pitches[dim] * d;\\n      }\\n\\n      return getInputFloat(input_index);\\n    }`:4===f?`\\n    ${b}\\n    float process(int indices[4]) {\\n      int input_index = 0;\\n      int output_index = coordsToOffset(TexCoords, ${l}, ${p});\\n\\n      ${g}\\n\\n      int m;\\n      int index_of_dim0, index_of_dim1, index_of_dim2, index_of_dim3;\\n      index_of_dim0 = output_index / output_pitches[0];\\n      m = output_index - index_of_dim0 * output_pitches[0];\\n      index_of_dim1 = m / output_pitches[1];\\n      m = m - index_of_dim1 * output_pitches[1];\\n      index_of_dim2 = m / output_pitches[2];\\n      m = m - index_of_dim2 * output_pitches[2];\\n      index_of_dim3 = m;\\n\\n      int index_of_input_dim2, index_of_input_dim3, x_offset, y_offset;\\n      index_of_input_dim2 = index_of_dim2 / scales[2];\\n      y_offset = index_of_dim2 - index_of_input_dim2 * scales[2];\\n      index_of_input_dim3 = index_of_dim3 / scales[3];\\n      x_offset = index_of_dim3 - index_of_input_dim3 * scales[3];\\n\\n      input_index = index_of_dim0 * input_pitches[0] +\\n            index_of_dim1 * input_pitches[1] +\\n            index_of_input_dim2 * input_pitches[2] +\\n            index_of_input_dim3;\\n\\n      float x00 = getInputFloat(input_index);\\n      float x10, x01, x11;\\n\\n      bool end_of_dim2 = false;\\n      if (index_of_input_dim2 == (${e[0].dims[2]} - 1)) {\\n        // It's the end in dimension 2\\n        x01 = x00;\\n        end_of_dim2 = true;\\n      } else {\\n        x01 = getInputFloat(input_index + input_pitches[2]);\\n      }\\n\\n      if (index_of_input_dim3 == (input_pitches[2] - 1)) {\\n        // It's the end in dimension 3\\n        x10 = x00;\\n        x11 = x01;\\n      }\\n      else {\\n        x10 = getInputFloat(input_index + 1);\\n        x11 = end_of_dim2 ? x10 : getInputFloat(input_index + input_pitches[2] + 1);\\n      }\\n\\n      float y0 = x00 + float(y_offset) * (x01 - x00) / float(scales[2]);\\n      float y1 = x10 + float(y_offset) * (x11 - x10) / float(scales[2]);\\n      return y0 + float(x_offset) * (y1 - y0) / float(scales[3]);\\n    }`:`\\n    ${b}\\n    float process(int indices[2]) {\\n      int input_index = 0;\\n      int output_index = coordsToOffset(TexCoords, ${l}, ${p});\\n\\n      ${g}\\n\\n      int m;\\n      int index_of_dim0, index_of_dim1;\\n      index_of_dim0 = output_index / output_pitches[0];\\n      m = output_index - index_of_dim0 * output_pitches[0];\\n      index_of_dim1 = m;\\n\\n      int index_of_input_dim0, index_of_input_dim1, x_offset, y_offset;\\n      index_of_input_dim0 = index_of_dim0 / scales[0];\\n      y_offset = index_of_dim0 - index_of_input_dim0 * scales[0];\\n      index_of_input_dim1 = index_of_dim1 / scales[1];\\n      x_offset = index_of_dim1 - index_of_input_dim1 * scales[1];\\n\\n      input_index = index_of_input_dim0 * input_pitches[0] + index_of_input_dim1;\\n\\n      float x00 = getInputFloat(input_index);\\n      float x10, x01, x11;\\n\\n      bool end_of_dim0 = false;\\n      if (index_of_input_dim0 == (${e[0].dims[0]} - 1)) {\\n        // It's the end in dimension 0\\n        x01 = x00;\\n        end_of_dim0 = true;\\n      } else {\\n        x01 = getInputFloat(input_index + input_pitches[0]);\\n      }\\n\\n      if (index_of_input_dim1 == (input_pitches[0] - 1)) {\\n        // It's the end in dimension 1\\n        x10 = x00;\\n        x11 = x01;\\n      }\\n      else {\\n        x10 = getInputFloat(input_index + 1);\\n        x11 = end_of_dim0 ? x10 : getInputFloat(input_index + input_pitches[0] + 1);\\n      }\\n\\n      float y0 = x00 + float(y_offset) * (x01 - x00) / float(scales[0]);\\n      float y1 = x10 + float(y_offset) * (x11 - x10) / float(scales[0]);\\n      return y0 + float(x_offset) * (y1 - y0) / float(scales[1]);\\n    }`;return Object.assign(Object.assign({},a),{output:{dims:c,type:e[0].type,textureType:o.TextureType.unpacked},shaderSource:m,variables:[{name:\"scales\",type:\"int\",arrayLength:n.scales.length,data:n.scales.map((t=>Math.ceil(t)))}]})};e.validateInputs=(t,e)=>{if(!t||e.opset<9&&1!==t.length||e.opset>=9&&e.opset<11&&2!==t.length||e.opset>=11&&t.length<2)throw new Error(\"invalid inputs.\");if(e.scales.length>0&&t[0].dims.length!==e.scales.length)throw new Error(\"Invalid input shape.\");if(\"string\"===t[0].type)throw new Error(\"Invalid input tensor types.\")},e.scalesValidation=(t,e,n)=>{if(n){for(const e of t)if(e<=0)throw new Error(\"Scale value should be greater than 0.\")}else for(const e of t)if(e<1)throw new Error(\"Scale value should be greater than or equal to 1.\");if(!(\"linear\"!==e&&\"cubic\"!==e||2===t.length||4===t.length&&1===t[0]&&1===t[1]))throw new Error(`'Linear' mode and 'Cubic' mode only support 2-D inputs ('Bilinear', 'Bicubic')         or 4-D inputs with the corresponding outermost 2 scale values being 1         in the ${n?\"Resize\":\"Upsample\"} opeartor.`)}},1958:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.ProgramManager=void 0;const r=n(1670),i=n(6231),o=n(8879),a=n(5060);e.ProgramManager=class{constructor(t,e,n){this.profiler=t,this.glContext=e,this.textureLayoutStrategy=n,this.repo=new Map,this.attributesBound=!1}getArtifact(t){return this.repo.get(t)}setArtifact(t,e){this.repo.set(t,e)}run(t,e,n){var r;this.profiler.event(\"op\",`ProgramManager.run ${null!==(r=t.programInfo.name)&&void 0!==r?r:\"unknown kernel\"}`,(()=>{var r;const o=this.glContext.gl,a=t.program;o.useProgram(a);try{this.bindOutput(n),this.attributesBound||this.bindAttributes(t.attribLocations),this.bindUniforms(t.uniformLocations,null!==(r=t.programInfo.variables)&&void 0!==r?r:[],e)}catch(e){throw i.Logger.error(\"ProgramManager\",t.programInfo.shaderSource),e}this.profiler.event(\"backend\",\"GlContext.draw()\",(()=>{this.glContext.draw()}))}),this.glContext)}dispose(){this.vertexShader&&this.glContext.deleteShader(this.vertexShader),this.repo.forEach((t=>this.glContext.deleteProgram(t.program)))}build(t,e,n){return this.profiler.event(\"backend\",\"ProgramManager.build\",(()=>{const r=new o.GlslPreprocessor(this.glContext,t,e,n),i=r.preprocess(),a=this.compile(i);return{programInfo:t,program:a,uniformLocations:this.getUniformLocations(a,r.context.programInfo.inputNames,r.context.programInfo.variables),attribLocations:this.getAttribLocations(a)}}))}compile(t){if(!this.vertexShader){i.Logger.verbose(\"ProrgramManager\",\"Compiling and caching Vertex shader for the first time\");const t=(0,a.getVertexShaderSource)(this.glContext.version);this.vertexShader=this.glContext.compileShader(t,this.glContext.gl.VERTEX_SHADER)}r.env.debug&&i.Logger.verbose(\"ProrgramManager\",`FragShader:\\n${t}\\n`);const e=this.glContext.compileShader(t,this.glContext.gl.FRAGMENT_SHADER),n=this.glContext.createProgram(this.vertexShader,e);return this.glContext.deleteShader(e),n}bindOutput(t){const e=t.width,n=t.height;i.Logger.verbose(\"ProrgramManager\",`Binding output texture to Framebuffer: w/h=${e}/${n}, shape=${t.shape}, type=${t.tensor.type}`),this.glContext.attachFramebuffer(t.texture,e,n)}bindAttributes(t){const e=t.position,n=t.textureCoord;this.glContext.setVertexAttributes(e,n),this.attributesBound=!0}bindUniforms(t,e,n){var r;const i=this.glContext.gl;let o=0;for(const{name:a,type:s,location:u,arrayLength:c}of t){const t=null===(r=e.find((t=>t.name===a)))||void 0===r?void 0:r.data;if(\"sampler2D\"!==s&&!t)throw new Error(`variable '${a}' does not have data defined in program info`);switch(s){case\"sampler2D\":this.bindTexture(n[o],u,o),o++;break;case\"float\":c?i.uniform1fv(u,t):i.uniform1f(u,t);break;case\"int\":c?i.uniform1iv(u,t):i.uniform1i(u,t);break;default:throw new Error(`Uniform not implemented: ${s}`)}}}bindTexture(t,e,n){this.glContext.bindTextureToUniform(t.texture,n,e)}getAttribLocations(t){return{position:this.getAttribLocation(t,\"position\"),textureCoord:this.getAttribLocation(t,\"textureCoord\")}}getUniformLocations(t,e,n){const r=[];if(e)for(const n of e)r.push({name:n,type:\"sampler2D\",location:this.getUniformLocation(t,n)});if(n)for(const e of n)r.push(Object.assign(Object.assign({},e),{location:this.getUniformLocation(t,e.name)}));return r}getUniformLocation(t,e){const n=this.glContext.gl.getUniformLocation(t,e);if(null===n)throw new Error(`Uniform ${e} not found.`);return n}getAttribLocation(t,e){return this.glContext.gl.getAttribLocation(t,e)}}},6416:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.WebGLSessionHandler=void 0;const r=n(6231),i=n(1047),o=n(8316),a=n(1640),s=n(1958),u=n(7859),c=n(5702);e.WebGLSessionHandler=class{constructor(t,e){this.backend=t,this.context=e,this.layoutStrategy=new u.PreferLogicalStrategy(t.glContext.maxTextureSize),this.programManager=new s.ProgramManager(this.context.profiler,t.glContext,this.layoutStrategy),this.textureManager=new c.TextureManager(t.glContext,this.layoutStrategy,this.context.profiler,{reuseTextures:\"full\"===t.textureCacheMode}),this.packedTextureDataCache=new Map,this.unpackedTextureDataCache=new Map,this.pack=t.pack,this.pack2unpackMap=new Map,this.unpack2packMap=new Map}createInferenceHandler(){return new o.WebGLInferenceHandler(this)}onGraphInitialized(t){const e=t.getValues().filter((t=>-1===t.from&&t.tensor)).map((t=>t.tensor.dataId));this.initializers=new Set(e)}isInitializer(t){return!!this.initializers&&this.initializers.has(t)}addInitializer(t){this.initializers.add(t)}getTextureData(t,e){return e?this.packedTextureDataCache.get(t):this.unpackedTextureDataCache.get(t)}setTextureData(t,e,n=!1){r.Logger.verbose(\"WebGLSessionHandler\",\"Storing Texture data in cache\"),n?this.packedTextureDataCache.set(t,e):this.unpackedTextureDataCache.set(t,e)}dispose(){this.programManager.dispose(),this.textureManager.clearActiveTextures(),this.packedTextureDataCache.forEach((t=>this.textureManager.releaseTexture(t,!0))),this.packedTextureDataCache=new Map,this.unpackedTextureDataCache.forEach((t=>this.textureManager.releaseTexture(t,!0))),this.unpackedTextureDataCache=new Map}resolve(t,e,n){const r=(0,i.resolveOperator)(t,e,a.WEBGL_OP_RESOLVE_RULES);return{impl:r.opImpl,context:r.opInit?r.opInit(t,n):t}}}},7769:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.Uint8DataEncoder=e.RGBAFloatDataEncoder=e.RedFloat32DataEncoder=void 0;const r=n(6231);e.RedFloat32DataEncoder=class{constructor(t,e=1){if(1===e)this.internalFormat=t.R32F,this.format=t.RED,this.textureType=t.FLOAT,this.channelSize=e;else{if(4!==e)throw new Error(`Invalid number of channels: ${e}`);this.internalFormat=t.RGBA32F,this.format=t.RGBA,this.textureType=t.FLOAT,this.channelSize=e}}encode(t,e){let n,i;return t.constructor!==Float32Array&&(r.Logger.warning(\"Encoder\",\"data was not of type Float32; creating new Float32Array\"),i=new Float32Array(t)),e*this.channelSize>t.length?(r.Logger.warning(\"Encoder\",\"Source data too small. Allocating larger array\"),i=t,n=this.allocate(e*this.channelSize),i.forEach(((t,e)=>n[e]=t))):(i=t,n=i),n}allocate(t){return new Float32Array(4*t)}decode(t,e){return 1===this.channelSize?t.filter(((t,e)=>e%4==0)).subarray(0,e):t.subarray(0,e)}},e.RGBAFloatDataEncoder=class{constructor(t,e=1,n){if(1!==e&&4!==e)throw new Error(`Invalid number of channels: ${e}`);this.internalFormat=t.RGBA,this.format=t.RGBA,this.channelSize=e,this.textureType=n||t.FLOAT}encode(t,e){let n=t;return 1===this.channelSize&&(r.Logger.verbose(\"Encoder\",\"Exploding into a larger array\"),n=this.allocate(e),t.forEach(((t,e)=>n[4*e]=t))),n}allocate(t){return new Float32Array(4*t)}decode(t,e){return 1===this.channelSize?t.filter(((t,e)=>e%4==0)).subarray(0,e):t.subarray(0,e)}},e.Uint8DataEncoder=class{constructor(t,e=1){if(this.channelSize=4,1===e)this.internalFormat=t.ALPHA,this.format=t.ALPHA,this.textureType=t.UNSIGNED_BYTE,this.channelSize=e;else{if(4!==e)throw new Error(`Invalid number of channels: ${e}`);this.internalFormat=t.RGBA,this.format=t.RGBA,this.textureType=t.UNSIGNED_BYTE,this.channelSize=e}}encode(t,e){return new Uint8Array(t.buffer,t.byteOffset,t.byteLength)}allocate(t){return new Uint8Array(t*this.channelSize)}decode(t,e){if(t instanceof Uint8Array)return t.subarray(0,e);throw new Error(`Invalid array type: ${t.constructor}`)}}},7859:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.getBatchDim=e.sizeToSquarishShape=e.getRowsCols=e.sizeFromShape=e.isInt=e.parseAxisParam=e.squeezeShape=e.PreferLogicalStrategy=e.AlwaysKeepOriginalSizeStrategy=void 0;const r=n(6231),i=n(2517);function o(t,e){const n=[],r=[],i=null!=e&&Array.isArray(e)&&0===e.length,o=null==e||i?null:a(e,t).sort();let s=0;for(let e=0;e<t.length;++e){if(null!=o){if(o[s]===e&&1!==t[e])throw new Error(`Can't squeeze axis ${e} since its dim '${t[e]}' is not 1`);(null==o[s]||o[s]>e)&&1===t[e]&&(n.push(t[e]),r.push(e)),o[s]<=e&&s++}1!==t[e]&&(n.push(t[e]),r.push(e))}return{newShape:n,keptDims:r}}function a(t,e){const n=e.length;return t=null==t?e.map(((t,e)=>e)):[].concat(t),(0,i.assert)(t.every((t=>t>=-n&&t<n)),(()=>`All values in axis param must be in range [-${n}, ${n}) but got axis ${t}`)),(0,i.assert)(t.every(s),(()=>`All values in axis param must be integers but got axis ${t}`)),t.map((t=>t<0?n+t:t))}function s(t){return t%1==0}function u(t){if(0===t.length)return 1;let e=t[0];for(let n=1;n<t.length;n++)e*=t[n];return e}function c(t){const e=Math.ceil(Math.sqrt(t));return[e,Math.ceil(t/e)]}e.AlwaysKeepOriginalSizeStrategy=class{constructor(t){this.maxTextureSize=t}computeTextureWH(t,e){if(0===t.length)return[1,1];const n=this.maxTextureSize;if(e&&void 0!==e.breakAxis){const i=e.breakAxis>=t.length?1:t.slice(e.breakAxis).reduce(((t,e)=>t*e)),o=e.breakAxis<=0?1:t.slice(0,e.breakAxis).reduce(((t,e)=>t*e));if(!(i>n||o>n))return[i,o];r.Logger.verbose(\"TextureLayout\",`Given width/height preferences were unattainable: shape:${t}, breakAxis:${e.breakAxis}`)}const i=t.reduce(((t,e)=>t*e));let o=Math.floor(Math.sqrt(i));for(;o<n&&o<i&&i%o!=0;o++);if(o>=n||i%o!=0)throw new Error(`The given dimensions are outside this GPU's boundaries: ${t}`);return[o,i/o]}},e.PreferLogicalStrategy=class{constructor(t){this.maxTextureSize=t}computeTextureWH(t,e){const n=this.computeTexture(t,e);return e&&e.isPacked&&(n[0]/=2,n[1]/=2),e&&e.reverseWH?[n[1],n[0]]:n}computeTexture(t,e){const n=e&&e.isPacked;if(0===t.length)return n?[2,2]:[1,1];let i=this.maxTextureSize;if(e&&void 0!==e.breakAxis){const n=e.breakAxis>=t.length?1:t.slice(e.breakAxis).reduce(((t,e)=>t*e)),o=e.breakAxis<=0?1:t.slice(0,e.breakAxis).reduce(((t,e)=>t*e));if(!(n>i||o>i))return[n,o];r.Logger.verbose(\"TextureLayout\",`Given width/height preferences were unattainable: shape:${t}, breakAxis:${e.breakAxis}`)}let a=t.slice(0);if(n&&(i*=2,a=a.map(((t,e)=>e>=a.length-2?a[e]%2==0?a[e]:a[e]+1:a[e])),1===a.length&&(a=[2,a[0]])),2!==a.length){const t=o(a);a=t.newShape}const s=u(a);return a.length<=1&&s<=i?[1,s]:2===a.length&&a[0]<=i&&a[1]<=i?a:3===a.length&&a[0]*a[1]<=i&&a[2]<=i?[a[0]*a[1],a[2]]:3===a.length&&a[0]<=i&&a[1]*a[2]<=i?[a[0],a[1]*a[2]]:4===a.length&&a[0]*a[1]*a[2]<=i&&a[3]<=i?[a[0]*a[1]*a[2],a[3]]:4===a.length&&a[0]<=i&&a[1]*a[2]*a[3]<=i?[a[0],a[1]*a[2]*a[3]]:n?c(s/4).map((t=>2*t)):c(s)}},e.squeezeShape=o,e.parseAxisParam=a,e.isInt=s,e.sizeFromShape=u,e.getRowsCols=function(t){if(0===t.length)throw Error(\"Cannot get rows and columns of an empty shape array.\");return[t.length>1?t[t.length-2]:1,t[t.length-1]]},e.sizeToSquarishShape=c,e.getBatchDim=function(t,e=2){return u(t.slice(0,t.length-e))}},4057:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.createTextureLayoutFromShape=e.calculateTextureWidthAndHeight=e.createTextureLayoutFromTextureType=void 0;const r=n(2517),i=n(2039);e.createTextureLayoutFromTextureType=(t,n,r)=>{const o=r===i.TextureType.unpacked||r===i.TextureType.unpackedReversed?1:4,a=r===i.TextureType.packed,s=r===i.TextureType.unpackedReversed||r===i.TextureType.packed,u=r===i.TextureType.packedLastDimension?n.length-1:void 0,c=r===i.TextureType.packedLastDimension?n.map(((t,e)=>e===n.length-1?4*t:t)):void 0;return(0,e.createTextureLayoutFromShape)(t,n,o,c,{isPacked:a,reverseWH:s,breakAxis:u})},e.calculateTextureWidthAndHeight=(t,n,r)=>{const i=(0,e.createTextureLayoutFromTextureType)(t,n,r);return[i.width,i.height]},e.createTextureLayoutFromShape=(t,e,n=1,i,o)=>{const a=!(!o||!o.isPacked),[s,u]=t.computeTextureWH(a&&i||e,o),c=e.length;let l=e.slice(0);if(0===c&&(l=[1]),1===n)i=e;else if(a){if(4!==n)throw new Error(\"a packed texture must be 4-channel\");i=e,c>0&&(l[c-1]=Math.ceil(l[c-1]/2)),c>1&&(l[c-2]=Math.ceil(l[c-2]/2))}else if(!i)throw new Error(\"Unpacked shape is needed when using channels > 1\");return{width:s,height:u,channels:n,isPacked:a,shape:l,strides:r.ShapeUtil.computeStrides(l),unpackedShape:i,reversedWH:o&&o.reverseWH}}},5702:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.TextureManager=void 0;const r=n(6231);e.TextureManager=class{constructor(t,e,n,r){this.glContext=t,this.layoutStrategy=e,this.profiler=n,this.config=r,this.pendingRead=new Map,r.reuseTextures&&(this.inUseTextures=new Map,this.idleTextures=new Map,this.textureLookup=new Map)}createTextureFromLayout(t,e,n,i){const o=this.toEncoderType(t),a=this.glContext.getEncoder(o,e.channels||1,i);if(e.isPacked&&1===i)throw new Error(\"not implemented\");const s=e.width,u=e.height;let c,l;if(this.config.reuseTextures){c=`${s}x${u}_${a.format}_${a.internalFormat}_${a.textureType}`,l=this.inUseTextures.get(c),l||(l=[],this.inUseTextures.set(c,l));const e=this.idleTextures.get(c);if(e&&e.length>0){const r=e.pop();return l.push(r),1===i&&this.glContext.updateTexture(r,s,u,a,this.toTextureData(t,n)),r}}r.Logger.verbose(\"TextureManager\",`Creating new texture of size ${e.width}x${e.height}`);const p=this.glContext.allocateTexture(s,u,a,this.toTextureData(t,n));return this.config.reuseTextures&&(l.push(p),this.textureLookup.set(p,c)),p}readTexture(t,e,n){return n||(n=1),this.profiler.event(\"backend\",\"TextureManager.readTexture\",(()=>{const r=t.shape.reduce(((t,e)=>t*e))*n,i=this.glContext.readTexture(t.texture,t.width,t.height,r,this.toEncoderType(e),n);return this.toTensorData(e,i)}))}async readTextureAsync(t,e,n){const r=t.tensor.dataId;if(n||(n=1),this.pendingRead.has(r)){const t=this.pendingRead.get(r);return new Promise((e=>null==t?void 0:t.push(e)))}return this.profiler.event(\"backend\",\"TextureManager.readTextureAsync\",(async()=>{this.pendingRead.set(r,[]);const i=t.shape.reduce(((t,e)=>t*e))*n;await this.glContext.createAndWaitForFence();const o=this.glContext.readTexture(t.texture,t.width,t.height,i,this.toEncoderType(e),n),a=this.toTensorData(e,o),s=this.pendingRead.get(r);return this.pendingRead.delete(r),null==s||s.forEach((t=>t(a))),a}))}readUint8TextureAsFloat(t){return this.profiler.event(\"backend\",\"TextureManager.readUint8TextureAsFloat\",(()=>{const e=t.shape.reduce(((t,e)=>t*e)),n=this.glContext.readTexture(t.texture,t.width,t.height,4*e,\"byte\",4);return new Float32Array(n.buffer,n.byteOffset,e)}))}releaseTexture(t,e){let n;if(this.config.reuseTextures&&(n=this.textureLookup.get(t.texture),n)){e&&this.textureLookup.delete(n);const r=this.inUseTextures.get(n);if(r){const e=r.indexOf(t.texture);if(-1!==e){r.splice(e,1);let i=this.idleTextures.get(n);i||(i=[],this.idleTextures.set(n,i)),i.push(t.texture)}}}n&&!e||(r.Logger.verbose(\"TextureManager\",`Deleting texture of size ${t.width}x${t.height}`),this.glContext.deleteTexture(t.texture))}toTensorData(t,e){switch(t){case\"int16\":return e instanceof Int16Array?e:Int16Array.from(e);case\"int32\":return e instanceof Int32Array?e:Int32Array.from(e);case\"int8\":return e instanceof Int8Array?e:Int8Array.from(e);case\"uint16\":return e instanceof Uint16Array?e:Uint16Array.from(e);case\"uint32\":return e instanceof Uint32Array?e:Uint32Array.from(e);case\"uint8\":case\"bool\":return e instanceof Uint8Array?e:Uint8Array.from(e);case\"float32\":return e instanceof Float32Array?e:Float32Array.from(e);case\"float64\":return e instanceof Float64Array?e:Float64Array.from(e);default:throw new Error(`TensorData type ${t} is not supported`)}}toTextureData(t,e){if(e)return e instanceof Float32Array?e:new Float32Array(e)}toEncoderType(t){return\"float\"}clearActiveTextures(){this.glContext.clearActiveTextures()}}},2039:(t,e)=>{\"use strict\";var n;Object.defineProperty(e,\"__esModule\",{value:!0}),e.TextureType=void 0,(n=e.TextureType||(e.TextureType={}))[n.unpacked=0]=\"unpacked\",n[n.unpackedReversed=1]=\"unpackedReversed\",n[n.packed=2]=\"packed\",n[n.downloadUint8AsFloat=3]=\"downloadUint8AsFloat\",n[n.packedLastDimension=4]=\"packedLastDimension\"},9390:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.getGlChannels=e.getCoordsDataType=e.getSqueezedParams=e.squeezeInputShape=e.generateShaderFuncNameFromInputSamplerNameAtOutCoords=e.generateShaderFuncNameFromInputSamplerName=e.repeatedTry=e.getPackedShape=void 0;const r=n(2517);e.getPackedShape=function(t){const e=t.length;return t.slice(0,e-1).concat(t[e-1]/4)},e.repeatedTry=async function(t,e=(t=>0),n){return new Promise(((r,i)=>{let o=0;const a=()=>{if(t())return void r();o++;const s=e(o);null!=n&&o>=n?i():setTimeout(a,s)};a()}))},e.generateShaderFuncNameFromInputSamplerName=function(t){return(0,r.assert)(void 0!==t&&0!==t.length,(()=>\"empty string found for sampler name\")),\"get\"+t.charAt(0).toUpperCase()+t.slice(1)},e.generateShaderFuncNameFromInputSamplerNameAtOutCoords=function(t){return(0,r.assert)(void 0!==t&&0!==t.length,(()=>\"empty string found for sampler name\")),\"get\"+t.charAt(0).toUpperCase()+t.slice(1)+\"AtOutCoords\"},e.squeezeInputShape=function(t,e){let n=JSON.parse(JSON.stringify(t));return n=e,n},e.getSqueezedParams=function(t,e){return e.map((e=>t[e])).join(\", \")},e.getCoordsDataType=function(t){if(t<=1)return\"int\";if(2===t)return\"ivec2\";if(3===t)return\"ivec3\";if(4===t)return\"ivec4\";if(5===t)return\"ivec5\";if(6===t)return\"ivec6\";throw Error(`GPU for rank ${t} is not yet supported`)},e.getGlChannels=function(t=6){return[\"x\",\"y\",\"z\",\"w\",\"u\",\"v\"].slice(0,t)}},7305:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.createNewWebGLContext=e.createWebGLContext=void 0;const r=n(6231),i=n(1713),o={};function a(t){const e=function(){if(\"undefined\"==typeof document){if(\"undefined\"==typeof OffscreenCanvas)throw new TypeError(\"failed to create canvas: OffscreenCanvas is not supported\");return new OffscreenCanvas(1,1)}const t=document.createElement(\"canvas\");return t.width=1,t.height=1,t}();let n;const o={alpha:!1,depth:!1,antialias:!1,stencil:!1,preserveDrawingBuffer:!1,premultipliedAlpha:!1,failIfMajorPerformanceCaveat:!1};if((!t||\"webgl2\"===t)&&(n=e.getContext(\"webgl2\",o),n))try{return new i.WebGLContext(n,2)}catch(t){r.Logger.warning(\"GlContextFactory\",`failed to create WebGLContext using contextId 'webgl2'. Error: ${t}`)}if((!t||\"webgl\"===t)&&(n=e.getContext(\"webgl\",o)||e.getContext(\"experimental-webgl\",o),n))try{return new i.WebGLContext(n,1)}catch(t){r.Logger.warning(\"GlContextFactory\",`failed to create WebGLContext using contextId 'webgl' or 'experimental-webgl'. Error: ${t}`)}throw new Error(\"WebGL is not supported\")}e.createWebGLContext=function t(e){let n;e&&\"webgl2\"!==e||!(\"webgl2\"in o)?e&&\"webgl\"!==e||!(\"webgl\"in o)||(n=o.webgl):n=o.webgl2,n=n||a(e),e=e||1===n.version?\"webgl\":\"webgl2\";const r=n.gl;return o[e]=n,r.isContextLost()?(delete o[e],t(e)):(r.disable(r.DEPTH_TEST),r.disable(r.STENCIL_TEST),r.disable(r.BLEND),r.disable(r.DITHER),r.disable(r.POLYGON_OFFSET_FILL),r.disable(r.SAMPLE_COVERAGE),r.enable(r.SCISSOR_TEST),r.enable(r.CULL_FACE),r.cullFace(r.BACK),n)},e.createNewWebGLContext=a},1713:function(t,e,n){\"use strict\";var r=this&&this.__createBinding||(Object.create?function(t,e,n,r){void 0===r&&(r=n);var i=Object.getOwnPropertyDescriptor(e,n);i&&!(\"get\"in i?!e.__esModule:i.writable||i.configurable)||(i={enumerable:!0,get:function(){return e[n]}}),Object.defineProperty(t,r,i)}:function(t,e,n,r){void 0===r&&(r=n),t[r]=e[n]}),i=this&&this.__setModuleDefault||(Object.create?function(t,e){Object.defineProperty(t,\"default\",{enumerable:!0,value:e})}:function(t,e){t.default=e}),o=this&&this.__importStar||function(t){if(t&&t.__esModule)return t;var e={};if(null!=t)for(var n in t)\"default\"!==n&&Object.prototype.hasOwnProperty.call(t,n)&&r(e,t,n);return i(e,t),e};Object.defineProperty(e,\"__esModule\",{value:!0}),e.WebGLContext=e.linearSearchLastTrue=void 0;const a=n(1670),s=o(n(7769)),u=n(9390);function c(t){let e=0;for(;e<t.length&&t[e]();++e);return e-1}e.linearSearchLastTrue=c,e.WebGLContext=class{constructor(t,e){this.frameBufferBound=!1,this.itemsToPoll=[],this.gl=t,this.version=e,this.getExtensions(),this.vertexbuffer=this.createVertexbuffer(),this.framebuffer=this.createFramebuffer(),this.queryVitalParameters()}allocateTexture(t,e,n,r){const i=this.gl,o=i.createTexture();i.bindTexture(i.TEXTURE_2D,o),i.texParameteri(i.TEXTURE_2D,i.TEXTURE_MIN_FILTER,i.NEAREST),i.texParameteri(i.TEXTURE_2D,i.TEXTURE_MAG_FILTER,i.NEAREST),i.texParameteri(i.TEXTURE_2D,i.TEXTURE_WRAP_S,i.CLAMP_TO_EDGE),i.texParameteri(i.TEXTURE_2D,i.TEXTURE_WRAP_T,i.CLAMP_TO_EDGE);const a=r?n.encode(r,t*e):null;return i.texImage2D(i.TEXTURE_2D,0,n.internalFormat,t,e,0,n.format,n.textureType,a),this.checkError(),o}updateTexture(t,e,n,r,i){const o=this.gl;o.bindTexture(o.TEXTURE_2D,t);const a=r.encode(i,e*n);o.texSubImage2D(o.TEXTURE_2D,0,0,0,e,n,r.format,r.textureType,a),this.checkError()}attachFramebuffer(t,e,n){const r=this.gl;r.bindTexture(r.TEXTURE_2D,t),r.bindFramebuffer(r.FRAMEBUFFER,this.framebuffer),r.framebufferTexture2D(r.FRAMEBUFFER,r.COLOR_ATTACHMENT0,r.TEXTURE_2D,t,0),this.checkError(),r.viewport(0,0,e,n),r.scissor(0,0,e,n)}readTexture(t,e,n,r,i,o){const a=this.gl;o||(o=1),this.frameBufferBound||this.attachFramebuffer(t,e,n);const s=this.getEncoder(i,o),u=s.allocate(e*n);return a.bindTexture(a.TEXTURE_2D,t),a.framebufferTexture2D(a.FRAMEBUFFER,a.COLOR_ATTACHMENT0,a.TEXTURE_2D,t,0),a.readPixels(0,0,e,n,a.RGBA,s.textureType,u),this.checkError(),s.decode(u,r)}isFramebufferReady(){return!0}getActiveTexture(){const t=this.gl;return\"TEXTURE\"+(t.getParameter(this.gl.ACTIVE_TEXTURE)-t.TEXTURE0)}getTextureBinding(){return this.gl.getParameter(this.gl.TEXTURE_BINDING_2D)}getFramebufferBinding(){return this.gl.getParameter(this.gl.FRAMEBUFFER_BINDING)}setVertexAttributes(t,e){const n=this.gl;n.vertexAttribPointer(t,3,n.FLOAT,!1,20,0),n.enableVertexAttribArray(t),-1!==e&&(n.vertexAttribPointer(e,2,n.FLOAT,!1,20,12),n.enableVertexAttribArray(e)),this.checkError()}createProgram(t,e){const n=this.gl,r=n.createProgram();return n.attachShader(r,t),n.attachShader(r,e),n.linkProgram(r),r}compileShader(t,e){const n=this.gl,r=n.createShader(e);if(!r)throw new Error(`createShader() returned null with type ${e}`);if(n.shaderSource(r,t),n.compileShader(r),!1===n.getShaderParameter(r,n.COMPILE_STATUS))throw new Error(`Failed to compile shader: ${n.getShaderInfoLog(r)}\\nShader source:\\n${t}`);return r}deleteShader(t){this.gl.deleteShader(t)}bindTextureToUniform(t,e,n){const r=this.gl;r.activeTexture(r.TEXTURE0+e),this.checkError(),r.bindTexture(r.TEXTURE_2D,t),this.checkError(),r.uniform1i(n,e),this.checkError()}draw(){this.gl.drawArrays(this.gl.TRIANGLE_STRIP,0,4),this.checkError()}checkError(){if(a.env.debug){const t=this.gl,e=t.getError();let n=\"\";switch(e){case t.NO_ERROR:return;case t.INVALID_ENUM:n=\"INVALID_ENUM\";break;case t.INVALID_VALUE:n=\"INVALID_VALUE\";break;case t.INVALID_OPERATION:n=\"INVALID_OPERATION\";break;case t.INVALID_FRAMEBUFFER_OPERATION:n=\"INVALID_FRAMEBUFFER_OPERATION\";break;case t.OUT_OF_MEMORY:n=\"OUT_OF_MEMORY\";break;case t.CONTEXT_LOST_WEBGL:n=\"CONTEXT_LOST_WEBGL\";break;default:n=`Unknown WebGL Error: ${e.toString(16)}`}throw new Error(n)}}deleteTexture(t){this.gl.deleteTexture(t)}deleteProgram(t){this.gl.deleteProgram(t)}getEncoder(t,e,n=0){if(2===this.version)return new s.RedFloat32DataEncoder(this.gl,e);switch(t){case\"float\":return 1===n||this.isRenderFloat32Supported?new s.RGBAFloatDataEncoder(this.gl,e):new s.RGBAFloatDataEncoder(this.gl,e,this.textureHalfFloatExtension.HALF_FLOAT_OES);case\"int\":throw new Error(\"not implemented\");case\"byte\":return new s.Uint8DataEncoder(this.gl,e);default:throw new Error(`Invalid dataType: ${t}`)}}clearActiveTextures(){const t=this.gl;for(let e=0;e<this.maxTextureImageUnits;++e)t.activeTexture(t.TEXTURE0+e),t.bindTexture(t.TEXTURE_2D,null)}dispose(){if(this.disposed)return;const t=this.gl;t.bindFramebuffer(t.FRAMEBUFFER,null),t.deleteFramebuffer(this.framebuffer),t.bindBuffer(t.ARRAY_BUFFER,null),t.deleteBuffer(this.vertexbuffer),t.bindBuffer(t.ELEMENT_ARRAY_BUFFER,null),t.finish(),this.disposed=!0}createDefaultGeometry(){return new Float32Array([-1,1,0,0,1,-1,-1,0,0,0,1,1,0,1,1,1,-1,0,1,0])}createVertexbuffer(){const t=this.gl,e=t.createBuffer();if(!e)throw new Error(\"createBuffer() returned null\");const n=this.createDefaultGeometry();return t.bindBuffer(t.ARRAY_BUFFER,e),t.bufferData(t.ARRAY_BUFFER,n,t.STATIC_DRAW),this.checkError(),e}createFramebuffer(){const t=this.gl.createFramebuffer();if(!t)throw new Error(\"createFramebuffer returned null\");return t}queryVitalParameters(){const t=this.gl;if(this.isFloatTextureAttachableToFrameBuffer=this.checkFloatTextureAttachableToFrameBuffer(),this.isRenderFloat32Supported=this.checkRenderFloat32(),this.isFloat32DownloadSupported=this.checkFloat32Download(),1===this.version&&!this.textureHalfFloatExtension&&!this.isRenderFloat32Supported)throw new Error(\"both float32 and float16 TextureType are not supported\");this.isBlendSupported=!this.isRenderFloat32Supported||this.checkFloat32Blend(),this.maxTextureSize=t.getParameter(t.MAX_TEXTURE_SIZE),this.maxTextureImageUnits=t.getParameter(t.MAX_TEXTURE_IMAGE_UNITS),this.version}getExtensions(){2===this.version?(this.colorBufferFloatExtension=this.gl.getExtension(\"EXT_color_buffer_float\"),this.disjointTimerQueryWebgl2Extension=this.gl.getExtension(\"EXT_disjoint_timer_query_webgl2\")):(this.textureFloatExtension=this.gl.getExtension(\"OES_texture_float\"),this.textureHalfFloatExtension=this.gl.getExtension(\"OES_texture_half_float\"))}checkFloatTextureAttachableToFrameBuffer(){const t=this.gl,e=t.createTexture();t.bindTexture(t.TEXTURE_2D,e);const n=2===this.version?t.RGBA32F:t.RGBA;t.texImage2D(t.TEXTURE_2D,0,n,1,1,0,t.RGBA,t.FLOAT,null);const r=t.createFramebuffer();t.bindFramebuffer(t.FRAMEBUFFER,r),t.framebufferTexture2D(t.FRAMEBUFFER,t.COLOR_ATTACHMENT0,t.TEXTURE_2D,e,0);const i=t.checkFramebufferStatus(t.FRAMEBUFFER)===t.FRAMEBUFFER_COMPLETE;return t.bindTexture(t.TEXTURE_2D,null),t.bindFramebuffer(t.FRAMEBUFFER,null),t.deleteTexture(e),t.deleteFramebuffer(r),i}checkRenderFloat32(){if(2===this.version){if(!this.colorBufferFloatExtension)return!1}else if(!this.textureFloatExtension)return!1;return this.isFloatTextureAttachableToFrameBuffer}checkFloat32Download(){if(2===this.version){if(!this.colorBufferFloatExtension)return!1}else{if(!this.textureFloatExtension)return!1;if(!this.gl.getExtension(\"WEBGL_color_buffer_float\"))return!1}return this.isFloatTextureAttachableToFrameBuffer}checkFloat32Blend(){const t=this.gl;let e,n,r,i,o;try{e=t.createTexture(),n=t.createFramebuffer(),t.bindTexture(t.TEXTURE_2D,e);const a=2===this.version?t.RGBA32F:t.RGBA;return t.texImage2D(t.TEXTURE_2D,0,a,1,1,0,t.RGBA,t.FLOAT,null),t.bindFramebuffer(t.FRAMEBUFFER,n),t.framebufferTexture2D(t.FRAMEBUFFER,t.COLOR_ATTACHMENT0,t.TEXTURE_2D,e,0),t.enable(t.BLEND),r=t.createShader(t.VERTEX_SHADER),!!r&&(t.shaderSource(r,\"void main(){}\"),t.compileShader(r),i=t.createShader(t.FRAGMENT_SHADER),!!i&&(t.shaderSource(i,\"precision highp float;void main(){gl_FragColor=vec4(0.5);}\"),t.compileShader(i),o=t.createProgram(),!!o&&(t.attachShader(o,r),t.attachShader(o,i),t.linkProgram(o),t.useProgram(o),t.drawArrays(t.POINTS,0,1),t.getError()===t.NO_ERROR)))}finally{t.disable(t.BLEND),o&&t.deleteProgram(o),r&&t.deleteShader(r),i&&t.deleteShader(i),n&&(t.bindFramebuffer(t.FRAMEBUFFER,null),t.deleteFramebuffer(n)),e&&(t.bindTexture(t.TEXTURE_2D,null),t.deleteTexture(e))}}beginTimer(){if(2===this.version&&this.disjointTimerQueryWebgl2Extension){const t=this.gl,e=this.disjointTimerQueryWebgl2Extension,n=t.createQuery();return t.beginQuery(e.TIME_ELAPSED_EXT,n),n}throw new Error(\"WebGL1 profiling currently not supported.\")}endTimer(){if(2!==this.version||!this.disjointTimerQueryWebgl2Extension)throw new Error(\"WebGL1 profiling currently not supported\");{const t=this.gl,e=this.disjointTimerQueryWebgl2Extension;t.endQuery(e.TIME_ELAPSED_EXT)}}isTimerResultAvailable(t){let e=!1,n=!1;if(2!==this.version||!this.disjointTimerQueryWebgl2Extension)throw new Error(\"WebGL1 profiling currently not supported\");{const r=this.gl,i=this.disjointTimerQueryWebgl2Extension;e=r.getQueryParameter(t,r.QUERY_RESULT_AVAILABLE),n=r.getParameter(i.GPU_DISJOINT_EXT)}return e&&!n}getTimerResult(t){let e=0;if(2!==this.version)throw new Error(\"WebGL1 profiling currently not supported\");{const n=this.gl;e=n.getQueryParameter(t,n.QUERY_RESULT),n.deleteQuery(t)}return e/1e6}async waitForQueryAndGetTime(t){return await(0,u.repeatedTry)((()=>this.isTimerResultAvailable(t))),this.getTimerResult(t)}async createAndWaitForFence(){const t=this.createFence(this.gl);return this.pollFence(t)}createFence(t){let e;const n=t,r=n.fenceSync(n.SYNC_GPU_COMMANDS_COMPLETE,0);return t.flush(),e=null===r?()=>!0:()=>{const t=n.clientWaitSync(r,0,0);return t===n.ALREADY_SIGNALED||t===n.CONDITION_SATISFIED},{query:r,isFencePassed:e}}async pollFence(t){return new Promise((e=>{this.addItemToPoll((()=>t.isFencePassed()),(()=>e()))}))}pollItems(){const t=c(this.itemsToPoll.map((t=>t.isDoneFn)));for(let e=0;e<=t;++e){const{resolveFn:t}=this.itemsToPoll[e];t()}this.itemsToPoll=this.itemsToPoll.slice(t+1)}async addItemToPoll(t,e){this.itemsToPoll.push({isDoneFn:t,resolveFn:e}),this.itemsToPoll.length>1||await(0,u.repeatedTry)((()=>(this.pollItems(),0===this.itemsToPoll.length)))}}},1036:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.ExecutionPlan=void 0;const r=n(6231);class i{constructor(t,e){this.op=t,this.node=e}}e.ExecutionPlan=class{constructor(t,e,n){this.graph=t,this.profiler=n,this.initialize(e)}initialize(t){this.profiler.event(\"session\",\"ExecutionPlan.initialize\",(()=>{const e=this.graph.getNodes();if(e.length!==t.length)throw new Error(\"The size of nodes and OPs do not match.\");this._ops=t.map(((t,n)=>new i(t,e[n]))),this.reset(),this._starter=[],this._ops.forEach(((t,e)=>{let n=!0;for(const e of t.node.inputs)if(!this._values[e]&&-1===this.graph.getInputIndices().indexOf(e)){n=!1;break}n&&this._starter.push(e)}))}))}reset(){this._values=this.graph.getValues().map((t=>t.tensor))}async execute(t,e){return this.profiler.event(\"session\",\"ExecutionPlan.execute\",(async()=>{this.reset();const n=t.createInferenceHandler(),i=this.graph.getInputIndices();if(e.length!==i.length)throw new Error(`number of input tensors don't match the number of inputs to the model: actual: ${e.length} expected: ${i.length}`);e.forEach(((t,e)=>{const n=i[e];this._values[n]=t}));const o=this._starter.slice(0),a=this.graph.getValues(),s=this.graph.getNodes();let u=0;for(;u<o.length;){const t=o[u++],e=this._ops[t],i=e.node.inputs.map((t=>this._values[t]));if(-1!==i.indexOf(void 0))throw new Error(`unresolved input detected: op: ${e.node}`);const c=i;r.Logger.verbose(\"ExecPlan\",`Runing op:${e.node.name} (${c.map(((t,n)=>`'${e.node.inputs[n]}': ${t.type}[${t.dims.join(\",\")}]`)).join(\", \")})`);const l=await this.profiler.event(\"node\",e.node.name,(async()=>e.op.impl(n,c,e.op.context)));if(l.length!==e.node.outputs.length)throw new Error(\"the size of output does not match model definition.\");l.forEach(((t,n)=>{const r=e.node.outputs[n];if(this._values[r])throw new Error(`output [${r}] already has value: op:${e.node.name}`);this._values[r]=t}));const p=new Set;l.forEach(((t,n)=>{const r=e.node.outputs[n];for(const t of a[r].to){const e=s[t];let n=!0;for(const t of e.inputs)if(!this._values[t]){n=!1;break}n&&p.add(t)}})),o.push(...p)}const c=[];for(let t=0;t<this.graph.getOutputIndices().length;t++){const e=this.graph.getOutputIndices()[t],n=this._values[e];if(void 0===n)throw new Error(`required output [${e}] does not have value`);0===e?await n.getData():n.data,c.push(n)}return r.Logger.verbose(\"ExecPlan\",\"disposing of inferenceHandler\"),n.dispose(),c}))}}},7070:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.Graph=void 0;const r=n(1446),i=n(7778),o=n(9395),a=n(9162),s=n(2517);var u=o.onnxruntime.experimental.fbs;e.Graph={from:(t,e)=>new p(t,e)};class c{constructor(t){this._from=void 0,this._to=[],this.tensor=void 0,this.type=void 0,t&&(this.type=s.ProtoUtil.tensorValueTypeFromProto(t.type.tensorType))}get from(){return this._from}get to(){return this._to}}class l{constructor(t,e){t instanceof r.onnx.NodeProto?(this.name=t.name,this.opType=t.opType,this.attributes=new i.Attribute(t.attribute)):t instanceof u.Node&&(this.name=null!=e?e:t.name(),this.opType=t.opType(),this.attributes=new i.Attribute(s.ProtoUtil.tensorAttributesFromORTFormat(t))),this.inputs=[],this.outputs=[],this.executeNode=!0}}class p{constructor(t,e){if(!t)throw new TypeError(\"graph is empty\");this.buildGraph(t),this.transformGraph(e),this.checkIsAcyclic()}getInputIndices(){return this._allInputIndices}getInputNames(){return this._allInputNames}getOutputIndices(){return this._allOutputIndices}getOutputNames(){return this._allOutputNames}getValues(){return this._allData}getNodes(){return this._nodes}buildGraph(t){if(t instanceof r.onnx.GraphProto)this.buildGraphFromOnnxFormat(t);else{if(!(t instanceof u.Graph))throw new TypeError(\"Graph type is not supported.\");this.buildGraphFromOrtFormat(t)}}buildGraphFromOnnxFormat(t){const e=new Map;this._allData=[],this._allInputIndices=[],this._allInputNames=[],this._allOutputIndices=[],this._allOutputNames=[],this._nodes=[];const n=new Map;if(!t.input)throw new Error(\"missing information in graph: input\");const r=[];for(const n of t.input){if(e.has(n.name))throw new Error(`duplicated input name: ${n.name}`);const t=this._allData.push(new c(n))-1;e.set(n.name,t),r.push(n.name)}if(!t.initializer)throw new Error(\"missing information in graph: initializer\");for(const n of t.initializer){let t=e.get(n.name);if(void 0===t){const r=new c;r.type={shape:{dims:s.ProtoUtil.tensorDimsFromProto(n.dims)},tensorType:s.ProtoUtil.tensorDataTypeFromProto(n.dataType)},t=this._allData.push(r)-1,e.set(n.name,t)}this._allData[t]._from=-1,this._allData[t].tensor=a.Tensor.fromProto(n)}for(let t=0;t<this._allData.length;t++)this._allData[t].tensor||(this._allInputIndices.push(t),this._allInputNames.push(r[t]));if(!t.output)throw new Error(\"missing information in graph: output\");for(const n of t.output){if(e.has(n.name))throw new Error(`duplicated output name: ${n.name}`);const t=this._allData.push(new c(n))-1;e.set(n.name,t),this._allOutputIndices.push(t),this._allOutputNames.push(n.name)}if(!t.node)throw new Error(\"missing information in graph: node\");for(const e of t.node){if(!e.name)for(let t=0;;t++){const r=`unnamed_${e.opType}_${t}`;if(!n.has(r)){e.name=r;break}}if(n.has(e.name))throw new Error(`duplicated node name: ${e.name}`);const t=this._nodes.push(new l(e))-1;n.set(e.name,t)}for(let n=0;n<this._nodes.length;n++){const r=this._nodes[n],i=t.node[n];if(!i.output)throw new Error(`missing output for node: ${i.name}`);for(const t of i.output){let o=e.get(t);if(void 0===o&&(o=this._allData.push(new c)-1,e.set(t,o)),r.outputs.push(o),void 0!==this._allData[o]._from)throw new Error(`multiple nodes output to one data value: ${o}`);if(this._allData[o]._from=n,\"Constant\"===i.opType){if(!i.attribute||1!==i.attribute.length||!i.attribute[0].t)throw new Error(\"missing attributes or missing tensor value in attributes for this Constant operator\");if(!i.output||1!==i.output.length)throw new Error(\"missing output or incorrect number of outputs for this Constant operator\");r.outputs.pop(),r.executeNode=!1,this._allData[o]._from=-1,this._allData[o].tensor=a.Tensor.fromProto(i.attribute[0].t)}}}for(let n=0;n<this._nodes.length;n++){const r=this._nodes[n],i=t.node[n];if(!i.input)throw new Error(`missing input for node: ${i.name}`);for(const t of i.input){const o=e.get(t);if(void 0===o){if(\"\"===t&&3===i.input.length&&\"Resize\"===i.opType)continue;throw new Error(`unrecognized input '${t}' for node: ${i.name}`)}r.inputs.push(o),this._allData[o]._to.push(n)}}return!0}buildGraphFromOrtFormat(t){var e,n,r;const i=new Map;this._allData=[],this._allInputIndices=[],this._allInputNames=[],this._allOutputIndices=[],this._allOutputNames=[],this._nodes=[];const o=new Map,p=[];for(let o=0;o<t.inputsLength();o++){const a=t.inputs(o);if(i.has(a))throw new Error(`duplicated input name: ${a}`);for(let o=0;o<t.nodeArgsLength();o++)if((null===(e=t.nodeArgs(o))||void 0===e?void 0:e.name())===a){const e=new c;if((null===(r=null===(n=t.nodeArgs(o))||void 0===n?void 0:n.type())||void 0===r?void 0:r.valueType())!==u.TypeInfoValue.tensor_type)throw new Error(\"Unexpected value type for the nodeArg.\");const l=t.nodeArgs(o).type().value(new u.TensorTypeAndShape),f=s.ProtoUtil.tensorDataTypeFromProto(l.elemType()),d=l.shape(),h=[];for(let t=0;t<d.dimLength();t++)h.push(s.LongUtil.longToNumber(d.dim(t).value().dimValue()));e.type={shape:{dims:h},tensorType:f};const g=this._allData.push(e)-1;i.set(a,g),p.push(a)}}for(let e=0;e<t.initializersLength();e++){const n=t.initializers(e);let r=i.get(n.name());if(void 0===r){const t=new c,e=s.ProtoUtil.tensorDimsFromORTFormat(n),o=s.ProtoUtil.tensorDataTypeFromProto(n.dataType());t.type={shape:{dims:e},tensorType:o},r=this._allData.push(t)-1,i.set(n.name(),r)}this._allData[r]._from=-1,this._allData[r].tensor=a.Tensor.fromOrtTensor(n)}for(let t=0;t<this._allData.length;t++)this._allData[t].tensor||(this._allInputIndices.push(t),this._allInputNames.push(p[t]));for(let e=0;e<t.outputsLength();e++){const n=t.outputs(e);if(i.has(n))throw new Error(`duplicated output name: ${n}`);const r=this._allData.push(new c)-1;i.set(n,r),this._allOutputIndices.push(r),this._allOutputNames.push(n)}if(!t.nodes)throw new Error(\"missing information in graph: node\");for(let e=0;e<t.nodesLength();e++){const n=t.nodes(e);let r=n.name();if(!r)for(let t=0;r=`unnamed_${n.opType()}_${t}`,o.has(r);t++);if(o.has(r))throw new Error(`duplicated node name: ${r}`);const i=this._nodes.push(new l(n,r))-1;o.set(r,i)}for(let e=0;e<this._nodes.length;e++){const n=this._nodes[e],r=t.nodes(e);if(null==r)throw new Error(`No node exists at index ${e}`);if(0===(null==r?void 0:r.outputsLength()))throw new Error(`missing output for node: ${r.name}`);for(let t=0;t<(null==r?void 0:r.outputsLength());t++){const o=null==r?void 0:r.outputs(t);let s=i.get(o);if(void 0===s&&(s=this._allData.push(new c)-1,i.set(o,s)),n.outputs.push(s),void 0!==this._allData[s]._from)throw new Error(`multiple nodes output to one data value: ${s}`);if(this._allData[s]._from=e,\"Constant\"===r.opType()){if(1!==r.attributesLength()||!r.attributes(0).t())throw new Error(\"missing attributes or missing tensor value in attributes for this Constant operator\");if(1!==r.outputsLength())throw new Error(\"missing output or incorrect number of outputs for this Constant operator\");n.outputs.pop(),n.executeNode=!1,this._allData[s]._from=-1,this._allData[s].tensor=a.Tensor.fromOrtTensor(r.attributes(0).t())}}}for(let e=0;e<this._nodes.length;e++){const n=this._nodes[e],r=t.nodes(e);if(0===r.inputsLength())throw new Error(`missing input for node: ${r.name}`);for(let t=0;t<r.inputsLength();t++){const o=r.inputs(t),a=i.get(o);if(void 0===a)throw new Error(`unrecognized input '${o}' for node: ${r.name()}`);n.inputs.push(a),this._allData[a]._to.push(e)}}}checkIsAcyclic(){const t=new Set;this._allInputIndices.forEach((e=>{this._allData[e]._to.forEach((e=>{t.add(e)}))}));const e=Array.from(t),n=new Array(this._nodes.length).fill(\"white\");for(;e.length>0;){const t=e.pop();\"gray\"===n[t]?n[t]=\"black\":(e.push(t),n[t]=\"gray\",this._nodes[t].outputs.forEach((r=>{const i=this._allData[r];if(void 0!==i.tensor)throw new Error(\"node outputs should not be initialized\");if(i._from!==t)throw new Error(\"from property of the Value object doesn't match index of Node being processed\");i._to.forEach((t=>{if(\"gray\"===n[t])throw new Error(\"model graph is cyclic\");\"white\"===n[t]&&e.push(t)}))})))}}transformGraph(t){this.removeAllIdentityNodes(),this.removeAllDropoutNodes(),this.fuseConvActivationNodes(),t&&t.transformGraph(this),this.finalizeGraph()}finalizeGraph(){let t=0;for(let e=0;e<this._nodes.length;e++)this._nodes[e].executeNode?t>0&&(this._nodes[e].inputs.forEach((n=>{const r=this._allData[n]._to.indexOf(e+t);-1!==r&&(this._allData[n]._to[r]=e)})),this._nodes[e].outputs.forEach((n=>{this._allData[n]._from&&this._allData[n]._from===e+t&&(this._allData[n]._from=e)}))):(t++,this._nodes[e].outputs.forEach((t=>{this._allData[t]._from=-2})),this._nodes.splice(e,1),e--);t=0;for(let e=0;e<this._allData.length;e++)if(-2!==this._allData[e].from||-1!==this._allOutputIndices.indexOf(e+t)){if(t>0){let n=-1;void 0!==this._allData[e].from&&-1!==this._allData[e].from?(n=this._nodes[this._allData[e].from].outputs.indexOf(e+t),-1!==n&&(this._nodes[this._allData[e].from].outputs[n]=e)):(n=this._allInputIndices.indexOf(e+t),-1!==n&&(this._allInputIndices[n]=e)),this._allData[e].to.forEach((r=>{n=this._nodes[r].inputs.indexOf(e+t),-1!==n&&(this._nodes[r].inputs[n]=e)})),0===this._allData[e].to.length&&(n=this._allOutputIndices.indexOf(e+t),-1!==n&&(this._allOutputIndices[n]=e))}}else t++,this._allData.splice(e,1),e--}deleteNode(t){const e=this._nodes[t];if(e.outputs.length>1)for(let t=1;t<e.outputs.length;t++)if(this._allData[e.outputs[t]].to.length>0)throw new Error(\"Node deletion with more than one output connected to other nodes is not supported. \");e.executeNode=!1;const n=e.inputs[0],r=e.outputs[0],i=this._allData[r].to,o=this._allData[n].to.indexOf(t);if(-1===o)throw new Error(\"The Value object doesn't have the current Node in it's 'to' property \");this._allData[n].to.splice(o,1),this._allData[r]._to=[];const a=this._allOutputIndices.indexOf(r);if(-1!==a&&(this._allOutputIndices[a]=n),i&&i.length>0)for(const t of i){const e=this._nodes[t].inputs.indexOf(r);if(-1===e)throw new Error(\"The Node object doesn't have the output Value in it's 'inputs' property \");this._nodes[t].inputs[e]=n,this._allData[n].to.push(t)}}removeAllDropoutNodes(){let t=0;for(const e of this._nodes){if(\"Dropout\"===e.opType){if(1!==e.inputs.length)throw new Error(\"Dropout nodes should only contain one input. \");if(1!==e.outputs.length&&2!==e.outputs.length)throw new Error(\"Dropout nodes should contain either 1 or 2 output(s)\");if(2===e.outputs.length&&0!==this._allData[e.outputs[1]]._to.length)throw new Error(\"Dropout nodes's second output should not be referenced by other nodes\");this.deleteNode(t)}t++}}removeAllIdentityNodes(){let t=0;for(const e of this._nodes)\"Identity\"===e.opType&&this.deleteNode(t),t++}isActivation(t){switch(t.opType){case\"Relu\":case\"Sigmoid\":case\"Clip\":return!0;default:return!1}}fuseConvActivationNodes(){for(const t of this._nodes)if(\"Conv\"===t.opType){const e=this._allData[t.outputs[0]]._to;if(1===e.length&&this.isActivation(this._nodes[e[0]])){const n=this._nodes[e[0]];if(\"Clip\"===n.opType)if(1===n.inputs.length)try{t.attributes.set(\"activation_params\",\"floats\",[n.attributes.getFloat(\"min\"),n.attributes.getFloat(\"max\")])}catch(e){t.attributes.set(\"activation_params\",\"floats\",[s.MIN_CLIP,s.MAX_CLIP])}else{if(!(n.inputs.length>=3&&void 0!==this._allData[n.inputs[1]].tensor&&void 0!==this._allData[n.inputs[2]].tensor))continue;t.attributes.set(\"activation_params\",\"floats\",[this._allData[n.inputs[1]].tensor.floatData[0],this._allData[n.inputs[2]].tensor.floatData[0]])}t.attributes.set(\"activation\",\"string\",n.opType),this.deleteNode(e[0])}}}}},6231:(t,e)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.now=e.Profiler=e.Logger=void 0;const n={verbose:1e3,info:2e3,warning:4e3,error:5e3,fatal:6e3},r={none:new class{log(t,e,n){}},console:new class{log(t,e,n){console.log(`${this.color(t)} ${n?\"\u001b[35m\"+n+\"\u001b[0m \":\"\"}${e}`)}color(t){switch(t){case\"verbose\":return\"\u001b[34;40mv\u001b[0m\";case\"info\":return\"\u001b[32mi\u001b[0m\";case\"warning\":return\"\u001b[30;43mw\u001b[0m\";case\"error\":return\"\u001b[31;40me\u001b[0m\";case\"fatal\":return\"\u001b[101mf\u001b[0m\";default:throw new Error(`unsupported severity: ${t}`)}}}},i={provider:\"console\",minimalSeverity:\"warning\",logDateTime:!0,logSourceLocation:!1};let o={\"\":i};function a(t,e,n,r){if(void 0===e)return i=t,{verbose:a.verbose.bind(null,i),info:a.info.bind(null,i),warning:a.warning.bind(null,i),error:a.error.bind(null,i),fatal:a.fatal.bind(null,i)};if(void 0===n)s(t,e);else if(\"number\"==typeof n&&void 0===r)s(t,e);else if(\"string\"==typeof n&&void 0===r)s(t,n,0,e);else{if(\"string\"!=typeof n||\"number\"!=typeof r)throw new TypeError(\"input is valid\");s(t,n,0,e)}var i}function s(t,e,i,a){const s=o[a||\"\"]||o[\"\"];n[t]<n[s.minimalSeverity]||(s.logDateTime&&(e=`${(new Date).toISOString()}|${e}`),s.logSourceLocation,r[s.provider].log(t,e,a))}!function(t){function e(t){o={},n(\"\",t||{})}function n(t,n){if(\"*\"===t)e(n);else{const e=o[t]||i;o[t]={provider:n.provider||e.provider,minimalSeverity:n.minimalSeverity||e.minimalSeverity,logDateTime:void 0===n.logDateTime?e.logDateTime:n.logDateTime,logSourceLocation:void 0===n.logSourceLocation?e.logSourceLocation:n.logSourceLocation}}}t.verbose=function(e,n){t(\"verbose\",e,n)},t.info=function(e,n){t(\"info\",e,n)},t.warning=function(e,n){t(\"warning\",e,n)},t.error=function(e,n){t(\"error\",e,n)},t.fatal=function(e,n){t(\"fatal\",e,n)},t.reset=e,t.set=n,t.setWithEnv=function(t){const e={};t.logLevel&&(e.minimalSeverity=t.logLevel),n(\"\",e)}}(a||(a={})),e.Logger=a;class u{constructor(t,e,n,r,i,o){this.category=t,this.name=e,this.startTime=n,this.endCallback=r,this.timer=i,this.ctx=o}end(){return this.endCallback(this)}async checkTimer(){if(void 0===this.ctx||void 0===this.timer)throw new Error(\"No webgl timer found\");return this.ctx.endTimer(),this.ctx.waitForQueryAndGetTime(this.timer)}}class c{constructor(t,e,n,r){this.category=t,this.name=e,this.startTime=n,this.endTime=r}}e.Profiler=class{static create(t){return void 0===t?new this:new this(t.maxNumberEvents,t.flushBatchSize,t.flushIntervalInMilliseconds)}constructor(t,e,n){this._started=!1,this._flushPointer=0,this._started=!1,this._maxNumberEvents=void 0===t?1e4:t,this._flushBatchSize=void 0===e?10:e,this._flushIntervalInMilliseconds=void 0===n?5e3:n}start(){this._started=!0,this._timingEvents=[],this._flushTime=(0,e.now)(),this._flushPointer=0}stop(){for(this._started=!1;this._flushPointer<this._timingEvents.length;this._flushPointer++)this.logOneEvent(this._timingEvents[this._flushPointer])}event(t,e,n,r){const i=this._started?this.begin(t,e,r):void 0;let o=!1;const a=n();if(a&&\"function\"==typeof a.then)return o=!0,new Promise(((t,e)=>{a.then((async e=>{i&&await i.end(),t(e)}),(async t=>{i&&await i.end(),e(t)}))}));if(!o&&i){const t=i.end();if(t&&\"function\"==typeof t.then)return new Promise(((e,n)=>{t.then((()=>{e(a)}),(t=>{n(t)}))}))}return a}begin(t,n,r){if(!this._started)throw new Error(\"profiler is not started yet\");if(void 0===r){const r=(0,e.now)();return this.flush(r),new u(t,n,r,(t=>this.endSync(t)))}{const e=r.beginTimer();return new u(t,n,0,(async t=>this.end(t)),e,r)}}async end(t){const e=await t.checkTimer();this._timingEvents.length<this._maxNumberEvents&&(this._timingEvents.push(new c(t.category,t.name,t.startTime,e)),this.flush(e))}endSync(t){const n=(0,e.now)();this._timingEvents.length<this._maxNumberEvents&&(this._timingEvents.push(new c(t.category,t.name,t.startTime,n)),this.flush(n))}logOneEvent(t){e.Logger.verbose(`Profiler.${t.category}`,`${(t.endTime-t.startTime).toFixed(2)}ms on event '${t.name}' at ${t.endTime.toFixed(2)}`)}flush(t){if(this._timingEvents.length-this._flushPointer>=this._flushBatchSize||t-this._flushTime>=this._flushIntervalInMilliseconds){for(const t=this._flushPointer;this._flushPointer<t+this._flushBatchSize&&this._flushPointer<this._timingEvents.length;this._flushPointer++)this.logOneEvent(this._timingEvents[this._flushPointer]);this._flushTime=(0,e.now)()}}get started(){return this._started}},e.now=\"undefined\"!=typeof performance&&performance.now?()=>performance.now():Date.now},2644:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.Model=void 0;const r=n(5686),i=n(1446),o=n(7070),a=n(9395),s=n(2517);var u=a.onnxruntime.experimental.fbs;e.Model=class{constructor(){}load(t,e,n){if(!n)try{return void this.loadFromOnnxFormat(t,e)}catch(t){if(void 0!==n)throw t}this.loadFromOrtFormat(t,e)}loadFromOnnxFormat(t,e){const n=i.onnx.ModelProto.decode(t);if(s.LongUtil.longToNumber(n.irVersion)<3)throw new Error(\"only support ONNX model with IR_VERSION>=3\");this._opsets=n.opsetImport.map((t=>({domain:t.domain,version:s.LongUtil.longToNumber(t.version)}))),this._graph=o.Graph.from(n.graph,e)}loadFromOrtFormat(t,e){const n=new r.flatbuffers.ByteBuffer(t),i=u.InferenceSession.getRootAsInferenceSession(n).model();if(s.LongUtil.longToNumber(i.irVersion())<3)throw new Error(\"only support ONNX model with IR_VERSION>=3\");this._opsets=[];for(let t=0;t<i.opsetImportLength();t++){const e=i.opsetImport(t);this._opsets.push({domain:null==e?void 0:e.domain(),version:s.LongUtil.longToNumber(e.version())})}this._graph=o.Graph.from(i.graph(),e)}get graph(){return this._graph}get opsets(){return this._opsets}}},782:(t,e)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.FLOAT_TYPES=e.INT_TYPES=e.NUMBER_TYPES=void 0,e.NUMBER_TYPES=[\"float32\",\"float64\",\"int32\",\"int16\",\"int8\",\"uint16\",\"uint32\",\"uint8\"],e.INT_TYPES=[\"int32\",\"int16\",\"int8\",\"uint16\",\"uint32\",\"uint8\"],e.FLOAT_TYPES=[\"float32\",\"float64\"]},1047:(t,e)=>{\"use strict\";function n(t,e){if(e.endsWith(\"+\")){const n=Number.parseInt(e.substring(0,e.length-1),10);return!isNaN(n)&&n<=t}if(2===e.split(\"-\").length){const n=e.split(\"-\"),r=Number.parseInt(n[0],10),i=Number.parseInt(n[1],10);return!isNaN(r)&&!isNaN(i)&&r<=t&&t<=i}return Number.parseInt(e,10)===t}Object.defineProperty(e,\"__esModule\",{value:!0}),e.resolveOperator=void 0,e.resolveOperator=function(t,e,r){for(const i of r){const r=i[0],o=i[1],a=i[2],s=i[3],u=i[4];if(t.opType===r)for(const t of e)if((t.domain===o||\"ai.onnx\"===t.domain&&\"\"===o)&&n(t.version,a))return{opImpl:s,opInit:u}}throw new TypeError(`cannot resolve operator '${t.opType}' with opsets: ${e.map((t=>`${t.domain||\"ai.onnx\"} v${t.version}`)).join(\", \")}`)}},9395:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.onnxruntime=void 0;const r=n(5686);var i,o;i=e.onnxruntime||(e.onnxruntime={}),function(t){let e;!function(t){t[t.UNDEFINED=0]=\"UNDEFINED\",t[t.FLOAT=1]=\"FLOAT\",t[t.INT=2]=\"INT\",t[t.STRING=3]=\"STRING\",t[t.TENSOR=4]=\"TENSOR\",t[t.GRAPH=5]=\"GRAPH\",t[t.FLOATS=6]=\"FLOATS\",t[t.INTS=7]=\"INTS\",t[t.STRINGS=8]=\"STRINGS\",t[t.TENSORS=9]=\"TENSORS\",t[t.GRAPHS=10]=\"GRAPHS\",t[t.SPARSE_TENSOR=11]=\"SPARSE_TENSOR\",t[t.SPARSE_TENSORS=12]=\"SPARSE_TENSORS\"}(e=t.AttributeType||(t.AttributeType={}))}((o=i.experimental||(i.experimental={})).fbs||(o.fbs={})),function(t){!function(t){!function(t){let e;!function(t){t[t.UNKNOWN=0]=\"UNKNOWN\",t[t.VALUE=1]=\"VALUE\",t[t.PARAM=2]=\"PARAM\"}(e=t.DimensionValueType||(t.DimensionValueType={}))}(t.fbs||(t.fbs={}))}(t.experimental||(t.experimental={}))}(e.onnxruntime||(e.onnxruntime={})),function(t){!function(t){!function(t){let e;!function(t){t[t.UNDEFINED=0]=\"UNDEFINED\",t[t.FLOAT=1]=\"FLOAT\",t[t.UINT8=2]=\"UINT8\",t[t.INT8=3]=\"INT8\",t[t.UINT16=4]=\"UINT16\",t[t.INT16=5]=\"INT16\",t[t.INT32=6]=\"INT32\",t[t.INT64=7]=\"INT64\",t[t.STRING=8]=\"STRING\",t[t.BOOL=9]=\"BOOL\",t[t.FLOAT16=10]=\"FLOAT16\",t[t.DOUBLE=11]=\"DOUBLE\",t[t.UINT32=12]=\"UINT32\",t[t.UINT64=13]=\"UINT64\",t[t.COMPLEX64=14]=\"COMPLEX64\",t[t.COMPLEX128=15]=\"COMPLEX128\",t[t.BFLOAT16=16]=\"BFLOAT16\"}(e=t.TensorDataType||(t.TensorDataType={}))}(t.fbs||(t.fbs={}))}(t.experimental||(t.experimental={}))}(e.onnxruntime||(e.onnxruntime={})),function(t){!function(t){!function(t){let e;!function(t){t[t.Primitive=0]=\"Primitive\",t[t.Fused=1]=\"Fused\"}(e=t.NodeType||(t.NodeType={}))}(t.fbs||(t.fbs={}))}(t.experimental||(t.experimental={}))}(e.onnxruntime||(e.onnxruntime={})),function(t){!function(t){!function(t){let e;!function(t){t[t.NONE=0]=\"NONE\",t[t.tensor_type=1]=\"tensor_type\",t[t.sequence_type=2]=\"sequence_type\",t[t.map_type=3]=\"map_type\"}(e=t.TypeInfoValue||(t.TypeInfoValue={}))}(t.fbs||(t.fbs={}))}(t.experimental||(t.experimental={}))}(e.onnxruntime||(e.onnxruntime={})),function(t){!function(e){!function(e){class n{constructor(){this.bb=null,this.bb_pos=0}__init(t,e){return this.bb_pos=t,this.bb=e,this}static getRootAsShape(t,e){return(e||new n).__init(t.readInt32(t.position())+t.position(),t)}static getSizePrefixedRootAsShape(t,e){return t.setPosition(t.position()+r.flatbuffers.SIZE_PREFIX_LENGTH),(e||new n).__init(t.readInt32(t.position())+t.position(),t)}dim(e,n){let r=this.bb.__offset(this.bb_pos,4);return r?(n||new t.experimental.fbs.Dimension).__init(this.bb.__indirect(this.bb.__vector(this.bb_pos+r)+4*e),this.bb):null}dimLength(){let t=this.bb.__offset(this.bb_pos,4);return t?this.bb.__vector_len(this.bb_pos+t):0}static startShape(t){t.startObject(1)}static addDim(t,e){t.addFieldOffset(0,e,0)}static createDimVector(t,e){t.startVector(4,e.length,4);for(let n=e.length-1;n>=0;n--)t.addOffset(e[n]);return t.endVector()}static startDimVector(t,e){t.startVector(4,e,4)}static endShape(t){return t.endObject()}static createShape(t,e){return n.startShape(t),n.addDim(t,e),n.endShape(t)}}e.Shape=n}(e.fbs||(e.fbs={}))}(t.experimental||(t.experimental={}))}(e.onnxruntime||(e.onnxruntime={})),function(t){!function(e){!function(e){class n{constructor(){this.bb=null,this.bb_pos=0}__init(t,e){return this.bb_pos=t,this.bb=e,this}static getRootAsDimension(t,e){return(e||new n).__init(t.readInt32(t.position())+t.position(),t)}static getSizePrefixedRootAsDimension(t,e){return t.setPosition(t.position()+r.flatbuffers.SIZE_PREFIX_LENGTH),(e||new n).__init(t.readInt32(t.position())+t.position(),t)}value(e){let n=this.bb.__offset(this.bb_pos,4);return n?(e||new t.experimental.fbs.DimensionValue).__init(this.bb.__indirect(this.bb_pos+n),this.bb):null}denotation(t){let e=this.bb.__offset(this.bb_pos,6);return e?this.bb.__string(this.bb_pos+e,t):null}static startDimension(t){t.startObject(2)}static addValue(t,e){t.addFieldOffset(0,e,0)}static addDenotation(t,e){t.addFieldOffset(1,e,0)}static endDimension(t){return t.endObject()}static createDimension(t,e,r){return n.startDimension(t),n.addValue(t,e),n.addDenotation(t,r),n.endDimension(t)}}e.Dimension=n}(e.fbs||(e.fbs={}))}(t.experimental||(t.experimental={}))}(e.onnxruntime||(e.onnxruntime={})),function(t){!function(e){!function(e){class n{constructor(){this.bb=null,this.bb_pos=0}__init(t,e){return this.bb_pos=t,this.bb=e,this}static getRootAsDimensionValue(t,e){return(e||new n).__init(t.readInt32(t.position())+t.position(),t)}static getSizePrefixedRootAsDimensionValue(t,e){return t.setPosition(t.position()+r.flatbuffers.SIZE_PREFIX_LENGTH),(e||new n).__init(t.readInt32(t.position())+t.position(),t)}dimType(){let e=this.bb.__offset(this.bb_pos,4);return e?this.bb.readInt8(this.bb_pos+e):t.experimental.fbs.DimensionValueType.UNKNOWN}dimValue(){let t=this.bb.__offset(this.bb_pos,6);return t?this.bb.readInt64(this.bb_pos+t):this.bb.createLong(0,0)}dimParam(t){let e=this.bb.__offset(this.bb_pos,8);return e?this.bb.__string(this.bb_pos+e,t):null}static startDimensionValue(t){t.startObject(3)}static addDimType(e,n){e.addFieldInt8(0,n,t.experimental.fbs.DimensionValueType.UNKNOWN)}static addDimValue(t,e){t.addFieldInt64(1,e,t.createLong(0,0))}static addDimParam(t,e){t.addFieldOffset(2,e,0)}static endDimensionValue(t){return t.endObject()}static createDimensionValue(t,e,r,i){return n.startDimensionValue(t),n.addDimType(t,e),n.addDimValue(t,r),n.addDimParam(t,i),n.endDimensionValue(t)}}e.DimensionValue=n}(e.fbs||(e.fbs={}))}(t.experimental||(t.experimental={}))}(e.onnxruntime||(e.onnxruntime={})),function(t){!function(e){!function(e){class n{constructor(){this.bb=null,this.bb_pos=0}__init(t,e){return this.bb_pos=t,this.bb=e,this}static getRootAsTensorTypeAndShape(t,e){return(e||new n).__init(t.readInt32(t.position())+t.position(),t)}static getSizePrefixedRootAsTensorTypeAndShape(t,e){return t.setPosition(t.position()+r.flatbuffers.SIZE_PREFIX_LENGTH),(e||new n).__init(t.readInt32(t.position())+t.position(),t)}elemType(){let e=this.bb.__offset(this.bb_pos,4);return e?this.bb.readInt32(this.bb_pos+e):t.experimental.fbs.TensorDataType.UNDEFINED}shape(e){let n=this.bb.__offset(this.bb_pos,6);return n?(e||new t.experimental.fbs.Shape).__init(this.bb.__indirect(this.bb_pos+n),this.bb):null}static startTensorTypeAndShape(t){t.startObject(2)}static addElemType(e,n){e.addFieldInt32(0,n,t.experimental.fbs.TensorDataType.UNDEFINED)}static addShape(t,e){t.addFieldOffset(1,e,0)}static endTensorTypeAndShape(t){return t.endObject()}static createTensorTypeAndShape(t,e,r){return n.startTensorTypeAndShape(t),n.addElemType(t,e),n.addShape(t,r),n.endTensorTypeAndShape(t)}}e.TensorTypeAndShape=n}(e.fbs||(e.fbs={}))}(t.experimental||(t.experimental={}))}(e.onnxruntime||(e.onnxruntime={})),function(t){!function(e){!function(e){class n{constructor(){this.bb=null,this.bb_pos=0}__init(t,e){return this.bb_pos=t,this.bb=e,this}static getRootAsMapType(t,e){return(e||new n).__init(t.readInt32(t.position())+t.position(),t)}static getSizePrefixedRootAsMapType(t,e){return t.setPosition(t.position()+r.flatbuffers.SIZE_PREFIX_LENGTH),(e||new n).__init(t.readInt32(t.position())+t.position(),t)}keyType(){let e=this.bb.__offset(this.bb_pos,4);return e?this.bb.readInt32(this.bb_pos+e):t.experimental.fbs.TensorDataType.UNDEFINED}valueType(e){let n=this.bb.__offset(this.bb_pos,6);return n?(e||new t.experimental.fbs.TypeInfo).__init(this.bb.__indirect(this.bb_pos+n),this.bb):null}static startMapType(t){t.startObject(2)}static addKeyType(e,n){e.addFieldInt32(0,n,t.experimental.fbs.TensorDataType.UNDEFINED)}static addValueType(t,e){t.addFieldOffset(1,e,0)}static endMapType(t){return t.endObject()}static createMapType(t,e,r){return n.startMapType(t),n.addKeyType(t,e),n.addValueType(t,r),n.endMapType(t)}}e.MapType=n}(e.fbs||(e.fbs={}))}(t.experimental||(t.experimental={}))}(e.onnxruntime||(e.onnxruntime={})),function(t){!function(e){!function(e){class n{constructor(){this.bb=null,this.bb_pos=0}__init(t,e){return this.bb_pos=t,this.bb=e,this}static getRootAsSequenceType(t,e){return(e||new n).__init(t.readInt32(t.position())+t.position(),t)}static getSizePrefixedRootAsSequenceType(t,e){return t.setPosition(t.position()+r.flatbuffers.SIZE_PREFIX_LENGTH),(e||new n).__init(t.readInt32(t.position())+t.position(),t)}elemType(e){let n=this.bb.__offset(this.bb_pos,4);return n?(e||new t.experimental.fbs.TypeInfo).__init(this.bb.__indirect(this.bb_pos+n),this.bb):null}static startSequenceType(t){t.startObject(1)}static addElemType(t,e){t.addFieldOffset(0,e,0)}static endSequenceType(t){return t.endObject()}static createSequenceType(t,e){return n.startSequenceType(t),n.addElemType(t,e),n.endSequenceType(t)}}e.SequenceType=n}(e.fbs||(e.fbs={}))}(t.experimental||(t.experimental={}))}(e.onnxruntime||(e.onnxruntime={})),function(t){!function(t){(t.fbs||(t.fbs={})).EdgeEnd=class{constructor(){this.bb=null,this.bb_pos=0}__init(t,e){return this.bb_pos=t,this.bb=e,this}nodeIndex(){return this.bb.readUint32(this.bb_pos)}srcArgIndex(){return this.bb.readInt32(this.bb_pos+4)}dstArgIndex(){return this.bb.readInt32(this.bb_pos+8)}static createEdgeEnd(t,e,n,r){return t.prep(4,12),t.writeInt32(r),t.writeInt32(n),t.writeInt32(e),t.offset()}}}(t.experimental||(t.experimental={}))}(e.onnxruntime||(e.onnxruntime={})),function(t){!function(e){!function(e){class n{constructor(){this.bb=null,this.bb_pos=0}__init(t,e){return this.bb_pos=t,this.bb=e,this}static getRootAsNodeEdge(t,e){return(e||new n).__init(t.readInt32(t.position())+t.position(),t)}static getSizePrefixedRootAsNodeEdge(t,e){return t.setPosition(t.position()+r.flatbuffers.SIZE_PREFIX_LENGTH),(e||new n).__init(t.readInt32(t.position())+t.position(),t)}nodeIndex(){let t=this.bb.__offset(this.bb_pos,4);return t?this.bb.readUint32(this.bb_pos+t):0}inputEdges(e,n){let r=this.bb.__offset(this.bb_pos,6);return r?(n||new t.experimental.fbs.EdgeEnd).__init(this.bb.__vector(this.bb_pos+r)+12*e,this.bb):null}inputEdgesLength(){let t=this.bb.__offset(this.bb_pos,6);return t?this.bb.__vector_len(this.bb_pos+t):0}outputEdges(e,n){let r=this.bb.__offset(this.bb_pos,8);return r?(n||new t.experimental.fbs.EdgeEnd).__init(this.bb.__vector(this.bb_pos+r)+12*e,this.bb):null}outputEdgesLength(){let t=this.bb.__offset(this.bb_pos,8);return t?this.bb.__vector_len(this.bb_pos+t):0}static startNodeEdge(t){t.startObject(3)}static addNodeIndex(t,e){t.addFieldInt32(0,e,0)}static addInputEdges(t,e){t.addFieldOffset(1,e,0)}static startInputEdgesVector(t,e){t.startVector(12,e,4)}static addOutputEdges(t,e){t.addFieldOffset(2,e,0)}static startOutputEdgesVector(t,e){t.startVector(12,e,4)}static endNodeEdge(t){return t.endObject()}static createNodeEdge(t,e,r,i){return n.startNodeEdge(t),n.addNodeIndex(t,e),n.addInputEdges(t,r),n.addOutputEdges(t,i),n.endNodeEdge(t)}}e.NodeEdge=n}(e.fbs||(e.fbs={}))}(t.experimental||(t.experimental={}))}(e.onnxruntime||(e.onnxruntime={})),function(t){!function(e){!function(e){class n{constructor(){this.bb=null,this.bb_pos=0}__init(t,e){return this.bb_pos=t,this.bb=e,this}static getRootAsNode(t,e){return(e||new n).__init(t.readInt32(t.position())+t.position(),t)}static getSizePrefixedRootAsNode(t,e){return t.setPosition(t.position()+r.flatbuffers.SIZE_PREFIX_LENGTH),(e||new n).__init(t.readInt32(t.position())+t.position(),t)}name(t){let e=this.bb.__offset(this.bb_pos,4);return e?this.bb.__string(this.bb_pos+e,t):null}docString(t){let e=this.bb.__offset(this.bb_pos,6);return e?this.bb.__string(this.bb_pos+e,t):null}domain(t){let e=this.bb.__offset(this.bb_pos,8);return e?this.bb.__string(this.bb_pos+e,t):null}sinceVersion(){let t=this.bb.__offset(this.bb_pos,10);return t?this.bb.readInt32(this.bb_pos+t):0}index(){let t=this.bb.__offset(this.bb_pos,12);return t?this.bb.readUint32(this.bb_pos+t):0}opType(t){let e=this.bb.__offset(this.bb_pos,14);return e?this.bb.__string(this.bb_pos+e,t):null}type(){let e=this.bb.__offset(this.bb_pos,16);return e?this.bb.readInt32(this.bb_pos+e):t.experimental.fbs.NodeType.Primitive}executionProviderType(t){let e=this.bb.__offset(this.bb_pos,18);return e?this.bb.__string(this.bb_pos+e,t):null}inputs(t,e){let n=this.bb.__offset(this.bb_pos,20);return n?this.bb.__string(this.bb.__vector(this.bb_pos+n)+4*t,e):null}inputsLength(){let t=this.bb.__offset(this.bb_pos,20);return t?this.bb.__vector_len(this.bb_pos+t):0}outputs(t,e){let n=this.bb.__offset(this.bb_pos,22);return n?this.bb.__string(this.bb.__vector(this.bb_pos+n)+4*t,e):null}outputsLength(){let t=this.bb.__offset(this.bb_pos,22);return t?this.bb.__vector_len(this.bb_pos+t):0}attributes(e,n){let r=this.bb.__offset(this.bb_pos,24);return r?(n||new t.experimental.fbs.Attribute).__init(this.bb.__indirect(this.bb.__vector(this.bb_pos+r)+4*e),this.bb):null}attributesLength(){let t=this.bb.__offset(this.bb_pos,24);return t?this.bb.__vector_len(this.bb_pos+t):0}inputArgCounts(t){let e=this.bb.__offset(this.bb_pos,26);return e?this.bb.readInt32(this.bb.__vector(this.bb_pos+e)+4*t):0}inputArgCountsLength(){let t=this.bb.__offset(this.bb_pos,26);return t?this.bb.__vector_len(this.bb_pos+t):0}inputArgCountsArray(){let t=this.bb.__offset(this.bb_pos,26);return t?new Int32Array(this.bb.bytes().buffer,this.bb.bytes().byteOffset+this.bb.__vector(this.bb_pos+t),this.bb.__vector_len(this.bb_pos+t)):null}implicitInputs(t,e){let n=this.bb.__offset(this.bb_pos,28);return n?this.bb.__string(this.bb.__vector(this.bb_pos+n)+4*t,e):null}implicitInputsLength(){let t=this.bb.__offset(this.bb_pos,28);return t?this.bb.__vector_len(this.bb_pos+t):0}static startNode(t){t.startObject(13)}static addName(t,e){t.addFieldOffset(0,e,0)}static addDocString(t,e){t.addFieldOffset(1,e,0)}static addDomain(t,e){t.addFieldOffset(2,e,0)}static addSinceVersion(t,e){t.addFieldInt32(3,e,0)}static addIndex(t,e){t.addFieldInt32(4,e,0)}static addOpType(t,e){t.addFieldOffset(5,e,0)}static addType(e,n){e.addFieldInt32(6,n,t.experimental.fbs.NodeType.Primitive)}static addExecutionProviderType(t,e){t.addFieldOffset(7,e,0)}static addInputs(t,e){t.addFieldOffset(8,e,0)}static createInputsVector(t,e){t.startVector(4,e.length,4);for(let n=e.length-1;n>=0;n--)t.addOffset(e[n]);return t.endVector()}static startInputsVector(t,e){t.startVector(4,e,4)}static addOutputs(t,e){t.addFieldOffset(9,e,0)}static createOutputsVector(t,e){t.startVector(4,e.length,4);for(let n=e.length-1;n>=0;n--)t.addOffset(e[n]);return t.endVector()}static startOutputsVector(t,e){t.startVector(4,e,4)}static addAttributes(t,e){t.addFieldOffset(10,e,0)}static createAttributesVector(t,e){t.startVector(4,e.length,4);for(let n=e.length-1;n>=0;n--)t.addOffset(e[n]);return t.endVector()}static startAttributesVector(t,e){t.startVector(4,e,4)}static addInputArgCounts(t,e){t.addFieldOffset(11,e,0)}static createInputArgCountsVector(t,e){t.startVector(4,e.length,4);for(let n=e.length-1;n>=0;n--)t.addInt32(e[n]);return t.endVector()}static startInputArgCountsVector(t,e){t.startVector(4,e,4)}static addImplicitInputs(t,e){t.addFieldOffset(12,e,0)}static createImplicitInputsVector(t,e){t.startVector(4,e.length,4);for(let n=e.length-1;n>=0;n--)t.addOffset(e[n]);return t.endVector()}static startImplicitInputsVector(t,e){t.startVector(4,e,4)}static endNode(t){return t.endObject()}static createNode(t,e,r,i,o,a,s,u,c,l,p,f,d,h){return n.startNode(t),n.addName(t,e),n.addDocString(t,r),n.addDomain(t,i),n.addSinceVersion(t,o),n.addIndex(t,a),n.addOpType(t,s),n.addType(t,u),n.addExecutionProviderType(t,c),n.addInputs(t,l),n.addOutputs(t,p),n.addAttributes(t,f),n.addInputArgCounts(t,d),n.addImplicitInputs(t,h),n.endNode(t)}}e.Node=n}(e.fbs||(e.fbs={}))}(t.experimental||(t.experimental={}))}(e.onnxruntime||(e.onnxruntime={})),function(t){!function(e){!function(e){class n{constructor(){this.bb=null,this.bb_pos=0}__init(t,e){return this.bb_pos=t,this.bb=e,this}static getRootAsValueInfo(t,e){return(e||new n).__init(t.readInt32(t.position())+t.position(),t)}static getSizePrefixedRootAsValueInfo(t,e){return t.setPosition(t.position()+r.flatbuffers.SIZE_PREFIX_LENGTH),(e||new n).__init(t.readInt32(t.position())+t.position(),t)}name(t){let e=this.bb.__offset(this.bb_pos,4);return e?this.bb.__string(this.bb_pos+e,t):null}docString(t){let e=this.bb.__offset(this.bb_pos,6);return e?this.bb.__string(this.bb_pos+e,t):null}type(e){let n=this.bb.__offset(this.bb_pos,8);return n?(e||new t.experimental.fbs.TypeInfo).__init(this.bb.__indirect(this.bb_pos+n),this.bb):null}static startValueInfo(t){t.startObject(3)}static addName(t,e){t.addFieldOffset(0,e,0)}static addDocString(t,e){t.addFieldOffset(1,e,0)}static addType(t,e){t.addFieldOffset(2,e,0)}static endValueInfo(t){return t.endObject()}static createValueInfo(t,e,r,i){return n.startValueInfo(t),n.addName(t,e),n.addDocString(t,r),n.addType(t,i),n.endValueInfo(t)}}e.ValueInfo=n}(e.fbs||(e.fbs={}))}(t.experimental||(t.experimental={}))}(e.onnxruntime||(e.onnxruntime={})),function(t){!function(e){!function(e){class n{constructor(){this.bb=null,this.bb_pos=0}__init(t,e){return this.bb_pos=t,this.bb=e,this}static getRootAsTypeInfo(t,e){return(e||new n).__init(t.readInt32(t.position())+t.position(),t)}static getSizePrefixedRootAsTypeInfo(t,e){return t.setPosition(t.position()+r.flatbuffers.SIZE_PREFIX_LENGTH),(e||new n).__init(t.readInt32(t.position())+t.position(),t)}denotation(t){let e=this.bb.__offset(this.bb_pos,4);return e?this.bb.__string(this.bb_pos+e,t):null}valueType(){let e=this.bb.__offset(this.bb_pos,6);return e?this.bb.readUint8(this.bb_pos+e):t.experimental.fbs.TypeInfoValue.NONE}value(t){let e=this.bb.__offset(this.bb_pos,8);return e?this.bb.__union(t,this.bb_pos+e):null}static startTypeInfo(t){t.startObject(3)}static addDenotation(t,e){t.addFieldOffset(0,e,0)}static addValueType(e,n){e.addFieldInt8(1,n,t.experimental.fbs.TypeInfoValue.NONE)}static addValue(t,e){t.addFieldOffset(2,e,0)}static endTypeInfo(t){return t.endObject()}static createTypeInfo(t,e,r,i){return n.startTypeInfo(t),n.addDenotation(t,e),n.addValueType(t,r),n.addValue(t,i),n.endTypeInfo(t)}}e.TypeInfo=n}(e.fbs||(e.fbs={}))}(t.experimental||(t.experimental={}))}(e.onnxruntime||(e.onnxruntime={})),function(t){!function(t){!function(t){class e{constructor(){this.bb=null,this.bb_pos=0}__init(t,e){return this.bb_pos=t,this.bb=e,this}static getRootAsOperatorSetId(t,n){return(n||new e).__init(t.readInt32(t.position())+t.position(),t)}static getSizePrefixedRootAsOperatorSetId(t,n){return t.setPosition(t.position()+r.flatbuffers.SIZE_PREFIX_LENGTH),(n||new e).__init(t.readInt32(t.position())+t.position(),t)}domain(t){let e=this.bb.__offset(this.bb_pos,4);return e?this.bb.__string(this.bb_pos+e,t):null}version(){let t=this.bb.__offset(this.bb_pos,6);return t?this.bb.readInt64(this.bb_pos+t):this.bb.createLong(0,0)}static startOperatorSetId(t){t.startObject(2)}static addDomain(t,e){t.addFieldOffset(0,e,0)}static addVersion(t,e){t.addFieldInt64(1,e,t.createLong(0,0))}static endOperatorSetId(t){return t.endObject()}static createOperatorSetId(t,n,r){return e.startOperatorSetId(t),e.addDomain(t,n),e.addVersion(t,r),e.endOperatorSetId(t)}}t.OperatorSetId=e}(t.fbs||(t.fbs={}))}(t.experimental||(t.experimental={}))}(e.onnxruntime||(e.onnxruntime={})),function(t){!function(e){!function(e){class n{constructor(){this.bb=null,this.bb_pos=0}__init(t,e){return this.bb_pos=t,this.bb=e,this}static getRootAsTensor(t,e){return(e||new n).__init(t.readInt32(t.position())+t.position(),t)}static getSizePrefixedRootAsTensor(t,e){return t.setPosition(t.position()+r.flatbuffers.SIZE_PREFIX_LENGTH),(e||new n).__init(t.readInt32(t.position())+t.position(),t)}name(t){let e=this.bb.__offset(this.bb_pos,4);return e?this.bb.__string(this.bb_pos+e,t):null}docString(t){let e=this.bb.__offset(this.bb_pos,6);return e?this.bb.__string(this.bb_pos+e,t):null}dims(t){let e=this.bb.__offset(this.bb_pos,8);return e?this.bb.readInt64(this.bb.__vector(this.bb_pos+e)+8*t):this.bb.createLong(0,0)}dimsLength(){let t=this.bb.__offset(this.bb_pos,8);return t?this.bb.__vector_len(this.bb_pos+t):0}dataType(){let e=this.bb.__offset(this.bb_pos,10);return e?this.bb.readInt32(this.bb_pos+e):t.experimental.fbs.TensorDataType.UNDEFINED}rawData(t){let e=this.bb.__offset(this.bb_pos,12);return e?this.bb.readUint8(this.bb.__vector(this.bb_pos+e)+t):0}rawDataLength(){let t=this.bb.__offset(this.bb_pos,12);return t?this.bb.__vector_len(this.bb_pos+t):0}rawDataArray(){let t=this.bb.__offset(this.bb_pos,12);return t?new Uint8Array(this.bb.bytes().buffer,this.bb.bytes().byteOffset+this.bb.__vector(this.bb_pos+t),this.bb.__vector_len(this.bb_pos+t)):null}stringData(t,e){let n=this.bb.__offset(this.bb_pos,14);return n?this.bb.__string(this.bb.__vector(this.bb_pos+n)+4*t,e):null}stringDataLength(){let t=this.bb.__offset(this.bb_pos,14);return t?this.bb.__vector_len(this.bb_pos+t):0}static startTensor(t){t.startObject(6)}static addName(t,e){t.addFieldOffset(0,e,0)}static addDocString(t,e){t.addFieldOffset(1,e,0)}static addDims(t,e){t.addFieldOffset(2,e,0)}static createDimsVector(t,e){t.startVector(8,e.length,8);for(let n=e.length-1;n>=0;n--)t.addInt64(e[n]);return t.endVector()}static startDimsVector(t,e){t.startVector(8,e,8)}static addDataType(e,n){e.addFieldInt32(3,n,t.experimental.fbs.TensorDataType.UNDEFINED)}static addRawData(t,e){t.addFieldOffset(4,e,0)}static createRawDataVector(t,e){t.startVector(1,e.length,1);for(let n=e.length-1;n>=0;n--)t.addInt8(e[n]);return t.endVector()}static startRawDataVector(t,e){t.startVector(1,e,1)}static addStringData(t,e){t.addFieldOffset(5,e,0)}static createStringDataVector(t,e){t.startVector(4,e.length,4);for(let n=e.length-1;n>=0;n--)t.addOffset(e[n]);return t.endVector()}static startStringDataVector(t,e){t.startVector(4,e,4)}static endTensor(t){return t.endObject()}static createTensor(t,e,r,i,o,a,s){return n.startTensor(t),n.addName(t,e),n.addDocString(t,r),n.addDims(t,i),n.addDataType(t,o),n.addRawData(t,a),n.addStringData(t,s),n.endTensor(t)}}e.Tensor=n}(e.fbs||(e.fbs={}))}(t.experimental||(t.experimental={}))}(e.onnxruntime||(e.onnxruntime={})),function(t){!function(e){!function(e){class n{constructor(){this.bb=null,this.bb_pos=0}__init(t,e){return this.bb_pos=t,this.bb=e,this}static getRootAsSparseTensor(t,e){return(e||new n).__init(t.readInt32(t.position())+t.position(),t)}static getSizePrefixedRootAsSparseTensor(t,e){return t.setPosition(t.position()+r.flatbuffers.SIZE_PREFIX_LENGTH),(e||new n).__init(t.readInt32(t.position())+t.position(),t)}values(e){let n=this.bb.__offset(this.bb_pos,4);return n?(e||new t.experimental.fbs.Tensor).__init(this.bb.__indirect(this.bb_pos+n),this.bb):null}indices(e){let n=this.bb.__offset(this.bb_pos,6);return n?(e||new t.experimental.fbs.Tensor).__init(this.bb.__indirect(this.bb_pos+n),this.bb):null}dims(t){let e=this.bb.__offset(this.bb_pos,8);return e?this.bb.readInt64(this.bb.__vector(this.bb_pos+e)+8*t):this.bb.createLong(0,0)}dimsLength(){let t=this.bb.__offset(this.bb_pos,8);return t?this.bb.__vector_len(this.bb_pos+t):0}static startSparseTensor(t){t.startObject(3)}static addValues(t,e){t.addFieldOffset(0,e,0)}static addIndices(t,e){t.addFieldOffset(1,e,0)}static addDims(t,e){t.addFieldOffset(2,e,0)}static createDimsVector(t,e){t.startVector(8,e.length,8);for(let n=e.length-1;n>=0;n--)t.addInt64(e[n]);return t.endVector()}static startDimsVector(t,e){t.startVector(8,e,8)}static endSparseTensor(t){return t.endObject()}static createSparseTensor(t,e,r,i){return n.startSparseTensor(t),n.addValues(t,e),n.addIndices(t,r),n.addDims(t,i),n.endSparseTensor(t)}}e.SparseTensor=n}(e.fbs||(e.fbs={}))}(t.experimental||(t.experimental={}))}(e.onnxruntime||(e.onnxruntime={})),function(t){!function(e){!function(e){class n{constructor(){this.bb=null,this.bb_pos=0}__init(t,e){return this.bb_pos=t,this.bb=e,this}static getRootAsAttribute(t,e){return(e||new n).__init(t.readInt32(t.position())+t.position(),t)}static getSizePrefixedRootAsAttribute(t,e){return t.setPosition(t.position()+r.flatbuffers.SIZE_PREFIX_LENGTH),(e||new n).__init(t.readInt32(t.position())+t.position(),t)}name(t){let e=this.bb.__offset(this.bb_pos,4);return e?this.bb.__string(this.bb_pos+e,t):null}docString(t){let e=this.bb.__offset(this.bb_pos,6);return e?this.bb.__string(this.bb_pos+e,t):null}type(){let e=this.bb.__offset(this.bb_pos,8);return e?this.bb.readInt32(this.bb_pos+e):t.experimental.fbs.AttributeType.UNDEFINED}f(){let t=this.bb.__offset(this.bb_pos,10);return t?this.bb.readFloat32(this.bb_pos+t):0}i(){let t=this.bb.__offset(this.bb_pos,12);return t?this.bb.readInt64(this.bb_pos+t):this.bb.createLong(0,0)}s(t){let e=this.bb.__offset(this.bb_pos,14);return e?this.bb.__string(this.bb_pos+e,t):null}t(e){let n=this.bb.__offset(this.bb_pos,16);return n?(e||new t.experimental.fbs.Tensor).__init(this.bb.__indirect(this.bb_pos+n),this.bb):null}g(e){let n=this.bb.__offset(this.bb_pos,18);return n?(e||new t.experimental.fbs.Graph).__init(this.bb.__indirect(this.bb_pos+n),this.bb):null}floats(t){let e=this.bb.__offset(this.bb_pos,20);return e?this.bb.readFloat32(this.bb.__vector(this.bb_pos+e)+4*t):0}floatsLength(){let t=this.bb.__offset(this.bb_pos,20);return t?this.bb.__vector_len(this.bb_pos+t):0}floatsArray(){let t=this.bb.__offset(this.bb_pos,20);return t?new Float32Array(this.bb.bytes().buffer,this.bb.bytes().byteOffset+this.bb.__vector(this.bb_pos+t),this.bb.__vector_len(this.bb_pos+t)):null}ints(t){let e=this.bb.__offset(this.bb_pos,22);return e?this.bb.readInt64(this.bb.__vector(this.bb_pos+e)+8*t):this.bb.createLong(0,0)}intsLength(){let t=this.bb.__offset(this.bb_pos,22);return t?this.bb.__vector_len(this.bb_pos+t):0}strings(t,e){let n=this.bb.__offset(this.bb_pos,24);return n?this.bb.__string(this.bb.__vector(this.bb_pos+n)+4*t,e):null}stringsLength(){let t=this.bb.__offset(this.bb_pos,24);return t?this.bb.__vector_len(this.bb_pos+t):0}tensors(e,n){let r=this.bb.__offset(this.bb_pos,26);return r?(n||new t.experimental.fbs.Tensor).__init(this.bb.__indirect(this.bb.__vector(this.bb_pos+r)+4*e),this.bb):null}tensorsLength(){let t=this.bb.__offset(this.bb_pos,26);return t?this.bb.__vector_len(this.bb_pos+t):0}graphs(e,n){let r=this.bb.__offset(this.bb_pos,28);return r?(n||new t.experimental.fbs.Graph).__init(this.bb.__indirect(this.bb.__vector(this.bb_pos+r)+4*e),this.bb):null}graphsLength(){let t=this.bb.__offset(this.bb_pos,28);return t?this.bb.__vector_len(this.bb_pos+t):0}static startAttribute(t){t.startObject(13)}static addName(t,e){t.addFieldOffset(0,e,0)}static addDocString(t,e){t.addFieldOffset(1,e,0)}static addType(e,n){e.addFieldInt32(2,n,t.experimental.fbs.AttributeType.UNDEFINED)}static addF(t,e){t.addFieldFloat32(3,e,0)}static addI(t,e){t.addFieldInt64(4,e,t.createLong(0,0))}static addS(t,e){t.addFieldOffset(5,e,0)}static addT(t,e){t.addFieldOffset(6,e,0)}static addG(t,e){t.addFieldOffset(7,e,0)}static addFloats(t,e){t.addFieldOffset(8,e,0)}static createFloatsVector(t,e){t.startVector(4,e.length,4);for(let n=e.length-1;n>=0;n--)t.addFloat32(e[n]);return t.endVector()}static startFloatsVector(t,e){t.startVector(4,e,4)}static addInts(t,e){t.addFieldOffset(9,e,0)}static createIntsVector(t,e){t.startVector(8,e.length,8);for(let n=e.length-1;n>=0;n--)t.addInt64(e[n]);return t.endVector()}static startIntsVector(t,e){t.startVector(8,e,8)}static addStrings(t,e){t.addFieldOffset(10,e,0)}static createStringsVector(t,e){t.startVector(4,e.length,4);for(let n=e.length-1;n>=0;n--)t.addOffset(e[n]);return t.endVector()}static startStringsVector(t,e){t.startVector(4,e,4)}static addTensors(t,e){t.addFieldOffset(11,e,0)}static createTensorsVector(t,e){t.startVector(4,e.length,4);for(let n=e.length-1;n>=0;n--)t.addOffset(e[n]);return t.endVector()}static startTensorsVector(t,e){t.startVector(4,e,4)}static addGraphs(t,e){t.addFieldOffset(12,e,0)}static createGraphsVector(t,e){t.startVector(4,e.length,4);for(let n=e.length-1;n>=0;n--)t.addOffset(e[n]);return t.endVector()}static startGraphsVector(t,e){t.startVector(4,e,4)}static endAttribute(t){return t.endObject()}static createAttribute(t,e,r,i,o,a,s,u,c,l,p,f,d,h){return n.startAttribute(t),n.addName(t,e),n.addDocString(t,r),n.addType(t,i),n.addF(t,o),n.addI(t,a),n.addS(t,s),n.addT(t,u),n.addG(t,c),n.addFloats(t,l),n.addInts(t,p),n.addStrings(t,f),n.addTensors(t,d),n.addGraphs(t,h),n.endAttribute(t)}}e.Attribute=n}(e.fbs||(e.fbs={}))}(t.experimental||(t.experimental={}))}(e.onnxruntime||(e.onnxruntime={})),function(t){!function(e){!function(e){class n{constructor(){this.bb=null,this.bb_pos=0}__init(t,e){return this.bb_pos=t,this.bb=e,this}static getRootAsGraph(t,e){return(e||new n).__init(t.readInt32(t.position())+t.position(),t)}static getSizePrefixedRootAsGraph(t,e){return t.setPosition(t.position()+r.flatbuffers.SIZE_PREFIX_LENGTH),(e||new n).__init(t.readInt32(t.position())+t.position(),t)}initializers(e,n){let r=this.bb.__offset(this.bb_pos,4);return r?(n||new t.experimental.fbs.Tensor).__init(this.bb.__indirect(this.bb.__vector(this.bb_pos+r)+4*e),this.bb):null}initializersLength(){let t=this.bb.__offset(this.bb_pos,4);return t?this.bb.__vector_len(this.bb_pos+t):0}nodeArgs(e,n){let r=this.bb.__offset(this.bb_pos,6);return r?(n||new t.experimental.fbs.ValueInfo).__init(this.bb.__indirect(this.bb.__vector(this.bb_pos+r)+4*e),this.bb):null}nodeArgsLength(){let t=this.bb.__offset(this.bb_pos,6);return t?this.bb.__vector_len(this.bb_pos+t):0}nodes(e,n){let r=this.bb.__offset(this.bb_pos,8);return r?(n||new t.experimental.fbs.Node).__init(this.bb.__indirect(this.bb.__vector(this.bb_pos+r)+4*e),this.bb):null}nodesLength(){let t=this.bb.__offset(this.bb_pos,8);return t?this.bb.__vector_len(this.bb_pos+t):0}maxNodeIndex(){let t=this.bb.__offset(this.bb_pos,10);return t?this.bb.readUint32(this.bb_pos+t):0}nodeEdges(e,n){let r=this.bb.__offset(this.bb_pos,12);return r?(n||new t.experimental.fbs.NodeEdge).__init(this.bb.__indirect(this.bb.__vector(this.bb_pos+r)+4*e),this.bb):null}nodeEdgesLength(){let t=this.bb.__offset(this.bb_pos,12);return t?this.bb.__vector_len(this.bb_pos+t):0}inputs(t,e){let n=this.bb.__offset(this.bb_pos,14);return n?this.bb.__string(this.bb.__vector(this.bb_pos+n)+4*t,e):null}inputsLength(){let t=this.bb.__offset(this.bb_pos,14);return t?this.bb.__vector_len(this.bb_pos+t):0}outputs(t,e){let n=this.bb.__offset(this.bb_pos,16);return n?this.bb.__string(this.bb.__vector(this.bb_pos+n)+4*t,e):null}outputsLength(){let t=this.bb.__offset(this.bb_pos,16);return t?this.bb.__vector_len(this.bb_pos+t):0}sparseInitializers(e,n){let r=this.bb.__offset(this.bb_pos,18);return r?(n||new t.experimental.fbs.SparseTensor).__init(this.bb.__indirect(this.bb.__vector(this.bb_pos+r)+4*e),this.bb):null}sparseInitializersLength(){let t=this.bb.__offset(this.bb_pos,18);return t?this.bb.__vector_len(this.bb_pos+t):0}static startGraph(t){t.startObject(8)}static addInitializers(t,e){t.addFieldOffset(0,e,0)}static createInitializersVector(t,e){t.startVector(4,e.length,4);for(let n=e.length-1;n>=0;n--)t.addOffset(e[n]);return t.endVector()}static startInitializersVector(t,e){t.startVector(4,e,4)}static addNodeArgs(t,e){t.addFieldOffset(1,e,0)}static createNodeArgsVector(t,e){t.startVector(4,e.length,4);for(let n=e.length-1;n>=0;n--)t.addOffset(e[n]);return t.endVector()}static startNodeArgsVector(t,e){t.startVector(4,e,4)}static addNodes(t,e){t.addFieldOffset(2,e,0)}static createNodesVector(t,e){t.startVector(4,e.length,4);for(let n=e.length-1;n>=0;n--)t.addOffset(e[n]);return t.endVector()}static startNodesVector(t,e){t.startVector(4,e,4)}static addMaxNodeIndex(t,e){t.addFieldInt32(3,e,0)}static addNodeEdges(t,e){t.addFieldOffset(4,e,0)}static createNodeEdgesVector(t,e){t.startVector(4,e.length,4);for(let n=e.length-1;n>=0;n--)t.addOffset(e[n]);return t.endVector()}static startNodeEdgesVector(t,e){t.startVector(4,e,4)}static addInputs(t,e){t.addFieldOffset(5,e,0)}static createInputsVector(t,e){t.startVector(4,e.length,4);for(let n=e.length-1;n>=0;n--)t.addOffset(e[n]);return t.endVector()}static startInputsVector(t,e){t.startVector(4,e,4)}static addOutputs(t,e){t.addFieldOffset(6,e,0)}static createOutputsVector(t,e){t.startVector(4,e.length,4);for(let n=e.length-1;n>=0;n--)t.addOffset(e[n]);return t.endVector()}static startOutputsVector(t,e){t.startVector(4,e,4)}static addSparseInitializers(t,e){t.addFieldOffset(7,e,0)}static createSparseInitializersVector(t,e){t.startVector(4,e.length,4);for(let n=e.length-1;n>=0;n--)t.addOffset(e[n]);return t.endVector()}static startSparseInitializersVector(t,e){t.startVector(4,e,4)}static endGraph(t){return t.endObject()}static createGraph(t,e,r,i,o,a,s,u,c){return n.startGraph(t),n.addInitializers(t,e),n.addNodeArgs(t,r),n.addNodes(t,i),n.addMaxNodeIndex(t,o),n.addNodeEdges(t,a),n.addInputs(t,s),n.addOutputs(t,u),n.addSparseInitializers(t,c),n.endGraph(t)}}e.Graph=n}(e.fbs||(e.fbs={}))}(t.experimental||(t.experimental={}))}(e.onnxruntime||(e.onnxruntime={})),function(t){!function(e){!function(e){class n{constructor(){this.bb=null,this.bb_pos=0}__init(t,e){return this.bb_pos=t,this.bb=e,this}static getRootAsModel(t,e){return(e||new n).__init(t.readInt32(t.position())+t.position(),t)}static getSizePrefixedRootAsModel(t,e){return t.setPosition(t.position()+r.flatbuffers.SIZE_PREFIX_LENGTH),(e||new n).__init(t.readInt32(t.position())+t.position(),t)}irVersion(){let t=this.bb.__offset(this.bb_pos,4);return t?this.bb.readInt64(this.bb_pos+t):this.bb.createLong(0,0)}opsetImport(e,n){let r=this.bb.__offset(this.bb_pos,6);return r?(n||new t.experimental.fbs.OperatorSetId).__init(this.bb.__indirect(this.bb.__vector(this.bb_pos+r)+4*e),this.bb):null}opsetImportLength(){let t=this.bb.__offset(this.bb_pos,6);return t?this.bb.__vector_len(this.bb_pos+t):0}producerName(t){let e=this.bb.__offset(this.bb_pos,8);return e?this.bb.__string(this.bb_pos+e,t):null}producerVersion(t){let e=this.bb.__offset(this.bb_pos,10);return e?this.bb.__string(this.bb_pos+e,t):null}domain(t){let e=this.bb.__offset(this.bb_pos,12);return e?this.bb.__string(this.bb_pos+e,t):null}modelVersion(){let t=this.bb.__offset(this.bb_pos,14);return t?this.bb.readInt64(this.bb_pos+t):this.bb.createLong(0,0)}docString(t){let e=this.bb.__offset(this.bb_pos,16);return e?this.bb.__string(this.bb_pos+e,t):null}graph(e){let n=this.bb.__offset(this.bb_pos,18);return n?(e||new t.experimental.fbs.Graph).__init(this.bb.__indirect(this.bb_pos+n),this.bb):null}graphDocString(t){let e=this.bb.__offset(this.bb_pos,20);return e?this.bb.__string(this.bb_pos+e,t):null}static startModel(t){t.startObject(9)}static addIrVersion(t,e){t.addFieldInt64(0,e,t.createLong(0,0))}static addOpsetImport(t,e){t.addFieldOffset(1,e,0)}static createOpsetImportVector(t,e){t.startVector(4,e.length,4);for(let n=e.length-1;n>=0;n--)t.addOffset(e[n]);return t.endVector()}static startOpsetImportVector(t,e){t.startVector(4,e,4)}static addProducerName(t,e){t.addFieldOffset(2,e,0)}static addProducerVersion(t,e){t.addFieldOffset(3,e,0)}static addDomain(t,e){t.addFieldOffset(4,e,0)}static addModelVersion(t,e){t.addFieldInt64(5,e,t.createLong(0,0))}static addDocString(t,e){t.addFieldOffset(6,e,0)}static addGraph(t,e){t.addFieldOffset(7,e,0)}static addGraphDocString(t,e){t.addFieldOffset(8,e,0)}static endModel(t){return t.endObject()}static createModel(t,e,r,i,o,a,s,u,c,l){return n.startModel(t),n.addIrVersion(t,e),n.addOpsetImport(t,r),n.addProducerName(t,i),n.addProducerVersion(t,o),n.addDomain(t,a),n.addModelVersion(t,s),n.addDocString(t,u),n.addGraph(t,c),n.addGraphDocString(t,l),n.endModel(t)}}e.Model=n}(e.fbs||(e.fbs={}))}(t.experimental||(t.experimental={}))}(e.onnxruntime||(e.onnxruntime={})),function(t){!function(t){!function(t){class e{constructor(){this.bb=null,this.bb_pos=0}__init(t,e){return this.bb_pos=t,this.bb=e,this}static getRootAsKernelCreateInfos(t,n){return(n||new e).__init(t.readInt32(t.position())+t.position(),t)}static getSizePrefixedRootAsKernelCreateInfos(t,n){return t.setPosition(t.position()+r.flatbuffers.SIZE_PREFIX_LENGTH),(n||new e).__init(t.readInt32(t.position())+t.position(),t)}nodeIndices(t){let e=this.bb.__offset(this.bb_pos,4);return e?this.bb.readUint32(this.bb.__vector(this.bb_pos+e)+4*t):0}nodeIndicesLength(){let t=this.bb.__offset(this.bb_pos,4);return t?this.bb.__vector_len(this.bb_pos+t):0}nodeIndicesArray(){let t=this.bb.__offset(this.bb_pos,4);return t?new Uint32Array(this.bb.bytes().buffer,this.bb.bytes().byteOffset+this.bb.__vector(this.bb_pos+t),this.bb.__vector_len(this.bb_pos+t)):null}kernelDefHashes(t){let e=this.bb.__offset(this.bb_pos,6);return e?this.bb.readUint64(this.bb.__vector(this.bb_pos+e)+8*t):this.bb.createLong(0,0)}kernelDefHashesLength(){let t=this.bb.__offset(this.bb_pos,6);return t?this.bb.__vector_len(this.bb_pos+t):0}static startKernelCreateInfos(t){t.startObject(2)}static addNodeIndices(t,e){t.addFieldOffset(0,e,0)}static createNodeIndicesVector(t,e){t.startVector(4,e.length,4);for(let n=e.length-1;n>=0;n--)t.addInt32(e[n]);return t.endVector()}static startNodeIndicesVector(t,e){t.startVector(4,e,4)}static addKernelDefHashes(t,e){t.addFieldOffset(1,e,0)}static createKernelDefHashesVector(t,e){t.startVector(8,e.length,8);for(let n=e.length-1;n>=0;n--)t.addInt64(e[n]);return t.endVector()}static startKernelDefHashesVector(t,e){t.startVector(8,e,8)}static endKernelCreateInfos(t){return t.endObject()}static createKernelCreateInfos(t,n,r){return e.startKernelCreateInfos(t),e.addNodeIndices(t,n),e.addKernelDefHashes(t,r),e.endKernelCreateInfos(t)}}t.KernelCreateInfos=e}(t.fbs||(t.fbs={}))}(t.experimental||(t.experimental={}))}(e.onnxruntime||(e.onnxruntime={})),function(t){!function(e){!function(e){class n{constructor(){this.bb=null,this.bb_pos=0}__init(t,e){return this.bb_pos=t,this.bb=e,this}static getRootAsSubGraphSessionState(t,e){return(e||new n).__init(t.readInt32(t.position())+t.position(),t)}static getSizePrefixedRootAsSubGraphSessionState(t,e){return t.setPosition(t.position()+r.flatbuffers.SIZE_PREFIX_LENGTH),(e||new n).__init(t.readInt32(t.position())+t.position(),t)}graphId(t){let e=this.bb.__offset(this.bb_pos,4);return e?this.bb.__string(this.bb_pos+e,t):null}sessionState(e){let n=this.bb.__offset(this.bb_pos,6);return n?(e||new t.experimental.fbs.SessionState).__init(this.bb.__indirect(this.bb_pos+n),this.bb):null}static startSubGraphSessionState(t){t.startObject(2)}static addGraphId(t,e){t.addFieldOffset(0,e,0)}static addSessionState(t,e){t.addFieldOffset(1,e,0)}static endSubGraphSessionState(t){let e=t.endObject();return t.requiredField(e,4),e}static createSubGraphSessionState(t,e,r){return n.startSubGraphSessionState(t),n.addGraphId(t,e),n.addSessionState(t,r),n.endSubGraphSessionState(t)}}e.SubGraphSessionState=n}(e.fbs||(e.fbs={}))}(t.experimental||(t.experimental={}))}(e.onnxruntime||(e.onnxruntime={})),function(t){!function(e){!function(e){class n{constructor(){this.bb=null,this.bb_pos=0}__init(t,e){return this.bb_pos=t,this.bb=e,this}static getRootAsSessionState(t,e){return(e||new n).__init(t.readInt32(t.position())+t.position(),t)}static getSizePrefixedRootAsSessionState(t,e){return t.setPosition(t.position()+r.flatbuffers.SIZE_PREFIX_LENGTH),(e||new n).__init(t.readInt32(t.position())+t.position(),t)}kernels(e){let n=this.bb.__offset(this.bb_pos,4);return n?(e||new t.experimental.fbs.KernelCreateInfos).__init(this.bb.__indirect(this.bb_pos+n),this.bb):null}subGraphSessionStates(e,n){let r=this.bb.__offset(this.bb_pos,6);return r?(n||new t.experimental.fbs.SubGraphSessionState).__init(this.bb.__indirect(this.bb.__vector(this.bb_pos+r)+4*e),this.bb):null}subGraphSessionStatesLength(){let t=this.bb.__offset(this.bb_pos,6);return t?this.bb.__vector_len(this.bb_pos+t):0}static startSessionState(t){t.startObject(2)}static addKernels(t,e){t.addFieldOffset(0,e,0)}static addSubGraphSessionStates(t,e){t.addFieldOffset(1,e,0)}static createSubGraphSessionStatesVector(t,e){t.startVector(4,e.length,4);for(let n=e.length-1;n>=0;n--)t.addOffset(e[n]);return t.endVector()}static startSubGraphSessionStatesVector(t,e){t.startVector(4,e,4)}static endSessionState(t){return t.endObject()}static createSessionState(t,e,r){return n.startSessionState(t),n.addKernels(t,e),n.addSubGraphSessionStates(t,r),n.endSessionState(t)}}e.SessionState=n}(e.fbs||(e.fbs={}))}(t.experimental||(t.experimental={}))}(e.onnxruntime||(e.onnxruntime={})),function(t){!function(e){!function(e){class n{constructor(){this.bb=null,this.bb_pos=0}__init(t,e){return this.bb_pos=t,this.bb=e,this}static getRootAsInferenceSession(t,e){return(e||new n).__init(t.readInt32(t.position())+t.position(),t)}static getSizePrefixedRootAsInferenceSession(t,e){return t.setPosition(t.position()+r.flatbuffers.SIZE_PREFIX_LENGTH),(e||new n).__init(t.readInt32(t.position())+t.position(),t)}static bufferHasIdentifier(t){return t.__has_identifier(\"ORTM\")}ortVersion(t){let e=this.bb.__offset(this.bb_pos,4);return e?this.bb.__string(this.bb_pos+e,t):null}model(e){let n=this.bb.__offset(this.bb_pos,6);return n?(e||new t.experimental.fbs.Model).__init(this.bb.__indirect(this.bb_pos+n),this.bb):null}sessionState(e){let n=this.bb.__offset(this.bb_pos,8);return n?(e||new t.experimental.fbs.SessionState).__init(this.bb.__indirect(this.bb_pos+n),this.bb):null}static startInferenceSession(t){t.startObject(3)}static addOrtVersion(t,e){t.addFieldOffset(0,e,0)}static addModel(t,e){t.addFieldOffset(1,e,0)}static addSessionState(t,e){t.addFieldOffset(2,e,0)}static endInferenceSession(t){return t.endObject()}static finishInferenceSessionBuffer(t,e){t.finish(e,\"ORTM\")}static finishSizePrefixedInferenceSessionBuffer(t,e){t.finish(e,\"ORTM\",!0)}static createInferenceSession(t,e,r,i){return n.startInferenceSession(t),n.addOrtVersion(t,e),n.addModel(t,r),n.addSessionState(t,i),n.endInferenceSession(t)}}e.InferenceSession=n}(e.fbs||(e.fbs={}))}(t.experimental||(t.experimental={}))}(e.onnxruntime||(e.onnxruntime={}))},7448:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.OnnxjsSessionHandler=void 0;const r=n(1670),i=n(9162);e.OnnxjsSessionHandler=class{constructor(t){this.session=t,this.inputNames=this.session.inputNames,this.outputNames=this.session.outputNames}async dispose(){}async run(t,e,n){const o=new Map;for(const e in t)if(Object.hasOwnProperty.call(t,e)){const n=t[e];o.set(e,new i.Tensor(n.dims,n.type,void 0,void 0,n.data))}const a=await this.session.run(o),s={};return a.forEach(((t,e)=>{s[e]=new r.Tensor(t.type,t.data,t.dims)})),s}startProfiling(){this.session.startProfiling()}endProfiling(){this.session.endProfiling()}}},6919:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.Session=void 0;const r=n(7067),i=n(1296),o=n(7091),a=n(1036),s=n(6231),u=n(2644);e.Session=class{constructor(t={}){this._initialized=!1,this.backendHint=t.backendHint,this.profiler=s.Profiler.create(t.profiler),this.context={profiler:this.profiler,graphInputTypes:[],graphInputDims:[]}}get inputNames(){return this._model.graph.getInputNames()}get outputNames(){return this._model.graph.getOutputNames()}startProfiling(){this.profiler.start()}endProfiling(){this.profiler.stop()}async loadModel(t,e,n){await this.profiler.event(\"session\",\"Session.loadModel\",(async()=>{const a=await(0,o.resolveBackend)(this.backendHint);if(this.sessionHandler=a.createSessionHandler(this.context),this._model=new u.Model,\"string\"==typeof t){const e=t.endsWith(\".ort\");if(\"undefined\"==typeof fetch){const n=await(0,i.promisify)(r.readFile)(t);this.initialize(n,e)}else{const n=await fetch(t),r=await n.arrayBuffer();this.initialize(new Uint8Array(r),e)}}else if(ArrayBuffer.isView(t))this.initialize(t);else{const r=new Uint8Array(t,e||0,n||t.byteLength);this.initialize(r)}}))}initialize(t,e){if(this._initialized)throw new Error(\"already initialized\");this.profiler.event(\"session\",\"Session.initialize\",(()=>{const n=this.sessionHandler.transformGraph?this.sessionHandler:void 0;this._model.load(t,n,e),this.sessionHandler.onGraphInitialized&&this.sessionHandler.onGraphInitialized(this._model.graph),this.initializeOps(this._model.graph),this._executionPlan=new a.ExecutionPlan(this._model.graph,this._ops,this.profiler)})),this._initialized=!0}async run(t){if(!this._initialized)throw new Error(\"session not initialized yet\");return this.profiler.event(\"session\",\"Session.run\",(async()=>{const e=this.normalizeAndValidateInputs(t),n=await this._executionPlan.execute(this.sessionHandler,e);return this.createOutput(n)}))}normalizeAndValidateInputs(t){const e=this._model.graph.getInputNames();if(Array.isArray(t)){if(t.length!==e.length)throw new Error(`incorrect input array length: expected ${e.length} but got ${t.length}`)}else{if(t.size!==e.length)throw new Error(`incorrect input map size: expected ${e.length} but got ${t.size}`);const n=new Array(t.size);let r=0;for(let i=0;i<e.length;++i){const o=t.get(e[i]);if(!o)throw new Error(`missing input tensor for: '${name}'`);n[r++]=o}t=n}if(this.context.graphInputTypes&&0!==this.context.graphInputTypes.length&&this.context.graphInputDims&&0!==this.context.graphInputDims.length)this.validateInputTensorDims(this.context.graphInputDims,t,!1);else{const e=this._model.graph.getInputIndices(),n=this._model.graph.getValues(),r=new Array(e.length);for(let i=0;i<e.length;++i){const o=n[e[i]];r[i]=o.type.shape.dims,this.context.graphInputTypes.push(o.type.tensorType),this.context.graphInputDims.push(t[i].dims)}this.validateInputTensorDims(r,t,!0)}return this.validateInputTensorTypes(this.context.graphInputTypes,t),t}validateInputTensorTypes(t,e){for(let n=0;n<e.length;n++){const r=t[n],i=e[n].type;if(r!==i)throw new Error(`input tensor[${n}] check failed: expected type '${r}' but got ${i}`)}}validateInputTensorDims(t,e,n){for(let r=0;r<e.length;r++){const i=t[r],o=e[r].dims;if(!this.compareTensorDims(i,o,n))throw new Error(`input tensor[${r}] check failed: expected shape '[${i.join(\",\")}]' but got [${o.join(\",\")}]`)}}compareTensorDims(t,e,n){if(t.length!==e.length)return!1;for(let r=0;r<t.length;++r)if(t[r]!==e[r]&&(!n||0!==t[r]))return!1;return!0}createOutput(t){const e=this._model.graph.getOutputNames();if(t.length!==e.length)throw new Error(\"expected number of outputs do not match number of generated outputs\");const n=new Map;for(let r=0;r<e.length;++r)n.set(e[r],t[r]);return n}initializeOps(t){const e=t.getNodes();this._ops=new Array(e.length);for(let n=0;n<e.length;n++)this._ops[n]=this.sessionHandler.resolve(e[n],this._model.opsets,t)}}},9162:function(t,e,n){\"use strict\";var r=this&&this.__importDefault||function(t){return t&&t.__esModule?t:{default:t}};Object.defineProperty(e,\"__esModule\",{value:!0}),e.Tensor=void 0;const i=n(3442),o=r(n(3720)),a=n(1446),s=n(9395),u=n(2517);var c=s.onnxruntime.experimental.fbs;class l{get data(){if(void 0===this.cache){const t=this.dataProvider(this.dataId);if(t.length!==this.size)throw new Error(\"Length of data provided by the Data Provider is inconsistent with the dims of this Tensor.\");this.cache=t}return this.cache}get stringData(){if(\"string\"!==this.type)throw new TypeError(\"data type is not string\");return this.data}get integerData(){switch(this.type){case\"uint8\":case\"int8\":case\"uint16\":case\"int16\":case\"int32\":case\"uint32\":case\"bool\":return this.data;default:throw new TypeError(\"data type is not integer (uint8, int8, uint16, int16, int32, uint32, bool)\")}}get floatData(){switch(this.type){case\"float32\":case\"float64\":return this.data;default:throw new TypeError(\"data type is not float (float32, float64)\")}}get numberData(){if(\"string\"!==this.type)return this.data;throw new TypeError(\"type cannot be non-number (string)\")}get(t){return this.data[u.ShapeUtil.indicesToOffset(t,this.strides)]}set(t,e){this.data[u.ShapeUtil.indicesToOffset(t,this.strides)]=e}async getData(){return void 0===this.cache&&(this.cache=await this.asyncDataProvider(this.dataId)),this.cache}get strides(){return this._strides||(this._strides=u.ShapeUtil.computeStrides(this.dims)),this._strides}constructor(t,e,n,r,o,a=i.Guid.create()){this.dims=t,this.type=e,this.dataProvider=n,this.asyncDataProvider=r,this.cache=o,this.dataId=a,this.size=u.ShapeUtil.validateDimsAndCalcSize(t);const s=this.size,c=void 0===n&&void 0===r&&void 0===o;if(void 0!==o&&o.length!==s)throw new RangeError(\"Input dims doesn't match data length.\");if(\"string\"===e){if(!(void 0===o||Array.isArray(o)&&o.every((t=>\"string\"==typeof t))))throw new TypeError(\"cache should be a string array\");c&&(this.cache=new Array(s))}else{if(void 0!==o){const t=f(e);if(!(o instanceof t))throw new TypeError(`cache should be type ${t.name}`)}if(c){const t=new ArrayBuffer(s*function(t){switch(t){case\"bool\":case\"int8\":case\"uint8\":return 1;case\"int16\":case\"uint16\":return 2;case\"int32\":case\"uint32\":case\"float32\":return 4;case\"float64\":return 8;default:throw new Error(`cannot calculate sizeof() on type ${t}`)}}(e));this.cache=function(t,e){return new(f(e))(t)}(t,e)}}}static fromProto(t){if(!t)throw new Error(\"cannot construct Value from an empty tensor\");const e=u.ProtoUtil.tensorDataTypeFromProto(t.dataType),n=u.ProtoUtil.tensorDimsFromProto(t.dims),r=new l(n,e);if(\"string\"===e)t.stringData.forEach(((t,e)=>{r.data[e]=(0,u.decodeUtf8String)(t)}));else if(t.rawData&&\"number\"==typeof t.rawData.byteLength&&t.rawData.byteLength>0){const e=r.data,n=new DataView(t.rawData.buffer,t.rawData.byteOffset,t.rawData.byteLength),i=p(t.dataType),o=t.rawData.byteLength/i;if(t.rawData.byteLength%i!=0)throw new Error(\"invalid buffer length\");if(e.length!==o)throw new Error(\"buffer length mismatch\");for(let r=0;r<o;r++){const o=h(n,t.dataType,r*i);e[r]=o}}else{let e;switch(t.dataType){case a.onnx.TensorProto.DataType.FLOAT:e=t.floatData;break;case a.onnx.TensorProto.DataType.INT32:case a.onnx.TensorProto.DataType.INT16:case a.onnx.TensorProto.DataType.UINT16:case a.onnx.TensorProto.DataType.INT8:case a.onnx.TensorProto.DataType.UINT8:case a.onnx.TensorProto.DataType.BOOL:e=t.int32Data;break;case a.onnx.TensorProto.DataType.INT64:e=t.int64Data;break;case a.onnx.TensorProto.DataType.DOUBLE:e=t.doubleData;break;case a.onnx.TensorProto.DataType.UINT32:case a.onnx.TensorProto.DataType.UINT64:e=t.uint64Data;break;default:throw new Error(\"unspecific error\")}if(null==e)throw new Error(\"failed to populate data from a tensorproto value\");const n=r.data;if(n.length!==e.length)throw new Error(\"array length mismatch\");for(let r=0;r<e.length;r++){const i=e[r];o.default.isLong(i)?n[r]=d(i,t.dataType):n[r]=i}}return r}static fromData(t,e,n){return new l(e,n,void 0,void 0,t)}static fromOrtTensor(t){if(!t)throw new Error(\"cannot construct Value from an empty tensor\");const e=u.ProtoUtil.tensorDimsFromORTFormat(t),n=u.ProtoUtil.tensorDataTypeFromProto(t.dataType()),r=new l(e,n);if(\"string\"===n)for(let e=0;e<t.stringDataLength();e++)r.data[e]=t.stringData(e);else if(t.rawDataArray()&&\"number\"==typeof t.rawDataLength()&&t.rawDataLength()>0){const e=r.data,n=new DataView(t.rawDataArray().buffer,t.rawDataArray().byteOffset,t.rawDataLength()),i=p(t.dataType()),o=t.rawDataLength()/i;if(t.rawDataLength()%i!=0)throw new Error(\"invalid buffer length\");if(e.length!==o)throw new Error(\"buffer length mismatch\");for(let r=0;r<o;r++){const o=h(n,t.dataType(),r*i);e[r]=o}}return r}}function p(t){switch(t){case a.onnx.TensorProto.DataType.UINT8:case a.onnx.TensorProto.DataType.INT8:case a.onnx.TensorProto.DataType.BOOL:return 1;case a.onnx.TensorProto.DataType.UINT16:case a.onnx.TensorProto.DataType.INT16:return 2;case a.onnx.TensorProto.DataType.FLOAT:case a.onnx.TensorProto.DataType.INT32:case a.onnx.TensorProto.DataType.UINT32:return 4;case a.onnx.TensorProto.DataType.INT64:case a.onnx.TensorProto.DataType.DOUBLE:case a.onnx.TensorProto.DataType.UINT64:return 8;default:throw new Error(`cannot calculate sizeof() on type ${a.onnx.TensorProto.DataType[t]}`)}}function f(t){switch(t){case\"bool\":case\"uint8\":return Uint8Array;case\"int8\":return Int8Array;case\"int16\":return Int16Array;case\"uint16\":return Uint16Array;case\"int32\":return Int32Array;case\"uint32\":return Uint32Array;case\"float32\":return Float32Array;case\"float64\":return Float64Array;default:throw new Error(\"unspecified error\")}}function d(t,e){if(e===a.onnx.TensorProto.DataType.INT64||e===c.TensorDataType.INT64){if(t.greaterThanOrEqual(2147483648)||t.lessThan(-2147483648))throw new TypeError(\"int64 is not supported\")}else{if(e!==a.onnx.TensorProto.DataType.UINT32&&e!==c.TensorDataType.UINT32&&e!==a.onnx.TensorProto.DataType.UINT64&&e!==c.TensorDataType.UINT64)throw new TypeError(`not a LONG type: ${a.onnx.TensorProto.DataType[e]}`);if(t.greaterThanOrEqual(4294967296)||t.lessThan(0))throw new TypeError(\"uint64 is not supported\")}return t.toNumber()}function h(t,e,n){switch(e){case a.onnx.TensorProto.DataType.BOOL:case a.onnx.TensorProto.DataType.UINT8:return t.getUint8(n);case a.onnx.TensorProto.DataType.INT8:return t.getInt8(n);case a.onnx.TensorProto.DataType.UINT16:return t.getUint16(n,!0);case a.onnx.TensorProto.DataType.INT16:return t.getInt16(n,!0);case a.onnx.TensorProto.DataType.FLOAT:return t.getFloat32(n,!0);case a.onnx.TensorProto.DataType.INT32:return t.getInt32(n,!0);case a.onnx.TensorProto.DataType.UINT32:return t.getUint32(n,!0);case a.onnx.TensorProto.DataType.INT64:return d(o.default.fromBits(t.getUint32(n,!0),t.getUint32(n+4,!0),!1),e);case a.onnx.TensorProto.DataType.DOUBLE:return t.getFloat64(n,!0);case a.onnx.TensorProto.DataType.UINT64:return d(o.default.fromBits(t.getUint32(n,!0),t.getUint32(n+4,!0),!0),e);default:throw new Error(`cannot read from DataView for type ${a.onnx.TensorProto.DataType[e]}`)}}e.Tensor=l},2517:function(t,e,n){\"use strict\";var r=this&&this.__importDefault||function(t){return t&&t.__esModule?t:{default:t}};Object.defineProperty(e,\"__esModule\",{value:!0}),e.decodeUtf8String=e.MAX_CLIP=e.MIN_CLIP=e.PoolConvUtil=e.ReduceUtil=e.SplitUtil=e.MathUtil=e.ShapeUtil=e.LongUtil=e.ProtoUtil=e.GemmUtil=e.arrayCopyHelper=e.BroadcastUtil=e.MatMulUtil=e.ArrayUtil=e.assert=e.checkInputsShape=void 0;const i=n(5686),o=r(n(3720)),a=n(1446),s=n(9162);e.checkInputsShape=function(t,...e){if(!t||t.length!==e.length)return!1;for(let n=0;n<t.length;n++)if(!t[n].dims||t[n].dims.length!==e[n])return!1;return!0},e.assert=function(t,e){if(!t)throw new Error(\"string\"==typeof e?e:e())},e.ArrayUtil=class{static arraysEqual(t,e){if(t.length!==e.length)return!1;for(let n=0;n<t.length;n++)if(t[n]!==e[n])return!1;return!0}};class u{static preprocessInputShapes(t,e){return[1===t.length?[1,t[0]]:t,1===e.length?[e[0],1]:e]}static postprocessOutputShape(t,e,n){1===e&&t.splice(t.length-2,1),1===n&&t.pop()}static calcMatMulShape(t,e){return t[1]!==e[0]?void 0:[t[0],e[1]]}}e.MatMulUtil=u;class c{static calcShape(t,e,n=!1){const r=t.length,i=e.length;if(0===r)return e;if(0===i)return t;const o=Math.max(t.length,e.length),a=new Array(o);if(n){if(r<2||i<2)return;const n=u.calcMatMulShape([t[r-2],t[r-1]],[e[i-2],e[i-1]]);if(void 0===n)return;[a[o-2],a[o-1]]=n}for(let s=n?3:1;s<=o;s++){const n=r-s<0?1:t[r-s],u=i-s<0?1:e[i-s];if(n!==u&&n>1&&u>1)return;a[o-s]=Math.max(n,u)}return a}static index(t,e){const n=new Array(e.length);return c.fillIndex(t,e,n),n}static fillIndex(t,e,n){const r=t.length-e.length;for(let i=0;i<e.length;i++)n[i]=t[r+i]%e[i]}static calc(t,e,n,r,i){const o=c.calcShape(t.dims,e.dims);if(o){if(r&&!f.areEqual(o,t.dims))return;const a=f.size(o),u=r?t:new s.Tensor(o,i||t.type);if(0===o.length)u.set([],n(t.get([]),e.get([])));else{const r=new Array(o.length),i=new Array(t.dims.length),s=new Array(e.dims.length);let l,p=0,f=0,d=!1,h=!1;0===t.dims.length&&(p=t.get([]),d=!0),0===e.dims.length&&(f=e.get([]),h=!0);for(let g=0;g<a;g++){l=g;for(let t=o.length-1;t>=0;t--)r[t]=l%o[t],l=Math.floor(l/o[t]);d||(c.fillIndex(r,t.dims,i),p=t.get(i)),h||(c.fillIndex(r,e.dims,s),f=e.get(s)),u.set(r,n(p,f))}}return u}}static isValidBroadcast(t,e){const n=t.length,r=e.length;if(n>r)return!1;for(let i=1;i<=n;i++)if(1!==t[n-i]&&t[n-i]!==e[r-i])return!1;return!0}static getBroadcastDims(t,e){const n=t.length,r=[];for(let i=0;i<n;i++){const o=n-1-i,a=t[o]||1;(e[e.length-1-i]||1)>1&&1===a&&r.unshift(o)}return r}}e.BroadcastUtil=c,e.arrayCopyHelper=function(t,e,n,r,i){if(r<0||r>=e.length)throw new Error(\"sourceIndex out of bounds\");if(n<0||n>=t.length)throw new Error(\"targetIndex out of bounds\");if(r+i>e.length)throw new Error(\"source indices to be copied are outside bounds\");if(n+i>t.length)throw new Error(\"target array is too small to hold result\");for(let o=0;o<i;o++)t[n+o]=e[r+o]},e.GemmUtil=class{static getShapeOfGemmResult(t,e,n,r,i){if(2!==t.length||2!==n.length)throw new Error(\"shape need to be of size 2\");let o,a,s;e?(o=t[1],a=t[0]):(o=t[0],a=t[1]);let u=-1;if(r?(s=n[0],u=1):(s=n[1],u=0),n[u]!==a)throw new Error(\"dimension mismatch\");if(o<=0||s<=0||a<=0)throw new Error(\"invalid shape specified\");if(i&&!c.isValidBroadcast(i,[o,s]))throw new Error(\"gemm: invalid bias shape for broadcast\");return[o,s,a]}};class l{static tensorDataTypeFromProto(t){switch(t){case a.onnx.TensorProto.DataType.INT8:return\"int8\";case a.onnx.TensorProto.DataType.UINT8:return\"uint8\";case a.onnx.TensorProto.DataType.BOOL:return\"bool\";case a.onnx.TensorProto.DataType.INT16:return\"int16\";case a.onnx.TensorProto.DataType.UINT16:return\"uint16\";case a.onnx.TensorProto.DataType.INT32:return\"int32\";case a.onnx.TensorProto.DataType.UINT32:return\"uint32\";case a.onnx.TensorProto.DataType.FLOAT:return\"float32\";case a.onnx.TensorProto.DataType.DOUBLE:return\"float64\";case a.onnx.TensorProto.DataType.STRING:return\"string\";case a.onnx.TensorProto.DataType.INT64:return\"int32\";case a.onnx.TensorProto.DataType.UINT64:return\"uint32\";default:throw new Error(`unsupported data type: ${a.onnx.TensorProto.DataType[t]}`)}}static tensorDataTypeStringToEnum(t){switch(t){case\"int8\":return a.onnx.TensorProto.DataType.INT8;case\"uint8\":return a.onnx.TensorProto.DataType.UINT8;case\"bool\":return a.onnx.TensorProto.DataType.BOOL;case\"int16\":return a.onnx.TensorProto.DataType.INT16;case\"uint16\":return a.onnx.TensorProto.DataType.UINT16;case\"int32\":return a.onnx.TensorProto.DataType.INT32;case\"uint32\":return a.onnx.TensorProto.DataType.UINT32;case\"float32\":return a.onnx.TensorProto.DataType.FLOAT;case\"float64\":return a.onnx.TensorProto.DataType.DOUBLE;case\"string\":return a.onnx.TensorProto.DataType.STRING;case\"int64\":return a.onnx.TensorProto.DataType.INT64;case\"uint64\":return a.onnx.TensorProto.DataType.UINT64;default:throw new Error(`unsupported data type: ${t}`)}}static tensorDimsFromProto(t){return t.map((t=>o.default.isLong(t)?t.toNumber():t))}static tensorValueTypeFromProto(t){return{tensorType:l.tensorDataTypeFromProto(t.elemType),shape:{dims:l.tensorDimsFromProto(t.shape.dim.map((t=>t.dimValue)))}}}static tensorDimsFromORTFormat(t){const e=[];for(let n=0;n<t.dimsLength();n++)e.push(p.longToNumber(t.dims(n)));return e}static tensorAttributesFromORTFormat(t){const e=[];for(let n=0;n<t.attributesLength();n++)e.push(t.attributes(n));return e}}e.ProtoUtil=l;class p{static longToNumber(t,e){return o.default.isLong(t)?t.toNumber():t instanceof i.flatbuffers.Long?o.default.fromValue({low:t.low,high:t.high,unsigned:null!=e&&e}).toNumber():t}static isLong(t){return o.default.isLong(t)||t instanceof i.flatbuffers.Long}}e.LongUtil=p;class f{static size(t){return f.getSizeFromDimensionRange(t,0,t.length)}static sizeFromDimension(t,e){if(e<0||e>t.length)throw new Error(`invalid dimension of ${e} for sizeFromDimension as Tensor has ${t.length} dimensions.`);return f.getSizeFromDimensionRange(t,e,t.length)}static sizeToDimension(t,e){if(e<0||e>t.length)throw new Error(`invalid dimension of ${e} for sizeToDimension as Tensor has ${t.length} dimensions.`);return f.getSizeFromDimensionRange(t,0,e)}static getSizeFromDimensionRange(t,e,n){let r=1;for(let i=e;i<n;i++){if(t[i]<=0)throw new Error(\"cannot get valid size from specified dimension range. Most likely the range contains 0 or negative values in them.\");r*=t[i]}return r}static computeStrides(t){const e=t.length;if(0===e)return[];if(1===e)return[1];const n=new Array(e);n[e-1]=1,n[e-2]=t[e-1];for(let r=e-3;r>=0;--r)n[r]=n[r+1]*t[r+1];return n}static transpose(t){return t.slice().reverse()}static indicesToOffset(t,e,n){void 0===n&&(n=t.length);let r=0;for(let i=0;i<n;++i)r+=e[i]*t[i];return r}static offsetToIndices(t,e){const n=e.length;if(0===n)return[];if(1===n)return[t*e[0]];const r=new Array(e.length);for(let n=0;n<r.length-1;++n)r[n]=Math.floor(t/e[n]),t-=r[n]*e[n];return r[r.length-1]=t,r}static normalizeAxis(t,e){if(t<-e&&t>=e)throw new Error(\"unsupported axis for this operation.\");return t<0?t+e:t}static normalizeAxes(t,e){return t.map((t=>this.normalizeAxis(t,e)))}static incrementIndex(t,e,n){if(0===e.length||0===t.length)throw new Error(\"Index incrementing unsupported for scalar Tensor\");if(void 0===n)n=e.length;else if(n<=0||n>e.length)throw new Error(\"Incorrect axis to increment on\");for(let r=n-1;r>=0&&(t[r]++,!(t[r]<e[r]));--r)t[r]=0}static calculateReshapedDims(t,e){if(0===e.length){if(0===t.length||1===f.size(t))return[];throw new Error(\"cannot reshape to a scalar Tensor\")}const n=e.length,r=new Array(n);let i=-1,o=1;for(let a=0;a<n;a++){if(e[a]<-1)throw new Error(\"a dimension in shape hints cannot be less than -1\");if(-1===e[a]){if(-1!==i)throw new Error(\"at most one dimension in shape hints can be -1\");i=a}else{if(0===e[a]){if(a>=t.length)throw new Error(\"the dimension with value zero exceeds the dimension size of the input tensor\");r[a]=t[a]}else r[a]=e[a];o*=r[a]}}const a=f.size(t);if(-1!==i){if(a%o!=0)throw new Error(`the input tensor cannot be reshaped to the requested shape. Input shape: [${t}] Output shape: [${e}]`);r[i]=a/o}else if(o!==a)throw new Error(\"reshapedDims and originalDims don't have matching sizes\");return r}static sortBasedOnPerm(t,e){return e?e.map((e=>t[e])):t.slice().reverse()}static padShape(t,e){const n=t.length;return t.map(((t,r)=>t+e[r]+e[r+n]))}static areEqual(t,e){return t.length===e.length&&t.every(((t,n)=>t===e[n]))}static validateDimsAndCalcSize(t){if(t.length>6)throw new TypeError(\"Only rank 0 to 6 is supported for tensor shape.\");let e=1;for(const n of t){if(!Number.isInteger(n))throw new TypeError(`Invalid shape: ${n} is not an integer`);if(n<0||n>2147483647)throw new TypeError(`Invalid shape: length ${n} is not allowed`);e*=n}return e}static flattenShape(t,e){e<0&&(e+=t.length);const n=t.reduce(((t,e)=>t*e),1),r=t.slice(e).reduce(((t,e)=>t*e),1);return[n/r,r]}static squeezeShape(t,e){const n=new Array;e=f.normalizeAxes(e,t.length);for(let r=0;r<t.length;r++){const i=e.indexOf(r)>=0;if(i&&1!==t[r])throw new Error(\"squeeze an axis of size different than 1\");(0===e.length&&t[r]>1||e.length>0&&!i)&&n.push(t[r])}return n}static unsqueezeShape(t,e){const n=new Array(t.length+e.length);n.fill(0);for(let t=0;t<e.length;t++){const r=f.normalizeAxis(e[t],n.length);if(r>=n.length)throw new Error(\"'axes' has an out of range axis\");if(0!==n[r])throw new Error(\"'axes' has a duplicate axis\");n[r]=1}let r=0;for(let e=0;e<n.length;e++)0===n[e]&&(n[e]=t[r++]);if(r!==t.length)throw new Error(\"the unsqueezed dimension could not be established\");return n}}e.ShapeUtil=f,e.MathUtil=class{static sqr(t,e,n,r,i){if(r<0||r>=e.length)throw new Error(\"sourceIndex out of bounds\");if(n<0||n>=t.length)throw new Error(\"targetIndex out of bounds\");if(r+i>e.length)throw new Error(\"source indices to be copied are outside bounds\");if(n+i>t.length)throw new Error(\"target array is too small to hold result\");for(let o=0;o<i;o++)t[n+o]+=Math.pow(e[r+o],2)}static axpy(t,e,n,r,i,o){if(r<0||r>=e.length)throw new Error(\"sourceIndex out of bounds\");if(n<0||n>=t.length)throw new Error(\"targetIndex out of bounds\");if(r+i>e.length)throw new Error(\"source indices to be copied are outside bounds\");if(n+i>t.length)throw new Error(\"target array is too small to hold result\");for(let a=0;a<i;a++)t[n+a]+=o*e[r+a]}static powx(t,e,n,r,i,o){if(r<0||r>=e.length)throw new Error(\"sourceIndex out of bounds\");if(n<0||n>=t.length)throw new Error(\"targetIndex out of bounds\");if(r+i>e.length)throw new Error(\"source indices to be copied are outside bounds\");if(n+i>t.length)throw new Error(\"target array is too small to hold result\");for(let a=0;a<i;a++)t[n+a]=Math.pow(e[r+a],o)}static mul(t,e,n,r,i){if(r<0||r>=e.length)throw new Error(\"sourceIndex out of bounds\");if(n<0||n>=t.length)throw new Error(\"targetIndex out of bounds\");if(r+i>e.length)throw new Error(\"source indices to be copied are outside bounds\");if(n+i>t.length)throw new Error(\"target array is too small to hold result\");for(let o=0;o<i;o++)t[n+o]=e[r+o]*t[n+o]}};class d{static splitShape(t,e,n,r){if(0===n.length){if(!r)throw new Error(\"need to know number of outputs when the 'split' attribute is not specified\");d.determineSplit(t[e],r,n)}const i=[],o=[0];for(let r=0;r<n.length;++r){0!==r&&o.push(o[r-1]+n[r-1]);const a=t.slice();a[e]=n[r],i.push(a)}return[i,o]}static determineSplit(t,e,n){if(t%e!=0)throw new Error(\"cannot split tensor to equal sized parts\");for(let r=0;r<e;++r)n.push(t/e)}}e.SplitUtil=d;class h{static calcReduce(t,e,n,r,i){const o=t.dims.slice(0);0===e.length&&o.forEach(((t,n)=>e.push(n)));const a=h.calcReduceShape(o,e,!0),u=f.size(a),l=new s.Tensor(a,t.type),p=f.computeStrides(a),d=f.computeStrides(o),g=new Array(o.length);for(let n=0;n<u;n++){const a=f.offsetToIndices(n,p);c.fillIndex(a,o,g),l.set(a,h.calcReduceByAxis(t.numberData,e,o,0,f.indicesToOffset(g,d),r,i))}return n?l:new s.Tensor(h.calcReduceShape(o,e,n),l.type,void 0,void 0,l.data,l.dataId)}static calcReduceByAxis(t,e,n,r,i,o,a){let s=0;if(r>=e.length)return o(t[i]);const u=e[r],c=u>=n.length?1:f.size(n.slice(u+1));for(let l=0;l<n[u];l++)s=0===l?h.calcReduceByAxis(t,e,n,r+1,i,o,a):a(s,h.calcReduceByAxis(t,e,n,r+1,i,o,a)),i+=c;return s}static calcReduceShape(t,e,n){const r=t.slice();for(let t=0;t<e.length;t++)r[e[t]]=n?1:0;return r.filter((t=>0!==t))}}e.ReduceUtil=h;class g{static adjustPoolAttributes(t,e,n,r,i,o){if(!t&&n.length!==e.length-2)throw new Error(\"length of specified kernel shapes should be 2 less than length of input dimensions\");if(t)for(let t=0;t<e.length-2;t++)t>=n.length?n.push(e[t+2]):n[t]=e[t+2];for(let t=0;t<n.length;t++)if(t<r.length){if(r[t]<0)throw new Error(\"strides should be greater than or equal to 1\")}else r.push(1);for(let t=0;t<n.length;t++)if(t<i.length){if(i[t]<0)throw new Error(\"dilations should be greater than or equal to 1\")}else i.push(1);for(let t=0;t<2*n.length;t++)if(t<o.length){if(o[t]<0)throw new Error(\"pad should be greater than or equal to 1\")}else o.push(0);for(let t=0;t<n.length;t++){if(n[t]<=0)throw new Error(\"kernel shapes need to be greater than 0\");if(o[t]>=n[t]||o[t+n.length]>=n[t])throw new Error(\"pads should be smaller than kernel\")}}static adjustPadsBasedOnAutoPad(t,e,n,r,i,o){if(o){if(i.length!==2*(t.length-2))throw new Error(\"length of pads should be twice the length of data dimensions\");if(e.length!==t.length-2)throw new Error(\"length of strides should be the length of data dimensions\");if(r.length!==t.length-2)throw new Error(\"length of kernel shapes should be the length of data dimensions\");for(let a=0;a<t.length-2;a++)g.adjustPadAndReturnShape(t[a+2],e[a],n[a],r[a],i,a,a+t.length-2,o)}}static computePoolOutputShape(t,e,n,r,i,o,a){if(e.length<=0)throw new Error(\"input shape must be of size greater than 0\");const s=[e[0],e[1]];return g.computeShapeHelper(t,e,s,n,r,i,o,a),s}static computeConvOutputShape(t,e,n,r,i,o,a){if(t.length<=0||e.length<=0)throw new Error(\"invalid input tensor dims or invalid filter tensor dims\");const s=[t[0],e[0]];return g.computeShapeHelper(!1,t,s,n,r,i,o,a),s}static computeShapeHelper(t,e,n,r,i,o,a,s){if(t)for(let t=0;t<e.length-2;t++)n.push(1);else for(let t=0;t<e.length-2;t++)n.push(g.adjustPadAndReturnShape(e[t+2],r[t],i[t],o[t],a,t,t+e.length-2,s))}static adjustPadAndReturnShape(t,e,n,r,i,o,a,s){const u=n*(r-1)+1;if(!s||\"NOTSET\"===s)return Math.floor((t+i[o]+i[a]-u)/e+1);switch(s){case\"VALID\":return i[o]=0,i[a]=0,Math.floor((t-u)/e+1);case\"SAME_LOWER\":case\"SAME_UPPER\":if(1!==n)throw new Error(\"Dilation not supported for SAME_UPPER or SAME_LOWER\");{const n=((t+e-1)/e-1)*e+r-t;return i[o]=\"SAME_LOWER\"===s?Math.floor((n+1)/2):Math.floor(n/2),i[a]=n-i[o],Math.floor((t+n-r)/e+1)}default:throw new Error(\"Unsupported AutoPad type\")}}}e.PoolConvUtil=g,e.MIN_CLIP=-34028234663852886e22,e.MAX_CLIP=34028234663852886e22,e.decodeUtf8String=function(t){return(new TextDecoder).decode(t)}},7967:(t,e)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.iterateExtraOptions=void 0,e.iterateExtraOptions=(t,n,r,i)=>{if(\"object\"==typeof t&&null!==t){if(r.has(t))throw new Error(\"Circular reference in options\");r.add(t)}Object.entries(t).forEach((([t,o])=>{const a=n?n+t:t;if(\"object\"==typeof o)(0,e.iterateExtraOptions)(o,a+\".\",r,i);else if(\"string\"==typeof o||\"number\"==typeof o)i(a,o.toString());else{if(\"boolean\"!=typeof o)throw new Error(\"Can't handle extra config type: \"+typeof o);i(a,o?\"1\":\"0\")}}))}},2157:function(t,e,n){\"use strict\";var r,i=this&&this.__createBinding||(Object.create?function(t,e,n,r){void 0===r&&(r=n);var i=Object.getOwnPropertyDescriptor(e,n);i&&!(\"get\"in i?!e.__esModule:i.writable||i.configurable)||(i={enumerable:!0,get:function(){return e[n]}}),Object.defineProperty(t,r,i)}:function(t,e,n,r){void 0===r&&(r=n),t[r]=e[n]}),o=this&&this.__setModuleDefault||(Object.create?function(t,e){Object.defineProperty(t,\"default\",{enumerable:!0,value:e})}:function(t,e){t.default=e}),a=this&&this.__importStar||function(t){if(t&&t.__esModule)return t;var e={};if(null!=t)for(var n in t)\"default\"!==n&&Object.prototype.hasOwnProperty.call(t,n)&&i(e,t,n);return o(e,t),e};Object.defineProperty(e,\"__esModule\",{value:!0}),e.endProfiling=e.run=e.releaseSession=e.createSession=e.createSessionFinalize=e.createSessionAllocate=e.initOrt=e.initWasm=void 0;const s=n(1670),u=a(n(349)),c=n(6361),l=()=>!!s.env.wasm.proxy&&\"undefined\"!=typeof document;let p,f,d,h=!1,g=!1,b=!1;const m=[],y=[],_=[],v=[],w=[],x=[],T=()=>{if(h||!g||b||!p)throw new Error(\"worker not ready\")},S=t=>{switch(t.data.type){case\"init-wasm\":h=!1,t.data.err?(b=!0,f[1](t.data.err)):(g=!0,f[0]());break;case\"init-ort\":t.data.err?d[1](t.data.err):d[0]();break;case\"create_allocate\":t.data.err?m.shift()[1](t.data.err):m.shift()[0](t.data.out);break;case\"create_finalize\":t.data.err?y.shift()[1](t.data.err):y.shift()[0](t.data.out);break;case\"create\":t.data.err?_.shift()[1](t.data.err):_.shift()[0](t.data.out);break;case\"release\":t.data.err?v.shift()[1](t.data.err):v.shift()[0]();break;case\"run\":t.data.err?w.shift()[1](t.data.err):w.shift()[0](t.data.out);break;case\"end-profiling\":t.data.err?x.shift()[1](t.data.err):x.shift()[0]()}},O=\"undefined\"!=typeof document?null===(r=null===document||void 0===document?void 0:document.currentScript)||void 0===r?void 0:r.src:void 0;e.initWasm=async()=>{if(l()){if(g)return;if(h)throw new Error(\"multiple calls to 'initWasm()' detected.\");if(b)throw new Error(\"previous call to 'initWasm()' failed.\");return h=!0,void 0===s.env.wasm.wasmPaths&&O&&0!==O.indexOf(\"blob:\")&&(s.env.wasm.wasmPaths=O.substr(0,+O.lastIndexOf(\"/\")+1)),new Promise(((t,e)=>{null==p||p.terminate(),p=n(9710).Z(),p.onmessage=S,f=[t,e];const r={type:\"init-wasm\",in:s.env.wasm};p.postMessage(r)}))}return(0,c.initializeWebAssembly)(s.env.wasm)},e.initOrt=async(t,e)=>{if(l())return T(),new Promise(((n,r)=>{d=[n,r];const i={type:\"init-ort\",in:{numThreads:t,loggingLevel:e}};p.postMessage(i)}));u.initOrt(t,e)},e.createSessionAllocate=async t=>l()?(T(),new Promise(((e,n)=>{m.push([e,n]);const r={type:\"create_allocate\",in:{model:t}};p.postMessage(r,[t.buffer])}))):u.createSessionAllocate(t),e.createSessionFinalize=async(t,e)=>l()?(T(),new Promise(((n,r)=>{y.push([n,r]);const i={type:\"create_finalize\",in:{modeldata:t,options:e}};p.postMessage(i)}))):u.createSessionFinalize(t,e),e.createSession=async(t,e)=>l()?(T(),new Promise(((n,r)=>{_.push([n,r]);const i={type:\"create\",in:{model:t,options:e}};p.postMessage(i,[t.buffer])}))):u.createSession(t,e),e.releaseSession=async t=>{if(l())return T(),new Promise(((e,n)=>{v.push([e,n]);const r={type:\"release\",in:t};p.postMessage(r)}));u.releaseSession(t)},e.run=async(t,e,n,r,i)=>l()?(T(),new Promise(((o,a)=>{w.push([o,a]);const s={type:\"run\",in:{sessionId:t,inputIndices:e,inputs:n,outputIndices:r,options:i}};p.postMessage(s,u.extractTransferableBuffers(n))}))):u.run(t,e,n,r,i),e.endProfiling=async t=>{if(l())return T(),new Promise(((e,n)=>{x.push([e,n]);const r={type:\"end-profiling\",in:t};p.postMessage(r)}));u.endProfiling(t)}},586:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.setRunOptions=void 0;const r=n(7967),i=n(4983),o=n(6361);e.setRunOptions=t=>{const e=(0,o.getInstance)();let n=0;const a=[],s=t||{};try{if(void 0===(null==t?void 0:t.logSeverityLevel))s.logSeverityLevel=2;else if(\"number\"!=typeof t.logSeverityLevel||!Number.isInteger(t.logSeverityLevel)||t.logSeverityLevel<0||t.logSeverityLevel>4)throw new Error(`log serverity level is not valid: ${t.logSeverityLevel}`);if(void 0===(null==t?void 0:t.logVerbosityLevel))s.logVerbosityLevel=0;else if(\"number\"!=typeof t.logVerbosityLevel||!Number.isInteger(t.logVerbosityLevel))throw new Error(`log verbosity level is not valid: ${t.logVerbosityLevel}`);void 0===(null==t?void 0:t.terminate)&&(s.terminate=!1);let o=0;if(void 0!==(null==t?void 0:t.tag)&&(o=(0,i.allocWasmString)(t.tag,a)),n=e._OrtCreateRunOptions(s.logSeverityLevel,s.logVerbosityLevel,!!s.terminate,o),0===n)throw new Error(\"Can't create run options\");return void 0!==(null==t?void 0:t.extra)&&(0,r.iterateExtraOptions)(t.extra,\"\",new WeakSet,((t,r)=>{const o=(0,i.allocWasmString)(t,a),s=(0,i.allocWasmString)(r,a);if(0!==e._OrtAddRunConfigEntry(n,o,s))throw new Error(`Can't set a run config entry: ${t} - ${r}`)})),[n,a]}catch(t){throw 0!==n&&e._OrtReleaseRunOptions(n),a.forEach(e._free),t}}},2306:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.OnnxruntimeWebAssemblySessionHandler=void 0;const r=n(2806),i=n(1670),o=n(2850),a=n(2157);let s;e.OnnxruntimeWebAssemblySessionHandler=class{async createSessionAllocate(t){const e=await fetch(t),n=await e.arrayBuffer();return(0,a.createSessionAllocate)(new Uint8Array(n))}async loadModel(t,e){if(s||(await(0,a.initOrt)(i.env.wasm.numThreads,(t=>{switch(t){case\"verbose\":return 0;case\"info\":return 1;case\"warning\":return 2;case\"error\":return 3;case\"fatal\":return 4;default:throw new Error(`unsupported logging level: ${t}`)}})(i.env.logLevel)),s=!0),\"string\"==typeof t)if(\"undefined\"==typeof fetch){const n=await(0,o.promisify)(r.readFile)(t);[this.sessionId,this.inputNames,this.outputNames]=await(0,a.createSession)(n,e)}else{const n=await this.createSessionAllocate(t);[this.sessionId,this.inputNames,this.outputNames]=await(0,a.createSessionFinalize)(n,e)}else[this.sessionId,this.inputNames,this.outputNames]=await(0,a.createSession)(t,e)}async dispose(){return(0,a.releaseSession)(this.sessionId)}async run(t,e,n){const r=[],o=[];Object.entries(t).forEach((t=>{const e=t[0],n=t[1],i=this.inputNames.indexOf(e);if(-1===i)throw new Error(`invalid input '${e}'`);r.push(n),o.push(i)}));const s=[];Object.entries(e).forEach((t=>{const e=t[0],n=this.outputNames.indexOf(e);if(-1===n)throw new Error(`invalid output '${e}'`);s.push(n)}));const u=await(0,a.run)(this.sessionId,o,r.map((t=>[t.type,t.dims,t.data])),s,n),c={};for(let t=0;t<u.length;t++)c[this.outputNames[s[t]]]=new i.Tensor(u[t][0],u[t][2],u[t][1]);return c}startProfiling(){}endProfiling(){(0,a.endProfiling)(this.sessionId)}}},4919:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.setSessionOptions=void 0;const r=n(7967),i=n(4983),o=n(6361);e.setSessionOptions=t=>{const e=(0,o.getInstance)();let n=0;const a=[],s=t||{};(t=>{t.extra||(t.extra={}),t.extra.session||(t.extra.session={});const e=t.extra.session;e.use_ort_model_bytes_directly||(e.use_ort_model_bytes_directly=\"1\")})(s);try{void 0===(null==t?void 0:t.graphOptimizationLevel)&&(s.graphOptimizationLevel=\"all\");const u=(t=>{switch(t){case\"disabled\":return 0;case\"basic\":return 1;case\"extended\":return 2;case\"all\":return 99;default:throw new Error(`unsupported graph optimization level: ${t}`)}})(s.graphOptimizationLevel);void 0===(null==t?void 0:t.enableCpuMemArena)&&(s.enableCpuMemArena=!0),void 0===(null==t?void 0:t.enableMemPattern)&&(s.enableMemPattern=!0),void 0===(null==t?void 0:t.executionMode)&&(s.executionMode=\"sequential\");const c=(t=>{switch(t){case\"sequential\":return 0;case\"parallel\":return 1;default:throw new Error(`unsupported execution mode: ${t}`)}})(s.executionMode);let l=0;if(void 0!==(null==t?void 0:t.logId)&&(l=(0,i.allocWasmString)(t.logId,a)),void 0===(null==t?void 0:t.logSeverityLevel))s.logSeverityLevel=2;else if(\"number\"!=typeof t.logSeverityLevel||!Number.isInteger(t.logSeverityLevel)||t.logSeverityLevel<0||t.logSeverityLevel>4)throw new Error(`log serverity level is not valid: ${t.logSeverityLevel}`);if(void 0===(null==t?void 0:t.logVerbosityLevel))s.logVerbosityLevel=0;else if(\"number\"!=typeof t.logVerbosityLevel||!Number.isInteger(t.logVerbosityLevel))throw new Error(`log verbosity level is not valid: ${t.logVerbosityLevel}`);if(void 0===(null==t?void 0:t.enableProfiling)&&(s.enableProfiling=!1),n=e._OrtCreateSessionOptions(u,!!s.enableCpuMemArena,!!s.enableMemPattern,c,!!s.enableProfiling,0,l,s.logSeverityLevel,s.logVerbosityLevel),0===n)throw new Error(\"Can't create session options\");return(null==t?void 0:t.executionProviders)&&((t,e,n)=>{for(const r of e){let e=\"string\"==typeof r?r:r.name;switch(e){case\"xnnpack\":e=\"XNNPACK\";break;case\"wasm\":case\"cpu\":continue;default:throw new Error(`not supported EP: ${e}`)}const a=(0,i.allocWasmString)(e,n);if(0!==(0,o.getInstance)()._OrtAppendExecutionProvider(t,a))throw new Error(`Can't append execution provider: ${e}`)}})(n,t.executionProviders,a),void 0!==(null==t?void 0:t.extra)&&(0,r.iterateExtraOptions)(t.extra,\"\",new WeakSet,((t,r)=>{const o=(0,i.allocWasmString)(t,a),s=(0,i.allocWasmString)(r,a);if(0!==e._OrtAddSessionConfigEntry(n,o,s))throw new Error(`Can't set a session config entry: ${t} - ${r}`)})),[n,a]}catch(t){throw 0!==n&&e._OrtReleaseSessionOptions(n),a.forEach(e._free),t}}},4983:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.allocWasmString=void 0;const r=n(6361);e.allocWasmString=(t,e)=>{const n=(0,r.getInstance)(),i=n.lengthBytesUTF8(t)+1,o=n._malloc(i);return n.stringToUTF8(t,o,i),e.push(o),o}},349:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.extractTransferableBuffers=e.endProfiling=e.run=e.releaseSession=e.createSession=e.createSessionFinalize=e.createSessionAllocate=e.initOrt=void 0;const r=n(586),i=n(4919),o=n(4983),a=n(6361);e.initOrt=(t,e)=>{const n=(0,a.getInstance)()._OrtInit(t,e);if(0!==n)throw new Error(`Can't initialize onnxruntime. error code = ${n}`)};const s=new Map;e.createSessionAllocate=t=>{const e=(0,a.getInstance)(),n=e._malloc(t.byteLength);return e.HEAPU8.set(t,n),[n,t.byteLength]},e.createSessionFinalize=(t,e)=>{const n=(0,a.getInstance)();let r=0,o=0,u=[];try{if([o,u]=(0,i.setSessionOptions)(e),r=n._OrtCreateSession(t[0],t[1],o),0===r)throw new Error(\"Can't create a session\")}finally{n._free(t[0]),n._OrtReleaseSessionOptions(o),u.forEach(n._free)}const c=n._OrtGetInputCount(r),l=n._OrtGetOutputCount(r),p=[],f=[],d=[],h=[];for(let t=0;t<c;t++){const e=n._OrtGetInputName(r,t);if(0===e)throw new Error(\"Can't get an input name\");f.push(e),p.push(n.UTF8ToString(e))}for(let t=0;t<l;t++){const e=n._OrtGetOutputName(r,t);if(0===e)throw new Error(\"Can't get an output name\");h.push(e),d.push(n.UTF8ToString(e))}return s.set(r,[r,f,h]),[r,p,d]},e.createSession=(t,n)=>{const r=(0,e.createSessionAllocate)(t);return(0,e.createSessionFinalize)(r,n)},e.releaseSession=t=>{const e=(0,a.getInstance)(),n=s.get(t);if(!n)throw new Error(\"invalid session id\");const r=n[0],i=n[1],o=n[2];i.forEach(e._OrtFree),o.forEach(e._OrtFree),e._OrtReleaseSession(r),s.delete(t)};const u=t=>{switch(t){case\"int8\":return 3;case\"uint8\":return 2;case\"bool\":return 9;case\"int16\":return 5;case\"uint16\":return 4;case\"int32\":return 6;case\"uint32\":return 12;case\"float32\":return 1;case\"float64\":return 11;case\"string\":return 8;case\"int64\":return 7;case\"uint64\":return 13;default:throw new Error(`unsupported data type: ${t}`)}},c=t=>{switch(t){case 3:return\"int8\";case 2:return\"uint8\";case 9:return\"bool\";case 5:return\"int16\";case 4:return\"uint16\";case 6:return\"int32\";case 12:return\"uint32\";case 1:return\"float32\";case 11:return\"float64\";case 8:return\"string\";case 7:return\"int64\";case 13:return\"uint64\";default:throw new Error(`unsupported data type: ${t}`)}},l=t=>{switch(t){case\"float32\":return Float32Array;case\"uint8\":case\"bool\":return Uint8Array;case\"int8\":return Int8Array;case\"uint16\":return Uint16Array;case\"int16\":return Int16Array;case\"int32\":return Int32Array;case\"float64\":return Float64Array;case\"uint32\":return Uint32Array;case\"int64\":return BigInt64Array;case\"uint64\":return BigUint64Array;default:throw new Error(`unsupported type: ${t}`)}};e.run=(t,e,n,i,p)=>{const f=(0,a.getInstance)(),d=s.get(t);if(!d)throw new Error(\"invalid session id\");const h=d[0],g=d[1],b=d[2],m=e.length,y=i.length;let _=0,v=[];const w=[],x=[];try{[_,v]=(0,r.setRunOptions)(p);for(let t=0;t<m;t++){const e=n[t][0],r=n[t][1],i=n[t][2];let a,s;if(Array.isArray(i)){s=4*i.length,a=f._malloc(s),x.push(a);let t=a/4;for(let e=0;e<i.length;e++){if(\"string\"!=typeof i[e])throw new TypeError(`tensor data at index ${e} is not a string`);f.HEAPU32[t++]=(0,o.allocWasmString)(i[e],x)}}else s=i.byteLength,a=f._malloc(s),x.push(a),f.HEAPU8.set(new Uint8Array(i.buffer,i.byteOffset,s),a);const c=f.stackSave(),l=f.stackAlloc(4*r.length);try{let t=l/4;r.forEach((e=>f.HEAP32[t++]=e));const n=f._OrtCreateTensor(u(e),a,s,l,r.length);if(0===n)throw new Error(\"Can't create a tensor\");w.push(n)}finally{f.stackRestore(c)}}const t=f.stackSave(),a=f.stackAlloc(4*m),s=f.stackAlloc(4*m),d=f.stackAlloc(4*y),T=f.stackAlloc(4*y);try{let n=a/4,r=s/4,o=d/4,u=T/4;for(let t=0;t<m;t++)f.HEAPU32[n++]=w[t],f.HEAPU32[r++]=g[e[t]];for(let t=0;t<y;t++)f.HEAPU32[o++]=0,f.HEAPU32[u++]=b[i[t]];let p=f._OrtRun(h,s,a,m,T,y,d,_);const v=[];if(0===p)for(let t=0;t<y;t++){const e=f.HEAPU32[d/4+t],n=f.stackSave(),r=f.stackAlloc(16);let i,o=0;try{if(p=f._OrtGetTensorData(e,r,r+4,r+8,r+12),0!==p)throw new Error(`Can't access output tensor data. error code = ${p}`);let t=r/4;const a=f.HEAPU32[t++];o=f.HEAPU32[t++];const s=f.HEAPU32[t++],u=f.HEAPU32[t++],d=[];for(let t=0;t<u;t++)d.push(f.HEAPU32[s/4+t]);f._OrtFree(s);const h=0===d.length?1:d.reduce(((t,e)=>t*e));if(i=c(a),\"string\"===i){const t=[];let e=o/4;for(let n=0;n<h;n++){const r=f.HEAPU32[e++],i=n===h-1?void 0:f.HEAPU32[e]-r;t.push(f.UTF8ToString(r,i))}v.push([i,d,t])}else{const t=new(l(i))(h);new Uint8Array(t.buffer,t.byteOffset,t.byteLength).set(f.HEAPU8.subarray(o,o+t.byteLength)),v.push([i,d,t])}}finally{f.stackRestore(n),\"string\"===i&&o&&f._free(o),f._OrtReleaseTensor(e)}}if(0===p)return v;throw new Error(`failed to call OrtRun(). error code = ${p}.`)}finally{f.stackRestore(t)}}finally{w.forEach(f._OrtReleaseTensor),x.forEach(f._free),f._OrtReleaseRunOptions(_),v.forEach(f._free)}},e.endProfiling=t=>{const e=(0,a.getInstance)(),n=s.get(t);if(!n)throw new Error(\"invalid session id\");const r=n[0],i=e._OrtEndProfiling(r);if(0===i)throw new Error(\"Can't get an profile file name\");e._OrtFree(i)},e.extractTransferableBuffers=t=>{const e=[];for(const n of t){const t=n[2];!Array.isArray(t)&&t.buffer&&e.push(t.buffer)}return e}},6361:function(t,e,n){\"use strict\";var r=this&&this.__createBinding||(Object.create?function(t,e,n,r){void 0===r&&(r=n);var i=Object.getOwnPropertyDescriptor(e,n);i&&!(\"get\"in i?!e.__esModule:i.writable||i.configurable)||(i={enumerable:!0,get:function(){return e[n]}}),Object.defineProperty(t,r,i)}:function(t,e,n,r){void 0===r&&(r=n),t[r]=e[n]}),i=this&&this.__setModuleDefault||(Object.create?function(t,e){Object.defineProperty(t,\"default\",{enumerable:!0,value:e})}:function(t,e){t.default=e}),o=this&&this.__importStar||function(t){if(t&&t.__esModule)return t;var e={};if(null!=t)for(var n in t)\"default\"!==n&&Object.prototype.hasOwnProperty.call(t,n)&&r(e,t,n);return i(e,t),e},a=this&&this.__importDefault||function(t){return t&&t.__esModule?t:{default:t}};Object.defineProperty(e,\"__esModule\",{value:!0}),e.dispose=e.getInstance=e.initializeWebAssembly=void 0;const s=o(n(6449)),u=a(n(932)),c=n(3474);let l,p=!1,f=!1,d=!1;const h=(t,e)=>e?t?\"ort-wasm-simd-threaded.wasm\":\"ort-wasm-threaded.wasm\":t?\"ort-wasm-simd.wasm\":\"ort-wasm.wasm\";e.initializeWebAssembly=async t=>{if(p)return Promise.resolve();if(f)throw new Error(\"multiple calls to 'initializeWebAssembly()' detected.\");if(d)throw new Error(\"previous call to 'initializeWebAssembly()' failed.\");f=!0;const e=t.initTimeout,r=t.numThreads,i=t.simd,o=r>1&&(()=>{try{return\"undefined\"!=typeof SharedArrayBuffer&&(\"undefined\"!=typeof MessageChannel&&(new MessageChannel).port1.postMessage(new SharedArrayBuffer(1)),WebAssembly.validate(new Uint8Array([0,97,115,109,1,0,0,0,1,4,1,96,0,0,3,2,1,0,5,4,1,3,1,1,10,11,1,9,0,65,0,254,16,2,0,26,11])))}catch(t){return!1}})(),a=i&&(()=>{try{return WebAssembly.validate(new Uint8Array([0,97,115,109,1,0,0,0,1,4,1,96,0,0,3,2,1,0,10,30,1,28,0,65,0,253,15,253,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,253,186,1,26,11]))}catch(t){return!1}})(),g=\"string\"==typeof t.wasmPaths?t.wasmPaths:void 0,b=h(!1,o),m=h(a,o),y=\"object\"==typeof t.wasmPaths?t.wasmPaths[m]:void 0;let _=!1;const v=[];if(e>0&&v.push(new Promise((t=>{setTimeout((()=>{_=!0,t()}),e)}))),v.push(new Promise(((t,e)=>{const r=o?c:u.default,i={locateFile:(t,e)=>o&&t.endsWith(\".worker.js\")&&\"undefined\"!=typeof Blob?URL.createObjectURL(new Blob([n(4154)],{type:\"text/javascript\"})):t===b?null!=y?y:(null!=g?g:e)+m:e+t};if(o)if(\"undefined\"==typeof Blob)i.mainScriptUrlOrBlob=s.join(\"/\",\"ort-wasm-threaded.js\");else{const t=`var ortWasmThreaded=(function(){var _scriptDir;return ${r.toString()}})();`;i.mainScriptUrlOrBlob=new Blob([t],{type:\"text/javascript\"})}r(i).then((e=>{f=!1,p=!0,l=e,t()}),(t=>{f=!1,d=!0,e(t)}))}))),await Promise.race(v),_)throw new Error(`WebAssembly backend initializing failed due to timeout: ${e}ms`)},e.getInstance=()=>{if(p&&l)return l;throw new Error(\"WebAssembly is not initialized yet.\")},e.dispose=()=>{var t;!p||f||d||(f=!0,null===(t=l.PThread)||void 0===t||t.terminateAllThreads(),l=void 0,f=!1,p=!1,d=!0)}},9710:(t,e,n)=>{\"use strict\";n.d(e,{Z:()=>o});var r=n(477),i=n.n(r);function o(){return i()('/*!\\n* ONNX Runtime Web v1.14.0\\n* Copyright (c) Microsoft Corporation. All rights reserved.\\n* Licensed under the MIT License.\\n*/\\n(()=>{var t={474:(t,e,n)=>{var _scriptDir,r=(_scriptDir=(_scriptDir=\"undefined\"!=typeof document&&document.currentScript?document.currentScript.src:void 0)||\"/index.js\",function(t){function e(){return j.buffer!=D&&N(j.buffer),P}function r(){return j.buffer!=D&&N(j.buffer),U}function a(){return j.buffer!=D&&N(j.buffer),F}function i(){return j.buffer!=D&&N(j.buffer),I}function o(){return j.buffer!=D&&N(j.buffer),W}var u,c,s;t=t||{},u||(u=void 0!==t?t:{}),u.ready=new Promise((function(t,e){c=t,s=e}));var l,f,p,h,d,y,b=Object.assign({},u),m=\"./this.program\",g=(t,e)=>{throw e},v=\"object\"==typeof window,w=\"function\"==typeof importScripts,_=\"object\"==typeof process&&\"object\"==typeof process.versions&&\"string\"==typeof process.versions.node,O=u.ENVIRONMENT_IS_PTHREAD||!1,A=\"\";function S(t){return u.locateFile?u.locateFile(t,A):A+t}if(_){let e;A=w?n(908).dirname(A)+\"/\":\"//\",y=()=>{d||(h=n(384),d=n(908))},l=function(t,e){return y(),t=d.normalize(t),h.readFileSync(t,e?void 0:\"utf8\")},p=t=>((t=l(t,!0)).buffer||(t=new Uint8Array(t)),t),f=(t,e,n)=>{y(),t=d.normalize(t),h.readFile(t,(function(t,r){t?n(t):e(r.buffer)}))},1<process.argv.length&&(m=process.argv[1].replace(/\\\\\\\\/g,\"/\")),process.argv.slice(2),process.on(\"uncaughtException\",(function(t){if(!(t instanceof ct))throw t})),process.on(\"unhandledRejection\",(function(t){throw t})),g=(t,e)=>{if(Q())throw process.exitCode=t,e;e instanceof ct||x(\"exiting due to exception: \"+e),process.exit(t)},u.inspect=function(){return\"[Emscripten Module object]\"};try{e=n(925)}catch(t){throw console.error(\\'The \"worker_threads\" module is not supported in this node.js build - perhaps a newer version is needed?\\'),t}n.g.Worker=e.Worker}else(v||w)&&(w?A=self.location.href:\"undefined\"!=typeof document&&document.currentScript&&(A=document.currentScript.src),_scriptDir&&(A=_scriptDir),A=0!==A.indexOf(\"blob:\")?A.substr(0,A.replace(/[?#].*/,\"\").lastIndexOf(\"/\")+1):\"\",_||(l=t=>{var e=new XMLHttpRequest;return e.open(\"GET\",t,!1),e.send(null),e.responseText},w&&(p=t=>{var e=new XMLHttpRequest;return e.open(\"GET\",t,!1),e.responseType=\"arraybuffer\",e.send(null),new Uint8Array(e.response)}),f=(t,e,n)=>{var r=new XMLHttpRequest;r.open(\"GET\",t,!0),r.responseType=\"arraybuffer\",r.onload=()=>{200==r.status||0==r.status&&r.response?e(r.response):n()},r.onerror=n,r.send(null)}));_&&\"undefined\"==typeof performance&&(n.g.performance=n(953).performance);var T=console.log.bind(console),E=console.warn.bind(console);_&&(y(),T=t=>h.writeSync(1,t+\"\\\\n\"),E=t=>h.writeSync(2,t+\"\\\\n\"));var M,C=u.print||T,x=u.printErr||E;Object.assign(u,b),b=null,u.thisProgram&&(m=u.thisProgram),u.quit&&(g=u.quit),u.wasmBinary&&(M=u.wasmBinary);var R=u.noExitRuntime||!1;\"object\"!=typeof WebAssembly&&at(\"no native wasm support detected\");var j,k,D,P,U,F,I,W,H=!1,L=\"undefined\"!=typeof TextDecoder?new TextDecoder(\"utf8\"):void 0;function z(t,e,n){var r=(e>>>=0)+n;for(n=e;t[n]&&!(n>=r);)++n;if(16<n-e&&t.buffer&&L)return L.decode(t.buffer instanceof SharedArrayBuffer?t.slice(e,n):t.subarray(e,n));for(r=\"\";e<n;){var a=t[e++];if(128&a){var i=63&t[e++];if(192==(224&a))r+=String.fromCharCode((31&a)<<6|i);else{var o=63&t[e++];65536>(a=224==(240&a)?(15&a)<<12|i<<6|o:(7&a)<<18|i<<12|o<<6|63&t[e++])?r+=String.fromCharCode(a):(a-=65536,r+=String.fromCharCode(55296|a>>10,56320|1023&a))}}else r+=String.fromCharCode(a)}return r}function Y(t,e){return(t>>>=0)?z(r(),t,e):\"\"}function B(t,e,n,r){if(!(0<r))return 0;var a=n>>>=0;r=n+r-1;for(var i=0;i<t.length;++i){var o=t.charCodeAt(i);if(55296<=o&&57343>=o&&(o=65536+((1023&o)<<10)|1023&t.charCodeAt(++i)),127>=o){if(n>=r)break;e[n++>>>0]=o}else{if(2047>=o){if(n+1>=r)break;e[n++>>>0]=192|o>>6}else{if(65535>=o){if(n+2>=r)break;e[n++>>>0]=224|o>>12}else{if(n+3>=r)break;e[n++>>>0]=240|o>>18,e[n++>>>0]=128|o>>12&63}e[n++>>>0]=128|o>>6&63}e[n++>>>0]=128|63&o}}return e[n>>>0]=0,n-a}function G(t){for(var e=0,n=0;n<t.length;++n){var r=t.charCodeAt(n);127>=r?e++:2047>=r?e+=2:55296<=r&&57343>=r?(e+=4,++n):e+=3}return e}function N(t){D=t,u.HEAP8=P=new Int8Array(t),u.HEAP16=new Int16Array(t),u.HEAP32=F=new Int32Array(t),u.HEAPU8=U=new Uint8Array(t),u.HEAPU16=new Uint16Array(t),u.HEAPU32=I=new Uint32Array(t),u.HEAPF32=new Float32Array(t),u.HEAPF64=W=new Float64Array(t)}O&&(D=u.buffer);var V=u.INITIAL_MEMORY||16777216;if(O)j=u.wasmMemory,D=u.buffer;else if(u.wasmMemory)j=u.wasmMemory;else if(!((j=new WebAssembly.Memory({initial:V/65536,maximum:65536,shared:!0})).buffer instanceof SharedArrayBuffer))throw x(\"requested a shared WebAssembly.Memory but the returned buffer is not a SharedArrayBuffer, indicating that while the browser has SharedArrayBuffer it does not have WebAssembly threads support - you may need to set a flag\"),_&&console.log(\"(on node you may need: --experimental-wasm-threads --experimental-wasm-bulk-memory and also use a recent version)\"),Error(\"bad memory\");j&&(D=j.buffer),V=D.byteLength,N(D);var $,q=[],X=[],J=[],Z=[];function Q(){return R||!1}function K(){var t=u.preRun.shift();q.unshift(t)}var tt,et=0,nt=null,rt=null;function at(t){throw O?postMessage({cmd:\"onAbort\",arg:t}):u.onAbort&&u.onAbort(t),x(t=\"Aborted(\"+t+\")\"),H=!0,t=new WebAssembly.RuntimeError(t+\". Build with -sASSERTIONS for more info.\"),s(t),t}function it(){return tt.startsWith(\"data:application/octet-stream;base64,\")}function ot(){var t=tt;try{if(t==tt&&M)return new Uint8Array(M);if(p)return p(t);throw\"both async and sync fetching of the wasm failed\"}catch(t){at(t)}}tt=\"ort-wasm-threaded.wasm\",it()||(tt=S(tt));var ut={};function ct(t){this.name=\"ExitStatus\",this.message=\"Program terminated with exit(\"+t+\")\",this.status=t}function st(t){(t=ht.Vb[t])||at(),ht.mc(t)}function lt(t){var e=ht.Cc();if(!e)return 6;ht.ac.push(e),ht.Vb[t.Ub]=e,e.Ub=t.Ub;var n={cmd:\"run\",start_routine:t.Ic,arg:t.zc,pthread_ptr:t.Ub};return e.$b=()=>{n.time=performance.now(),e.postMessage(n,t.Nc)},e.loaded&&(e.$b(),delete e.$b),0}function ft(t){if(O)return $t(1,1,t);Q()||(ht.oc(),u.onExit&&u.onExit(t),H=!0),g(t,new ct(t))}function pt(t,e){if(!e&&O)throw bt(t),\"unwind\";Q()||O||(me(),dt(J),be(0),re[1].length&&ae(1,10),re[2].length&&ae(2,10),ht.oc()),ft(t)}var ht={Yb:[],ac:[],qc:[],Vb:{},fc:function(){O&&ht.Ec()},Pc:function(){},Ec:function(){ht.receiveObjectTransfer=ht.Gc,ht.threadInitTLS=ht.pc,ht.setExitStatus=ht.nc,R=!1},nc:function(){},oc:function(){for(var t of Object.values(ht.Vb))ht.mc(t);for(t of ht.Yb)t.terminate();ht.Yb=[]},mc:function(t){var e=t.Ub;delete ht.Vb[e],ht.Yb.push(t),ht.ac.splice(ht.ac.indexOf(t),1),t.Ub=0,Oe(e)},Gc:function(){},pc:function(){ht.qc.forEach((t=>t()))},Fc:function(t,e){t.onmessage=n=>{var r=(n=n.data).cmd;if(t.Ub&&(ht.Bc=t.Ub),n.targetThread&&n.targetThread!=he()){var a=ht.Vb[n.Qc];a?a.postMessage(n,n.transferList):x(\\'Internal error! Worker sent a message \"\\'+r+\\'\" to target pthread \\'+n.targetThread+\", but that thread no longer exists!\")}else\"processProxyingQueue\"===r?zt(n.queue):\"spawnThread\"===r?lt(n):\"cleanupThread\"===r?st(n.thread):\"killThread\"===r?(n=n.thread,r=ht.Vb[n],delete ht.Vb[n],r.terminate(),Oe(n),ht.ac.splice(ht.ac.indexOf(r),1),r.Ub=0):\"cancelThread\"===r?ht.Vb[n.thread].postMessage({cmd:\"cancel\"}):\"loaded\"===r?(t.loaded=!0,e&&e(t),t.$b&&(t.$b(),delete t.$b)):\"print\"===r?C(\"Thread \"+n.threadId+\": \"+n.text):\"printErr\"===r?x(\"Thread \"+n.threadId+\": \"+n.text):\"alert\"===r?alert(\"Thread \"+n.threadId+\": \"+n.text):\"setimmediate\"===n.target?t.postMessage(n):\"onAbort\"===r?u.onAbort&&u.onAbort(n.arg):r&&x(\"worker sent an unknown command \"+r);ht.Bc=void 0},t.onerror=t=>{throw x(\"worker sent an error! \"+t.filename+\":\"+t.lineno+\": \"+t.message),t},_&&(t.on(\"message\",(function(e){t.onmessage({data:e})})),t.on(\"error\",(function(e){t.onerror(e)})),t.on(\"detachedExit\",(function(){}))),t.postMessage({cmd:\"load\",urlOrBlob:u.mainScriptUrlOrBlob||_scriptDir,wasmMemory:j,wasmModule:k})},yc:function(){var t=S(\"ort-wasm-threaded.worker.js\");ht.Yb.push(new Worker(t))},Cc:function(){return 0==ht.Yb.length&&(ht.yc(),ht.Fc(ht.Yb[0])),ht.Yb.pop()}};function dt(t){for(;0<t.length;)t.shift()(u)}function yt(t){var e=Ee();return t=t(),Me(e),t}function bt(t){if(O)return $t(2,0,t);try{pt(t)}catch(t){t instanceof ct||\"unwind\"==t||g(1,t)}}u.PThread=ht,u.establishStackSpace=function(){var t=he(),e=a()[t+44>>2>>>0];t=a()[t+48>>2>>>0],Te(e,e-t),Me(e)};var mt=[];function gt(t){var e=mt[t];return e||(t>=mt.length&&(mt.length=t+1),mt[t]=e=$.get(t)),e}u.invokeEntryPoint=function(t,e){t=gt(t)(e),Q()?ht.nc(t):Ae(t)};var vt,wt,_t=[],Ot=0,At=0;function St(t){this.Zb=t,this.Sb=t-24,this.xc=function(t){i()[this.Sb+4>>2>>>0]=t},this.bc=function(){return i()[this.Sb+4>>2>>>0]},this.wc=function(t){i()[this.Sb+8>>2>>>0]=t},this.Dc=function(){return i()[this.Sb+8>>2>>>0]},this.rc=function(){a()[this.Sb>>2>>>0]=0},this.hc=function(t){t=t?1:0,e()[this.Sb+12>>0>>>0]=t},this.uc=function(){return 0!=e()[this.Sb+12>>0>>>0]},this.ic=function(t){t=t?1:0,e()[this.Sb+13>>0>>>0]=t},this.kc=function(){return 0!=e()[this.Sb+13>>0>>>0]},this.fc=function(t,e){this.cc(0),this.xc(t),this.wc(e),this.rc(),this.hc(!1),this.ic(!1)},this.sc=function(){Atomics.add(a(),this.Sb>>2,1)},this.Hc=function(){return 1===Atomics.sub(a(),this.Sb>>2,1)},this.cc=function(t){i()[this.Sb+16>>2>>>0]=t},this.tc=function(){return i()[this.Sb+16>>2>>>0]},this.vc=function(){if(Re(this.bc()))return i()[this.Zb>>2>>>0];var t=this.tc();return 0!==t?t:this.Zb}}function Tt(t){return ye(new St(t).Sb)}function Et(t,e,n,r){return O?$t(3,1,t,e,n,r):Mt(t,e,n,r)}function Mt(t,e,n,r){if(\"undefined\"==typeof SharedArrayBuffer)return x(\"Current environment does not support SharedArrayBuffer, pthreads are not available!\"),6;var a=[];return O&&0===a.length?Et(t,e,n,r):(t={Ic:n,Ub:t,zc:r,Nc:a},O?(t.Oc=\"spawnThread\",postMessage(t,a),0):lt(t))}function Ct(t,e,n){return O?$t(4,1,t,e,n):0}function xt(t,e){if(O)return $t(5,1,t,e)}function Rt(t,e){if(O)return $t(6,1,t,e)}function jt(t,e,n){if(O)return $t(7,1,t,e,n)}function kt(t,e,n){return O?$t(8,1,t,e,n):0}function Dt(t,e){if(O)return $t(9,1,t,e)}function Pt(t,e,n){if(O)return $t(10,1,t,e,n)}function Ut(t,e,n,r){if(O)return $t(11,1,t,e,n,r)}function Ft(t,e,n,r){if(O)return $t(12,1,t,e,n,r)}function It(t,e,n,r){if(O)return $t(13,1,t,e,n,r)}function Wt(t){if(O)return $t(14,1,t)}function Ht(t,e){if(O)return $t(15,1,t,e)}function Lt(t,e,n){if(O)return $t(16,1,t,e,n)}function zt(t){Atomics.store(a(),t>>2,1),he()&&_e(t),Atomics.compareExchange(a(),t>>2,1,0)}function Yt(t){return i()[t>>>2]+4294967296*a()[t+4>>>2]}function Bt(t,e,n,r,a,i){return O?$t(17,1,t,e,n,r,a,i):-52}function Gt(t,e,n,r,a,i){if(O)return $t(18,1,t,e,n,r,a,i)}function Nt(t){var n=G(t)+1,r=de(n);return r&&B(t,e(),r,n),r}function Vt(t,e,n){function r(t){return(t=t.toTimeString().match(/\\\\(([A-Za-z ]+)\\\\)$/))?t[1]:\"GMT\"}if(O)return $t(19,1,t,e,n);var o=(new Date).getFullYear(),u=new Date(o,0,1),c=new Date(o,6,1);o=u.getTimezoneOffset();var s=c.getTimezoneOffset(),l=Math.max(o,s);a()[t>>2>>>0]=60*l,a()[e>>2>>>0]=Number(o!=s),t=r(u),e=r(c),t=Nt(t),e=Nt(e),s<o?(i()[n>>2>>>0]=t,i()[n+4>>2>>>0]=e):(i()[n>>2>>>0]=e,i()[n+4>>2>>>0]=t)}function $t(t,e){var n=arguments.length-2,r=arguments;return yt((()=>{for(var a=Ce(8*n),i=a>>3,u=0;u<n;u++){var c=r[2+u];o()[i+u>>>0]=c}return we(t,n,a,e)}))}u.executeNotifiedProxyingQueue=zt,wt=_?()=>{var t=process.hrtime();return 1e3*t[0]+t[1]/1e6}:O?()=>performance.now()-u.__performance_now_clock_drift:()=>performance.now();var qt,Xt=[],Jt={};function Zt(){if(!qt){var t,e={USER:\"web_user\",LOGNAME:\"web_user\",PATH:\"/\",PWD:\"/\",HOME:\"/home/web_user\",LANG:(\"object\"==typeof navigator&&navigator.languages&&navigator.languages[0]||\"C\").replace(\"-\",\"_\")+\".UTF-8\",_:m||\"./this.program\"};for(t in Jt)void 0===Jt[t]?delete e[t]:e[t]=Jt[t];var n=[];for(t in e)n.push(t+\"=\"+e[t]);qt=n}return qt}function Qt(t,n){if(O)return $t(20,1,t,n);var r=0;return Zt().forEach((function(a,o){var u=n+r;for(o=i()[t+4*o>>2>>>0]=u,u=0;u<a.length;++u)e()[o++>>0>>>0]=a.charCodeAt(u);e()[o>>0>>>0]=0,r+=a.length+1})),0}function Kt(t,e){if(O)return $t(21,1,t,e);var n=Zt();i()[t>>2>>>0]=n.length;var r=0;return n.forEach((function(t){r+=t.length+1})),i()[e>>2>>>0]=r,0}function te(t){return O?$t(22,1,t):52}function ee(t,e,n,r){return O?$t(23,1,t,e,n,r):52}function ne(t,e,n,r,a){return O?$t(24,1,t,e,n,r,a):70}var re=[null,[],[]];function ae(t,e){var n=re[t];0===e||10===e?((1===t?C:x)(z(n,0)),n.length=0):n.push(e)}function ie(t,e,n,a){if(O)return $t(25,1,t,e,n,a);for(var o=0,u=0;u<n;u++){var c=i()[e>>2>>>0],s=i()[e+4>>2>>>0];e+=8;for(var l=0;l<s;l++)ae(t,r()[c+l>>>0]);o+=s}return i()[a>>2>>>0]=o,0}var oe=0;function ue(t){return 0==t%4&&(0!=t%100||0==t%400)}var ce=[31,29,31,30,31,30,31,31,30,31,30,31],se=[31,28,31,30,31,30,31,31,30,31,30,31];function le(t,n,r,i){function o(t,e,n){for(t=\"number\"==typeof t?t.toString():t||\"\";t.length<e;)t=n[0]+t;return t}function u(t,e){return o(t,e,\"0\")}function c(t,e){function n(t){return 0>t?-1:0<t?1:0}var r;return 0===(r=n(t.getFullYear()-e.getFullYear()))&&0===(r=n(t.getMonth()-e.getMonth()))&&(r=n(t.getDate()-e.getDate())),r}function s(t){switch(t.getDay()){case 0:return new Date(t.getFullYear()-1,11,29);case 1:return t;case 2:return new Date(t.getFullYear(),0,3);case 3:return new Date(t.getFullYear(),0,2);case 4:return new Date(t.getFullYear(),0,1);case 5:return new Date(t.getFullYear()-1,11,31);case 6:return new Date(t.getFullYear()-1,11,30)}}function l(t){var e=t.Wb;for(t=new Date(new Date(t.Xb+1900,0,1).getTime());0<e;){var n=t.getMonth(),r=(ue(t.getFullYear())?ce:se)[n];if(!(e>r-t.getDate())){t.setDate(t.getDate()+e);break}e-=r-t.getDate()+1,t.setDate(1),11>n?t.setMonth(n+1):(t.setMonth(0),t.setFullYear(t.getFullYear()+1))}return n=new Date(t.getFullYear()+1,0,4),e=s(new Date(t.getFullYear(),0,4)),n=s(n),0>=c(e,t)?0>=c(n,t)?t.getFullYear()+1:t.getFullYear():t.getFullYear()-1}var f=a()[i+40>>2>>>0];for(var p in i={Lc:a()[i>>2>>>0],Kc:a()[i+4>>2>>>0],dc:a()[i+8>>2>>>0],jc:a()[i+12>>2>>>0],ec:a()[i+16>>2>>>0],Xb:a()[i+20>>2>>>0],Tb:a()[i+24>>2>>>0],Wb:a()[i+28>>2>>>0],Rc:a()[i+32>>2>>>0],Jc:a()[i+36>>2>>>0],Mc:f?Y(f):\"\"},r=Y(r),f={\"%c\":\"%a %b %d %H:%M:%S %Y\",\"%D\":\"%m/%d/%y\",\"%F\":\"%Y-%m-%d\",\"%h\":\"%b\",\"%r\":\"%I:%M:%S %p\",\"%R\":\"%H:%M\",\"%T\":\"%H:%M:%S\",\"%x\":\"%m/%d/%y\",\"%X\":\"%H:%M:%S\",\"%Ec\":\"%c\",\"%EC\":\"%C\",\"%Ex\":\"%m/%d/%y\",\"%EX\":\"%H:%M:%S\",\"%Ey\":\"%y\",\"%EY\":\"%Y\",\"%Od\":\"%d\",\"%Oe\":\"%e\",\"%OH\":\"%H\",\"%OI\":\"%I\",\"%Om\":\"%m\",\"%OM\":\"%M\",\"%OS\":\"%S\",\"%Ou\":\"%u\",\"%OU\":\"%U\",\"%OV\":\"%V\",\"%Ow\":\"%w\",\"%OW\":\"%W\",\"%Oy\":\"%y\"})r=r.replace(new RegExp(p,\"g\"),f[p]);var h=\"Sunday Monday Tuesday Wednesday Thursday Friday Saturday\".split(\" \"),d=\"January February March April May June July August September October November December\".split(\" \");for(p in f={\"%a\":function(t){return h[t.Tb].substring(0,3)},\"%A\":function(t){return h[t.Tb]},\"%b\":function(t){return d[t.ec].substring(0,3)},\"%B\":function(t){return d[t.ec]},\"%C\":function(t){return u((t.Xb+1900)/100|0,2)},\"%d\":function(t){return u(t.jc,2)},\"%e\":function(t){return o(t.jc,2,\" \")},\"%g\":function(t){return l(t).toString().substring(2)},\"%G\":function(t){return l(t)},\"%H\":function(t){return u(t.dc,2)},\"%I\":function(t){return 0==(t=t.dc)?t=12:12<t&&(t-=12),u(t,2)},\"%j\":function(t){for(var e=0,n=0;n<=t.ec-1;e+=(ue(t.Xb+1900)?ce:se)[n++]);return u(t.jc+e,3)},\"%m\":function(t){return u(t.ec+1,2)},\"%M\":function(t){return u(t.Kc,2)},\"%n\":function(){return\"\\\\n\"},\"%p\":function(t){return 0<=t.dc&&12>t.dc?\"AM\":\"PM\"},\"%S\":function(t){return u(t.Lc,2)},\"%t\":function(){return\"\\\\t\"},\"%u\":function(t){return t.Tb||7},\"%U\":function(t){return u(Math.floor((t.Wb+7-t.Tb)/7),2)},\"%V\":function(t){var e=Math.floor((t.Wb+7-(t.Tb+6)%7)/7);if(2>=(t.Tb+371-t.Wb-2)%7&&e++,e)53==e&&(4==(n=(t.Tb+371-t.Wb)%7)||3==n&&ue(t.Xb)||(e=1));else{e=52;var n=(t.Tb+7-t.Wb-1)%7;(4==n||5==n&&ue(t.Xb%400-1))&&e++}return u(e,2)},\"%w\":function(t){return t.Tb},\"%W\":function(t){return u(Math.floor((t.Wb+7-(t.Tb+6)%7)/7),2)},\"%y\":function(t){return(t.Xb+1900).toString().substring(2)},\"%Y\":function(t){return t.Xb+1900},\"%z\":function(t){var e=0<=(t=t.Jc);return t=Math.abs(t)/60,(e?\"+\":\"-\")+String(\"0000\"+(t/60*100+t%60)).slice(-4)},\"%Z\":function(t){return t.Mc},\"%%\":function(){return\"%\"}},r=r.replace(/%%/g,\"\\\\0\\\\0\"),f)r.includes(p)&&(r=r.replace(new RegExp(p,\"g\"),f[p](i)));return p=function(t){var e=Array(G(t)+1);return B(t,e,0,e.length),e}(r=r.replace(/\\\\0\\\\0/g,\"%\")),p.length>n?0:(function(t,n){e().set(t,n>>>0)}(p,t),p.length-1)}ht.fc();var fe=[null,ft,bt,Et,Ct,xt,Rt,jt,kt,Dt,Pt,Ut,Ft,It,Wt,Ht,Lt,Bt,Gt,Vt,Qt,Kt,te,ee,ne,ie],pe={b:function(t){return de(t+24)+24},n:function(t){return(t=new St(t)).uc()||(t.hc(!0),Ot--),t.ic(!1),_t.push(t),t.sc(),t.vc()},ma:function(t){throw x(\"Unexpected exception thrown, this is not properly supported - aborting\"),H=!0,t},x:function(){Se(0);var t=_t.pop();if(t.Hc()&&!t.kc()){var e=t.Dc();e&&gt(e)(t.Zb),Tt(t.Zb)}At=0},e:function(){var t=At;if(!t)return oe=0;var e=new St(t);e.cc(t);var n=e.bc();if(!n)return oe=0,t;for(var r=Array.prototype.slice.call(arguments),a=0;a<r.length;a++){var i=r[a];if(0===i||i===n)break;if(xe(i,n,e.Sb+16))return oe=i,t}return oe=n,t},l:function(){var t=At;if(!t)return oe=0;var e=new St(t);e.cc(t);var n=e.bc();if(!n)return oe=0,t;for(var r=Array.prototype.slice.call(arguments),a=0;a<r.length;a++){var i=r[a];if(0===i||i===n)break;if(xe(i,n,e.Sb+16))return oe=i,t}return oe=n,t},h:function(){var t=At;if(!t)return oe=0;var e=new St(t);e.cc(t);var n=e.bc();if(!n)return oe=0,t;for(var r=Array.prototype.slice.call(arguments),a=0;a<r.length;a++){var i=r[a];if(0===i||i===n)break;if(xe(i,n,e.Sb+16))return oe=i,t}return oe=n,t},t:Tt,M:function(){var t=_t.pop();t||at(\"no exception to throw\");var e=t.Zb;throw t.kc()||(_t.push(t),t.ic(!0),t.hc(!1),Ot++),At=e,e},c:function(t,e,n){throw new St(t).fc(e,n),At=t,Ot++,t},pa:function(){return Ot},Fa:function(t){ge(t,!w,1,!v),ht.pc()},T:function(t){O?postMessage({cmd:\"cleanupThread\",thread:t}):st(t)},xa:Mt,j:function(t){throw At||(At=t),t},H:Ct,Ma:xt,ua:Rt,wa:jt,oa:kt,Ka:Dt,Ca:Pt,Ja:Ut,V:Ft,va:It,sa:Wt,La:Ht,ta:Lt,Ta:function(){},X:function(){at(\"To use dlopen, you need enable dynamic linking, see https://github.com/emscripten-core/emscripten/wiki/Linking\")},Ua:function(){at(\"To use dlopen, you need enable dynamic linking, see https://github.com/emscripten-core/emscripten/wiki/Linking\")},W:function(){return Date.now()},ya:function(){return 2097152},Oa:function(){return!0},za:function(t,e,n,r){if(t==e)setTimeout((()=>zt(r)));else if(O)postMessage({targetThread:t,cmd:\"processProxyingQueue\",queue:r});else{if(!(t=ht.Vb[t]))return;t.postMessage({cmd:\"processProxyingQueue\",queue:r})}return 1},Ea:function(){return-1},Pa:function(t,e){t=new Date(1e3*Yt(t)),a()[e>>2>>>0]=t.getUTCSeconds(),a()[e+4>>2>>>0]=t.getUTCMinutes(),a()[e+8>>2>>>0]=t.getUTCHours(),a()[e+12>>2>>>0]=t.getUTCDate(),a()[e+16>>2>>>0]=t.getUTCMonth(),a()[e+20>>2>>>0]=t.getUTCFullYear()-1900,a()[e+24>>2>>>0]=t.getUTCDay(),t=(t.getTime()-Date.UTC(t.getUTCFullYear(),0,1,0,0,0,0))/864e5|0,a()[e+28>>2>>>0]=t},Qa:function(t,e){t=new Date(1e3*Yt(t)),a()[e>>2>>>0]=t.getSeconds(),a()[e+4>>2>>>0]=t.getMinutes(),a()[e+8>>2>>>0]=t.getHours(),a()[e+12>>2>>>0]=t.getDate(),a()[e+16>>2>>>0]=t.getMonth(),a()[e+20>>2>>>0]=t.getFullYear()-1900,a()[e+24>>2>>>0]=t.getDay();var n=new Date(t.getFullYear(),0,1),r=(t.getTime()-n.getTime())/864e5|0;a()[e+28>>2>>>0]=r,a()[e+36>>2>>>0]=-60*t.getTimezoneOffset(),r=new Date(t.getFullYear(),6,1).getTimezoneOffset(),t=0|(r!=(n=n.getTimezoneOffset())&&t.getTimezoneOffset()==Math.min(n,r)),a()[e+32>>2>>>0]=t},Ra:function(t){var e=new Date(a()[t+20>>2>>>0]+1900,a()[t+16>>2>>>0],a()[t+12>>2>>>0],a()[t+8>>2>>>0],a()[t+4>>2>>>0],a()[t>>2>>>0],0),n=a()[t+32>>2>>>0],r=e.getTimezoneOffset(),i=new Date(e.getFullYear(),0,1),o=new Date(e.getFullYear(),6,1).getTimezoneOffset(),u=i.getTimezoneOffset(),c=Math.min(u,o);return 0>n?a()[t+32>>2>>>0]=Number(o!=u&&c==r):0<n!=(c==r)&&(o=Math.max(u,o),e.setTime(e.getTime()+6e4*((0<n?c:o)-r))),a()[t+24>>2>>>0]=e.getDay(),n=(e.getTime()-i.getTime())/864e5|0,a()[t+28>>2>>>0]=n,a()[t>>2>>>0]=e.getSeconds(),a()[t+4>>2>>>0]=e.getMinutes(),a()[t+8>>2>>>0]=e.getHours(),a()[t+12>>2>>>0]=e.getDate(),a()[t+16>>2>>>0]=e.getMonth(),e.getTime()/1e3|0},Aa:Bt,Ba:Gt,Sa:function t(e,n,r){t.Ac||(t.Ac=!0,Vt(e,n,r))},y:function(){at(\"\")},U:function(){if(!_&&!w){var t=\"Blocking on the main thread is very dangerous, see https://emscripten.org/docs/porting/pthreads.html#blocking-on-the-main-browser-thread\";vt||(vt={}),vt[t]||(vt[t]=1,_&&(t=\"warning: \"+t),x(t))}},ra:function(){return 4294901760},B:wt,Ia:function(t,e,n){r().copyWithin(t>>>0,e>>>0,e+n>>>0)},F:function(){return _?n(993).cpus().length:navigator.hardwareConcurrency},Da:function(t,e,n){Xt.length=e,n>>=3;for(var r=0;r<e;r++)Xt[r]=o()[n+r>>>0];return(0>t?ut[-t-1]:fe[t]).apply(null,Xt)},qa:function(t){var e=r().length;if((t>>>=0)<=e||4294901760<t)return!1;for(var n=1;4>=n;n*=2){var a=e*(1+.2/n);a=Math.min(a,t+100663296);var i=Math;a=Math.max(t,a),i=i.min.call(i,4294901760,a+(65536-a%65536)%65536);t:{try{j.grow(i-D.byteLength+65535>>>16),N(j.buffer);var o=1;break t}catch(t){}o=void 0}if(o)return!0}return!1},Na:function(){throw\"unwind\"},Ga:Qt,Ha:Kt,J:pt,I:te,S:ee,ga:ne,R:ie,d:function(){return oe},na:function t(r,a){t.lc||(t.lc=function(){if(\"object\"==typeof crypto&&\"function\"==typeof crypto.getRandomValues){var t=new Uint8Array(1);return()=>(crypto.getRandomValues(t),t[0])}if(_)try{var e=n(Object(function(){var t=new Error(\"Cannot find module \\'crypto\\'\");throw t.code=\"MODULE_NOT_FOUND\",t}()));return()=>e.randomBytes(1)[0]}catch(t){}return()=>at(\"randomDevice\")}());for(var i=0;i<a;i++)e()[r+i>>0>>>0]=t.lc();return 0},ia:function(t,e,n){var r=Ee();try{return gt(t)(e,n)}catch(t){if(Me(r),t!==t+0)throw t;Se(1,0)}},ja:function(t,e,n){var r=Ee();try{return gt(t)(e,n)}catch(t){if(Me(r),t!==t+0)throw t;Se(1,0)}},K:function(t){var e=Ee();try{return gt(t)()}catch(t){if(Me(e),t!==t+0)throw t;Se(1,0)}},f:function(t,e){var n=Ee();try{return gt(t)(e)}catch(t){if(Me(n),t!==t+0)throw t;Se(1,0)}},P:function(t,e,n){var r=Ee();try{return gt(t)(e,n)}catch(t){if(Me(r),t!==t+0)throw t;Se(1,0)}},Q:function(t,e,n){var r=Ee();try{return gt(t)(e,n)}catch(t){if(Me(r),t!==t+0)throw t;Se(1,0)}},k:function(t,e,n){var r=Ee();try{return gt(t)(e,n)}catch(t){if(Me(r),t!==t+0)throw t;Se(1,0)}},p:function(t,e,n,r){var a=Ee();try{return gt(t)(e,n,r)}catch(t){if(Me(a),t!==t+0)throw t;Se(1,0)}},q:function(t,e,n,r,a){var i=Ee();try{return gt(t)(e,n,r,a)}catch(t){if(Me(i),t!==t+0)throw t;Se(1,0)}},N:function(t,e,n,r,a,i){var o=Ee();try{return gt(t)(e,n,r,a,i)}catch(t){if(Me(o),t!==t+0)throw t;Se(1,0)}},s:function(t,e,n,r,a,i){var o=Ee();try{return gt(t)(e,n,r,a,i)}catch(t){if(Me(o),t!==t+0)throw t;Se(1,0)}},w:function(t,e,n,r,a,i,o){var u=Ee();try{return gt(t)(e,n,r,a,i,o)}catch(t){if(Me(u),t!==t+0)throw t;Se(1,0)}},L:function(t,e,n,r,a,i,o,u){var c=Ee();try{return gt(t)(e,n,r,a,i,o,u)}catch(t){if(Me(c),t!==t+0)throw t;Se(1,0)}},E:function(t,e,n,r,a,i,o,u,c,s,l,f){var p=Ee();try{return gt(t)(e,n,r,a,i,o,u,c,s,l,f)}catch(t){if(Me(p),t!==t+0)throw t;Se(1,0)}},aa:function(t,e,n,r,a,i,o,u){var c=Ee();try{return He(t,e,n,r,a,i,o,u)}catch(t){if(Me(c),t!==t+0)throw t;Se(1,0)}},_:function(t,e,n,r,a,i,o){var u=Ee();try{return ke(t,e,n,r,a,i,o)}catch(t){if(Me(u),t!==t+0)throw t;Se(1,0)}},Z:function(t,e,n,r,a){var i=Ee();try{return Le(t,e,n,r,a)}catch(t){if(Me(i),t!==t+0)throw t;Se(1,0)}},ca:function(t,e,n,r){var a=Ee();try{return Ie(t,e,n,r)}catch(t){if(Me(a),t!==t+0)throw t;Se(1,0)}},$:function(t){var e=Ee();try{return je(t)}catch(t){if(Me(e),t!==t+0)throw t;Se(1,0)}},ba:function(t,e){var n=Ee();try{return We(t,e)}catch(t){if(Me(n),t!==t+0)throw t;Se(1,0)}},Y:function(t,e,n){var r=Ee();try{return De(t,e,n)}catch(t){if(Me(r),t!==t+0)throw t;Se(1,0)}},g:function(t){var e=Ee();try{gt(t)()}catch(t){if(Me(e),t!==t+0)throw t;Se(1,0)}},r:function(t,e){var n=Ee();try{gt(t)(e)}catch(t){if(Me(n),t!==t+0)throw t;Se(1,0)}},i:function(t,e,n){var r=Ee();try{gt(t)(e,n)}catch(t){if(Me(r),t!==t+0)throw t;Se(1,0)}},ha:function(t,e,n,r){var a=Ee();try{gt(t)(e,n,r)}catch(t){if(Me(a),t!==t+0)throw t;Se(1,0)}},m:function(t,e,n,r){var a=Ee();try{gt(t)(e,n,r)}catch(t){if(Me(a),t!==t+0)throw t;Se(1,0)}},v:function(t,e,n,r,a){var i=Ee();try{gt(t)(e,n,r,a)}catch(t){if(Me(i),t!==t+0)throw t;Se(1,0)}},u:function(t,e,n,r,a,i){var o=Ee();try{gt(t)(e,n,r,a,i)}catch(t){if(Me(o),t!==t+0)throw t;Se(1,0)}},O:function(t,e,n,r,a,i,o){var u=Ee();try{gt(t)(e,n,r,a,i,o)}catch(t){if(Me(u),t!==t+0)throw t;Se(1,0)}},A:function(t,e,n,r,a,i,o,u){var c=Ee();try{gt(t)(e,n,r,a,i,o,u)}catch(t){if(Me(c),t!==t+0)throw t;Se(1,0)}},ka:function(t,e,n,r,a,i,o,u,c){var s=Ee();try{gt(t)(e,n,r,a,i,o,u,c)}catch(t){if(Me(s),t!==t+0)throw t;Se(1,0)}},C:function(t,e,n,r,a,i,o,u,c,s,l){var f=Ee();try{gt(t)(e,n,r,a,i,o,u,c,s,l)}catch(t){if(Me(f),t!==t+0)throw t;Se(1,0)}},D:function(t,e,n,r,a,i,o,u,c,s,l,f,p,h,d,y){var b=Ee();try{gt(t)(e,n,r,a,i,o,u,c,s,l,f,p,h,d,y)}catch(t){if(Me(b),t!==t+0)throw t;Se(1,0)}},fa:function(t,e,n,r,a,i,o,u){var c=Ee();try{Pe(t,e,n,r,a,i,o,u)}catch(t){if(Me(c),t!==t+0)throw t;Se(1,0)}},da:function(t,e,n,r,a,i,o,u,c,s,l,f){var p=Ee();try{Fe(t,e,n,r,a,i,o,u,c,s,l,f)}catch(t){if(Me(p),t!==t+0)throw t;Se(1,0)}},ea:function(t,e,n,r,a,i){var o=Ee();try{Ue(t,e,n,r,a,i)}catch(t){if(Me(o),t!==t+0)throw t;Se(1,0)}},o:function(t){return t},a:j||u.wasmMemory,G:function(t){oe=t},la:le,z:function(t,e,n,r){return le(t,e,n,r)}};!function(){function t(t,e){u.asm=t.exports,ht.qc.push(u.asm.sb),$=u.asm.ub,X.unshift(u.asm.Va),k=e,O||(et--,u.monitorRunDependencies&&u.monitorRunDependencies(et),0==et&&(null!==nt&&(clearInterval(nt),nt=null),rt&&(t=rt,rt=null,t())))}function e(e){t(e.instance,e.module)}function n(t){return function(){if(!M&&(v||w)){if(\"function\"==typeof fetch&&!tt.startsWith(\"file://\"))return fetch(tt,{credentials:\"same-origin\"}).then((function(t){if(!t.ok)throw\"failed to load wasm binary file at \\'\"+tt+\"\\'\";return t.arrayBuffer()})).catch((function(){return ot()}));if(f)return new Promise((function(t,e){f(tt,(function(e){t(new Uint8Array(e))}),e)}))}return Promise.resolve().then((function(){return ot()}))}().then((function(t){return WebAssembly.instantiate(t,r)})).then((function(t){return t})).then(t,(function(t){x(\"failed to asynchronously prepare wasm: \"+t),at(t)}))}var r={a:pe};if(O||(et++,u.monitorRunDependencies&&u.monitorRunDependencies(et)),u.instantiateWasm)try{return u.instantiateWasm(r,t)}catch(t){return x(\"Module.instantiateWasm callback failed with error: \"+t),!1}(M||\"function\"!=typeof WebAssembly.instantiateStreaming||it()||tt.startsWith(\"file://\")||_||\"function\"!=typeof fetch?n(e):fetch(tt,{credentials:\"same-origin\"}).then((function(t){return WebAssembly.instantiateStreaming(t,r).then(e,(function(t){return x(\"wasm streaming compile failed: \"+t),x(\"falling back to ArrayBuffer instantiation\"),n(e)}))}))).catch(s)}(),u.___wasm_call_ctors=function(){return(u.___wasm_call_ctors=u.asm.Va).apply(null,arguments)},u._OrtInit=function(){return(u._OrtInit=u.asm.Wa).apply(null,arguments)},u._OrtCreateSessionOptions=function(){return(u._OrtCreateSessionOptions=u.asm.Xa).apply(null,arguments)},u._OrtAppendExecutionProvider=function(){return(u._OrtAppendExecutionProvider=u.asm.Ya).apply(null,arguments)},u._OrtAddSessionConfigEntry=function(){return(u._OrtAddSessionConfigEntry=u.asm.Za).apply(null,arguments)},u._OrtReleaseSessionOptions=function(){return(u._OrtReleaseSessionOptions=u.asm._a).apply(null,arguments)},u._OrtCreateSession=function(){return(u._OrtCreateSession=u.asm.$a).apply(null,arguments)},u._OrtReleaseSession=function(){return(u._OrtReleaseSession=u.asm.ab).apply(null,arguments)},u._OrtGetInputCount=function(){return(u._OrtGetInputCount=u.asm.bb).apply(null,arguments)},u._OrtGetOutputCount=function(){return(u._OrtGetOutputCount=u.asm.cb).apply(null,arguments)},u._OrtGetInputName=function(){return(u._OrtGetInputName=u.asm.db).apply(null,arguments)},u._OrtGetOutputName=function(){return(u._OrtGetOutputName=u.asm.eb).apply(null,arguments)},u._OrtFree=function(){return(u._OrtFree=u.asm.fb).apply(null,arguments)},u._OrtCreateTensor=function(){return(u._OrtCreateTensor=u.asm.gb).apply(null,arguments)},u._OrtGetTensorData=function(){return(u._OrtGetTensorData=u.asm.hb).apply(null,arguments)},u._OrtReleaseTensor=function(){return(u._OrtReleaseTensor=u.asm.ib).apply(null,arguments)},u._OrtCreateRunOptions=function(){return(u._OrtCreateRunOptions=u.asm.jb).apply(null,arguments)},u._OrtAddRunConfigEntry=function(){return(u._OrtAddRunConfigEntry=u.asm.kb).apply(null,arguments)},u._OrtReleaseRunOptions=function(){return(u._OrtReleaseRunOptions=u.asm.lb).apply(null,arguments)},u._OrtRun=function(){return(u._OrtRun=u.asm.mb).apply(null,arguments)},u._OrtEndProfiling=function(){return(u._OrtEndProfiling=u.asm.nb).apply(null,arguments)};var he=u._pthread_self=function(){return(he=u._pthread_self=u.asm.ob).apply(null,arguments)},de=u._malloc=function(){return(de=u._malloc=u.asm.pb).apply(null,arguments)},ye=u._free=function(){return(ye=u._free=u.asm.qb).apply(null,arguments)},be=u._fflush=function(){return(be=u._fflush=u.asm.rb).apply(null,arguments)};u.__emscripten_tls_init=function(){return(u.__emscripten_tls_init=u.asm.sb).apply(null,arguments)};var me=u.___funcs_on_exit=function(){return(me=u.___funcs_on_exit=u.asm.tb).apply(null,arguments)},ge=u.__emscripten_thread_init=function(){return(ge=u.__emscripten_thread_init=u.asm.vb).apply(null,arguments)};u.__emscripten_thread_crashed=function(){return(u.__emscripten_thread_crashed=u.asm.wb).apply(null,arguments)};var ve,we=u._emscripten_run_in_main_runtime_thread_js=function(){return(we=u._emscripten_run_in_main_runtime_thread_js=u.asm.xb).apply(null,arguments)},_e=u.__emscripten_proxy_execute_task_queue=function(){return(_e=u.__emscripten_proxy_execute_task_queue=u.asm.yb).apply(null,arguments)},Oe=u.__emscripten_thread_free_data=function(){return(Oe=u.__emscripten_thread_free_data=u.asm.zb).apply(null,arguments)},Ae=u.__emscripten_thread_exit=function(){return(Ae=u.__emscripten_thread_exit=u.asm.Ab).apply(null,arguments)},Se=u._setThrew=function(){return(Se=u._setThrew=u.asm.Bb).apply(null,arguments)},Te=u._emscripten_stack_set_limits=function(){return(Te=u._emscripten_stack_set_limits=u.asm.Cb).apply(null,arguments)},Ee=u.stackSave=function(){return(Ee=u.stackSave=u.asm.Db).apply(null,arguments)},Me=u.stackRestore=function(){return(Me=u.stackRestore=u.asm.Eb).apply(null,arguments)},Ce=u.stackAlloc=function(){return(Ce=u.stackAlloc=u.asm.Fb).apply(null,arguments)},xe=u.___cxa_can_catch=function(){return(xe=u.___cxa_can_catch=u.asm.Gb).apply(null,arguments)},Re=u.___cxa_is_pointer_type=function(){return(Re=u.___cxa_is_pointer_type=u.asm.Hb).apply(null,arguments)},je=u.dynCall_j=function(){return(je=u.dynCall_j=u.asm.Ib).apply(null,arguments)},ke=u.dynCall_iiiiij=function(){return(ke=u.dynCall_iiiiij=u.asm.Jb).apply(null,arguments)},De=u.dynCall_jii=function(){return(De=u.dynCall_jii=u.asm.Kb).apply(null,arguments)},Pe=u.dynCall_viiiiij=function(){return(Pe=u.dynCall_viiiiij=u.asm.Lb).apply(null,arguments)},Ue=u.dynCall_vjji=function(){return(Ue=u.dynCall_vjji=u.asm.Mb).apply(null,arguments)},Fe=u.dynCall_viiijjjii=function(){return(Fe=u.dynCall_viiijjjii=u.asm.Nb).apply(null,arguments)},Ie=u.dynCall_iij=function(){return(Ie=u.dynCall_iij=u.asm.Ob).apply(null,arguments)},We=u.dynCall_ji=function(){return(We=u.dynCall_ji=u.asm.Pb).apply(null,arguments)},He=u.dynCall_iiiiiij=function(){return(He=u.dynCall_iiiiiij=u.asm.Qb).apply(null,arguments)},Le=u.dynCall_iiij=function(){return(Le=u.dynCall_iiij=u.asm.Rb).apply(null,arguments)};function ze(){function t(){if(!ve&&(ve=!0,u.calledRun=!0,!H)&&(O||dt(X),c(u),u.onRuntimeInitialized&&u.onRuntimeInitialized(),!O)){if(u.postRun)for(\"function\"==typeof u.postRun&&(u.postRun=[u.postRun]);u.postRun.length;){var t=u.postRun.shift();Z.unshift(t)}dt(Z)}}if(!(0<et))if(O)c(u),O||dt(X),postMessage({cmd:\"loaded\"});else{if(u.preRun)for(\"function\"==typeof u.preRun&&(u.preRun=[u.preRun]);u.preRun.length;)K();dt(q),0<et||(u.setStatus?(u.setStatus(\"Running...\"),setTimeout((function(){setTimeout((function(){u.setStatus(\"\")}),1),t()}),1)):t())}}if(u.UTF8ToString=Y,u.stringToUTF8=function(t,e,n){return B(t,r(),e,n)},u.lengthBytesUTF8=G,u.keepRuntimeAlive=Q,u.wasmMemory=j,u.stackSave=Ee,u.stackRestore=Me,u.stackAlloc=Ce,u.ExitStatus=ct,u.PThread=ht,rt=function t(){ve||ze(),ve||(rt=t)},u.preInit)for(\"function\"==typeof u.preInit&&(u.preInit=[u.preInit]);0<u.preInit.length;)u.preInit.pop()();return ze(),t.ready});t.exports=r},932:(t,e,n)=>{var _scriptDir,r=(_scriptDir=(_scriptDir=\"undefined\"!=typeof document&&document.currentScript?document.currentScript.src:void 0)||\"/index.js\",function(t){var e,r,a;t=t||{},e||(e=void 0!==t?t:{}),e.ready=new Promise((function(t,e){r=t,a=e}));var i,o,u,c,s,l,f=Object.assign({},e),p=\"./this.program\",h=(t,e)=>{throw e},d=\"object\"==typeof window,y=\"function\"==typeof importScripts,b=\"object\"==typeof process&&\"object\"==typeof process.versions&&\"string\"==typeof process.versions.node,m=\"\";b?(m=y?n(908).dirname(m)+\"/\":\"//\",l=()=>{s||(c=n(384),s=n(908))},i=function(t,e){return l(),t=s.normalize(t),c.readFileSync(t,e?void 0:\"utf8\")},u=t=>((t=i(t,!0)).buffer||(t=new Uint8Array(t)),t),o=(t,e,n)=>{l(),t=s.normalize(t),c.readFile(t,(function(t,r){t?n(t):e(r.buffer)}))},1<process.argv.length&&(p=process.argv[1].replace(/\\\\\\\\/g,\"/\")),process.argv.slice(2),process.on(\"uncaughtException\",(function(t){if(!(t instanceof J))throw t})),process.on(\"unhandledRejection\",(function(t){throw t})),h=(t,e)=>{if(_||0<L)throw process.exitCode=t,e;e instanceof J||w(\"exiting due to exception: \"+e),process.exit(t)},e.inspect=function(){return\"[Emscripten Module object]\"}):(d||y)&&(y?m=self.location.href:\"undefined\"!=typeof document&&document.currentScript&&(m=document.currentScript.src),_scriptDir&&(m=_scriptDir),m=0!==m.indexOf(\"blob:\")?m.substr(0,m.replace(/[?#].*/,\"\").lastIndexOf(\"/\")+1):\"\",i=t=>{var e=new XMLHttpRequest;return e.open(\"GET\",t,!1),e.send(null),e.responseText},y&&(u=t=>{var e=new XMLHttpRequest;return e.open(\"GET\",t,!1),e.responseType=\"arraybuffer\",e.send(null),new Uint8Array(e.response)}),o=(t,e,n)=>{var r=new XMLHttpRequest;r.open(\"GET\",t,!0),r.responseType=\"arraybuffer\",r.onload=()=>{200==r.status||0==r.status&&r.response?e(r.response):n()},r.onerror=n,r.send(null)});var g,v=e.print||console.log.bind(console),w=e.printErr||console.warn.bind(console);Object.assign(e,f),f=null,e.thisProgram&&(p=e.thisProgram),e.quit&&(h=e.quit),e.wasmBinary&&(g=e.wasmBinary);var _=e.noExitRuntime||!1;\"object\"!=typeof WebAssembly&&V(\"no native wasm support detected\");var O,A,S,T,E,M,C=!1,x=\"undefined\"!=typeof TextDecoder?new TextDecoder(\"utf8\"):void 0;function R(t,e,n){var r=(e>>>=0)+n;for(n=e;t[n]&&!(n>=r);)++n;if(16<n-e&&t.buffer&&x)return x.decode(t.subarray(e,n));for(r=\"\";e<n;){var a=t[e++];if(128&a){var i=63&t[e++];if(192==(224&a))r+=String.fromCharCode((31&a)<<6|i);else{var o=63&t[e++];65536>(a=224==(240&a)?(15&a)<<12|i<<6|o:(7&a)<<18|i<<12|o<<6|63&t[e++])?r+=String.fromCharCode(a):(a-=65536,r+=String.fromCharCode(55296|a>>10,56320|1023&a))}}else r+=String.fromCharCode(a)}return r}function j(t,e){return(t>>>=0)?R(T,t,e):\"\"}function k(t,e,n,r){if(!(0<r))return 0;var a=n>>>=0;r=n+r-1;for(var i=0;i<t.length;++i){var o=t.charCodeAt(i);if(55296<=o&&57343>=o&&(o=65536+((1023&o)<<10)|1023&t.charCodeAt(++i)),127>=o){if(n>=r)break;e[n++>>>0]=o}else{if(2047>=o){if(n+1>=r)break;e[n++>>>0]=192|o>>6}else{if(65535>=o){if(n+2>=r)break;e[n++>>>0]=224|o>>12}else{if(n+3>=r)break;e[n++>>>0]=240|o>>18,e[n++>>>0]=128|o>>12&63}e[n++>>>0]=128|o>>6&63}e[n++>>>0]=128|63&o}}return e[n>>>0]=0,n-a}function D(t){for(var e=0,n=0;n<t.length;++n){var r=t.charCodeAt(n);127>=r?e++:2047>=r?e+=2:55296<=r&&57343>=r?(e+=4,++n):e+=3}return e}function P(){var t=O.buffer;A=t,e.HEAP8=S=new Int8Array(t),e.HEAP16=new Int16Array(t),e.HEAP32=E=new Int32Array(t),e.HEAPU8=T=new Uint8Array(t),e.HEAPU16=new Uint16Array(t),e.HEAPU32=M=new Uint32Array(t),e.HEAPF32=new Float32Array(t),e.HEAPF64=new Float64Array(t)}var U,F=[],I=[],W=[],H=[],L=0;function z(){var t=e.preRun.shift();F.unshift(t)}var Y,B=0,G=null,N=null;function V(t){throw e.onAbort&&e.onAbort(t),w(t=\"Aborted(\"+t+\")\"),C=!0,t=new WebAssembly.RuntimeError(t+\". Build with -sASSERTIONS for more info.\"),a(t),t}function $(){return Y.startsWith(\"data:application/octet-stream;base64,\")}if(Y=\"ort-wasm.wasm\",!$()){var q=Y;Y=e.locateFile?e.locateFile(q,m):m+q}function X(){var t=Y;try{if(t==Y&&g)return new Uint8Array(g);if(u)return u(t);throw\"both async and sync fetching of the wasm failed\"}catch(t){V(t)}}function J(t){this.name=\"ExitStatus\",this.message=\"Program terminated with exit(\"+t+\")\",this.status=t}function Z(t){for(;0<t.length;)t.shift()(e)}var Q=[],K=0,tt=0;function et(t){this.Db=t,this.zb=t-24,this.Ub=function(t){M[this.zb+4>>2>>>0]=t},this.Eb=function(){return M[this.zb+4>>2>>>0]},this.Sb=function(t){M[this.zb+8>>2>>>0]=t},this.Wb=function(){return M[this.zb+8>>2>>>0]},this.Tb=function(){E[this.zb>>2>>>0]=0},this.Ib=function(t){S[this.zb+12>>0>>>0]=t?1:0},this.Pb=function(){return 0!=S[this.zb+12>>0>>>0]},this.Jb=function(t){S[this.zb+13>>0>>>0]=t?1:0},this.Lb=function(){return 0!=S[this.zb+13>>0>>>0]},this.Rb=function(t,e){this.Fb(0),this.Ub(t),this.Sb(e),this.Tb(),this.Ib(!1),this.Jb(!1)},this.Nb=function(){E[this.zb>>2>>>0]+=1},this.Xb=function(){var t=E[this.zb>>2>>>0];return E[this.zb>>2>>>0]=t-1,1===t},this.Fb=function(t){M[this.zb+16>>2>>>0]=t},this.Ob=function(){return M[this.zb+16>>2>>>0]},this.Qb=function(){if(Mt(this.Eb()))return M[this.Db>>2>>>0];var t=this.Ob();return 0!==t?t:this.Db}}function nt(t){return vt(new et(t).zb)}var rt=[];function at(t){var e=rt[t];return e||(t>=rt.length&&(rt.length=t+1),rt[t]=e=U.get(t)),e}function it(t){var e=D(t)+1,n=gt(e);return n&&k(t,S,n,e),n}var ot={};function ut(){if(!ct){var t,e={USER:\"web_user\",LOGNAME:\"web_user\",PATH:\"/\",PWD:\"/\",HOME:\"/home/web_user\",LANG:(\"object\"==typeof navigator&&navigator.languages&&navigator.languages[0]||\"C\").replace(\"-\",\"_\")+\".UTF-8\",_:p||\"./this.program\"};for(t in ot)void 0===ot[t]?delete e[t]:e[t]=ot[t];var n=[];for(t in e)n.push(t+\"=\"+e[t]);ct=n}return ct}var ct,st=[null,[],[]];function lt(t,e){var n=st[t];0===e||10===e?((1===t?v:w)(R(n,0)),n.length=0):n.push(e)}var ft=0;function pt(t){return 0==t%4&&(0!=t%100||0==t%400)}var ht=[31,29,31,30,31,30,31,31,30,31,30,31],dt=[31,28,31,30,31,30,31,31,30,31,30,31];function yt(t,e,n,r){function a(t,e,n){for(t=\"number\"==typeof t?t.toString():t||\"\";t.length<e;)t=n[0]+t;return t}function i(t,e){return a(t,e,\"0\")}function o(t,e){function n(t){return 0>t?-1:0<t?1:0}var r;return 0===(r=n(t.getFullYear()-e.getFullYear()))&&0===(r=n(t.getMonth()-e.getMonth()))&&(r=n(t.getDate()-e.getDate())),r}function u(t){switch(t.getDay()){case 0:return new Date(t.getFullYear()-1,11,29);case 1:return t;case 2:return new Date(t.getFullYear(),0,3);case 3:return new Date(t.getFullYear(),0,2);case 4:return new Date(t.getFullYear(),0,1);case 5:return new Date(t.getFullYear()-1,11,31);case 6:return new Date(t.getFullYear()-1,11,30)}}function c(t){var e=t.Bb;for(t=new Date(new Date(t.Cb+1900,0,1).getTime());0<e;){var n=t.getMonth(),r=(pt(t.getFullYear())?ht:dt)[n];if(!(e>r-t.getDate())){t.setDate(t.getDate()+e);break}e-=r-t.getDate()+1,t.setDate(1),11>n?t.setMonth(n+1):(t.setMonth(0),t.setFullYear(t.getFullYear()+1))}return n=new Date(t.getFullYear()+1,0,4),e=u(new Date(t.getFullYear(),0,4)),n=u(n),0>=o(e,t)?0>=o(n,t)?t.getFullYear()+1:t.getFullYear():t.getFullYear()-1}var s=E[r+40>>2>>>0];for(var l in r={$b:E[r>>2>>>0],Zb:E[r+4>>2>>>0],Gb:E[r+8>>2>>>0],Kb:E[r+12>>2>>>0],Hb:E[r+16>>2>>>0],Cb:E[r+20>>2>>>0],Ab:E[r+24>>2>>>0],Bb:E[r+28>>2>>>0],bc:E[r+32>>2>>>0],Yb:E[r+36>>2>>>0],ac:s?j(s):\"\"},n=j(n),s={\"%c\":\"%a %b %d %H:%M:%S %Y\",\"%D\":\"%m/%d/%y\",\"%F\":\"%Y-%m-%d\",\"%h\":\"%b\",\"%r\":\"%I:%M:%S %p\",\"%R\":\"%H:%M\",\"%T\":\"%H:%M:%S\",\"%x\":\"%m/%d/%y\",\"%X\":\"%H:%M:%S\",\"%Ec\":\"%c\",\"%EC\":\"%C\",\"%Ex\":\"%m/%d/%y\",\"%EX\":\"%H:%M:%S\",\"%Ey\":\"%y\",\"%EY\":\"%Y\",\"%Od\":\"%d\",\"%Oe\":\"%e\",\"%OH\":\"%H\",\"%OI\":\"%I\",\"%Om\":\"%m\",\"%OM\":\"%M\",\"%OS\":\"%S\",\"%Ou\":\"%u\",\"%OU\":\"%U\",\"%OV\":\"%V\",\"%Ow\":\"%w\",\"%OW\":\"%W\",\"%Oy\":\"%y\"})n=n.replace(new RegExp(l,\"g\"),s[l]);var f=\"Sunday Monday Tuesday Wednesday Thursday Friday Saturday\".split(\" \"),p=\"January February March April May June July August September October November December\".split(\" \");for(l in s={\"%a\":function(t){return f[t.Ab].substring(0,3)},\"%A\":function(t){return f[t.Ab]},\"%b\":function(t){return p[t.Hb].substring(0,3)},\"%B\":function(t){return p[t.Hb]},\"%C\":function(t){return i((t.Cb+1900)/100|0,2)},\"%d\":function(t){return i(t.Kb,2)},\"%e\":function(t){return a(t.Kb,2,\" \")},\"%g\":function(t){return c(t).toString().substring(2)},\"%G\":function(t){return c(t)},\"%H\":function(t){return i(t.Gb,2)},\"%I\":function(t){return 0==(t=t.Gb)?t=12:12<t&&(t-=12),i(t,2)},\"%j\":function(t){for(var e=0,n=0;n<=t.Hb-1;e+=(pt(t.Cb+1900)?ht:dt)[n++]);return i(t.Kb+e,3)},\"%m\":function(t){return i(t.Hb+1,2)},\"%M\":function(t){return i(t.Zb,2)},\"%n\":function(){return\"\\\\n\"},\"%p\":function(t){return 0<=t.Gb&&12>t.Gb?\"AM\":\"PM\"},\"%S\":function(t){return i(t.$b,2)},\"%t\":function(){return\"\\\\t\"},\"%u\":function(t){return t.Ab||7},\"%U\":function(t){return i(Math.floor((t.Bb+7-t.Ab)/7),2)},\"%V\":function(t){var e=Math.floor((t.Bb+7-(t.Ab+6)%7)/7);if(2>=(t.Ab+371-t.Bb-2)%7&&e++,e)53==e&&(4==(n=(t.Ab+371-t.Bb)%7)||3==n&&pt(t.Cb)||(e=1));else{e=52;var n=(t.Ab+7-t.Bb-1)%7;(4==n||5==n&&pt(t.Cb%400-1))&&e++}return i(e,2)},\"%w\":function(t){return t.Ab},\"%W\":function(t){return i(Math.floor((t.Bb+7-(t.Ab+6)%7)/7),2)},\"%y\":function(t){return(t.Cb+1900).toString().substring(2)},\"%Y\":function(t){return t.Cb+1900},\"%z\":function(t){var e=0<=(t=t.Yb);return t=Math.abs(t)/60,(e?\"+\":\"-\")+String(\"0000\"+(t/60*100+t%60)).slice(-4)},\"%Z\":function(t){return t.ac},\"%%\":function(){return\"%\"}},n=n.replace(/%%/g,\"\\\\0\\\\0\"),s)n.includes(l)&&(n=n.replace(new RegExp(l,\"g\"),s[l](r)));return l=function(t){var e=Array(D(t)+1);return k(t,e,0,e.length),e}(n=n.replace(/\\\\0\\\\0/g,\"%\")),l.length>e?0:(S.set(l,t>>>0),l.length-1)}var bt={a:function(t){return gt(t+24)+24},m:function(t){return(t=new et(t)).Pb()||(t.Ib(!0),K--),t.Jb(!1),Q.push(t),t.Nb(),t.Qb()},ia:function(t){throw w(\"Unexpected exception thrown, this is not properly supported - aborting\"),C=!0,t},w:function(){Ot(0);var t=Q.pop();if(t.Xb()&&!t.Lb()){var e=t.Wb();e&&at(e)(t.Db),nt(t.Db)}tt=0},d:function(){var t=tt;if(!t)return ft=0;var e=new et(t);e.Fb(t);var n=e.Eb();if(!n)return ft=0,t;for(var r=Array.prototype.slice.call(arguments),a=0;a<r.length;a++){var i=r[a];if(0===i||i===n)break;if(Et(i,n,e.zb+16))return ft=i,t}return ft=n,t},k:function(){var t=tt;if(!t)return ft=0;var e=new et(t);e.Fb(t);var n=e.Eb();if(!n)return ft=0,t;for(var r=Array.prototype.slice.call(arguments),a=0;a<r.length;a++){var i=r[a];if(0===i||i===n)break;if(Et(i,n,e.zb+16))return ft=i,t}return ft=n,t},g:function(){var t=tt;if(!t)return ft=0;var e=new et(t);e.Fb(t);var n=e.Eb();if(!n)return ft=0,t;for(var r=Array.prototype.slice.call(arguments),a=0;a<r.length;a++){var i=r[a];if(0===i||i===n)break;if(Et(i,n,e.zb+16))return ft=i,t}return ft=n,t},s:nt,L:function(){var t=Q.pop();t||V(\"no exception to throw\");var e=t.Db;throw t.Lb()||(Q.push(t),t.Jb(!0),t.Ib(!1),K++),tt=e,e},b:function(t,e,n){throw new et(t).Rb(e,n),tt=t,K++,t},la:function(){return K},i:function(t){throw tt||(tt=t),t},H:function(){return 0},Ba:function(){},pa:function(){},ra:function(){},ka:function(){return 0},za:function(){},ua:function(){},ya:function(){},R:function(){},qa:function(){},na:function(){},Aa:function(){},oa:function(){},Ha:function(){},Ja:function(){V(\"To use dlopen, you need enable dynamic linking, see https://github.com/emscripten-core/emscripten/wiki/Linking\")},Ia:function(){V(\"To use dlopen, you need enable dynamic linking, see https://github.com/emscripten-core/emscripten/wiki/Linking\")},S:function(){return Date.now()},Ca:function(){return!0},Da:function(t,e){t=new Date(1e3*(M[t>>>2]+4294967296*E[t+4>>>2])),E[e>>2>>>0]=t.getUTCSeconds(),E[e+4>>2>>>0]=t.getUTCMinutes(),E[e+8>>2>>>0]=t.getUTCHours(),E[e+12>>2>>>0]=t.getUTCDate(),E[e+16>>2>>>0]=t.getUTCMonth(),E[e+20>>2>>>0]=t.getUTCFullYear()-1900,E[e+24>>2>>>0]=t.getUTCDay(),E[e+28>>2>>>0]=(t.getTime()-Date.UTC(t.getUTCFullYear(),0,1,0,0,0,0))/864e5|0},Ea:function(t,e){t=new Date(1e3*(M[t>>>2]+4294967296*E[t+4>>>2])),E[e>>2>>>0]=t.getSeconds(),E[e+4>>2>>>0]=t.getMinutes(),E[e+8>>2>>>0]=t.getHours(),E[e+12>>2>>>0]=t.getDate(),E[e+16>>2>>>0]=t.getMonth(),E[e+20>>2>>>0]=t.getFullYear()-1900,E[e+24>>2>>>0]=t.getDay();var n=new Date(t.getFullYear(),0,1);E[e+28>>2>>>0]=(t.getTime()-n.getTime())/864e5|0,E[e+36>>2>>>0]=-60*t.getTimezoneOffset();var r=new Date(t.getFullYear(),6,1).getTimezoneOffset();n=n.getTimezoneOffset(),E[e+32>>2>>>0]=0|(r!=n&&t.getTimezoneOffset()==Math.min(n,r))},Fa:function(t){var e=new Date(E[t+20>>2>>>0]+1900,E[t+16>>2>>>0],E[t+12>>2>>>0],E[t+8>>2>>>0],E[t+4>>2>>>0],E[t>>2>>>0],0),n=E[t+32>>2>>>0],r=e.getTimezoneOffset(),a=new Date(e.getFullYear(),0,1),i=new Date(e.getFullYear(),6,1).getTimezoneOffset(),o=a.getTimezoneOffset(),u=Math.min(o,i);return 0>n?E[t+32>>2>>>0]=Number(i!=o&&u==r):0<n!=(u==r)&&(i=Math.max(o,i),e.setTime(e.getTime()+6e4*((0<n?u:i)-r))),E[t+24>>2>>>0]=e.getDay(),E[t+28>>2>>>0]=(e.getTime()-a.getTime())/864e5|0,E[t>>2>>>0]=e.getSeconds(),E[t+4>>2>>>0]=e.getMinutes(),E[t+8>>2>>>0]=e.getHours(),E[t+12>>2>>>0]=e.getDate(),E[t+16>>2>>>0]=e.getMonth(),e.getTime()/1e3|0},sa:function(){return-52},ta:function(){},Ga:function t(e,n,r){t.Vb||(t.Vb=!0,function(t,e,n){function r(t){return(t=t.toTimeString().match(/\\\\(([A-Za-z ]+)\\\\)$/))?t[1]:\"GMT\"}var a=(new Date).getFullYear(),i=new Date(a,0,1),o=new Date(a,6,1);a=i.getTimezoneOffset();var u=o.getTimezoneOffset();E[t>>2>>>0]=60*Math.max(a,u),E[e>>2>>>0]=Number(a!=u),t=r(i),e=r(o),t=it(t),e=it(e),u<a?(M[n>>2>>>0]=t,M[n+4>>2>>>0]=e):(M[n>>2>>>0]=e,M[n+4>>2>>>0]=t)}(e,n,r))},B:function(){V(\"\")},ma:function(){return 4294901760},I:b?()=>{var t=process.hrtime();return 1e3*t[0]+t[1]/1e6}:()=>performance.now(),xa:function(t,e,n){T.copyWithin(t>>>0,e>>>0,e+n>>>0)},G:function(t){var e=T.length;if(4294901760<(t>>>=0))return!1;for(var n=1;4>=n;n*=2){var r=e*(1+.2/n);r=Math.min(r,t+100663296);var a=Math;r=Math.max(t,r),a=a.min.call(a,4294901760,r+(65536-r%65536)%65536);t:{try{O.grow(a-A.byteLength+65535>>>16),P();var i=1;break t}catch(t){}i=void 0}if(i)return!0}return!1},va:function(t,e){var n=0;return ut().forEach((function(r,a){var i=e+n;for(a=M[t+4*a>>2>>>0]=i,i=0;i<r.length;++i)S[a++>>0>>>0]=r.charCodeAt(i);S[a>>0>>>0]=0,n+=r.length+1})),0},wa:function(t,e){var n=ut();M[t>>2>>>0]=n.length;var r=0;return n.forEach((function(t){r+=t.length+1})),M[e>>2>>>0]=r,0},ba:function(t){_||0<L||(_t(),Z(W),wt(0),st[1].length&&lt(1,10),st[2].length&&lt(2,10)),_||0<L||(e.onExit&&e.onExit(t),C=!0),h(t,new J(t))},E:function(){return 52},Q:function(){return 52},ca:function(){return 70},P:function(t,e,n,r){for(var a=0,i=0;i<n;i++){var o=M[e>>2>>>0],u=M[e+4>>2>>>0];e+=8;for(var c=0;c<u;c++)lt(t,T[o+c>>>0]);a+=u}return M[r>>2>>>0]=a,0},c:function(){return ft},ja:function t(e,r){t.Mb||(t.Mb=function(){if(\"object\"==typeof crypto&&\"function\"==typeof crypto.getRandomValues){var t=new Uint8Array(1);return()=>(crypto.getRandomValues(t),t[0])}if(b)try{var e=n(Object(function(){var t=new Error(\"Cannot find module \\'crypto\\'\");throw t.code=\"MODULE_NOT_FOUND\",t}()));return()=>e.randomBytes(1)[0]}catch(t){}return()=>V(\"randomDevice\")}());for(var a=0;a<r;a++)S[e+a>>0>>>0]=t.Mb();return 0},ea:function(t,e,n){var r=At();try{return at(t)(e,n)}catch(t){if(St(r),t!==t+0)throw t;Ot(1,0)}},fa:function(t,e,n){var r=At();try{return at(t)(e,n)}catch(t){if(St(r),t!==t+0)throw t;Ot(1,0)}},J:function(t){var e=At();try{return at(t)()}catch(t){if(St(e),t!==t+0)throw t;Ot(1,0)}},e:function(t,e){var n=At();try{return at(t)(e)}catch(t){if(St(n),t!==t+0)throw t;Ot(1,0)}},N:function(t,e,n){var r=At();try{return at(t)(e,n)}catch(t){if(St(r),t!==t+0)throw t;Ot(1,0)}},O:function(t,e,n){var r=At();try{return at(t)(e,n)}catch(t){if(St(r),t!==t+0)throw t;Ot(1,0)}},j:function(t,e,n){var r=At();try{return at(t)(e,n)}catch(t){if(St(r),t!==t+0)throw t;Ot(1,0)}},o:function(t,e,n,r){var a=At();try{return at(t)(e,n,r)}catch(t){if(St(a),t!==t+0)throw t;Ot(1,0)}},p:function(t,e,n,r,a){var i=At();try{return at(t)(e,n,r,a)}catch(t){if(St(i),t!==t+0)throw t;Ot(1,0)}},M:function(t,e,n,r,a,i){var o=At();try{return at(t)(e,n,r,a,i)}catch(t){if(St(o),t!==t+0)throw t;Ot(1,0)}},r:function(t,e,n,r,a,i){var o=At();try{return at(t)(e,n,r,a,i)}catch(t){if(St(o),t!==t+0)throw t;Ot(1,0)}},v:function(t,e,n,r,a,i,o){var u=At();try{return at(t)(e,n,r,a,i,o)}catch(t){if(St(u),t!==t+0)throw t;Ot(1,0)}},K:function(t,e,n,r,a,i,o,u){var c=At();try{return at(t)(e,n,r,a,i,o,u)}catch(t){if(St(c),t!==t+0)throw t;Ot(1,0)}},D:function(t,e,n,r,a,i,o,u,c,s,l,f){var p=At();try{return at(t)(e,n,r,a,i,o,u,c,s,l,f)}catch(t){if(St(p),t!==t+0)throw t;Ot(1,0)}},X:function(t,e,n,r,a,i,o,u){var c=At();try{return Ft(t,e,n,r,a,i,o,u)}catch(t){if(St(c),t!==t+0)throw t;Ot(1,0)}},V:function(t,e,n,r,a,i,o){var u=At();try{return xt(t,e,n,r,a,i,o)}catch(t){if(St(u),t!==t+0)throw t;Ot(1,0)}},U:function(t,e,n,r,a){var i=At();try{return It(t,e,n,r,a)}catch(t){if(St(i),t!==t+0)throw t;Ot(1,0)}},Z:function(t,e,n,r){var a=At();try{return Pt(t,e,n,r)}catch(t){if(St(a),t!==t+0)throw t;Ot(1,0)}},W:function(t){var e=At();try{return Ct(t)}catch(t){if(St(e),t!==t+0)throw t;Ot(1,0)}},Y:function(t,e){var n=At();try{return Ut(t,e)}catch(t){if(St(n),t!==t+0)throw t;Ot(1,0)}},T:function(t,e,n){var r=At();try{return Rt(t,e,n)}catch(t){if(St(r),t!==t+0)throw t;Ot(1,0)}},f:function(t){var e=At();try{at(t)()}catch(t){if(St(e),t!==t+0)throw t;Ot(1,0)}},q:function(t,e){var n=At();try{at(t)(e)}catch(t){if(St(n),t!==t+0)throw t;Ot(1,0)}},h:function(t,e,n){var r=At();try{at(t)(e,n)}catch(t){if(St(r),t!==t+0)throw t;Ot(1,0)}},da:function(t,e,n,r){var a=At();try{at(t)(e,n,r)}catch(t){if(St(a),t!==t+0)throw t;Ot(1,0)}},l:function(t,e,n,r){var a=At();try{at(t)(e,n,r)}catch(t){if(St(a),t!==t+0)throw t;Ot(1,0)}},t:function(t,e,n,r,a){var i=At();try{at(t)(e,n,r,a)}catch(t){if(St(i),t!==t+0)throw t;Ot(1,0)}},u:function(t,e,n,r,a,i){var o=At();try{at(t)(e,n,r,a,i)}catch(t){if(St(o),t!==t+0)throw t;Ot(1,0)}},x:function(t,e,n,r,a,i,o){var u=At();try{at(t)(e,n,r,a,i,o)}catch(t){if(St(u),t!==t+0)throw t;Ot(1,0)}},z:function(t,e,n,r,a,i,o,u){var c=At();try{at(t)(e,n,r,a,i,o,u)}catch(t){if(St(c),t!==t+0)throw t;Ot(1,0)}},ga:function(t,e,n,r,a,i,o,u,c){var s=At();try{at(t)(e,n,r,a,i,o,u,c)}catch(t){if(St(s),t!==t+0)throw t;Ot(1,0)}},A:function(t,e,n,r,a,i,o,u,c,s,l){var f=At();try{at(t)(e,n,r,a,i,o,u,c,s,l)}catch(t){if(St(f),t!==t+0)throw t;Ot(1,0)}},C:function(t,e,n,r,a,i,o,u,c,s,l,f,p,h,d,y){var b=At();try{at(t)(e,n,r,a,i,o,u,c,s,l,f,p,h,d,y)}catch(t){if(St(b),t!==t+0)throw t;Ot(1,0)}},aa:function(t,e,n,r,a,i,o,u){var c=At();try{jt(t,e,n,r,a,i,o,u)}catch(t){if(St(c),t!==t+0)throw t;Ot(1,0)}},_:function(t,e,n,r,a,i,o,u,c,s,l,f){var p=At();try{Dt(t,e,n,r,a,i,o,u,c,s,l,f)}catch(t){if(St(p),t!==t+0)throw t;Ot(1,0)}},$:function(t,e,n,r,a,i){var o=At();try{kt(t,e,n,r,a,i)}catch(t){if(St(o),t!==t+0)throw t;Ot(1,0)}},n:function(t){return t},F:function(t){ft=t},ha:yt,y:function(t,e,n,r){return yt(t,e,n,r)}};!function(){function t(t){e.asm=t.exports,O=e.asm.Ka,P(),U=e.asm.ib,I.unshift(e.asm.La),B--,e.monitorRunDependencies&&e.monitorRunDependencies(B),0==B&&(null!==G&&(clearInterval(G),G=null),N&&(t=N,N=null,t()))}function n(e){t(e.instance)}function r(t){return function(){if(!g&&(d||y)){if(\"function\"==typeof fetch&&!Y.startsWith(\"file://\"))return fetch(Y,{credentials:\"same-origin\"}).then((function(t){if(!t.ok)throw\"failed to load wasm binary file at \\'\"+Y+\"\\'\";return t.arrayBuffer()})).catch((function(){return X()}));if(o)return new Promise((function(t,e){o(Y,(function(e){t(new Uint8Array(e))}),e)}))}return Promise.resolve().then((function(){return X()}))}().then((function(t){return WebAssembly.instantiate(t,i)})).then((function(t){return t})).then(t,(function(t){w(\"failed to asynchronously prepare wasm: \"+t),V(t)}))}var i={a:bt};if(B++,e.monitorRunDependencies&&e.monitorRunDependencies(B),e.instantiateWasm)try{return e.instantiateWasm(i,t)}catch(t){return w(\"Module.instantiateWasm callback failed with error: \"+t),!1}(g||\"function\"!=typeof WebAssembly.instantiateStreaming||$()||Y.startsWith(\"file://\")||b||\"function\"!=typeof fetch?r(n):fetch(Y,{credentials:\"same-origin\"}).then((function(t){return WebAssembly.instantiateStreaming(t,i).then(n,(function(t){return w(\"wasm streaming compile failed: \"+t),w(\"falling back to ArrayBuffer instantiation\"),r(n)}))}))).catch(a)}(),e.___wasm_call_ctors=function(){return(e.___wasm_call_ctors=e.asm.La).apply(null,arguments)},e._OrtInit=function(){return(e._OrtInit=e.asm.Ma).apply(null,arguments)},e._OrtCreateSessionOptions=function(){return(e._OrtCreateSessionOptions=e.asm.Na).apply(null,arguments)},e._OrtAppendExecutionProvider=function(){return(e._OrtAppendExecutionProvider=e.asm.Oa).apply(null,arguments)},e._OrtAddSessionConfigEntry=function(){return(e._OrtAddSessionConfigEntry=e.asm.Pa).apply(null,arguments)},e._OrtReleaseSessionOptions=function(){return(e._OrtReleaseSessionOptions=e.asm.Qa).apply(null,arguments)},e._OrtCreateSession=function(){return(e._OrtCreateSession=e.asm.Ra).apply(null,arguments)},e._OrtReleaseSession=function(){return(e._OrtReleaseSession=e.asm.Sa).apply(null,arguments)},e._OrtGetInputCount=function(){return(e._OrtGetInputCount=e.asm.Ta).apply(null,arguments)},e._OrtGetOutputCount=function(){return(e._OrtGetOutputCount=e.asm.Ua).apply(null,arguments)},e._OrtGetInputName=function(){return(e._OrtGetInputName=e.asm.Va).apply(null,arguments)},e._OrtGetOutputName=function(){return(e._OrtGetOutputName=e.asm.Wa).apply(null,arguments)},e._OrtFree=function(){return(e._OrtFree=e.asm.Xa).apply(null,arguments)},e._OrtCreateTensor=function(){return(e._OrtCreateTensor=e.asm.Ya).apply(null,arguments)},e._OrtGetTensorData=function(){return(e._OrtGetTensorData=e.asm.Za).apply(null,arguments)},e._OrtReleaseTensor=function(){return(e._OrtReleaseTensor=e.asm._a).apply(null,arguments)},e._OrtCreateRunOptions=function(){return(e._OrtCreateRunOptions=e.asm.$a).apply(null,arguments)},e._OrtAddRunConfigEntry=function(){return(e._OrtAddRunConfigEntry=e.asm.ab).apply(null,arguments)},e._OrtReleaseRunOptions=function(){return(e._OrtReleaseRunOptions=e.asm.bb).apply(null,arguments)},e._OrtRun=function(){return(e._OrtRun=e.asm.cb).apply(null,arguments)},e._OrtEndProfiling=function(){return(e._OrtEndProfiling=e.asm.db).apply(null,arguments)};var mt,gt=e._malloc=function(){return(gt=e._malloc=e.asm.eb).apply(null,arguments)},vt=e._free=function(){return(vt=e._free=e.asm.fb).apply(null,arguments)},wt=e._fflush=function(){return(wt=e._fflush=e.asm.gb).apply(null,arguments)},_t=e.___funcs_on_exit=function(){return(_t=e.___funcs_on_exit=e.asm.hb).apply(null,arguments)},Ot=e._setThrew=function(){return(Ot=e._setThrew=e.asm.jb).apply(null,arguments)},At=e.stackSave=function(){return(At=e.stackSave=e.asm.kb).apply(null,arguments)},St=e.stackRestore=function(){return(St=e.stackRestore=e.asm.lb).apply(null,arguments)},Tt=e.stackAlloc=function(){return(Tt=e.stackAlloc=e.asm.mb).apply(null,arguments)},Et=e.___cxa_can_catch=function(){return(Et=e.___cxa_can_catch=e.asm.nb).apply(null,arguments)},Mt=e.___cxa_is_pointer_type=function(){return(Mt=e.___cxa_is_pointer_type=e.asm.ob).apply(null,arguments)},Ct=e.dynCall_j=function(){return(Ct=e.dynCall_j=e.asm.pb).apply(null,arguments)},xt=e.dynCall_iiiiij=function(){return(xt=e.dynCall_iiiiij=e.asm.qb).apply(null,arguments)},Rt=e.dynCall_jii=function(){return(Rt=e.dynCall_jii=e.asm.rb).apply(null,arguments)},jt=e.dynCall_viiiiij=function(){return(jt=e.dynCall_viiiiij=e.asm.sb).apply(null,arguments)},kt=e.dynCall_vjji=function(){return(kt=e.dynCall_vjji=e.asm.tb).apply(null,arguments)},Dt=e.dynCall_viiijjjii=function(){return(Dt=e.dynCall_viiijjjii=e.asm.ub).apply(null,arguments)},Pt=e.dynCall_iij=function(){return(Pt=e.dynCall_iij=e.asm.vb).apply(null,arguments)},Ut=e.dynCall_ji=function(){return(Ut=e.dynCall_ji=e.asm.wb).apply(null,arguments)},Ft=e.dynCall_iiiiiij=function(){return(Ft=e.dynCall_iiiiiij=e.asm.xb).apply(null,arguments)},It=e.dynCall_iiij=function(){return(It=e.dynCall_iiij=e.asm.yb).apply(null,arguments)};function Wt(){function t(){if(!mt&&(mt=!0,e.calledRun=!0,!C)){if(Z(I),r(e),e.onRuntimeInitialized&&e.onRuntimeInitialized(),e.postRun)for(\"function\"==typeof e.postRun&&(e.postRun=[e.postRun]);e.postRun.length;){var t=e.postRun.shift();H.unshift(t)}Z(H)}}if(!(0<B)){if(e.preRun)for(\"function\"==typeof e.preRun&&(e.preRun=[e.preRun]);e.preRun.length;)z();Z(F),0<B||(e.setStatus?(e.setStatus(\"Running...\"),setTimeout((function(){setTimeout((function(){e.setStatus(\"\")}),1),t()}),1)):t())}}if(e.UTF8ToString=j,e.stringToUTF8=function(t,e,n){return k(t,T,e,n)},e.lengthBytesUTF8=D,e.stackSave=At,e.stackRestore=St,e.stackAlloc=Tt,N=function t(){mt||Wt(),mt||(N=t)},e.preInit)for(\"function\"==typeof e.preInit&&(e.preInit=[e.preInit]);0<e.preInit.length;)e.preInit.pop()();return Wt(),t.ready});t.exports=r},967:(t,e)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.iterateExtraOptions=void 0,e.iterateExtraOptions=(t,n,r,a)=>{if(\"object\"==typeof t&&null!==t){if(r.has(t))throw new Error(\"Circular reference in options\");r.add(t)}Object.entries(t).forEach((([t,i])=>{const o=n?n+t:t;if(\"object\"==typeof i)(0,e.iterateExtraOptions)(i,o+\".\",r,a);else if(\"string\"==typeof i||\"number\"==typeof i)a(o,i.toString());else{if(\"boolean\"!=typeof i)throw new Error(\"Can\\'t handle extra config type: \"+typeof i);a(o,i?\"1\":\"0\")}}))}},586:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.setRunOptions=void 0;const r=n(967),a=n(983),i=n(361);e.setRunOptions=t=>{const e=(0,i.getInstance)();let n=0;const o=[],u=t||{};try{if(void 0===(null==t?void 0:t.logSeverityLevel))u.logSeverityLevel=2;else if(\"number\"!=typeof t.logSeverityLevel||!Number.isInteger(t.logSeverityLevel)||t.logSeverityLevel<0||t.logSeverityLevel>4)throw new Error(`log serverity level is not valid: ${t.logSeverityLevel}`);if(void 0===(null==t?void 0:t.logVerbosityLevel))u.logVerbosityLevel=0;else if(\"number\"!=typeof t.logVerbosityLevel||!Number.isInteger(t.logVerbosityLevel))throw new Error(`log verbosity level is not valid: ${t.logVerbosityLevel}`);void 0===(null==t?void 0:t.terminate)&&(u.terminate=!1);let i=0;if(void 0!==(null==t?void 0:t.tag)&&(i=(0,a.allocWasmString)(t.tag,o)),n=e._OrtCreateRunOptions(u.logSeverityLevel,u.logVerbosityLevel,!!u.terminate,i),0===n)throw new Error(\"Can\\'t create run options\");return void 0!==(null==t?void 0:t.extra)&&(0,r.iterateExtraOptions)(t.extra,\"\",new WeakSet,((t,r)=>{const i=(0,a.allocWasmString)(t,o),u=(0,a.allocWasmString)(r,o);if(0!==e._OrtAddRunConfigEntry(n,i,u))throw new Error(`Can\\'t set a run config entry: ${t} - ${r}`)})),[n,o]}catch(t){throw 0!==n&&e._OrtReleaseRunOptions(n),o.forEach(e._free),t}}},919:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.setSessionOptions=void 0;const r=n(967),a=n(983),i=n(361);e.setSessionOptions=t=>{const e=(0,i.getInstance)();let n=0;const o=[],u=t||{};(t=>{t.extra||(t.extra={}),t.extra.session||(t.extra.session={});const e=t.extra.session;e.use_ort_model_bytes_directly||(e.use_ort_model_bytes_directly=\"1\")})(u);try{void 0===(null==t?void 0:t.graphOptimizationLevel)&&(u.graphOptimizationLevel=\"all\");const c=(t=>{switch(t){case\"disabled\":return 0;case\"basic\":return 1;case\"extended\":return 2;case\"all\":return 99;default:throw new Error(`unsupported graph optimization level: ${t}`)}})(u.graphOptimizationLevel);void 0===(null==t?void 0:t.enableCpuMemArena)&&(u.enableCpuMemArena=!0),void 0===(null==t?void 0:t.enableMemPattern)&&(u.enableMemPattern=!0),void 0===(null==t?void 0:t.executionMode)&&(u.executionMode=\"sequential\");const s=(t=>{switch(t){case\"sequential\":return 0;case\"parallel\":return 1;default:throw new Error(`unsupported execution mode: ${t}`)}})(u.executionMode);let l=0;if(void 0!==(null==t?void 0:t.logId)&&(l=(0,a.allocWasmString)(t.logId,o)),void 0===(null==t?void 0:t.logSeverityLevel))u.logSeverityLevel=2;else if(\"number\"!=typeof t.logSeverityLevel||!Number.isInteger(t.logSeverityLevel)||t.logSeverityLevel<0||t.logSeverityLevel>4)throw new Error(`log serverity level is not valid: ${t.logSeverityLevel}`);if(void 0===(null==t?void 0:t.logVerbosityLevel))u.logVerbosityLevel=0;else if(\"number\"!=typeof t.logVerbosityLevel||!Number.isInteger(t.logVerbosityLevel))throw new Error(`log verbosity level is not valid: ${t.logVerbosityLevel}`);if(void 0===(null==t?void 0:t.enableProfiling)&&(u.enableProfiling=!1),n=e._OrtCreateSessionOptions(c,!!u.enableCpuMemArena,!!u.enableMemPattern,s,!!u.enableProfiling,0,l,u.logSeverityLevel,u.logVerbosityLevel),0===n)throw new Error(\"Can\\'t create session options\");return(null==t?void 0:t.executionProviders)&&((t,e,n)=>{for(const r of e){let e=\"string\"==typeof r?r:r.name;switch(e){case\"xnnpack\":e=\"XNNPACK\";break;case\"wasm\":case\"cpu\":continue;default:throw new Error(`not supported EP: ${e}`)}const o=(0,a.allocWasmString)(e,n);if(0!==(0,i.getInstance)()._OrtAppendExecutionProvider(t,o))throw new Error(`Can\\'t append execution provider: ${e}`)}})(n,t.executionProviders,o),void 0!==(null==t?void 0:t.extra)&&(0,r.iterateExtraOptions)(t.extra,\"\",new WeakSet,((t,r)=>{const i=(0,a.allocWasmString)(t,o),u=(0,a.allocWasmString)(r,o);if(0!==e._OrtAddSessionConfigEntry(n,i,u))throw new Error(`Can\\'t set a session config entry: ${t} - ${r}`)})),[n,o]}catch(t){throw 0!==n&&e._OrtReleaseSessionOptions(n),o.forEach(e._free),t}}},983:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.allocWasmString=void 0;const r=n(361);e.allocWasmString=(t,e)=>{const n=(0,r.getInstance)(),a=n.lengthBytesUTF8(t)+1,i=n._malloc(a);return n.stringToUTF8(t,i,a),e.push(i),i}},349:(t,e,n)=>{\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.extractTransferableBuffers=e.endProfiling=e.run=e.releaseSession=e.createSession=e.createSessionFinalize=e.createSessionAllocate=e.initOrt=void 0;const r=n(586),a=n(919),i=n(983),o=n(361);e.initOrt=(t,e)=>{const n=(0,o.getInstance)()._OrtInit(t,e);if(0!==n)throw new Error(`Can\\'t initialize onnxruntime. error code = ${n}`)};const u=new Map;e.createSessionAllocate=t=>{const e=(0,o.getInstance)(),n=e._malloc(t.byteLength);return e.HEAPU8.set(t,n),[n,t.byteLength]},e.createSessionFinalize=(t,e)=>{const n=(0,o.getInstance)();let r=0,i=0,c=[];try{if([i,c]=(0,a.setSessionOptions)(e),r=n._OrtCreateSession(t[0],t[1],i),0===r)throw new Error(\"Can\\'t create a session\")}finally{n._free(t[0]),n._OrtReleaseSessionOptions(i),c.forEach(n._free)}const s=n._OrtGetInputCount(r),l=n._OrtGetOutputCount(r),f=[],p=[],h=[],d=[];for(let t=0;t<s;t++){const e=n._OrtGetInputName(r,t);if(0===e)throw new Error(\"Can\\'t get an input name\");p.push(e),f.push(n.UTF8ToString(e))}for(let t=0;t<l;t++){const e=n._OrtGetOutputName(r,t);if(0===e)throw new Error(\"Can\\'t get an output name\");d.push(e),h.push(n.UTF8ToString(e))}return u.set(r,[r,p,d]),[r,f,h]},e.createSession=(t,n)=>{const r=(0,e.createSessionAllocate)(t);return(0,e.createSessionFinalize)(r,n)},e.releaseSession=t=>{const e=(0,o.getInstance)(),n=u.get(t);if(!n)throw new Error(\"invalid session id\");const r=n[0],a=n[1],i=n[2];a.forEach(e._OrtFree),i.forEach(e._OrtFree),e._OrtReleaseSession(r),u.delete(t)};const c=t=>{switch(t){case\"int8\":return 3;case\"uint8\":return 2;case\"bool\":return 9;case\"int16\":return 5;case\"uint16\":return 4;case\"int32\":return 6;case\"uint32\":return 12;case\"float32\":return 1;case\"float64\":return 11;case\"string\":return 8;case\"int64\":return 7;case\"uint64\":return 13;default:throw new Error(`unsupported data type: ${t}`)}},s=t=>{switch(t){case 3:return\"int8\";case 2:return\"uint8\";case 9:return\"bool\";case 5:return\"int16\";case 4:return\"uint16\";case 6:return\"int32\";case 12:return\"uint32\";case 1:return\"float32\";case 11:return\"float64\";case 8:return\"string\";case 7:return\"int64\";case 13:return\"uint64\";default:throw new Error(`unsupported data type: ${t}`)}},l=t=>{switch(t){case\"float32\":return Float32Array;case\"uint8\":case\"bool\":return Uint8Array;case\"int8\":return Int8Array;case\"uint16\":return Uint16Array;case\"int16\":return Int16Array;case\"int32\":return Int32Array;case\"float64\":return Float64Array;case\"uint32\":return Uint32Array;case\"int64\":return BigInt64Array;case\"uint64\":return BigUint64Array;default:throw new Error(`unsupported type: ${t}`)}};e.run=(t,e,n,a,f)=>{const p=(0,o.getInstance)(),h=u.get(t);if(!h)throw new Error(\"invalid session id\");const d=h[0],y=h[1],b=h[2],m=e.length,g=a.length;let v=0,w=[];const _=[],O=[];try{[v,w]=(0,r.setRunOptions)(f);for(let t=0;t<m;t++){const e=n[t][0],r=n[t][1],a=n[t][2];let o,u;if(Array.isArray(a)){u=4*a.length,o=p._malloc(u),O.push(o);let t=o/4;for(let e=0;e<a.length;e++){if(\"string\"!=typeof a[e])throw new TypeError(`tensor data at index ${e} is not a string`);p.HEAPU32[t++]=(0,i.allocWasmString)(a[e],O)}}else u=a.byteLength,o=p._malloc(u),O.push(o),p.HEAPU8.set(new Uint8Array(a.buffer,a.byteOffset,u),o);const s=p.stackSave(),l=p.stackAlloc(4*r.length);try{let t=l/4;r.forEach((e=>p.HEAP32[t++]=e));const n=p._OrtCreateTensor(c(e),o,u,l,r.length);if(0===n)throw new Error(\"Can\\'t create a tensor\");_.push(n)}finally{p.stackRestore(s)}}const t=p.stackSave(),o=p.stackAlloc(4*m),u=p.stackAlloc(4*m),h=p.stackAlloc(4*g),A=p.stackAlloc(4*g);try{let n=o/4,r=u/4,i=h/4,c=A/4;for(let t=0;t<m;t++)p.HEAPU32[n++]=_[t],p.HEAPU32[r++]=y[e[t]];for(let t=0;t<g;t++)p.HEAPU32[i++]=0,p.HEAPU32[c++]=b[a[t]];let f=p._OrtRun(d,u,o,m,A,g,h,v);const w=[];if(0===f)for(let t=0;t<g;t++){const e=p.HEAPU32[h/4+t],n=p.stackSave(),r=p.stackAlloc(16);let a,i=0;try{if(f=p._OrtGetTensorData(e,r,r+4,r+8,r+12),0!==f)throw new Error(`Can\\'t access output tensor data. error code = ${f}`);let t=r/4;const o=p.HEAPU32[t++];i=p.HEAPU32[t++];const u=p.HEAPU32[t++],c=p.HEAPU32[t++],h=[];for(let t=0;t<c;t++)h.push(p.HEAPU32[u/4+t]);p._OrtFree(u);const d=0===h.length?1:h.reduce(((t,e)=>t*e));if(a=s(o),\"string\"===a){const t=[];let e=i/4;for(let n=0;n<d;n++){const r=p.HEAPU32[e++],a=n===d-1?void 0:p.HEAPU32[e]-r;t.push(p.UTF8ToString(r,a))}w.push([a,h,t])}else{const t=new(l(a))(d);new Uint8Array(t.buffer,t.byteOffset,t.byteLength).set(p.HEAPU8.subarray(i,i+t.byteLength)),w.push([a,h,t])}}finally{p.stackRestore(n),\"string\"===a&&i&&p._free(i),p._OrtReleaseTensor(e)}}if(0===f)return w;throw new Error(`failed to call OrtRun(). error code = ${f}.`)}finally{p.stackRestore(t)}}finally{_.forEach(p._OrtReleaseTensor),O.forEach(p._free),p._OrtReleaseRunOptions(v),w.forEach(p._free)}},e.endProfiling=t=>{const e=(0,o.getInstance)(),n=u.get(t);if(!n)throw new Error(\"invalid session id\");const r=n[0],a=e._OrtEndProfiling(r);if(0===a)throw new Error(\"Can\\'t get an profile file name\");e._OrtFree(a)},e.extractTransferableBuffers=t=>{const e=[];for(const n of t){const t=n[2];!Array.isArray(t)&&t.buffer&&e.push(t.buffer)}return e}},361:function(t,e,n){\"use strict\";var r=this&&this.__createBinding||(Object.create?function(t,e,n,r){void 0===r&&(r=n);var a=Object.getOwnPropertyDescriptor(e,n);a&&!(\"get\"in a?!e.__esModule:a.writable||a.configurable)||(a={enumerable:!0,get:function(){return e[n]}}),Object.defineProperty(t,r,a)}:function(t,e,n,r){void 0===r&&(r=n),t[r]=e[n]}),a=this&&this.__setModuleDefault||(Object.create?function(t,e){Object.defineProperty(t,\"default\",{enumerable:!0,value:e})}:function(t,e){t.default=e}),i=this&&this.__importStar||function(t){if(t&&t.__esModule)return t;var e={};if(null!=t)for(var n in t)\"default\"!==n&&Object.prototype.hasOwnProperty.call(t,n)&&r(e,t,n);return a(e,t),e},o=this&&this.__importDefault||function(t){return t&&t.__esModule?t:{default:t}};Object.defineProperty(e,\"__esModule\",{value:!0}),e.dispose=e.getInstance=e.initializeWebAssembly=void 0;const u=i(n(449)),c=o(n(932)),s=n(474);let l,f=!1,p=!1,h=!1;const d=(t,e)=>e?t?\"ort-wasm-simd-threaded.wasm\":\"ort-wasm-threaded.wasm\":t?\"ort-wasm-simd.wasm\":\"ort-wasm.wasm\";e.initializeWebAssembly=async t=>{if(f)return Promise.resolve();if(p)throw new Error(\"multiple calls to \\'initializeWebAssembly()\\' detected.\");if(h)throw new Error(\"previous call to \\'initializeWebAssembly()\\' failed.\");p=!0;const e=t.initTimeout,r=t.numThreads,a=t.simd,i=r>1&&(()=>{try{return\"undefined\"!=typeof SharedArrayBuffer&&(\"undefined\"!=typeof MessageChannel&&(new MessageChannel).port1.postMessage(new SharedArrayBuffer(1)),WebAssembly.validate(new Uint8Array([0,97,115,109,1,0,0,0,1,4,1,96,0,0,3,2,1,0,5,4,1,3,1,1,10,11,1,9,0,65,0,254,16,2,0,26,11])))}catch(t){return!1}})(),o=a&&(()=>{try{return WebAssembly.validate(new Uint8Array([0,97,115,109,1,0,0,0,1,4,1,96,0,0,3,2,1,0,10,30,1,28,0,65,0,253,15,253,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,253,186,1,26,11]))}catch(t){return!1}})(),y=\"string\"==typeof t.wasmPaths?t.wasmPaths:void 0,b=d(!1,i),m=d(o,i),g=\"object\"==typeof t.wasmPaths?t.wasmPaths[m]:void 0;let v=!1;const w=[];if(e>0&&w.push(new Promise((t=>{setTimeout((()=>{v=!0,t()}),e)}))),w.push(new Promise(((t,e)=>{const r=i?s:c.default,a={locateFile:(t,e)=>i&&t.endsWith(\".worker.js\")&&\"undefined\"!=typeof Blob?URL.createObjectURL(new Blob([n(154)],{type:\"text/javascript\"})):t===b?null!=g?g:(null!=y?y:e)+m:e+t};if(i)if(\"undefined\"==typeof Blob)a.mainScriptUrlOrBlob=u.join(\"/\",\"ort-wasm-threaded.js\");else{const t=`var ortWasmThreaded=(function(){var _scriptDir;return ${r.toString()}})();`;a.mainScriptUrlOrBlob=new Blob([t],{type:\"text/javascript\"})}r(a).then((e=>{p=!1,f=!0,l=e,t()}),(t=>{p=!1,h=!0,e(t)}))}))),await Promise.race(w),v)throw new Error(`WebAssembly backend initializing failed due to timeout: ${e}ms`)},e.getInstance=()=>{if(f&&l)return l;throw new Error(\"WebAssembly is not initialized yet.\")},e.dispose=()=>{var t;!f||p||h||(p=!0,null===(t=l.PThread)||void 0===t||t.terminateAllThreads(),l=void 0,p=!1,f=!1,h=!0)}},154:t=>{\"use strict\";t.exports=\\'\"use strict\";var e={},t=\"object\"==typeof process&&\"object\"==typeof process.versions&&\"string\"==typeof process.versions.node;if(t){var r=require(\"worker_threads\"),a=r.parentPort;a.on(\"message\",(e=>onmessage({data:e})));var o=require(\"fs\");Object.assign(global,{self:global,require:require,Module:e,location:{href:__filename},Worker:r.Worker,importScripts:function(e){(0,eval)(o.readFileSync(e,\"utf8\"))},postMessage:function(e){a.postMessage(e)},performance:global.performance||{now:function(){return Date.now()}}})}var s=!1,n=[],i=function(){var e=Array.prototype.slice.call(arguments).join(\" \");t?o.writeSync(2,e+\"\\\\\\\\n\"):console.error(e)};self.alert=function(){var t=Array.prototype.slice.call(arguments).join(\" \");postMessage({cmd:\"alert\",text:t,threadId:e._pthread_self()})},e.instantiateWasm=(t,r)=>{var a=new WebAssembly.Instance(e.wasmModule,t);return r(a),e.wasmModule=null,a.exports},self.onunhandledrejection=e=>{throw e.reason??e},self.onmessage=t=>{try{if(\"load\"===t.data.cmd){if(e.wasmModule=t.data.wasmModule,e.wasmMemory=t.data.wasmMemory,e.buffer=e.wasmMemory.buffer,e.ENVIRONMENT_IS_PTHREAD=!0,\"string\"==typeof t.data.urlOrBlob)importScripts(t.data.urlOrBlob);else{var r=URL.createObjectURL(t.data.urlOrBlob);importScripts(r),URL.revokeObjectURL(r)}ortWasmThreaded(e).then((function(t){e=t}))}else if(\"run\"===t.data.cmd){e.__performance_now_clock_drift=performance.now()-t.data.time,e.__emscripten_thread_init(t.data.pthread_ptr,0,0,1),e.establishStackSpace(),e.PThread.receiveObjectTransfer(t.data),e.PThread.threadInitTLS(),s||(n.forEach((t=>{e.executeNotifiedProxyingQueue(t)})),n=[],s=!0);try{e.invokeEntryPoint(t.data.start_routine,t.data.arg)}catch(t){if(\"unwind\"!=t){if(!(t instanceof e.ExitStatus))throw t;e.keepRuntimeAlive()||e.__emscripten_thread_exit(t.status)}}}else\"cancel\"===t.data.cmd?e._pthread_self()&&e.__emscripten_thread_exit(-1):\"setimmediate\"===t.data.target||(\"processProxyingQueue\"===t.data.cmd?s?e.executeNotifiedProxyingQueue(t.data.queue):n.push(t.data.queue):(i(\"worker.js received unknown command \"+t.data.cmd),i(t.data)))}catch(t){throw i(\"worker.js onmessage() captured an uncaught exception: \"+t),t&&t.stack&&i(t.stack),e.__emscripten_thread_crashed&&e.__emscripten_thread_crashed(),t}};\\\\n\\'},384:()=>{},993:()=>{},908:()=>{},953:()=>{},925:()=>{},449:()=>{}},e={};function n(r){var a=e[r];if(void 0!==a)return a.exports;var i=e[r]={exports:{}};return t[r].call(i.exports,i,i.exports,n),i.exports}n.g=function(){if(\"object\"==typeof globalThis)return globalThis;try{return this||new Function(\"return this\")()}catch(t){if(\"object\"==typeof window)return window}}(),(()=>{\"use strict\";const t=n(349),e=n(361);self.onmessage=n=>{switch(n.data.type){case\"init-wasm\":(0,e.initializeWebAssembly)(n.data.in).then((()=>postMessage({type:\"init-wasm\"})),(t=>postMessage({type:\"init-wasm\",err:t})));break;case\"init-ort\":try{const{numThreads:e,loggingLevel:r}=n.data.in;(0,t.initOrt)(e,r),postMessage({type:\"init-ort\"})}catch(t){postMessage({type:\"init-ort\",err:t})}break;case\"create_allocate\":try{const{model:e}=n.data.in,r=(0,t.createSessionAllocate)(e);postMessage({type:\"create_allocate\",out:r})}catch(t){postMessage({type:\"create_allocate\",err:t})}break;case\"create_finalize\":try{const{modeldata:e,options:r}=n.data.in,a=(0,t.createSessionFinalize)(e,r);postMessage({type:\"create_finalize\",out:a})}catch(t){postMessage({type:\"create_finalize\",err:t})}break;case\"create\":try{const{model:e,options:r}=n.data.in,a=(0,t.createSession)(e,r);postMessage({type:\"create\",out:a})}catch(t){postMessage({type:\"create\",err:t})}break;case\"release\":try{const e=n.data.in;(0,t.releaseSession)(e),postMessage({type:\"release\"})}catch(t){postMessage({type:\"release\",err:t})}break;case\"run\":try{const{sessionId:e,inputIndices:r,inputs:a,outputIndices:i,options:o}=n.data.in,u=(0,t.run)(e,r,a,i,o);postMessage({type:\"run\",out:u},(0,t.extractTransferableBuffers)(u))}catch(t){postMessage({type:\"run\",err:t})}break;case\"end-profiling\":try{const e=n.data.in;(0,t.endProfiling)(e),postMessage({type:\"end-profiling\"})}catch(t){postMessage({type:\"end-profiling\",err:t})}}}})()})();\\n',\"Worker\",void 0,void 0)}},477:t=>{\"use strict\";t.exports=function(t,e,n,r){var i=self||window;try{try{var o;try{o=new i.Blob([t])}catch(e){(o=new(i.BlobBuilder||i.WebKitBlobBuilder||i.MozBlobBuilder||i.MSBlobBuilder)).append(t),o=o.getBlob()}var a=i.URL||i.webkitURL,s=a.createObjectURL(o),u=new i[e](s,n);return a.revokeObjectURL(s),u}catch(r){return new i[e](\"data:application/javascript,\".concat(encodeURIComponent(t)),n)}}catch(t){if(!r)throw Error(\"Inline worker is not supported\");return new i[e](r,n)}}},4154:t=>{\"use strict\";t.exports='\"use strict\";var e={},t=\"object\"==typeof process&&\"object\"==typeof process.versions&&\"string\"==typeof process.versions.node;if(t){var r=require(\"worker_threads\"),a=r.parentPort;a.on(\"message\",(e=>onmessage({data:e})));var o=require(\"fs\");Object.assign(global,{self:global,require:require,Module:e,location:{href:__filename},Worker:r.Worker,importScripts:function(e){(0,eval)(o.readFileSync(e,\"utf8\"))},postMessage:function(e){a.postMessage(e)},performance:global.performance||{now:function(){return Date.now()}}})}var s=!1,n=[],i=function(){var e=Array.prototype.slice.call(arguments).join(\" \");t?o.writeSync(2,e+\"\\\\n\"):console.error(e)};self.alert=function(){var t=Array.prototype.slice.call(arguments).join(\" \");postMessage({cmd:\"alert\",text:t,threadId:e._pthread_self()})},e.instantiateWasm=(t,r)=>{var a=new WebAssembly.Instance(e.wasmModule,t);return r(a),e.wasmModule=null,a.exports},self.onunhandledrejection=e=>{throw e.reason??e},self.onmessage=t=>{try{if(\"load\"===t.data.cmd){if(e.wasmModule=t.data.wasmModule,e.wasmMemory=t.data.wasmMemory,e.buffer=e.wasmMemory.buffer,e.ENVIRONMENT_IS_PTHREAD=!0,\"string\"==typeof t.data.urlOrBlob)importScripts(t.data.urlOrBlob);else{var r=URL.createObjectURL(t.data.urlOrBlob);importScripts(r),URL.revokeObjectURL(r)}ortWasmThreaded(e).then((function(t){e=t}))}else if(\"run\"===t.data.cmd){e.__performance_now_clock_drift=performance.now()-t.data.time,e.__emscripten_thread_init(t.data.pthread_ptr,0,0,1),e.establishStackSpace(),e.PThread.receiveObjectTransfer(t.data),e.PThread.threadInitTLS(),s||(n.forEach((t=>{e.executeNotifiedProxyingQueue(t)})),n=[],s=!0);try{e.invokeEntryPoint(t.data.start_routine,t.data.arg)}catch(t){if(\"unwind\"!=t){if(!(t instanceof e.ExitStatus))throw t;e.keepRuntimeAlive()||e.__emscripten_thread_exit(t.status)}}}else\"cancel\"===t.data.cmd?e._pthread_self()&&e.__emscripten_thread_exit(-1):\"setimmediate\"===t.data.target||(\"processProxyingQueue\"===t.data.cmd?s?e.executeNotifiedProxyingQueue(t.data.queue):n.push(t.data.queue):(i(\"worker.js received unknown command \"+t.data.cmd),i(t.data)))}catch(t){throw i(\"worker.js onmessage() captured an uncaught exception: \"+t),t&&t.stack&&i(t.stack),e.__emscripten_thread_crashed&&e.__emscripten_thread_crashed(),t}};\\n'},1670:t=>{\"use strict\";t.exports=__WEBPACK_EXTERNAL_MODULE__1670__},7067:()=>{},1296:()=>{},1384:()=>{},3993:()=>{},908:()=>{},6953:()=>{},9925:()=>{},2806:()=>{},6449:()=>{},2850:()=>{},5381:()=>{},5686:(t,e,n)=>{\"use strict\";n.r(e),n.d(e,{flatbuffers:()=>r});var r={};r.Offset,r.Table,r.SIZEOF_SHORT=2,r.SIZEOF_INT=4,r.FILE_IDENTIFIER_LENGTH=4,r.SIZE_PREFIX_LENGTH=4,r.Encoding={UTF8_BYTES:1,UTF16_STRING:2},r.int32=new Int32Array(2),r.float32=new Float32Array(r.int32.buffer),r.float64=new Float64Array(r.int32.buffer),r.isLittleEndian=1===new Uint16Array(new Uint8Array([1,0]).buffer)[0],r.Long=function(t,e){this.low=0|t,this.high=0|e},r.Long.create=function(t,e){return 0==t&&0==e?r.Long.ZERO:new r.Long(t,e)},r.Long.prototype.toFloat64=function(){return(this.low>>>0)+4294967296*this.high},r.Long.prototype.equals=function(t){return this.low==t.low&&this.high==t.high},r.Long.ZERO=new r.Long(0,0),r.Builder=function(t){if(t)e=t;else var e=1024;this.bb=r.ByteBuffer.allocate(e),this.space=e,this.minalign=1,this.vtable=null,this.vtable_in_use=0,this.isNested=!1,this.object_start=0,this.vtables=[],this.vector_num_elems=0,this.force_defaults=!1},r.Builder.prototype.clear=function(){this.bb.clear(),this.space=this.bb.capacity(),this.minalign=1,this.vtable=null,this.vtable_in_use=0,this.isNested=!1,this.object_start=0,this.vtables=[],this.vector_num_elems=0,this.force_defaults=!1},r.Builder.prototype.forceDefaults=function(t){this.force_defaults=t},r.Builder.prototype.dataBuffer=function(){return this.bb},r.Builder.prototype.asUint8Array=function(){return this.bb.bytes().subarray(this.bb.position(),this.bb.position()+this.offset())},r.Builder.prototype.prep=function(t,e){t>this.minalign&&(this.minalign=t);for(var n=1+~(this.bb.capacity()-this.space+e)&t-1;this.space<n+t+e;){var i=this.bb.capacity();this.bb=r.Builder.growByteBuffer(this.bb),this.space+=this.bb.capacity()-i}this.pad(n)},r.Builder.prototype.pad=function(t){for(var e=0;e<t;e++)this.bb.writeInt8(--this.space,0)},r.Builder.prototype.writeInt8=function(t){this.bb.writeInt8(this.space-=1,t)},r.Builder.prototype.writeInt16=function(t){this.bb.writeInt16(this.space-=2,t)},r.Builder.prototype.writeInt32=function(t){this.bb.writeInt32(this.space-=4,t)},r.Builder.prototype.writeInt64=function(t){this.bb.writeInt64(this.space-=8,t)},r.Builder.prototype.writeFloat32=function(t){this.bb.writeFloat32(this.space-=4,t)},r.Builder.prototype.writeFloat64=function(t){this.bb.writeFloat64(this.space-=8,t)},r.Builder.prototype.addInt8=function(t){this.prep(1,0),this.writeInt8(t)},r.Builder.prototype.addInt16=function(t){this.prep(2,0),this.writeInt16(t)},r.Builder.prototype.addInt32=function(t){this.prep(4,0),this.writeInt32(t)},r.Builder.prototype.addInt64=function(t){this.prep(8,0),this.writeInt64(t)},r.Builder.prototype.addFloat32=function(t){this.prep(4,0),this.writeFloat32(t)},r.Builder.prototype.addFloat64=function(t){this.prep(8,0),this.writeFloat64(t)},r.Builder.prototype.addFieldInt8=function(t,e,n){(this.force_defaults||e!=n)&&(this.addInt8(e),this.slot(t))},r.Builder.prototype.addFieldInt16=function(t,e,n){(this.force_defaults||e!=n)&&(this.addInt16(e),this.slot(t))},r.Builder.prototype.addFieldInt32=function(t,e,n){(this.force_defaults||e!=n)&&(this.addInt32(e),this.slot(t))},r.Builder.prototype.addFieldInt64=function(t,e,n){!this.force_defaults&&e.equals(n)||(this.addInt64(e),this.slot(t))},r.Builder.prototype.addFieldFloat32=function(t,e,n){(this.force_defaults||e!=n)&&(this.addFloat32(e),this.slot(t))},r.Builder.prototype.addFieldFloat64=function(t,e,n){(this.force_defaults||e!=n)&&(this.addFloat64(e),this.slot(t))},r.Builder.prototype.addFieldOffset=function(t,e,n){(this.force_defaults||e!=n)&&(this.addOffset(e),this.slot(t))},r.Builder.prototype.addFieldStruct=function(t,e,n){e!=n&&(this.nested(e),this.slot(t))},r.Builder.prototype.nested=function(t){if(t!=this.offset())throw new Error(\"FlatBuffers: struct must be serialized inline.\")},r.Builder.prototype.notNested=function(){if(this.isNested)throw new Error(\"FlatBuffers: object serialization must not be nested.\")},r.Builder.prototype.slot=function(t){this.vtable[t]=this.offset()},r.Builder.prototype.offset=function(){return this.bb.capacity()-this.space},r.Builder.growByteBuffer=function(t){var e=t.capacity();if(3221225472&e)throw new Error(\"FlatBuffers: cannot grow buffer beyond 2 gigabytes.\");var n=e<<1,i=r.ByteBuffer.allocate(n);return i.setPosition(n-e),i.bytes().set(t.bytes(),n-e),i},r.Builder.prototype.addOffset=function(t){this.prep(r.SIZEOF_INT,0),this.writeInt32(this.offset()-t+r.SIZEOF_INT)},r.Builder.prototype.startObject=function(t){this.notNested(),null==this.vtable&&(this.vtable=[]),this.vtable_in_use=t;for(var e=0;e<t;e++)this.vtable[e]=0;this.isNested=!0,this.object_start=this.offset()},r.Builder.prototype.endObject=function(){if(null==this.vtable||!this.isNested)throw new Error(\"FlatBuffers: endObject called without startObject\");this.addInt32(0);for(var t=this.offset(),e=this.vtable_in_use-1;e>=0&&0==this.vtable[e];e--);for(var n=e+1;e>=0;e--)this.addInt16(0!=this.vtable[e]?t-this.vtable[e]:0);this.addInt16(t-this.object_start);var i=(n+2)*r.SIZEOF_SHORT;this.addInt16(i);var o=0,a=this.space;t:for(e=0;e<this.vtables.length;e++){var s=this.bb.capacity()-this.vtables[e];if(i==this.bb.readInt16(s)){for(var u=r.SIZEOF_SHORT;u<i;u+=r.SIZEOF_SHORT)if(this.bb.readInt16(a+u)!=this.bb.readInt16(s+u))continue t;o=this.vtables[e];break}}return o?(this.space=this.bb.capacity()-t,this.bb.writeInt32(this.space,o-t)):(this.vtables.push(this.offset()),this.bb.writeInt32(this.bb.capacity()-t,this.offset()-t)),this.isNested=!1,t},r.Builder.prototype.finish=function(t,e,n){var i=n?r.SIZE_PREFIX_LENGTH:0;if(e){var o=e;if(this.prep(this.minalign,r.SIZEOF_INT+r.FILE_IDENTIFIER_LENGTH+i),o.length!=r.FILE_IDENTIFIER_LENGTH)throw new Error(\"FlatBuffers: file identifier must be length \"+r.FILE_IDENTIFIER_LENGTH);for(var a=r.FILE_IDENTIFIER_LENGTH-1;a>=0;a--)this.writeInt8(o.charCodeAt(a))}this.prep(this.minalign,r.SIZEOF_INT+i),this.addOffset(t),i&&this.addInt32(this.bb.capacity()-this.space),this.bb.setPosition(this.space)},r.Builder.prototype.finishSizePrefixed=function(t,e){this.finish(t,e,!0)},r.Builder.prototype.requiredField=function(t,e){var n=this.bb.capacity()-t,r=n-this.bb.readInt32(n);if(0==this.bb.readInt16(r+e))throw new Error(\"FlatBuffers: field \"+e+\" must be set\")},r.Builder.prototype.startVector=function(t,e,n){this.notNested(),this.vector_num_elems=e,this.prep(r.SIZEOF_INT,t*e),this.prep(n,t*e)},r.Builder.prototype.endVector=function(){return this.writeInt32(this.vector_num_elems),this.offset()},r.Builder.prototype.createString=function(t){if(t instanceof Uint8Array)var e=t;else{e=[];for(var n=0;n<t.length;){var r,i=t.charCodeAt(n++);(r=i<55296||i>=56320?i:(i<<10)+t.charCodeAt(n++)+-56613888)<128?e.push(r):(r<2048?e.push(r>>6&31|192):(r<65536?e.push(r>>12&15|224):e.push(r>>18&7|240,r>>12&63|128),e.push(r>>6&63|128)),e.push(63&r|128))}}this.addInt8(0),this.startVector(1,e.length,1),this.bb.setPosition(this.space-=e.length),n=0;for(var o=this.space,a=this.bb.bytes();n<e.length;n++)a[o++]=e[n];return this.endVector()},r.Builder.prototype.createLong=function(t,e){return r.Long.create(t,e)},r.ByteBuffer=function(t){this.bytes_=t,this.position_=0},r.ByteBuffer.allocate=function(t){return new r.ByteBuffer(new Uint8Array(t))},r.ByteBuffer.prototype.clear=function(){this.position_=0},r.ByteBuffer.prototype.bytes=function(){return this.bytes_},r.ByteBuffer.prototype.position=function(){return this.position_},r.ByteBuffer.prototype.setPosition=function(t){this.position_=t},r.ByteBuffer.prototype.capacity=function(){return this.bytes_.length},r.ByteBuffer.prototype.readInt8=function(t){return this.readUint8(t)<<24>>24},r.ByteBuffer.prototype.readUint8=function(t){return this.bytes_[t]},r.ByteBuffer.prototype.readInt16=function(t){return this.readUint16(t)<<16>>16},r.ByteBuffer.prototype.readUint16=function(t){return this.bytes_[t]|this.bytes_[t+1]<<8},r.ByteBuffer.prototype.readInt32=function(t){return this.bytes_[t]|this.bytes_[t+1]<<8|this.bytes_[t+2]<<16|this.bytes_[t+3]<<24},r.ByteBuffer.prototype.readUint32=function(t){return this.readInt32(t)>>>0},r.ByteBuffer.prototype.readInt64=function(t){return new r.Long(this.readInt32(t),this.readInt32(t+4))},r.ByteBuffer.prototype.readUint64=function(t){return new r.Long(this.readUint32(t),this.readUint32(t+4))},r.ByteBuffer.prototype.readFloat32=function(t){return r.int32[0]=this.readInt32(t),r.float32[0]},r.ByteBuffer.prototype.readFloat64=function(t){return r.int32[r.isLittleEndian?0:1]=this.readInt32(t),r.int32[r.isLittleEndian?1:0]=this.readInt32(t+4),r.float64[0]},r.ByteBuffer.prototype.writeInt8=function(t,e){this.bytes_[t]=e},r.ByteBuffer.prototype.writeUint8=function(t,e){this.bytes_[t]=e},r.ByteBuffer.prototype.writeInt16=function(t,e){this.bytes_[t]=e,this.bytes_[t+1]=e>>8},r.ByteBuffer.prototype.writeUint16=function(t,e){this.bytes_[t]=e,this.bytes_[t+1]=e>>8},r.ByteBuffer.prototype.writeInt32=function(t,e){this.bytes_[t]=e,this.bytes_[t+1]=e>>8,this.bytes_[t+2]=e>>16,this.bytes_[t+3]=e>>24},r.ByteBuffer.prototype.writeUint32=function(t,e){this.bytes_[t]=e,this.bytes_[t+1]=e>>8,this.bytes_[t+2]=e>>16,this.bytes_[t+3]=e>>24},r.ByteBuffer.prototype.writeInt64=function(t,e){this.writeInt32(t,e.low),this.writeInt32(t+4,e.high)},r.ByteBuffer.prototype.writeUint64=function(t,e){this.writeUint32(t,e.low),this.writeUint32(t+4,e.high)},r.ByteBuffer.prototype.writeFloat32=function(t,e){r.float32[0]=e,this.writeInt32(t,r.int32[0])},r.ByteBuffer.prototype.writeFloat64=function(t,e){r.float64[0]=e,this.writeInt32(t,r.int32[r.isLittleEndian?0:1]),this.writeInt32(t+4,r.int32[r.isLittleEndian?1:0])},r.ByteBuffer.prototype.getBufferIdentifier=function(){if(this.bytes_.length<this.position_+r.SIZEOF_INT+r.FILE_IDENTIFIER_LENGTH)throw new Error(\"FlatBuffers: ByteBuffer is too short to contain an identifier.\");for(var t=\"\",e=0;e<r.FILE_IDENTIFIER_LENGTH;e++)t+=String.fromCharCode(this.readInt8(this.position_+r.SIZEOF_INT+e));return t},r.ByteBuffer.prototype.__offset=function(t,e){var n=t-this.readInt32(t);return e<this.readInt16(n)?this.readInt16(n+e):0},r.ByteBuffer.prototype.__union=function(t,e){return t.bb_pos=e+this.readInt32(e),t.bb=this,t},r.ByteBuffer.prototype.__string=function(t,e){t+=this.readInt32(t);var n=this.readInt32(t),i=\"\",o=0;if(t+=r.SIZEOF_INT,e===r.Encoding.UTF8_BYTES)return this.bytes_.subarray(t,t+n);for(;o<n;){var a,s=this.readUint8(t+o++);if(s<192)a=s;else{var u=this.readUint8(t+o++);if(s<224)a=(31&s)<<6|63&u;else{var c=this.readUint8(t+o++);a=s<240?(15&s)<<12|(63&u)<<6|63&c:(7&s)<<18|(63&u)<<12|(63&c)<<6|63&this.readUint8(t+o++)}}a<65536?i+=String.fromCharCode(a):(a-=65536,i+=String.fromCharCode(55296+(a>>10),56320+(1023&a)))}return i},r.ByteBuffer.prototype.__indirect=function(t){return t+this.readInt32(t)},r.ByteBuffer.prototype.__vector=function(t){return t+this.readInt32(t)+r.SIZEOF_INT},r.ByteBuffer.prototype.__vector_len=function(t){return this.readInt32(t+this.readInt32(t))},r.ByteBuffer.prototype.__has_identifier=function(t){if(t.length!=r.FILE_IDENTIFIER_LENGTH)throw new Error(\"FlatBuffers: file identifier must be length \"+r.FILE_IDENTIFIER_LENGTH);for(var e=0;e<r.FILE_IDENTIFIER_LENGTH;e++)if(t.charCodeAt(e)!=this.readInt8(this.position_+r.SIZEOF_INT+e))return!1;return!0},r.ByteBuffer.prototype.createLong=function(t,e){return r.Long.create(t,e)}}},__webpack_module_cache__={};function __nested_webpack_require_546802__(t){var e=__webpack_module_cache__[t];if(void 0!==e)return e.exports;var n=__webpack_module_cache__[t]={exports:{}};return __webpack_modules__[t].call(n.exports,n,n.exports,__nested_webpack_require_546802__),n.exports}__nested_webpack_require_546802__.n=t=>{var e=t&&t.__esModule?()=>t.default:()=>t;return __nested_webpack_require_546802__.d(e,{a:e}),e},__nested_webpack_require_546802__.d=(t,e)=>{for(var n in e)__nested_webpack_require_546802__.o(e,n)&&!__nested_webpack_require_546802__.o(t,n)&&Object.defineProperty(t,n,{enumerable:!0,get:e[n]})},__nested_webpack_require_546802__.g=function(){if(\"object\"==typeof globalThis)return globalThis;try{return this||new Function(\"return this\")()}catch(t){if(\"object\"==typeof window)return window}}(),__nested_webpack_require_546802__.o=(t,e)=>Object.prototype.hasOwnProperty.call(t,e),__nested_webpack_require_546802__.r=t=>{\"undefined\"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(t,Symbol.toStringTag,{value:\"Module\"}),Object.defineProperty(t,\"__esModule\",{value:!0})};var __nested_webpack_exports__=__nested_webpack_require_546802__(6018);return __nested_webpack_exports__})()));\n//# sourceMappingURL=ort-web.min.js.map\n\n//# sourceURL=webpack://semanticfinder/./node_modules/onnxruntime-web/dist/ort-web.min.js?");

/***/ }),

/***/ "./node_modules/whatwg-fetch/fetch.js":
/*!********************************************!*\
  !*** ./node_modules/whatwg-fetch/fetch.js ***!
  \********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   DOMException: () => (/* binding */ DOMException),\n/* harmony export */   Headers: () => (/* binding */ Headers),\n/* harmony export */   Request: () => (/* binding */ Request),\n/* harmony export */   Response: () => (/* binding */ Response),\n/* harmony export */   fetch: () => (/* binding */ fetch)\n/* harmony export */ });\n/* eslint-disable no-prototype-builtins */\nvar g =\n  (typeof globalThis !== 'undefined' && globalThis) ||\n  (typeof self !== 'undefined' && self) ||\n  // eslint-disable-next-line no-undef\n  (typeof __webpack_require__.g !== 'undefined' && __webpack_require__.g) ||\n  {}\n\nvar support = {\n  searchParams: 'URLSearchParams' in g,\n  iterable: 'Symbol' in g && 'iterator' in Symbol,\n  blob:\n    'FileReader' in g &&\n    'Blob' in g &&\n    (function() {\n      try {\n        new Blob()\n        return true\n      } catch (e) {\n        return false\n      }\n    })(),\n  formData: 'FormData' in g,\n  arrayBuffer: 'ArrayBuffer' in g\n}\n\nfunction isDataView(obj) {\n  return obj && DataView.prototype.isPrototypeOf(obj)\n}\n\nif (support.arrayBuffer) {\n  var viewClasses = [\n    '[object Int8Array]',\n    '[object Uint8Array]',\n    '[object Uint8ClampedArray]',\n    '[object Int16Array]',\n    '[object Uint16Array]',\n    '[object Int32Array]',\n    '[object Uint32Array]',\n    '[object Float32Array]',\n    '[object Float64Array]'\n  ]\n\n  var isArrayBufferView =\n    ArrayBuffer.isView ||\n    function(obj) {\n      return obj && viewClasses.indexOf(Object.prototype.toString.call(obj)) > -1\n    }\n}\n\nfunction normalizeName(name) {\n  if (typeof name !== 'string') {\n    name = String(name)\n  }\n  if (/[^a-z0-9\\-#$%&'*+.^_`|~!]/i.test(name) || name === '') {\n    throw new TypeError('Invalid character in header field name: \"' + name + '\"')\n  }\n  return name.toLowerCase()\n}\n\nfunction normalizeValue(value) {\n  if (typeof value !== 'string') {\n    value = String(value)\n  }\n  return value\n}\n\n// Build a destructive iterator for the value list\nfunction iteratorFor(items) {\n  var iterator = {\n    next: function() {\n      var value = items.shift()\n      return {done: value === undefined, value: value}\n    }\n  }\n\n  if (support.iterable) {\n    iterator[Symbol.iterator] = function() {\n      return iterator\n    }\n  }\n\n  return iterator\n}\n\nfunction Headers(headers) {\n  this.map = {}\n\n  if (headers instanceof Headers) {\n    headers.forEach(function(value, name) {\n      this.append(name, value)\n    }, this)\n  } else if (Array.isArray(headers)) {\n    headers.forEach(function(header) {\n      if (header.length != 2) {\n        throw new TypeError('Headers constructor: expected name/value pair to be length 2, found' + header.length)\n      }\n      this.append(header[0], header[1])\n    }, this)\n  } else if (headers) {\n    Object.getOwnPropertyNames(headers).forEach(function(name) {\n      this.append(name, headers[name])\n    }, this)\n  }\n}\n\nHeaders.prototype.append = function(name, value) {\n  name = normalizeName(name)\n  value = normalizeValue(value)\n  var oldValue = this.map[name]\n  this.map[name] = oldValue ? oldValue + ', ' + value : value\n}\n\nHeaders.prototype['delete'] = function(name) {\n  delete this.map[normalizeName(name)]\n}\n\nHeaders.prototype.get = function(name) {\n  name = normalizeName(name)\n  return this.has(name) ? this.map[name] : null\n}\n\nHeaders.prototype.has = function(name) {\n  return this.map.hasOwnProperty(normalizeName(name))\n}\n\nHeaders.prototype.set = function(name, value) {\n  this.map[normalizeName(name)] = normalizeValue(value)\n}\n\nHeaders.prototype.forEach = function(callback, thisArg) {\n  for (var name in this.map) {\n    if (this.map.hasOwnProperty(name)) {\n      callback.call(thisArg, this.map[name], name, this)\n    }\n  }\n}\n\nHeaders.prototype.keys = function() {\n  var items = []\n  this.forEach(function(value, name) {\n    items.push(name)\n  })\n  return iteratorFor(items)\n}\n\nHeaders.prototype.values = function() {\n  var items = []\n  this.forEach(function(value) {\n    items.push(value)\n  })\n  return iteratorFor(items)\n}\n\nHeaders.prototype.entries = function() {\n  var items = []\n  this.forEach(function(value, name) {\n    items.push([name, value])\n  })\n  return iteratorFor(items)\n}\n\nif (support.iterable) {\n  Headers.prototype[Symbol.iterator] = Headers.prototype.entries\n}\n\nfunction consumed(body) {\n  if (body._noBody) return\n  if (body.bodyUsed) {\n    return Promise.reject(new TypeError('Already read'))\n  }\n  body.bodyUsed = true\n}\n\nfunction fileReaderReady(reader) {\n  return new Promise(function(resolve, reject) {\n    reader.onload = function() {\n      resolve(reader.result)\n    }\n    reader.onerror = function() {\n      reject(reader.error)\n    }\n  })\n}\n\nfunction readBlobAsArrayBuffer(blob) {\n  var reader = new FileReader()\n  var promise = fileReaderReady(reader)\n  reader.readAsArrayBuffer(blob)\n  return promise\n}\n\nfunction readBlobAsText(blob) {\n  var reader = new FileReader()\n  var promise = fileReaderReady(reader)\n  var match = /charset=([A-Za-z0-9_-]+)/.exec(blob.type)\n  var encoding = match ? match[1] : 'utf-8'\n  reader.readAsText(blob, encoding)\n  return promise\n}\n\nfunction readArrayBufferAsText(buf) {\n  var view = new Uint8Array(buf)\n  var chars = new Array(view.length)\n\n  for (var i = 0; i < view.length; i++) {\n    chars[i] = String.fromCharCode(view[i])\n  }\n  return chars.join('')\n}\n\nfunction bufferClone(buf) {\n  if (buf.slice) {\n    return buf.slice(0)\n  } else {\n    var view = new Uint8Array(buf.byteLength)\n    view.set(new Uint8Array(buf))\n    return view.buffer\n  }\n}\n\nfunction Body() {\n  this.bodyUsed = false\n\n  this._initBody = function(body) {\n    /*\n      fetch-mock wraps the Response object in an ES6 Proxy to\n      provide useful test harness features such as flush. However, on\n      ES5 browsers without fetch or Proxy support pollyfills must be used;\n      the proxy-pollyfill is unable to proxy an attribute unless it exists\n      on the object before the Proxy is created. This change ensures\n      Response.bodyUsed exists on the instance, while maintaining the\n      semantic of setting Request.bodyUsed in the constructor before\n      _initBody is called.\n    */\n    // eslint-disable-next-line no-self-assign\n    this.bodyUsed = this.bodyUsed\n    this._bodyInit = body\n    if (!body) {\n      this._noBody = true;\n      this._bodyText = ''\n    } else if (typeof body === 'string') {\n      this._bodyText = body\n    } else if (support.blob && Blob.prototype.isPrototypeOf(body)) {\n      this._bodyBlob = body\n    } else if (support.formData && FormData.prototype.isPrototypeOf(body)) {\n      this._bodyFormData = body\n    } else if (support.searchParams && URLSearchParams.prototype.isPrototypeOf(body)) {\n      this._bodyText = body.toString()\n    } else if (support.arrayBuffer && support.blob && isDataView(body)) {\n      this._bodyArrayBuffer = bufferClone(body.buffer)\n      // IE 10-11 can't handle a DataView body.\n      this._bodyInit = new Blob([this._bodyArrayBuffer])\n    } else if (support.arrayBuffer && (ArrayBuffer.prototype.isPrototypeOf(body) || isArrayBufferView(body))) {\n      this._bodyArrayBuffer = bufferClone(body)\n    } else {\n      this._bodyText = body = Object.prototype.toString.call(body)\n    }\n\n    if (!this.headers.get('content-type')) {\n      if (typeof body === 'string') {\n        this.headers.set('content-type', 'text/plain;charset=UTF-8')\n      } else if (this._bodyBlob && this._bodyBlob.type) {\n        this.headers.set('content-type', this._bodyBlob.type)\n      } else if (support.searchParams && URLSearchParams.prototype.isPrototypeOf(body)) {\n        this.headers.set('content-type', 'application/x-www-form-urlencoded;charset=UTF-8')\n      }\n    }\n  }\n\n  if (support.blob) {\n    this.blob = function() {\n      var rejected = consumed(this)\n      if (rejected) {\n        return rejected\n      }\n\n      if (this._bodyBlob) {\n        return Promise.resolve(this._bodyBlob)\n      } else if (this._bodyArrayBuffer) {\n        return Promise.resolve(new Blob([this._bodyArrayBuffer]))\n      } else if (this._bodyFormData) {\n        throw new Error('could not read FormData body as blob')\n      } else {\n        return Promise.resolve(new Blob([this._bodyText]))\n      }\n    }\n  }\n\n  this.arrayBuffer = function() {\n    if (this._bodyArrayBuffer) {\n      var isConsumed = consumed(this)\n      if (isConsumed) {\n        return isConsumed\n      } else if (ArrayBuffer.isView(this._bodyArrayBuffer)) {\n        return Promise.resolve(\n          this._bodyArrayBuffer.buffer.slice(\n            this._bodyArrayBuffer.byteOffset,\n            this._bodyArrayBuffer.byteOffset + this._bodyArrayBuffer.byteLength\n          )\n        )\n      } else {\n        return Promise.resolve(this._bodyArrayBuffer)\n      }\n    } else if (support.blob) {\n      return this.blob().then(readBlobAsArrayBuffer)\n    } else {\n      throw new Error('could not read as ArrayBuffer')\n    }\n  }\n\n  this.text = function() {\n    var rejected = consumed(this)\n    if (rejected) {\n      return rejected\n    }\n\n    if (this._bodyBlob) {\n      return readBlobAsText(this._bodyBlob)\n    } else if (this._bodyArrayBuffer) {\n      return Promise.resolve(readArrayBufferAsText(this._bodyArrayBuffer))\n    } else if (this._bodyFormData) {\n      throw new Error('could not read FormData body as text')\n    } else {\n      return Promise.resolve(this._bodyText)\n    }\n  }\n\n  if (support.formData) {\n    this.formData = function() {\n      return this.text().then(decode)\n    }\n  }\n\n  this.json = function() {\n    return this.text().then(JSON.parse)\n  }\n\n  return this\n}\n\n// HTTP methods whose capitalization should be normalized\nvar methods = ['CONNECT', 'DELETE', 'GET', 'HEAD', 'OPTIONS', 'PATCH', 'POST', 'PUT', 'TRACE']\n\nfunction normalizeMethod(method) {\n  var upcased = method.toUpperCase()\n  return methods.indexOf(upcased) > -1 ? upcased : method\n}\n\nfunction Request(input, options) {\n  if (!(this instanceof Request)) {\n    throw new TypeError('Please use the \"new\" operator, this DOM object constructor cannot be called as a function.')\n  }\n\n  options = options || {}\n  var body = options.body\n\n  if (input instanceof Request) {\n    if (input.bodyUsed) {\n      throw new TypeError('Already read')\n    }\n    this.url = input.url\n    this.credentials = input.credentials\n    if (!options.headers) {\n      this.headers = new Headers(input.headers)\n    }\n    this.method = input.method\n    this.mode = input.mode\n    this.signal = input.signal\n    if (!body && input._bodyInit != null) {\n      body = input._bodyInit\n      input.bodyUsed = true\n    }\n  } else {\n    this.url = String(input)\n  }\n\n  this.credentials = options.credentials || this.credentials || 'same-origin'\n  if (options.headers || !this.headers) {\n    this.headers = new Headers(options.headers)\n  }\n  this.method = normalizeMethod(options.method || this.method || 'GET')\n  this.mode = options.mode || this.mode || null\n  this.signal = options.signal || this.signal || (function () {\n    if ('AbortController' in g) {\n      var ctrl = new AbortController();\n      return ctrl.signal;\n    }\n  }());\n  this.referrer = null\n\n  if ((this.method === 'GET' || this.method === 'HEAD') && body) {\n    throw new TypeError('Body not allowed for GET or HEAD requests')\n  }\n  this._initBody(body)\n\n  if (this.method === 'GET' || this.method === 'HEAD') {\n    if (options.cache === 'no-store' || options.cache === 'no-cache') {\n      // Search for a '_' parameter in the query string\n      var reParamSearch = /([?&])_=[^&]*/\n      if (reParamSearch.test(this.url)) {\n        // If it already exists then set the value with the current time\n        this.url = this.url.replace(reParamSearch, '$1_=' + new Date().getTime())\n      } else {\n        // Otherwise add a new '_' parameter to the end with the current time\n        var reQueryString = /\\?/\n        this.url += (reQueryString.test(this.url) ? '&' : '?') + '_=' + new Date().getTime()\n      }\n    }\n  }\n}\n\nRequest.prototype.clone = function() {\n  return new Request(this, {body: this._bodyInit})\n}\n\nfunction decode(body) {\n  var form = new FormData()\n  body\n    .trim()\n    .split('&')\n    .forEach(function(bytes) {\n      if (bytes) {\n        var split = bytes.split('=')\n        var name = split.shift().replace(/\\+/g, ' ')\n        var value = split.join('=').replace(/\\+/g, ' ')\n        form.append(decodeURIComponent(name), decodeURIComponent(value))\n      }\n    })\n  return form\n}\n\nfunction parseHeaders(rawHeaders) {\n  var headers = new Headers()\n  // Replace instances of \\r\\n and \\n followed by at least one space or horizontal tab with a space\n  // https://tools.ietf.org/html/rfc7230#section-3.2\n  var preProcessedHeaders = rawHeaders.replace(/\\r?\\n[\\t ]+/g, ' ')\n  // Avoiding split via regex to work around a common IE11 bug with the core-js 3.6.0 regex polyfill\n  // https://github.com/github/fetch/issues/748\n  // https://github.com/zloirock/core-js/issues/751\n  preProcessedHeaders\n    .split('\\r')\n    .map(function(header) {\n      return header.indexOf('\\n') === 0 ? header.substr(1, header.length) : header\n    })\n    .forEach(function(line) {\n      var parts = line.split(':')\n      var key = parts.shift().trim()\n      if (key) {\n        var value = parts.join(':').trim()\n        try {\n          headers.append(key, value)\n        } catch (error) {\n          console.warn('Response ' + error.message)\n        }\n      }\n    })\n  return headers\n}\n\nBody.call(Request.prototype)\n\nfunction Response(bodyInit, options) {\n  if (!(this instanceof Response)) {\n    throw new TypeError('Please use the \"new\" operator, this DOM object constructor cannot be called as a function.')\n  }\n  if (!options) {\n    options = {}\n  }\n\n  this.type = 'default'\n  this.status = options.status === undefined ? 200 : options.status\n  if (this.status < 200 || this.status > 599) {\n    throw new RangeError(\"Failed to construct 'Response': The status provided (0) is outside the range [200, 599].\")\n  }\n  this.ok = this.status >= 200 && this.status < 300\n  this.statusText = options.statusText === undefined ? '' : '' + options.statusText\n  this.headers = new Headers(options.headers)\n  this.url = options.url || ''\n  this._initBody(bodyInit)\n}\n\nBody.call(Response.prototype)\n\nResponse.prototype.clone = function() {\n  return new Response(this._bodyInit, {\n    status: this.status,\n    statusText: this.statusText,\n    headers: new Headers(this.headers),\n    url: this.url\n  })\n}\n\nResponse.error = function() {\n  var response = new Response(null, {status: 200, statusText: ''})\n  response.ok = false\n  response.status = 0\n  response.type = 'error'\n  return response\n}\n\nvar redirectStatuses = [301, 302, 303, 307, 308]\n\nResponse.redirect = function(url, status) {\n  if (redirectStatuses.indexOf(status) === -1) {\n    throw new RangeError('Invalid status code')\n  }\n\n  return new Response(null, {status: status, headers: {location: url}})\n}\n\nvar DOMException = g.DOMException\ntry {\n  new DOMException()\n} catch (err) {\n  DOMException = function(message, name) {\n    this.message = message\n    this.name = name\n    var error = Error(message)\n    this.stack = error.stack\n  }\n  DOMException.prototype = Object.create(Error.prototype)\n  DOMException.prototype.constructor = DOMException\n}\n\nfunction fetch(input, init) {\n  return new Promise(function(resolve, reject) {\n    var request = new Request(input, init)\n\n    if (request.signal && request.signal.aborted) {\n      return reject(new DOMException('Aborted', 'AbortError'))\n    }\n\n    var xhr = new XMLHttpRequest()\n\n    function abortXhr() {\n      xhr.abort()\n    }\n\n    xhr.onload = function() {\n      var options = {\n        statusText: xhr.statusText,\n        headers: parseHeaders(xhr.getAllResponseHeaders() || '')\n      }\n      // This check if specifically for when a user fetches a file locally from the file system\n      // Only if the status is out of a normal range\n      if (request.url.indexOf('file://') === 0 && (xhr.status < 200 || xhr.status > 599)) {\n        options.status = 200;\n      } else {\n        options.status = xhr.status;\n      }\n      options.url = 'responseURL' in xhr ? xhr.responseURL : options.headers.get('X-Request-URL')\n      var body = 'response' in xhr ? xhr.response : xhr.responseText\n      setTimeout(function() {\n        resolve(new Response(body, options))\n      }, 0)\n    }\n\n    xhr.onerror = function() {\n      setTimeout(function() {\n        reject(new TypeError('Network request failed'))\n      }, 0)\n    }\n\n    xhr.ontimeout = function() {\n      setTimeout(function() {\n        reject(new TypeError('Network request timed out'))\n      }, 0)\n    }\n\n    xhr.onabort = function() {\n      setTimeout(function() {\n        reject(new DOMException('Aborted', 'AbortError'))\n      }, 0)\n    }\n\n    function fixUrl(url) {\n      try {\n        return url === '' && g.location.href ? g.location.href : url\n      } catch (e) {\n        return url\n      }\n    }\n\n    xhr.open(request.method, fixUrl(request.url), true)\n\n    if (request.credentials === 'include') {\n      xhr.withCredentials = true\n    } else if (request.credentials === 'omit') {\n      xhr.withCredentials = false\n    }\n\n    if ('responseType' in xhr) {\n      if (support.blob) {\n        xhr.responseType = 'blob'\n      } else if (\n        support.arrayBuffer\n      ) {\n        xhr.responseType = 'arraybuffer'\n      }\n    }\n\n    if (init && typeof init.headers === 'object' && !(init.headers instanceof Headers || (g.Headers && init.headers instanceof g.Headers))) {\n      var names = [];\n      Object.getOwnPropertyNames(init.headers).forEach(function(name) {\n        names.push(normalizeName(name))\n        xhr.setRequestHeader(name, normalizeValue(init.headers[name]))\n      })\n      request.headers.forEach(function(value, name) {\n        if (names.indexOf(name) === -1) {\n          xhr.setRequestHeader(name, value)\n        }\n      })\n    } else {\n      request.headers.forEach(function(value, name) {\n        xhr.setRequestHeader(name, value)\n      })\n    }\n\n    if (request.signal) {\n      request.signal.addEventListener('abort', abortXhr)\n\n      xhr.onreadystatechange = function() {\n        // DONE (success or failure)\n        if (xhr.readyState === 4) {\n          request.signal.removeEventListener('abort', abortXhr)\n        }\n      }\n    }\n\n    xhr.send(typeof request._bodyInit === 'undefined' ? null : request._bodyInit)\n  })\n}\n\nfetch.polyfill = true\n\nif (!g.fetch) {\n  g.fetch = fetch\n  g.Headers = Headers\n  g.Request = Request\n  g.Response = Response\n}\n\n\n//# sourceURL=webpack://semanticfinder/./node_modules/whatwg-fetch/fetch.js?");

/***/ }),

/***/ "./src/js/index.js":
/*!*************************!*\
  !*** ./src/js/index.js ***!
  \*************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var bootstrap_dist_js_bootstrap_bundle_min_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! bootstrap/dist/js/bootstrap.bundle.min.js */ \"./node_modules/bootstrap/dist/js/bootstrap.bundle.min.js\");\n/* harmony import */ var bootstrap_dist_js_bootstrap_bundle_min_js__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(bootstrap_dist_js_bootstrap_bundle_min_js__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var codemirror__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! codemirror */ \"./node_modules/codemirror/lib/codemirror.js\");\n/* harmony import */ var codemirror__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(codemirror__WEBPACK_IMPORTED_MODULE_1__);\n/* harmony import */ var pako__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! pako */ \"./node_modules/pako/dist/pako.esm.mjs\");\n/* harmony import */ var codemirror_mode_javascript_javascript_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! codemirror/mode/javascript/javascript.js */ \"./node_modules/codemirror/mode/javascript/javascript.js\");\n/* harmony import */ var codemirror_mode_javascript_javascript_js__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(codemirror_mode_javascript_javascript_js__WEBPACK_IMPORTED_MODULE_3__);\n/* harmony import */ var codemirror_addon_search_searchcursor_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! codemirror/addon/search/searchcursor.js */ \"./node_modules/codemirror/addon/search/searchcursor.js\");\n/* harmony import */ var codemirror_addon_search_searchcursor_js__WEBPACK_IMPORTED_MODULE_4___default = /*#__PURE__*/__webpack_require__.n(codemirror_addon_search_searchcursor_js__WEBPACK_IMPORTED_MODULE_4__);\n/* harmony import */ var _semantic_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./semantic.js */ \"./src/js/semantic.js\");\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./utils.js */ \"./src/js/utils.js\");\n/* harmony import */ var _css_styles_css__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../css/styles.css */ \"./src/css/styles.css\");\n/* harmony import */ var bootstrap_dist_css_bootstrap_min_css__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! bootstrap/dist/css/bootstrap.min.css */ \"./node_modules/bootstrap/dist/css/bootstrap.min.css\");\n/* harmony import */ var codemirror_lib_codemirror_css__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! codemirror/lib/codemirror.css */ \"./node_modules/codemirror/lib/codemirror.css\");\n/* harmony import */ var ollama_browser__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ollama/browser */ \"./node_modules/ollama/dist/browser.js\");\n/* harmony import */ var marked__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! marked */ \"./node_modules/marked/lib/marked.esm.js\");\n/* harmony import */ var _SemanticFinder_svg__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./SemanticFinder.svg */ \"./src/js/SemanticFinder.svg\");\n// @ts-nocheck\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n/**\n * @type {Array<CodeMirror.TextMarker>}\n */\nlet markers = [];\n/**\n * @type {CodeMirror.EditorFromTextArea}\n */\nlet editor;\nlet submitTime = 0;\nlet isProcessing = false;\nlet selectedIndex = -1;\nlet selectedClassName = '';\nlet prevCard;\nconst nextButton = document.getElementById('next');\nconst prevButton = document.getElementById('prev');\nconst submitButton = document.getElementById('submit_button');\nconst summaryButton = document.getElementById('get_summary')\nconst chatButton = document.getElementById('get_chat')\nconst dimensionalityReductionButton = document.getElementById('dimensionalityReduction')\nconst progressBarEmbeddings = document.getElementById('progressBarProgress');\nconst progressBarChat = document.getElementById('progressBarChat');\nconst progressBarSummary = document.getElementById('progressBarSummary');\n\nasync function fetchModels(modelType, sortOption) {\n    try {\n        const filename = `models/${modelType}_${sortOption}_sizes.json`;\n        const response = await fetch(filename);\n\n        if (!response.ok) {\n            throw new Error(`Failed to fetch data: ${response.status} - ${response.statusText}`);\n        }\n\n        const data = await response.json()\n        return data;\n    } catch (error) {\n        console.error('Error:', error);\n        return null;\n    }\n}\n\nasync function replaceOptionsWithJSONData(jsonData) {\n    // Get the select element\n    const selectElement = document.getElementById(\"model-name\");\n\n    // Clear existing options\n    selectElement.innerHTML = \"\";\n\n    // Iterate over the models and add options to the select element\n    jsonData.models.forEach((model) => {\n        const option = document.createElement(\"option\");\n        option.value = model.id;\n        option.textContent = `${model.id} | ${model.model_size}Mb ${model.downloads} ${model.likes}`;\n\n        // Check if the current model's ID is \"TaylorAI/gte-tiny\"\n        if (model.id === \"TaylorAI/gte-tiny\") {\n            option.selected = true;\n        }\n\n        selectElement.appendChild(option);\n    });\n}\n\n////////////////////////////////////\nfunction removeHighlights() {\n    markers.forEach(_ => _.clear());\n    markers.length = 0;\n}\n\nfunction deactivateSubmitButton(button = submitButton) {\n    if (button) {\n        button.setAttribute('disabled', '');\n        button.textContent = 'Loading...';\n    }\n}\n\nfunction activateSubmitButton(button = submitButton, buttonText = \"Find\") {\n    if (button) {\n        button.removeAttribute('disabled');\n        button.textContent = buttonText;\n    }\n}\n\nfunction finishCallback() {\n    summaryButton.removeAttribute('disabled');\n    chatButton.removeAttribute('disabled');\n    dimensionalityReductionButton.removeAttribute('disabled');\n    submitButton.textContent = 'Find';\n    isProcessing = false;\n    const processTime = new Date().getTime() - submitTime;\n    console.log(`Finished ${processTime}ms`);\n    //tsne(); // for development perform tsne right after finishing\n    activateScrollButtons();\n}\n\nasync function onSubmit() {\n    summaryButton.setAttribute('disabled', '');\n    chatButton.setAttribute('disabled', '');\n    dimensionalityReductionButton.setAttribute('disabled', '');\n    if (!isProcessing) {\n        submitTime = new Date().getTime();\n        isProcessing = true;\n        submitButton.textContent = 'Stop';\n\n        document.getElementById('results-list').innerHTML = '';\n        selectedIndex = -1;\n        await semanticHighlight(finishCallback);\n    } else {\n        submitButton.textContent = 'Submit';\n        isProcessing = false;\n    }\n}\n\nasync function resetResults() {\n    removeHighlights();\n\n    // Get results list element\n    const resultsDiv = document.getElementById('results-list');\n    resultsDiv.innerHTML = '';\n}\n\n/**\n *\n * @param {*} results\n */\nasync function updateResults(results) {\n    resetResults();\n    const k = document.getElementById('threshold').value;\n\n    for (let i = 0; i < Math.min(k, results.length); i++) {\n        const resultItem = results[i];\n\n        let highlightClass;\n        if (i === 0) highlightClass = 'highlight-first';\n        else if (i === 1) highlightClass = 'highlight-second';\n        else highlightClass = 'highlight-third';\n\n        createHighlight(resultItem[0], highlightClass, resultItem[1]);\n    }\n}\n\n/**\n * @param {string} text\n * @param {string} className\n * @param {number} similarity\n */\nfunction createHighlight(text, className, similarity) {\n    const resultsDiv = document.getElementById('results-list');\n    const cursor = editor.getSearchCursor(text);\n\n    while (cursor.findNext()) {\n        const marker = editor.markText(cursor.from(), cursor.to(), { className });\n        markers.push(marker);\n\n        // create card\n        const listItem = document.createElement('div');\n        listItem.classList.add('card');\n        listItem.innerHTML = createCardHTML(text, similarity);\n\n        resultsDiv.appendChild(listItem);\n\n        const index = resultsDiv.childElementCount - 1;\n\n        // Add click listener for card\n        listItem.addEventListener('click', function () {\n            editor.scrollIntoView(markers[index].find());\n            highlightSelected(index);\n        });\n    }\n}\n\n/**\n * @param {string} title\n * @param {number} similarity\n * @returns\n */\nfunction createCardHTML(title, similarity) {\n    return `\n        <div class=\"card-body\">\n            <h5 class=\"card-title\">${title}</h5>\n            <h6 class=\"card-subtitle mb-2 text-muted\">Similarity: ${similarity.toFixed(2)}</h6>\n        </div>\n    `;\n}\n\n/**\n *\n * @param {number} index\n */\nfunction highlightSelected(index) {\n    highlightCard(index);\n    if (selectedIndex !== -1) {\n        const marker0 = editor.markText(markers[selectedIndex].find().from, markers[selectedIndex].find().to, { className: selectedClassName });\n        markers[selectedIndex].clear();\n        markers[selectedIndex] = marker0;\n    }\n\n    selectedIndex = index;\n    selectedClassName = markers[selectedIndex].className;\n\n    const marker1 = editor.markText(markers[selectedIndex].find().from, markers[selectedIndex].find().to, { className: 'highlight-select' });\n    markers[selectedIndex].clear();\n    markers[selectedIndex] = marker1;\n}\n\nfunction highlightCard(index) {\n    const resultsDiv = document.getElementById('results-list');\n    const cards = resultsDiv.getElementsByClassName('card');\n\n    // Ensure the index is within the range of the cards.\n    if (prevCard) {\n        prevCard.style.backgroundColor = '';\n    }\n    prevCard = cards[index];\n    cards[index].style.backgroundColor = '#f4ac90';\n}\n\nasync function setProgressBarValue(value, progressBar = progressBarEmbeddings) {\n    if (value === '' || value === '0') {\n        progressBar.style.transition = 'width .1s ease'; // Temporarily override the transition duration\n        progressBar.classList.add('progress-bar-animated');\n        progressBar.classList.add('progress-bar-striped');\n    } else {\n        progressBar.style.transition = ''; // Restore the original transition\n    }\n\n    progressBar.style.width = value + '%';\n    progressBar.textContent = value + '%';\n    progressBar.parentNode.setAttribute('aria-valuenow', value);\n\n    if (value === 100) {\n        progressBar.classList.remove('progress-bar-animated');\n        progressBar.classList.remove('progress-bar-striped');\n    }\n}\n\n\nfunction updateSplitParam(splitParamValue) {\n    const splitParam = document.getElementById('split-param');\n\n    switch (splitParamValue) {\n        case 'Words':\n            splitParam.disabled = false;\n            document.querySelector(\"label[for='split-param']\").textContent = '# Words';\n            splitParam.type = 'number';\n            splitParam.value = 7;\n            splitParam.min = 1;\n            break;\n        case 'Tokens':\n            splitParam.disabled = false;\n            document.querySelector(\"label[for='split-param']\").textContent = '# Tokens';\n            splitParam.type = 'number';\n            splitParam.value = 15;\n            splitParam.min = 1;\n            splitParam.max = 512;\n            break;\n        case 'Chars':\n            splitParam.disabled = false;\n            document.querySelector(\"label[for='split-param']\").textContent = '# Chars';\n            splitParam.type = 'number';\n            splitParam.value = 40;\n            splitParam.min = 1;\n            break;\n        case 'Regex':\n            splitParam.disabled = false;\n            document.querySelector(\"label[for='split-param']\").textContent = 'Regex';\n            splitParam.type = 'text';\n            splitParam.value = '[.,]\\\\s';\n            break;\n        default:\n            splitParam.value = null;\n            splitParam.disabled = true;\n            document.querySelector(\"label[for='split-param']\").textContent = '';\n            splitParam.placeholder = '';\n    }\n}\n\nasync function CoderMirrorFindAndScrollIntoView(CM_text) {\n    editor.scrollIntoView(CM_text.find())\n}\n\nlet cachedQueryValues = \n    {\"text\" : \"\",\n    \"splitType\": \"\",\n    \"splitParam\":\"\",\n    \"inputTexts\":\"\",\n    \"inputQuery\":\"\"\n\n    }\n\nasync function semanticHighlight(callback) {\n    deactivateScrollButtons();\n    resetResults();\n    setProgressBarValue(0);\n\n    // query input embedding\n    const inputQuery = document.getElementById('query-text').value;\n\n    // chunk vals\n    const text = editor.getValue('');\n    const splitType = document.getElementById('split-type').value;\n    const splitParam = document.getElementById('split-param').value;\n\n    // avoid executing the chunking logic if params are the same\n    const chunkValuesEqual = (\n        text === cachedQueryValues.text &&\n        splitType === cachedQueryValues.splitType &&\n        splitParam === cachedQueryValues.splitParam\n    );\n    \n    let inputTexts;\n\n    if (chunkValuesEqual) {\n        inputTexts = cachedQueryValues.inputTexts\n    } else {\n        inputTexts = await (0,_utils_js__WEBPACK_IMPORTED_MODULE_6__.splitText)(text, splitType, splitParam);\n    \n        //inputTexts = await splitText(text, splitType, splitParam);\n        // update cache var\n        cachedQueryValues.text = text;\n        cachedQueryValues.splitType = splitType;\n        cachedQueryValues.splitParam = splitParam;\n        cachedQueryValues.inputTexts = inputTexts;\n\n    }\n\n\n// full text search NULL CHECKS !\n \n  // Example usage:\n  const wordsToCheckAnyInput = document.getElementById(\"wordsToCheckAny\");\n  const wordsToCheckAllInput = document.getElementById(\"wordsToCheckAll\");\n  const wordsToAvoidAnyInput = document.getElementById(\"wordsToAvoidAny\");\n  const wordsToAvoidAllInput = document.getElementById(\"wordsToAvoidAll\");\n  \n  const wordsToCheckAny = wordsToCheckAnyInput.value.trim() ? wordsToCheckAnyInput.value.split(',').map(word => word.trim()) : [];\n  const wordsToCheckAll = wordsToCheckAllInput.value.trim() ? wordsToCheckAllInput.value.split(',').map(word => word.trim()) : [];\n  const wordsToAvoidAny = wordsToAvoidAnyInput.value.trim() ? wordsToAvoidAnyInput.value.split(',').map(word => word.trim()) : [];\n  const wordsToAvoidAll = wordsToAvoidAllInput.value.trim() ? wordsToAvoidAllInput.value.split(',').map(word => word.trim()) : [];\n  \n  \n  const filterTexts = (inputTexts, wordsToCheckAny, wordsToCheckAll, wordsToAvoidAny, wordsToAvoidAll) => {\n    return inputTexts.reduce((result, text) => {\n      // Skip empty fields or fields containing only an empty string\n      if (text.trim() === \"\") {\n        return result;\n      }\n  \n      const shouldInclude =\n        (isEmptyArray(wordsToCheckAny) || wordsToCheckAny.some(word => text.includes(word))) &&\n        (isEmptyArray(wordsToAvoidAny) || !wordsToAvoidAny.some(word => text.includes(word))) &&\n        (isEmptyArray(wordsToCheckAll) || wordsToCheckAll.every(word => text.includes(word))) &&\n        (isEmptyArray(wordsToAvoidAll) || !wordsToAvoidAll.every(word => text.includes(word)));\n  \n      if (shouldInclude) {\n        result.push(text);\n      }\n  \n      return result;\n    }, []);\n  };\n  \n  const isEmptyArray = (arr) => arr.length === 0 || (arr.length === 1 && arr[0] === \"\");\n  \n  // Example usage:\n\n  inputTexts = filterTexts(inputTexts, wordsToCheckAny, wordsToCheckAll, wordsToAvoidAny, wordsToAvoidAll);\n\n  // full text search\n  \n    //console.log(inputTexts)\n\n    //let inputTexts = await splitText(text, splitType, splitParam);\n    // Initialize inputTexts dictionary with 0 as similarity\n    inputTexts = inputTexts.reduce((acc, text) => {\n        acc[text] = 0;\n        return acc;\n    }, {});\n\n    const numUpdates = document.getElementById('update-rate').value;\n\n    await (0,_semantic_js__WEBPACK_IMPORTED_MODULE_5__.embedQuery)(inputQuery);\n\n    const N = Object.keys(inputTexts).length;\n    const interval = Math.ceil(N / Math.min(numUpdates, N));\n    const progressBarInterval = Math.ceil(N / Math.min(100, N));\n\n    // this part here is still a performance bottleneck and responsible for ~50% of the processing time \n    // it performs a lookup in a dictionary where key-value pairs (text-embeddings) are stored\n    // if the value has an embedding already, it's appended to the results dict \n    // if not, it needs to be calculated \n    // the logic has the advantage that when e.g. one sentence is appended to a book, 99% of the index \n    // can be reused and it is super fast. On the other hand it slows down other user cases where you know \n    // in advance, that the text:embeddings won't change.\n    // will need to add a cache for inputTexts in the future\n\n    let i = 0;\n    let lastProgressBarUpdate = 0;\n    const inputTextPromises = Object.keys(inputTexts).map(async (inputText, i) => {\n        if (!isProcessing) {\n          return Promise.resolve();\n        }\n      \n        const cosineSimilarity = await (0,_semantic_js__WEBPACK_IMPORTED_MODULE_5__.similarity)(inputText);\n\n        inputTexts[inputText] = cosineSimilarity;\n      \n        if (i % progressBarInterval === 0 || i === N - 1) {\n            const currentTime = Date.now();\n            const timeSinceLastUpdate = currentTime - lastProgressBarUpdate;\n            \n            // update the porgress bar only every 100ms to avoid slowing down on consecutive calls\n            // makes ~0.3s difference with 23k embeddings!\n            if (timeSinceLastUpdate >= 100) {\n              const progress = Math.round(((i + 1) * 100) / N);\n              setProgressBarValue(progress);\n          \n              lastProgressBarUpdate = currentTime;\n            }\n          }\n        \n        if (i === N - 1) {\n            const progress = Math.round(((i + 1) * 100) / N);\n              setProgressBarValue(progress);\n        }\n      \n        if (i !== 0 && (i % interval === 0 || i === N - 1)) {\n            const sortedResults = Object.entries(inputTexts).sort((a, b) => b[1] - a[1]);\n            updateResults(sortedResults);\n          if (markers.length > 0 && (selectedIndex === -1 || selectedIndex === 0)) {\n            CoderMirrorFindAndScrollIntoView(markers[0]);\n          }\n        }\n      \n        return Promise.resolve();\n      });\n      \n      await Promise.all(inputTextPromises);\n      \n    callback();\n}\n\nfunction activateScrollButtons() {\n    // Enable the next and prev buttons\n    if (nextButton) {\n        nextButton.removeAttribute('disabled');\n    }\n\n    if (prevButton) {\n        prevButton.removeAttribute('disabled');\n    }\n}\n\nfunction deactivateScrollButtons() {\n    // Disable the next and prev buttons\n    if (nextButton) {\n        nextButton.setAttribute('disabled', '');\n    }\n\n    if (prevButton) {\n        prevButton.setAttribute('disabled', '');\n    }\n}\n\nfunction nextMarker() {\n    if (selectedIndex === -1) {\n        highlightSelected(0);\n    } else {\n        highlightSelected((selectedIndex + 1) % markers.length);\n        editor.scrollIntoView(markers[selectedIndex].find());\n    }\n}\n\nfunction prevMarker() {\n    if (selectedIndex === -1) {\n        highlightSelected(0);\n    } else {\n        highlightSelected((selectedIndex - 1 + markers.length) % markers.length);\n        editor.scrollIntoView(markers[selectedIndex].find());\n    }\n}\n\nasync function summarizeTopResults() {\n    var topResultsString = Array.from(document.querySelectorAll('#results-list .card-title')).map(title => title.textContent).join('; ');\n    //console.log(topResultsString)\n    //let currentTopResults = \"The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on each side. During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest man-made structure in the world, a title it held for 41 years until the Chrysler Building in New York City was finished in 1930. It was the first structure to reach a height of 300 metres. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct.\"\n    const currentSummary = await (0,_semantic_js__WEBPACK_IMPORTED_MODULE_5__.summarizeText)(topResultsString);\n    //console.log(currentSummary[0].summary_text)\n    //document.getElementById(\"summary_text\").innerHTML = currentSummary[0].summary_text //out[0].summary_text;\n}\n\nfunction get_top_search_results(){\n    const search_results = \"\\nParagraph: \" + Array.from(document.querySelectorAll('#results-list .card-title')).map(title => title.textContent).join('\\nParagraph: ');\n    return search_results\n    }\n\nasync function chatTopResults() {\n    document.getElementById(\"chat_text\").innerHTML = \"\"; // progress bar\n\n    const chatQuery = document.getElementById(\"chat_query\").value;\n    \n    const finalQuery = chatQuery.replace(\"SEARCH_RESULTS\", `\"\"\"${get_top_search_results()}\"\"\"`).replace(\"FULL_TEXT\",`\"\"\"${editor.getValue()}\"\"\"`) // add variables in string\n    console.log(finalQuery)\n    if (finalQuery.length > 10000){\n        alert(\"Attention: Context might be too large (> 10.000 chars) and require too much RAM to be processed. Try working with fewer results or shorter chunks.\")\n    }\n\n    var max_new_tokens = document.getElementById(\"chat_max_new_tokens\").value;\n    const currentChat = await (0,_semantic_js__WEBPACK_IMPORTED_MODULE_5__.chatText)(finalQuery, max_new_tokens);\n}\n\nfunction resetMetadata() {\n    document.getElementById(\"textTitle\").value = \"\";\n    document.getElementById(\"textAuthor\").value = \"\";\n    document.getElementById(\"textYear\").value = \"\";\n    document.getElementById(\"textSourceURL\").value = \"\";\n    document.getElementById(\"textNotes\").value = \"\";\n    document.getElementById(\"textLanguage\").value = \"\";\n}\n\n\nfunction createMetaJSON() {\n\n    const modelName = document.getElementById(\"model-name\").value;\n    const quantized = document.getElementById(\"quantized\").checked;\n    const splitType = document.getElementById(\"split-type\").value;\n    const splitParam = document.getElementById(\"split-param\").value;\n    const exportDecimals = parseInt(document.getElementById(\"exportDecimals\").value);\n    const textTitle = document.getElementById(\"textTitle\").value;\n    const textAuthor = document.getElementById(\"textAuthor\").value;\n    const textYear = parseInt(document.getElementById(\"textYear\").value, 10);\n    const textSourceURL = document.getElementById(\"textSourceURL\").value;\n    const textNotes = document.getElementById(\"textNotes\").value;\n    const textLanguage = document.getElementById(\"textLanguage\").value;\n    const wordsToCheckAny = document.getElementById(\"wordsToCheckAny\").value;\n    const wordsToCheckAll = document.getElementById(\"wordsToCheckAll\").value;\n    const wordsToAvoidAny = document.getElementById(\"wordsToAvoidAny\").value;\n    const wordsToAvoidAll = document.getElementById(\"wordsToAvoidAll\").value;\n  \n    const lines = editor.lineCount();\n    const characters = editor.getValue().length;\n    \n    // shorthand property names\n    const metaJSON = {\n        textTitle,\n        textAuthor,\n        textYear,\n        textLanguage,\n        textSourceURL,\n        textNotes,\n        modelName,\n        quantized,\n        splitType,\n        splitParam,\n        exportDecimals,\n        lines,\n        characters,\n        wordsToCheckAny,\n        wordsToCheckAll,\n        wordsToAvoidAny,\n        wordsToAvoidAll\n\n    };\n    \n    return metaJSON\n}\n\nfunction setValuesFromMetaJSON(jsonObject) {\n    // Set values based on the provided JSON object\n    document.getElementById(\"model-name\").value = jsonObject.modelName || \"\";\n    document.getElementById(\"quantized\").checked = jsonObject.quantized;\n    document.getElementById(\"split-type\").value = jsonObject.splitType || \"\";\n\n    document.getElementById(\"exportDecimals\").value = jsonObject.exportDecimals || \"\";\n    document.getElementById(\"textTitle\").value = jsonObject.textTitle || \"\";\n    document.getElementById(\"textAuthor\").value = jsonObject.textAuthor || \"\";\n    document.getElementById(\"textYear\").value = jsonObject.textYear || \"\";\n    document.getElementById(\"textSourceURL\").value = jsonObject.textSourceURL || \"\";\n    document.getElementById(\"textNotes\").value = jsonObject.textNotes || \"\";\n    document.getElementById(\"textLanguage\").value = jsonObject.textLanguage || \"\";\n    document.getElementById(\"wordsToCheckAny\").value = jsonObject.wordsToCheckAny || \"\";\n    document.getElementById(\"wordsToCheckAll\").value = jsonObject.wordsToCheckAll || \"\";\n    document.getElementById(\"wordsToAvoidAny\").value = jsonObject.wordsToAvoidAny || \"\";\n    document.getElementById(\"wordsToAvoidAll\").value = jsonObject.wordsToAvoidAll || \"\";\n\n    updateSplitParam(jsonObject.splitType); // causing a bug, needs fix\n    document.getElementById(\"split-param\").value = jsonObject.splitParam || \"\";\n}\n\n\n\nasync function reloadModel(modelName){\n    deactivateSubmitButton();\n    setProgressBarValue(0);\n    await (0,_semantic_js__WEBPACK_IMPORTED_MODULE_5__.loadSemantic)(modelName);\n    activateSubmitButton();\n}\n\nfunction handleFileUpload() {\n    console.log(\" File upload started...\")\n    ;(0,_utils_js__WEBPACK_IMPORTED_MODULE_6__.showToast)(\" File upload started...\");\n    const fileInput = document.getElementById('file-upload');\n    const file = fileInput.files[0];\n\n    if (!file) {\n        alert('Please select a file.');\n        return;\n    }\n\n    // Read the file as an ArrayBuffer\n    const reader = new FileReader();\n    reader.onload = function (event) {\n        const arrayBuffer = event.target.result;\n\n        // Use pako.js to decompress the gzip data\n        const inflatedData = pako__WEBPACK_IMPORTED_MODULE_2__[\"default\"].inflate(arrayBuffer, { to: 'string' });\n\n        // Convert the JSON string to a JavaScript object\n        const jsonData = JSON.parse(inflatedData);\n\n        setValuesFromMetaJSON(jsonData.meta)\n\n        if (jsonData && jsonData.text !== \"\") {\n            editor.setValue(jsonData.text);\n        }\n\n        reloadModel(jsonData.meta.modelName)\n\n        // Post the data to the semanticWorker\n        semanticWorker.postMessage({ type: 'importEmbeddingsDict', data: jsonData.index });\n    };\n\n    // Read the file as an ArrayBuffer\n    reader.readAsArrayBuffer(file);\n    //submitButton.click(); // dont click as the model must load first!\n\n    (0,_utils_js__WEBPACK_IMPORTED_MODULE_6__.showToast)(\"Index loaded \");\n    console.log('Index loaded ');\n}\n\nfunction handleRemoteFileUpload(fileURL ) {\n    editor.setValue(\"\");\n    document.getElementById('update-rate').value = 1;\n    (0,_utils_js__WEBPACK_IMPORTED_MODULE_6__.showToast)(\" Loading file...\");\n    console.log(fileURL)\n\n    if (!fileURL) {\n        alert('Please enter a valid URL.');\n        return;\n    }\n\n    // Make a fetch request to get the remote file\n    fetch(fileURL)\n        .then(response => {\n            if (!response.ok) {\n                throw new Error(`Failed to fetch file (${response.status} ${response.statusText})`);\n            }\n            return response.arrayBuffer();\n        })\n        .then(arrayBuffer => {\n            // Use pako.js to decompress the gzip data\n            const inflatedData = pako__WEBPACK_IMPORTED_MODULE_2__[\"default\"].inflate(arrayBuffer, { to: 'string' });\n\n            // Convert the JSON string to a JavaScript object\n            const jsonData = JSON.parse(inflatedData);\n\n            setValuesFromMetaJSON(jsonData.meta);\n\n            if (jsonData && jsonData.text !== \"\") {\n                editor.setValue(jsonData.text);\n            }\n\n            reloadModel(jsonData.meta.modelName);\n\n            // Post the data to the semanticWorker\n            semanticWorker.postMessage({ type: 'importEmbeddingsDict', data: jsonData.index });\n\n            (0,_utils_js__WEBPACK_IMPORTED_MODULE_6__.showToast)(\"Index loaded \");\n        })\n        .catch(error => {\n            alert(`Error: ${error.message}`);\n        });\n}\n\n// Function to generate random points with labels and colors\nfunction generateRandomPoints(numPoints) {\n    const points = [];\n    for (let i = 0; i < numPoints; i++) {\n        const point = {\n            x: Math.random() * 500, // Adjust the range as needed\n            y: Math.random() * 500,\n            label: generateRandomString(),\n            color: Math.random() // Random value between 0 and 1 for shades of green\n        };\n        points.push(point);\n    }\n    return points;\n}\n\n// Function to generate a random string\nfunction generateRandomString() {\n    const characters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz';\n    let result = '';\n    for (let i = 0; i < 5; i++) {\n        result += characters.charAt(Math.floor(Math.random() * characters.length));\n    }\n    return result;\n}\n\nasync function tsne() {\n    semanticWorker.postMessage({\n        type: \"tsne\",\n        data: {\n            \"iterations\": document.getElementById(\"dimReductionIterations\").value,\n            \"dimensionalityReductionSimilarityThreshold\": document.getElementById(\"dimensionalityReductionSimilarityThreshold\").value     \n        }\n\n    });\n}\n\nlet ollama_response = \"\"\nasync function ollama_chat(server_url = 'http://localhost:11434'){\n    //const ollama = new Ollama({ host: server_url }) // doesn't currently work\n\n    const chatQuery = document.getElementById(\"ollama_chat_query\").value;\n    const finalQuery = chatQuery.replace(\"SEARCH_RESULTS\", `\"\"\"${get_top_search_results()}\"\"\"`).replace(\"FULL_TEXT\",`\"\"\"${editor.getValue()}\"\"\"`)\n    \n    console.log(finalQuery);\n    const message = { role: 'user', content: finalQuery }\n\n    ollama_response = \"\"\n    const ollama_chat_model = document.getElementById(\"ollama_chat_model\").value\n\n    const response = await ollama_browser__WEBPACK_IMPORTED_MODULE_10__[\"default\"].chat({ model: ollama_chat_model, messages: [message], stream: true })\n    for await (const part of response) {\n        const ollama_char = part.message.content\n\n        ollama_response += ollama_char\n        \n        document.getElementById(\"ollama_chat_text\").innerHTML = (0,marked__WEBPACK_IMPORTED_MODULE_11__.marked)(ollama_response)\n    }\n}\n\n\n/**\n * Setup the application when the page loads.\n */\nwindow.onload = async function () {\n    window.onSubmit = onSubmit;\n\n    editor = codemirror__WEBPACK_IMPORTED_MODULE_1___default().fromTextArea(document.getElementById('input-text'), {\n        lineNumbers: true,\n        mode: 'text/plain',\n        matchBrackets: true,\n        lineWrapping: true\n    });\n\n    const fontFamilyInput = document.getElementById(\"font-family\");\n    const fontSizeInput = document.getElementById(\"font-size\");\n\n    const updateStyles = () => {\n        const newFontFamily = fontFamilyInput.value;\n        const newFontSize = fontSizeInput.value + \"px\";\n        const codeMirrorElement = document.querySelector(\".CodeMirror.cm-s-default.CodeMirror-wrap\");\n\n        codeMirrorElement.style.fontFamily = newFontFamily;\n        codeMirrorElement.style.fontSize = newFontSize;\n    };\n\n    document.addEventListener(\"input\", (event) => {\n        if (event.target === fontFamilyInput || event.target === fontSizeInput) {\n            updateStyles();\n        }\n    });\n\n    document.getElementById('model-name').addEventListener('change', async function () {\n        deactivateSubmitButton();\n        setProgressBarValue(0);\n        const modelName = this.value;\n        await (0,_semantic_js__WEBPACK_IMPORTED_MODULE_5__.loadSemantic)(modelName);\n        activateSubmitButton();\n    });\n\n    document.getElementById('quantized').addEventListener('change', async function () {\n        deactivateSubmitButton();\n        setProgressBarValue(0);\n        const modelName = document.getElementById(\"model-name\").value\n        await (0,_semantic_js__WEBPACK_IMPORTED_MODULE_5__.loadSemantic)(modelName);\n        activateSubmitButton();\n    });\n\n    document.getElementById('summary-model-name').addEventListener('change', async function () {\n        deactivateSubmitButton(summaryButton);\n        setProgressBarValue(0, progressBarSummary);\n        const modelName = this.value;\n        await (0,_semantic_js__WEBPACK_IMPORTED_MODULE_5__.loadSummary)(modelName);\n        activateSubmitButton(summaryButton, \"Summarize\");\n    });\n\n    document.getElementById('chat-model-name').addEventListener('change', async function () {\n        deactivateSubmitButton(chatButton);\n        setProgressBarValue(0, progressBarChat);\n        const modelName = this.value;\n        console.log(modelName);\n        await (0,_semantic_js__WEBPACK_IMPORTED_MODULE_5__.loadChat)(modelName);\n        activateSubmitButton(chatButton, \"Chat\");\n    });\n    \n    // Call the function manually or bind it to an event\n    document.getElementById('split-type').addEventListener('change', function() {\n        updateSplitParam(document.getElementById('split-type').value);\n    });\n\n    // Example of calling the function manually\n    // updateSplitParam();\n    \n\n\n    // Dynamically load/overwrite existing options from JSON. Useful for different sorting or updates.\n    //const modelType = 'feature-extraction'; // Replace with 'text2text' if needed\n    //const sortingOptions = ['trending', 'likes', 'downloads', 'modified'];\n    //const selectedSortOption = 'downloads'; // Replace with the desired sorting option\n    //fetchModels(modelType, selectedSortOption)\n    //    .then(data => {\n    //        if (data) {\n    //            console.log(data);\n    //            replaceOptionsWithJSONData(data)\n    //        }\n    //    })\n    //    .catch(err => {\n    //        console.error('Error:', err);\n    //    });\n\n    let summary_is_loaded = true; // Flag to track the first click\n    document.getElementById('get_summary').addEventListener('click', async function (event) {\n        deactivateSubmitButton(summaryButton);\n        event.preventDefault();\n        let this_model = document.getElementById('summary-model-name').value;\n\n        if (summary_is_loaded) {\n            await (0,_semantic_js__WEBPACK_IMPORTED_MODULE_5__.loadSummary)(this_model); // Execute only on the first click\n            summary_is_loaded = false; // Set the flag to false after the first click\n        }\n\n        await summarizeTopResults(); // Execute on every click after the first one\n        activateSubmitButton(summaryButton, \"Summarize\");\n    });\n\n    let chat_is_loaded = true; // Flag to track the first click\n    document.getElementById('get_chat').addEventListener('click', async function (event) {\n        deactivateSubmitButton(chatButton);\n        event.preventDefault();\n        let this_model = document.getElementById('chat-model-name').value;\n\n        if (chat_is_loaded) {\n            await (0,_semantic_js__WEBPACK_IMPORTED_MODULE_5__.loadChat)(this_model); // Execute only on the first click\n            chat_is_loaded = false; // Set the flag to false after the first click\n        }\n\n        await chatTopResults(); // Execute on every click after the first one\n        activateSubmitButton(chatButton, \"Chat\");\n    });\n    \n    document.getElementById('ollama_get_chat').addEventListener('click', function (event) {\n        ollama_chat();\n    });\n\n    document.getElementById('next').addEventListener('click', function (event) {\n        event.preventDefault();\n        nextMarker();\n    });\n\n    document.getElementById('prev').addEventListener('click', function (event) {\n        event.preventDefault();\n        prevMarker();\n    });\n\n    function exportEmbeddings(type, text = '') {\n        semanticWorker.postMessage({\n            type: type,\n            data: {\n                \"text\": text,\n                \"meta\": createMetaJSON()\n            }\n        });\n    }\n\n    document.getElementById('exportEmbeddingsDict').addEventListener('click', function (event) {\n        exportEmbeddings('exportEmbeddingsDict');\n    });\n\n    document.getElementById('resetMetadata').addEventListener('click', function (event) {\n        resetMetadata();\n    });\n\n    document.getElementById('dimensionalityReduction').addEventListener('click', function (event) {\n        tsne();\n    });\n\n    document.getElementById('exportEmbeddingsDictWithText').addEventListener('click', function (event) {\n        const currentEditorText = editor.getValue('');\n        exportEmbeddings('exportEmbeddingsDict', currentEditorText);\n    });\n\n    document.getElementById('confirm-upload').addEventListener('click', function (event) {\n        document.getElementById('update-rate').value = 1;\n        handleFileUpload();\n    });\n\n    document.getElementById('confirm-remote-upload').addEventListener('click', function (event) {\n        document.getElementById('update-rate').value = 1;\n        handleRemoteFileUpload(document.getElementById('importURL').value);\n    });\n\n    // initialize loading\n    // read url params and load from Hf or from remote \n    const getUrlParameters = () => new URLSearchParams(window.location.search);\n    const urlParams = getUrlParameters();\n\n    if (urlParams.has('url')) {\n        handleRemoteFileUpload(urlParams.get('url'));\n\n    } else if (urlParams.has('hf')) {\n        handleRemoteFileUpload(\n            `https://huggingface.co/datasets/do-me/SemanticFinder/resolve/main/${urlParams.get('hf')}.json.gz`);\n\n    } \n    else {\n        const modelName = document.getElementById('model-name').value;\n        await (0,_semantic_js__WEBPACK_IMPORTED_MODULE_5__.loadSemantic)(modelName);\n        activateSubmitButton();\n    }\n};\n\n//# sourceURL=webpack://semanticfinder/./src/js/index.js?");

/***/ }),

/***/ "./src/js/semantic.js":
/*!****************************!*\
  !*** ./src/js/semantic.js ***!
  \****************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   chatText: () => (/* binding */ chatText),\n/* harmony export */   embedQuery: () => (/* binding */ embedQuery),\n/* harmony export */   getTokens: () => (/* binding */ getTokens),\n/* harmony export */   loadChat: () => (/* binding */ loadChat),\n/* harmony export */   loadSemantic: () => (/* binding */ loadSemantic),\n/* harmony export */   loadSummary: () => (/* binding */ loadSummary),\n/* harmony export */   similarity: () => (/* binding */ similarity),\n/* harmony export */   summarizeText: () => (/* binding */ summarizeText)\n/* harmony export */ });\n/* harmony import */ var _xenova_transformers__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @xenova/transformers */ \"./node_modules/@xenova/transformers/src/transformers.js\");\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./utils.js */ \"./src/js/utils.js\");\n\n\n\n// @ts-ignore\n_xenova_transformers__WEBPACK_IMPORTED_MODULE_0__.env.allowLocalModels = false;\n\n/**\n * @type {Worker}\n */\nconst worker = new Worker(new URL(/* worker import */ __webpack_require__.p + __webpack_require__.u(\"src_js_worker_js\"), __webpack_require__.b), {\n    type: undefined\n});\n\nwindow.semanticWorker = worker;\n\n/**\n * @type {EmbeddingVector}\n */\nlet queryEmbedding;\n\n/**\n * @type {Object<string, Function>}\n */\nconst similarityResolveMap = {};\n\n/**\n * @type {Object<string, Function>}\n */\nconst tokensResolveMap = {};\n\n/**\n * @type Function\n */\nlet loadResolve;\n\n/**\n * @type Function\n */\nlet queryResolve;\n\nfunction downloadFile(data, filename, mimeType) {\n    const blob = new Blob([data], { type: mimeType });\n\n    const link = document.createElement('a');\n    link.href = window.URL.createObjectURL(blob);\n    link.download = filename;\n\n    // Append the link to the body for programmatic click\n    document.body.appendChild(link);\n    link.click();\n\n    // Remove the link from the DOM\n    document.body.removeChild(link);\n}\n\nworker.onmessage = function (event) {\n    const message = event.data;\n    let resolve;\n\n    switch (message.type) {\n        case 'embeddingsDict':\n            const gzippedData = message.data;\n            //console.log(\"Embeddings data received.\");\n            // Download gzipped data as 'index.json.gz'\n            downloadFile(gzippedData, message.filename, 'application/gzip');\n            break;\n        case \"download\":\n            let downloadBar = document.getElementById('loading-progress');\n\n            if (message.data.status === 'progress') {\n                if (message.data.file !== \"onnx/model_quantized.onnx\") { break; }\n                let progress = message.data.progress.toFixed(2);\n                downloadBar.style.width = progress + '%';\n                downloadBar.textContent = progress + \"%\";\n\n                downloadBar.setAttribute('aria-valuenow', progress);\n            } else if (message.data.status === 'ready') {\n                downloadBar.style.width = '100%';\n                downloadBar.setAttribute('aria-valuenow', 100);\n                downloadBar.textContent = \"\";\n                loadResolve();\n            }\n            break;\n        case \"chat_download\":\n            let chatDownloadBar = document.getElementById('chat-progress');\n\n            if (message.data.status === 'progress') {\n                if (message.data.file !== \"onnx/decoder_model_merged_quantized.onnx\") { break; }\n                let progress = message.data.progress.toFixed(2);\n                chatDownloadBar.style.width = progress + '%';\n                chatDownloadBar.textContent = Math.round(progress) + '%';\n                chatDownloadBar.setAttribute('aria-valuenow', progress);\n            } else if (message.data.status === 'ready') {\n                chatDownloadBar.style.width = '100%';\n                chatDownloadBar.setAttribute('aria-valuenow', 100);\n                chatDownloadBar.textContent = \"\";\n                loadResolve();\n            }\n            break;\n        case \"summary_download\":\n            let summaryDownloadBar = document.getElementById('summary-progress');\n\n            if (message.data.status === 'progress') {\n                if (message.data.file !== \"onnx/decoder_model_merged_quantized.onnx\") { break; }\n                let progress = message.data.progress.toFixed(2);\n                summaryDownloadBar.style.width = progress + '%';\n                summaryDownloadBar.textContent = Math.round(progress) + '%';\n                summaryDownloadBar.setAttribute('aria-valuenow', progress);\n            } else if (message.data.status === 'ready') {\n                summaryDownloadBar.style.width = '100%';\n                summaryDownloadBar.setAttribute('aria-valuenow', 100);\n                summaryDownloadBar.textContent = \"\";\n                loadResolve();\n            }\n            break;\n        case 'chat':\n            //console.log(message.chat_text);\n            document.getElementById(\"chat_text\").innerHTML = message.chat_text\n            queryResolve(message.chat_text);\n            break;\n        case 'summary':\n            //console.log(message.summary_text);\n            document.getElementById(\"summary_text\").innerHTML = message.summary_text\n            queryResolve(message.summary_text);\n            break;\n        case 'query':\n            queryEmbedding = message.embedding;\n            queryResolve();\n            break;\n        case 'similarity':\n            resolve = similarityResolveMap[message.text];\n            resolve(calculateCosineSimilarity(message.embedding));\n            delete similarityResolveMap[message.text];\n            break;\n        case 'tokens':\n            resolve = tokensResolveMap[message.text];\n            resolve(message.tokens);\n            delete tokensResolveMap[message.text];\n            break;\n        case 'tsne':\n            console.log(message.plotDataArray)\n            ;(0,_utils_js__WEBPACK_IMPORTED_MODULE_1__.loadScatterplot)(message.plotDataArray);\n\n            break\n        default:\n            console.error('Unknown message type: ' + message.type);\n    }\n};\n\n/**\n * @param {string} text\n * @returns {Promise<number>}\n */\nasync function similarity(text) {\n    worker.postMessage({\n        type: 'similarity',\n        text\n    });\n    return new Promise((resolve) => {\n        // needs to return calculateCosineSimilarity(queryEmbedding, textEmbedding);\n        similarityResolveMap[text] = resolve;\n    });\n}\n\n/**\n *\n * @param {string} text\n * @returns\n */\nasync function summarizeText(text) {\n    worker.postMessage({\n        type: 'summary',\n        text\n    });\n    return new Promise((resolve) => {\n        queryResolve = resolve;\n    });\n}\n\n/**\n *\n * @param {string} text\n * @returns\n */\nasync function chatText(text, max_new_tokens) {\n    worker.postMessage({\n        type: 'chat',\n        max_new_tokens: max_new_tokens,\n        text\n    });\n    return new Promise((resolve) => {\n        queryResolve = resolve;\n    });\n}\n\n/**\n *\n * @param {string} text\n * @returns\n */\nasync function embedQuery(text) {\n    worker.postMessage({\n        type: 'query',\n        text\n    });\n    return new Promise((resolve) => {\n        queryResolve = resolve;\n    });\n}\n\n/**\n *\n * @param {string} text\n * @returns\n */\nasync function getTokens(text) {\n    worker.postMessage({\n        type: 'getTokens',\n        text\n    });\n    return new Promise((resolve) => {\n        tokensResolveMap[text] = resolve;\n    });\n}\n\n/**\n * @param {string} modelName\n * @returns\n */\nasync function loadSemantic(modelName) {\n    const quantized = document.getElementById(\"quantized\").checked;\n    const downloadBar = document.getElementById('loading-progress');\n    downloadBar.style.width = '0%';\n    downloadBar.textContent = 'Loading model...';\n    worker.postMessage({\n        type: 'load',\n        model_name: modelName,\n        quantized: quantized\n    });\n    return new Promise((resolve) => {\n        loadResolve = resolve;\n    });\n}\n\nasync function loadChat(modelName) {\n    //const quantized = document.getElementById(\"quantized\").checked;\n    let downloadBar = document.getElementById('chat-progress');\n    downloadBar.style.width = '0%';\n    downloadBar.textContent = 'Loading model...';\n\n    if (modelName.includes(\"Qwen\")) {\n        worker.postMessage({\n            type: 'load_text-generation',\n            model_name: modelName\n            //quantized: quantized\n        });\n     }\n\n    else {\n        worker.postMessage({\n            type: 'load_text2text-generation',\n            model_name: modelName\n            //quantized: quantized\n        });\n    }\n    return new Promise((resolve) => {\n        loadResolve = resolve;\n    });\n}\n\nasync function loadSummary(modelName) {\n    //const quantized = document.getElementById(\"quantized\").checked;\n    let downloadBar = document.getElementById('summary-progress');\n    downloadBar.style.width = '0%';\n    downloadBar.textContent = 'Loading model...';\n    worker.postMessage({\n        type: 'load_summary',\n        model_name: modelName\n        //quantized: quantized\n    });\n    return new Promise((resolve) => {\n        loadResolve = resolve;\n    });\n}\n\n/**\n * @typedef {Array<number>} EmbeddingVector\n * @param {EmbeddingVector} embedding\n * @returns {number}\n */\nfunction calculateCosineSimilarity(embedding) {\n    let dotProduct = 0;\n    let queryMagnitude = 0;\n    let embeddingMagnitude = 0;\n    const queryEmbeddingLength = queryEmbedding.length;\n    for (let i = 0; i < queryEmbeddingLength; i++) {\n        dotProduct += queryEmbedding[i] * embedding[i];\n        queryMagnitude += queryEmbedding[i] ** 2;\n        embeddingMagnitude += embedding[i] ** 2;\n    }\n    return dotProduct / (Math.sqrt(queryMagnitude) * Math.sqrt(embeddingMagnitude));\n}\n\n\n//# sourceURL=webpack://semanticfinder/./src/js/semantic.js?");

/***/ }),

/***/ "./src/js/utils.js":
/*!*************************!*\
  !*** ./src/js/utils.js ***!
  \*************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   heapBasedSorting: () => (/* binding */ heapBasedSorting),\n/* harmony export */   loadScatterplot: () => (/* binding */ loadScatterplot),\n/* harmony export */   removeScatterplot: () => (/* binding */ removeScatterplot),\n/* harmony export */   showToast: () => (/* binding */ showToast),\n/* harmony export */   splitText: () => (/* binding */ splitText)\n/* harmony export */ });\n/* harmony import */ var _semantic__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./semantic */ \"./src/js/semantic.js\");\n/* harmony import */ var _deck_gl_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @deck.gl/core */ \"./node_modules/@deck.gl/core/dist/esm/lib/deck.js\");\n/* harmony import */ var _deck_gl_layers__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @deck.gl/layers */ \"./node_modules/@deck.gl/layers/dist/esm/scatterplot-layer/scatterplot-layer.js\");\n\n\n\n//import {ScatterplotLayer} from '@deck.gl/layers';\n/**\n * @param {string} text\n * @param {string} splitType\n * @param {string} splitParam\n * @returns {Promise<Array<string> | null>}\n */\nasync function splitText(text, splitType, splitParam) {\n    switch (splitType) {\n        case 'Regex':\n            return splitByRegex(text, splitParam);\n        case 'Sentence':\n            return splitBySentences(text);\n        case 'Words':\n            return splitByWords(text, parseInt(splitParam));\n        case 'Chars':\n            return splitByChars(text, parseInt(splitParam));\n        case 'Tokens':\n            return await splitByTokens(text, parseInt(splitParam));\n        default:\n            console.error('Invalid split type');\n            return null;\n    }\n}\n\n/**\n * @param {string} text\n * @param {number} numTokens\n * @returns {Promise<Array<string> | null>}\n */\nasync function splitByTokens(text, numTokens) {\n    const words = text.split(' ');\n    const chunks = [];\n\n    for (let i = 0; i < words.length; i++) {\n        const word = words[i];\n        const tokens = await (0,_semantic__WEBPACK_IMPORTED_MODULE_0__.getTokens)(word);\n\n        // Check if there's no chunk or if the last chunk + the new word would exceed numTokens\n        if (chunks.length === 0 || (await (0,_semantic__WEBPACK_IMPORTED_MODULE_0__.getTokens)(chunks[chunks.length - 1])).length + tokens.length > numTokens) {\n            chunks.push(word);\n        } else {\n            chunks[chunks.length - 1] += ' ' + word;\n        }\n    }\n    //console.table(chunks);\n    console.log(\"Number of chunks: \" + chunks.length)\n    return chunks;\n}\n\n/**\n * @param {string} text\n * @param {number} numWords\n * @returns {Array<string> | null}\n */\nfunction splitByWords(text, numWords) {\n    if (isNaN(numWords) || !Number.isInteger(numWords)) {\n        console.error('numWords must be an integer.');\n        return null;\n    }\n\n    const words = text.split(' ');\n    let chunks = [];\n    let currentChunk = [];\n\n    for (let i = 0; i < words.length; i++) {\n        currentChunk.push(words[i]);\n\n        if (currentChunk.length === numWords) {\n            chunks.push(currentChunk.join(' '));\n            currentChunk = [];\n        }\n    }\n\n    if (currentChunk.length > 0) {\n        chunks.push(currentChunk.join(' '));\n    }\n    chunks = chunks.filter(chunk => chunk.trim().length > 0);\n\n    //console.table(chunks);\n    console.log(\"Number of chunks: \" + chunks.length)\n\n    return chunks;\n}\n\n/**\n * @param {string} text\n * @param {number} numChars\n * @returns {Array<string> | null}\n */\nfunction splitByChars(text, numChars) {\n    const words = text.split(' ');\n    const chunks = [];\n\n    for (let i = 0; i < words.length; i++) {\n        const word = words[i];\n\n        if (chunks.length === 0 || chunks[chunks.length - 1].length + word.length + 1 > numChars) {\n            chunks.push(word);\n        } else {\n            chunks[chunks.length - 1] += ' ' + word;\n        }\n    }\n    // console.table(chunks);\n    console.log(\"Number of chunks: \" + chunks.length)\n    return chunks;\n}\n\n/**\n * @param {string} text\n * @returns {Array<string> | null}\n */\nfunction splitBySentences(text) {\n    const chunks = text.match(/[^.!?]+[.!?]+/g);\n    console.log(\"Number of chunks: \" + chunks.length)\n\n    return chunks\n}\n\n/**\n * @param {string} text\n * @param {string} r\n * @returns {Array<string> | null}\n */\nfunction splitByRegex(text, r) {\n    const regex = new RegExp(r, 'g');\n    const chunks = text.split(regex);\n\n    console.log(\"Number of chunks: \" + chunks.length)\n\n    return chunks\n}\n\n// Sorting algorithms: heap-based sorting is quite superior for 1000+ and usually less than half of the time of normal sorting\n// might be interesting to use it once indices become larger than 100k but for now not a bottleneck\n\n// Original code\nfunction normalSorting(inputTexts) {\n    const startTime = performance.now();\n    const sortedResults = Object.entries(inputTexts).sort((a, b) => b[1] - a[1]);\n    const endTime = performance.now();\n    console.log(`Original code took ${endTime - startTime} milliseconds`);\n    // updateResults(sortedResults); // Commented out, replace with your actual implementation\n}\n\n// MaxHeap class\nclass MaxHeap {\n    constructor(array) {\n        this.heap = [...array];\n        this.buildHeap();\n    }\n\n    buildHeap() {\n        const n = this.heap.length;\n        for (let i = Math.floor(n / 2) - 1; i >= 0; i--) {\n            this.heapifyDown(i);\n        }\n    }\n\n    heapifyDown(i) {\n        const left = 2 * i + 1;\n        const right = 2 * i + 2;\n        let largest = i;\n\n        if (left < this.heap.length && this.heap[left][1] > this.heap[largest][1]) {\n            largest = left;\n        }\n\n        if (right < this.heap.length && this.heap[right][1] > this.heap[largest][1]) {\n            largest = right;\n        }\n\n        if (largest !== i) {\n            this.swap(i, largest);\n            this.heapifyDown(largest);\n        }\n    }\n\n    extractMax() {\n        if (this.heap.length === 0) {\n            return null;\n        }\n\n        const max = this.heap[0];\n        const last = this.heap.pop();\n\n        if (this.heap.length > 0) {\n            this.heap[0] = last;\n            this.heapifyDown(0);\n        }\n\n        return max;\n    }\n\n    swap(i, j) {\n        [this.heap[i], this.heap[j]] = [this.heap[j], this.heap[i]];\n    }\n}\n\n// Heap-based solution\nfunction heapBasedSorting(inputTexts, n) {\n    //const startTime = performance.now();\n\n    const entries = Object.entries(inputTexts);\n    const maxHeap = new MaxHeap(entries);\n\n    const nLargest = [];\n    for (let i = 0; i < n && i < entries.length; i++) {\n        const maxEntry = maxHeap.extractMax();\n        nLargest.push(maxEntry);\n    }\n    return nLargest\n\n    //const endTime = performance.now();\n    //console.log(`Heap-based solution took ${endTime - startTime} milliseconds`);\n    // updateResults(nLargest); // Commented out, replace with your actual implementation\n}\n\n/*\n// Test objects\nfunction generateTestObject(size) {\n    const testObject = {};\n    for (let i = 0; i < size; i++) {\n        testObject[`key${i}`] = Math.random();\n    }\n    return testObject;\n}\n\n//const obj100 = generateTestObject(100);\n//const obj10000 = generateTestObject(10000);\n//const obj100000 = generateTestObject(100000);\n\n// Usage\n//const n = 5; // Change this to the desired number of largest values\n\n//normalSorting(obj100);\n//heapBasedSorting(obj100, n);\n\n//normalSorting(obj10000);\n//heapBasedSorting(obj10000, n);\n\n//normalSorting(obj100000);\n//heapBasedSorting(obj100000, n);\n\nOriginal code took 0.19999999925494194 milliseconds\nHeap-based solution took 0.10000000149011612 milliseconds\n\nOriginal code took 19.5 milliseconds\nHeap-based solution took 9.299999997019768 milliseconds\n\nOriginal code took 166.69999999925494 milliseconds\nHeap-based solution took 60.5 milliseconds\n\n*/\n\nconst toastMessage = document.getElementById(\"toastMessage\");\nconst toastText = document.getElementById(\"toastText\");\nconst closeToastButton = document.getElementById(\"closeToastButton\");\n\nfunction showToast(message) {\n    toastText.textContent = message;\n    toastMessage.style.display = \"block\";\n\n    setTimeout(() => {\n        hideToast();\n    }, 2500);\n}\n\nfunction hideToast() {\n    toastMessage.style.display = \"none\";\n}\n\ncloseToastButton.addEventListener(\"click\", () => {\n    hideToast();\n});\n\nfunction generateGridData(gridSize = 20) {\n    const gridData = [];\n\n    // Create vertical lines\n    for (let i = -gridSize; i <= gridSize; i++) {\n        gridData.push({\n            sourcePosition: [i, -gridSize],\n            targetPosition: [i, gridSize],\n            color: [169, 169, 169],\n        });\n    }\n\n    // Create horizontal lines\n    for (let j = -gridSize; j <= gridSize; j++) {\n        gridData.push({\n            sourcePosition: [-gridSize, j],\n            targetPosition: [gridSize, j],\n            color: [169, 169, 169],\n        });\n    }\n\n    return gridData;\n}\n\nconst plotContainer = document.getElementById(\"plot-container\");\nlet deckgl;\nasync function loadScatterplot(data) {\n\n    removeScatterplot();\n    // Find the minimum and maximum similarity values, x values, and y values in the data array\n    const minSimilarity = Math.min(...data.map(item => item.similarity));\n    const maxSimilarity = Math.max(...data.map(item => item.similarity));\n\n    const minX = Math.min(...data.map(item => item.x));\n    const maxX = Math.max(...data.map(item => item.x));\n\n    const minY = Math.min(...data.map(item => item.y));\n    const maxY = Math.max(...data.map(item => item.y));\n\n    data = data.map(item => {\n        // Normalize similarity values to the range [0, 1]\n        const normalizedSimilarity = (item.similarity - minSimilarity) / (maxSimilarity - minSimilarity);\n\n        // Normalize x and y coordinates to the range [0, 1]\n        const normalizedX = (item.x - minX) / (maxX - minX);\n        const normalizedY = (item.y - minY) / (maxY - minY);\n\n        // Use the normalized similarity value as alpha (opacity)\n        const alpha = Math.min(1, Math.max(0, normalizedSimilarity));\n\n        // Map the alpha value to the entire opacity spectrum\n        const color = [0, 0, 255, Math.floor(alpha * 255)]; // RGBA format with alpha value\n\n        return {\n            coordinates: [normalizedX, normalizedY],\n            color: color,\n            similarity: item.similarity,\n            label: item.label,\n        };\n    });\n\n    // Calculate the bounding box of the data\n    const bounds = data.reduce(\n        (acc, point) => ({\n            minX: Math.min(acc.minX, point.coordinates[0]),\n            minY: Math.min(acc.minY, point.coordinates[1]),\n            maxX: Math.max(acc.maxX, point.coordinates[0]),\n            maxY: Math.max(acc.maxY, point.coordinates[1]),\n        }),\n        { minX: Infinity, minY: Infinity, maxX: -Infinity, maxY: -Infinity }\n    );\n\n    deckgl = new _deck_gl_core__WEBPACK_IMPORTED_MODULE_1__[\"default\"]({\n        canvas: 'deckgl',\n        container: 'plot-container',\n        initialViewState: {\n            latitude: (bounds.minY + bounds.maxY) / 2,\n            longitude: (bounds.minX + bounds.maxX) / 2,\n            zoom: 9\n        },\n        controller: true,\n        pickingRadius: 25,\n        layers: [\n            // Add a new LineLayer for the coordinate system\n            /*new LineLayer({\n                id: 'coordinate-system',\n                data: generateGridData(20),\n                getSourcePosition: d => d.sourcePosition,\n                getTargetPosition: d => d.targetPosition,\n                getColor: d => d.color,\n                getWidth: 1,\n                pickable: false\n            }),\n            */\n            // ScatterplotLayer with all points added right away\n            new _deck_gl_layers__WEBPACK_IMPORTED_MODULE_2__[\"default\"]({\n                id: 'scatterplot',\n                data: data,\n                getPosition: d => d.coordinates,\n                getRadius: parseInt(document.getElementById(\"scatterplotRadius\").value), // Adjust the radius to fit the new range\n                getFillColor: d => d.color,\n                pickable: true, // Enable picking for on-hover interaction\n                onHover: info => {\n                    const tooltip = document.getElementById('tooltip');\n\n                    if (info.object) {\n                        const canvas = document.getElementById('deckgl');\n                        const rect = canvas.getBoundingClientRect();\n\n                        // Calculate the correct position by subtracting the canvas offset and adding the scroll position\n                        const left = window.scrollX + info.x + rect.left + 30;\n                        const top = window.scrollY + info.y + rect.top + -50;\n\n                        tooltip.innerHTML = `${info.object.label} <br>Similarity: ${info.object.similarity.toFixed(2)}`;\n                        tooltip.style.left = `${left}px`;\n                        tooltip.style.top = `${top}px`;\n                        tooltip.style.display = 'block';\n                    } else {\n                        tooltip.style.display = 'none';\n                    }\n                },\n                onClick: info => {\n                    const tooltip = document.getElementById('tooltip');\n            \n                    if (info.object) {\n                        const canvas = document.getElementById('deckgl');\n                        const rect = canvas.getBoundingClientRect();\n            \n                        // Calculate the correct position by subtracting the canvas offset and adding the scroll position\n                        const left = window.scrollX + info.x + rect.left + 30;\n                        const top = window.scrollY + info.y + rect.top + -50;\n            \n                        tooltip.innerHTML = `${info.object.label} <br>Similarity: ${info.object.similarity.toFixed(2)}`;\n                        tooltip.style.left = `${left}px`;\n                        tooltip.style.top = `${top}px`;\n                        tooltip.style.display = 'block';\n                    } else {\n                        tooltip.style.display = 'none';\n                    }\n                }\n\n            })\n        ]\n    });\n\n    plotContainer.style.height = \"700px\";\n}\n\nfunction removeScatterplot() {\n    if (deckgl) {\n        deckgl.finalize();\n        deckgl = null;\n    }\n}\n\n\n//# sourceURL=webpack://semanticfinder/./src/js/utils.js?");

/***/ }),

/***/ "./src/js/SemanticFinder.svg":
/*!***********************************!*\
  !*** ./src/js/SemanticFinder.svg ***!
  \***********************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("module.exports = __webpack_require__.p + \"SemanticFinder.svg\";\n\n//# sourceURL=webpack://semanticfinder/./src/js/SemanticFinder.svg?");

/***/ }),

/***/ "?2ca1":
/*!**********************************!*\
  !*** onnxruntime-node (ignored) ***!
  \**********************************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://semanticfinder/onnxruntime-node_(ignored)?");

/***/ }),

/***/ "?0a40":
/*!********************!*\
  !*** fs (ignored) ***!
  \********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://semanticfinder/fs_(ignored)?");

/***/ }),

/***/ "?61c2":
/*!**********************!*\
  !*** path (ignored) ***!
  \**********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://semanticfinder/path_(ignored)?");

/***/ }),

/***/ "?0740":
/*!***********************!*\
  !*** sharp (ignored) ***!
  \***********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://semanticfinder/sharp_(ignored)?");

/***/ }),

/***/ "?66bb":
/*!****************************!*\
  !*** stream/web (ignored) ***!
  \****************************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://semanticfinder/stream/web_(ignored)?");

/***/ }),

/***/ "?0a9a":
/*!********************!*\
  !*** fs (ignored) ***!
  \********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://semanticfinder/fs_(ignored)?");

/***/ }),

/***/ "?73ea":
/*!**********************!*\
  !*** path (ignored) ***!
  \**********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://semanticfinder/path_(ignored)?");

/***/ }),

/***/ "?845f":
/*!*********************!*\
  !*** url (ignored) ***!
  \*********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://semanticfinder/url_(ignored)?");

/***/ }),

/***/ "./node_modules/@babel/runtime/helpers/esm/defineProperty.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@babel/runtime/helpers/esm/defineProperty.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ _defineProperty)\n/* harmony export */ });\n/* harmony import */ var _toPropertyKey_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./toPropertyKey.js */ \"./node_modules/@babel/runtime/helpers/esm/toPropertyKey.js\");\n\nfunction _defineProperty(obj, key, value) {\n  key = (0,_toPropertyKey_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(key);\n  if (key in obj) {\n    Object.defineProperty(obj, key, {\n      value: value,\n      enumerable: true,\n      configurable: true,\n      writable: true\n    });\n  } else {\n    obj[key] = value;\n  }\n  return obj;\n}\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@babel/runtime/helpers/esm/defineProperty.js?");

/***/ }),

/***/ "./node_modules/@babel/runtime/helpers/esm/toPrimitive.js":
/*!****************************************************************!*\
  !*** ./node_modules/@babel/runtime/helpers/esm/toPrimitive.js ***!
  \****************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ toPrimitive)\n/* harmony export */ });\n/* harmony import */ var _typeof_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./typeof.js */ \"./node_modules/@babel/runtime/helpers/esm/typeof.js\");\n\nfunction toPrimitive(t, r) {\n  if (\"object\" != (0,_typeof_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(t) || !t) return t;\n  var e = t[Symbol.toPrimitive];\n  if (void 0 !== e) {\n    var i = e.call(t, r || \"default\");\n    if (\"object\" != (0,_typeof_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(i)) return i;\n    throw new TypeError(\"@@toPrimitive must return a primitive value.\");\n  }\n  return (\"string\" === r ? String : Number)(t);\n}\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@babel/runtime/helpers/esm/toPrimitive.js?");

/***/ }),

/***/ "./node_modules/@babel/runtime/helpers/esm/toPropertyKey.js":
/*!******************************************************************!*\
  !*** ./node_modules/@babel/runtime/helpers/esm/toPropertyKey.js ***!
  \******************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ toPropertyKey)\n/* harmony export */ });\n/* harmony import */ var _typeof_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./typeof.js */ \"./node_modules/@babel/runtime/helpers/esm/typeof.js\");\n/* harmony import */ var _toPrimitive_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./toPrimitive.js */ \"./node_modules/@babel/runtime/helpers/esm/toPrimitive.js\");\n\n\nfunction toPropertyKey(t) {\n  var i = (0,_toPrimitive_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(t, \"string\");\n  return \"symbol\" == (0,_typeof_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(i) ? i : String(i);\n}\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@babel/runtime/helpers/esm/toPropertyKey.js?");

/***/ }),

/***/ "./node_modules/@babel/runtime/helpers/esm/typeof.js":
/*!***********************************************************!*\
  !*** ./node_modules/@babel/runtime/helpers/esm/typeof.js ***!
  \***********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ _typeof)\n/* harmony export */ });\nfunction _typeof(o) {\n  \"@babel/helpers - typeof\";\n\n  return _typeof = \"function\" == typeof Symbol && \"symbol\" == typeof Symbol.iterator ? function (o) {\n    return typeof o;\n  } : function (o) {\n    return o && \"function\" == typeof Symbol && o.constructor === Symbol && o !== Symbol.prototype ? \"symbol\" : typeof o;\n  }, _typeof(o);\n}\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@babel/runtime/helpers/esm/typeof.js?");

/***/ }),

/***/ "./node_modules/@huggingface/jinja/dist/index.js":
/*!*******************************************************!*\
  !*** ./node_modules/@huggingface/jinja/dist/index.js ***!
  \*******************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Environment: () => (/* binding */ Environment),\n/* harmony export */   Interpreter: () => (/* binding */ Interpreter),\n/* harmony export */   Template: () => (/* binding */ Template),\n/* harmony export */   parse: () => (/* binding */ parse),\n/* harmony export */   tokenize: () => (/* binding */ tokenize)\n/* harmony export */ });\n// src/lexer.ts\nvar TOKEN_TYPES = Object.freeze({\n  Text: \"Text\",\n  // The text between Jinja statements or expressions\n  NumericLiteral: \"NumericLiteral\",\n  // e.g., 123\n  BooleanLiteral: \"BooleanLiteral\",\n  // true or false\n  StringLiteral: \"StringLiteral\",\n  // 'string'\n  Identifier: \"Identifier\",\n  // Variables, functions, etc.\n  Equals: \"Equals\",\n  // =\n  OpenParen: \"OpenParen\",\n  // (\n  CloseParen: \"CloseParen\",\n  // )\n  OpenStatement: \"OpenStatement\",\n  // {%\n  CloseStatement: \"CloseStatement\",\n  // %}\n  OpenExpression: \"OpenExpression\",\n  // {{\n  CloseExpression: \"CloseExpression\",\n  // }}\n  OpenSquareBracket: \"OpenSquareBracket\",\n  // [\n  CloseSquareBracket: \"CloseSquareBracket\",\n  // ]\n  Comma: \"Comma\",\n  // ,\n  Dot: \"Dot\",\n  // .\n  Colon: \"Colon\",\n  // :\n  Pipe: \"Pipe\",\n  // |\n  CallOperator: \"CallOperator\",\n  // ()\n  AdditiveBinaryOperator: \"AdditiveBinaryOperator\",\n  // + -\n  MultiplicativeBinaryOperator: \"MultiplicativeBinaryOperator\",\n  // * / %\n  ComparisonBinaryOperator: \"ComparisonBinaryOperator\",\n  // < > <= >= == !=\n  UnaryOperator: \"UnaryOperator\",\n  // ! - +\n  // Keywords\n  Set: \"Set\",\n  If: \"If\",\n  For: \"For\",\n  In: \"In\",\n  NotIn: \"NotIn\",\n  Else: \"Else\",\n  EndIf: \"EndIf\",\n  ElseIf: \"ElseIf\",\n  EndFor: \"EndFor\",\n  And: \"And\",\n  Or: \"Or\",\n  Not: \"UnaryOperator\"\n});\nvar KEYWORDS = Object.freeze({\n  set: TOKEN_TYPES.Set,\n  for: TOKEN_TYPES.For,\n  in: TOKEN_TYPES.In,\n  if: TOKEN_TYPES.If,\n  else: TOKEN_TYPES.Else,\n  endif: TOKEN_TYPES.EndIf,\n  elif: TOKEN_TYPES.ElseIf,\n  endfor: TOKEN_TYPES.EndFor,\n  and: TOKEN_TYPES.And,\n  or: TOKEN_TYPES.Or,\n  not: TOKEN_TYPES.Not,\n  \"not in\": TOKEN_TYPES.NotIn,\n  // Literals\n  true: TOKEN_TYPES.BooleanLiteral,\n  false: TOKEN_TYPES.BooleanLiteral\n});\nvar Token = class {\n  /**\n   * Constructs a new Token.\n   * @param {string} value The raw value as seen inside the source code.\n   * @param {TokenType} type The type of token.\n   */\n  constructor(value, type) {\n    this.value = value;\n    this.type = type;\n  }\n};\nfunction isWord(char) {\n  return /\\w/.test(char);\n}\nfunction isInteger(char) {\n  return /[0-9]/.test(char);\n}\nvar ORDERED_MAPPING_TABLE = [\n  // Control sequences\n  [\"{%\", TOKEN_TYPES.OpenStatement],\n  [\"%}\", TOKEN_TYPES.CloseStatement],\n  [\"{{\", TOKEN_TYPES.OpenExpression],\n  [\"}}\", TOKEN_TYPES.CloseExpression],\n  // Single character tokens\n  [\"(\", TOKEN_TYPES.OpenParen],\n  [\")\", TOKEN_TYPES.CloseParen],\n  [\"[\", TOKEN_TYPES.OpenSquareBracket],\n  [\"]\", TOKEN_TYPES.CloseSquareBracket],\n  [\",\", TOKEN_TYPES.Comma],\n  [\".\", TOKEN_TYPES.Dot],\n  [\":\", TOKEN_TYPES.Colon],\n  [\"|\", TOKEN_TYPES.Pipe],\n  // Comparison operators\n  [\"<=\", TOKEN_TYPES.ComparisonBinaryOperator],\n  [\">=\", TOKEN_TYPES.ComparisonBinaryOperator],\n  [\"==\", TOKEN_TYPES.ComparisonBinaryOperator],\n  [\"!=\", TOKEN_TYPES.ComparisonBinaryOperator],\n  [\"<\", TOKEN_TYPES.ComparisonBinaryOperator],\n  [\">\", TOKEN_TYPES.ComparisonBinaryOperator],\n  // Arithmetic operators\n  [\"+\", TOKEN_TYPES.AdditiveBinaryOperator],\n  [\"-\", TOKEN_TYPES.AdditiveBinaryOperator],\n  [\"*\", TOKEN_TYPES.MultiplicativeBinaryOperator],\n  [\"/\", TOKEN_TYPES.MultiplicativeBinaryOperator],\n  [\"%\", TOKEN_TYPES.MultiplicativeBinaryOperator],\n  // Assignment operator\n  [\"=\", TOKEN_TYPES.Equals]\n];\nvar ESCAPE_CHARACTERS = /* @__PURE__ */ new Map([\n  [\"n\", \"\\n\"],\n  // New line\n  [\"t\", \"\t\"],\n  // Horizontal tab\n  [\"r\", \"\\r\"],\n  // Carriage return\n  [\"b\", \"\\b\"],\n  // Backspace\n  [\"f\", \"\\f\"],\n  // Form feed\n  [\"v\", \"\\v\"],\n  // Vertical tab\n  [\"'\", \"'\"],\n  // Single quote\n  ['\"', '\"'],\n  // Double quote\n  [\"\\\\\", \"\\\\\"]\n  // Backslash\n]);\nfunction tokenize(source) {\n  const tokens = [];\n  const src = source;\n  let cursorPosition = 0;\n  const consumeWhile = (predicate) => {\n    let str = \"\";\n    while (predicate(src[cursorPosition])) {\n      if (src[cursorPosition] === \"\\\\\") {\n        ++cursorPosition;\n        if (cursorPosition >= src.length)\n          throw new SyntaxError(\"Unexpected end of input\");\n        const escaped = src[cursorPosition++];\n        const unescaped = ESCAPE_CHARACTERS.get(escaped);\n        if (unescaped === void 0) {\n          throw new SyntaxError(`Unexpected escaped character: ${escaped}`);\n        }\n        str += unescaped;\n        continue;\n      }\n      str += src[cursorPosition++];\n      if (cursorPosition >= src.length)\n        throw new SyntaxError(\"Unexpected end of input\");\n    }\n    return str;\n  };\n  main:\n    while (cursorPosition < src.length) {\n      const lastTokenType = tokens.at(-1)?.type;\n      if (lastTokenType === void 0 || lastTokenType === TOKEN_TYPES.CloseStatement || lastTokenType === TOKEN_TYPES.CloseExpression) {\n        let text = \"\";\n        while (cursorPosition < src.length && // Keep going until we hit the next Jinja statement or expression\n        !(src[cursorPosition] === \"{\" && (src[cursorPosition + 1] === \"%\" || src[cursorPosition + 1] === \"{\"))) {\n          text += src[cursorPosition++];\n        }\n        if (text.length > 0) {\n          tokens.push(new Token(text, TOKEN_TYPES.Text));\n          continue;\n        }\n      }\n      consumeWhile((char2) => /\\s/.test(char2));\n      const char = src[cursorPosition];\n      if (char === \"-\" || char === \"+\") {\n        const lastTokenType2 = tokens.at(-1)?.type;\n        if (lastTokenType2 === TOKEN_TYPES.Text || lastTokenType2 === void 0) {\n          throw new SyntaxError(`Unexpected character: ${char}`);\n        }\n        switch (lastTokenType2) {\n          case TOKEN_TYPES.Identifier:\n          case TOKEN_TYPES.NumericLiteral:\n          case TOKEN_TYPES.BooleanLiteral:\n          case TOKEN_TYPES.StringLiteral:\n          case TOKEN_TYPES.CloseParen:\n          case TOKEN_TYPES.CloseSquareBracket:\n            break;\n          default: {\n            ++cursorPosition;\n            const num = consumeWhile(isInteger);\n            tokens.push(\n              new Token(`${char}${num}`, num.length > 0 ? TOKEN_TYPES.NumericLiteral : TOKEN_TYPES.UnaryOperator)\n            );\n            continue;\n          }\n        }\n      }\n      for (const [char2, token] of ORDERED_MAPPING_TABLE) {\n        const slice2 = src.slice(cursorPosition, cursorPosition + char2.length);\n        if (slice2 === char2) {\n          tokens.push(new Token(char2, token));\n          cursorPosition += char2.length;\n          continue main;\n        }\n      }\n      if (char === \"'\") {\n        ++cursorPosition;\n        const str = consumeWhile((char2) => char2 !== \"'\");\n        tokens.push(new Token(str, TOKEN_TYPES.StringLiteral));\n        ++cursorPosition;\n        continue;\n      }\n      if (isInteger(char)) {\n        const num = consumeWhile(isInteger);\n        tokens.push(new Token(num, TOKEN_TYPES.NumericLiteral));\n        continue;\n      }\n      if (isWord(char)) {\n        const word = consumeWhile(isWord);\n        const type = Object.hasOwn(KEYWORDS, word) ? KEYWORDS[word] : TOKEN_TYPES.Identifier;\n        if (type === TOKEN_TYPES.In && tokens.at(-1)?.type === TOKEN_TYPES.Not) {\n          tokens.pop();\n          tokens.push(new Token(\"not in\", TOKEN_TYPES.NotIn));\n        } else {\n          tokens.push(new Token(word, type));\n        }\n        continue;\n      }\n      throw new SyntaxError(`Unexpected character: ${char}`);\n    }\n  return tokens;\n}\n\n// src/ast.ts\nvar Statement = class {\n  type = \"Statement\";\n};\nvar Program = class extends Statement {\n  constructor(body) {\n    super();\n    this.body = body;\n  }\n  type = \"Program\";\n};\nvar If = class extends Statement {\n  constructor(test, body, alternate) {\n    super();\n    this.test = test;\n    this.body = body;\n    this.alternate = alternate;\n  }\n  type = \"If\";\n};\nvar For = class extends Statement {\n  constructor(loopvar, iterable, body) {\n    super();\n    this.loopvar = loopvar;\n    this.iterable = iterable;\n    this.body = body;\n  }\n  type = \"For\";\n};\nvar SetStatement = class extends Statement {\n  constructor(assignee, value) {\n    super();\n    this.assignee = assignee;\n    this.value = value;\n  }\n  type = \"Set\";\n};\nvar Expression = class extends Statement {\n  type = \"Expression\";\n};\nvar MemberExpression = class extends Expression {\n  constructor(object, property, computed) {\n    super();\n    this.object = object;\n    this.property = property;\n    this.computed = computed;\n  }\n  type = \"MemberExpression\";\n};\nvar CallExpression = class extends Expression {\n  constructor(callee, args) {\n    super();\n    this.callee = callee;\n    this.args = args;\n  }\n  type = \"CallExpression\";\n};\nvar Identifier = class extends Expression {\n  /**\n   * @param {string} value The name of the identifier\n   */\n  constructor(value) {\n    super();\n    this.value = value;\n  }\n  type = \"Identifier\";\n};\nvar Literal = class extends Expression {\n  constructor(value) {\n    super();\n    this.value = value;\n  }\n  type = \"Literal\";\n};\nvar NumericLiteral = class extends Literal {\n  type = \"NumericLiteral\";\n};\nvar StringLiteral = class extends Literal {\n  type = \"StringLiteral\";\n  constructor(value) {\n    super(value);\n  }\n};\nvar BooleanLiteral = class extends Literal {\n  type = \"BooleanLiteral\";\n};\nvar BinaryExpression = class extends Expression {\n  constructor(operator, left, right) {\n    super();\n    this.operator = operator;\n    this.left = left;\n    this.right = right;\n  }\n  type = \"BinaryExpression\";\n};\nvar FilterExpression = class extends Expression {\n  constructor(operand, filter) {\n    super();\n    this.operand = operand;\n    this.filter = filter;\n  }\n  type = \"FilterExpression\";\n};\nvar UnaryExpression = class extends Expression {\n  constructor(operator, argument) {\n    super();\n    this.operator = operator;\n    this.argument = argument;\n  }\n  type = \"UnaryExpression\";\n};\nvar SliceExpression = class extends Expression {\n  constructor(start = void 0, stop = void 0, step = void 0) {\n    super();\n    this.start = start;\n    this.stop = stop;\n    this.step = step;\n  }\n  type = \"SliceExpression\";\n};\n\n// src/parser.ts\nfunction parse(tokens) {\n  const program = new Program([]);\n  let current = 0;\n  function expect(type, error) {\n    const prev = tokens[current++];\n    if (!prev || prev.type !== type) {\n      throw new Error(`Parser Error: ${error}. ${prev.type} !== ${type}.`);\n    }\n    return prev;\n  }\n  function parseAny() {\n    switch (tokens[current].type) {\n      case TOKEN_TYPES.Text:\n        return parseText();\n      case TOKEN_TYPES.OpenStatement:\n        return parseJinjaStatement();\n      case TOKEN_TYPES.OpenExpression:\n        return parseJinjaExpression();\n      default:\n        throw new SyntaxError(`Unexpected token type: ${tokens[current].type}`);\n    }\n  }\n  function not(...types) {\n    return current + types.length <= tokens.length && types.some((type, i) => type !== tokens[current + i].type);\n  }\n  function is(...types) {\n    return current + types.length <= tokens.length && types.every((type, i) => type === tokens[current + i].type);\n  }\n  function parseText() {\n    return new StringLiteral(expect(TOKEN_TYPES.Text, \"Expected text token\").value);\n  }\n  function parseJinjaStatement() {\n    expect(TOKEN_TYPES.OpenStatement, \"Expected opening statement token\");\n    let result;\n    switch (tokens[current].type) {\n      case TOKEN_TYPES.Set:\n        ++current;\n        result = parseSetStatement();\n        expect(TOKEN_TYPES.CloseStatement, \"Expected closing statement token\");\n        break;\n      case TOKEN_TYPES.If:\n        ++current;\n        result = parseIfStatement();\n        expect(TOKEN_TYPES.OpenStatement, \"Expected {% token\");\n        expect(TOKEN_TYPES.EndIf, \"Expected endif token\");\n        expect(TOKEN_TYPES.CloseStatement, \"Expected %} token\");\n        break;\n      case TOKEN_TYPES.For:\n        ++current;\n        result = parseForStatement();\n        expect(TOKEN_TYPES.OpenStatement, \"Expected {% token\");\n        expect(TOKEN_TYPES.EndFor, \"Expected endfor token\");\n        expect(TOKEN_TYPES.CloseStatement, \"Expected %} token\");\n        break;\n      default:\n        throw new SyntaxError(`Unknown statement type: ${tokens[current].type}`);\n    }\n    return result;\n  }\n  function parseJinjaExpression() {\n    expect(TOKEN_TYPES.OpenExpression, \"Expected opening expression token\");\n    const result = parseExpression();\n    expect(TOKEN_TYPES.CloseExpression, \"Expected closing expression token\");\n    return result;\n  }\n  function parseSetStatement() {\n    const left = parseExpression();\n    if (is(TOKEN_TYPES.Equals)) {\n      ++current;\n      const value = parseSetStatement();\n      return new SetStatement(left, value);\n    }\n    return left;\n  }\n  function parseIfStatement() {\n    const test = parseExpression();\n    expect(TOKEN_TYPES.CloseStatement, \"Expected closing statement token\");\n    const body = [];\n    const alternate = [];\n    while (!(tokens[current]?.type === TOKEN_TYPES.OpenStatement && (tokens[current + 1]?.type === TOKEN_TYPES.ElseIf || tokens[current + 1]?.type === TOKEN_TYPES.Else || tokens[current + 1]?.type === TOKEN_TYPES.EndIf))) {\n      body.push(parseAny());\n    }\n    if (tokens[current]?.type === TOKEN_TYPES.OpenStatement && tokens[current + 1]?.type !== TOKEN_TYPES.EndIf) {\n      ++current;\n      if (is(TOKEN_TYPES.ElseIf)) {\n        expect(TOKEN_TYPES.ElseIf, \"Expected elseif token\");\n        alternate.push(parseIfStatement());\n      } else {\n        expect(TOKEN_TYPES.Else, \"Expected else token\");\n        expect(TOKEN_TYPES.CloseStatement, \"Expected closing statement token\");\n        while (!(tokens[current]?.type === TOKEN_TYPES.OpenStatement && tokens[current + 1]?.type === TOKEN_TYPES.EndIf)) {\n          alternate.push(parseAny());\n        }\n      }\n    }\n    return new If(test, body, alternate);\n  }\n  function parseForStatement() {\n    const loopVariable = parsePrimaryExpression();\n    if (!(loopVariable instanceof Identifier)) {\n      throw new SyntaxError(`Expected identifier for the loop variable`);\n    }\n    expect(TOKEN_TYPES.In, \"Expected `in` keyword following loop variable\");\n    const iterable = parseExpression();\n    expect(TOKEN_TYPES.CloseStatement, \"Expected closing statement token\");\n    const body = [];\n    while (not(TOKEN_TYPES.OpenStatement, TOKEN_TYPES.EndFor)) {\n      body.push(parseAny());\n    }\n    return new For(loopVariable, iterable, body);\n  }\n  function parseExpression() {\n    return parseLogicalOrExpression();\n  }\n  function parseLogicalOrExpression() {\n    let left = parseLogicalAndExpression();\n    while (is(TOKEN_TYPES.Or)) {\n      const operator = tokens[current];\n      ++current;\n      const right = parseLogicalAndExpression();\n      left = new BinaryExpression(operator, left, right);\n    }\n    return left;\n  }\n  function parseLogicalAndExpression() {\n    let left = parseLogicalNegationExpression();\n    while (is(TOKEN_TYPES.And)) {\n      const operator = tokens[current];\n      ++current;\n      const right = parseLogicalNegationExpression();\n      left = new BinaryExpression(operator, left, right);\n    }\n    return left;\n  }\n  function parseLogicalNegationExpression() {\n    let right;\n    while (is(TOKEN_TYPES.Not)) {\n      const operator = tokens[current];\n      ++current;\n      const arg = parseLogicalNegationExpression();\n      right = new UnaryExpression(operator, arg);\n    }\n    return right ?? parseComparisonExpression();\n  }\n  function parseComparisonExpression() {\n    let left = parseAdditiveExpression();\n    while (is(TOKEN_TYPES.ComparisonBinaryOperator) || is(TOKEN_TYPES.In) || is(TOKEN_TYPES.NotIn)) {\n      const operator = tokens[current];\n      ++current;\n      const right = parseAdditiveExpression();\n      left = new BinaryExpression(operator, left, right);\n    }\n    return left;\n  }\n  function parseAdditiveExpression() {\n    let left = parseMultiplicativeExpression();\n    while (is(TOKEN_TYPES.AdditiveBinaryOperator)) {\n      const operator = tokens[current];\n      ++current;\n      const right = parseMultiplicativeExpression();\n      left = new BinaryExpression(operator, left, right);\n    }\n    return left;\n  }\n  function parseCallMemberExpression() {\n    const member = parseMemberExpression();\n    if (is(TOKEN_TYPES.OpenParen)) {\n      return parseCallExpression(member);\n    }\n    return member;\n  }\n  function parseCallExpression(callee) {\n    let callExpression = new CallExpression(callee, parseArgs());\n    if (is(TOKEN_TYPES.OpenParen)) {\n      callExpression = parseCallExpression(callExpression);\n    }\n    return callExpression;\n  }\n  function parseArgs() {\n    expect(TOKEN_TYPES.OpenParen, \"Expected opening parenthesis for arguments list\");\n    const args = is(TOKEN_TYPES.CloseParen) ? [] : parseArgumentsList();\n    expect(TOKEN_TYPES.CloseParen, \"Expected closing parenthesis for arguments list\");\n    return args;\n  }\n  function parseArgumentsList() {\n    const args = [parseExpression()];\n    while (is(TOKEN_TYPES.Comma)) {\n      ++current;\n      args.push(parseExpression());\n    }\n    return args;\n  }\n  function parseMemberExpressionArgumentsList() {\n    const slices = [];\n    let isSlice = false;\n    while (!is(TOKEN_TYPES.CloseSquareBracket)) {\n      if (is(TOKEN_TYPES.Colon)) {\n        slices.push(void 0);\n        ++current;\n        isSlice = true;\n      } else {\n        slices.push(parseExpression());\n        if (is(TOKEN_TYPES.Colon)) {\n          ++current;\n          isSlice = true;\n        }\n      }\n    }\n    if (slices.length === 0) {\n      throw new SyntaxError(`Expected at least one argument for member/slice expression`);\n    }\n    if (isSlice) {\n      if (slices.length > 3) {\n        throw new SyntaxError(`Expected 0-3 arguments for slice expression`);\n      }\n      return new SliceExpression(...slices);\n    }\n    return slices[0];\n  }\n  function parseMemberExpression() {\n    let object = parsePrimaryExpression();\n    while (is(TOKEN_TYPES.Dot) || is(TOKEN_TYPES.OpenSquareBracket)) {\n      const operator = tokens[current];\n      ++current;\n      let property;\n      const computed = operator.type !== TOKEN_TYPES.Dot;\n      if (computed) {\n        property = parseMemberExpressionArgumentsList();\n        expect(TOKEN_TYPES.CloseSquareBracket, \"Expected closing square bracket\");\n      } else {\n        property = parsePrimaryExpression();\n        if (property.type !== \"Identifier\") {\n          throw new SyntaxError(`Expected identifier following dot operator`);\n        }\n      }\n      object = new MemberExpression(object, property, computed);\n    }\n    return object;\n  }\n  function parseMultiplicativeExpression() {\n    let left = parseFilterExpression();\n    while (is(TOKEN_TYPES.MultiplicativeBinaryOperator)) {\n      const operator = tokens[current];\n      ++current;\n      const right = parseFilterExpression();\n      left = new BinaryExpression(operator, left, right);\n    }\n    return left;\n  }\n  function parseFilterExpression() {\n    let operand = parseCallMemberExpression();\n    while (is(TOKEN_TYPES.Pipe)) {\n      ++current;\n      const filter = parsePrimaryExpression();\n      if (!(filter instanceof Identifier)) {\n        throw new SyntaxError(`Expected identifier for the filter`);\n      }\n      operand = new FilterExpression(operand, filter);\n    }\n    return operand;\n  }\n  function parsePrimaryExpression() {\n    const token = tokens[current];\n    switch (token.type) {\n      case TOKEN_TYPES.NumericLiteral:\n        ++current;\n        return new NumericLiteral(Number(token.value));\n      case TOKEN_TYPES.StringLiteral:\n        ++current;\n        return new StringLiteral(token.value);\n      case TOKEN_TYPES.BooleanLiteral:\n        ++current;\n        return new BooleanLiteral(token.value === \"true\");\n      case TOKEN_TYPES.Identifier:\n        ++current;\n        return new Identifier(token.value);\n      case TOKEN_TYPES.OpenParen: {\n        ++current;\n        const expression = parseExpression();\n        if (tokens[current].type !== TOKEN_TYPES.CloseParen) {\n          throw new SyntaxError(\"Expected closing parenthesis\");\n        }\n        ++current;\n        return expression;\n      }\n      default:\n        throw new SyntaxError(`Unexpected token: ${token.type}`);\n    }\n  }\n  while (current < tokens.length) {\n    program.body.push(parseAny());\n  }\n  return program;\n}\n\n// src/utils.ts\nfunction slice(array, start, stop, step = 1) {\n  const direction = Math.sign(step);\n  if (direction >= 0) {\n    start = (start ??= 0) < 0 ? Math.max(array.length + start, 0) : Math.min(start, array.length);\n    stop = (stop ??= array.length) < 0 ? Math.max(array.length + stop, 0) : Math.min(stop, array.length);\n  } else {\n    start = (start ??= array.length - 1) < 0 ? Math.max(array.length + start, -1) : Math.min(start, array.length - 1);\n    stop = (stop ??= -1) < -1 ? Math.max(array.length + stop, -1) : Math.min(stop, array.length - 1);\n  }\n  const result = [];\n  for (let i = start; direction * i < direction * stop; i += step) {\n    result.push(array[i]);\n  }\n  return result;\n}\n\n// src/runtime.ts\nvar RuntimeValue = class {\n  type = \"RuntimeValue\";\n  value;\n  /**\n   * A collection of built-in functions for this type.\n   */\n  builtins = /* @__PURE__ */ new Map();\n  /**\n   * Creates a new RuntimeValue.\n   */\n  constructor(value = void 0) {\n    this.value = value;\n  }\n  /**\n   * Determines truthiness or falsiness of the runtime value.\n   * This function should be overridden by subclasses if it has custom truthiness criteria.\n   * @returns {BooleanValue} BooleanValue(true) if the value is truthy, BooleanValue(false) otherwise.\n   */\n  __bool__() {\n    return new BooleanValue(!!this.value);\n  }\n};\nvar NumericValue = class extends RuntimeValue {\n  type = \"NumericValue\";\n};\nvar StringValue = class extends RuntimeValue {\n  type = \"StringValue\";\n  builtins = /* @__PURE__ */ new Map([\n    [\n      \"upper\",\n      new FunctionValue(() => {\n        return new StringValue(this.value.toUpperCase());\n      })\n    ],\n    [\n      \"lower\",\n      new FunctionValue(() => {\n        return new StringValue(this.value.toLowerCase());\n      })\n    ],\n    [\n      \"strip\",\n      new FunctionValue(() => {\n        return new StringValue(this.value.trim());\n      })\n    ],\n    [\"length\", new NumericValue(this.value.length)]\n  ]);\n};\nvar BooleanValue = class extends RuntimeValue {\n  type = \"BooleanValue\";\n};\nvar ObjectValue = class extends RuntimeValue {\n  type = \"ObjectValue\";\n  /**\n   * NOTE: necessary to override since all JavaScript arrays are considered truthy,\n   * while only non-empty Python arrays are consider truthy.\n   *\n   * e.g.,\n   *  - JavaScript:  {} && 5 -> 5\n   *  - Python:      {} and 5 -> {}\n   */\n  __bool__() {\n    return new BooleanValue(this.value.size > 0);\n  }\n};\nvar ArrayValue = class extends RuntimeValue {\n  type = \"ArrayValue\";\n  builtins = /* @__PURE__ */ new Map([[\"length\", new NumericValue(this.value.length)]]);\n  /**\n   * NOTE: necessary to override since all JavaScript arrays are considered truthy,\n   * while only non-empty Python arrays are consider truthy.\n   *\n   * e.g.,\n   *  - JavaScript:  [] && 5 -> 5\n   *  - Python:      [] and 5 -> []\n   */\n  __bool__() {\n    return new BooleanValue(this.value.length > 0);\n  }\n};\nvar FunctionValue = class extends RuntimeValue {\n  type = \"FunctionValue\";\n};\nvar NullValue = class extends RuntimeValue {\n  type = \"NullValue\";\n};\nvar UndefinedValue = class extends RuntimeValue {\n  type = \"UndefinedValue\";\n};\nvar Environment = class {\n  constructor(parent) {\n    this.parent = parent;\n  }\n  /**\n   * The variables declared in this environment.\n   */\n  variables = /* @__PURE__ */ new Map();\n  /**\n   * Set the value of a variable in the current environment.\n   */\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any, @typescript-eslint/explicit-module-boundary-types\n  set(name, value) {\n    return this.declareVariable(name, convertToRuntimeValues(value));\n  }\n  declareVariable(name, value) {\n    if (this.variables.has(name)) {\n      throw new SyntaxError(`Variable already declared: ${name}`);\n    }\n    this.variables.set(name, value);\n    return value;\n  }\n  // private assignVariable(name: string, value: AnyRuntimeValue): AnyRuntimeValue {\n  // \tconst env = this.resolve(name);\n  // \tenv.variables.set(name, value);\n  // \treturn value;\n  // }\n  /**\n   * Declare if doesn't exist, assign otherwise.\n   */\n  setVariable(name, value) {\n    let env;\n    try {\n      env = this.resolve(name);\n    } catch {\n    }\n    (env ?? this).variables.set(name, value);\n    return value;\n  }\n  /**\n   * Resolve the environment in which the variable is declared.\n   * @param {string} name The name of the variable.\n   * @returns {Environment} The environment in which the variable is declared.\n   */\n  resolve(name) {\n    if (this.variables.has(name)) {\n      return this;\n    }\n    if (this.parent) {\n      return this.parent.resolve(name);\n    }\n    throw new Error(`Unknown variable: ${name}`);\n  }\n  lookupVariable(name) {\n    return this.resolve(name).variables.get(name) ?? new NullValue();\n  }\n};\nvar Interpreter = class {\n  global;\n  constructor(env) {\n    this.global = env ?? new Environment();\n  }\n  /**\n   * Run the program.\n   */\n  run(program) {\n    return this.evaluate(program, this.global);\n  }\n  /**\n   * Evaulates expressions following the binary operation type.\n   */\n  evaluateBinaryExpression(node, environment) {\n    const left = this.evaluate(node.left, environment);\n    const right = this.evaluate(node.right, environment);\n    switch (node.operator.value) {\n      case \"==\":\n        return new BooleanValue(left.value == right.value);\n      case \"!=\":\n        return new BooleanValue(left.value != right.value);\n      case \"and\":\n        return left.__bool__().value ? right : left;\n      case \"or\":\n        return left.__bool__().value ? left : right;\n    }\n    if (left instanceof UndefinedValue || right instanceof UndefinedValue) {\n      throw new Error(\"Cannot perform operation on undefined values\");\n    } else if (left instanceof NullValue || right instanceof NullValue) {\n      throw new Error(\"Cannot perform operation on null values\");\n    } else if (left instanceof NumericValue && right instanceof NumericValue) {\n      switch (node.operator.value) {\n        case \"+\":\n          return new NumericValue(left.value + right.value);\n        case \"-\":\n          return new NumericValue(left.value - right.value);\n        case \"*\":\n          return new NumericValue(left.value * right.value);\n        case \"/\":\n          return new NumericValue(left.value / right.value);\n        case \"%\":\n          return new NumericValue(left.value % right.value);\n        case \"<\":\n          return new BooleanValue(left.value < right.value);\n        case \">\":\n          return new BooleanValue(left.value > right.value);\n        case \">=\":\n          return new BooleanValue(left.value >= right.value);\n        case \"<=\":\n          return new BooleanValue(left.value <= right.value);\n      }\n    } else if (right instanceof ArrayValue) {\n      const member = right.value.find((x) => x.value === left.value) !== void 0;\n      switch (node.operator.value) {\n        case \"in\":\n          return new BooleanValue(member);\n        case \"not in\":\n          return new BooleanValue(!member);\n      }\n    }\n    if (left instanceof StringValue || right instanceof StringValue) {\n      switch (node.operator.value) {\n        case \"+\":\n          return new StringValue(left.value.toString() + right.value.toString());\n      }\n    }\n    if (left instanceof StringValue && right instanceof StringValue) {\n      switch (node.operator.value) {\n        case \"in\":\n          return new BooleanValue(right.value.includes(left.value));\n        case \"not in\":\n          return new BooleanValue(!right.value.includes(left.value));\n      }\n    }\n    throw new SyntaxError(`Unknown operator \"${node.operator.value}\" between ${left.type} and ${right.type}`);\n  }\n  /**\n   * Evaulates expressions following the filter operation type.\n   */\n  evaluateFilterExpression(node, environment) {\n    const operand = this.evaluate(node.operand, environment);\n    if (operand instanceof ArrayValue) {\n      switch (node.filter.value) {\n        case \"first\":\n          return operand.value[0];\n        case \"last\":\n          return operand.value[operand.value.length - 1];\n        case \"length\":\n          return new NumericValue(operand.value.length);\n        case \"reverse\":\n          return new ArrayValue(operand.value.reverse());\n        case \"sort\":\n          return new ArrayValue(\n            operand.value.sort((a, b) => {\n              if (a.type !== b.type) {\n                throw new Error(`Cannot compare different types: ${a.type} and ${b.type}`);\n              }\n              switch (a.type) {\n                case \"NumericValue\":\n                  return a.value - b.value;\n                case \"StringValue\":\n                  return a.value.localeCompare(b.value);\n                default:\n                  throw new Error(`Cannot compare type: ${a.type}`);\n              }\n            })\n          );\n        default:\n          throw new Error(`Unknown ArrayValue filter: ${node.filter.value}`);\n      }\n    } else if (operand instanceof StringValue) {\n      switch (node.filter.value) {\n        case \"length\":\n          return new NumericValue(operand.value.length);\n        case \"upper\":\n          return new StringValue(operand.value.toUpperCase());\n        case \"lower\":\n          return new StringValue(operand.value.toLowerCase());\n        case \"title\":\n          return new StringValue(operand.value.replace(/\\b\\w/g, (c) => c.toUpperCase()));\n        case \"capitalize\":\n          return new StringValue(operand.value.charAt(0).toUpperCase() + operand.value.slice(1));\n        case \"trim\":\n          return new StringValue(operand.value.trim());\n        default:\n          throw new Error(`Unknown StringValue filter: ${node.filter.value}`);\n      }\n    } else if (operand instanceof NumericValue) {\n      switch (node.filter.value) {\n        case \"abs\":\n          return new NumericValue(Math.abs(operand.value));\n        default:\n          throw new Error(`Unknown NumericValue filter: ${node.filter.value}`);\n      }\n    }\n    throw new Error(`Cannot apply filter \"${node.filter.value}\" to type: ${operand.type}`);\n  }\n  /**\n   * Evaulates expressions following the unary operation type.\n   */\n  evaluateUnaryExpression(node, environment) {\n    const argument = this.evaluate(node.argument, environment);\n    switch (node.operator.value) {\n      case \"not\":\n        return new BooleanValue(!argument.value);\n      default:\n        throw new SyntaxError(`Unknown operator: ${node.operator.value}`);\n    }\n  }\n  evalProgram(program, environment) {\n    return this.evaluateBlock(program.body, environment);\n  }\n  evaluateBlock(statements, environment) {\n    let result = \"\";\n    for (const statement of statements) {\n      const lastEvaluated = this.evaluate(statement, environment);\n      if (lastEvaluated.type !== \"NullValue\") {\n        result += lastEvaluated.value;\n      }\n    }\n    result = result.replace(/^\\n/, \"\");\n    return new StringValue(result);\n  }\n  evaluateIdentifier(node, environment) {\n    return environment.lookupVariable(node.value);\n  }\n  evaluateCallExpression(expr, environment) {\n    const args = expr.args.map((arg) => this.evaluate(arg, environment));\n    const fn = this.evaluate(expr.callee, environment);\n    if (fn.type !== \"FunctionValue\") {\n      throw new Error(`Cannot call something that is not a function: got ${fn.type}`);\n    }\n    return fn.value(args, environment);\n  }\n  evaluateSliceExpression(object, expr, environment) {\n    if (!(object instanceof ArrayValue || object instanceof StringValue)) {\n      throw new Error(\"Slice object must be an array or string\");\n    }\n    const start = this.evaluate(expr.start, environment);\n    const stop = this.evaluate(expr.stop, environment);\n    const step = this.evaluate(expr.step, environment);\n    if (!(start instanceof NumericValue || start instanceof UndefinedValue)) {\n      throw new Error(\"Slice start must be numeric or undefined\");\n    }\n    if (!(stop instanceof NumericValue || stop instanceof UndefinedValue)) {\n      throw new Error(\"Slice stop must be numeric or undefined\");\n    }\n    if (!(step instanceof NumericValue || step instanceof UndefinedValue)) {\n      throw new Error(\"Slice step must be numeric or undefined\");\n    }\n    if (object instanceof ArrayValue) {\n      return new ArrayValue(slice(object.value, start.value, stop.value, step.value));\n    } else {\n      return new StringValue(slice(Array.from(object.value), start.value, stop.value, step.value).join(\"\"));\n    }\n  }\n  evaluateMemberExpression(expr, environment) {\n    const object = this.evaluate(expr.object, environment);\n    let property;\n    if (expr.computed) {\n      if (expr.property.type === \"SliceExpression\") {\n        return this.evaluateSliceExpression(object, expr.property, environment);\n      } else {\n        property = this.evaluate(expr.property, environment);\n      }\n    } else {\n      property = new StringValue(expr.property.value);\n    }\n    let value;\n    if (object instanceof ObjectValue) {\n      if (!(property instanceof StringValue)) {\n        throw new Error(`Cannot access property with non-string: got ${property.type}`);\n      }\n      value = object.value.get(property.value) ?? object.builtins.get(property.value);\n    } else if (object instanceof ArrayValue || object instanceof StringValue) {\n      if (property instanceof NumericValue) {\n        value = object.value.at(property.value);\n        if (object instanceof StringValue) {\n          value = new StringValue(object.value.at(property.value));\n        }\n      } else if (property instanceof StringValue) {\n        value = object.builtins.get(property.value);\n      } else {\n        throw new Error(`Cannot access property with non-string/non-number: got ${property.type}`);\n      }\n    } else {\n      if (!(property instanceof StringValue)) {\n        throw new Error(`Cannot access property with non-string: got ${property.type}`);\n      }\n      value = object.builtins.get(property.value);\n    }\n    if (!(value instanceof RuntimeValue)) {\n      throw new Error(`${object.type} has no property '${property.value}'`);\n    }\n    return value;\n  }\n  evaluateSet(node, environment) {\n    if (node.assignee.type !== \"Identifier\") {\n      throw new Error(`Invalid LHS inside assignment expression: ${JSON.stringify(node.assignee)}`);\n    }\n    const variableName = node.assignee.value;\n    environment.setVariable(variableName, this.evaluate(node.value, environment));\n    return new NullValue();\n  }\n  evaluateIf(node, environment) {\n    const test = this.evaluate(node.test, environment);\n    return this.evaluateBlock(test.__bool__().value ? node.body : node.alternate, environment);\n  }\n  evaluateFor(node, environment) {\n    const scope = new Environment(environment);\n    const iterable = this.evaluate(node.iterable, scope);\n    if (!(iterable instanceof ArrayValue)) {\n      throw new Error(`Expected iterable type in for loop: got ${iterable.type}`);\n    }\n    let result = \"\";\n    for (let i = 0; i < iterable.value.length; ++i) {\n      scope.setVariable(\n        \"loop\",\n        new ObjectValue(\n          new Map(\n            [\n              [\"index\", new NumericValue(i + 1)],\n              [\"index0\", new NumericValue(i)],\n              [\"first\", new BooleanValue(i === 0)],\n              [\"last\", new BooleanValue(i === iterable.value.length - 1)],\n              [\"length\", new NumericValue(iterable.value.length)]\n            ].map(([key, value]) => [key, value])\n          )\n        )\n      );\n      scope.setVariable(node.loopvar.value, iterable.value[i]);\n      const evaluated = this.evaluateBlock(node.body, scope);\n      result += evaluated.value;\n    }\n    return new StringValue(result);\n  }\n  evaluate(statement, environment) {\n    if (statement === void 0)\n      return new UndefinedValue();\n    switch (statement.type) {\n      case \"Program\":\n        return this.evalProgram(statement, environment);\n      case \"Set\":\n        return this.evaluateSet(statement, environment);\n      case \"If\":\n        return this.evaluateIf(statement, environment);\n      case \"For\":\n        return this.evaluateFor(statement, environment);\n      case \"NumericLiteral\":\n        return new NumericValue(Number(statement.value));\n      case \"StringLiteral\":\n        return new StringValue(statement.value);\n      case \"BooleanLiteral\":\n        return new BooleanValue(statement.value);\n      case \"Identifier\":\n        return this.evaluateIdentifier(statement, environment);\n      case \"CallExpression\":\n        return this.evaluateCallExpression(statement, environment);\n      case \"MemberExpression\":\n        return this.evaluateMemberExpression(statement, environment);\n      case \"UnaryExpression\":\n        return this.evaluateUnaryExpression(statement, environment);\n      case \"BinaryExpression\":\n        return this.evaluateBinaryExpression(statement, environment);\n      case \"FilterExpression\":\n        return this.evaluateFilterExpression(statement, environment);\n      default:\n        throw new SyntaxError(`Unknown node type: ${statement.type}`);\n    }\n  }\n};\nfunction convertToRuntimeValues(input) {\n  switch (typeof input) {\n    case \"number\":\n      return new NumericValue(input);\n    case \"string\":\n      return new StringValue(input);\n    case \"boolean\":\n      return new BooleanValue(input);\n    case \"object\":\n      if (input === null) {\n        return new NullValue();\n      } else if (Array.isArray(input)) {\n        return new ArrayValue(input.map(convertToRuntimeValues));\n      } else {\n        return new ObjectValue(\n          new Map(Object.entries(input).map(([key, value]) => [key, convertToRuntimeValues(value)]))\n        );\n      }\n    case \"function\":\n      return new FunctionValue((args, _scope) => {\n        const result = input(...args.map((x) => x.value)) ?? null;\n        return convertToRuntimeValues(result);\n      });\n    default:\n      throw new Error(`Cannot convert to runtime value: ${input}`);\n  }\n}\n\n// src/index.ts\nvar Template = class {\n  parsed;\n  /**\n   * @param {string} template The template string\n   */\n  constructor(template) {\n    template = template.replace(/%}\\s+{%/g, \"%}{%\");\n    const tokens = tokenize(template);\n    this.parsed = parse(tokens);\n  }\n  render(items) {\n    const env = new Environment();\n    env.set(\"false\", false);\n    env.set(\"true\", true);\n    env.set(\"raise_exception\", (args) => {\n      throw new Error(args);\n    });\n    for (const [key, value] of Object.entries(items)) {\n      env.set(key, value);\n    }\n    const interpreter = new Interpreter(env);\n    const result = interpreter.run(this.parsed);\n    return result.value;\n  }\n};\n\n\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@huggingface/jinja/dist/index.js?");

/***/ }),

/***/ "./node_modules/@xenova/transformers/src/backends/onnx.js":
/*!****************************************************************!*\
  !*** ./node_modules/@xenova/transformers/src/backends/onnx.js ***!
  \****************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("var onnxruntime_node__WEBPACK_IMPORTED_MODULE_0___namespace_cache;\nvar onnxruntime_web__WEBPACK_IMPORTED_MODULE_1___namespace_cache;\n__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   ONNX: () => (/* binding */ ONNX),\n/* harmony export */   executionProviders: () => (/* binding */ executionProviders)\n/* harmony export */ });\n/* harmony import */ var onnxruntime_node__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! onnxruntime-node */ \"?2ca1\");\n/* harmony import */ var onnxruntime_web__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! onnxruntime-web */ \"./node_modules/onnxruntime-web/dist/ort-web.min.js\");\n/**\n * @file Handler file for choosing the correct version of ONNX Runtime, based on the environment.\n * Ideally, we could import the `onnxruntime-web` and `onnxruntime-node` packages only when needed,\n * but dynamic imports don't seem to work with the current webpack version and/or configuration.\n * This is possibly due to the experimental nature of top-level await statements.\n * So, we just import both packages, and use the appropriate one based on the environment:\n *   - When running in node, we use `onnxruntime-node`.\n *   - When running in the browser, we use `onnxruntime-web` (`onnxruntime-node` is not bundled).\n * \n * This module is not directly exported, but can be accessed through the environment variables:\n * ```javascript\n * import { env } from '@xenova/transformers';\n * console.log(env.backends.onnx);\n * ```\n * \n * @module backends/onnx\n */\n\n// NOTE: Import order matters here. We need to import `onnxruntime-node` before `onnxruntime-web`.\n// In either case, we select the default export if it exists, otherwise we use the named export.\n\n\n\n/** @type {import('onnxruntime-web')} The ONNX runtime module. */\nlet ONNX;\n\nconst executionProviders = [\n    // 'webgpu',\n    'wasm'\n];\n\nif (typeof process !== 'undefined' && process?.release?.name === 'node') {\n    // Running in a node-like environment.\n    ONNX = onnxruntime_node__WEBPACK_IMPORTED_MODULE_0__ ?? /*#__PURE__*/ (onnxruntime_node__WEBPACK_IMPORTED_MODULE_0___namespace_cache || (onnxruntime_node__WEBPACK_IMPORTED_MODULE_0___namespace_cache = __webpack_require__.t(onnxruntime_node__WEBPACK_IMPORTED_MODULE_0__, 2)));\n\n    // Add `cpu` execution provider, with higher precedence that `wasm`.\n    executionProviders.unshift('cpu');\n\n} else {\n    // Running in a browser-environment\n    ONNX = onnxruntime_web__WEBPACK_IMPORTED_MODULE_1__ ?? /*#__PURE__*/ (onnxruntime_web__WEBPACK_IMPORTED_MODULE_1___namespace_cache || (onnxruntime_web__WEBPACK_IMPORTED_MODULE_1___namespace_cache = __webpack_require__.t(onnxruntime_web__WEBPACK_IMPORTED_MODULE_1__, 2)));\n\n    // SIMD for WebAssembly does not operate correctly in some recent versions of iOS (16.4.x).\n    // As a temporary fix, we disable it for now.\n    // For more information, see: https://github.com/microsoft/onnxruntime/issues/15644\n    const isIOS = typeof navigator !== 'undefined' && /iP(hone|od|ad).+16_4.+AppleWebKit/.test(navigator.userAgent);\n    if (isIOS) {\n        ONNX.env.wasm.simd = false;\n    }\n}\n\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@xenova/transformers/src/backends/onnx.js?");

/***/ }),

/***/ "./node_modules/@xenova/transformers/src/configs.js":
/*!**********************************************************!*\
  !*** ./node_modules/@xenova/transformers/src/configs.js ***!
  \**********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   AutoConfig: () => (/* binding */ AutoConfig),\n/* harmony export */   PretrainedConfig: () => (/* binding */ PretrainedConfig)\n/* harmony export */ });\n/* harmony import */ var _utils_hub_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./utils/hub.js */ \"./node_modules/@xenova/transformers/src/utils/hub.js\");\n\n/**\n * @file Helper module for using model configs. For more information, see the corresponding\n * [Python documentation](https://huggingface.co/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig).\n * \n * **Example:** Load an `AutoConfig`.\n * \n * ```javascript\n * import { AutoConfig } from '@xenova/transformers';\n * let config = await AutoConfig.from_pretrained('bert-base-uncased');\n * console.log(config);\n * // PretrainedConfig {\n * //   \"model_type\": \"bert\",\n * //   \"is_encoder_decoder\": false,\n * //   \"architectures\": [\n * //       \"BertForMaskedLM\"\n * //   ],\n * //   \"vocab_size\": 30522\n * //   \"num_attention_heads\": 12,\n * //   \"num_hidden_layers\": 12,\n * //   \"hidden_size\": 768,\n * //   \"max_position_embeddings\": 512,\n * //   ...\n * // }\n * ```\n * \n * @module configs\n */\n\n\n\n/**\n * @typedef {import('./utils/hub.js').PretrainedOptions} PretrainedOptions\n */\n\n\n/**\n * Loads a config from the specified path.\n * @param {string} pretrained_model_name_or_path The path to the config directory.\n * @param {PretrainedOptions} options Additional options for loading the config.\n * @returns {Promise<Array>} A promise that resolves with information about the loaded config.\n */\nasync function loadConfig(pretrained_model_name_or_path, options) {\n    let info = await (0,_utils_hub_js__WEBPACK_IMPORTED_MODULE_0__.getModelJSON)(pretrained_model_name_or_path, 'config.json', true, options);\n    return info;\n}\n\n/**\n * Base class for all configuration classes. For more information, see the corresponding\n * [Python documentation](https://huggingface.co/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig).\n */\nclass PretrainedConfig {\n    // NOTE: Typo in original\n\n    /**\n     * Create a new PreTrainedTokenizer instance.\n     * @param {Object} configJSON The JSON of the config.\n     */\n    constructor(configJSON) {\n        this.model_type = null;\n        this.is_encoder_decoder = false;\n\n        Object.assign(this, configJSON);\n    }\n\n    /**\n     * Loads a pre-trained config from the given `pretrained_model_name_or_path`. \n     * \n     * @param {string} pretrained_model_name_or_path The path to the pre-trained config.\n     * @param {PretrainedOptions} options Additional options for loading the config.\n     * @throws {Error} Throws an error if the config.json is not found in the `pretrained_model_name_or_path`.\n     * \n     * @returns {Promise<PretrainedConfig>} A new instance of the `PretrainedConfig` class.\n     */\n    static async from_pretrained(pretrained_model_name_or_path, {\n        progress_callback = null,\n        config = null,\n        cache_dir = null,\n        local_files_only = false,\n        revision = 'main',\n    } = {}) {\n\n        let data = config ?? await loadConfig(pretrained_model_name_or_path, {\n            progress_callback,\n            config,\n            cache_dir,\n            local_files_only,\n            revision,\n        })\n        return new this(data);\n    }\n}\n\n/**\n * Helper class which is used to instantiate pretrained configs with the `from_pretrained` function.\n * \n * @example\n * let config = await AutoConfig.from_pretrained('bert-base-uncased'); \n */\nclass AutoConfig {\n    /** @type {PretrainedConfig.from_pretrained} */\n    static async from_pretrained(...args) {\n        return PretrainedConfig.from_pretrained(...args);\n    }\n}\n\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@xenova/transformers/src/configs.js?");

/***/ }),

/***/ "./node_modules/@xenova/transformers/src/env.js":
/*!******************************************************!*\
  !*** ./node_modules/@xenova/transformers/src/env.js ***!
  \******************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   env: () => (/* binding */ env)\n/* harmony export */ });\n/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! fs */ \"?0a9a\");\n/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! path */ \"?73ea\");\n/* harmony import */ var url__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! url */ \"?845f\");\n/* harmony import */ var _backends_onnx_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./backends/onnx.js */ \"./node_modules/@xenova/transformers/src/backends/onnx.js\");\n/**\n * @file Module used to configure Transformers.js.\n * \n * **Example:** Disable remote models.\n * ```javascript\n * import { env } from '@xenova/transformers';\n * env.allowRemoteModels = false;\n * ```\n * \n * **Example:** Set local model path.\n * ```javascript\n * import { env } from '@xenova/transformers';\n * env.localModelPath = '/path/to/local/models/';\n * ```\n * \n * **Example:** Set cache directory.\n * ```javascript\n * import { env } from '@xenova/transformers';\n * env.cacheDir = '/path/to/cache/directory/';\n * ```\n * \n * @module env\n */\n\n\n\n\n\n\nconst { env: onnx_env } = _backends_onnx_js__WEBPACK_IMPORTED_MODULE_3__.ONNX;\n\nconst VERSION = '2.15.1';\n\n// Check if various APIs are available (depends on environment)\nconst WEB_CACHE_AVAILABLE = typeof self !== 'undefined' && 'caches' in self;\nconst FS_AVAILABLE = !isEmpty(fs__WEBPACK_IMPORTED_MODULE_0__); // check if file system is available\nconst PATH_AVAILABLE = !isEmpty(path__WEBPACK_IMPORTED_MODULE_1__); // check if path is available\n\nconst RUNNING_LOCALLY = FS_AVAILABLE && PATH_AVAILABLE;\n\nconst __dirname = RUNNING_LOCALLY\n    ? path__WEBPACK_IMPORTED_MODULE_1__.dirname(path__WEBPACK_IMPORTED_MODULE_1__.dirname(url__WEBPACK_IMPORTED_MODULE_2__.fileURLToPath(\"file:///home/runner/work/SemanticFinder/SemanticFinder/node_modules/@xenova/transformers/src/env.js\")))\n    : './';\n\n// Only used for environments with access to file system\nconst DEFAULT_CACHE_DIR = RUNNING_LOCALLY\n    ? path__WEBPACK_IMPORTED_MODULE_1__.join(__dirname, '/.cache/')\n    : null;\n\n// Set local model path, based on available APIs\nconst DEFAULT_LOCAL_MODEL_PATH = '/models/';\nconst localModelPath = RUNNING_LOCALLY\n    ? path__WEBPACK_IMPORTED_MODULE_1__.join(__dirname, DEFAULT_LOCAL_MODEL_PATH)\n    : DEFAULT_LOCAL_MODEL_PATH;\n\n// Set path to wasm files. This is needed when running in a web worker.\n// https://onnxruntime.ai/docs/api/js/interfaces/Env.WebAssemblyFlags.html#wasmPaths\n// We use remote wasm files by default to make it easier for newer users.\n// In practice, users should probably self-host the necessary .wasm files.\nonnx_env.wasm.wasmPaths = RUNNING_LOCALLY\n    ? path__WEBPACK_IMPORTED_MODULE_1__.join(__dirname, '/dist/')\n    : `https://cdn.jsdelivr.net/npm/@xenova/transformers@${VERSION}/dist/`;\n\n\n/**\n * Global variable used to control execution. This provides users a simple way to configure Transformers.js.\n * @property {Object} backends Expose environment variables of different backends,\n * allowing users to set these variables if they want to.\n * @property {string} __dirname Directory name of module. Useful for resolving local paths.\n * @property {string} version This version of Transformers.js.\n * @property {boolean} allowRemoteModels Whether to allow loading of remote files, defaults to `true`.\n * If set to `false`, it will have the same effect as setting `local_files_only=true` when loading pipelines, models, tokenizers, processors, etc.\n * @property {string} remoteHost Host URL to load models from. Defaults to the Hugging Face Hub.\n * @property {string} remotePathTemplate Path template to fill in and append to `remoteHost` when loading models.\n * @property {boolean} allowLocalModels Whether to allow loading of local files, defaults to `true`.\n * If set to `false`, it will skip the local file check and try to load the model from the remote host.\n * @property {string} localModelPath Path to load local models from. Defaults to `/models/`.\n * @property {boolean} useFS Whether to use the file system to load files. By default, it is `true` if available.\n * @property {boolean} useBrowserCache Whether to use Cache API to cache models. By default, it is `true` if available.\n * @property {boolean} useFSCache Whether to use the file system to cache files. By default, it is `true` if available.\n * @property {string} cacheDir The directory to use for caching files with the file system. By default, it is `./.cache`.\n * @property {boolean} useCustomCache Whether to use a custom cache system (defined by `customCache`), defaults to `false`.\n * @property {Object} customCache The custom cache to use. Defaults to `null`. Note: this must be an object which\n * implements the `match` and `put` functions of the Web Cache API. For more information, see https://developer.mozilla.org/en-US/docs/Web/API/Cache\n */\nconst env = {\n    /////////////////// Backends settings ///////////////////\n    backends: {\n        // onnxruntime-web/onnxruntime-node\n        onnx: onnx_env,\n\n        // TensorFlow.js\n        tfjs: {},\n    },\n\n    __dirname,\n    version: VERSION,\n\n    /////////////////// Model settings ///////////////////\n    allowRemoteModels: true,\n    remoteHost: 'https://huggingface.co/',\n    remotePathTemplate: '{model}/resolve/{revision}/',\n\n    allowLocalModels: true,\n    localModelPath: localModelPath,\n    useFS: FS_AVAILABLE,\n\n    /////////////////// Cache settings ///////////////////\n    useBrowserCache: WEB_CACHE_AVAILABLE,\n\n    useFSCache: FS_AVAILABLE,\n    cacheDir: DEFAULT_CACHE_DIR,\n\n    useCustomCache: false,\n    customCache: null,\n    //////////////////////////////////////////////////////\n}\n\n\n/**\n * @param {Object} obj\n * @private\n */\nfunction isEmpty(obj) {\n    return Object.keys(obj).length === 0;\n}\n\n\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@xenova/transformers/src/env.js?");

/***/ }),

/***/ "./node_modules/@xenova/transformers/src/models.js":
/*!*********************************************************!*\
  !*** ./node_modules/@xenova/transformers/src/models.js ***!
  \*********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   ASTForAudioClassification: () => (/* binding */ ASTForAudioClassification),\n/* harmony export */   ASTModel: () => (/* binding */ ASTModel),\n/* harmony export */   ASTPreTrainedModel: () => (/* binding */ ASTPreTrainedModel),\n/* harmony export */   AlbertForMaskedLM: () => (/* binding */ AlbertForMaskedLM),\n/* harmony export */   AlbertForQuestionAnswering: () => (/* binding */ AlbertForQuestionAnswering),\n/* harmony export */   AlbertForSequenceClassification: () => (/* binding */ AlbertForSequenceClassification),\n/* harmony export */   AlbertModel: () => (/* binding */ AlbertModel),\n/* harmony export */   AlbertPreTrainedModel: () => (/* binding */ AlbertPreTrainedModel),\n/* harmony export */   AutoModel: () => (/* binding */ AutoModel),\n/* harmony export */   AutoModelForAudioClassification: () => (/* binding */ AutoModelForAudioClassification),\n/* harmony export */   AutoModelForCTC: () => (/* binding */ AutoModelForCTC),\n/* harmony export */   AutoModelForCausalLM: () => (/* binding */ AutoModelForCausalLM),\n/* harmony export */   AutoModelForDepthEstimation: () => (/* binding */ AutoModelForDepthEstimation),\n/* harmony export */   AutoModelForDocumentQuestionAnswering: () => (/* binding */ AutoModelForDocumentQuestionAnswering),\n/* harmony export */   AutoModelForImageClassification: () => (/* binding */ AutoModelForImageClassification),\n/* harmony export */   AutoModelForImageMatting: () => (/* binding */ AutoModelForImageMatting),\n/* harmony export */   AutoModelForImageSegmentation: () => (/* binding */ AutoModelForImageSegmentation),\n/* harmony export */   AutoModelForImageToImage: () => (/* binding */ AutoModelForImageToImage),\n/* harmony export */   AutoModelForMaskGeneration: () => (/* binding */ AutoModelForMaskGeneration),\n/* harmony export */   AutoModelForMaskedLM: () => (/* binding */ AutoModelForMaskedLM),\n/* harmony export */   AutoModelForObjectDetection: () => (/* binding */ AutoModelForObjectDetection),\n/* harmony export */   AutoModelForQuestionAnswering: () => (/* binding */ AutoModelForQuestionAnswering),\n/* harmony export */   AutoModelForSemanticSegmentation: () => (/* binding */ AutoModelForSemanticSegmentation),\n/* harmony export */   AutoModelForSeq2SeqLM: () => (/* binding */ AutoModelForSeq2SeqLM),\n/* harmony export */   AutoModelForSequenceClassification: () => (/* binding */ AutoModelForSequenceClassification),\n/* harmony export */   AutoModelForSpeechSeq2Seq: () => (/* binding */ AutoModelForSpeechSeq2Seq),\n/* harmony export */   AutoModelForTextToSpectrogram: () => (/* binding */ AutoModelForTextToSpectrogram),\n/* harmony export */   AutoModelForTextToWaveform: () => (/* binding */ AutoModelForTextToWaveform),\n/* harmony export */   AutoModelForTokenClassification: () => (/* binding */ AutoModelForTokenClassification),\n/* harmony export */   AutoModelForVision2Seq: () => (/* binding */ AutoModelForVision2Seq),\n/* harmony export */   AutoModelForZeroShotObjectDetection: () => (/* binding */ AutoModelForZeroShotObjectDetection),\n/* harmony export */   BartForConditionalGeneration: () => (/* binding */ BartForConditionalGeneration),\n/* harmony export */   BartForSequenceClassification: () => (/* binding */ BartForSequenceClassification),\n/* harmony export */   BartModel: () => (/* binding */ BartModel),\n/* harmony export */   BartPretrainedModel: () => (/* binding */ BartPretrainedModel),\n/* harmony export */   BaseModelOutput: () => (/* binding */ BaseModelOutput),\n/* harmony export */   BeitForImageClassification: () => (/* binding */ BeitForImageClassification),\n/* harmony export */   BeitModel: () => (/* binding */ BeitModel),\n/* harmony export */   BeitPreTrainedModel: () => (/* binding */ BeitPreTrainedModel),\n/* harmony export */   BertForMaskedLM: () => (/* binding */ BertForMaskedLM),\n/* harmony export */   BertForQuestionAnswering: () => (/* binding */ BertForQuestionAnswering),\n/* harmony export */   BertForSequenceClassification: () => (/* binding */ BertForSequenceClassification),\n/* harmony export */   BertForTokenClassification: () => (/* binding */ BertForTokenClassification),\n/* harmony export */   BertModel: () => (/* binding */ BertModel),\n/* harmony export */   BertPreTrainedModel: () => (/* binding */ BertPreTrainedModel),\n/* harmony export */   BlenderbotForConditionalGeneration: () => (/* binding */ BlenderbotForConditionalGeneration),\n/* harmony export */   BlenderbotModel: () => (/* binding */ BlenderbotModel),\n/* harmony export */   BlenderbotPreTrainedModel: () => (/* binding */ BlenderbotPreTrainedModel),\n/* harmony export */   BlenderbotSmallForConditionalGeneration: () => (/* binding */ BlenderbotSmallForConditionalGeneration),\n/* harmony export */   BlenderbotSmallModel: () => (/* binding */ BlenderbotSmallModel),\n/* harmony export */   BlenderbotSmallPreTrainedModel: () => (/* binding */ BlenderbotSmallPreTrainedModel),\n/* harmony export */   BloomForCausalLM: () => (/* binding */ BloomForCausalLM),\n/* harmony export */   BloomModel: () => (/* binding */ BloomModel),\n/* harmony export */   BloomPreTrainedModel: () => (/* binding */ BloomPreTrainedModel),\n/* harmony export */   CLIPModel: () => (/* binding */ CLIPModel),\n/* harmony export */   CLIPPreTrainedModel: () => (/* binding */ CLIPPreTrainedModel),\n/* harmony export */   CLIPSegForImageSegmentation: () => (/* binding */ CLIPSegForImageSegmentation),\n/* harmony export */   CLIPSegModel: () => (/* binding */ CLIPSegModel),\n/* harmony export */   CLIPSegPreTrainedModel: () => (/* binding */ CLIPSegPreTrainedModel),\n/* harmony export */   CLIPTextModelWithProjection: () => (/* binding */ CLIPTextModelWithProjection),\n/* harmony export */   CLIPVisionModelWithProjection: () => (/* binding */ CLIPVisionModelWithProjection),\n/* harmony export */   CamembertForMaskedLM: () => (/* binding */ CamembertForMaskedLM),\n/* harmony export */   CamembertForQuestionAnswering: () => (/* binding */ CamembertForQuestionAnswering),\n/* harmony export */   CamembertForSequenceClassification: () => (/* binding */ CamembertForSequenceClassification),\n/* harmony export */   CamembertForTokenClassification: () => (/* binding */ CamembertForTokenClassification),\n/* harmony export */   CamembertModel: () => (/* binding */ CamembertModel),\n/* harmony export */   CamembertPreTrainedModel: () => (/* binding */ CamembertPreTrainedModel),\n/* harmony export */   CausalLMOutput: () => (/* binding */ CausalLMOutput),\n/* harmony export */   CausalLMOutputWithPast: () => (/* binding */ CausalLMOutputWithPast),\n/* harmony export */   ChineseCLIPModel: () => (/* binding */ ChineseCLIPModel),\n/* harmony export */   ChineseCLIPPreTrainedModel: () => (/* binding */ ChineseCLIPPreTrainedModel),\n/* harmony export */   ClapAudioModelWithProjection: () => (/* binding */ ClapAudioModelWithProjection),\n/* harmony export */   ClapModel: () => (/* binding */ ClapModel),\n/* harmony export */   ClapPreTrainedModel: () => (/* binding */ ClapPreTrainedModel),\n/* harmony export */   ClapTextModelWithProjection: () => (/* binding */ ClapTextModelWithProjection),\n/* harmony export */   CodeGenForCausalLM: () => (/* binding */ CodeGenForCausalLM),\n/* harmony export */   CodeGenModel: () => (/* binding */ CodeGenModel),\n/* harmony export */   CodeGenPreTrainedModel: () => (/* binding */ CodeGenPreTrainedModel),\n/* harmony export */   ConvBertForMaskedLM: () => (/* binding */ ConvBertForMaskedLM),\n/* harmony export */   ConvBertForQuestionAnswering: () => (/* binding */ ConvBertForQuestionAnswering),\n/* harmony export */   ConvBertForSequenceClassification: () => (/* binding */ ConvBertForSequenceClassification),\n/* harmony export */   ConvBertForTokenClassification: () => (/* binding */ ConvBertForTokenClassification),\n/* harmony export */   ConvBertModel: () => (/* binding */ ConvBertModel),\n/* harmony export */   ConvBertPreTrainedModel: () => (/* binding */ ConvBertPreTrainedModel),\n/* harmony export */   ConvNextForImageClassification: () => (/* binding */ ConvNextForImageClassification),\n/* harmony export */   ConvNextModel: () => (/* binding */ ConvNextModel),\n/* harmony export */   ConvNextPreTrainedModel: () => (/* binding */ ConvNextPreTrainedModel),\n/* harmony export */   ConvNextV2ForImageClassification: () => (/* binding */ ConvNextV2ForImageClassification),\n/* harmony export */   ConvNextV2Model: () => (/* binding */ ConvNextV2Model),\n/* harmony export */   ConvNextV2PreTrainedModel: () => (/* binding */ ConvNextV2PreTrainedModel),\n/* harmony export */   DPTForDepthEstimation: () => (/* binding */ DPTForDepthEstimation),\n/* harmony export */   DPTModel: () => (/* binding */ DPTModel),\n/* harmony export */   DPTPreTrainedModel: () => (/* binding */ DPTPreTrainedModel),\n/* harmony export */   DebertaForMaskedLM: () => (/* binding */ DebertaForMaskedLM),\n/* harmony export */   DebertaForQuestionAnswering: () => (/* binding */ DebertaForQuestionAnswering),\n/* harmony export */   DebertaForSequenceClassification: () => (/* binding */ DebertaForSequenceClassification),\n/* harmony export */   DebertaForTokenClassification: () => (/* binding */ DebertaForTokenClassification),\n/* harmony export */   DebertaModel: () => (/* binding */ DebertaModel),\n/* harmony export */   DebertaPreTrainedModel: () => (/* binding */ DebertaPreTrainedModel),\n/* harmony export */   DebertaV2ForMaskedLM: () => (/* binding */ DebertaV2ForMaskedLM),\n/* harmony export */   DebertaV2ForQuestionAnswering: () => (/* binding */ DebertaV2ForQuestionAnswering),\n/* harmony export */   DebertaV2ForSequenceClassification: () => (/* binding */ DebertaV2ForSequenceClassification),\n/* harmony export */   DebertaV2ForTokenClassification: () => (/* binding */ DebertaV2ForTokenClassification),\n/* harmony export */   DebertaV2Model: () => (/* binding */ DebertaV2Model),\n/* harmony export */   DebertaV2PreTrainedModel: () => (/* binding */ DebertaV2PreTrainedModel),\n/* harmony export */   DeiTForImageClassification: () => (/* binding */ DeiTForImageClassification),\n/* harmony export */   DeiTModel: () => (/* binding */ DeiTModel),\n/* harmony export */   DeiTPreTrainedModel: () => (/* binding */ DeiTPreTrainedModel),\n/* harmony export */   DepthAnythingForDepthEstimation: () => (/* binding */ DepthAnythingForDepthEstimation),\n/* harmony export */   DepthAnythingPreTrainedModel: () => (/* binding */ DepthAnythingPreTrainedModel),\n/* harmony export */   DetrForObjectDetection: () => (/* binding */ DetrForObjectDetection),\n/* harmony export */   DetrForSegmentation: () => (/* binding */ DetrForSegmentation),\n/* harmony export */   DetrModel: () => (/* binding */ DetrModel),\n/* harmony export */   DetrObjectDetectionOutput: () => (/* binding */ DetrObjectDetectionOutput),\n/* harmony export */   DetrPreTrainedModel: () => (/* binding */ DetrPreTrainedModel),\n/* harmony export */   DetrSegmentationOutput: () => (/* binding */ DetrSegmentationOutput),\n/* harmony export */   Dinov2ForImageClassification: () => (/* binding */ Dinov2ForImageClassification),\n/* harmony export */   Dinov2Model: () => (/* binding */ Dinov2Model),\n/* harmony export */   Dinov2PreTrainedModel: () => (/* binding */ Dinov2PreTrainedModel),\n/* harmony export */   DistilBertForMaskedLM: () => (/* binding */ DistilBertForMaskedLM),\n/* harmony export */   DistilBertForQuestionAnswering: () => (/* binding */ DistilBertForQuestionAnswering),\n/* harmony export */   DistilBertForSequenceClassification: () => (/* binding */ DistilBertForSequenceClassification),\n/* harmony export */   DistilBertForTokenClassification: () => (/* binding */ DistilBertForTokenClassification),\n/* harmony export */   DistilBertModel: () => (/* binding */ DistilBertModel),\n/* harmony export */   DistilBertPreTrainedModel: () => (/* binding */ DistilBertPreTrainedModel),\n/* harmony export */   DonutSwinModel: () => (/* binding */ DonutSwinModel),\n/* harmony export */   DonutSwinPreTrainedModel: () => (/* binding */ DonutSwinPreTrainedModel),\n/* harmony export */   ElectraForMaskedLM: () => (/* binding */ ElectraForMaskedLM),\n/* harmony export */   ElectraForQuestionAnswering: () => (/* binding */ ElectraForQuestionAnswering),\n/* harmony export */   ElectraForSequenceClassification: () => (/* binding */ ElectraForSequenceClassification),\n/* harmony export */   ElectraForTokenClassification: () => (/* binding */ ElectraForTokenClassification),\n/* harmony export */   ElectraModel: () => (/* binding */ ElectraModel),\n/* harmony export */   ElectraPreTrainedModel: () => (/* binding */ ElectraPreTrainedModel),\n/* harmony export */   EsmForMaskedLM: () => (/* binding */ EsmForMaskedLM),\n/* harmony export */   EsmForSequenceClassification: () => (/* binding */ EsmForSequenceClassification),\n/* harmony export */   EsmForTokenClassification: () => (/* binding */ EsmForTokenClassification),\n/* harmony export */   EsmModel: () => (/* binding */ EsmModel),\n/* harmony export */   EsmPreTrainedModel: () => (/* binding */ EsmPreTrainedModel),\n/* harmony export */   FalconForCausalLM: () => (/* binding */ FalconForCausalLM),\n/* harmony export */   FalconModel: () => (/* binding */ FalconModel),\n/* harmony export */   FalconPreTrainedModel: () => (/* binding */ FalconPreTrainedModel),\n/* harmony export */   GLPNForDepthEstimation: () => (/* binding */ GLPNForDepthEstimation),\n/* harmony export */   GLPNModel: () => (/* binding */ GLPNModel),\n/* harmony export */   GLPNPreTrainedModel: () => (/* binding */ GLPNPreTrainedModel),\n/* harmony export */   GPT2LMHeadModel: () => (/* binding */ GPT2LMHeadModel),\n/* harmony export */   GPT2Model: () => (/* binding */ GPT2Model),\n/* harmony export */   GPT2PreTrainedModel: () => (/* binding */ GPT2PreTrainedModel),\n/* harmony export */   GPTBigCodeForCausalLM: () => (/* binding */ GPTBigCodeForCausalLM),\n/* harmony export */   GPTBigCodeModel: () => (/* binding */ GPTBigCodeModel),\n/* harmony export */   GPTBigCodePreTrainedModel: () => (/* binding */ GPTBigCodePreTrainedModel),\n/* harmony export */   GPTJForCausalLM: () => (/* binding */ GPTJForCausalLM),\n/* harmony export */   GPTJModel: () => (/* binding */ GPTJModel),\n/* harmony export */   GPTJPreTrainedModel: () => (/* binding */ GPTJPreTrainedModel),\n/* harmony export */   GPTNeoForCausalLM: () => (/* binding */ GPTNeoForCausalLM),\n/* harmony export */   GPTNeoModel: () => (/* binding */ GPTNeoModel),\n/* harmony export */   GPTNeoPreTrainedModel: () => (/* binding */ GPTNeoPreTrainedModel),\n/* harmony export */   GPTNeoXForCausalLM: () => (/* binding */ GPTNeoXForCausalLM),\n/* harmony export */   GPTNeoXModel: () => (/* binding */ GPTNeoXModel),\n/* harmony export */   GPTNeoXPreTrainedModel: () => (/* binding */ GPTNeoXPreTrainedModel),\n/* harmony export */   HubertForCTC: () => (/* binding */ HubertForCTC),\n/* harmony export */   HubertForSequenceClassification: () => (/* binding */ HubertForSequenceClassification),\n/* harmony export */   HubertModel: () => (/* binding */ HubertModel),\n/* harmony export */   HubertPreTrainedModel: () => (/* binding */ HubertPreTrainedModel),\n/* harmony export */   ImageMattingOutput: () => (/* binding */ ImageMattingOutput),\n/* harmony export */   LlamaForCausalLM: () => (/* binding */ LlamaForCausalLM),\n/* harmony export */   LlamaModel: () => (/* binding */ LlamaModel),\n/* harmony export */   LlamaPreTrainedModel: () => (/* binding */ LlamaPreTrainedModel),\n/* harmony export */   LongT5ForConditionalGeneration: () => (/* binding */ LongT5ForConditionalGeneration),\n/* harmony export */   LongT5Model: () => (/* binding */ LongT5Model),\n/* harmony export */   LongT5PreTrainedModel: () => (/* binding */ LongT5PreTrainedModel),\n/* harmony export */   M2M100ForConditionalGeneration: () => (/* binding */ M2M100ForConditionalGeneration),\n/* harmony export */   M2M100Model: () => (/* binding */ M2M100Model),\n/* harmony export */   M2M100PreTrainedModel: () => (/* binding */ M2M100PreTrainedModel),\n/* harmony export */   MBartForCausalLM: () => (/* binding */ MBartForCausalLM),\n/* harmony export */   MBartForConditionalGeneration: () => (/* binding */ MBartForConditionalGeneration),\n/* harmony export */   MBartForSequenceClassification: () => (/* binding */ MBartForSequenceClassification),\n/* harmony export */   MBartModel: () => (/* binding */ MBartModel),\n/* harmony export */   MBartPreTrainedModel: () => (/* binding */ MBartPreTrainedModel),\n/* harmony export */   MPNetForMaskedLM: () => (/* binding */ MPNetForMaskedLM),\n/* harmony export */   MPNetForQuestionAnswering: () => (/* binding */ MPNetForQuestionAnswering),\n/* harmony export */   MPNetForSequenceClassification: () => (/* binding */ MPNetForSequenceClassification),\n/* harmony export */   MPNetForTokenClassification: () => (/* binding */ MPNetForTokenClassification),\n/* harmony export */   MPNetModel: () => (/* binding */ MPNetModel),\n/* harmony export */   MPNetPreTrainedModel: () => (/* binding */ MPNetPreTrainedModel),\n/* harmony export */   MT5ForConditionalGeneration: () => (/* binding */ MT5ForConditionalGeneration),\n/* harmony export */   MT5Model: () => (/* binding */ MT5Model),\n/* harmony export */   MT5PreTrainedModel: () => (/* binding */ MT5PreTrainedModel),\n/* harmony export */   MarianMTModel: () => (/* binding */ MarianMTModel),\n/* harmony export */   MarianModel: () => (/* binding */ MarianModel),\n/* harmony export */   MarianPreTrainedModel: () => (/* binding */ MarianPreTrainedModel),\n/* harmony export */   MaskedLMOutput: () => (/* binding */ MaskedLMOutput),\n/* harmony export */   MistralForCausalLM: () => (/* binding */ MistralForCausalLM),\n/* harmony export */   MistralModel: () => (/* binding */ MistralModel),\n/* harmony export */   MistralPreTrainedModel: () => (/* binding */ MistralPreTrainedModel),\n/* harmony export */   MobileBertForMaskedLM: () => (/* binding */ MobileBertForMaskedLM),\n/* harmony export */   MobileBertForQuestionAnswering: () => (/* binding */ MobileBertForQuestionAnswering),\n/* harmony export */   MobileBertForSequenceClassification: () => (/* binding */ MobileBertForSequenceClassification),\n/* harmony export */   MobileBertModel: () => (/* binding */ MobileBertModel),\n/* harmony export */   MobileBertPreTrainedModel: () => (/* binding */ MobileBertPreTrainedModel),\n/* harmony export */   MobileViTForImageClassification: () => (/* binding */ MobileViTForImageClassification),\n/* harmony export */   MobileViTModel: () => (/* binding */ MobileViTModel),\n/* harmony export */   MobileViTPreTrainedModel: () => (/* binding */ MobileViTPreTrainedModel),\n/* harmony export */   ModelOutput: () => (/* binding */ ModelOutput),\n/* harmony export */   MptForCausalLM: () => (/* binding */ MptForCausalLM),\n/* harmony export */   MptModel: () => (/* binding */ MptModel),\n/* harmony export */   MptPreTrainedModel: () => (/* binding */ MptPreTrainedModel),\n/* harmony export */   NomicBertModel: () => (/* binding */ NomicBertModel),\n/* harmony export */   NomicBertPreTrainedModel: () => (/* binding */ NomicBertPreTrainedModel),\n/* harmony export */   OPTForCausalLM: () => (/* binding */ OPTForCausalLM),\n/* harmony export */   OPTModel: () => (/* binding */ OPTModel),\n/* harmony export */   OPTPreTrainedModel: () => (/* binding */ OPTPreTrainedModel),\n/* harmony export */   OwlViTForObjectDetection: () => (/* binding */ OwlViTForObjectDetection),\n/* harmony export */   OwlViTModel: () => (/* binding */ OwlViTModel),\n/* harmony export */   OwlViTPreTrainedModel: () => (/* binding */ OwlViTPreTrainedModel),\n/* harmony export */   Owlv2ForObjectDetection: () => (/* binding */ Owlv2ForObjectDetection),\n/* harmony export */   Owlv2Model: () => (/* binding */ Owlv2Model),\n/* harmony export */   Owlv2PreTrainedModel: () => (/* binding */ Owlv2PreTrainedModel),\n/* harmony export */   PhiForCausalLM: () => (/* binding */ PhiForCausalLM),\n/* harmony export */   PhiModel: () => (/* binding */ PhiModel),\n/* harmony export */   PhiPreTrainedModel: () => (/* binding */ PhiPreTrainedModel),\n/* harmony export */   PreTrainedModel: () => (/* binding */ PreTrainedModel),\n/* harmony export */   PretrainedMixin: () => (/* binding */ PretrainedMixin),\n/* harmony export */   QuestionAnsweringModelOutput: () => (/* binding */ QuestionAnsweringModelOutput),\n/* harmony export */   Qwen2ForCausalLM: () => (/* binding */ Qwen2ForCausalLM),\n/* harmony export */   Qwen2Model: () => (/* binding */ Qwen2Model),\n/* harmony export */   Qwen2PreTrainedModel: () => (/* binding */ Qwen2PreTrainedModel),\n/* harmony export */   ResNetForImageClassification: () => (/* binding */ ResNetForImageClassification),\n/* harmony export */   ResNetModel: () => (/* binding */ ResNetModel),\n/* harmony export */   ResNetPreTrainedModel: () => (/* binding */ ResNetPreTrainedModel),\n/* harmony export */   RoFormerForMaskedLM: () => (/* binding */ RoFormerForMaskedLM),\n/* harmony export */   RoFormerForQuestionAnswering: () => (/* binding */ RoFormerForQuestionAnswering),\n/* harmony export */   RoFormerForSequenceClassification: () => (/* binding */ RoFormerForSequenceClassification),\n/* harmony export */   RoFormerForTokenClassification: () => (/* binding */ RoFormerForTokenClassification),\n/* harmony export */   RoFormerModel: () => (/* binding */ RoFormerModel),\n/* harmony export */   RoFormerPreTrainedModel: () => (/* binding */ RoFormerPreTrainedModel),\n/* harmony export */   RobertaForMaskedLM: () => (/* binding */ RobertaForMaskedLM),\n/* harmony export */   RobertaForQuestionAnswering: () => (/* binding */ RobertaForQuestionAnswering),\n/* harmony export */   RobertaForSequenceClassification: () => (/* binding */ RobertaForSequenceClassification),\n/* harmony export */   RobertaForTokenClassification: () => (/* binding */ RobertaForTokenClassification),\n/* harmony export */   RobertaModel: () => (/* binding */ RobertaModel),\n/* harmony export */   RobertaPreTrainedModel: () => (/* binding */ RobertaPreTrainedModel),\n/* harmony export */   SamImageSegmentationOutput: () => (/* binding */ SamImageSegmentationOutput),\n/* harmony export */   SamModel: () => (/* binding */ SamModel),\n/* harmony export */   SamPreTrainedModel: () => (/* binding */ SamPreTrainedModel),\n/* harmony export */   SegformerForImageClassification: () => (/* binding */ SegformerForImageClassification),\n/* harmony export */   SegformerForSemanticSegmentation: () => (/* binding */ SegformerForSemanticSegmentation),\n/* harmony export */   SegformerModel: () => (/* binding */ SegformerModel),\n/* harmony export */   SegformerPreTrainedModel: () => (/* binding */ SegformerPreTrainedModel),\n/* harmony export */   Seq2SeqLMOutput: () => (/* binding */ Seq2SeqLMOutput),\n/* harmony export */   SequenceClassifierOutput: () => (/* binding */ SequenceClassifierOutput),\n/* harmony export */   SiglipModel: () => (/* binding */ SiglipModel),\n/* harmony export */   SiglipPreTrainedModel: () => (/* binding */ SiglipPreTrainedModel),\n/* harmony export */   SiglipTextModel: () => (/* binding */ SiglipTextModel),\n/* harmony export */   SiglipVisionModel: () => (/* binding */ SiglipVisionModel),\n/* harmony export */   SpeechT5ForSpeechToText: () => (/* binding */ SpeechT5ForSpeechToText),\n/* harmony export */   SpeechT5ForTextToSpeech: () => (/* binding */ SpeechT5ForTextToSpeech),\n/* harmony export */   SpeechT5HifiGan: () => (/* binding */ SpeechT5HifiGan),\n/* harmony export */   SpeechT5Model: () => (/* binding */ SpeechT5Model),\n/* harmony export */   SpeechT5PreTrainedModel: () => (/* binding */ SpeechT5PreTrainedModel),\n/* harmony export */   SqueezeBertForMaskedLM: () => (/* binding */ SqueezeBertForMaskedLM),\n/* harmony export */   SqueezeBertForQuestionAnswering: () => (/* binding */ SqueezeBertForQuestionAnswering),\n/* harmony export */   SqueezeBertForSequenceClassification: () => (/* binding */ SqueezeBertForSequenceClassification),\n/* harmony export */   SqueezeBertModel: () => (/* binding */ SqueezeBertModel),\n/* harmony export */   SqueezeBertPreTrainedModel: () => (/* binding */ SqueezeBertPreTrainedModel),\n/* harmony export */   Swin2SRForImageSuperResolution: () => (/* binding */ Swin2SRForImageSuperResolution),\n/* harmony export */   Swin2SRModel: () => (/* binding */ Swin2SRModel),\n/* harmony export */   Swin2SRPreTrainedModel: () => (/* binding */ Swin2SRPreTrainedModel),\n/* harmony export */   SwinForImageClassification: () => (/* binding */ SwinForImageClassification),\n/* harmony export */   SwinModel: () => (/* binding */ SwinModel),\n/* harmony export */   SwinPreTrainedModel: () => (/* binding */ SwinPreTrainedModel),\n/* harmony export */   T5ForConditionalGeneration: () => (/* binding */ T5ForConditionalGeneration),\n/* harmony export */   T5Model: () => (/* binding */ T5Model),\n/* harmony export */   T5PreTrainedModel: () => (/* binding */ T5PreTrainedModel),\n/* harmony export */   TableTransformerForObjectDetection: () => (/* binding */ TableTransformerForObjectDetection),\n/* harmony export */   TableTransformerModel: () => (/* binding */ TableTransformerModel),\n/* harmony export */   TableTransformerObjectDetectionOutput: () => (/* binding */ TableTransformerObjectDetectionOutput),\n/* harmony export */   TableTransformerPreTrainedModel: () => (/* binding */ TableTransformerPreTrainedModel),\n/* harmony export */   TokenClassifierOutput: () => (/* binding */ TokenClassifierOutput),\n/* harmony export */   TrOCRForCausalLM: () => (/* binding */ TrOCRForCausalLM),\n/* harmony export */   TrOCRPreTrainedModel: () => (/* binding */ TrOCRPreTrainedModel),\n/* harmony export */   ViTForImageClassification: () => (/* binding */ ViTForImageClassification),\n/* harmony export */   ViTModel: () => (/* binding */ ViTModel),\n/* harmony export */   ViTPreTrainedModel: () => (/* binding */ ViTPreTrainedModel),\n/* harmony export */   VisionEncoderDecoderModel: () => (/* binding */ VisionEncoderDecoderModel),\n/* harmony export */   VitMatteForImageMatting: () => (/* binding */ VitMatteForImageMatting),\n/* harmony export */   VitMattePreTrainedModel: () => (/* binding */ VitMattePreTrainedModel),\n/* harmony export */   VitsModel: () => (/* binding */ VitsModel),\n/* harmony export */   VitsModelOutput: () => (/* binding */ VitsModelOutput),\n/* harmony export */   VitsPreTrainedModel: () => (/* binding */ VitsPreTrainedModel),\n/* harmony export */   Wav2Vec2BertForCTC: () => (/* binding */ Wav2Vec2BertForCTC),\n/* harmony export */   Wav2Vec2BertForSequenceClassification: () => (/* binding */ Wav2Vec2BertForSequenceClassification),\n/* harmony export */   Wav2Vec2BertModel: () => (/* binding */ Wav2Vec2BertModel),\n/* harmony export */   Wav2Vec2BertPreTrainedModel: () => (/* binding */ Wav2Vec2BertPreTrainedModel),\n/* harmony export */   Wav2Vec2ForCTC: () => (/* binding */ Wav2Vec2ForCTC),\n/* harmony export */   Wav2Vec2ForSequenceClassification: () => (/* binding */ Wav2Vec2ForSequenceClassification),\n/* harmony export */   Wav2Vec2Model: () => (/* binding */ Wav2Vec2Model),\n/* harmony export */   Wav2Vec2PreTrainedModel: () => (/* binding */ Wav2Vec2PreTrainedModel),\n/* harmony export */   WavLMForCTC: () => (/* binding */ WavLMForCTC),\n/* harmony export */   WavLMForSequenceClassification: () => (/* binding */ WavLMForSequenceClassification),\n/* harmony export */   WavLMModel: () => (/* binding */ WavLMModel),\n/* harmony export */   WavLMPreTrainedModel: () => (/* binding */ WavLMPreTrainedModel),\n/* harmony export */   WhisperForConditionalGeneration: () => (/* binding */ WhisperForConditionalGeneration),\n/* harmony export */   WhisperModel: () => (/* binding */ WhisperModel),\n/* harmony export */   WhisperPreTrainedModel: () => (/* binding */ WhisperPreTrainedModel),\n/* harmony export */   XLMForQuestionAnswering: () => (/* binding */ XLMForQuestionAnswering),\n/* harmony export */   XLMForSequenceClassification: () => (/* binding */ XLMForSequenceClassification),\n/* harmony export */   XLMForTokenClassification: () => (/* binding */ XLMForTokenClassification),\n/* harmony export */   XLMModel: () => (/* binding */ XLMModel),\n/* harmony export */   XLMPreTrainedModel: () => (/* binding */ XLMPreTrainedModel),\n/* harmony export */   XLMRobertaForMaskedLM: () => (/* binding */ XLMRobertaForMaskedLM),\n/* harmony export */   XLMRobertaForQuestionAnswering: () => (/* binding */ XLMRobertaForQuestionAnswering),\n/* harmony export */   XLMRobertaForSequenceClassification: () => (/* binding */ XLMRobertaForSequenceClassification),\n/* harmony export */   XLMRobertaForTokenClassification: () => (/* binding */ XLMRobertaForTokenClassification),\n/* harmony export */   XLMRobertaModel: () => (/* binding */ XLMRobertaModel),\n/* harmony export */   XLMRobertaPreTrainedModel: () => (/* binding */ XLMRobertaPreTrainedModel),\n/* harmony export */   XLMWithLMHeadModel: () => (/* binding */ XLMWithLMHeadModel),\n/* harmony export */   YolosForObjectDetection: () => (/* binding */ YolosForObjectDetection),\n/* harmony export */   YolosModel: () => (/* binding */ YolosModel),\n/* harmony export */   YolosObjectDetectionOutput: () => (/* binding */ YolosObjectDetectionOutput),\n/* harmony export */   YolosPreTrainedModel: () => (/* binding */ YolosPreTrainedModel)\n/* harmony export */ });\n/* harmony import */ var _configs_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./configs.js */ \"./node_modules/@xenova/transformers/src/configs.js\");\n/* harmony import */ var _utils_core_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./utils/core.js */ \"./node_modules/@xenova/transformers/src/utils/core.js\");\n/* harmony import */ var _utils_hub_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./utils/hub.js */ \"./node_modules/@xenova/transformers/src/utils/hub.js\");\n/* harmony import */ var _utils_generation_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./utils/generation.js */ \"./node_modules/@xenova/transformers/src/utils/generation.js\");\n/* harmony import */ var _utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./utils/tensor.js */ \"./node_modules/@xenova/transformers/src/utils/tensor.js\");\n/* harmony import */ var _backends_onnx_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./backends/onnx.js */ \"./node_modules/@xenova/transformers/src/backends/onnx.js\");\n/* harmony import */ var _transformers_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./transformers.js */ \"./node_modules/@xenova/transformers/src/transformers.js\");\n\n/**\n * @file Definitions of all models available in Transformers.js.\n * \n * **Example:** Load and run an `AutoModel`.\n * \n * ```javascript\n * import { AutoModel, AutoTokenizer } from '@xenova/transformers';\n *\n * let tokenizer = await AutoTokenizer.from_pretrained('Xenova/bert-base-uncased');\n * let model = await AutoModel.from_pretrained('Xenova/bert-base-uncased');\n *\n * let inputs = await tokenizer('I love transformers!');\n * let { logits } = await model(inputs);\n * // Tensor {\n * //     data: Float32Array(183132) [-7.117443084716797, -7.107812881469727, -7.092104911804199, ...]\n * //     dims: (3) [1, 6, 30522],\n * //     type: \"float32\",\n * //     size: 183132,\n * // }\n * ```\n * \n * We also provide other `AutoModel`s (listed below), which you can use in the same way as the Python library. For example:\n * \n * **Example:** Load and run an `AutoModelForSeq2SeqLM`.\n * ```javascript\n * import { AutoModelForSeq2SeqLM, AutoTokenizer } from '@xenova/transformers';\n * \n * let tokenizer = await AutoTokenizer.from_pretrained('Xenova/t5-small');\n * let model = await AutoModelForSeq2SeqLM.from_pretrained('Xenova/t5-small');\n *\n * let { input_ids } = await tokenizer('translate English to German: I love transformers!');\n * let outputs = await model.generate(input_ids);\n * let decoded = tokenizer.decode(outputs[0], { skip_special_tokens: true });\n * // 'Ich liebe Transformatoren!'\n * ```\n * \n * @module models\n */\n\n\n\n\n\n\n\n\n\n\n\n\n\nconst { InferenceSession, Tensor: ONNXTensor, env } = _backends_onnx_js__WEBPACK_IMPORTED_MODULE_5__.ONNX;\n\n/** @typedef {import('onnxruntime-web').InferenceSession} InferenceSession */\n\n//////////////////////////////////////////////////\n// Model types: used internally\nconst MODEL_TYPES = {\n    EncoderOnly: 0,\n    EncoderDecoder: 1,\n    Seq2Seq: 2,\n    Vision2Seq: 3,\n    DecoderOnly: 4,\n    MaskGeneration: 5,\n}\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// Helper functions\n\n// NOTE: These will be populated fully later\nconst MODEL_TYPE_MAPPING = new Map();\nconst MODEL_NAME_TO_CLASS_MAPPING = new Map();\nconst MODEL_CLASS_TO_NAME_MAPPING = new Map();\n\n\n/**\n * Constructs an InferenceSession using a model file located at the specified path.\n * @param {string} pretrained_model_name_or_path The path to the directory containing the model file.\n * @param {string} fileName The name of the model file.\n * @param {import('./utils/hub.js').PretrainedOptions} options Additional options for loading the model.\n * @returns {Promise<InferenceSession>} A Promise that resolves to an InferenceSession object.\n * @private\n */\nasync function constructSession(pretrained_model_name_or_path, fileName, options) {\n    // TODO add option for user to force specify their desired execution provider\n    let modelFileName = `onnx/${fileName}${options.quantized ? '_quantized' : ''}.onnx`;\n    let buffer = await (0,_utils_hub_js__WEBPACK_IMPORTED_MODULE_2__.getModelFile)(pretrained_model_name_or_path, modelFileName, true, options);\n\n    try {\n        return await InferenceSession.create(buffer, {\n            executionProviders: _backends_onnx_js__WEBPACK_IMPORTED_MODULE_5__.executionProviders,\n        });\n    } catch (err) {\n        // If the execution provided was only wasm, throw the error\n        if (_backends_onnx_js__WEBPACK_IMPORTED_MODULE_5__.executionProviders.length === 1 && _backends_onnx_js__WEBPACK_IMPORTED_MODULE_5__.executionProviders[0] === 'wasm') {\n            throw err;\n        }\n\n        console.warn(err);\n        console.warn(\n            'Something went wrong during model construction (most likely a missing operation). ' +\n            'Using `wasm` as a fallback. '\n        )\n        return await InferenceSession.create(buffer, {\n            executionProviders: ['wasm']\n        });\n    }\n}\n\n/**\n * Validate model inputs\n * @param {InferenceSession} session The InferenceSession object that will be run.\n * @param {Record<string, Tensor>} inputs The inputs to check.\n * @returns {Record<string, Tensor>} The checked inputs.\n * @throws {Error} If any inputs are missing.\n * @private\n */\nfunction validateInputs(session, inputs) {\n    /**\n     * NOTE: Create either a shallow or deep copy based on `onnx.wasm.proxy`\n     * @type {Record<string, Tensor>}\n     */\n    const checkedInputs = Object.create(null);\n    const missingInputs = [];\n    for (const inputName of session.inputNames) {\n        const tensor = inputs[inputName];\n        // Rare case where one of the model's input names corresponds to a built-in\n        // object name (e.g., toString), which would cause a simple (!tensor) check to fail,\n        // because it's not undefined but a function.\n        if (!(tensor instanceof _utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.Tensor)) {\n            missingInputs.push(inputName);\n            continue;\n        }\n        // NOTE: When `env.wasm.proxy is true` the tensor is moved across the Worker\n        // boundary, transferring ownership to the worker and invalidating the tensor.\n        // So, in this case, we simply sacrifice a clone for it.\n        checkedInputs[inputName] = env.wasm.proxy ? tensor.clone() : tensor;\n    }\n    if (missingInputs.length > 0) {\n        throw new Error(\n            `An error occurred during model execution: \"Missing the following inputs: ${missingInputs.join(', ')}.`);\n    }\n\n    const numInputsProvided = Object.keys(inputs).length;\n    const numInputsNeeded = session.inputNames.length;\n    if (numInputsProvided > numInputsNeeded) {\n        // No missing inputs, but too many inputs were provided.\n        // Warn the user and ignore the extra inputs.\n        let ignored = Object.keys(inputs).filter(inputName => !session.inputNames.includes(inputName));\n        console.warn(`WARNING: Too many inputs were provided (${numInputsProvided} > ${numInputsNeeded}). The following inputs will be ignored: \"${ignored.join(', ')}\".`);\n    }\n\n    return checkedInputs;\n}\n\n/**\n * Executes an InferenceSession using the specified inputs.\n * NOTE: `inputs` must contain at least the input names of the model.\n *  - If additional inputs are passed, they will be ignored.\n *  - If inputs are missing, an error will be thrown.\n * \n * @param {InferenceSession} session The InferenceSession object to run.\n * @param {Object} inputs An object that maps input names to input tensors.\n * @returns {Promise<Object>} A Promise that resolves to an object that maps output names to output tensors.\n * @private\n */\nasync function sessionRun(session, inputs) {\n    const checkedInputs = validateInputs(session, inputs);\n    try {\n        // @ts-ignore\n        let output = await session.run(checkedInputs);\n        output = replaceTensors(output);\n        return output;\n    } catch (e) {\n        // This usually occurs when the inputs are of the wrong type.\n        console.error(`An error occurred during model execution: \"${e}\".`);\n        console.error('Inputs given to model:', checkedInputs);\n        throw e;\n    }\n}\n\n/**\n * Replaces ONNX Tensor objects with custom Tensor objects to support additional functions.\n * @param {Object} obj The object to replace tensor objects in.\n * @returns {Object} The object with tensor objects replaced by custom Tensor objects.\n * @private\n */\nfunction replaceTensors(obj) {\n    for (let prop in obj) {\n        if (obj[prop] instanceof ONNXTensor) {\n            obj[prop] = new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.Tensor(obj[prop]);\n        } else if (typeof obj[prop] === 'object') {\n            replaceTensors(obj[prop]);\n        }\n    }\n    return obj;\n}\n\n\n/**\n * Converts an array or Tensor of integers to an int64 Tensor.\n * @param {Array|Tensor} items The input integers to be converted.\n * @returns {Tensor} The int64 Tensor with the converted values.\n * @throws {Error} If the input array is empty or the input is a batched Tensor and not all sequences have the same length.\n * @private\n */\nfunction toI64Tensor(items) {\n    if (items instanceof _utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.Tensor) {\n        return items;\n    }\n    // items is an array\n    if (items.length === 0) {\n        throw Error(\"items must be non-empty\");\n    }\n\n    if (Array.isArray(items[0])) {\n        // batched\n        if (items.some(x => x.length !== items[0].length)) {\n            throw Error(\"Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' and/or 'truncation=True' to have batched tensors with the same length.\")\n        }\n\n        return new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.Tensor('int64',\n            BigInt64Array.from(items.flat().map(x => BigInt(x))),\n            [items.length, items[0].length]\n        );\n    } else {\n        //flat\n        return new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.Tensor('int64',\n            BigInt64Array.from(items.map(x => BigInt(x))),\n            [1, items.length]\n        );\n    }\n}\n\n/**\n * Prepares an attention mask for a sequence of tokens based on configuration options.\n * @param {Object} self The calling object instance.\n * @param {Tensor} tokens The input tokens.\n * @returns {Tensor} The attention mask tensor.\n * @private\n */\nfunction prepareAttentionMask(self, tokens) {\n\n    // Prepare attention mask\n    let pad_token_id = self.config.pad_token_id ?? null;\n    let eos_token_id = self.config.eos_token_id ?? null;\n    if ((0,_utils_core_js__WEBPACK_IMPORTED_MODULE_1__.isIntegralNumber)(eos_token_id)) {\n        eos_token_id = [eos_token_id];\n    }\n\n    let is_pad_token_in_inputs = tokens.indexOf(pad_token_id) !== -1;\n    let is_pad_token_not_equal_to_eos_token_id = (eos_token_id === null) || !eos_token_id.includes(pad_token_id)\n\n    if (is_pad_token_in_inputs && is_pad_token_not_equal_to_eos_token_id) {\n        let data = BigInt64Array.from(\n            // Note: != so that int matches bigint\n            // @ts-ignore\n            tokens.data.map(x => x != pad_token_id)\n        )\n        return new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.Tensor('int64', data, tokens.dims)\n    } else {\n        return (0,_utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.ones_like)(tokens);\n    }\n}\n\n/**\n * Add position IDs to the feeds object.\n * @param {Object} session The inference session.\n * @param {Object} feeds The input to the model.\n * @param {boolean} use_cache_branch Whether to use the cache branch of the model.\n * @returns {void}\n * @private\n */\nfunction preparePositionIds(session, feeds, use_cache_branch) {\n    if (!session.inputNames.includes('position_ids')) return;\n\n    const data = new BigInt64Array(feeds.attention_mask.data.length);\n\n    // Compute cumulative sum of the attention mask along the sequence length dimension\n    for (let i = 0; i < feeds.attention_mask.dims[0]; ++i) {\n        let start = i * feeds.attention_mask.dims[1];\n        let sum = BigInt(0);\n        for (let j = 0; j < feeds.attention_mask.dims[1]; ++j) {\n            const index = start + j;\n            if (feeds.attention_mask.data[index] === 0n) {\n                data[index] = BigInt(1);\n            } else { // === 1n\n                data[index] = sum;\n                sum += feeds.attention_mask.data[index];\n            }\n        }\n    }\n\n    feeds.position_ids = new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.Tensor('int64', data, feeds.attention_mask.dims);\n\n    if (use_cache_branch) {\n        feeds.position_ids = feeds.position_ids.slice(null, -1).unsqueeze_(-1);\n    }\n}\n\n/**\n * Creates a boolean tensor with a single value.\n * @param {boolean} value The value of the tensor.\n * @returns {Tensor} The boolean tensor.\n * @private\n */\nfunction boolTensor(value) {\n    return new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.Tensor('bool', [value], [1]);\n}\n\n// JS doesn't support mixins, so we define some reused functions here, and allow \"this\" to be passed in\n/**\n * Perform forward pass on the seq2seq model (both encoder and decoder).\n * @param {Object} self The seq2seq model object.\n * @param {Object} model_inputs The input object for the model containing encoder and decoder inputs.\n * @returns {Promise<Seq2SeqLMOutput>} Promise that resolves with the output of the seq2seq model.\n * @private\n */\nasync function seq2seqForward(self, model_inputs) {\n\n    let { encoder_outputs, past_key_values } = model_inputs;\n\n    if (!encoder_outputs) {\n        // Encoder outputs are not given, so we must compute them.\n        encoder_outputs = (await encoderForward(self, model_inputs)).last_hidden_state;\n    }\n    let decoderFeeds = {\n        input_ids: model_inputs.decoder_input_ids,\n        encoder_hidden_states: encoder_outputs,\n    };\n    const use_cache_branch = !!past_key_values;\n\n    if (self.decoder_merged_session.inputNames.includes('use_cache_branch')) {\n        decoderFeeds.use_cache_branch = boolTensor(use_cache_branch);\n    }\n\n    if (self.decoder_merged_session.inputNames.includes('encoder_attention_mask')) {\n        decoderFeeds.encoder_attention_mask = model_inputs.attention_mask\n    }\n\n    preparePositionIds(self.decoder_merged_session, decoderFeeds, use_cache_branch);\n    self.addPastKeyValues(decoderFeeds, past_key_values);\n\n    const decoderResults = await sessionRun(self.decoder_merged_session, decoderFeeds);\n    let logits = decoderResults.logits;\n    past_key_values = self.getPastKeyValues(decoderResults, past_key_values);\n\n    // Get cross attention and/or decoder attentions if they are present\n    const attns = self.getAttentions(decoderResults);\n\n    return new Seq2SeqLMOutput({ logits, past_key_values, encoder_outputs, ...attns });\n}\n\n/**\n * Start the beam search process for the seq2seq model.\n * @param {PreTrainedModel} self The seq2seq model object.\n * @param {Tensor} inputTokenIds Array of input token ids for each input sequence.\n * @param {Object} generation_config The generation config.\n * @param {number} numOutputTokens The maximum number of output tokens for the model.\n * @returns {Object[]} Array of beam search objects.\n * @private\n */\nfunction seq2seqStartBeams(self, inputTokenIds, generation_config, numOutputTokens) {\n    let beams = [];\n    let beamId = 0;\n\n    // @ts-ignore\n    const requires_attention_mask = self.requires_attention_mask ?? true;\n\n    // decoder_input_ids == output_token_ids\n    let decoder_input_ids =\n        generation_config.decoder_input_ids\n        ?? generation_config.decoder_start_token_id\n        ?? generation_config.bos_token_id\n        ?? generation_config.eos_token_id;\n\n    // Support input as tensor or list\n    // TODO support batched decoder_input_ids\n    if (decoder_input_ids instanceof _utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.Tensor) {\n        decoder_input_ids = decoder_input_ids.tolist().flat();\n    } else if (!Array.isArray(decoder_input_ids)) {\n        decoder_input_ids = [decoder_input_ids];\n    }\n\n    for (let tokens of inputTokenIds) {\n        // TODO: Improve\n        // Currently, just add back batch dimension.\n        // In future, allow for true parallel execution\n        tokens.dims = [1, ...tokens.dims]\n\n        // Create beam\n        let start = {\n            inputs: tokens,\n            encoder_outputs: null,\n            prev_model_outputs: null,\n\n            output_token_ids: decoder_input_ids,\n            done: false,\n            score: 0,\n            id: beamId++ // assign unique id to beams\n        }\n\n        if (requires_attention_mask) {\n            start.attention_mask = prepareAttentionMask(self, tokens);\n        }\n\n        beams.push(start);\n    }\n\n    return beams;\n}\n\n/**\n * Run beam search on the seq2seq model for a single beam.\n * @param {PreTrainedModel} self The seq2seq model object.\n * @param {Object} beam The beam search object for which to run the model.\n * @param {Object} options options\n * @param {string} [options.input_name='input_ids'] The name of the input tensor for the encoder.\n * @returns {Promise<Object>} Promise that resolves with the output of the seq2seq model for the given beam.\n * @private\n */\nasync function seq2seqRunBeam(self, beam) {\n    const input_name = self.main_input_name;\n\n    let decoder_input_ids = beam.output_token_ids;\n    if (beam.prev_model_outputs) {\n        // After the first step, `prev_model_outputs` won't be null.\n        // So, we cut decoder_input_ids if past is used\n        decoder_input_ids = decoder_input_ids.slice(-1);\n    }\n\n    // 1. Prepare\n    let model_inputs = {\n        [input_name]: beam.inputs,\n        decoder_input_ids: toI64Tensor(decoder_input_ids),\n        encoder_outputs: beam.encoder_outputs,\n        past_key_values: beam.prev_model_outputs?.past_key_values,\n    }\n    if (beam.attention_mask) {\n        model_inputs.attention_mask = beam.attention_mask\n    }\n\n    // 2. Run\n    let output = await self.forward(model_inputs);\n\n    // 3. Update\n    beam.prev_model_outputs = output;\n    beam.encoder_outputs = output.encoder_outputs;\n\n    return output;\n}\n\n/**\n * Update a beam with a new token ID.\n * @param {Object} beam The beam to update.\n * @param {number} newTokenId The new token ID to add to the beam's output.\n * @private\n */\nfunction seq2seqUpdatebeam(beam, newTokenId) {\n    beam.output_token_ids = [...beam.output_token_ids, newTokenId];\n}\n\n/**\n * Forward pass of an encoder model.\n * @param {Object} self The encoder model.\n * @param {Object} model_inputs The input data to be used for the forward pass.\n * @returns {Promise<Object>} Promise that resolves with an object containing the model's outputs.\n * @private\n */\nasync function encoderForward(self, model_inputs) {\n    const encoderFeeds = Object.create(null);\n    for (const key of self.session.inputNames) {\n        encoderFeeds[key] = model_inputs[key];\n    }\n    if (self.session.inputNames.includes('token_type_ids') && !encoderFeeds.token_type_ids) {\n        // Assign default `token_type_ids` (all zeroes) to the `encoderFeeds` if the model expects it,\n        // but they weren't created by the tokenizer.\n        encoderFeeds.token_type_ids = new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.Tensor(\n            'int64',\n            new BigInt64Array(encoderFeeds.input_ids.data.length),\n            encoderFeeds.input_ids.dims\n        )\n    }\n    return await sessionRun(self.session, encoderFeeds);\n}\n\n\n/**\n * Forward pass of a decoder model.\n * @param {Object} self The decoder model.\n * @param {Object} model_inputs The input data to be used for the forward pass.\n * @returns {Promise<Object>} Promise that resolves with an object containing the logits and past key values.\n * @private\n */\nasync function decoderForward(self, model_inputs) {\n    let { input_ids, past_key_values, attention_mask } = model_inputs;\n    let decoderFeeds = {\n        input_ids: input_ids,\n        attention_mask: attention_mask ?? prepareAttentionMask(self, input_ids),\n    }\n    const use_cache_branch = !!past_key_values;\n\n    if (self.session.inputNames.includes('use_cache_branch')) {\n        decoderFeeds.use_cache_branch = boolTensor(use_cache_branch);\n    }\n\n    preparePositionIds(self.session, decoderFeeds, use_cache_branch);\n\n    self.addPastKeyValues(decoderFeeds, past_key_values);\n\n    let decoderResults = await sessionRun(self.session, decoderFeeds);\n\n    let logits = decoderResults.logits;\n\n    past_key_values = self.getPastKeyValues(decoderResults, past_key_values);\n    return { logits, past_key_values };\n}\n\n/**\n * Starts the generation of text by initializing the beams for the given input token IDs.\n * @param {Object} self The text generation model object.\n * @param {Tensor} inputTokenIds An tensor of input token IDs to generate text from.\n * @param {Object} generation_config The generation config.\n * @param {number} numOutputTokens The maximum number of tokens to generate for each beam.\n * @param {Tensor} [inputs_attention_mask] The attention mask tensor for the input token IDs.\n * @returns {Object[]} An array of beams initialized with the given inputs and parameters.\n * @private\n */\nfunction decoderStartBeams(self, inputTokenIds, generation_config, numOutputTokens, inputs_attention_mask) {\n    let beams = [];\n\n    let beamId = 0;\n    for (let tokens of inputTokenIds) {\n        let output_token_ids = tokens.tolist().map(Number);\n\n        // TODO: Improve\n        // Currently, just add back batch dimension.\n        // In future, allow for true parallel execution\n        tokens.dims = [1, ...tokens.dims]\n\n        let attn_mask;\n        if (inputs_attention_mask) {\n            attn_mask = inputs_attention_mask[beamId];\n            attn_mask.dims = [1, ...attn_mask.dims]\n\n        } else {\n            attn_mask = prepareAttentionMask(self, tokens)\n        }\n\n        let start = {\n            input: tokens,\n            model_input_ids: tokens,\n            attention_mask: attn_mask,\n            prev_model_outputs: null,\n\n            output_token_ids: output_token_ids,\n            num_output_tokens: numOutputTokens,\n\n            done: false,\n            score: 0,\n            id: beamId++ // assign unique id to beams\n        }\n\n        beams.push(start);\n    }\n    return beams;\n}\n\n/**\n * Runs a single step of the text generation process for a given beam.\n *\n * @param {Object} self The decoder object.\n * @param {Object} beam The beam to run.\n * @param {Tensor} beam.input The input tensor.\n * @param {Tensor} beam.model_input_ids The input ids to the model.\n * @param {Tensor} beam.attention_mask The attention mask.\n * @param {Object} beam.prev_model_outputs The past key values.\n * @param {number[]} beam.output_token_ids The output token ids.\n * @returns {Promise<Object>} The output of the generation step.\n * @private\n */\nasync function decoderRunBeam(self, beam) {\n    let attnMaskData = new BigInt64Array(beam.output_token_ids.length).fill(1n)\n\n    // 1. Prepare\n    let model_inputs = {\n        input_ids: beam.model_input_ids,\n        attention_mask: new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.Tensor(\n            'int64',\n            attnMaskData,\n            [1, attnMaskData.length]\n        ),\n        past_key_values: beam.prev_model_outputs?.past_key_values,\n    }\n\n    // 2. Run\n    let output = await self.forward(model_inputs);\n\n    // 3. Update\n    beam.prev_model_outputs = output;\n\n    return output;\n}\n\n/**\n * Update a beam with a new token ID.\n * @param {Object} beam The beam to update.\n * @param {number} newTokenId The new token ID to add to the beam's output.\n * @private\n */\nfunction decoderUpdatebeam(beam, newTokenId) {\n    beam.output_token_ids = [...beam.output_token_ids, newTokenId];\n    beam.model_input_ids = new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.Tensor('int64', [BigInt(newTokenId)], [1, 1]);\n}\n\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n/**\n * A base class for pre-trained models that provides the model configuration and an ONNX session.\n */\nclass PreTrainedModel extends _utils_core_js__WEBPACK_IMPORTED_MODULE_1__.Callable {\n    main_input_name = 'input_ids';\n\n    /**\n     * Creates a new instance of the `PreTrainedModel` class.\n     * @param {Object} config The model configuration.\n     * @param {any} session session for the model.\n     */\n    constructor(config, session) {\n        super();\n\n        this.config = config;\n        this.session = session;\n\n        const modelName = MODEL_CLASS_TO_NAME_MAPPING.get(this.constructor);\n        const modelType = MODEL_TYPE_MAPPING.get(modelName);\n\n        this.can_generate = false;\n        this._runBeam = null;\n        this._getStartBeams = null;\n        this._updateBeam = null;\n        this._forward = null;\n        if (modelType === MODEL_TYPES.DecoderOnly) {\n            this.can_generate = true;\n\n            this._runBeam = decoderRunBeam;\n            this._getStartBeams = decoderStartBeams;\n            this._updateBeam = decoderUpdatebeam;\n            this._forward = decoderForward;\n\n        } else if (modelType === MODEL_TYPES.Seq2Seq || modelType === MODEL_TYPES.Vision2Seq) {\n            this.can_generate = true;\n\n            this._runBeam = seq2seqRunBeam;\n            this._getStartBeams = seq2seqStartBeams;\n            this._updateBeam = seq2seqUpdatebeam;\n            this._forward = seq2seqForward;\n\n        } else if (modelType === MODEL_TYPES.EncoderDecoder) {\n            this._forward = encoderForward;\n\n        } else { // should be MODEL_TYPES.EncoderOnly\n            this._forward = encoderForward;\n        }\n    }\n\n    /**\n    * Disposes of all the ONNX sessions that were created during inference.\n    * @returns {Promise<unknown[]>} An array of promises, one for each ONNX session that is being disposed.\n    * @todo Use https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/FinalizationRegistry\n    */\n    async dispose() {\n        const promises = [];\n        for (let key of Object.keys(this)) {\n            const item = this[key];\n            // @ts-ignore\n            if (item instanceof InferenceSession) {\n                promises.push(item.handler.dispose())\n            }\n        }\n        return await Promise.all(promises);\n    }\n\n    /**\n     * Instantiate one of the model classes of the library from a pretrained model.\n     * \n     * The model class to instantiate is selected based on the `model_type` property of the config object\n     * (either passed as an argument or loaded from `pretrained_model_name_or_path` if possible)\n     * \n     * @param {string} pretrained_model_name_or_path The name or path of the pretrained model. Can be either:\n     * - A string, the *model id* of a pretrained model hosted inside a model repo on huggingface.co.\n     *   Valid model ids can be located at the root-level, like `bert-base-uncased`, or namespaced under a\n     *   user or organization name, like `dbmdz/bert-base-german-cased`.\n     * - A path to a *directory* containing model weights, e.g., `./my_model_directory/`.\n     * @param {import('./utils/hub.js').PretrainedOptions} options Additional options for loading the model.\n     * \n     * @returns {Promise<PreTrainedModel>} A new instance of the `PreTrainedModel` class.\n     */\n    static async from_pretrained(pretrained_model_name_or_path, {\n        quantized = true,\n        progress_callback = null,\n        config = null,\n        cache_dir = null,\n        local_files_only = false,\n        revision = 'main',\n        model_file_name = null,\n    } = {}) {\n\n        let options = {\n            quantized,\n            progress_callback,\n            config,\n            cache_dir,\n            local_files_only,\n            revision,\n            model_file_name,\n        }\n\n        const modelName = MODEL_CLASS_TO_NAME_MAPPING.get(this);\n        const modelType = MODEL_TYPE_MAPPING.get(modelName);\n\n        let info;\n        if (modelType === MODEL_TYPES.DecoderOnly) {\n            info = await Promise.all([\n                _configs_js__WEBPACK_IMPORTED_MODULE_0__.AutoConfig.from_pretrained(pretrained_model_name_or_path, options),\n                constructSession(pretrained_model_name_or_path, options.model_file_name ?? 'decoder_model_merged', options),\n                (0,_utils_hub_js__WEBPACK_IMPORTED_MODULE_2__.getModelJSON)(pretrained_model_name_or_path, 'generation_config.json', false, options),\n            ]);\n\n        } else if (modelType === MODEL_TYPES.Seq2Seq || modelType === MODEL_TYPES.Vision2Seq) {\n            info = await Promise.all([\n                _configs_js__WEBPACK_IMPORTED_MODULE_0__.AutoConfig.from_pretrained(pretrained_model_name_or_path, options),\n                constructSession(pretrained_model_name_or_path, 'encoder_model', options),\n                constructSession(pretrained_model_name_or_path, 'decoder_model_merged', options),\n                (0,_utils_hub_js__WEBPACK_IMPORTED_MODULE_2__.getModelJSON)(pretrained_model_name_or_path, 'generation_config.json', false, options),\n            ]);\n\n        } else if (modelType === MODEL_TYPES.MaskGeneration) {\n            info = await Promise.all([\n                _configs_js__WEBPACK_IMPORTED_MODULE_0__.AutoConfig.from_pretrained(pretrained_model_name_or_path, options),\n                constructSession(pretrained_model_name_or_path, 'vision_encoder', options),\n                constructSession(pretrained_model_name_or_path, 'prompt_encoder_mask_decoder', options),\n            ]);\n\n        } else if (modelType === MODEL_TYPES.EncoderDecoder) {\n            info = await Promise.all([\n                _configs_js__WEBPACK_IMPORTED_MODULE_0__.AutoConfig.from_pretrained(pretrained_model_name_or_path, options),\n                constructSession(pretrained_model_name_or_path, 'encoder_model', options),\n                constructSession(pretrained_model_name_or_path, 'decoder_model_merged', options),\n            ]);\n\n        } else { // should be MODEL_TYPES.EncoderOnly\n            if (modelType !== MODEL_TYPES.EncoderOnly) {\n                console.warn(`Model type for '${modelName ?? config?.model_type}' not found, assuming encoder-only architecture. Please report this at https://github.com/xenova/transformers.js/issues/new/choose.`)\n            }\n            info = await Promise.all([\n                _configs_js__WEBPACK_IMPORTED_MODULE_0__.AutoConfig.from_pretrained(pretrained_model_name_or_path, options),\n                constructSession(pretrained_model_name_or_path, options.model_file_name ?? 'model', options)\n            ]);\n        }\n\n        // @ts-ignore\n        return new this(...info);\n    }\n\n    /**\n     * Runs the model with the provided inputs\n     * @param {Object} model_inputs Object containing input tensors\n     * @returns {Promise<Object>} Object containing output tensors\n     */\n    async _call(model_inputs) {\n        return await this.forward(model_inputs);\n    }\n\n    /**\n     * Forward method for a pretrained model. If not overridden by a subclass, the correct forward method\n     * will be chosen based on the model type.\n     * @param {Object} model_inputs The input data to the model in the format specified in the ONNX model.\n     * @returns {Promise<Object>} The output data from the model in the format specified in the ONNX model.\n     * @throws {Error} This method must be implemented in subclasses.\n     */\n    async forward(model_inputs) {\n        return await this._forward(this, model_inputs);\n    }\n\n    /**\n     * @param {import('./utils/generation.js').GenerationConfigType} generation_config \n     * @param {number} input_ids_seq_length The starting sequence length for the input ids.\n     * @returns {LogitsProcessorList}\n     * @private\n     */\n    _get_logits_processor(\n        generation_config,\n        input_ids_seq_length,\n        // encoder_input_ids, TODO\n        // prefix_allowed_tokens_fn, TODO\n        logits_processor = null\n    ) {\n        const processors = new _utils_generation_js__WEBPACK_IMPORTED_MODULE_3__.LogitsProcessorList();\n\n        // if (generation_config.diversity_penalty !== null && generation_config.diversity_penalty > 0.0) {\n        //     processors.push(new HammingDiversityLogitsProcessor(\n        //         generation_config.diversity_penalty,\n        //         generation_config.num_beams,\n        //         generation_config.num_beam_groups\n        //     ));\n        // }\n\n        // if (generation_config.encoder_repetition_penalty !== null && generation_config.encoder_repetition_penalty !== 1.0) {\n        //     processors.push(new EncoderRepetitionPenaltyLogitsProcessor(\n        //         generation_config.encoder_repetition_penalty,\n        //         encoder_input_ids\n        //     ));\n        // }\n\n        if (generation_config.repetition_penalty !== null && generation_config.repetition_penalty !== 1.0) {\n            processors.push(new _utils_generation_js__WEBPACK_IMPORTED_MODULE_3__.RepetitionPenaltyLogitsProcessor(generation_config.repetition_penalty));\n        }\n\n        if (generation_config.no_repeat_ngram_size !== null && generation_config.no_repeat_ngram_size > 0) {\n            processors.push(new _utils_generation_js__WEBPACK_IMPORTED_MODULE_3__.NoRepeatNGramLogitsProcessor(generation_config.no_repeat_ngram_size));\n        }\n\n        // if (generation_config.encoder_no_repeat_ngram_size !== null && generation_config.encoder_no_repeat_ngram_size > 0) {\n        //     if (this.config.is_encoder_decoder) {\n        //         processors.push(new EncoderNoRepeatNGramLogitsProcessor(\n        //             generation_config.encoder_no_repeat_ngram_size,\n        //             encoder_input_ids\n        //         ));\n        //     } else {\n        //         throw new Error(\"It's impossible to use `encoder_no_repeat_ngram_size` with decoder-only architecture\");\n        //     }\n        // }\n\n        if (generation_config.bad_words_ids !== null) {\n            processors.push(new _utils_generation_js__WEBPACK_IMPORTED_MODULE_3__.NoBadWordsLogitsProcessor(generation_config.bad_words_ids, generation_config.eos_token_id));\n        }\n\n        if (generation_config.min_length !== null && generation_config.eos_token_id !== null && generation_config.min_length > 0) {\n            processors.push(new _utils_generation_js__WEBPACK_IMPORTED_MODULE_3__.MinLengthLogitsProcessor(generation_config.min_length, generation_config.eos_token_id));\n        }\n\n        if (generation_config.min_new_tokens !== null && generation_config.eos_token_id !== null && generation_config.min_new_tokens > 0) {\n            processors.push(new _utils_generation_js__WEBPACK_IMPORTED_MODULE_3__.MinNewTokensLengthLogitsProcessor(\n                input_ids_seq_length,\n                generation_config.min_new_tokens,\n                generation_config.eos_token_id\n            ));\n        }\n\n        // if (prefix_allowed_tokens_fn !== null) {\n        //     processors.push(new PrefixConstrainedLogitsProcessor(\n        //         prefix_allowed_tokens_fn,\n        //         generation_config.num_beams / generation_config.num_beam_groups\n        //     ));\n        // }\n\n\n        if (generation_config.forced_bos_token_id !== null) {\n            processors.push(new _utils_generation_js__WEBPACK_IMPORTED_MODULE_3__.ForcedBOSTokenLogitsProcessor(generation_config.forced_bos_token_id));\n        }\n\n        if (generation_config.forced_eos_token_id !== null) {\n            processors.push(new _utils_generation_js__WEBPACK_IMPORTED_MODULE_3__.ForcedEOSTokenLogitsProcessor(\n                generation_config.max_length,\n                generation_config.forced_eos_token_id\n            ));\n        }\n\n        // if (generation_config.remove_invalid_values === true) {\n        //     processors.push(new InfNanRemoveLogitsProcessor());\n        // }\n\n        // if (generation_config.exponential_decay_length_penalty !== null) {\n        //     processors.push(new ExponentialDecayLengthPenalty(\n        //         generation_config.exponential_decay_length_penalty,\n        //         generation_config.eos_token_id,\n        //         input_ids_seq_length\n        //     ));\n        // }\n\n        // if (generation_config.suppress_tokens !== null) {\n        //     processors.push(new SuppressTokensLogitsProcessor(generation_config.suppress_tokens));\n        // }\n\n        if (generation_config.begin_suppress_tokens !== null) {\n            let begin_index = (input_ids_seq_length > 1 || generation_config.forced_bos_token_id === null)\n                ? input_ids_seq_length\n                : input_ids_seq_length + 1;\n\n            if (generation_config.forced_decoder_ids !== null) {\n                // generation starts after the last token that is forced\n                begin_index += generation_config.forced_decoder_ids[generation_config.forced_decoder_ids.length - 1][0];\n            }\n            processors.push(new _utils_generation_js__WEBPACK_IMPORTED_MODULE_3__.SuppressTokensAtBeginLogitsProcessor(generation_config.begin_suppress_tokens, begin_index));\n        }\n\n        if (generation_config.forced_decoder_ids !== null) {\n            processors.push(new _utils_generation_js__WEBPACK_IMPORTED_MODULE_3__.ForceTokensLogitsProcessor(generation_config.forced_decoder_ids));\n        }\n\n        if (logits_processor !== null) {\n            processors.extend(logits_processor)\n        }\n\n        // `LogitNormalization` should always be the last logit processor, when present\n        // if (generation_config.renormalize_logits === true) {\n        //     processors.push(new LogitNormalization());\n        // }\n\n        return processors;\n    }\n\n    /**\n     * This function merges multiple generation configs together to form a final generation config to be used by the model for text generation.\n     * It first creates an empty `GenerationConfig` object, then it applies the model's own `generation_config` property to it. Finally, if a `generation_config` object was passed in the arguments, it overwrites the corresponding properties in the final config with those of the passed config object.\n     * @param {import('./utils/generation.js').GenerationConfigType} generation_config A `GenerationConfig` object containing generation parameters.\n     * @returns {import('./utils/generation.js').GenerationConfigType} The final generation config object to be used by the model for text generation.\n     */\n    _get_generation_config(generation_config) {\n        // Create empty generation config (contains defaults)\n        // We pass `this.config` so that if `eos_token_id` or `bos_token_id` exist in the model's config, we will use them\n        let gen_config = new _utils_generation_js__WEBPACK_IMPORTED_MODULE_3__.GenerationConfig(this.config);\n\n        // Apply model's generation config, if it exists\n        if ('generation_config' in this) {\n            Object.assign(gen_config, this.generation_config);\n        }\n\n        // Finally, use any generation config specified by the user\n        // when calling `generate`\n        if (generation_config !== null) {\n            Object.assign(gen_config, generation_config);\n        }\n        return gen_config;\n    }\n\n    /**\n     * @typedef {import('./utils/maths.js').TypedArray} TypedArray\n     */\n\n    /**\n     * @typedef {{ sequences: Tensor, decoder_attentions: Tensor, cross_attentions: Tensor }} EncoderDecoderOutput\n     * @typedef {Object} DecoderOutput\n     * \n     * Generates text based on the given inputs and generation configuration using the model.\n     * @param {Tensor|Array|TypedArray} inputs An array of input token IDs.\n     * @param {Object|GenerationConfig|null} generation_config The generation configuration to use. If null, default configuration will be used.\n     * @param {Object|null} logits_processor An optional logits processor to use. If null, a new LogitsProcessorList instance will be created.\n     * @param {Object} options options\n     * @param {Object} [options.inputs_attention_mask=null] An optional attention mask for the inputs.\n     * @returns {Promise<number[][]|EncoderDecoderOutput|DecoderOutput>} An array of generated output sequences, where each sequence is an array of token IDs.\n     * @throws {Error} Throws an error if the inputs array is empty.\n     */\n    async generate(\n        inputs,\n        generation_config = null,\n        logits_processor = null,\n        {\n            inputs_attention_mask = null\n        } = {},\n    ) {\n        if (!this.can_generate) {\n            const modelName = MODEL_CLASS_TO_NAME_MAPPING.get(this.constructor);\n            let errorMessage = `The current model class (${modelName}) is not compatible with \\`.generate()\\`, as it doesn't have a language model head.`\n\n            const modelType = this.config.model_type;\n            const possibleInfo =\n                MODEL_WITH_LM_HEAD_MAPPING_NAMES.get(modelType)\n                ?? MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING_NAMES.get(modelType)\n                ?? MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING_NAMES.get(modelType)\n                // ?? MODEL_FOR_TEXT_TO_SPECTROGRAM_MAPPING_NAMES.get(modelType) // TODO\n                ?? MODEL_FOR_VISION_2_SEQ_MAPPING_NAMES.get(modelType);\n\n            if (possibleInfo) {\n                // TODO: support multiple possible classes\n                errorMessage += ` Please use the following class instead: '${possibleInfo[0]}'`;\n            }\n            throw Error(errorMessage);\n        }\n\n        if (!(inputs instanceof _utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.Tensor) && !(0,_utils_core_js__WEBPACK_IMPORTED_MODULE_1__.isTypedArray)(inputs) && !Array.isArray(inputs)) {\n            throw Error(`\\`inputs\\` must be a Tensor, TypedArray, or Array, but is \"${inputs.constructor.name}\".`);\n        }\n\n        let input_ids_seq_length;\n\n        // Prepare `input_ids` which will be used for auto-regressive generation\n        // TODO: Update to align with HF transformers' implementation\n        if (this.config.is_encoder_decoder) {\n            // Generating from the encoder outputs\n            input_ids_seq_length = 0;\n\n        } else {\n            input_ids_seq_length = inputs instanceof _utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.Tensor ? inputs.dims.at(-1) : inputs.length;\n\n            // decoder-only\n            if (input_ids_seq_length === 0) {\n                throw Error(\"Must supply a non-empty array of input token ids.\")\n            }\n        }\n\n        // Update generation config with defaults\n        generation_config = this._get_generation_config(generation_config);\n\n        logits_processor = logits_processor ?? new _utils_generation_js__WEBPACK_IMPORTED_MODULE_3__.LogitsProcessorList()\n\n        // Update logits processor\n        logits_processor = this._get_logits_processor(\n            generation_config,\n            input_ids_seq_length,\n            logits_processor\n        )\n\n        /** @type {number[]} */\n        let eos_token_ids = generation_config.eos_token_id;\n        if (eos_token_ids !== null && !Array.isArray(eos_token_ids)) {\n            eos_token_ids = [eos_token_ids];\n        }\n\n        // TODO implement early_stopping\n        // https://huggingface.co/blog/how-to-generate\n\n        let numOutputTokens = 1;\n        const maxOutputTokens = numOutputTokens + (generation_config.max_new_tokens ?? Infinity);\n\n        // Only use max length if max_new_tokens is not provided\n        const useMaxLength = Number.isInteger(generation_config.max_length) && (generation_config.max_new_tokens ?? null) === null;\n        let sampler = _utils_generation_js__WEBPACK_IMPORTED_MODULE_3__.Sampler.getSampler(generation_config);\n\n        // @ts-ignore\n        let beams = this.getStartBeams(inputs, generation_config, numOutputTokens, inputs_attention_mask);\n\n        while (beams.some(x => !x.done) && numOutputTokens < maxOutputTokens) {\n            let newest_beams = [];\n            for (let beam of beams) {\n                if (beam.done) {\n                    // Add this beam back into the pool\n                    newest_beams.push(beam);\n                    continue\n                }\n                if (useMaxLength && beam.output_token_ids.length >= generation_config.max_length) {\n                    // Set this beam to done and add it back into the pool\n                    beam.done = true;\n                    newest_beams.push(beam);\n                    continue\n                }\n\n                // @ts-ignore\n                let output = await this.runBeam(beam);\n\n                // add attentions/scores to beam only if user requested\n                if (generation_config.output_attentions) {\n                    this.addAttentionsToBeam(beam, output);\n                }\n                if (generation_config.output_scores) {\n                    // TODO add\n                }\n\n                // Logits are of the form [batch_size, out_seq_length, vocab_size]\n                // In most cases, this will be [batch_size, 1, vocab_size]\n                // So, we select the last token's logits:\n                // (equivalent to `logits = outputs.logits[:, -1, :]`)\n                let logits = output.logits.slice(null, -1, null);\n\n                // Apply logits processor\n                logits_processor(beam.output_token_ids, logits);\n\n                let sampledTokens = sampler(logits);\n                for (let [newTokenId, logProb] of sampledTokens) {\n                    // use previous beam as a starting point\n                    let newBeam = { ...beam };\n\n                    // update new beam\n                    // @ts-ignore\n                    this.updateBeam(newBeam, newTokenId);\n\n                    newBeam.score += logProb;\n\n                    if (eos_token_ids && eos_token_ids.includes(newTokenId)) {\n                        newBeam.done = true;\n                    }\n\n                    newest_beams.push(newBeam);\n                }\n            }\n            ++numOutputTokens;\n\n            // Next, we get the best beams, per ID\n            newest_beams = this.groupBeams(newest_beams).map(\n                group => group\n                    .sort((a, b) => b.score - a.score)      // sort by score\n                    .slice(0, generation_config.num_beams)  // remove outside beam width\n            );\n\n            // Flatten beams\n            beams = newest_beams.flat();\n\n            // Run callback\n            if (generation_config.callback_function) {\n                generation_config.callback_function(beams);\n            }\n        }\n\n        // TODO: Ensure that we can return non-batched outputs\n\n        const groupedBeams = this.groupBeams(beams);\n\n        const getFlattened = (key) => groupedBeams.map(\n            batch => {\n                if (generation_config.num_return_sequences > 1) {\n                    return batch.slice(0, generation_config.num_return_sequences).map(x => x[key]);\n                } else {\n                    return [batch[0][key]];\n                }\n            }\n        ).flat(); // Flatten across batches (depth=1)\n\n        const sequences = getFlattened('output_token_ids'); // [1, seqLength]\n\n        if (generation_config.return_dict_in_generate) {\n            // NOTE: `decoder_attentions` and `cross_attentions` should be:\n            //    list (one element for each generated token)\n            //    of list (one element for each layer of the decoder)\n            //    of torch.FloatTensor of shape (batch_size, num_heads, generated_length, sequence_length)\n            // However, since we are only generating one batch at a time, they are of the form:\n            //   list (batches)\n            //   of list (one element for each generated token)\n            //   of list (one element for each layer of the decoder)\n            //   of torch.FloatTensor of shape (1, num_heads, generated_length, sequence_length)\n            // \n            // TODO: In future (when true parallelism, we should be able to return the correct shape)\n\n            const decoder_attentions = getFlattened('decoder_attentions');\n            const cross_attentions = getFlattened('cross_attentions');\n\n            return {\n                sequences,\n\n                decoder_attentions,\n                cross_attentions,\n            }\n        } else {\n            return sequences;\n        }\n    }\n\n    /**\n     * Helper function to add attentions to beam\n     * @param {Object} beam \n     * @param {Object} output\n     * @private \n     */\n    addAttentionsToBeam(beam, output) {\n        if (this.config.is_encoder_decoder) {\n            if (!output.cross_attentions || output.cross_attentions.length === 0) {\n                throw Error(\n                    \"`output_attentions` is true, but the model did not produce cross-attentions. \" +\n                    \"This is most likely because the model was not exported with `output_attentions=True`.\"\n                )\n            }\n            if (!beam.cross_attentions) {\n                beam.cross_attentions = [];\n            }\n            beam.cross_attentions.push(output.cross_attentions);\n        }\n\n        if (!output.decoder_attentions || output.decoder_attentions.length === 0) {\n            throw Error(\n                \"`output_attentions` is true, but the model did not produce decoder-attentions. \" +\n                \"This is most likely because the model was not exported with `output_attentions=True`.\"\n            )\n        }\n        if (!beam.decoder_attentions) {\n            beam.decoder_attentions = [];\n        }\n        beam.decoder_attentions.push(output.decoder_attentions);\n    }\n\n    /**\n     * Groups an array of beam objects by their ids.\n     *\n     * @param {Array} beams The array of beam objects to group.\n     * @returns {Array} An array of arrays, where each inner array contains beam objects with the same id.\n     */\n    groupBeams(beams) {\n        // Group beams by their ids\n        const groups = Object.create(null);\n        for (const obj of beams) {\n            if (groups[obj.id] === undefined) {\n                groups[obj.id] = [obj];\n            } else {\n                groups[obj.id].push(obj);\n            }\n        }\n\n        return Object.values(groups);\n    }\n\n    /**\n     * Returns an object containing past key values from the given decoder results object.\n     *\n     * @param {Object} decoderResults The decoder results object.\n     * @param {Object} pastKeyValues The previous past key values.\n     * @returns {Object} An object containing past key values.\n     */\n    getPastKeyValues(decoderResults, pastKeyValues) {\n\n        const pkvs = Object.create(null);\n\n        for (const name in decoderResults) {\n            if (name.startsWith('present')) {\n                let newName = name.replace('present', 'past_key_values');\n\n                if (pastKeyValues && name.includes('encoder')) {\n                    // Optimization introduced by optimum to reuse past key values. So, we just replace the constant\n                    // outputs with the previous past key values.\n                    // https://github.com/huggingface/optimum/blob/0bf2c05fb7e1182b52d21b703cfc95fd9e4ea3dc/optimum/onnxruntime/base.py#L677-L704\n                    pkvs[newName] = pastKeyValues[newName];\n                } else {\n                    pkvs[newName] = decoderResults[name];\n                }\n            }\n        }\n        return pkvs;\n    }\n\n    /**\n     * Returns an object containing attentions from the given decoder results object.\n     *\n     * @param {Object} decoderResults The decoder results object.\n     * @returns {Object} An object containing attentions.\n     */\n    getAttentions(decoderResults) {\n        const attns = Object.create(null);\n\n        for (const attnName of ['cross_attentions', 'decoder_attentions']) {\n            const result = [];\n            for (const name in decoderResults) {\n                if (name.startsWith(attnName)) {\n                    const index = name.split('.').pop()\n                    result[index] = decoderResults[name];\n                }\n            }\n            attns[attnName] = result;\n        }\n        return attns;\n    }\n\n    /**\n     * Adds past key values to the decoder feeds object. If pastKeyValues is null, creates new tensors for past key values.\n     *\n     * @param {Object} decoderFeeds The decoder feeds object to add past key values to.\n     * @param {Object} pastKeyValues An object containing past key values.\n     */\n    addPastKeyValues(decoderFeeds, pastKeyValues) {\n        if (pastKeyValues) {\n            Object.assign(decoderFeeds, pastKeyValues)\n        } else {\n            // TODO support batches (i.e., batch_size > 1)\n            const batch_size = 1;\n\n            // @ts-ignore\n            if (this.config.is_encoder_decoder && (this.add_encoder_pkv ?? true)) {\n                // @ts-ignore\n                let encoder_dims = [batch_size, this.num_encoder_heads, 0, this.encoder_dim_kv];\n                // @ts-ignore\n                let decoder_dims = [batch_size, this.num_decoder_heads, 0, this.decoder_dim_kv];\n                // @ts-ignore\n                for (let i = 0; i < this.num_decoder_layers; ++i) {\n                    decoderFeeds[`past_key_values.${i}.encoder.key`] = new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.Tensor('float32', [], encoder_dims)\n                    decoderFeeds[`past_key_values.${i}.encoder.value`] = new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.Tensor('float32', [], encoder_dims)\n                    decoderFeeds[`past_key_values.${i}.decoder.key`] = new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.Tensor('float32', [], decoder_dims)\n                    decoderFeeds[`past_key_values.${i}.decoder.value`] = new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.Tensor('float32', [], decoder_dims)\n                }\n            } else if (this.config.model_type === 'falcon') {\n                // NOTE: Custom implementation for Falcon\n                // @ts-ignore\n                let dims = [batch_size * this.num_heads, 0, this.dim_kv]\n                // @ts-ignore\n                for (let i = 0; i < this.num_layers; ++i) {\n                    decoderFeeds[`past_key_values.${i}.key`] = new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.Tensor('float32', [], dims)\n                    decoderFeeds[`past_key_values.${i}.value`] = new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.Tensor('float32', [], dims)\n                }\n            } else if (this.config.multi_query) { // e.g., for `gpt_bigcode`\n                // @ts-ignore\n                let dims = [batch_size * this.num_heads, 0, 2 * this.dim_kv]\n                // @ts-ignore\n                for (let i = 0; i < this.num_layers; ++i) {\n                    decoderFeeds[`past_key_values.${i}.key_value`] = new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.Tensor('float32', [], dims)\n                }\n            } else if (this.config.model_type === 'bloom') {\n                // NOTE: Custom implementation for Bloom\n\n                // @ts-ignore\n                let keyDims = [batch_size * this.num_heads, this.dim_kv, 0] // [batch_size x num_heads,64,past_sequence_length]\n                // @ts-ignore\n                let valueDims = [batch_size * this.num_heads, 0, this.dim_kv] // [batch_size x num_heads,past_sequence_length,64]\n                // @ts-ignore\n                for (let i = 0; i < this.num_layers; ++i) {\n                    decoderFeeds[`past_key_values.${i}.key`] = new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.Tensor('float32', [], keyDims)\n                    decoderFeeds[`past_key_values.${i}.value`] = new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.Tensor('float32', [], valueDims)\n                }\n            } else { // Decoder-only\n                // @ts-ignore\n                let dims = [batch_size, this.num_heads, 0, this.dim_kv]\n                // @ts-ignore\n                for (let i = 0; i < this.num_layers; ++i) {\n                    decoderFeeds[`past_key_values.${i}.key`] = new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.Tensor('float32', [], dims)\n                    decoderFeeds[`past_key_values.${i}.value`] = new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.Tensor('float32', [], dims)\n                }\n            }\n        }\n    }\n\n    /**\n     * Initializes and returns the beam for text generation task\n     * @param {Tensor} inputTokenIds The input token ids.\n     * @param {Object} generation_config The generation config.\n     * @param {number} numOutputTokens The number of tokens to be generated.\n     * @param {Tensor} inputs_attention_mask Optional input attention mask.\n     * @returns {any} A Beam object representing the initialized beam.\n     * @private\n     */\n    getStartBeams(inputTokenIds, generation_config, numOutputTokens, inputs_attention_mask) {\n        return this._getStartBeams(this, inputTokenIds, generation_config, numOutputTokens, inputs_attention_mask)\n    }\n\n    /**\n     * Runs a single step of the beam search generation algorithm.\n     * @param {any} beam The current beam being generated.\n     * @returns {Promise<any>} The updated beam after a single generation step.\n     * @private\n     */\n    async runBeam(beam) {\n        return await this._runBeam(this, beam);\n    }\n\n    /**\n     * Update a beam with a new token ID.\n     * @param {Object} beam The beam to update.\n     * @param {number} newTokenId The new token ID to add to the beam's output.\n     * @private\n     */\n    updateBeam(beam, newTokenId) {\n        return this._updateBeam(beam, newTokenId);\n    }\n}\n\n//////////////////////////////////////////////////\n// Base model output class\nclass ModelOutput { }\n\n/**\n * Base class for model's outputs, with potential hidden states and attentions.\n */\nclass BaseModelOutput extends ModelOutput {\n    /**\n     * @param {Object} output The output of the model.\n     * @param {Tensor} output.last_hidden_state Sequence of hidden-states at the output of the last layer of the model.\n     * @param {Tensor} [output.hidden_states] Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.\n     * @param {Tensor} [output.attentions] Attentions weights after the attention softmax, used to compute the weighted average in the self-attention heads.\n     */\n    constructor({ last_hidden_state, hidden_states = null, attentions = null }) {\n        super();\n        this.last_hidden_state = last_hidden_state;\n        this.hidden_states = hidden_states;\n        this.attentions = attentions;\n    }\n}\n//////////////////////////////////////////////////\n// Bert models\nclass BertPreTrainedModel extends PreTrainedModel { }\nclass BertModel extends BertPreTrainedModel { }\n\n/**\n * BertForMaskedLM is a class representing a BERT model for masked language modeling.\n */\nclass BertForMaskedLM extends BertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<MaskedLMOutput>} An object containing the model's output logits for masked language modeling.\n     */\n    async _call(model_inputs) {\n        return new MaskedLMOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * BertForSequenceClassification is a class representing a BERT model for sequence classification.\n */\nclass BertForSequenceClassification extends BertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * BertForTokenClassification is a class representing a BERT model for token classification.\n */\nclass BertForTokenClassification extends BertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.\n     */\n    async _call(model_inputs) {\n        return new TokenClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * BertForQuestionAnswering is a class representing a BERT model for question answering.\n */\nclass BertForQuestionAnswering extends BertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.\n     */\n    async _call(model_inputs) {\n        return new QuestionAnsweringModelOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// NomicBert models\nclass NomicBertPreTrainedModel extends PreTrainedModel { }\nclass NomicBertModel extends NomicBertPreTrainedModel { }\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// RoFormer models\nclass RoFormerPreTrainedModel extends PreTrainedModel { }\n\n/**\n * The bare RoFormer Model transformer outputting raw hidden-states without any specific head on top.\n */\nclass RoFormerModel extends RoFormerPreTrainedModel { }\n\n/**\n * RoFormer Model with a `language modeling` head on top.\n */\nclass RoFormerForMaskedLM extends RoFormerPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<MaskedLMOutput>} An object containing the model's output logits for masked language modeling.\n     */\n    async _call(model_inputs) {\n        return new MaskedLMOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * RoFormer Model transformer with a sequence classification/regression head on top (a linear layer on top of the pooled output)\n */\nclass RoFormerForSequenceClassification extends RoFormerPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * RoFormer Model with a token classification head on top (a linear layer on top of the hidden-states output)\n * e.g. for Named-Entity-Recognition (NER) tasks.\n */\nclass RoFormerForTokenClassification extends RoFormerPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.\n     */\n    async _call(model_inputs) {\n        return new TokenClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * RoFormer Model with a span classification head on top for extractive question-answering tasks like SQuAD\n * (a linear layers on top of the hidden-states output to compute `span start logits` and `span end logits`).\n */\nclass RoFormerForQuestionAnswering extends RoFormerPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.\n     */\n    async _call(model_inputs) {\n        return new QuestionAnsweringModelOutput(await super._call(model_inputs));\n    }\n}\n// TODO: Add RoFormerForCausalLM and RoFormerForMultipleChoice\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// ConvBert models\nclass ConvBertPreTrainedModel extends PreTrainedModel { }\n\n/**\n * The bare ConvBERT Model transformer outputting raw hidden-states without any specific head on top.\n */\nclass ConvBertModel extends ConvBertPreTrainedModel { }\n\n/**\n * ConvBERT Model with a language modeling head on top.\n */\nclass ConvBertForMaskedLM extends ConvBertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<MaskedLMOutput>} An object containing the model's output logits for masked language modeling.\n     */\n    async _call(model_inputs) {\n        return new MaskedLMOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * ConvBERT Model transformer with a sequence classification/regression head on top (a linear layer on top of the pooled output)\n */\nclass ConvBertForSequenceClassification extends ConvBertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * ConvBERT Model with a token classification head on top (a linear layer on top of the hidden-states output)\n * e.g. for Named-Entity-Recognition (NER) tasks.\n */\nclass ConvBertForTokenClassification extends ConvBertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.\n     */\n    async _call(model_inputs) {\n        return new TokenClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * ConvBERT Model with a span classification head on top for extractive question-answering tasks like SQuAD\n * (a linear layers on top of the hidden-states output to compute `span start logits` and `span end logits`)\n */\nclass ConvBertForQuestionAnswering extends ConvBertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.\n     */\n    async _call(model_inputs) {\n        return new QuestionAnsweringModelOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// Electra models\nclass ElectraPreTrainedModel extends PreTrainedModel { }\n\n/**\n * The bare Electra Model transformer outputting raw hidden-states without any specific head on top.\n * Identical to the BERT model except that it uses an additional linear layer between the embedding\n * layer and the encoder if the hidden size and embedding size are different.\n */\nclass ElectraModel extends ElectraPreTrainedModel { }\n// TODO add ElectraForPreTraining\n/**\n * Electra model with a language modeling head on top.\n */\nclass ElectraForMaskedLM extends ElectraPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<MaskedLMOutput>} An object containing the model's output logits for masked language modeling.\n     */\n    async _call(model_inputs) {\n        return new MaskedLMOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * ELECTRA Model transformer with a sequence classification/regression head on top (a linear layer on top of the pooled output)\n */\nclass ElectraForSequenceClassification extends ElectraPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * Electra model with a token classification head on top.\n */\nclass ElectraForTokenClassification extends ElectraPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.\n     */\n    async _call(model_inputs) {\n        return new TokenClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * LECTRA Model with a span classification head on top for extractive question-answering tasks like SQuAD\n * (a linear layers on top of the hidden-states output to compute `span start logits` and `span end logits`).\n */\nclass ElectraForQuestionAnswering extends ElectraPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.\n     */\n    async _call(model_inputs) {\n        return new QuestionAnsweringModelOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// CamemBERT models\nclass CamembertPreTrainedModel extends PreTrainedModel { }\n\n/**\n * The bare CamemBERT Model transformer outputting raw hidden-states without any specific head on top.\n */\nclass CamembertModel extends CamembertPreTrainedModel { }\n\n/**\n * CamemBERT Model with a `language modeling` head on top.\n */\nclass CamembertForMaskedLM extends CamembertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<MaskedLMOutput>} An object containing the model's output logits for masked language modeling.\n     */\n    async _call(model_inputs) {\n        return new MaskedLMOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * CamemBERT Model transformer with a sequence classification/regression head on top (a linear layer on top of the pooled output) e.g. for GLUE tasks.\n */\nclass CamembertForSequenceClassification extends CamembertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * CamemBERT Model with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks.\n */\nclass CamembertForTokenClassification extends CamembertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.\n     */\n    async _call(model_inputs) {\n        return new TokenClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * CamemBERT Model with a span classification head on top for extractive question-answering tasks\n */\nclass CamembertForQuestionAnswering extends CamembertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.\n     */\n    async _call(model_inputs) {\n        return new QuestionAnsweringModelOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// DeBERTa models\nclass DebertaPreTrainedModel extends PreTrainedModel { }\n\n/**\n * The bare DeBERTa Model transformer outputting raw hidden-states without any specific head on top.\n */\nclass DebertaModel extends DebertaPreTrainedModel { }\n\n/**\n * DeBERTa Model with a `language modeling` head on top.\n */\nclass DebertaForMaskedLM extends DebertaPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<MaskedLMOutput>} An object containing the model's output logits for masked language modeling.\n     */\n    async _call(model_inputs) {\n        return new MaskedLMOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * DeBERTa Model transformer with a sequence classification/regression head on top (a linear layer on top of the pooled output)\n */\nclass DebertaForSequenceClassification extends DebertaPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * DeBERTa Model with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks.\n */\nclass DebertaForTokenClassification extends DebertaPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.\n     */\n    async _call(model_inputs) {\n        return new TokenClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * DeBERTa Model with a span classification head on top for extractive question-answering tasks like SQuAD (a linear\n * layers on top of the hidden-states output to compute `span start logits` and `span end logits`).\n */\nclass DebertaForQuestionAnswering extends DebertaPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.\n     */\n    async _call(model_inputs) {\n        return new QuestionAnsweringModelOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// DeBERTa-v2 models\nclass DebertaV2PreTrainedModel extends PreTrainedModel { }\n\n/**\n * The bare DeBERTa-V2 Model transformer outputting raw hidden-states without any specific head on top.\n */\nclass DebertaV2Model extends DebertaV2PreTrainedModel { }\n\n/**\n * DeBERTa-V2 Model with a `language modeling` head on top.\n */\nclass DebertaV2ForMaskedLM extends DebertaV2PreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<MaskedLMOutput>} An object containing the model's output logits for masked language modeling.\n     */\n    async _call(model_inputs) {\n        return new MaskedLMOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * DeBERTa-V2 Model transformer with a sequence classification/regression head on top (a linear layer on top of the pooled output)\n */\nclass DebertaV2ForSequenceClassification extends DebertaV2PreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * DeBERTa-V2 Model with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks.\n */\nclass DebertaV2ForTokenClassification extends DebertaV2PreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.\n     */\n    async _call(model_inputs) {\n        return new TokenClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * DeBERTa-V2 Model with a span classification head on top for extractive question-answering tasks like SQuAD (a linear\n * layers on top of the hidden-states output to compute `span start logits` and `span end logits`).\n */\nclass DebertaV2ForQuestionAnswering extends DebertaV2PreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.\n     */\n    async _call(model_inputs) {\n        return new QuestionAnsweringModelOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// DistilBert models\nclass DistilBertPreTrainedModel extends PreTrainedModel { }\nclass DistilBertModel extends DistilBertPreTrainedModel { }\n\n/**\n * DistilBertForSequenceClassification is a class representing a DistilBERT model for sequence classification.\n */\nclass DistilBertForSequenceClassification extends DistilBertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * DistilBertForTokenClassification is a class representing a DistilBERT model for token classification.\n */\nclass DistilBertForTokenClassification extends DistilBertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.\n     */\n    async _call(model_inputs) {\n        return new TokenClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n\n/**\n * DistilBertForQuestionAnswering is a class representing a DistilBERT model for question answering.\n */\nclass DistilBertForQuestionAnswering extends DistilBertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.\n     */\n    async _call(model_inputs) {\n        return new QuestionAnsweringModelOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * DistilBertForMaskedLM is a class representing a DistilBERT model for masking task.\n */\nclass DistilBertForMaskedLM extends DistilBertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<MaskedLMOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new MaskedLMOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// ESM models\nclass EsmPreTrainedModel extends PreTrainedModel { }\n\n/**\n * The bare ESM Model transformer outputting raw hidden-states without any specific head on top.\n */\nclass EsmModel extends EsmPreTrainedModel { }\n\n/**\n * ESM Model with a `language modeling` head on top.\n */\nclass EsmForMaskedLM extends EsmPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<MaskedLMOutput>} An object containing the model's output logits for masked language modeling.\n     */\n    async _call(model_inputs) {\n        return new MaskedLMOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * ESM Model transformer with a sequence classification/regression head on top (a linear layer on top of the pooled output)\n */\nclass EsmForSequenceClassification extends EsmPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * ESM Model with a token classification head on top (a linear layer on top of the hidden-states output)\n * e.g. for Named-Entity-Recognition (NER) tasks.\n */\nclass EsmForTokenClassification extends EsmPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.\n     */\n    async _call(model_inputs) {\n        return new TokenClassifierOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// MobileBert models\nclass MobileBertPreTrainedModel extends PreTrainedModel { }\nclass MobileBertModel extends MobileBertPreTrainedModel { }\n\n/**\n * MobileBertForMaskedLM is a class representing a MobileBERT model for masking task.\n */\nclass MobileBertForMaskedLM extends MobileBertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<MaskedLMOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new MaskedLMOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * MobileBert Model transformer with a sequence classification/regression head on top (a linear layer on top of the pooled output)\n */\nclass MobileBertForSequenceClassification extends MobileBertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<SequenceClassifierOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * MobileBert Model with a span classification head on top for extractive question-answering tasks\n */\nclass MobileBertForQuestionAnswering extends MobileBertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<QuestionAnsweringModelOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new QuestionAnsweringModelOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// MPNet models\nclass MPNetPreTrainedModel extends PreTrainedModel { }\n\n/**\n * The bare MPNet Model transformer outputting raw hidden-states without any specific head on top.\n */\nclass MPNetModel extends MPNetPreTrainedModel { }\n\n/**\n * MPNetForMaskedLM is a class representing a MPNet model for masked language modeling.\n */\nclass MPNetForMaskedLM extends MPNetPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<MaskedLMOutput>} An object containing the model's output logits for masked language modeling.\n     */\n    async _call(model_inputs) {\n        return new MaskedLMOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * MPNetForSequenceClassification is a class representing a MPNet model for sequence classification.\n */\nclass MPNetForSequenceClassification extends MPNetPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * MPNetForTokenClassification is a class representing a MPNet model for token classification.\n */\nclass MPNetForTokenClassification extends MPNetPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.\n     */\n    async _call(model_inputs) {\n        return new TokenClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * MPNetForQuestionAnswering is a class representing a MPNet model for question answering.\n */\nclass MPNetForQuestionAnswering extends MPNetPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.\n     */\n    async _call(model_inputs) {\n        return new QuestionAnsweringModelOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// SqueezeBert models\nclass SqueezeBertPreTrainedModel extends PreTrainedModel { }\nclass SqueezeBertModel extends SqueezeBertPreTrainedModel { }\nclass SqueezeBertForMaskedLM extends SqueezeBertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<MaskedLMOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new MaskedLMOutput(await super._call(model_inputs));\n    }\n}\nclass SqueezeBertForSequenceClassification extends SqueezeBertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<SequenceClassifierOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\nclass SqueezeBertForQuestionAnswering extends SqueezeBertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<QuestionAnsweringModelOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new QuestionAnsweringModelOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// Albert models\nclass AlbertPreTrainedModel extends PreTrainedModel { }\nclass AlbertModel extends AlbertPreTrainedModel { }\nclass AlbertForSequenceClassification extends AlbertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<SequenceClassifierOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\nclass AlbertForQuestionAnswering extends AlbertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<QuestionAnsweringModelOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new QuestionAnsweringModelOutput(await super._call(model_inputs));\n    }\n}\nclass AlbertForMaskedLM extends AlbertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<MaskedLMOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new MaskedLMOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// T5 models\nclass T5PreTrainedModel extends PreTrainedModel { };\n\nclass T5Model extends T5PreTrainedModel { }\n\n/**\n * T5Model is a class representing a T5 model for conditional generation.\n */\nclass T5ForConditionalGeneration extends T5PreTrainedModel {\n\n    /**\n     * Creates a new instance of the `T5ForConditionalGeneration` class.\n     * @param {Object} config The model configuration.\n     * @param {any} session session for the model.\n     * @param {any} decoder_merged_session session for the decoder.\n     * @param {GenerationConfig} generation_config The generation configuration.\n     */\n    constructor(config, session, decoder_merged_session, generation_config) {\n        super(config, session);\n        this.decoder_merged_session = decoder_merged_session;\n        this.generation_config = generation_config;\n\n        this.num_decoder_layers = this.config.num_decoder_layers;\n        this.num_decoder_heads = this.config.num_heads;\n        this.decoder_dim_kv = this.config.d_kv;\n\n        this.num_encoder_layers = this.config.num_layers;\n        this.num_encoder_heads = this.config.num_heads;\n        this.encoder_dim_kv = this.config.d_kv;\n    }\n}\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// LONGT5 models\n/**\n * An abstract class to handle weights initialization and a simple interface for downloading and loading pretrained models.\n */\nclass LongT5PreTrainedModel extends PreTrainedModel { };\n\n/**\n * The bare LONGT5 Model transformer outputting raw hidden-states without any specific head on top.\n */\nclass LongT5Model extends LongT5PreTrainedModel { }\n\n/**\n * LONGT5 Model with a `language modeling` head on top.\n */\nclass LongT5ForConditionalGeneration extends LongT5PreTrainedModel {\n    /**\n     * Creates a new instance of the `LongT5ForConditionalGeneration` class.\n     * @param {Object} config The model configuration.\n     * @param {any} session session for the model.\n     * @param {any} decoder_merged_session session for the decoder.\n     * @param {GenerationConfig} generation_config The generation configuration.\n     */\n    constructor(config, session, decoder_merged_session, generation_config) {\n        super(config, session);\n        this.decoder_merged_session = decoder_merged_session;\n        this.generation_config = generation_config;\n\n        this.num_decoder_layers = this.config.num_decoder_layers;\n        this.num_decoder_heads = this.config.num_heads;\n        this.decoder_dim_kv = this.config.d_kv;\n\n        this.num_encoder_layers = this.config.num_layers;\n        this.num_encoder_heads = this.config.num_heads;\n        this.encoder_dim_kv = this.config.d_kv;\n    }\n}\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// MT5 models\nclass MT5PreTrainedModel extends PreTrainedModel { };\n\nclass MT5Model extends MT5PreTrainedModel { }\n\n/**\n * A class representing a conditional sequence-to-sequence model based on the MT5 architecture.\n */\nclass MT5ForConditionalGeneration extends MT5PreTrainedModel {\n\n    /**\n     * Creates a new instance of the `MT5ForConditionalGeneration` class.\n     * @param {any} config The model configuration.\n     * @param {any} session The ONNX session containing the encoder weights.\n     * @param {any} decoder_merged_session The ONNX session containing the merged decoder weights.\n     * @param {GenerationConfig} generation_config The generation configuration.\n     */\n    constructor(config, session, decoder_merged_session, generation_config) {\n        super(config, session);\n        this.decoder_merged_session = decoder_merged_session;\n        this.generation_config = generation_config;\n\n        this.num_decoder_layers = this.config.num_decoder_layers;\n        this.num_decoder_heads = this.config.num_heads;\n        this.decoder_dim_kv = this.config.d_kv;\n\n        this.num_encoder_layers = this.config.num_layers;\n        this.num_encoder_heads = this.config.num_heads;\n        this.encoder_dim_kv = this.config.d_kv;\n    }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// Bart models\nclass BartPretrainedModel extends PreTrainedModel { };\n\n/**\n * The bare BART Model outputting raw hidden-states without any specific head on top.\n */\nclass BartModel extends BartPretrainedModel { }\n\n/**\n * The BART Model with a language modeling head. Can be used for summarization.\n */\nclass BartForConditionalGeneration extends BartPretrainedModel {\n\n    /**\n     * Creates a new instance of the `BartForConditionalGeneration` class.\n     * @param {Object} config The configuration object for the Bart model.\n     * @param {Object} session The ONNX session used to execute the model.\n     * @param {Object} decoder_merged_session The ONNX session used to execute the decoder.\n     * @param {Object} generation_config The generation configuration object.\n     */\n    constructor(config, session, decoder_merged_session, generation_config) {\n        super(config, session);\n        this.decoder_merged_session = decoder_merged_session;\n        this.generation_config = generation_config;\n\n        this.num_decoder_layers = this.config.decoder_layers;\n        this.num_decoder_heads = this.config.decoder_attention_heads;\n        this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads;\n\n        this.num_encoder_layers = this.config.encoder_layers;\n        this.num_encoder_heads = this.config.encoder_attention_heads;\n        this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads;\n    }\n\n}\n\n/**\n * Bart model with a sequence classification/head on top (a linear layer on top of the pooled output)\n */\nclass BartForSequenceClassification extends BartPretrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// MBart models\nclass MBartPreTrainedModel extends PreTrainedModel { };\n\n/**\n * The bare MBART Model outputting raw hidden-states without any specific head on top.\n */\nclass MBartModel extends MBartPreTrainedModel { }\n\n/**\n * The MBART Model with a language modeling head. Can be used for summarization, after fine-tuning the pretrained models.\n */\nclass MBartForConditionalGeneration extends MBartPreTrainedModel {\n\n    /**\n     * Creates a new instance of the `MBartForConditionalGeneration` class.\n     * @param {Object} config The configuration object for the Bart model.\n     * @param {Object} session The ONNX session used to execute the model.\n     * @param {Object} decoder_merged_session The ONNX session used to execute the decoder.\n     * @param {Object} generation_config The generation configuration object.\n     */\n    constructor(config, session, decoder_merged_session, generation_config) {\n        super(config, session);\n        this.decoder_merged_session = decoder_merged_session;\n        this.generation_config = generation_config;\n\n        this.num_decoder_layers = this.config.decoder_layers;\n        this.num_decoder_heads = this.config.decoder_attention_heads;\n        this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads;\n\n        this.num_encoder_layers = this.config.encoder_layers;\n        this.num_encoder_heads = this.config.encoder_attention_heads;\n        this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads;\n    }\n\n}\n\n/**\n * MBart model with a sequence classification/head on top (a linear layer on top of the pooled output).\n */\nclass MBartForSequenceClassification extends MBartPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n\nclass MBartForCausalLM extends MBartPreTrainedModel {\n    /**\n     * Creates a new instance of the `MBartForCausalLM` class.\n     * @param {Object} config Configuration object for the model.\n     * @param {Object} decoder_merged_session ONNX Session object for the decoder.\n     * @param {Object} generation_config Configuration object for the generation process.\n     */\n    constructor(config, decoder_merged_session, generation_config) {\n        super(config, decoder_merged_session);\n        this.generation_config = generation_config;\n\n        this.num_decoder_layers = this.config.decoder_layers;\n        this.num_decoder_heads = this.config.decoder_attention_heads;\n        this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads;\n\n        this.num_encoder_layers = this.config.encoder_layers;\n        this.num_encoder_heads = this.config.encoder_attention_heads;\n        this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads;\n    }\n}\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// Blenderbot models\nclass BlenderbotPreTrainedModel extends PreTrainedModel { };\n\n/**\n * The bare Blenderbot Model outputting raw hidden-states without any specific head on top.\n */\nclass BlenderbotModel extends BlenderbotPreTrainedModel { }\n\n/**\n * The Blenderbot Model with a language modeling head. Can be used for summarization.\n */\nclass BlenderbotForConditionalGeneration extends BlenderbotPreTrainedModel {\n\n    /**\n     * Creates a new instance of the `BlenderbotForConditionalGeneration` class.\n     * @param {any} config The model configuration.\n     * @param {any} session The ONNX session containing the encoder weights.\n     * @param {any} decoder_merged_session The ONNX session containing the merged decoder weights.\n     * @param {GenerationConfig} generation_config The generation configuration.\n     */\n    constructor(config, session, decoder_merged_session, generation_config) {\n        super(config, session);\n        this.decoder_merged_session = decoder_merged_session;\n        this.generation_config = generation_config;\n\n        this.num_decoder_layers = this.config.decoder_layers;\n        this.num_decoder_heads = this.config.decoder_attention_heads;\n        this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads;\n\n        this.num_encoder_layers = this.config.encoder_layers;\n        this.num_encoder_heads = this.config.encoder_attention_heads;\n        this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads;\n    }\n}\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// Blenderbot models\nclass BlenderbotSmallPreTrainedModel extends PreTrainedModel { };\n\n/**\n * The bare BlenderbotSmall Model outputting raw hidden-states without any specific head on top.\n */\nclass BlenderbotSmallModel extends BlenderbotSmallPreTrainedModel { }\n\n/**\n * The BlenderbotSmall Model with a language modeling head. Can be used for summarization.\n */\nclass BlenderbotSmallForConditionalGeneration extends BlenderbotSmallPreTrainedModel {\n\n    /**\n     * Creates a new instance of the `BlenderbotForConditionalGeneration` class.\n     * @param {any} config The model configuration.\n     * @param {any} session The ONNX session containing the encoder weights.\n     * @param {any} decoder_merged_session The ONNX session containing the merged decoder weights.\n     * @param {GenerationConfig} generation_config The generation configuration.\n     */\n    constructor(config, session, decoder_merged_session, generation_config) {\n        super(config, session);\n        this.decoder_merged_session = decoder_merged_session;\n        this.generation_config = generation_config;\n\n        this.num_decoder_layers = this.config.decoder_layers;\n        this.num_decoder_heads = this.config.decoder_attention_heads;\n        this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads;\n\n        this.num_encoder_layers = this.config.encoder_layers;\n        this.num_encoder_heads = this.config.encoder_attention_heads;\n        this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads;\n    }\n}\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// Roberta models\nclass RobertaPreTrainedModel extends PreTrainedModel { }\nclass RobertaModel extends RobertaPreTrainedModel { }\n\n/**\n * RobertaForMaskedLM class for performing masked language modeling on Roberta models.\n */\nclass RobertaForMaskedLM extends RobertaPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<MaskedLMOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new MaskedLMOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * RobertaForSequenceClassification class for performing sequence classification on Roberta models.\n */\nclass RobertaForSequenceClassification extends RobertaPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<SequenceClassifierOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * RobertaForTokenClassification class for performing token classification on Roberta models.\n */\nclass RobertaForTokenClassification extends RobertaPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.\n     */\n    async _call(model_inputs) {\n        return new TokenClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * RobertaForQuestionAnswering class for performing question answering on Roberta models.\n */\nclass RobertaForQuestionAnswering extends RobertaPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<QuestionAnsweringModelOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new QuestionAnsweringModelOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// XLM models\n/**\n * An abstract class to handle weights initialization and a simple interface for downloading and loading pretrained models.\n */\nclass XLMPreTrainedModel extends PreTrainedModel { }\n\n/**\n * The bare XLM Model transformer outputting raw hidden-states without any specific head on top.\n */\nclass XLMModel extends XLMPreTrainedModel { }\n\n/**\n * The XLM Model transformer with a language modeling head on top (linear layer with weights tied to the input embeddings).\n */\nclass XLMWithLMHeadModel extends XLMPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<MaskedLMOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new MaskedLMOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * XLM Model with a sequence classification/regression head on top (a linear layer on top of the pooled output)\n */\nclass XLMForSequenceClassification extends XLMPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<SequenceClassifierOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * XLM Model with a token classification head on top (a linear layer on top of the hidden-states output)\n */\nclass XLMForTokenClassification extends XLMPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.\n     */\n    async _call(model_inputs) {\n        return new TokenClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * XLM Model with a span classification head on top for extractive question-answering tasks\n */\nclass XLMForQuestionAnswering extends XLMPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<QuestionAnsweringModelOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new QuestionAnsweringModelOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// XLMRoberta models\nclass XLMRobertaPreTrainedModel extends PreTrainedModel { }\nclass XLMRobertaModel extends XLMRobertaPreTrainedModel { }\n\n/**\n * XLMRobertaForMaskedLM class for performing masked language modeling on XLMRoberta models.\n */\nclass XLMRobertaForMaskedLM extends XLMRobertaPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<MaskedLMOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new MaskedLMOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * XLMRobertaForSequenceClassification class for performing sequence classification on XLMRoberta models.\n */\nclass XLMRobertaForSequenceClassification extends XLMRobertaPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<SequenceClassifierOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * XLMRobertaForTokenClassification class for performing token classification on XLMRoberta models.\n */\nclass XLMRobertaForTokenClassification extends XLMRobertaPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.\n     */\n    async _call(model_inputs) {\n        return new TokenClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * XLMRobertaForQuestionAnswering class for performing question answering on XLMRoberta models.\n */\nclass XLMRobertaForQuestionAnswering extends XLMRobertaPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     *\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<QuestionAnsweringModelOutput>} returned object\n     */\n    async _call(model_inputs) {\n        return new QuestionAnsweringModelOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// Audio Spectrogram Transformer (AST) models\nclass ASTPreTrainedModel extends PreTrainedModel { };\n\n/**\n * The bare AST Model transformer outputting raw hidden-states without any specific head on top.\n */\nclass ASTModel extends ASTPreTrainedModel { }\n\n/**\n * Audio Spectrogram Transformer model with an audio classification head on top\n * (a linear layer on top of the pooled output) e.g. for datasets like AudioSet, Speech Commands v2.\n */\nclass ASTForAudioClassification extends ASTPreTrainedModel { }\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// Whisper models\nclass WhisperPreTrainedModel extends PreTrainedModel { };\n\n/**\n * WhisperModel class for training Whisper models without a language model head.\n */\nclass WhisperModel extends WhisperPreTrainedModel { }\n\n/**\n * WhisperForConditionalGeneration class for generating conditional outputs from Whisper models.\n */\nclass WhisperForConditionalGeneration extends WhisperPreTrainedModel {\n\n    requires_attention_mask = false;\n    main_input_name = 'input_features';\n\n    /**\n     * Creates a new instance of the `WhisperForConditionalGeneration` class.\n     * @param {Object} config Configuration object for the model.\n     * @param {Object} session ONNX Session object for the model.\n     * @param {Object} decoder_merged_session ONNX Session object for the decoder.\n     * @param {Object} generation_config Configuration object for the generation process.\n     */\n    constructor(config, session, decoder_merged_session, generation_config) {\n        super(config, session);\n        this.decoder_merged_session = decoder_merged_session;\n        this.generation_config = generation_config;\n\n        this.num_decoder_layers = this.config.decoder_layers;\n        this.num_decoder_heads = this.config.decoder_attention_heads;\n        this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads;\n\n        this.num_encoder_layers = this.config.encoder_layers;\n        this.num_encoder_heads = this.config.encoder_attention_heads;\n        this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads;\n    }\n\n    /**\n     * @typedef {Object} WhisperGenerationConfig\n     * @extends GenerationConfig\n     * @property {boolean} [return_timestamps=null] Whether to return the timestamps with the text. This enables the `WhisperTimestampsLogitsProcessor`.\n     * @property {boolean} [return_token_timestamps=null] Whether to return token-level timestamps\n     * with the text. This can be used with or without the `return_timestamps` option. To get word-level\n     * timestamps, use the tokenizer to group the tokens into words.\n     * @property {number} [num_frames=null]  The number of audio frames available in this chunk. This is only used generating word-level timestamps.\n     */\n\n    /**\n     * Generates outputs based on input and generation configuration.\n     * @param {Object} inputs Input data for the model.\n     * @param {WhisperGenerationConfig} generation_config Configuration object for the generation process.\n     * @param {Object} logits_processor Optional logits processor object.\n     * @returns {Promise<Object>} Promise object represents the generated outputs.\n     */\n    async generate(\n        inputs,\n        generation_config = null,\n        logits_processor = null,\n        // {\n        //     return_timestamps = null,\n        //     return_token_timestamps = null,\n        //     language = null,\n        //     task = null,\n        // } = {},\n    ) {\n        // Create generation config object\n        generation_config = this._get_generation_config(generation_config);\n\n\n        // Whisper has additional options for returning timestamps\n        generation_config.return_timestamps ??= false;\n\n        // TODO add language and task\n\n        if (generation_config.return_timestamps) {\n            logits_processor = [new _utils_generation_js__WEBPACK_IMPORTED_MODULE_3__.WhisperTimeStampLogitsProcessor(generation_config)]\n        }\n\n        if (generation_config.return_token_timestamps) {\n            generation_config.output_attentions = true;\n            generation_config.return_dict_in_generate = true;\n\n            if (generation_config.task === 'translate') {\n                console.warn(\"Token-level timestamps may not be reliable for task 'translate'.\")\n            }\n\n            if (!generation_config.alignment_heads) {\n                throw new Error(\n                    \"Model generation config has no `alignment_heads`, token-level timestamps not available. \" +\n                    \"See https://gist.github.com/hollance/42e32852f24243b748ae6bc1f985b13a on how to add this property to the generation config.\"\n                )\n            }\n        }\n\n        const outputs = await super.generate(inputs, generation_config, logits_processor);\n\n        if (generation_config.return_token_timestamps && generation_config.alignment_heads) {\n            outputs[\"token_timestamps\"] = this._extract_token_timestamps(\n                outputs,\n                generation_config.alignment_heads,\n                generation_config.num_frames,\n            )\n        }\n\n        return outputs\n    }\n\n    /**\n     * Calculates token-level timestamps using the encoder-decoder cross-attentions and\n     * dynamic time-warping (DTW) to map each output token to a position in the input audio.\n     * @param {Object} generate_outputs Outputs generated by the model\n     * @param {Tensor[][][]} generate_outputs.cross_attentions The cross attentions output by the model\n     * @param {Tensor[][][]} generate_outputs.decoder_attentions The decoder attentions output by the model\n     * @param {number[][]} generate_outputs.sequences The sequences output by the model\n     * @param {number[][]} alignment_heads Alignment heads of the model\n     * @param {number} [num_frames=null] Number of frames in the input audio.\n     * @param {number} [time_precision=0.02] Precision of the timestamps in seconds\n     * @returns {Tensor} tensor containing the timestamps in seconds for each predicted token\n     */\n    _extract_token_timestamps(generate_outputs, alignment_heads, num_frames = null, time_precision = 0.02) {\n        if (!generate_outputs.cross_attentions) {\n            throw new Error(\n                \"Model outputs must contain cross attentions to extract timestamps. \" +\n                \"This is most likely because the model was not exported with `output_attentions=True`.\"\n            )\n        }\n\n        let median_filter_width = this.config.median_filter_width;\n        if (median_filter_width === undefined) {\n            console.warn(\"Model config has no `median_filter_width`, using default value of 7.\")\n            median_filter_width = 7;\n        }\n\n        const batchedMatrices = generate_outputs.cross_attentions.map(batch => {\n            // Create a list with `decoder_layers` elements, each a tensor of shape\n            // (batch size, attention_heads, output length, input length).\n            let cross_attentions = Array.from({ length: this.config.decoder_layers },\n                (_, i) => (0,_utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.cat)(batch.map(x => x[i]), 2)\n            );\n\n            let weights = (0,_utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.stack)(alignment_heads.map(([l, h]) => {\n                return num_frames\n                    ? cross_attentions[l].slice(null, h, null, [0, num_frames])\n                    : cross_attentions[l].slice(null, h);\n            }));\n            weights = weights.transpose(1, 0, 2, 3)\n\n            let [std, calculatedMean] = (0,_utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.std_mean)(weights, -2, 0, true);\n\n            // Normalize and smoothen the weights.\n            let smoothedWeights = weights.clone(); // [1, 8, seqLength, 1500]\n\n            for (let a = 0; a < smoothedWeights.dims[0]; ++a) {\n                let aTensor = smoothedWeights[a]; // [8, seqLength, 1500]\n\n                for (let b = 0; b < aTensor.dims[0]; ++b) {\n                    let bTensor = aTensor[b]; // [seqLength, 1500]\n\n                    const stdTensor = std[a][b][0]; // [1500]\n                    const meanTensor = calculatedMean[a][b][0]; // [1500]\n\n                    for (let c = 0; c < bTensor.dims[0]; ++c) {\n\n                        let cTensor = bTensor[c]; // [1500]\n                        for (let d = 0; d < cTensor.data.length; ++d) {\n                            cTensor.data[d] = (cTensor.data[d] - meanTensor.data[d]) / stdTensor.data[d]\n                        }\n\n                        // Apply median filter.\n                        cTensor.data.set((0,_transformers_js__WEBPACK_IMPORTED_MODULE_6__.medianFilter)(cTensor.data, median_filter_width))\n                    }\n                }\n            }\n\n            // Average the different cross-attention heads.\n            const matrix = (0,_utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.mean)(smoothedWeights, 1);\n            return matrix;\n        });\n\n        const timestampsShape = [generate_outputs.sequences.length, generate_outputs.sequences[0].length];\n\n        const timestamps = new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.Tensor(\n            'float32',\n            new Float32Array(timestampsShape[0] * timestampsShape[1]),\n            timestampsShape\n        );\n\n        // Perform dynamic time warping on each element of the batch.\n        for (let batch_idx = 0; batch_idx < timestampsShape[0]; ++batch_idx) {\n            // NOTE: Since we run only one batch at a time, we can squeeze to get the same dimensions\n            // as the python implementation\n            const matrix = batchedMatrices[batch_idx].neg().squeeze_(0);\n            let [text_indices, time_indices] = (0,_utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.dynamicTimeWarping)(matrix);\n\n            let diffs = Array.from({ length: text_indices.length - 1 }, (v, i) => text_indices[i + 1] - text_indices[i]);\n            let jumps = (0,_utils_core_js__WEBPACK_IMPORTED_MODULE_1__.mergeArrays)([1], diffs).map(x => !!x); // convert to boolean\n\n            let jump_times = [];\n            for (let i = 0; i < jumps.length; ++i) {\n                if (jumps[i]) {\n                    jump_times.push(time_indices[i] * time_precision);\n                    // NOTE: No point in rounding here, since we set to Float32Array later\n                }\n            }\n            timestamps[batch_idx].data.set(jump_times, 1)\n        }\n\n        return timestamps;\n    }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n/**\n * Vision Encoder-Decoder model based on OpenAI's GPT architecture for image captioning and other vision tasks\n */\nclass VisionEncoderDecoderModel extends PreTrainedModel {\n    main_input_name = 'pixel_values';\n\n    /**\n     * Creates a new instance of the `VisionEncoderDecoderModel` class.\n     * @param {Object} config The configuration object specifying the hyperparameters and other model settings.\n     * @param {Object} session The ONNX session containing the encoder model.\n     * @param {any} decoder_merged_session The ONNX session containing the merged decoder model.\n     * @param {Object} generation_config Configuration object for the generation process.\n     */\n    constructor(config, session, decoder_merged_session, generation_config) {\n        super(config, session);\n        this.decoder_merged_session = decoder_merged_session;\n        this.generation_config = generation_config;\n\n        // Extract configs\n        const encoderConfig = this.config.encoder;\n        const decoderConfig = this.config.decoder;\n\n        // Validate encoder\n        const encoderModelType = encoderConfig.model_type;\n        const encoderModel =\n            MODEL_MAPPING_NAMES_ENCODER_ONLY.get(encoderModelType)\n            ?? MODEL_MAPPING_NAMES_ENCODER_DECODER.get(encoderModelType);\n        if (!encoderModel) {\n            console.warn(`Model type for encoder '${encoderModelType}' not found, assuming encoder-only architecture. Please report this at https://github.com/xenova/transformers.js/issues/new/choose.`);\n        }\n\n        // Validate decoder\n        const decoderModel = MODEL_WITH_LM_HEAD_MAPPING_NAMES.get(decoderConfig.model_type);\n        if (!decoderModel) {\n            throw new Error(`Unable to construct \\`VisionEncoderDecoder\\` due to unsupported decoder: \"${this.config.decoder.model_type}\"`);\n        }\n\n        // @ts-ignore\n        const decoderModelClass = decoderModel[1];\n        // @ts-ignore\n        const decoder = new decoderModelClass(decoderConfig, decoder_merged_session, generation_config);\n\n        this.add_encoder_pkv = 'num_decoder_layers' in decoder;\n        if (this.add_encoder_pkv) {\n            // Decoder is part of an encoder-decoder model\n            this.num_decoder_layers = decoder.num_decoder_layers;\n            this.num_decoder_heads = decoder.num_decoder_heads;\n            this.decoder_dim_kv = decoder.decoder_dim_kv;\n\n            this.num_encoder_layers = decoder.num_encoder_layers;\n            this.num_encoder_heads = decoder.num_encoder_heads;\n            this.encoder_dim_kv = decoder.encoder_dim_kv;\n\n        } else {\n            // Decoder is a decoder-only model\n            this.num_layers = decoder.num_layers;\n            this.num_heads = decoder.num_heads;\n            this.dim_kv = decoder.dim_kv;\n        }\n    }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// CLIP models\nclass CLIPPreTrainedModel extends PreTrainedModel { }\n\n/**\n * CLIP Text and Vision Model with a projection layers on top\n * \n * **Example:** Perform zero-shot image classification with a `CLIPModel`.\n * \n * ```javascript\n * import { AutoTokenizer, AutoProcessor, CLIPModel, RawImage } from '@xenova/transformers';\n * \n * // Load tokenizer, processor, and model\n * let tokenizer = await AutoTokenizer.from_pretrained('Xenova/clip-vit-base-patch16');\n * let processor = await AutoProcessor.from_pretrained('Xenova/clip-vit-base-patch16');\n * let model = await CLIPModel.from_pretrained('Xenova/clip-vit-base-patch16');\n * \n * // Run tokenization\n * let texts = ['a photo of a car', 'a photo of a football match']\n * let text_inputs = tokenizer(texts, { padding: true, truncation: true });\n * \n * // Read image and run processor\n * let image = await RawImage.read('https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/football-match.jpg');\n * let image_inputs = await processor(image);\n * \n * // Run model with both text and pixel inputs\n * let output = await model({ ...text_inputs, ...image_inputs });\n * // {\n * //   logits_per_image: Tensor {\n * //     dims: [ 1, 2 ],\n * //     data: Float32Array(2) [ 18.579734802246094, 24.31830596923828 ],\n * //   },\n * //   logits_per_text: Tensor {\n * //     dims: [ 2, 1 ],\n * //     data: Float32Array(2) [ 18.579734802246094, 24.31830596923828 ],\n * //   },\n * //   text_embeds: Tensor {\n * //     dims: [ 2, 512 ],\n * //     data: Float32Array(1024) [ ... ],\n * //   },\n * //   image_embeds: Tensor {\n * //     dims: [ 1, 512 ],\n * //     data: Float32Array(512) [ ... ],\n * //   }\n * // }\n * ```\n */\nclass CLIPModel extends CLIPPreTrainedModel { }\n\n/**\n * CLIP Text Model with a projection layer on top (a linear layer on top of the pooled output)\n * \n * **Example:** Compute text embeddings with `CLIPTextModelWithProjection`.\n * \n * ```javascript\n * import { AutoTokenizer, CLIPTextModelWithProjection } from '@xenova/transformers';\n * \n * // Load tokenizer and text model\n * const tokenizer = await AutoTokenizer.from_pretrained('Xenova/clip-vit-base-patch16');\n * const text_model = await CLIPTextModelWithProjection.from_pretrained('Xenova/clip-vit-base-patch16');\n * \n * // Run tokenization\n * let texts = ['a photo of a car', 'a photo of a football match'];\n * let text_inputs = tokenizer(texts, { padding: true, truncation: true });\n * \n * // Compute embeddings\n * const { text_embeds } = await text_model(text_inputs);\n * // Tensor {\n * //   dims: [ 2, 512 ],\n * //   type: 'float32',\n * //   data: Float32Array(1024) [ ... ],\n * //   size: 1024\n * // }\n * ```\n */\nclass CLIPTextModelWithProjection extends CLIPPreTrainedModel {\n\n    /** @type {PreTrainedModel.from_pretrained} */\n    static async from_pretrained(pretrained_model_name_or_path, options = {}) {\n        // Update default model file name if not provided\n        options.model_file_name ??= 'text_model';\n        return super.from_pretrained(pretrained_model_name_or_path, options);\n    }\n}\n\n/**\n * CLIP Vision Model with a projection layer on top (a linear layer on top of the pooled output)\n * \n * **Example:** Compute vision embeddings with `CLIPVisionModelWithProjection`.\n * \n * ```javascript\n * import { AutoProcessor, CLIPVisionModelWithProjection, RawImage} from '@xenova/transformers';\n * \n * // Load processor and vision model\n * const processor = await AutoProcessor.from_pretrained('Xenova/clip-vit-base-patch16');\n * const vision_model = await CLIPVisionModelWithProjection.from_pretrained('Xenova/clip-vit-base-patch16');\n * \n * // Read image and run processor\n * let image = await RawImage.read('https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/football-match.jpg');\n * let image_inputs = await processor(image);\n * \n * // Compute embeddings\n * const { image_embeds } = await vision_model(image_inputs);\n * // Tensor {\n * //   dims: [ 1, 512 ],\n * //   type: 'float32',\n * //   data: Float32Array(512) [ ... ],\n * //   size: 512\n * // }\n * ```\n */\nclass CLIPVisionModelWithProjection extends CLIPPreTrainedModel {\n    /** @type {PreTrainedModel.from_pretrained} */\n    static async from_pretrained(pretrained_model_name_or_path, options = {}) {\n        // Update default model file name if not provided\n        options.model_file_name ??= 'vision_model';\n        return super.from_pretrained(pretrained_model_name_or_path, options);\n    }\n}\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// SigLIP models\nclass SiglipPreTrainedModel extends PreTrainedModel { }\n\n/**\n * SigLIP Text and Vision Model with a projection layers on top\n * \n * **Example:** Perform zero-shot image classification with a `SiglipModel`.\n * \n * ```javascript\n * import { AutoTokenizer, AutoProcessor, SiglipModel, RawImage } from '@xenova/transformers';\n * \n * // Load tokenizer, processor, and model\n * const tokenizer = await AutoTokenizer.from_pretrained('Xenova/siglip-base-patch16-224');\n * const processor = await AutoProcessor.from_pretrained('Xenova/siglip-base-patch16-224');\n * const model = await SiglipModel.from_pretrained('Xenova/siglip-base-patch16-224');\n * \n * // Run tokenization\n * const texts = ['a photo of 2 cats', 'a photo of 2 dogs'];\n * const text_inputs = tokenizer(texts, { padding: 'max_length', truncation: true });\n * \n * // Read image and run processor\n * const image = await RawImage.read('http://images.cocodataset.org/val2017/000000039769.jpg');\n * const image_inputs = await processor(image);\n * \n * // Run model with both text and pixel inputs\n * const output = await model({ ...text_inputs, ...image_inputs });\n * // {\n * //   logits_per_image: Tensor {\n * //     dims: [ 1, 2 ],\n * //     data: Float32Array(2) [ -1.6019744873046875, -10.720091819763184 ],\n * //   },\n * //   logits_per_text: Tensor {\n * //     dims: [ 2, 1 ],\n * //     data: Float32Array(2) [ -1.6019744873046875, -10.720091819763184 ],\n * //   },\n * //   text_embeds: Tensor {\n * //     dims: [ 2, 768 ],\n * //     data: Float32Array(1536) [ ... ],\n * //   },\n * //   image_embeds: Tensor {\n * //     dims: [ 1, 768 ],\n * //     data: Float32Array(768) [ ... ],\n * //   }\n * // }\n * ```\n */\nclass SiglipModel extends SiglipPreTrainedModel { }\n\n/**\n * The text model from SigLIP without any head or projection on top.\n * \n * **Example:** Compute text embeddings with `SiglipTextModel`.\n * \n * ```javascript\n * import { AutoTokenizer, SiglipTextModel } from '@xenova/transformers';\n * \n * // Load tokenizer and text model\n * const tokenizer = await AutoTokenizer.from_pretrained('Xenova/siglip-base-patch16-224');\n * const text_model = await SiglipTextModel.from_pretrained('Xenova/siglip-base-patch16-224');\n * \n * // Run tokenization\n * const texts = ['a photo of 2 cats', 'a photo of 2 dogs'];\n * const text_inputs = tokenizer(texts, { padding: 'max_length', truncation: true });\n * \n * // Compute embeddings\n * const { pooler_output } = await text_model(text_inputs);\n * // Tensor {\n * //   dims: [ 2, 768 ],\n * //   type: 'float32',\n * //   data: Float32Array(1536) [ ... ],\n * //   size: 1536\n * // }\n * ```\n */\nclass SiglipTextModel extends SiglipPreTrainedModel {\n\n    /** @type {PreTrainedModel.from_pretrained} */\n    static async from_pretrained(pretrained_model_name_or_path, options = {}) {\n        // Update default model file name if not provided\n        options.model_file_name ??= 'text_model';\n        return super.from_pretrained(pretrained_model_name_or_path, options);\n    }\n}\n\n/**\n * The vision model from SigLIP without any head or projection on top.\n * \n * **Example:** Compute vision embeddings with `SiglipVisionModel`.\n * \n * ```javascript\n * import { AutoProcessor, SiglipVisionModel, RawImage} from '@xenova/transformers';\n * \n * // Load processor and vision model\n * const processor = await AutoProcessor.from_pretrained('Xenova/siglip-base-patch16-224');\n * const vision_model = await SiglipVisionModel.from_pretrained('Xenova/siglip-base-patch16-224');\n * \n * // Read image and run processor\n * const image = await RawImage.read('https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/football-match.jpg');\n * const image_inputs = await processor(image);\n * \n * // Compute embeddings\n * const { pooler_output } = await vision_model(image_inputs);\n * // Tensor {\n * //   dims: [ 1, 768 ],\n * //   type: 'float32',\n * //   data: Float32Array(768) [ ... ],\n * //   size: 768\n * // }\n * ```\n */\nclass SiglipVisionModel extends CLIPPreTrainedModel {\n    /** @type {PreTrainedModel.from_pretrained} */\n    static async from_pretrained(pretrained_model_name_or_path, options = {}) {\n        // Update default model file name if not provided\n        options.model_file_name ??= 'vision_model';\n        return super.from_pretrained(pretrained_model_name_or_path, options);\n    }\n}\n//////////////////////////////////////////////////\n// ChineseCLIP models\nclass ChineseCLIPPreTrainedModel extends PreTrainedModel { }\n\nclass ChineseCLIPModel extends ChineseCLIPPreTrainedModel { }\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// CLIPSeg models\nclass CLIPSegPreTrainedModel extends PreTrainedModel { }\n\nclass CLIPSegModel extends CLIPSegPreTrainedModel { }\n\n/**\n * CLIPSeg model with a Transformer-based decoder on top for zero-shot and one-shot image segmentation.\n * \n * **Example:** Perform zero-shot image segmentation with a `CLIPSegForImageSegmentation` model.\n * \n * ```javascript\n * import { AutoTokenizer, AutoProcessor, CLIPSegForImageSegmentation, RawImage } from '@xenova/transformers';\n * \n * // Load tokenizer, processor, and model\n * const tokenizer = await AutoTokenizer.from_pretrained('Xenova/clipseg-rd64-refined');\n * const processor = await AutoProcessor.from_pretrained('Xenova/clipseg-rd64-refined');\n * const model = await CLIPSegForImageSegmentation.from_pretrained('Xenova/clipseg-rd64-refined');\n * \n * // Run tokenization\n * const texts = ['a glass', 'something to fill', 'wood', 'a jar'];\n * const text_inputs = tokenizer(texts, { padding: true, truncation: true });\n * \n * // Read image and run processor\n * const image = await RawImage.read('https://github.com/timojl/clipseg/blob/master/example_image.jpg?raw=true');\n * const image_inputs = await processor(image);\n * \n * // Run model with both text and pixel inputs\n * const { logits } = await model({ ...text_inputs, ...image_inputs });\n * // logits: Tensor {\n * //   dims: [4, 352, 352],\n * //   type: 'float32',\n * //   data: Float32Array(495616) [ ... ],\n * //   size: 495616\n * // }\n * ```\n * \n * You can visualize the predictions as follows:\n * ```javascript\n * const preds = logits\n *   .unsqueeze_(1)\n *   .sigmoid_()\n *   .mul_(255)\n *   .round_()\n *   .to('uint8');\n * \n * for (let i = 0; i < preds.dims[0]; ++i) {\n *   const img = RawImage.fromTensor(preds[i]);\n *   img.save(`prediction_${i}.png`);\n * }\n * ```\n */\nclass CLIPSegForImageSegmentation extends CLIPSegPreTrainedModel { }\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// GPT2 models\nclass GPT2PreTrainedModel extends PreTrainedModel {\n    /**\n     * Creates a new instance of the `GPT2PreTrainedModel` class.\n     * @param {Object} config The configuration of the model.\n     * @param {any} session The ONNX session containing the model weights.\n     * @param {GenerationConfig} generation_config The generation configuration.\n     */\n    constructor(config, session, generation_config) {\n        super(config, session);\n        this.generation_config = generation_config;\n\n        // config doesn't contain pad_token_id, so we assume it is the eos_token_id\n        this.config.pad_token_id = this.config.eos_token_id\n\n        this.num_heads = this.config.n_head\n        this.num_layers = this.config.n_layer\n        this.dim_kv = this.config.n_embd / this.num_heads;\n    }\n}\n\nclass GPT2Model extends GPT2PreTrainedModel { }\n\n/**\n * GPT-2 language model head on top of the GPT-2 base model. This model is suitable for text generation tasks.\n */\nclass GPT2LMHeadModel extends GPT2PreTrainedModel { }\n// export class GPT2ForSequenceClassification extends GPT2PreTrainedModel {\n// TODO\n// }\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// GPTNeo models\nclass GPTNeoPreTrainedModel extends PreTrainedModel {\n    /**\n     * Creates a new instance of the `GPTNeoPreTrainedModel` class.\n     * @param {Object} config The configuration of the model.\n     * @param {any} session The ONNX session containing the model weights.\n     * @param {GenerationConfig} generation_config The generation configuration.\n     */\n    constructor(config, session, generation_config) {\n        super(config, session);\n        this.generation_config = generation_config;\n\n        // config doesn't contain pad_token_id, so we assume it is the eos_token_id\n        this.config.pad_token_id = this.config.eos_token_id\n\n        this.num_heads = this.config.num_heads;\n        this.num_layers = this.config.num_layers;\n        this.dim_kv = this.config.hidden_size / this.num_heads;\n    }\n}\nclass GPTNeoModel extends GPTNeoPreTrainedModel { }\n\nclass GPTNeoForCausalLM extends GPTNeoPreTrainedModel { }\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// GPTNeoX models\nclass GPTNeoXPreTrainedModel extends PreTrainedModel {\n    /**\n     * Creates a new instance of the `GPTNeoXPreTrainedModel` class.\n     * @param {Object} config The configuration of the model.\n     * @param {any} session The ONNX session containing the model weights.\n     * @param {GenerationConfig} generation_config The generation configuration.\n     */\n    constructor(config, session, generation_config) {\n        super(config, session);\n        this.generation_config = generation_config;\n\n        // config doesn't contain pad_token_id, so we assume it is the eos_token_id\n        this.config.pad_token_id = this.config.eos_token_id\n\n        this.num_heads = this.config.num_attention_heads;\n        this.num_layers = this.config.num_hidden_layers;\n        this.dim_kv = this.config.hidden_size / this.num_heads;\n    }\n}\nclass GPTNeoXModel extends GPTNeoXPreTrainedModel { }\n\nclass GPTNeoXForCausalLM extends GPTNeoXPreTrainedModel { }\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// GPT-J models\nclass GPTJPreTrainedModel extends PreTrainedModel {\n    /**\n     * Creates a new instance of the `GPTJPreTrainedModel` class.\n     * @param {Object} config The configuration of the model.\n     * @param {any} session The ONNX session containing the model weights.\n     * @param {GenerationConfig} generation_config The generation configuration.\n     */\n    constructor(config, session, generation_config) {\n        super(config, session);\n        this.generation_config = generation_config;\n\n        // config doesn't contain pad_token_id, so we assume it is the eos_token_id\n        this.config.pad_token_id = this.config.eos_token_id\n\n        this.num_heads = this.config.n_head\n        this.num_layers = this.config.n_layer\n        this.dim_kv = this.config.n_embd / this.num_heads;\n    }\n}\n\nclass GPTJModel extends GPTJPreTrainedModel { }\n\nclass GPTJForCausalLM extends GPTJPreTrainedModel { }\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// GPTBigCode models\nclass GPTBigCodePreTrainedModel extends PreTrainedModel {\n    /**\n     * Creates a new instance of the `GPTBigCodePreTrainedModel` class.\n     * @param {Object} config The configuration of the model.\n     * @param {any} session The ONNX session containing the model weights.\n     * @param {GenerationConfig} generation_config The generation configuration.\n     */\n    constructor(config, session, generation_config) {\n        super(config, session);\n        this.generation_config = generation_config;\n\n        // config doesn't contain pad_token_id, so we assume it is the eos_token_id\n        this.config.pad_token_id = this.config.eos_token_id\n\n        this.num_heads = this.config.n_head\n        this.num_layers = this.config.n_layer\n        this.dim_kv = this.config.n_embd / this.num_heads;\n    }\n}\n\nclass GPTBigCodeModel extends GPTBigCodePreTrainedModel { }\n\nclass GPTBigCodeForCausalLM extends GPTBigCodePreTrainedModel { }\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// CodeGen models\nclass CodeGenPreTrainedModel extends PreTrainedModel {\n    /**\n     * Creates a new instance of the `CodeGenPreTrainedModel` class.\n     * @param {Object} config The model configuration object.\n     * @param {Object} session The ONNX session object.\n     * @param {GenerationConfig} generation_config The generation configuration.\n     */\n    constructor(config, session, generation_config) {\n        super(config, session);\n        this.generation_config = generation_config;\n\n        // config doesn't contain pad_token_id, so we assume it is the eos_token_id\n        this.config.pad_token_id = this.config.eos_token_id\n\n        this.num_heads = this.config.n_head\n        this.num_layers = this.config.n_layer\n        this.dim_kv = this.config.n_embd / this.num_heads;\n    }\n}\n/**\n * CodeGenModel is a class representing a code generation model without a language model head.\n */\nclass CodeGenModel extends CodeGenPreTrainedModel { }\n\n/**\n * CodeGenForCausalLM is a class that represents a code generation model based on the GPT-2 architecture. It extends the `CodeGenPreTrainedModel` class.\n */\nclass CodeGenForCausalLM extends CodeGenPreTrainedModel { }\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// LLama models\n\n/**\n * The bare LLama Model outputting raw hidden-states without any specific head on top.\n */\nclass LlamaPreTrainedModel extends PreTrainedModel {\n    /**\n     * Creates a new instance of the `LlamaPreTrainedModel` class.\n     * @param {Object} config The model configuration object.\n     * @param {Object} session The ONNX session object.\n     * @param {GenerationConfig} generation_config The generation configuration.\n     */\n    constructor(config, session, generation_config) {\n        super(config, session);\n        this.generation_config = generation_config;\n\n        // config doesn't contain pad_token_id, so we assume it is the eos_token_id\n        this.config.pad_token_id = this.config.eos_token_id\n\n        this.num_heads = this.config.num_key_value_heads ?? this.config.num_attention_heads\n        this.num_layers = this.config.num_hidden_layers\n        this.dim_kv = this.config.hidden_size / this.config.num_attention_heads\n    }\n}\n/**\n * The bare LLaMA Model outputting raw hidden-states without any specific head on top.\n */\nclass LlamaModel extends LlamaPreTrainedModel { }\n\nclass LlamaForCausalLM extends LlamaPreTrainedModel { }\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// Qwen2 models\n\n/**\n * The bare Qwen2 Model outputting raw hidden-states without any specific head on top.\n */\nclass Qwen2PreTrainedModel extends PreTrainedModel {\n    /**\n     * Creates a new instance of the `Qwen2PreTrainedModel` class.\n     * @param {Object} config The model configuration object.\n     * @param {Object} session The ONNX session object.\n     * @param {GenerationConfig} generation_config The generation configuration.\n     */\n    constructor(config, session, generation_config) {\n        super(config, session);\n        this.generation_config = generation_config;\n\n        // config doesn't contain pad_token_id, so we assume it is the eos_token_id\n        this.config.pad_token_id = this.config.eos_token_id\n\n        this.num_heads = this.config.num_key_value_heads ?? this.config.num_attention_heads\n        this.num_layers = this.config.num_hidden_layers\n        this.dim_kv = this.config.hidden_size / this.config.num_attention_heads\n    }\n}\n/**\n * The bare Qwen2 Model outputting raw hidden-states without any specific head on top.\n */\nclass Qwen2Model extends Qwen2PreTrainedModel { }\n\nclass Qwen2ForCausalLM extends Qwen2PreTrainedModel { }\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// Phi models\n\nclass PhiPreTrainedModel extends PreTrainedModel {\n    /**\n     * Creates a new instance of the `PhiPreTrainedModel` class.\n     * @param {Object} config The model configuration object.\n     * @param {Object} session The ONNX session object.\n     * @param {GenerationConfig} generation_config The generation configuration.\n     */\n    constructor(config, session, generation_config) {\n        super(config, session);\n        this.generation_config = generation_config;\n\n        // config doesn't contain pad_token_id, so we assume it is the eos_token_id\n        this.config.pad_token_id = this.config.eos_token_id;\n\n        this.num_heads = this.config.num_attention_heads;\n        this.num_layers = this.config.num_hidden_layers;\n        this.dim_kv = this.config.hidden_size / this.num_heads;\n    }\n}\n/**\n * The bare Phi Model outputting raw hidden-states without any specific head on top.\n */\nclass PhiModel extends PhiPreTrainedModel { }\n\nclass PhiForCausalLM extends PhiPreTrainedModel { }\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// Bloom models\n/**\n * The Bloom Model transformer with a language modeling head on top (linear layer with weights tied to the input embeddings).\n */\nclass BloomPreTrainedModel extends PreTrainedModel {\n    /**\n     * Creates a new instance of the `BloomPreTrainedModel` class.\n     * @param {Object} config The configuration of the model.\n     * @param {any} session The ONNX session containing the model weights.\n     * @param {GenerationConfig} generation_config The generation configuration.\n     */\n    constructor(config, session, generation_config) {\n        super(config, session);\n        this.generation_config = generation_config;\n\n        // config doesn't contain pad_token_id, so we assume it is the eos_token_id\n        this.config.pad_token_id = this.config.eos_token_id\n\n        this.num_heads = this.config.n_head\n        this.num_layers = this.config.n_layer\n        this.dim_kv = this.config.hidden_size / this.num_heads;\n    }\n}\n\n/**\n * The bare Bloom Model transformer outputting raw hidden-states without any specific head on top.\n */\nclass BloomModel extends BloomPreTrainedModel { }\n\n/**\n * The Bloom Model transformer with a language modeling head on top (linear layer with weights tied to the input embeddings).\n */\nclass BloomForCausalLM extends BloomPreTrainedModel { }\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// MPT models\nclass MptPreTrainedModel extends PreTrainedModel {\n    /**\n     * Creates a new instance of the `MptPreTrainedModel` class.\n     * @param {Object} config The model configuration object.\n     * @param {Object} session The ONNX session object.\n     * @param {GenerationConfig} generation_config The generation configuration.\n     */\n    constructor(config, session, generation_config) {\n        super(config, session);\n        this.generation_config = generation_config;\n\n        // config doesn't contain pad_token_id, so we assume it is the eos_token_id\n        this.config.pad_token_id = this.config.eos_token_id\n\n        this.num_heads = this.config.n_heads\n        this.num_layers = this.config.n_layers\n        this.dim_kv = this.config.d_model / this.num_heads;\n    }\n}\n\n/**\n * The bare Mpt Model transformer outputting raw hidden-states without any specific head on top.\n */\nclass MptModel extends MptPreTrainedModel { }\n\n/**\n * The MPT Model transformer with a language modeling head on top (linear layer with weights tied to the input embeddings).\n */\nclass MptForCausalLM extends MptPreTrainedModel { }\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// OPT models\nclass OPTPreTrainedModel extends PreTrainedModel {\n    /**\n     * Creates a new instance of the `OPTPreTrainedModel` class.\n     * @param {Object} config The model configuration object.\n     * @param {Object} session The ONNX session object.\n     * @param {GenerationConfig} generation_config The generation configuration.\n     */\n    constructor(config, session, generation_config) {\n        super(config, session);\n        this.generation_config = generation_config;\n\n        // config doesn't contain pad_token_id, so we assume it is the eos_token_id\n        this.config.pad_token_id = this.config.eos_token_id\n\n        this.num_heads = this.config.num_attention_heads;\n        this.num_layers = this.config.num_hidden_layers;\n        this.dim_kv = this.config.hidden_size / this.num_heads;\n    }\n}\n\n/**\n * The bare OPT Model outputting raw hidden-states without any specific head on top.\n */\nclass OPTModel extends OPTPreTrainedModel { }\n\n/**\n * The OPT Model transformer with a language modeling head on top (linear layer with weights tied to the input embeddings).\n */\nclass OPTForCausalLM extends OPTPreTrainedModel { }\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\nclass ViTPreTrainedModel extends PreTrainedModel { }\nclass ViTModel extends ViTPreTrainedModel { }\nclass ViTForImageClassification extends ViTPreTrainedModel {\n    /**\n     * @param {any} model_inputs\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\nclass VitMattePreTrainedModel extends PreTrainedModel { }\n\n/**\n * ViTMatte framework leveraging any vision backbone e.g. for ADE20k, CityScapes.\n * \n * **Example:** Perform image matting with a `VitMatteForImageMatting` model.\n * ```javascript\n * import { AutoProcessor, VitMatteForImageMatting, RawImage } from '@xenova/transformers';\n * \n * // Load processor and model\n * const processor = await AutoProcessor.from_pretrained('Xenova/vitmatte-small-distinctions-646');\n * const model = await VitMatteForImageMatting.from_pretrained('Xenova/vitmatte-small-distinctions-646');\n * \n * // Load image and trimap\n * const image = await RawImage.fromURL('https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/vitmatte_image.png');\n * const trimap = await RawImage.fromURL('https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/vitmatte_trimap.png');\n * \n * // Prepare image + trimap for the model\n * const inputs = await processor(image, trimap);\n * \n * // Predict alpha matte\n * const { alphas } = await model(inputs);\n * // Tensor {\n * //   dims: [ 1, 1, 640, 960 ],\n * //   type: 'float32',\n * //   size: 614400,\n * //   data: Float32Array(614400) [ 0.9894027709960938, 0.9970508813858032, ... ]\n * // }\n * ```\n * \n * You can visualize the alpha matte as follows:\n * ```javascript\n * import { Tensor, cat } from '@xenova/transformers';\n * \n * // Visualize predicted alpha matte\n * const imageTensor = new Tensor(\n *   'uint8',\n *   new Uint8Array(image.data),\n *   [image.height, image.width, image.channels]\n * ).transpose(2, 0, 1);\n * \n * // Convert float (0-1) alpha matte to uint8 (0-255)\n * const alphaChannel = alphas\n *   .squeeze(0)\n *   .mul_(255)\n *   .clamp_(0, 255)\n *   .round_()\n *   .to('uint8');\n * \n * // Concatenate original image with predicted alpha\n * const imageData = cat([imageTensor, alphaChannel], 0);\n * \n * // Save output image\n * const outputImage = RawImage.fromTensor(imageData);\n * outputImage.save('output.png');\n * ```\n */\nclass VitMatteForImageMatting extends VitMattePreTrainedModel {\n    /**\n     * @param {any} model_inputs\n     */\n    async _call(model_inputs) {\n        return new ImageMattingOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\nclass MobileViTPreTrainedModel extends PreTrainedModel { }\nclass MobileViTModel extends MobileViTPreTrainedModel { }\nclass MobileViTForImageClassification extends MobileViTPreTrainedModel {\n    /**\n     * @param {any} model_inputs\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n// TODO: MobileViTForSemanticSegmentation\n\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\nclass OwlViTPreTrainedModel extends PreTrainedModel { }\nclass OwlViTModel extends OwlViTPreTrainedModel { }\nclass OwlViTForObjectDetection extends OwlViTPreTrainedModel { }\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\nclass Owlv2PreTrainedModel extends PreTrainedModel { }\nclass Owlv2Model extends Owlv2PreTrainedModel { }\nclass Owlv2ForObjectDetection extends Owlv2PreTrainedModel { }\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// Beit Models\nclass BeitPreTrainedModel extends PreTrainedModel { }\nclass BeitModel extends BeitPreTrainedModel { }\nclass BeitForImageClassification extends BeitPreTrainedModel {\n    /**\n     * @param {any} model_inputs\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\nclass DetrPreTrainedModel extends PreTrainedModel { }\nclass DetrModel extends DetrPreTrainedModel { }\nclass DetrForObjectDetection extends DetrPreTrainedModel {\n    /**\n     * @param {any} model_inputs\n     */\n    async _call(model_inputs) {\n        return new DetrObjectDetectionOutput(await super._call(model_inputs));\n    }\n}\n\nclass DetrForSegmentation extends DetrPreTrainedModel {\n    /**\n     * Runs the model with the provided inputs\n     * @param {Object} model_inputs Model inputs\n     * @returns {Promise<DetrSegmentationOutput>} Object containing segmentation outputs\n     */\n    async _call(model_inputs) {\n        return new DetrSegmentationOutput(await super._call(model_inputs));\n    }\n}\n\nclass DetrObjectDetectionOutput extends ModelOutput {\n    /**\n     * @param {Object} output The output of the model.\n     * @param {Tensor} output.logits Classification logits (including no-object) for all queries.\n     * @param {Tensor} output.pred_boxes Normalized boxes coordinates for all queries, represented as (center_x, center_y, width, height).\n     * These values are normalized in [0, 1], relative to the size of each individual image in the batch (disregarding possible padding).\n     */\n    constructor({ logits, pred_boxes }) {\n        super();\n        this.logits = logits;\n        this.pred_boxes = pred_boxes;\n    }\n}\n\nclass DetrSegmentationOutput extends ModelOutput {\n    /**\n     * @param {Object} output The output of the model.\n     * @param {Tensor} output.logits The output logits of the model.\n     * @param {Tensor} output.pred_boxes Predicted boxes.\n     * @param {Tensor} output.pred_masks Predicted masks.\n     */\n    constructor({ logits, pred_boxes, pred_masks }) {\n        super();\n        this.logits = logits;\n        this.pred_boxes = pred_boxes;\n        this.pred_masks = pred_masks;\n    }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\nclass TableTransformerPreTrainedModel extends PreTrainedModel { }\n\n/**\n * The bare Table Transformer Model (consisting of a backbone and encoder-decoder Transformer)\n * outputting raw hidden-states without any specific head on top.\n */\nclass TableTransformerModel extends TableTransformerPreTrainedModel { }\n\n/**\n * Table Transformer Model (consisting of a backbone and encoder-decoder Transformer)\n * with object detection heads on top, for tasks such as COCO detection.\n */\nclass TableTransformerForObjectDetection extends TableTransformerPreTrainedModel {\n    /**\n     * @param {any} model_inputs\n     */\n    async _call(model_inputs) {\n        return new TableTransformerObjectDetectionOutput(await super._call(model_inputs));\n    }\n}\nclass TableTransformerObjectDetectionOutput extends DetrObjectDetectionOutput { }\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\nclass DeiTPreTrainedModel extends PreTrainedModel { }\nclass DeiTModel extends DeiTPreTrainedModel { }\nclass DeiTForImageClassification extends DeiTPreTrainedModel {\n    /**\n     * @param {any} model_inputs\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n/**\n * An abstract class to handle weights initialization and a simple interface for downloading and loading pretrained models.\n */\nclass ResNetPreTrainedModel extends PreTrainedModel { }\n\n/**\n * The bare ResNet model outputting raw features without any specific head on top.\n */\nclass ResNetModel extends ResNetPreTrainedModel { }\n\n/**\n * ResNet Model with an image classification head on top (a linear layer on top of the pooled features), e.g. for ImageNet.\n */\nclass ResNetForImageClassification extends ResNetPreTrainedModel {\n    /**\n     * @param {any} model_inputs\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\nclass SwinPreTrainedModel extends PreTrainedModel { }\nclass SwinModel extends SwinPreTrainedModel { }\nclass SwinForImageClassification extends SwinPreTrainedModel {\n    /**\n     * @param {any} model_inputs\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\nclass Swin2SRPreTrainedModel extends PreTrainedModel { }\n\n/**\n * The bare Swin2SR Model transformer outputting raw hidden-states without any specific head on top.\n */\nclass Swin2SRModel extends Swin2SRPreTrainedModel { }\n\n/**\n * Swin2SR Model transformer with an upsampler head on top for image super resolution and restoration.\n * \n * **Example:** Super-resolution w/ `Xenova/swin2SR-classical-sr-x2-64`.\n * \n * ```javascript\n * import { AutoProcessor, Swin2SRForImageSuperResolution, RawImage } from '@xenova/transformers';\n * \n * // Load processor and model\n * const model_id = 'Xenova/swin2SR-classical-sr-x2-64';\n * const processor = await AutoProcessor.from_pretrained(model_id);\n * const model = await Swin2SRForImageSuperResolution.from_pretrained(model_id);\n * \n * // Prepare model inputs\n * const url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/butterfly.jpg';\n * const image = await RawImage.fromURL(url);\n * const inputs = await processor(image);\n * \n * // Run model\n * const outputs = await model(inputs);\n * \n * // Convert Tensor to RawImage\n * const output = outputs.reconstruction.squeeze().clamp_(0, 1).mul_(255).round_().to('uint8');\n * const outputImage = RawImage.fromTensor(output);\n * // RawImage {\n * //   data: Uint8Array(786432) [ 41, 31, 24, ... ],\n * //   width: 512,\n * //   height: 512,\n * //   channels: 3\n * // }\n * ```\n */\nclass Swin2SRForImageSuperResolution extends Swin2SRPreTrainedModel { }\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\nclass DPTPreTrainedModel extends PreTrainedModel { }\n\n/**\n * The bare DPT Model transformer outputting raw hidden-states without any specific head on top.\n */\nclass DPTModel extends DPTPreTrainedModel { }\n\n/**\n * DPT Model with a depth estimation head on top (consisting of 3 convolutional layers) e.g. for KITTI, NYUv2.\n * \n * **Example:** Depth estimation w/ `Xenova/dpt-hybrid-midas`.\n * ```javascript\n * import { DPTForDepthEstimation, AutoProcessor, RawImage, interpolate, max } from '@xenova/transformers';\n * \n * // Load model and processor\n * const model_id = 'Xenova/dpt-hybrid-midas';\n * const model = await DPTForDepthEstimation.from_pretrained(model_id);\n * const processor = await AutoProcessor.from_pretrained(model_id);\n * \n * // Load image from URL\n * const url = 'http://images.cocodataset.org/val2017/000000039769.jpg';\n * const image = await RawImage.fromURL(url);\n * \n * // Prepare image for the model\n * const inputs = await processor(image);\n * \n * // Run model\n * const { predicted_depth } = await model(inputs);\n * \n * // Interpolate to original size\n * const prediction = interpolate(predicted_depth, image.size.reverse(), 'bilinear', false);\n * \n * // Visualize the prediction\n * const formatted = prediction.mul_(255 / max(prediction.data)[0]).to('uint8');\n * const depth = RawImage.fromTensor(formatted);\n * // RawImage {\n * //   data: Uint8Array(307200) [ 85, 85, 84, ... ],\n * //   width: 640,\n * //   height: 480,\n * //   channels: 1\n * // }\n * ```\n */\nclass DPTForDepthEstimation extends DPTPreTrainedModel { }\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\nclass DepthAnythingPreTrainedModel extends PreTrainedModel { }\n\n/**\n * Depth Anything Model with a depth estimation head on top (consisting of 3 convolutional layers) e.g. for KITTI, NYUv2.\n */\nclass DepthAnythingForDepthEstimation extends DepthAnythingPreTrainedModel { }\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\nclass GLPNPreTrainedModel extends PreTrainedModel { }\n\n/**\n * The bare GLPN encoder (Mix-Transformer) outputting raw hidden-states without any specific head on top.\n */\nclass GLPNModel extends GLPNPreTrainedModel { }\n\n/**\n * GLPN Model transformer with a lightweight depth estimation head on top e.g. for KITTI, NYUv2.\n * \n * **Example:** Depth estimation w/ `Xenova/glpn-kitti`.\n * ```javascript\n * import { GLPNForDepthEstimation, AutoProcessor, RawImage, interpolate, max } from '@xenova/transformers';\n * \n * // Load model and processor\n * const model_id = 'Xenova/glpn-kitti';\n * const model = await GLPNForDepthEstimation.from_pretrained(model_id);\n * const processor = await AutoProcessor.from_pretrained(model_id);\n * \n * // Load image from URL\n * const url = 'http://images.cocodataset.org/val2017/000000039769.jpg';\n * const image = await RawImage.fromURL(url);\n * \n * // Prepare image for the model\n * const inputs = await processor(image);\n * \n * // Run model\n * const { predicted_depth } = await model(inputs);\n * \n * // Interpolate to original size\n * const prediction = interpolate(predicted_depth, image.size.reverse(), 'bilinear', false);\n * \n * // Visualize the prediction\n * const formatted = prediction.mul_(255 / max(prediction.data)[0]).to('uint8');\n * const depth = RawImage.fromTensor(formatted);\n * // RawImage {\n * //   data: Uint8Array(307200) [ 207, 169, 154, ... ],\n * //   width: 640,\n * //   height: 480,\n * //   channels: 1\n * // }\n * ```\n */\nclass GLPNForDepthEstimation extends GLPNPreTrainedModel { }\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\nclass DonutSwinPreTrainedModel extends PreTrainedModel { }\n\n/**\n * The bare Donut Swin Model transformer outputting raw hidden-states without any specific head on top.\n * \n * **Example:** Step-by-step Document Parsing.\n * \n * ```javascript\n * import { AutoProcessor, AutoTokenizer, AutoModelForVision2Seq, RawImage } from '@xenova/transformers';\n * \n * // Choose model to use\n * const model_id = 'Xenova/donut-base-finetuned-cord-v2';\n * \n * // Prepare image inputs\n * const processor = await AutoProcessor.from_pretrained(model_id);\n * const url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/receipt.png';\n * const image = await RawImage.read(url);\n * const image_inputs = await processor(image);\n * \n * // Prepare decoder inputs\n * const tokenizer = await AutoTokenizer.from_pretrained(model_id);\n * const task_prompt = '<s_cord-v2>';\n * const decoder_input_ids = tokenizer(task_prompt, {\n *   add_special_tokens: false,\n * }).input_ids;\n * \n * // Create the model\n * const model = await AutoModelForVision2Seq.from_pretrained(model_id);\n * \n * // Run inference\n * const output = await model.generate(image_inputs.pixel_values, {\n *   decoder_input_ids,\n *   max_length: model.config.decoder.max_position_embeddings,\n * });\n * \n * // Decode output\n * const decoded = tokenizer.batch_decode(output)[0];\n * // <s_cord-v2><s_menu><s_nm> CINNAMON SUGAR</s_nm><s_unitprice> 17,000</s_unitprice><s_cnt> 1 x</s_cnt><s_price> 17,000</s_price></s_menu><s_sub_total><s_subtotal_price> 17,000</s_subtotal_price></s_sub_total><s_total><s_total_price> 17,000</s_total_price><s_cashprice> 20,000</s_cashprice><s_changeprice> 3,000</s_changeprice></s_total></s>\n * ```\n * \n * **Example:** Step-by-step Document Visual Question Answering (DocVQA)\n * \n * ```javascript\n * import { AutoProcessor, AutoTokenizer, AutoModelForVision2Seq, RawImage } from '@xenova/transformers';\n * \n * // Choose model to use\n * const model_id = 'Xenova/donut-base-finetuned-docvqa';\n * \n * // Prepare image inputs\n * const processor = await AutoProcessor.from_pretrained(model_id);\n * const url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/invoice.png';\n * const image = await RawImage.read(url);\n * const image_inputs = await processor(image);\n * \n * // Prepare decoder inputs\n * const tokenizer = await AutoTokenizer.from_pretrained(model_id);\n * const question = 'What is the invoice number?';\n * const task_prompt = `<s_docvqa><s_question>${question}</s_question><s_answer>`;\n * const decoder_input_ids = tokenizer(task_prompt, {\n *   add_special_tokens: false,\n * }).input_ids;\n * \n * // Create the model\n * const model = await AutoModelForVision2Seq.from_pretrained(model_id);\n * \n * // Run inference\n * const output = await model.generate(image_inputs.pixel_values, {\n *   decoder_input_ids,\n *   max_length: model.config.decoder.max_position_embeddings,\n * });\n * \n * // Decode output\n * const decoded = tokenizer.batch_decode(output)[0];\n * // <s_docvqa><s_question> What is the invoice number?</s_question><s_answer> us-001</s_answer></s>\n * ```\n */\nclass DonutSwinModel extends DonutSwinPreTrainedModel { }\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\nclass ConvNextPreTrainedModel extends PreTrainedModel { }\n\n/**\n * The bare ConvNext model outputting raw features without any specific head on top.\n */\nclass ConvNextModel extends ConvNextPreTrainedModel { }\n\n/**\n * ConvNext Model with an image classification head on top (a linear layer on top of the pooled features), e.g. for ImageNet.\n */\nclass ConvNextForImageClassification extends ConvNextPreTrainedModel {\n    /**\n     * @param {any} model_inputs\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\nclass ConvNextV2PreTrainedModel extends PreTrainedModel { }\n\n/**\n * The bare ConvNextV2 model outputting raw features without any specific head on top.\n */\nclass ConvNextV2Model extends ConvNextV2PreTrainedModel { }\n\n/**\n * ConvNextV2 Model with an image classification head on top (a linear layer on top of the pooled features), e.g. for ImageNet.\n */\nclass ConvNextV2ForImageClassification extends ConvNextV2PreTrainedModel {\n    /**\n     * @param {any} model_inputs\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\nclass Dinov2PreTrainedModel extends PreTrainedModel { }\n\n/**\n * The bare DINOv2 Model transformer outputting raw hidden-states without any specific head on top.\n */\nclass Dinov2Model extends Dinov2PreTrainedModel { }\n\n/**\n * Dinov2 Model transformer with an image classification head on top (a linear layer on top of the final hidden state of the [CLS] token) e.g. for ImageNet.\n */\nclass Dinov2ForImageClassification extends Dinov2PreTrainedModel {\n    /**\n     * @param {any} model_inputs\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\nclass YolosPreTrainedModel extends PreTrainedModel { }\nclass YolosModel extends YolosPreTrainedModel { }\nclass YolosForObjectDetection extends YolosPreTrainedModel {\n    /**\n     * @param {any} model_inputs\n     */\n    async _call(model_inputs) {\n        return new YolosObjectDetectionOutput(await super._call(model_inputs));\n    }\n}\n\nclass YolosObjectDetectionOutput extends ModelOutput {\n    /**\n     * @param {Object} output The output of the model.\n     * @param {Tensor} output.logits Classification logits (including no-object) for all queries.\n     * @param {Tensor} output.pred_boxes Normalized boxes coordinates for all queries, represented as (center_x, center_y, width, height).\n     * These values are normalized in [0, 1], relative to the size of each individual image in the batch (disregarding possible padding).\n     */\n    constructor({ logits, pred_boxes }) {\n        super();\n        this.logits = logits;\n        this.pred_boxes = pred_boxes;\n    }\n}\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\nclass SamPreTrainedModel extends PreTrainedModel { }\n\n/**\n * Segment Anything Model (SAM) for generating segmentation masks, given an input image\n * and optional 2D location and bounding boxes.\n * \n * **Example:** Perform mask generation w/ `Xenova/sam-vit-base`.\n * ```javascript\n * import { SamModel, AutoProcessor, RawImage } from '@xenova/transformers';\n * \n * const model = await SamModel.from_pretrained('Xenova/sam-vit-base');\n * const processor = await AutoProcessor.from_pretrained('Xenova/sam-vit-base');\n * \n * const img_url = 'https://huggingface.co/ybelkada/segment-anything/resolve/main/assets/car.png';\n * const raw_image = await RawImage.read(img_url);\n * const input_points = [[[450, 600]]] // 2D localization of a window\n * \n * const inputs = await processor(raw_image, input_points);\n * const outputs = await model(inputs);\n * \n * const masks = await processor.post_process_masks(outputs.pred_masks, inputs.original_sizes, inputs.reshaped_input_sizes);\n * // [\n * //   Tensor {\n * //     dims: [ 1, 3, 1764, 2646 ],\n * //     type: 'bool',\n * //     data: Uint8Array(14002632) [ ... ],\n * //     size: 14002632\n * //   }\n * // ]\n * const scores = outputs.iou_scores;\n * // Tensor {\n * //   dims: [ 1, 1, 3 ],\n * //   type: 'float32',\n * //   data: Float32Array(3) [\n * //     0.8892380595207214,\n * //     0.9311248064041138,\n * //     0.983696699142456\n * //   ],\n * //   size: 3\n * // }\n * ```\n */\nclass SamModel extends SamPreTrainedModel {\n    /**\n     * Creates a new instance of the `SamModel` class.\n     * @param {Object} config The configuration object specifying the hyperparameters and other model settings.\n     * @param {Object} vision_encoder The ONNX session containing the vision encoder model.\n     * @param {any} prompt_encoder_mask_decoder The ONNX session containing the prompt encoder and mask decoder model.\n     */\n    constructor(config, vision_encoder, prompt_encoder_mask_decoder) {\n        super(config, vision_encoder);\n        this.prompt_encoder_mask_decoder = prompt_encoder_mask_decoder;\n    }\n\n    /**\n     * Compute image embeddings and positional image embeddings, given the pixel values of an image.\n     * @param {Object} model_inputs Object containing the model inputs.\n     * @param {Tensor} model_inputs.pixel_values Pixel values obtained using a `SamProcessor`.\n     * @returns {Promise<{ image_embeddings: Tensor, image_positional_embeddings: Tensor }>} The image embeddings and positional image embeddings.\n     */\n    async get_image_embeddings({ pixel_values }) {\n        // in:\n        //  - pixel_values: tensor.float32[batch_size,3,1024,1024]\n        // \n        // out:\n        //  - image_embeddings: tensor.float32[batch_size,256,64,64]\n        //  - image_positional_embeddings: tensor.float32[batch_size,256,64,64]\n        return await encoderForward(this, { pixel_values })\n    }\n\n    /**\n     * @typedef {Object} SamModelInputs Object containing the model inputs.\n     * @property {Tensor} pixel_values Pixel values as a Tensor with shape `(batch_size, num_channels, height, width)`.\n     * These can be obtained using a `SamProcessor`.\n     * @property {Tensor} input_points Input 2D spatial points with shape `(batch_size, num_points, 2)`.\n     * This is used by the prompt encoder to encode the prompt.\n     * @property {Tensor} [input_labels] Input labels for the points, as a Tensor of shape `(batch_size, point_batch_size, num_points)`.\n     * This is used by the prompt encoder to encode the prompt. There are 4 types of labels:\n     *  - `1`: the point is a point that contains the object of interest\n     *  - `0`: the point is a point that does not contain the object of interest\n     *  - `-1`: the point corresponds to the background\n     *  - `-10`: the point is a padding point, thus should be ignored by the prompt encoder\n     * @property {Tensor} [image_embeddings] Image embeddings used by the mask decoder.\n     * @property {Tensor} [image_positional_embeddings] Image positional embeddings used by the mask decoder.\n     */\n\n    /**\n     * @param {SamModelInputs} model_inputs Object containing the model inputs.\n     * @returns {Promise<Object>} The output of the model.\n     */\n    async forward(model_inputs) {\n        if (!model_inputs.image_embeddings || !model_inputs.image_positional_embeddings) {\n            // Compute the image embeddings if they are missing\n            model_inputs = {\n                ...model_inputs,\n                ...(await this.get_image_embeddings(model_inputs))\n            }\n        }\n\n        if (!model_inputs.input_labels) {\n            // Set default input labels if they are missing\n            const shape = model_inputs.input_points.dims.slice(0, -1);\n            const numElements = shape.reduce((a, b) => a * b, 1);\n            model_inputs.input_labels = new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.Tensor(\n                'int64',\n                new BigInt64Array(numElements).fill(1n),\n                shape\n            );\n        }\n\n        // Returns:\n        //  - iou_scores: tensor.float32[batch_size,point_batch_size,3]\n        //  - pred_masks: tensor.float32[batch_size,point_batch_size,3,256,256]\n        return await sessionRun(this.prompt_encoder_mask_decoder, {\n            input_points: model_inputs.input_points,\n            input_labels: model_inputs.input_labels,\n            image_embeddings: model_inputs.image_embeddings,\n            image_positional_embeddings: model_inputs.image_positional_embeddings,\n        });\n    }\n\n    /**\n     * Runs the model with the provided inputs\n     * @param {Object} model_inputs Model inputs\n     * @returns {Promise<SamImageSegmentationOutput>} Object containing segmentation outputs\n     */\n    async _call(model_inputs) {\n        return new SamImageSegmentationOutput(await super._call(model_inputs));\n    }\n}\n\n\n/**\n * Base class for Segment-Anything model's output.\n */\nclass SamImageSegmentationOutput extends ModelOutput {\n    /**\n     * @param {Object} output The output of the model.\n     * @param {Tensor} output.iou_scores The output logits of the model.\n     * @param {Tensor} output.pred_masks Predicted boxes.\n     */\n    constructor({ iou_scores, pred_masks }) {\n        super();\n        this.iou_scores = iou_scores;\n        this.pred_masks = pred_masks;\n    }\n}\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// MarianMT models\nclass MarianPreTrainedModel extends PreTrainedModel { };\n\nclass MarianModel extends MarianPreTrainedModel { }\n\nclass MarianMTModel extends MarianPreTrainedModel {\n\n    /**\n     * Creates a new instance of the `MarianMTModel` class.\n    * @param {Object} config The model configuration object.\n    * @param {Object} session The ONNX session object.\n    * @param {any} decoder_merged_session \n    * @param {any} generation_config \n    */\n    constructor(config, session, decoder_merged_session, generation_config) {\n        super(config, session);\n        this.decoder_merged_session = decoder_merged_session;\n        this.generation_config = generation_config;\n\n        this.num_decoder_layers = this.config.decoder_layers;\n        this.num_decoder_heads = this.config.decoder_attention_heads;\n        this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads;\n\n        this.num_encoder_layers = this.config.encoder_layers;\n        this.num_encoder_heads = this.config.encoder_attention_heads;\n        this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads;\n    }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// M2M100 models\nclass M2M100PreTrainedModel extends PreTrainedModel { };\n\nclass M2M100Model extends M2M100PreTrainedModel { }\n\nclass M2M100ForConditionalGeneration extends M2M100PreTrainedModel {\n\n    /**\n     * Creates a new instance of the `M2M100ForConditionalGeneration` class.\n    * @param {Object} config The model configuration object.\n    * @param {Object} session The ONNX session object.\n    * @param {any} decoder_merged_session \n    * @param {any} generation_config \n    */\n    constructor(config, session, decoder_merged_session, generation_config) {\n        super(config, session);\n        this.decoder_merged_session = decoder_merged_session;\n        this.generation_config = generation_config;\n\n        this.num_decoder_layers = this.config.decoder_layers;\n        this.num_decoder_heads = this.config.decoder_attention_heads;\n        this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads;\n\n        this.num_encoder_layers = this.config.encoder_layers;\n        this.num_encoder_heads = this.config.encoder_attention_heads;\n        this.encoder_dim_kv = this.config.d_model / this.num_encoder_heads;\n    }\n\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// Wav2Vec2 models\nclass Wav2Vec2PreTrainedModel extends PreTrainedModel { };\n\n/**\n * The bare Wav2Vec2 Model transformer outputting raw hidden-states without any specific head on top.\n * \n * **Example:** Load and run a `Wav2Vec2Model` for feature extraction.\n * \n * ```javascript\n * import { AutoProcessor, AutoModel, read_audio } from '@xenova/transformers';\n * \n * // Read and preprocess audio\n * const processor = await AutoProcessor.from_pretrained('Xenova/mms-300m');\n * const audio = await read_audio('https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac', 16000);\n * const inputs = await processor(audio);\n * \n * // Run model with inputs\n * const model = await AutoModel.from_pretrained('Xenova/mms-300m');\n * const output = await model(inputs);\n * // {\n * //   last_hidden_state: Tensor {\n * //     dims: [ 1, 1144, 1024 ],\n * //     type: 'float32',\n * //     data: Float32Array(1171456) [ ... ],\n * //     size: 1171456\n * //   }\n * // }\n * ```\n */\nclass Wav2Vec2Model extends Wav2Vec2PreTrainedModel { }\n\nclass Wav2Vec2ForCTC extends Wav2Vec2PreTrainedModel {\n    /**\n     * @param {Object} model_inputs\n     * @param {Tensor} model_inputs.input_values Float values of input raw speech waveform.\n     * @param {Tensor} model_inputs.attention_mask Mask to avoid performing convolution and attention on padding token indices. Mask values selected in [0, 1]\n     */\n    async _call(model_inputs) {\n        return new CausalLMOutput(await super._call(model_inputs));\n    }\n}\n\nclass Wav2Vec2ForSequenceClassification extends Wav2Vec2PreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// Wav2Vec2 models\nclass Wav2Vec2BertPreTrainedModel extends PreTrainedModel { };\n\n/**\n * The bare Wav2Vec2Bert Model transformer outputting raw hidden-states without any specific head on top.\n */\nclass Wav2Vec2BertModel extends Wav2Vec2BertPreTrainedModel { }\n\n/**\n * Wav2Vec2Bert Model with a `language modeling` head on top for Connectionist Temporal Classification (CTC).\n */\nclass Wav2Vec2BertForCTC extends Wav2Vec2BertPreTrainedModel {\n    /**\n     * @param {Object} model_inputs\n     * @param {Tensor} model_inputs.input_features Float values of input mel-spectrogram.\n     * @param {Tensor} model_inputs.attention_mask Mask to avoid performing convolution and attention on padding token indices. Mask values selected in [0, 1]\n     */\n    async _call(model_inputs) {\n        return new CausalLMOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * Wav2Vec2Bert Model with a sequence classification head on top (a linear layer over the pooled output).\n */\nclass Wav2Vec2BertForSequenceClassification extends Wav2Vec2BertPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// Hubert models\nclass HubertPreTrainedModel extends PreTrainedModel { }\n\n/**\n * The bare Hubert Model transformer outputting raw hidden-states without any specific head on top.\n * \n * **Example:** Load and run a `HubertModel` for feature extraction.\n * \n * ```javascript\n * import { AutoProcessor, AutoModel, read_audio } from '@xenova/transformers';\n * \n * // Read and preprocess audio\n * const processor = await AutoProcessor.from_pretrained('Xenova/hubert-base-ls960');\n * const audio = await read_audio('https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/jfk.wav', 16000);\n * const inputs = await processor(audio);\n * \n * // Load and run model with inputs\n * const model = await AutoModel.from_pretrained('Xenova/hubert-base-ls960');\n * const output = await model(inputs);\n * // {\n * //   last_hidden_state: Tensor {\n * //     dims: [ 1, 549, 768 ],\n * //     type: 'float32',\n * //     data: Float32Array(421632) [0.0682469978928566, 0.08104046434164047, -0.4975186586380005, ...],\n * //     size: 421632\n * //   }\n * // }\n * ```\n */\nclass HubertModel extends Wav2Vec2PreTrainedModel { }\n\n/**\n * Hubert Model with a `language modeling` head on top for Connectionist Temporal Classification (CTC).\n */\nclass HubertForCTC extends Wav2Vec2PreTrainedModel {\n    /**\n     * @param {Object} model_inputs\n     * @param {Tensor} model_inputs.input_values Float values of input raw speech waveform.\n     * @param {Tensor} model_inputs.attention_mask Mask to avoid performing convolution and attention on padding token indices. Mask values selected in [0, 1]\n     */\n    async _call(model_inputs) {\n        return new CausalLMOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * Hubert Model with a sequence classification head on top (a linear layer over the pooled output) for tasks like SUPERB Keyword Spotting.\n */\nclass HubertForSequenceClassification extends Wav2Vec2PreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// WavLM models\n/**\n * An abstract class to handle weights initialization and a simple interface for downloading and loading pretrained models.\n */\nclass WavLMPreTrainedModel extends PreTrainedModel { };\n\n/**\n * The bare WavLM Model transformer outputting raw hidden-states without any specific head on top.\n * \n * **Example:** Load and run a `WavLMModel` for feature extraction.\n * \n * ```javascript\n * import { AutoProcessor, AutoModel, read_audio } from '@xenova/transformers';\n * \n * // Read and preprocess audio\n * const processor = await AutoProcessor.from_pretrained('Xenova/wavlm-base');\n * const audio = await read_audio('https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/jfk.wav', 16000);\n * const inputs = await processor(audio);\n * \n * // Run model with inputs\n * const model = await AutoModel.from_pretrained('Xenova/wavlm-base');\n * const output = await model(inputs);\n * // {\n * //   last_hidden_state: Tensor {\n * //     dims: [ 1, 549, 768 ],\n * //     type: 'float32',\n * //     data: Float32Array(421632) [-0.349443256855011, -0.39341306686401367,  0.022836603224277496, ...],\n * //     size: 421632\n * //   }\n * // }\n * ```\n */\nclass WavLMModel extends WavLMPreTrainedModel { }\n\n/**\n * WavLM Model with a `language modeling` head on top for Connectionist Temporal Classification (CTC).\n */\nclass WavLMForCTC extends WavLMPreTrainedModel {\n    /**\n     * @param {Object} model_inputs\n     * @param {Tensor} model_inputs.input_values Float values of input raw speech waveform.\n     * @param {Tensor} model_inputs.attention_mask Mask to avoid performing convolution and attention on padding token indices. Mask values selected in [0, 1]\n     */\n    async _call(model_inputs) {\n        return new CausalLMOutput(await super._call(model_inputs));\n    }\n}\n\n/**\n * WavLM Model with a sequence classification head on top (a linear layer over the pooled output).\n */\nclass WavLMForSequenceClassification extends WavLMPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.\n     */\n    async _call(model_inputs) {\n        return new SequenceClassifierOutput(await super._call(model_inputs));\n    }\n}\n\n//////////////////////////////////////////////////\n// SpeechT5 models\n/**\n * An abstract class to handle weights initialization and a simple interface for downloading and loading pretrained models.\n */\nclass SpeechT5PreTrainedModel extends PreTrainedModel { };\n\n/**\n * The bare SpeechT5 Encoder-Decoder Model outputting raw hidden-states without any specific pre- or post-nets.\n */\nclass SpeechT5Model extends SpeechT5PreTrainedModel { };\n\n/**\n * SpeechT5 Model with a speech encoder and a text decoder.\n * \n * **Example:** Generate speech from text with `SpeechT5ForSpeechToText`.\n * ```javascript\n * import { AutoTokenizer, AutoProcessor, SpeechT5ForTextToSpeech, SpeechT5HifiGan, Tensor } from '@xenova/transformers';\n * \n * // Load the tokenizer and processor\n * const tokenizer = await AutoTokenizer.from_pretrained('Xenova/speecht5_tts');\n * const processor = await AutoProcessor.from_pretrained('Xenova/speecht5_tts');\n * \n * // Load the models\n * // NOTE: We use the unquantized versions as they are more accurate\n * const model = await SpeechT5ForTextToSpeech.from_pretrained('Xenova/speecht5_tts', { quantized: false });\n * const vocoder = await SpeechT5HifiGan.from_pretrained('Xenova/speecht5_hifigan', { quantized: false });\n * \n * // Load speaker embeddings from URL\n * const speaker_embeddings_data = new Float32Array(\n *     await (await fetch('https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/speaker_embeddings.bin')).arrayBuffer()\n * );\n * const speaker_embeddings = new Tensor(\n *     'float32',\n *     speaker_embeddings_data,\n *     [1, speaker_embeddings_data.length]\n * )\n * \n * // Run tokenization\n * const { input_ids } = tokenizer('Hello, my dog is cute');\n * \n * // Generate waveform\n * const { waveform } = await model.generate_speech(input_ids, speaker_embeddings, { vocoder });\n * console.log(waveform)\n * // Tensor {\n * //   dims: [ 26112 ],\n * //   type: 'float32',\n * //   size: 26112,\n * //   data: Float32Array(26112) [ -0.00043630177970044315, -0.00018082228780258447, ... ],\n * // }\n * ```\n */\nclass SpeechT5ForSpeechToText extends SpeechT5PreTrainedModel { }\n\n/**\n * SpeechT5 Model with a text encoder and a speech decoder.\n */\nclass SpeechT5ForTextToSpeech extends SpeechT5PreTrainedModel {\n\n    /**\n     * Creates a new instance of the `SpeechT5ForTextToSpeech` class.\n     * @param {Object} config The model configuration.\n     * @param {any} session session for the model.\n     * @param {any} decoder_merged_session session for the decoder.\n     * @param {GenerationConfig} generation_config The generation configuration.\n     */\n    constructor(config, session, decoder_merged_session, generation_config) {\n        super(config, session);\n        this.decoder_merged_session = decoder_merged_session;\n        this.generation_config = generation_config;\n\n        this.num_decoder_layers = this.config.decoder_layers;\n        this.num_decoder_heads = this.config.decoder_attention_heads;\n        this.decoder_dim_kv = this.config.hidden_size / this.num_decoder_heads;\n\n        this.num_encoder_layers = this.config.encoder_layers;\n        this.num_encoder_heads = this.config.encoder_attention_heads;\n        this.encoder_dim_kv = this.config.hidden_size / this.num_encoder_heads;\n    }\n\n    /**\n     * @typedef {Object} SpeechOutput\n     * @property {Tensor} [spectrogram] The predicted log-mel spectrogram of shape\n     * `(output_sequence_length, config.num_mel_bins)`. Returned when no `vocoder` is provided\n     * @property {Tensor} [waveform] The predicted waveform of shape `(num_frames,)`. Returned when a `vocoder` is provided.\n     * @property {Tensor} [cross_attentions] The outputs of the decoder's cross-attention layers of shape\n     * `(config.decoder_layers, config.decoder_attention_heads, output_sequence_length, input_sequence_length)`. returned when `output_cross_attentions` is `true`.\n     */\n\n    /**\n     * Converts a sequence of input tokens into a sequence of mel spectrograms, which are subsequently turned into a speech waveform using a vocoder.\n     * @param {Tensor} input_values Indices of input sequence tokens in the vocabulary.\n     * @param {Tensor} speaker_embeddings Tensor containing the speaker embeddings.\n     * @param {Object} options Optional parameters for generating speech.\n     * @param {number} [options.threshold=0.5] The generated sequence ends when the predicted stop token probability exceeds this value.\n     * @param {number} [options.minlenratio=0.0] Used to calculate the minimum required length for the output sequence.\n     * @param {number} [options.maxlenratio=20.0] Used to calculate the maximum allowed length for the output sequence.\n     * @param {Object} [options.vocoder=null] The vocoder that converts the mel spectrogram into a speech waveform. If `null`, the output is the mel spectrogram.\n     * @param {boolean} [options.output_cross_attentions=false] Whether or not to return the attentions tensors of the decoder's cross-attention layers.\n     * @returns {Promise<SpeechOutput>} A promise which resolves to an object containing the spectrogram, waveform, and cross-attention tensors.\n     */\n    async generate_speech(input_values, speaker_embeddings, {\n        threshold = 0.5,\n        minlenratio = 0.0,\n        maxlenratio = 20.0,\n        vocoder = null,\n        // output_cross_attentions = false, // TODO add\n    } = {}) {\n\n        const model_inputs = {\n            input_ids: input_values\n        }\n\n        const { encoder_outputs, encoder_attention_mask } = await encoderForward(this, model_inputs);\n\n        const r = encoder_outputs.dims[1] / this.config.reduction_factor;\n        const maxlen = Math.floor(r * maxlenratio);\n        const minlen = Math.floor(r * minlenratio);\n\n        const num_mel_bins = this.config.num_mel_bins;\n\n        let spectrogramParts = [];\n        let past_key_values = null;\n        let decoder_outputs = null;\n        let idx = 0;\n\n        while (true) {\n            ++idx;\n\n            const use_cache_branch = boolTensor(!!decoder_outputs);\n            let output_sequence;\n            if (decoder_outputs) {\n                output_sequence = decoder_outputs.output_sequence_out;\n            } else {\n                output_sequence = new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.Tensor(\n                    'float32',\n                    new Float32Array(num_mel_bins),\n                    [1, 1, num_mel_bins],\n                )\n            }\n            let decoderFeeds = {\n                use_cache_branch,\n                output_sequence,\n                encoder_attention_mask: encoder_attention_mask,\n                speaker_embeddings: speaker_embeddings,\n                encoder_hidden_states: encoder_outputs,\n            };\n\n            this.addPastKeyValues(decoderFeeds, past_key_values);\n            decoder_outputs = await sessionRun(this.decoder_merged_session, decoderFeeds);\n            past_key_values = this.getPastKeyValues(decoder_outputs, past_key_values);\n\n            const { prob, spectrum } = decoder_outputs;\n            spectrogramParts.push(spectrum);\n\n            if (idx >= minlen && (\n                // Finished when stop token or maximum length is reached.\n                Array.from(prob.data).filter(p => p >= threshold).length > 0 || idx >= maxlen\n            )) {\n                break;\n            }\n        }\n\n        const spectrogram = (0,_utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__.cat)(spectrogramParts);\n        const { waveform } = await sessionRun(vocoder.session, { spectrogram });\n\n        return {\n            spectrogram,\n            waveform,\n            // cross_attentions: null, // TODO add\n        }\n    }\n}\n\n/**\n * HiFi-GAN vocoder.\n * \n * See [SpeechT5ForSpeechToText](./models#module_models.SpeechT5ForSpeechToText) for example usage.\n */\nclass SpeechT5HifiGan extends PreTrainedModel {\n    main_input_name = 'spectrogram';\n}\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// TrOCR models\nclass TrOCRPreTrainedModel extends PreTrainedModel {\n    /**\n     * Creates a new instance of the `TrOCRPreTrainedModel` class.\n     * @param {Object} config The configuration of the model.\n     * @param {any} session The ONNX session containing the model weights.\n     * @param {GenerationConfig} generation_config The generation configuration.\n     */\n    constructor(config, session, generation_config) {\n        super(config, session);\n        this.generation_config = generation_config;\n\n        // config doesn't contain pad_token_id, so we assume it is the eos_token_id\n        this.config.pad_token_id = this.config.eos_token_id;\n\n        this.num_encoder_layers = this.num_decoder_layers = this.config.decoder_layers;\n        this.num_encoder_heads = this.num_decoder_heads = this.config.decoder_attention_heads;\n        this.encoder_dim_kv = this.decoder_dim_kv = this.config.d_model / this.num_decoder_heads;\n    }\n}\n\n/**\n * The TrOCR Decoder with a language modeling head.\n */\nclass TrOCRForCausalLM extends TrOCRPreTrainedModel { }\n\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// Mistral models\n/**\n * The bare Mistral Model outputting raw hidden-states without any specific head on top.\n */\nclass MistralPreTrainedModel extends PreTrainedModel {\n    /**\n     * Creates a new instance of the `MistralPreTrainedModel` class.\n     * @param {Object} config The configuration of the model.\n     * @param {any} session The ONNX session containing the model weights.\n     * @param {GenerationConfig} generation_config The generation configuration.\n     */\n    constructor(config, session, generation_config) {\n        super(config, session);\n        this.generation_config = generation_config;\n\n        // config doesn't contain pad_token_id, so we assume it is the eos_token_id\n        this.config.pad_token_id = this.config.eos_token_id\n\n        this.num_heads = this.config.num_key_value_heads;\n        this.num_layers = this.config.num_hidden_layers;\n        this.dim_kv = this.config.hidden_size / this.config.num_attention_heads;\n    }\n}\n\nclass MistralModel extends MistralPreTrainedModel { }\n\nclass MistralForCausalLM extends MistralPreTrainedModel { }\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// Falcon models\n/**\n * The bare Falcon Model outputting raw hidden-states without any specific head on top.\n */\nclass FalconPreTrainedModel extends PreTrainedModel {\n    /**\n     * Creates a new instance of the `FalconPreTrainedModel` class.\n     * @param {Object} config The configuration of the model.\n     * @param {any} session The ONNX session containing the model weights.\n     * @param {GenerationConfig} generation_config The generation configuration.\n     */\n    constructor(config, session, generation_config) {\n        super(config, session);\n        this.generation_config = generation_config;\n\n        // config doesn't contain pad_token_id, so we assume it is the eos_token_id\n        this.config.pad_token_id = this.config.eos_token_id\n\n        this.num_heads = this.config.num_attention_heads;\n        this.num_layers = this.config.num_hidden_layers;\n        this.dim_kv = this.config.hidden_size / this.config.num_attention_heads;\n    }\n}\n\nclass FalconModel extends FalconPreTrainedModel { }\n\nclass FalconForCausalLM extends FalconPreTrainedModel { }\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// CLAP models\nclass ClapPreTrainedModel extends PreTrainedModel { }\n\nclass ClapModel extends ClapPreTrainedModel { }\n\n/**\n * CLAP Text Model with a projection layer on top (a linear layer on top of the pooled output).\n * \n * **Example:** Compute text embeddings with `ClapTextModelWithProjection`.\n * \n * ```javascript\n * import { AutoTokenizer, ClapTextModelWithProjection } from '@xenova/transformers';\n * \n * // Load tokenizer and text model\n * const tokenizer = await AutoTokenizer.from_pretrained('Xenova/clap-htsat-unfused');\n * const text_model = await ClapTextModelWithProjection.from_pretrained('Xenova/clap-htsat-unfused');\n * \n * // Run tokenization\n * const texts = ['a sound of a cat', 'a sound of a dog'];\n * const text_inputs = tokenizer(texts, { padding: true, truncation: true });\n * \n * // Compute embeddings\n * const { text_embeds } = await text_model(text_inputs);\n * // Tensor {\n * //   dims: [ 2, 512 ],\n * //   type: 'float32',\n * //   data: Float32Array(1024) [ ... ],\n * //   size: 1024\n * // }\n * ```\n */\nclass ClapTextModelWithProjection extends ClapPreTrainedModel {\n\n    /** @type {PreTrainedModel.from_pretrained} */\n    static async from_pretrained(pretrained_model_name_or_path, options = {}) {\n        // Update default model file name if not provided\n        options.model_file_name ??= 'text_model';\n        return super.from_pretrained(pretrained_model_name_or_path, options);\n    }\n}\n\n/**\n * CLAP Audio Model with a projection layer on top (a linear layer on top of the pooled output).\n * \n * **Example:** Compute audio embeddings with `ClapAudioModelWithProjection`.\n * \n * ```javascript\n * import { AutoProcessor, ClapAudioModelWithProjection, read_audio } from '@xenova/transformers';\n * \n * // Load processor and audio model\n * const processor = await AutoProcessor.from_pretrained('Xenova/clap-htsat-unfused');\n * const audio_model = await ClapAudioModelWithProjection.from_pretrained('Xenova/clap-htsat-unfused');\n * \n * // Read audio and run processor\n * const audio = await read_audio('https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/cat_meow.wav');\n * const audio_inputs = await processor(audio);\n * \n * // Compute embeddings\n * const { audio_embeds } = await audio_model(audio_inputs);\n * // Tensor {\n * //   dims: [ 1, 512 ],\n * //   type: 'float32',\n * //   data: Float32Array(512) [ ... ],\n * //   size: 512\n * // }\n * ```\n */\nclass ClapAudioModelWithProjection extends ClapPreTrainedModel {\n    /** @type {PreTrainedModel.from_pretrained} */\n    static async from_pretrained(pretrained_model_name_or_path, options = {}) {\n        // Update default model file name if not provided\n        options.model_file_name ??= 'audio_model';\n        return super.from_pretrained(pretrained_model_name_or_path, options);\n    }\n}\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// VITS models\nclass VitsPreTrainedModel extends PreTrainedModel { }\n\n/**\n * The complete VITS model, for text-to-speech synthesis.\n * \n * **Example:** Generate speech from text with `VitsModel`.\n * ```javascript\n * import { AutoTokenizer, VitsModel } from '@xenova/transformers';\n * \n * // Load the tokenizer and model\n * const tokenizer = await AutoTokenizer.from_pretrained('Xenova/mms-tts-eng');\n * const model = await VitsModel.from_pretrained('Xenova/mms-tts-eng');\n * \n * // Run tokenization\n * const inputs = tokenizer('I love transformers');\n * \n * // Generate waveform\n * const { waveform } = await model(inputs);\n * // Tensor {\n * //   dims: [ 1, 35328 ],\n * //   type: 'float32',\n * //   data: Float32Array(35328) [ ... ],\n * //   size: 35328,\n * // }\n * ```\n */\nclass VitsModel extends VitsPreTrainedModel {\n    /**\n     * Calls the model on new inputs.\n     * @param {Object} model_inputs The inputs to the model.\n     * @returns {Promise<VitsModelOutput>} The outputs for the VITS model.\n     */\n    async _call(model_inputs) {\n        return new VitsModelOutput(await super._call(model_inputs));\n    }\n}\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\n// Segformer models\nclass SegformerPreTrainedModel extends PreTrainedModel { }\n\n/**\n * The bare SegFormer encoder (Mix-Transformer) outputting raw hidden-states without any specific head on top.\n */\nclass SegformerModel extends SegformerPreTrainedModel { }\n\n/**\n * SegFormer Model transformer with an image classification head on top (a linear layer on top of the final hidden states) e.g. for ImageNet.\n */\nclass SegformerForImageClassification extends SegformerPreTrainedModel { }\n\n/**\n * SegFormer Model transformer with an all-MLP decode head on top e.g. for ADE20k, CityScapes.\n */\nclass SegformerForSemanticSegmentation extends SegformerPreTrainedModel { }\n\n//////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////\n// AutoModels, used to simplify construction of PreTrainedModels\n// (uses config to instantiate correct class)\n\n/**\n * Base class of all AutoModels. Contains the `from_pretrained` function\n * which is used to instantiate pretrained models.\n */\nclass PretrainedMixin {\n    /**\n     * Mapping from model type to model class.\n     * @type {Map<string, Object>[]}\n     */\n    static MODEL_CLASS_MAPPINGS = null;\n\n    /**\n     * Whether to attempt to instantiate the base class (`PretrainedModel`) if \n     * the model type is not found in the mapping.\n     */\n    static BASE_IF_FAIL = false;\n\n\n    /** @type {PreTrainedModel.from_pretrained} */\n    static async from_pretrained(pretrained_model_name_or_path, {\n        quantized = true,\n        progress_callback = null,\n        config = null,\n        cache_dir = null,\n        local_files_only = false,\n        revision = 'main',\n        model_file_name = null,\n    } = {}) {\n\n        let options = {\n            quantized,\n            progress_callback,\n            config,\n            cache_dir,\n            local_files_only,\n            revision,\n            model_file_name,\n        }\n        config = await _configs_js__WEBPACK_IMPORTED_MODULE_0__.AutoConfig.from_pretrained(pretrained_model_name_or_path, options);\n        if (!options.config) {\n            // If no config was passed, reuse this config for future processing\n            options.config = config;\n        }\n\n        if (!this.MODEL_CLASS_MAPPINGS) {\n            throw new Error(\"`MODEL_CLASS_MAPPINGS` not implemented for this type of `AutoClass`: \" + this.name);\n        }\n\n        for (let MODEL_CLASS_MAPPING of this.MODEL_CLASS_MAPPINGS) {\n            const modelInfo = MODEL_CLASS_MAPPING.get(config.model_type);\n            if (!modelInfo) {\n                continue; // Item not found in this mapping\n            }\n            return await modelInfo[1].from_pretrained(pretrained_model_name_or_path, options);\n        }\n\n        if (this.BASE_IF_FAIL) {\n            console.warn(`Unknown model class \"${config.model_type}\", attempting to construct from base class.`);\n            return await PreTrainedModel.from_pretrained(pretrained_model_name_or_path, options);\n        } else {\n            throw Error(`Unsupported model type: ${config.model_type}`)\n        }\n    }\n}\n\nconst MODEL_MAPPING_NAMES_ENCODER_ONLY = new Map([\n    ['bert', ['BertModel', BertModel]],\n    ['nomic_bert', ['NomicBertModel', NomicBertModel]],\n    ['roformer', ['RoFormerModel', RoFormerModel]],\n    ['electra', ['ElectraModel', ElectraModel]],\n    ['esm', ['EsmModel', EsmModel]],\n    ['convbert', ['ConvBertModel', ConvBertModel]],\n    ['camembert', ['CamembertModel', CamembertModel]],\n    ['deberta', ['DebertaModel', DebertaModel]],\n    ['deberta-v2', ['DebertaV2Model', DebertaV2Model]],\n    ['mpnet', ['MPNetModel', MPNetModel]],\n    ['albert', ['AlbertModel', AlbertModel]],\n    ['distilbert', ['DistilBertModel', DistilBertModel]],\n    ['roberta', ['RobertaModel', RobertaModel]],\n    ['xlm', ['XLMModel', XLMModel]],\n    ['xlm-roberta', ['XLMRobertaModel', XLMRobertaModel]],\n    ['clap', ['ClapModel', ClapModel]],\n    ['clip', ['CLIPModel', CLIPModel]],\n    ['clipseg', ['CLIPSegModel', CLIPSegModel]],\n    ['chinese_clip', ['ChineseCLIPModel', ChineseCLIPModel]],\n    ['siglip', ['SiglipModel', SiglipModel]],\n    ['mobilebert', ['MobileBertModel', MobileBertModel]],\n    ['squeezebert', ['SqueezeBertModel', SqueezeBertModel]],\n    ['wav2vec2', ['Wav2Vec2Model', Wav2Vec2Model]],\n    ['wav2vec2-bert', ['Wav2Vec2BertModel', Wav2Vec2BertModel]],\n    ['hubert', ['HubertModel', HubertModel]],\n    ['wavlm', ['WavLMModel', WavLMModel]],\n    ['audio-spectrogram-transformer', ['ASTModel', ASTModel]],\n    ['vits', ['VitsModel', VitsModel]],\n\n    ['detr', ['DetrModel', DetrModel]],\n    ['table-transformer', ['TableTransformerModel', TableTransformerModel]],\n    ['vit', ['ViTModel', ViTModel]],\n    ['mobilevit', ['MobileViTModel', MobileViTModel]],\n    ['owlvit', ['OwlViTModel', OwlViTModel]],\n    ['owlv2', ['Owlv2Model', Owlv2Model]],\n    ['beit', ['BeitModel', BeitModel]],\n    ['deit', ['DeiTModel', DeiTModel]],\n    ['convnext', ['ConvNextModel', ConvNextModel]],\n    ['convnextv2', ['ConvNextV2Model', ConvNextV2Model]],\n    ['dinov2', ['Dinov2Model', Dinov2Model]],\n    ['resnet', ['ResNetModel', ResNetModel]],\n    ['swin', ['SwinModel', SwinModel]],\n    ['swin2sr', ['Swin2SRModel', Swin2SRModel]],\n    ['donut-swin', ['DonutSwinModel', DonutSwinModel]],\n    ['yolos', ['YolosModel', YolosModel]],\n    ['dpt', ['DPTModel', DPTModel]],\n    ['glpn', ['GLPNModel', GLPNModel]],\n\n    ['hifigan', ['SpeechT5HifiGan', SpeechT5HifiGan]],\n\n]);\n\nconst MODEL_MAPPING_NAMES_ENCODER_DECODER = new Map([\n    ['t5', ['T5Model', T5Model]],\n    ['longt5', ['LongT5Model', LongT5Model]],\n    ['mt5', ['MT5Model', MT5Model]],\n    ['bart', ['BartModel', BartModel]],\n    ['mbart', ['MBartModel', MBartModel]],\n    ['marian', ['MarianModel', MarianModel]],\n    ['whisper', ['WhisperModel', WhisperModel]],\n    ['m2m_100', ['M2M100Model', M2M100Model]],\n    ['blenderbot', ['BlenderbotModel', BlenderbotModel]],\n    ['blenderbot-small', ['BlenderbotSmallModel', BlenderbotSmallModel]],\n]);\n\n\nconst MODEL_MAPPING_NAMES_DECODER_ONLY = new Map([\n    ['bloom', ['BloomModel', BloomModel]],\n    ['gpt2', ['GPT2Model', GPT2Model]],\n    ['gptj', ['GPTJModel', GPTJModel]],\n    ['gpt_bigcode', ['GPTBigCodeModel', GPTBigCodeModel]],\n    ['gpt_neo', ['GPTNeoModel', GPTNeoModel]],\n    ['gpt_neox', ['GPTNeoXModel', GPTNeoXModel]],\n    ['codegen', ['CodeGenModel', CodeGenModel]],\n    ['llama', ['LlamaModel', LlamaModel]],\n    ['qwen2', ['Qwen2Model', Qwen2Model]],\n    ['phi', ['PhiModel', PhiModel]],\n    ['mpt', ['MptModel', MptModel]],\n    ['opt', ['OPTModel', OPTModel]],\n    ['mistral', ['MistralModel', MistralModel]],\n    ['falcon', ['FalconModel', FalconModel]],\n]);\n\nconst MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING_NAMES = new Map([\n    ['speecht5', ['SpeechT5ForSpeechToText', SpeechT5ForSpeechToText]],\n    ['whisper', ['WhisperForConditionalGeneration', WhisperForConditionalGeneration]],\n]);\n\nconst MODEL_FOR_TEXT_TO_SPECTROGRAM_MAPPING_NAMES = new Map([\n    ['speecht5', ['SpeechT5ForTextToSpeech', SpeechT5ForTextToSpeech]],\n]);\n\nconst MODEL_FOR_TEXT_TO_WAVEFORM_MAPPING_NAMES = new Map([\n    ['vits', ['VitsModel', VitsModel]],\n]);\n\nconst MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING_NAMES = new Map([\n    ['bert', ['BertForSequenceClassification', BertForSequenceClassification]],\n    ['roformer', ['RoFormerForSequenceClassification', RoFormerForSequenceClassification]],\n    ['electra', ['ElectraForSequenceClassification', ElectraForSequenceClassification]],\n    ['esm', ['EsmForSequenceClassification', EsmForSequenceClassification]],\n    ['convbert', ['ConvBertForSequenceClassification', ConvBertForSequenceClassification]],\n    ['camembert', ['CamembertForSequenceClassification', CamembertForSequenceClassification]],\n    ['deberta', ['DebertaForSequenceClassification', DebertaForSequenceClassification]],\n    ['deberta-v2', ['DebertaV2ForSequenceClassification', DebertaV2ForSequenceClassification]],\n    ['mpnet', ['MPNetForSequenceClassification', MPNetForSequenceClassification]],\n    ['albert', ['AlbertForSequenceClassification', AlbertForSequenceClassification]],\n    ['distilbert', ['DistilBertForSequenceClassification', DistilBertForSequenceClassification]],\n    ['roberta', ['RobertaForSequenceClassification', RobertaForSequenceClassification]],\n    ['xlm', ['XLMForSequenceClassification', XLMForSequenceClassification]],\n    ['xlm-roberta', ['XLMRobertaForSequenceClassification', XLMRobertaForSequenceClassification]],\n    ['bart', ['BartForSequenceClassification', BartForSequenceClassification]],\n    ['mbart', ['MBartForSequenceClassification', MBartForSequenceClassification]],\n    ['mobilebert', ['MobileBertForSequenceClassification', MobileBertForSequenceClassification]],\n    ['squeezebert', ['SqueezeBertForSequenceClassification', SqueezeBertForSequenceClassification]],\n]);\n\nconst MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING_NAMES = new Map([\n    ['bert', ['BertForTokenClassification', BertForTokenClassification]],\n    ['roformer', ['RoFormerForTokenClassification', RoFormerForTokenClassification]],\n    ['electra', ['ElectraForTokenClassification', ElectraForTokenClassification]],\n    ['esm', ['EsmForTokenClassification', EsmForTokenClassification]],\n    ['convbert', ['ConvBertForTokenClassification', ConvBertForTokenClassification]],\n    ['camembert', ['CamembertForTokenClassification', CamembertForTokenClassification]],\n    ['deberta', ['DebertaForTokenClassification', DebertaForTokenClassification]],\n    ['deberta-v2', ['DebertaV2ForTokenClassification', DebertaV2ForTokenClassification]],\n    ['mpnet', ['MPNetForTokenClassification', MPNetForTokenClassification]],\n    ['distilbert', ['DistilBertForTokenClassification', DistilBertForTokenClassification]],\n    ['roberta', ['RobertaForTokenClassification', RobertaForTokenClassification]],\n    ['xlm', ['XLMForTokenClassification', XLMForTokenClassification]],\n    ['xlm-roberta', ['XLMRobertaForTokenClassification', XLMRobertaForTokenClassification]],\n]);\n\nconst MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING_NAMES = new Map([\n    ['t5', ['T5ForConditionalGeneration', T5ForConditionalGeneration]],\n    ['longt5', ['LongT5ForConditionalGeneration', LongT5ForConditionalGeneration]],\n    ['mt5', ['MT5ForConditionalGeneration', MT5ForConditionalGeneration]],\n    ['bart', ['BartForConditionalGeneration', BartForConditionalGeneration]],\n    ['mbart', ['MBartForConditionalGeneration', MBartForConditionalGeneration]],\n    ['marian', ['MarianMTModel', MarianMTModel]],\n    ['m2m_100', ['M2M100ForConditionalGeneration', M2M100ForConditionalGeneration]],\n    ['blenderbot', ['BlenderbotForConditionalGeneration', BlenderbotForConditionalGeneration]],\n    ['blenderbot-small', ['BlenderbotSmallForConditionalGeneration', BlenderbotSmallForConditionalGeneration]],\n]);\n\nconst MODEL_WITH_LM_HEAD_MAPPING_NAMES = new Map([\n    ['bloom', ['BloomForCausalLM', BloomForCausalLM]],\n    ['gpt2', ['GPT2LMHeadModel', GPT2LMHeadModel]],\n    ['gptj', ['GPTJForCausalLM', GPTJForCausalLM]],\n    ['gpt_bigcode', ['GPTBigCodeForCausalLM', GPTBigCodeForCausalLM]],\n    ['gpt_neo', ['GPTNeoForCausalLM', GPTNeoForCausalLM]],\n    ['gpt_neox', ['GPTNeoXForCausalLM', GPTNeoXForCausalLM]],\n    ['codegen', ['CodeGenForCausalLM', CodeGenForCausalLM]],\n    ['llama', ['LlamaForCausalLM', LlamaForCausalLM]],\n    ['qwen2', ['Qwen2ForCausalLM', Qwen2ForCausalLM]],\n    ['phi', ['PhiForCausalLM', PhiForCausalLM]],\n    ['mpt', ['MptForCausalLM', MptForCausalLM]],\n    ['opt', ['OPTForCausalLM', OPTForCausalLM]],\n    ['mbart', ['MBartForCausalLM', MBartForCausalLM]],\n    ['mistral', ['MistralForCausalLM', MistralForCausalLM]],\n    ['falcon', ['FalconForCausalLM', FalconForCausalLM]],\n    ['trocr', ['TrOCRForCausalLM', TrOCRForCausalLM]],\n]);\n\nconst MODEL_FOR_MASKED_LM_MAPPING_NAMES = new Map([\n    ['bert', ['BertForMaskedLM', BertForMaskedLM]],\n    ['roformer', ['RoFormerForMaskedLM', RoFormerForMaskedLM]],\n    ['electra', ['ElectraForMaskedLM', ElectraForMaskedLM]],\n    ['esm', ['EsmForMaskedLM', EsmForMaskedLM]],\n    ['convbert', ['ConvBertForMaskedLM', ConvBertForMaskedLM]],\n    ['camembert', ['CamembertForMaskedLM', CamembertForMaskedLM]],\n    ['deberta', ['DebertaForMaskedLM', DebertaForMaskedLM]],\n    ['deberta-v2', ['DebertaV2ForMaskedLM', DebertaV2ForMaskedLM]],\n    ['mpnet', ['MPNetForMaskedLM', MPNetForMaskedLM]],\n    ['albert', ['AlbertForMaskedLM', AlbertForMaskedLM]],\n    ['distilbert', ['DistilBertForMaskedLM', DistilBertForMaskedLM]],\n    ['roberta', ['RobertaForMaskedLM', RobertaForMaskedLM]],\n    ['xlm', ['XLMWithLMHeadModel', XLMWithLMHeadModel]],\n    ['xlm-roberta', ['XLMRobertaForMaskedLM', XLMRobertaForMaskedLM]],\n    ['mobilebert', ['MobileBertForMaskedLM', MobileBertForMaskedLM]],\n    ['squeezebert', ['SqueezeBertForMaskedLM', SqueezeBertForMaskedLM]],\n]);\n\nconst MODEL_FOR_QUESTION_ANSWERING_MAPPING_NAMES = new Map([\n    ['bert', ['BertForQuestionAnswering', BertForQuestionAnswering]],\n    ['roformer', ['RoFormerForQuestionAnswering', RoFormerForQuestionAnswering]],\n    ['electra', ['ElectraForQuestionAnswering', ElectraForQuestionAnswering]],\n    ['convbert', ['ConvBertForQuestionAnswering', ConvBertForQuestionAnswering]],\n    ['camembert', ['CamembertForQuestionAnswering', CamembertForQuestionAnswering]],\n    ['deberta', ['DebertaForQuestionAnswering', DebertaForQuestionAnswering]],\n    ['deberta-v2', ['DebertaV2ForQuestionAnswering', DebertaV2ForQuestionAnswering]],\n    ['mpnet', ['MPNetForQuestionAnswering', MPNetForQuestionAnswering]],\n    ['albert', ['AlbertForQuestionAnswering', AlbertForQuestionAnswering]],\n    ['distilbert', ['DistilBertForQuestionAnswering', DistilBertForQuestionAnswering]],\n    ['roberta', ['RobertaForQuestionAnswering', RobertaForQuestionAnswering]],\n    ['xlm', ['XLMForQuestionAnswering', XLMForQuestionAnswering]],\n    ['xlm-roberta', ['XLMRobertaForQuestionAnswering', XLMRobertaForQuestionAnswering]],\n    ['mobilebert', ['MobileBertForQuestionAnswering', MobileBertForQuestionAnswering]],\n    ['squeezebert', ['SqueezeBertForQuestionAnswering', SqueezeBertForQuestionAnswering]],\n]);\n\nconst MODEL_FOR_VISION_2_SEQ_MAPPING_NAMES = new Map([\n    ['vision-encoder-decoder', ['VisionEncoderDecoderModel', VisionEncoderDecoderModel]],\n]);\n\nconst MODEL_FOR_DOCUMENT_QUESTION_ANSWERING_MAPPING_NAMES = new Map([\n    ['vision-encoder-decoder', ['VisionEncoderDecoderModel', VisionEncoderDecoderModel]],\n]);\n\nconst MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING_NAMES = new Map([\n    ['vit', ['ViTForImageClassification', ViTForImageClassification]],\n    ['mobilevit', ['MobileViTForImageClassification', MobileViTForImageClassification]],\n    ['beit', ['BeitForImageClassification', BeitForImageClassification]],\n    ['deit', ['DeiTForImageClassification', DeiTForImageClassification]],\n    ['convnext', ['ConvNextForImageClassification', ConvNextForImageClassification]],\n    ['convnextv2', ['ConvNextV2ForImageClassification', ConvNextV2ForImageClassification]],\n    ['dinov2', ['Dinov2ForImageClassification', Dinov2ForImageClassification]],\n    ['resnet', ['ResNetForImageClassification', ResNetForImageClassification]],\n    ['swin', ['SwinForImageClassification', SwinForImageClassification]],\n    ['segformer', ['SegformerForImageClassification', SegformerForImageClassification]],\n]);\n\nconst MODEL_FOR_OBJECT_DETECTION_MAPPING_NAMES = new Map([\n    ['detr', ['DetrForObjectDetection', DetrForObjectDetection]],\n    ['table-transformer', ['TableTransformerForObjectDetection', TableTransformerForObjectDetection]],\n    ['yolos', ['YolosForObjectDetection', YolosForObjectDetection]],\n]);\n\nconst MODEL_FOR_ZERO_SHOT_OBJECT_DETECTION_MAPPING_NAMES = new Map([\n    ['owlvit', ['OwlViTForObjectDetection', OwlViTForObjectDetection]],\n    ['owlv2', ['Owlv2ForObjectDetection', Owlv2ForObjectDetection]],\n]);\n\nconst MODEL_FOR_IMAGE_SEGMENTATION_MAPPING_NAMES = new Map([\n    ['detr', ['DetrForSegmentation', DetrForSegmentation]],\n    ['clipseg', ['CLIPSegForImageSegmentation', CLIPSegForImageSegmentation]],\n]);\n\nconst MODEL_FOR_SEMANTIC_SEGMENTATION_MAPPING_NAMES = new Map([\n    ['segformer', ['SegformerForSemanticSegmentation', SegformerForSemanticSegmentation]],\n]);\n\nconst MODEL_FOR_MASK_GENERATION_MAPPING_NAMES = new Map([\n    ['sam', ['SamModel', SamModel]],\n]);\n\nconst MODEL_FOR_CTC_MAPPING_NAMES = new Map([\n    ['wav2vec2', ['Wav2Vec2ForCTC', Wav2Vec2ForCTC]],\n    ['wav2vec2-bert', ['Wav2Vec2BertForCTC', Wav2Vec2BertForCTC]],\n    ['wavlm', ['WavLMForCTC', WavLMForCTC]],\n    ['hubert', ['HubertForCTC', HubertForCTC]],\n]);\n\nconst MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING_NAMES = new Map([\n    ['wav2vec2', ['Wav2Vec2ForSequenceClassification', Wav2Vec2ForSequenceClassification]],\n    ['wav2vec2-bert', ['Wav2Vec2BertForSequenceClassification', Wav2Vec2BertForSequenceClassification]],\n    ['wavlm', ['WavLMForSequenceClassification', WavLMForSequenceClassification]],\n    ['hubert', ['HubertForSequenceClassification', HubertForSequenceClassification]],\n    ['audio-spectrogram-transformer', ['ASTForAudioClassification', ASTForAudioClassification]],\n]);\n\nconst MODEL_FOR_IMAGE_MATTING_MAPPING_NAMES = new Map([\n    ['vitmatte', ['VitMatteForImageMatting', VitMatteForImageMatting]],\n]);\n\nconst MODEL_FOR_IMAGE_TO_IMAGE_MAPPING_NAMES = new Map([\n    ['swin2sr', ['Swin2SRForImageSuperResolution', Swin2SRForImageSuperResolution]],\n])\n\nconst MODEL_FOR_DEPTH_ESTIMATION_MAPPING_NAMES = new Map([\n    ['dpt', ['DPTForDepthEstimation', DPTForDepthEstimation]],\n    ['depth_anything', ['DepthAnythingForDepthEstimation', DepthAnythingForDepthEstimation]],\n    ['glpn', ['GLPNForDepthEstimation', GLPNForDepthEstimation]],\n])\n\n\nconst MODEL_CLASS_TYPE_MAPPING = [\n    [MODEL_MAPPING_NAMES_ENCODER_ONLY, MODEL_TYPES.EncoderOnly],\n    [MODEL_MAPPING_NAMES_ENCODER_DECODER, MODEL_TYPES.EncoderDecoder],\n    [MODEL_MAPPING_NAMES_DECODER_ONLY, MODEL_TYPES.DecoderOnly],\n    [MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],\n    [MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],\n    [MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING_NAMES, MODEL_TYPES.Seq2Seq],\n    [MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING_NAMES, MODEL_TYPES.Seq2Seq],\n    [MODEL_WITH_LM_HEAD_MAPPING_NAMES, MODEL_TYPES.DecoderOnly],\n    [MODEL_FOR_MASKED_LM_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],\n    [MODEL_FOR_QUESTION_ANSWERING_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],\n    [MODEL_FOR_VISION_2_SEQ_MAPPING_NAMES, MODEL_TYPES.Vision2Seq],\n    [MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],\n    [MODEL_FOR_IMAGE_SEGMENTATION_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],\n    [MODEL_FOR_SEMANTIC_SEGMENTATION_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],\n    [MODEL_FOR_IMAGE_MATTING_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],\n    [MODEL_FOR_IMAGE_TO_IMAGE_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],\n    [MODEL_FOR_DEPTH_ESTIMATION_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],\n    [MODEL_FOR_OBJECT_DETECTION_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],\n    [MODEL_FOR_ZERO_SHOT_OBJECT_DETECTION_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],\n    [MODEL_FOR_MASK_GENERATION_MAPPING_NAMES, MODEL_TYPES.MaskGeneration],\n    [MODEL_FOR_CTC_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],\n    [MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],\n    [MODEL_FOR_TEXT_TO_SPECTROGRAM_MAPPING_NAMES, MODEL_TYPES.Seq2Seq],\n    [MODEL_FOR_TEXT_TO_WAVEFORM_MAPPING_NAMES, MODEL_TYPES.EncoderOnly],\n];\n\nfor (const [mappings, type] of MODEL_CLASS_TYPE_MAPPING) {\n    // @ts-ignore\n    for (const [name, model] of mappings.values()) {\n        MODEL_TYPE_MAPPING.set(name, type);\n        MODEL_CLASS_TO_NAME_MAPPING.set(model, name);\n        MODEL_NAME_TO_CLASS_MAPPING.set(name, model);\n    }\n}\n\nconst CUSTOM_MAPPING = [\n    ['CLIPTextModelWithProjection', CLIPTextModelWithProjection, MODEL_TYPES.EncoderOnly],\n    ['CLIPVisionModelWithProjection', CLIPVisionModelWithProjection, MODEL_TYPES.EncoderOnly],\n    ['SiglipTextModel', SiglipTextModel, MODEL_TYPES.EncoderOnly],\n    ['SiglipVisionModel', SiglipVisionModel, MODEL_TYPES.EncoderOnly],\n    ['ClapTextModelWithProjection', ClapTextModelWithProjection, MODEL_TYPES.EncoderOnly],\n    ['ClapAudioModelWithProjection', ClapAudioModelWithProjection, MODEL_TYPES.EncoderOnly],\n]\nfor (const [name, model, type] of CUSTOM_MAPPING) {\n    MODEL_TYPE_MAPPING.set(name, type);\n    MODEL_CLASS_TO_NAME_MAPPING.set(model, name);\n    MODEL_NAME_TO_CLASS_MAPPING.set(name, model);\n}\n\n\n/**\n * Helper class which is used to instantiate pretrained models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModel.from_pretrained('bert-base-uncased');\n */\nclass AutoModel extends PretrainedMixin {\n    /** @type {Map<string, Object>[]} */\n    // @ts-ignore\n    static MODEL_CLASS_MAPPINGS = MODEL_CLASS_TYPE_MAPPING.map(x => x[0]);\n    static BASE_IF_FAIL = true;\n}\n\n/**\n * Helper class which is used to instantiate pretrained sequence classification models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english');\n */\nclass AutoModelForSequenceClassification extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained token classification models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForTokenClassification.from_pretrained('Davlan/distilbert-base-multilingual-cased-ner-hrl');\n */\nclass AutoModelForTokenClassification extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained sequence-to-sequence models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForSeq2SeqLM.from_pretrained('t5-small');\n */\nclass AutoModelForSeq2SeqLM extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained sequence-to-sequence speech-to-text models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForSpeechSeq2Seq.from_pretrained('openai/whisper-tiny.en');\n */\nclass AutoModelForSpeechSeq2Seq extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained sequence-to-sequence text-to-spectrogram models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForTextToSpectrogram.from_pretrained('microsoft/speecht5_tts');\n */\nclass AutoModelForTextToSpectrogram extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_FOR_TEXT_TO_SPECTROGRAM_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained text-to-waveform models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForTextToSpectrogram.from_pretrained('facebook/mms-tts-eng');\n */\nclass AutoModelForTextToWaveform extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_FOR_TEXT_TO_WAVEFORM_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained causal language models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForCausalLM.from_pretrained('gpt2');\n */\nclass AutoModelForCausalLM extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_WITH_LM_HEAD_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained masked language models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForMaskedLM.from_pretrained('bert-base-uncased');\n */\nclass AutoModelForMaskedLM extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_FOR_MASKED_LM_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained question answering models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForQuestionAnswering.from_pretrained('distilbert-base-cased-distilled-squad');\n */\nclass AutoModelForQuestionAnswering extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_FOR_QUESTION_ANSWERING_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained vision-to-sequence models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForVision2Seq.from_pretrained('nlpconnect/vit-gpt2-image-captioning');\n */\nclass AutoModelForVision2Seq extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_FOR_VISION_2_SEQ_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained image classification models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForImageClassification.from_pretrained('google/vit-base-patch16-224');\n */\nclass AutoModelForImageClassification extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained image segmentation models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForImageSegmentation.from_pretrained('facebook/detr-resnet-50-panoptic');\n */\nclass AutoModelForImageSegmentation extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_FOR_IMAGE_SEGMENTATION_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained image segmentation models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForSemanticSegmentation.from_pretrained('nvidia/segformer-b3-finetuned-cityscapes-1024-1024');\n */\nclass AutoModelForSemanticSegmentation extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_FOR_SEMANTIC_SEGMENTATION_MAPPING_NAMES];\n}\n\n/**\n * Helper class which is used to instantiate pretrained object detection models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForObjectDetection.from_pretrained('facebook/detr-resnet-50');\n */\nclass AutoModelForObjectDetection extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_FOR_OBJECT_DETECTION_MAPPING_NAMES];\n}\n\nclass AutoModelForZeroShotObjectDetection extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_FOR_ZERO_SHOT_OBJECT_DETECTION_MAPPING_NAMES];\n}\n\n\n/**\n * Helper class which is used to instantiate pretrained mask generation models with the `from_pretrained` function.\n * The chosen model class is determined by the type specified in the model config.\n * \n * @example\n * let model = await AutoModelForMaskGeneration.from_pretrained('Xenova/sam-vit-base');\n */\nclass AutoModelForMaskGeneration extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_FOR_MASK_GENERATION_MAPPING_NAMES];\n}\n\nclass AutoModelForCTC extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_FOR_CTC_MAPPING_NAMES];\n}\n\nclass AutoModelForAudioClassification extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING_NAMES];\n}\n\nclass AutoModelForDocumentQuestionAnswering extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_FOR_DOCUMENT_QUESTION_ANSWERING_MAPPING_NAMES];\n}\n\nclass AutoModelForImageMatting extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_FOR_IMAGE_MATTING_MAPPING_NAMES];\n}\n\nclass AutoModelForImageToImage extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_FOR_IMAGE_TO_IMAGE_MAPPING_NAMES];\n}\n\nclass AutoModelForDepthEstimation extends PretrainedMixin {\n    static MODEL_CLASS_MAPPINGS = [MODEL_FOR_DEPTH_ESTIMATION_MAPPING_NAMES];\n}\n\n//////////////////////////////////////////////////\n\n//////////////////////////////////////////////////\nclass Seq2SeqLMOutput extends ModelOutput {\n    /**\n     * @param {Object} output The output of the model.\n     * @param {Tensor} output.logits The output logits of the model.\n     * @param {Tensor} output.past_key_values An tensor of key/value pairs that represent the previous state of the model.\n     * @param {Tensor} output.encoder_outputs The output of the encoder in a sequence-to-sequence model.\n     * @param {Tensor} [output.decoder_attentions] Attentions weights of the decoder, after the attention softmax, used to compute the weighted average in the self-attention heads.\n     * @param {Tensor} [output.cross_attentions] Attentions weights of the decoder's cross-attention layer, after the attention softmax, used to compute the weighted average in the cross-attention heads.\n     */\n    constructor({ logits, past_key_values, encoder_outputs, decoder_attentions = null, cross_attentions = null }) {\n        super();\n        this.logits = logits;\n        this.past_key_values = past_key_values;\n        this.encoder_outputs = encoder_outputs;\n        this.decoder_attentions = decoder_attentions;\n        this.cross_attentions = cross_attentions;\n    }\n}\n\n/**\n * Base class for outputs of sentence classification models.\n */\nclass SequenceClassifierOutput extends ModelOutput {\n    /**\n     * @param {Object} output The output of the model.\n     * @param {Tensor} output.logits classification (or regression if config.num_labels==1) scores (before SoftMax).\n     */\n    constructor({ logits }) {\n        super();\n        this.logits = logits;\n    }\n}\n\n/**\n * Base class for outputs of token classification models.\n */\nclass TokenClassifierOutput extends ModelOutput {\n    /**\n     * @param {Object} output The output of the model.\n     * @param {Tensor} output.logits Classification scores (before SoftMax).\n     */\n    constructor({ logits }) {\n        super();\n        this.logits = logits;\n    }\n}\n\n/**\n * Base class for masked language models outputs.\n */\nclass MaskedLMOutput extends ModelOutput {\n    /**\n     * @param {Object} output The output of the model.\n     * @param {Tensor} output.logits Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n     */\n    constructor({ logits }) {\n        super();\n        this.logits = logits;\n    }\n}\n\n/**\n * Base class for outputs of question answering models.\n */\nclass QuestionAnsweringModelOutput extends ModelOutput {\n    /**\n     * @param {Object} output The output of the model.\n     * @param {Tensor} output.start_logits Span-start scores (before SoftMax).\n     * @param {Tensor} output.end_logits Span-end scores (before SoftMax).\n     */\n    constructor({ start_logits, end_logits }) {\n        super();\n        this.start_logits = start_logits;\n        this.end_logits = end_logits;\n    }\n}\n\n\n/**\n * Base class for causal language model (or autoregressive) outputs.\n */\nclass CausalLMOutput extends ModelOutput {\n    /**\n     * @param {Object} output The output of the model.\n     * @param {Tensor} output.logits Prediction scores of the language modeling head (scores for each vocabulary token before softmax).\n     */\n    constructor({ logits }) {\n        super();\n        this.logits = logits;\n    }\n}\n\n/**\n * Base class for causal language model (or autoregressive) outputs.\n */\nclass CausalLMOutputWithPast extends ModelOutput {\n    /**\n     * @param {Object} output The output of the model.\n     * @param {Tensor} output.logits Prediction scores of the language modeling head (scores for each vocabulary token before softmax).\n     * @param {Tensor} output.past_key_values Contains pre-computed hidden-states (key and values in the self-attention blocks)\n     * that can be used (see `past_key_values` input) to speed up sequential decoding.\n     */\n    constructor({ logits, past_key_values }) {\n        super();\n        this.logits = logits;\n        this.past_key_values = past_key_values;\n    }\n}\n\nclass ImageMattingOutput extends ModelOutput {\n    /**\n     * @param {Object} output The output of the model.\n     * @param {Tensor} output.alphas Estimated alpha values, of shape `(batch_size, num_channels, height, width)`.\n     */\n    constructor({ alphas }) {\n        super();\n        this.alphas = alphas;\n    }\n}\n\n/**\n * Describes the outputs for the VITS model.\n */\nclass VitsModelOutput extends ModelOutput {\n    /**\n     * @param {Object} output The output of the model.\n     * @param {Tensor} output.waveform The final audio waveform predicted by the model, of shape `(batch_size, sequence_length)`.\n     * @param {Tensor} output.spectrogram The log-mel spectrogram predicted at the output of the flow model.\n     * This spectrogram is passed to the Hi-Fi GAN decoder model to obtain the final audio waveform.\n     */\n    constructor({ waveform, spectrogram }) {\n        super();\n        this.waveform = waveform;\n        this.spectrogram = spectrogram;\n    }\n}\n\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@xenova/transformers/src/models.js?");

/***/ }),

/***/ "./node_modules/@xenova/transformers/src/pipelines.js":
/*!************************************************************!*\
  !*** ./node_modules/@xenova/transformers/src/pipelines.js ***!
  \************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   AudioClassificationPipeline: () => (/* binding */ AudioClassificationPipeline),\n/* harmony export */   AutomaticSpeechRecognitionPipeline: () => (/* binding */ AutomaticSpeechRecognitionPipeline),\n/* harmony export */   DepthEstimationPipeline: () => (/* binding */ DepthEstimationPipeline),\n/* harmony export */   DocumentQuestionAnsweringPipeline: () => (/* binding */ DocumentQuestionAnsweringPipeline),\n/* harmony export */   FeatureExtractionPipeline: () => (/* binding */ FeatureExtractionPipeline),\n/* harmony export */   FillMaskPipeline: () => (/* binding */ FillMaskPipeline),\n/* harmony export */   ImageClassificationPipeline: () => (/* binding */ ImageClassificationPipeline),\n/* harmony export */   ImageSegmentationPipeline: () => (/* binding */ ImageSegmentationPipeline),\n/* harmony export */   ImageToImagePipeline: () => (/* binding */ ImageToImagePipeline),\n/* harmony export */   ImageToTextPipeline: () => (/* binding */ ImageToTextPipeline),\n/* harmony export */   ObjectDetectionPipeline: () => (/* binding */ ObjectDetectionPipeline),\n/* harmony export */   Pipeline: () => (/* binding */ Pipeline),\n/* harmony export */   QuestionAnsweringPipeline: () => (/* binding */ QuestionAnsweringPipeline),\n/* harmony export */   SummarizationPipeline: () => (/* binding */ SummarizationPipeline),\n/* harmony export */   Text2TextGenerationPipeline: () => (/* binding */ Text2TextGenerationPipeline),\n/* harmony export */   TextClassificationPipeline: () => (/* binding */ TextClassificationPipeline),\n/* harmony export */   TextGenerationPipeline: () => (/* binding */ TextGenerationPipeline),\n/* harmony export */   TextToAudioPipeline: () => (/* binding */ TextToAudioPipeline),\n/* harmony export */   TokenClassificationPipeline: () => (/* binding */ TokenClassificationPipeline),\n/* harmony export */   TranslationPipeline: () => (/* binding */ TranslationPipeline),\n/* harmony export */   ZeroShotAudioClassificationPipeline: () => (/* binding */ ZeroShotAudioClassificationPipeline),\n/* harmony export */   ZeroShotClassificationPipeline: () => (/* binding */ ZeroShotClassificationPipeline),\n/* harmony export */   ZeroShotImageClassificationPipeline: () => (/* binding */ ZeroShotImageClassificationPipeline),\n/* harmony export */   ZeroShotObjectDetectionPipeline: () => (/* binding */ ZeroShotObjectDetectionPipeline),\n/* harmony export */   pipeline: () => (/* binding */ pipeline)\n/* harmony export */ });\n/* harmony import */ var _tokenizers_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./tokenizers.js */ \"./node_modules/@xenova/transformers/src/tokenizers.js\");\n/* harmony import */ var _models_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./models.js */ \"./node_modules/@xenova/transformers/src/models.js\");\n/* harmony import */ var _processors_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./processors.js */ \"./node_modules/@xenova/transformers/src/processors.js\");\n/* harmony import */ var _utils_core_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./utils/core.js */ \"./node_modules/@xenova/transformers/src/utils/core.js\");\n/* harmony import */ var _utils_maths_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./utils/maths.js */ \"./node_modules/@xenova/transformers/src/utils/maths.js\");\n/* harmony import */ var _utils_audio_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./utils/audio.js */ \"./node_modules/@xenova/transformers/src/utils/audio.js\");\n/* harmony import */ var _utils_tensor_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./utils/tensor.js */ \"./node_modules/@xenova/transformers/src/utils/tensor.js\");\n/* harmony import */ var _utils_image_js__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./utils/image.js */ \"./node_modules/@xenova/transformers/src/utils/image.js\");\n/**\n * @file Pipelines provide a high-level, easy to use, API for running machine learning models.\n * \n * **Example:** Instantiate pipeline using the `pipeline` function.\n * ```javascript\n * import { pipeline } from '@xenova/transformers';\n * \n * const classifier = await pipeline('sentiment-analysis');\n * const output = await classifier('I love transformers!');\n * // [{'label': 'POSITIVE', 'score': 0.999817686}]\n * ```\n * \n * @module pipelines\n */\n\n\n\n\n\n\n\n\n\n\n\n\n\n/**\n * @typedef {string | RawImage | URL} ImageInput\n * @typedef {ImageInput|ImageInput[]} ImagePipelineInputs\n */\n\n/**\n * Prepare images for further tasks.\n * @param {ImagePipelineInputs} images images to prepare.\n * @returns {Promise<RawImage[]>} returns processed images.\n * @private\n */\nasync function prepareImages(images) {\n    if (!Array.isArray(images)) {\n        images = [images];\n    }\n\n    // Possibly convert any non-images to images\n    return await Promise.all(images.map(x => _utils_image_js__WEBPACK_IMPORTED_MODULE_7__.RawImage.read(x)));\n}\n\n/**\n * @typedef {string | URL | Float32Array | Float64Array} AudioInput\n * @typedef {AudioInput|AudioInput[]} AudioPipelineInputs\n */\n\n/**\n * Prepare audios for further tasks.\n * @param {AudioPipelineInputs} audios audios to prepare.\n * @param {number} sampling_rate sampling rate of the audios.\n * @returns {Promise<Float32Array[]>} The preprocessed audio data.\n * @private\n */\nasync function prepareAudios(audios, sampling_rate) {\n    if (!Array.isArray(audios)) {\n        audios = [audios];\n    }\n\n    return await Promise.all(audios.map(x => {\n        if (typeof x === 'string' || x instanceof URL) {\n            return (0,_utils_audio_js__WEBPACK_IMPORTED_MODULE_5__.read_audio)(x, sampling_rate);\n        } else if (x instanceof Float64Array) {\n            return new Float32Array(x);\n        }\n        return x;\n    }));\n}\n\n/**\n * @typedef {Object} BoundingBox\n * @property {number} xmin The minimum x coordinate of the bounding box.\n * @property {number} ymin The minimum y coordinate of the bounding box.\n * @property {number} xmax The maximum x coordinate of the bounding box.\n * @property {number} ymax The maximum y coordinate of the bounding box.\n */\n\n/**\n * Helper function to convert list [xmin, xmax, ymin, ymax] into object { \"xmin\": xmin, ... }\n * @param {number[]} box The bounding box as a list.\n * @param {boolean} asInteger Whether to cast to integers.\n * @returns {BoundingBox} The bounding box as an object.\n * @private\n */\nfunction get_bounding_box(box, asInteger) {\n    if (asInteger) {\n        box = box.map(x => x | 0);\n    }\n    const [xmin, ymin, xmax, ymax] = box;\n\n    return { xmin, ymin, xmax, ymax };\n}\n\n\n/**\n * @callback DisposeType Disposes the item.\n * @returns {Promise<void>} A promise that resolves when the item has been disposed.\n * \n * @typedef {Object} Disposable\n * @property {DisposeType} dispose A promise that resolves when the pipeline has been disposed.\n */\n\n/**\n * The Pipeline class is the class from which all pipelines inherit.\n * Refer to this class for methods shared across different pipelines.\n * @extends Callable\n */\nclass Pipeline extends _utils_core_js__WEBPACK_IMPORTED_MODULE_3__.Callable {\n    /**\n     * Create a new Pipeline.\n     * @param {Object} options An object containing the following properties:\n     * @param {string} [options.task] The task of the pipeline. Useful for specifying subtasks.\n     * @param {PreTrainedModel} [options.model] The model used by the pipeline.\n     * @param {PreTrainedTokenizer} [options.tokenizer=null] The tokenizer used by the pipeline (if any).\n     * @param {Processor} [options.processor=null] The processor used by the pipeline (if any).\n     */\n    constructor({ task, model, tokenizer = null, processor = null }) {\n        super();\n        this.task = task;\n        this.model = model;\n        this.tokenizer = tokenizer;\n        this.processor = processor;\n    }\n\n    /** @type {DisposeType} */\n    async dispose() {\n        await this.model.dispose();\n    }\n}\n\n/**\n * @typedef {Object} ModelTokenizerConstructorArgs\n * @property {string} task The task of the pipeline. Useful for specifying subtasks.\n * @property {PreTrainedModel} model The model used by the pipeline.\n * @property {PreTrainedTokenizer} tokenizer The tokenizer used by the pipeline.\n * \n * @typedef {ModelTokenizerConstructorArgs} TextPipelineConstructorArgs An object used to instantiate a text-based pipeline.\n */\n\n/**\n * @typedef {Object} ModelProcessorConstructorArgs\n * @property {string} task The task of the pipeline. Useful for specifying subtasks.\n * @property {PreTrainedModel} model The model used by the pipeline.\n * @property {Processor} processor The processor used by the pipeline.\n * \n * @typedef {ModelProcessorConstructorArgs} AudioPipelineConstructorArgs An object used to instantiate an audio-based pipeline.\n * @typedef {ModelProcessorConstructorArgs} ImagePipelineConstructorArgs An object used to instantiate an image-based pipeline.\n */\n\n\n/**\n * @typedef {Object} ModelTokenizerProcessorConstructorArgs\n * @property {string} task The task of the pipeline. Useful for specifying subtasks.\n * @property {PreTrainedModel} model The model used by the pipeline.\n * @property {PreTrainedTokenizer} tokenizer The tokenizer used by the pipeline.\n * @property {Processor} processor The processor used by the pipeline.\n * \n * @typedef {ModelTokenizerProcessorConstructorArgs} TextAudioPipelineConstructorArgs An object used to instantiate a text- and audio-based pipeline.\n * @typedef {ModelTokenizerProcessorConstructorArgs} TextImagePipelineConstructorArgs An object used to instantiate a text- and image-based pipeline.\n */\n\n/**\n * @typedef {Object} TextClassificationSingle\n * @property {string} label The label predicted.\n * @property {number} score The corresponding probability.\n * @typedef {TextClassificationSingle[]} TextClassificationOutput\n * \n * @typedef {Object} TextClassificationPipelineOptions Parameters specific to text classification pipelines.\n * @property {number} [topk=1] The number of top predictions to be returned.\n * \n * @callback TextClassificationPipelineCallback Classify the text(s) given as inputs.\n * @param {string|string[]} texts The input text(s) to be classified.\n * @param {TextClassificationPipelineOptions} [options] The options to use for text classification.\n * @returns {Promise<TextClassificationOutput|TextClassificationOutput[]>} An array or object containing the predicted labels and scores.\n * \n * @typedef {TextPipelineConstructorArgs & TextClassificationPipelineCallback & Disposable} TextClassificationPipelineType\n */\n\n/**\n * Text classification pipeline using any `ModelForSequenceClassification`.\n *\n * **Example:** Sentiment-analysis w/ `Xenova/distilbert-base-uncased-finetuned-sst-2-english`.\n * ```javascript\n * const classifier = await pipeline('sentiment-analysis', 'Xenova/distilbert-base-uncased-finetuned-sst-2-english');\n * const output = await classifier('I love transformers!');\n * // [{ label: 'POSITIVE', score: 0.999788761138916 }]\n * ```\n * \n * **Example:** Multilingual sentiment-analysis w/ `Xenova/bert-base-multilingual-uncased-sentiment` (and return top 5 classes).\n * ```javascript\n * const classifier = await pipeline('sentiment-analysis', 'Xenova/bert-base-multilingual-uncased-sentiment');\n * const output = await classifier('Le meilleur film de tous les temps.', { topk: 5 });\n * // [\n * //   { label: '5 stars', score: 0.9610759615898132 },\n * //   { label: '4 stars', score: 0.03323351591825485 },\n * //   { label: '3 stars', score: 0.0036155181005597115 },\n * //   { label: '1 star', score: 0.0011325967498123646 },\n * //   { label: '2 stars', score: 0.0009423971059732139 }\n * // ]\n * ```\n * \n * **Example:** Toxic comment classification w/ `Xenova/toxic-bert` (and return all classes).\n * ```javascript\n * const classifier = await pipeline('text-classification', 'Xenova/toxic-bert');\n * const output = await classifier('I hate you!', { topk: null });\n * // [\n * //   { label: 'toxic', score: 0.9593140482902527 },\n * //   { label: 'insult', score: 0.16187334060668945 },\n * //   { label: 'obscene', score: 0.03452680632472038 },\n * //   { label: 'identity_hate', score: 0.0223250575363636 },\n * //   { label: 'threat', score: 0.019197041168808937 },\n * //   { label: 'severe_toxic', score: 0.005651099607348442 }\n * // ]\n * ```\n */\nclass TextClassificationPipeline extends (/** @type {new (options: TextPipelineConstructorArgs) => TextClassificationPipelineType} */ (Pipeline)) {\n\n    /**\n     * Create a new TextClassificationPipeline.\n     * @param {TextPipelineConstructorArgs} options An object used to instantiate the pipeline.\n     */\n    constructor(options) {\n        super(options);\n    }\n\n    /** @type {TextClassificationPipelineCallback} */\n    async _call(texts, {\n        topk = 1\n    } = {}) {\n\n        // Run tokenization\n        const model_inputs = this.tokenizer(texts, {\n            padding: true,\n            truncation: true,\n        });\n\n        // Run model\n        const outputs = await this.model(model_inputs)\n\n        // TODO: Use softmax tensor function\n        const function_to_apply =\n            this.model.config.problem_type === 'multi_label_classification'\n                ? batch => batch.sigmoid().data\n                : batch => (0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_4__.softmax)(batch.data); // single_label_classification (default)\n\n        const id2label = this.model.config.id2label;\n\n        const toReturn = [];\n        for (const batch of outputs.logits) {\n            const output = function_to_apply(batch);\n            const scores = (0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_4__.getTopItems)(output, topk);\n\n            const vals = scores.map(x => ({\n                label: id2label[x[0]],\n                score: x[1],\n            }));\n            if (topk === 1) {\n                toReturn.push(...vals);\n            } else {\n                toReturn.push(vals);\n            }\n        }\n\n        return Array.isArray(texts) || topk === 1 ? /** @type {TextClassificationOutput} */ (toReturn) : /** @type {TextClassificationOutput[]} */ (toReturn)[0];\n    }\n}\n\n/**\n * @typedef {Object} TokenClassificationSingle\n * @property {string} word The token/word classified. This is obtained by decoding the selected tokens.\n * @property {number} score The corresponding probability for `entity`.\n * @property {string} entity The entity predicted for that token/word.\n * @property {number} index The index of the corresponding token in the sentence.\n * @property {number} [start] The index of the start of the corresponding entity in the sentence.\n * @property {number} [end] The index of the end of the corresponding entity in the sentence.\n * @typedef {TokenClassificationSingle[]} TokenClassificationOutput\n * \n * @typedef {Object} TokenClassificationPipelineOptions Parameters specific to token classification pipelines.\n * @property {string[]} [ignore_labels] A list of labels to ignore.\n * \n * @callback TokenClassificationPipelineCallback Classify each token of the text(s) given as inputs.\n * @param {string|string[]} texts One or several texts (or one list of texts) for token classification.\n * @param {TokenClassificationPipelineOptions} [options] The options to use for token classification.\n * @returns {Promise<TokenClassificationOutput|TokenClassificationOutput[]>} The result.\n * \n * @typedef {TextPipelineConstructorArgs & TokenClassificationPipelineCallback & Disposable} TokenClassificationPipelineType\n */\n\n/**\n * Named Entity Recognition pipeline using any `ModelForTokenClassification`.\n * \n * **Example:** Perform named entity recognition with `Xenova/bert-base-NER`.\n * ```javascript\n * const classifier = await pipeline('token-classification', 'Xenova/bert-base-NER');\n * const output = await classifier('My name is Sarah and I live in London');\n * // [\n * //   { entity: 'B-PER', score: 0.9980202913284302, index: 4, word: 'Sarah' },\n * //   { entity: 'B-LOC', score: 0.9994474053382874, index: 9, word: 'London' }\n * // ]\n * ```\n * \n * **Example:** Perform named entity recognition with `Xenova/bert-base-NER` (and return all labels).\n * ```javascript\n * const classifier = await pipeline('token-classification', 'Xenova/bert-base-NER');\n * const output = await classifier('Sarah lives in the United States of America', { ignore_labels: [] });\n * // [\n * //   { entity: 'B-PER', score: 0.9966587424278259, index: 1, word: 'Sarah' },\n * //   { entity: 'O', score: 0.9987385869026184, index: 2, word: 'lives' },\n * //   { entity: 'O', score: 0.9990072846412659, index: 3, word: 'in' },\n * //   { entity: 'O', score: 0.9988298416137695, index: 4, word: 'the' },\n * //   { entity: 'B-LOC', score: 0.9995510578155518, index: 5, word: 'United' },\n * //   { entity: 'I-LOC', score: 0.9990395307540894, index: 6, word: 'States' },\n * //   { entity: 'I-LOC', score: 0.9986724853515625, index: 7, word: 'of' },\n * //   { entity: 'I-LOC', score: 0.9975294470787048, index: 8, word: 'America' }\n * // ]\n * ```\n */\nclass TokenClassificationPipeline extends (/** @type {new (options: TextPipelineConstructorArgs) => TokenClassificationPipelineType} */ (Pipeline)) {\n\n    /**\n     * Create a new TokenClassificationPipeline.\n     * @param {TextPipelineConstructorArgs} options An object used to instantiate the pipeline.\n     */\n    constructor(options) {\n        super(options);\n    }\n\n    /** @type {TokenClassificationPipelineCallback} */\n    async _call(texts, {\n        ignore_labels = ['O'],\n    } = {}) {\n\n        const isBatched = Array.isArray(texts);\n\n        // Run tokenization\n        const model_inputs = this.tokenizer(isBatched ? texts : [texts], {\n            padding: true,\n            truncation: true,\n        });\n\n        // Run model\n        const outputs = await this.model(model_inputs)\n\n        const logits = outputs.logits;\n        const id2label = this.model.config.id2label;\n\n        const toReturn = [];\n        for (let i = 0; i < logits.dims[0]; ++i) {\n            const ids = model_inputs.input_ids[i];\n            const batch = logits[i];\n\n            // List of tokens that aren't ignored\n            const tokens = [];\n            for (let j = 0; j < batch.dims[0]; ++j) {\n                const tokenData = batch[j];\n                const topScoreIndex = (0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_4__.max)(tokenData.data)[1];\n\n                const entity = id2label ? id2label[topScoreIndex] : `LABEL_${topScoreIndex}`;\n                if (ignore_labels.includes(entity)) {\n                    // We predicted a token that should be ignored. So, we skip it.\n                    continue;\n                }\n\n                // TODO add option to keep special tokens?\n                const word = this.tokenizer.decode([ids[j].item()], { skip_special_tokens: true });\n                if (word === '') {\n                    // Was a special token. So, we skip it.\n                    continue;\n                }\n\n                const scores = (0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_4__.softmax)(tokenData.data);\n\n                tokens.push({\n                    entity: entity,\n                    score: scores[topScoreIndex],\n                    index: j,\n                    word: word,\n\n                    // TODO: null for now, but will add\n                    start: null,\n                    end: null,\n                });\n            }\n            toReturn.push(tokens);\n        }\n        return isBatched ? toReturn : toReturn[0];\n    }\n}\n\n/**\n * @typedef {Object} QuestionAnsweringOutput\n * @property {number} score The probability associated to the answer.\n * @property {number} [start] The character start index of the answer (in the tokenized version of the input).\n * @property {number} [end] The character end index of the answer (in the tokenized version of the input).\n * @property {string} answer The answer to the question.\n * \n * @typedef {Object} QuestionAnsweringPipelineOptions Parameters specific to question answering pipelines.\n * @property {number} [topk=1] The number of top answer predictions to be returned.\n * \n * @callback QuestionAnsweringPipelineCallback Answer the question(s) given as inputs by using the context(s).\n * @param {string|string[]} question One or several question(s) (must be used in conjunction with the `context` argument).\n * @param {string|string[]} context One or several context(s) associated with the question(s) (must be used in conjunction with the `question` argument).\n * @param {QuestionAnsweringPipelineOptions} [options] The options to use for question answering.\n * @returns {Promise<QuestionAnsweringOutput|QuestionAnsweringOutput[]>} An array or object containing the predicted answers and scores.\n * \n * @typedef {TextPipelineConstructorArgs & QuestionAnsweringPipelineCallback & Disposable} QuestionAnsweringPipelineType\n */\n\n/**\n * Question Answering pipeline using any `ModelForQuestionAnswering`.\n * \n * **Example:** Run question answering with `Xenova/distilbert-base-uncased-distilled-squad`.\n * ```javascript\n * const answerer = await pipeline('question-answering', 'Xenova/distilbert-base-uncased-distilled-squad');\n * const question = 'Who was Jim Henson?';\n * const context = 'Jim Henson was a nice puppet.';\n * const output = await answerer(question, context);\n * // {\n * //   answer: \"a nice puppet\",\n * //   score: 0.5768911502526741\n * // }\n * ```\n */\nclass QuestionAnsweringPipeline extends (/** @type {new (options: TextPipelineConstructorArgs) => QuestionAnsweringPipelineType} */ (Pipeline)) {\n\n    /**\n     * Create a new QuestionAnsweringPipeline.\n     * @param {TextPipelineConstructorArgs} options An object used to instantiate the pipeline.\n     */\n    constructor(options) {\n        super(options);\n    }\n\n    /** @type {QuestionAnsweringPipelineCallback} */\n    async _call(question, context, {\n        topk = 1\n    } = {}) {\n\n        // Run tokenization\n        const inputs = this.tokenizer(question, {\n            text_pair: context,\n            padding: true,\n            truncation: true,\n        });\n\n        const output = await this.model(inputs);\n\n        /** @type {QuestionAnsweringOutput[]} */\n        const toReturn = [];\n        for (let j = 0; j < output.start_logits.dims[0]; ++j) {\n            const ids = inputs.input_ids[j];\n            const sepIndex = ids.indexOf(this.tokenizer.sep_token_id);\n\n            const s1 = Array.from((0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_4__.softmax)(output.start_logits[j].data))\n                .map((x, i) => [x, i])\n                .filter(x => x[1] > sepIndex);\n            const e1 = Array.from((0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_4__.softmax)(output.end_logits[j].data))\n                .map((x, i) => [x, i])\n                .filter(x => x[1] > sepIndex);\n\n            const options = (0,_utils_core_js__WEBPACK_IMPORTED_MODULE_3__.product)(s1, e1)\n                .filter(x => x[0][1] <= x[1][1])\n                .map(x => [x[0][1], x[1][1], x[0][0] * x[1][0]])\n                .sort((a, b) => b[2] - a[2]);\n\n            for (let k = 0; k < Math.min(options.length, topk); ++k) {\n                const [start, end, score] = options[k];\n\n                const answer_tokens = [...ids].slice(start, end + 1)\n\n                const answer = this.tokenizer.decode(answer_tokens, {\n                    skip_special_tokens: true,\n                });\n\n                // TODO add start and end?\n                // NOTE: HF returns character index\n                toReturn.push({\n                    answer, score\n                });\n            }\n        }\n\n        // Mimic HF's return type based on topk\n        return (topk === 1) ? toReturn[0] : toReturn;\n    }\n}\n\n\n/**\n * @typedef {Object} FillMaskSingle\n * @property {string} sequence The corresponding input with the mask token prediction.\n * @property {number} score The corresponding probability.\n * @property {number} token The predicted token id (to replace the masked one).\n * @property {string} token_str The predicted token (to replace the masked one).\n * @typedef {FillMaskSingle[]} FillMaskOutput\n * \n * @typedef {Object} FillMaskPipelineOptions Parameters specific to fill mask pipelines.\n * @property {number} [topk=5] When passed, overrides the number of predictions to return.\n * \n * @callback FillMaskPipelineCallback Fill the masked token in the text(s) given as inputs.\n * @param {string|string[]} texts One or several texts (or one list of prompts) with masked tokens.\n * @param {FillMaskPipelineOptions} [options] The options to use for masked language modelling.\n * @returns {Promise<FillMaskOutput|FillMaskOutput[]>} An array of objects containing the score, predicted token, predicted token string,\n * and the sequence with the predicted token filled in, or an array of such arrays (one for each input text).\n * If only one input text is given, the output will be an array of objects.\n * @throws {Error} When the mask token is not found in the input text.\n * \n * @typedef {TextPipelineConstructorArgs & FillMaskPipelineCallback & Disposable} FillMaskPipelineType\n */\n\n/**\n * Masked language modeling prediction pipeline using any `ModelWithLMHead`.\n * \n * **Example:** Perform masked language modelling (a.k.a. \"fill-mask\") with `Xenova/bert-base-uncased`.\n * ```javascript\n * const unmasker = await pipeline('fill-mask', 'Xenova/bert-base-cased');\n * const output = await unmasker('The goal of life is [MASK].');\n * // [\n * //   { token_str: 'survival', score: 0.06137419492006302, token: 8115, sequence: 'The goal of life is survival.' },\n * //   { token_str: 'love', score: 0.03902450203895569, token: 1567, sequence: 'The goal of life is love.' },\n * //   { token_str: 'happiness', score: 0.03253183513879776, token: 9266, sequence: 'The goal of life is happiness.' },\n * //   { token_str: 'freedom', score: 0.018736306577920914, token: 4438, sequence: 'The goal of life is freedom.' },\n * //   { token_str: 'life', score: 0.01859794743359089, token: 1297, sequence: 'The goal of life is life.' }\n * // ]\n * ```\n * \n * **Example:** Perform masked language modelling (a.k.a. \"fill-mask\") with `Xenova/bert-base-cased` (and return top result).\n * ```javascript\n * const unmasker = await pipeline('fill-mask', 'Xenova/bert-base-cased');\n * const output = await unmasker('The Milky Way is a [MASK] galaxy.', { topk: 1 });\n * // [{ token_str: 'spiral', score: 0.6299987435340881, token: 14061, sequence: 'The Milky Way is a spiral galaxy.' }]\n * ```\n */\nclass FillMaskPipeline extends (/** @type {new (options: TextPipelineConstructorArgs) => FillMaskPipelineType} */ (Pipeline)) {\n\n    /**\n     * Create a new FillMaskPipeline.\n     * @param {TextPipelineConstructorArgs} options An object used to instantiate the pipeline.\n     */\n    constructor(options) {\n        super(options);\n    }\n\n    /** @type {FillMaskPipelineCallback} */\n    async _call(texts, {\n        topk = 5\n    } = {}) {\n\n        // Run tokenization\n        const model_inputs = this.tokenizer(texts, {\n            padding: true,\n            truncation: true,\n        });\n\n        // Run model\n        const outputs = await this.model(model_inputs)\n\n        const toReturn = [];\n\n        for (let i = 0; i < model_inputs.input_ids.dims[0]; ++i) {\n            const ids = model_inputs.input_ids[i];\n            const mask_token_index = ids.indexOf(this.tokenizer.mask_token_id)\n\n            if (mask_token_index === -1) {\n                throw Error(`Mask token (${this.tokenizer.mask_token}) not found in text.`)\n            }\n            const logits = outputs.logits[i];\n            const itemLogits = logits[mask_token_index];\n\n            const scores = (0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_4__.getTopItems)((0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_4__.softmax)(itemLogits.data), topk);\n\n            toReturn.push(scores.map(x => {\n                const sequence = [...ids];\n                sequence[mask_token_index] = x[0];\n\n                return {\n                    score: x[1],\n                    token: x[0],\n                    token_str: this.tokenizer.model.vocab[x[0]],\n                    sequence: this.tokenizer.decode(sequence, { skip_special_tokens: true }),\n                }\n            }));\n        }\n        return Array.isArray(texts) ? toReturn : toReturn[0];\n    }\n}\n\n\n/**\n * @typedef {Object} Text2TextGenerationSingle\n * @property {string} generated_text The generated text.\n * @typedef {Text2TextGenerationSingle[]} Text2TextGenerationOutput\n * \n * @callback Text2TextGenerationPipelineCallback Generate the output text(s) using text(s) given as inputs.\n * @param {string|string[]} texts Input text for the encoder.\n * @param {import('./utils/generation.js').GenerationConfigType} [options] Additional keyword arguments to pass along to the generate method of the model.\n * @returns {Promise<Text2TextGenerationOutput|Text2TextGenerationOutput[]>}\n * \n * @typedef {TextPipelineConstructorArgs & Text2TextGenerationPipelineCallback & Disposable} Text2TextGenerationPipelineType\n */\n\n/**\n * Text2TextGenerationPipeline class for generating text using a model that performs text-to-text generation tasks.\n * \n * **Example:** Text-to-text generation w/ `Xenova/LaMini-Flan-T5-783M`.\n * ```javascript\n * const generator = await pipeline('text2text-generation', 'Xenova/LaMini-Flan-T5-783M');\n * const output = await generator('how can I become more healthy?', {\n *   max_new_tokens: 100,\n * });\n * // [{ generated_text: \"To become more healthy, you can: 1. Eat a balanced diet with plenty of fruits, vegetables, whole grains, lean proteins, and healthy fats. 2. Stay hydrated by drinking plenty of water. 3. Get enough sleep and manage stress levels. 4. Avoid smoking and excessive alcohol consumption. 5. Regularly exercise and maintain a healthy weight. 6. Practice good hygiene and sanitation. 7. Seek medical attention if you experience any health issues.\" }]\n * ```\n */\nclass Text2TextGenerationPipeline extends (/** @type {new (options: TextPipelineConstructorArgs) => Text2TextGenerationPipelineType} */ (Pipeline)) {\n    /** @type {'generated_text'} */\n    _key = 'generated_text';\n\n    /**\n     * Create a new Text2TextGenerationPipeline.\n     * @param {TextPipelineConstructorArgs} options An object used to instantiate the pipeline.\n     */\n    constructor(options) {\n        super(options);\n    }\n\n    /** @type {Text2TextGenerationPipelineCallback} */\n    async _call(texts, generate_kwargs = {}) {\n        if (!Array.isArray(texts)) {\n            texts = [texts];\n        }\n\n\n        // Add global prefix, if present\n        if (this.model.config.prefix) {\n            texts = texts.map(x => this.model.config.prefix + x)\n        }\n\n        // Handle task specific params:\n        const task_specific_params = this.model.config.task_specific_params\n        if (task_specific_params && task_specific_params[this.task]) {\n            // Add prefixes, if present\n            if (task_specific_params[this.task].prefix) {\n                texts = texts.map(x => task_specific_params[this.task].prefix + x)\n            }\n\n            // TODO update generation config\n        }\n\n        const tokenizer = this.tokenizer;\n        const tokenizer_options = {\n            padding: true,\n            truncation: true,\n        }\n        let input_ids;\n        if (this instanceof TranslationPipeline && '_build_translation_inputs' in tokenizer) {\n            // TODO: move to Translation pipeline?\n            // Currently put here to avoid code duplication\n            // @ts-ignore\n            input_ids = tokenizer._build_translation_inputs(texts, tokenizer_options, generate_kwargs).input_ids;\n\n        } else {\n            input_ids = tokenizer(texts, tokenizer_options).input_ids;\n        }\n\n        const outputTokenIds = await this.model.generate(input_ids, generate_kwargs);\n\n        return tokenizer.batch_decode(outputTokenIds, {\n            skip_special_tokens: true,\n        }).map(text => ({ [this._key]: text }));\n    }\n}\n\n\n/**\n * @typedef {Object} SummarizationSingle\n * @property {string} summary_text The summary text.\n * @typedef {SummarizationSingle[]} SummarizationOutput\n * \n * @callback SummarizationPipelineCallback Summarize the text(s) given as inputs.\n * @param {string|string[]} texts One or several articles (or one list of articles) to summarize.\n * @param {import('./utils/generation.js').GenerationConfigType} [options] Additional keyword arguments to pass along to the generate method of the model.\n * @returns {Promise<SummarizationOutput|SummarizationOutput[]>}\n * \n * @typedef {TextPipelineConstructorArgs & SummarizationPipelineCallback & Disposable} SummarizationPipelineType\n */\n\n/**\n * A pipeline for summarization tasks, inheriting from Text2TextGenerationPipeline.\n * \n * **Example:** Summarization w/ `Xenova/distilbart-cnn-6-6`.\n * ```javascript\n * const generator = await pipeline('summarization', 'Xenova/distilbart-cnn-6-6');\n * const text = 'The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, ' +\n *   'and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on each side. ' +\n *   'During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest ' +\n *   'man-made structure in the world, a title it held for 41 years until the Chrysler Building in New ' +\n *   'York City was finished in 1930. It was the first structure to reach a height of 300 metres. Due to ' +\n *   'the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the ' +\n *   'Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the Eiffel Tower is the second ' +\n *   'tallest free-standing structure in France after the Millau Viaduct.';\n * const output = await generator(text, {\n *   max_new_tokens: 100,\n * });\n * // [{ summary_text: ' The Eiffel Tower is about the same height as an 81-storey building and the tallest structure in Paris. It is the second tallest free-standing structure in France after the Millau Viaduct.' }]\n * ```\n */\nclass SummarizationPipeline extends (/** @type {new (options: TextPipelineConstructorArgs) => SummarizationPipelineType} */ (/** @type {any} */ (Text2TextGenerationPipeline))) {\n    /** @type {'summary_text'} */\n    _key = 'summary_text';\n\n    /**\n     * Create a new SummarizationPipeline.\n     * @param {TextPipelineConstructorArgs} options An object used to instantiate the pipeline.\n     */\n    constructor(options) {\n        super(options);\n    }\n}\n\n\n/**\n * @typedef {Object} TranslationSingle\n * @property {string} translation_text The translated text.\n * @typedef {TranslationSingle[]} TranslationOutput\n * \n * @callback TranslationPipelineCallback Translate the text(s) given as inputs.\n * @param {string|string[]} texts Texts to be translated.\n * @param {import('./utils/generation.js').GenerationConfigType} [options] Additional keyword arguments to pass along to the generate method of the model.\n * @returns {Promise<TranslationOutput|TranslationOutput[]>}\n * \n * @typedef {TextPipelineConstructorArgs & TranslationPipelineCallback & Disposable} TranslationPipelineType\n */\n\n/**\n * Translates text from one language to another.\n * \n * **Example:** Multilingual translation w/ `Xenova/nllb-200-distilled-600M`.\n * \n * See [here](https://github.com/facebookresearch/flores/blob/main/flores200/README.md#languages-in-flores-200)\n * for the full list of languages and their corresponding codes.\n * \n * ```javascript\n * const translator = await pipeline('translation', 'Xenova/nllb-200-distilled-600M');\n * const output = await translator('      ', {\n *   src_lang: 'hin_Deva', // Hindi\n *   tgt_lang: 'fra_Latn', // French\n * });\n * // [{ translation_text: 'La vie est comme une bote  chocolat.' }]\n * ```\n * \n * **Example:** Multilingual translation w/ `Xenova/m2m100_418M`.\n * \n * See [here](https://huggingface.co/facebook/m2m100_418M#languages-covered)\n * for the full list of languages and their corresponding codes.\n * \n * ```javascript\n * const translator = await pipeline('translation', 'Xenova/m2m100_418M');\n * const output = await translator('', {\n *   src_lang: 'zh', // Chinese\n *   tgt_lang: 'en', // English\n * });\n * // [{ translation_text: 'Life is like a box of chocolate.' }]\n * ```\n * \n * **Example:** Multilingual translation w/ `Xenova/mbart-large-50-many-to-many-mmt`.\n * \n * See [here](https://huggingface.co/facebook/mbart-large-50-many-to-many-mmt#languages-covered)\n * for the full list of languages and their corresponding codes.\n * \n * ```javascript\n * const translator = await pipeline('translation', 'Xenova/mbart-large-50-many-to-many-mmt');\n * const output = await translator('              ', {\n *   src_lang: 'hi_IN', // Hindi\n *   tgt_lang: 'fr_XX', // French\n * });\n * // [{ translation_text: 'Le chef des Nations affirme qu 'il n 'y a military solution in Syria.' }]\n * ```\n */\nclass TranslationPipeline extends (/** @type {new (options: TextPipelineConstructorArgs) => TranslationPipelineType} */ (/** @type {any} */ (Text2TextGenerationPipeline))) {\n    /** @type {'translation_text'} */\n    _key = 'translation_text';\n\n    /**\n     * Create a new TranslationPipeline.\n     * @param {TextPipelineConstructorArgs} options An object used to instantiate the pipeline.\n     */\n    constructor(options) {\n        super(options);\n    }\n}\n\n\n/**\n * @typedef {Object} TextGenerationSingle\n * @property {string} generated_text The generated text.\n * @typedef {TextGenerationSingle[]} TextGenerationOutput\n * \n * @typedef {Object} TextGenerationSpecificParams Parameters specific to text-generation pipelines.\n * @property {boolean} [add_special_tokens] Whether or not to add special tokens when tokenizing the sequences.\n * @typedef {import('./utils/generation.js').GenerationConfigType & TextGenerationSpecificParams} TextGenerationConfig\n * \n * @callback TextGenerationPipelineCallback Complete the prompt(s) given as inputs.\n * @param {string|string[]} texts One or several prompts (or one list of prompts) to complete.\n * @param {TextGenerationConfig} [options] Additional keyword arguments to pass along to the generate method of the model.\n * @returns {Promise<TextGenerationOutput|TextGenerationOutput[]>} An array or object containing the generated texts.\n * \n * @typedef {TextPipelineConstructorArgs & TextGenerationPipelineCallback & Disposable} TextGenerationPipelineType\n */\n\n/**\n * Language generation pipeline using any `ModelWithLMHead` or `ModelForCausalLM`.\n * This pipeline predicts the words that will follow a specified text prompt.\n * NOTE: For the full list of generation parameters, see [`GenerationConfig`](./utils/generation#module_utils/generation.GenerationConfig).\n * \n * **Example:** Text generation with `Xenova/distilgpt2` (default settings).\n * ```javascript\n * const generator = await pipeline('text-generation', 'Xenova/distilgpt2');\n * const text = 'I enjoy walking with my cute dog,';\n * const output = await generator(text);\n * // [{ generated_text: \"I enjoy walking with my cute dog, and I love to play with the other dogs.\" }]\n * ```\n * \n * **Example:** Text generation with `Xenova/distilgpt2` (custom settings).\n * ```javascript\n * const generator = await pipeline('text-generation', 'Xenova/distilgpt2');\n * const text = 'Once upon a time, there was';\n * const output = await generator(text, {\n *   temperature: 2,\n *   max_new_tokens: 10,\n *   repetition_penalty: 1.5,\n *   no_repeat_ngram_size: 2,\n *   num_beams: 2,\n *   num_return_sequences: 2,\n * });\n * // [{\n * //   \"generated_text\": \"Once upon a time, there was an abundance of information about the history and activities that\"\n * // }, {\n * //   \"generated_text\": \"Once upon a time, there was an abundance of information about the most important and influential\"\n * // }]\n * ```\n * \n * **Example:** Run code generation with `Xenova/codegen-350M-mono`.\n * ```javascript\n * const generator = await pipeline('text-generation', 'Xenova/codegen-350M-mono');\n * const text = 'def fib(n):';\n * const output = await generator(text, {\n *   max_new_tokens: 44,\n * });\n * // [{\n * //   generated_text: 'def fib(n):\\n' +\n * //     '    if n == 0:\\n' +\n * //     '        return 0\\n' +\n * //     '    elif n == 1:\\n' +\n * //     '        return 1\\n' +\n * //     '    else:\\n' +\n * //     '        return fib(n-1) + fib(n-2)\\n'\n * // }]\n * ```\n */\nclass TextGenerationPipeline extends (/** @type {new (options: TextPipelineConstructorArgs) => TextGenerationPipelineType} */ (Pipeline)) {\n\n    /**\n     * Create a new TextGenerationPipeline.\n     * @param {TextPipelineConstructorArgs} options An object used to instantiate the pipeline.\n     */\n    constructor(options) {\n        super(options);\n    }\n\n    /** @type {TextGenerationPipelineCallback} */\n    async _call(texts, generate_kwargs = {}) {\n\n        const isBatched = Array.isArray(texts);\n        if (!isBatched) {\n            texts = [/** @type {string}*/ (texts)];\n        }\n\n        // By default, do not add special tokens\n        const add_special_tokens = generate_kwargs.add_special_tokens ?? false;\n\n        this.tokenizer.padding_side = 'left';\n        const { input_ids, attention_mask } = this.tokenizer(texts, {\n            add_special_tokens,\n            padding: true,\n            truncation: true,\n        });\n\n        const outputTokenIds = await this.model.generate(input_ids, generate_kwargs, null, {\n            inputs_attention_mask: attention_mask\n        });\n\n        const decoded = this.tokenizer.batch_decode(outputTokenIds, {\n            skip_special_tokens: true,\n        });\n\n        /** @type {TextGenerationOutput[]} */\n        const toReturn = Array.from({ length: texts.length }, _ => []);\n        for (let i = 0; i < decoded.length; ++i) {\n            const textIndex = Math.floor(i / outputTokenIds.length * texts.length);\n\n            toReturn[textIndex].push({\n                generated_text: decoded[i]\n            });\n        }\n        return (!isBatched && toReturn.length === 1) ? toReturn[0] : toReturn;\n    }\n}\n\n/**\n * @typedef {Object} ZeroShotClassificationOutput\n * @property {string} sequence The sequence for which this is the output.\n * @property {string[]} labels The labels sorted by order of likelihood.\n * @property {number[]} scores The probabilities for each of the labels.\n * \n * @typedef {Object} ZeroShotClassificationPipelineOptions Parameters specific to zero-shot classification pipelines.\n * @property {string} [hypothesis_template=\"This example is {}.\"] The template used to turn each\n * candidate label into an NLI-style hypothesis. The candidate label will replace the {} placeholder.\n * @property {boolean} [multi_label=false] Whether or not multiple candidate labels can be true.\n * If `false`, the scores are normalized such that the sum of the label likelihoods for each sequence\n * is 1. If `true`, the labels are considered independent and probabilities are normalized for each\n * candidate by doing a softmax of the entailment score vs. the contradiction score.\n * \n * @callback ZeroShotClassificationPipelineCallback Classify the sequence(s) given as inputs.\n * @param {string|string[]} texts The sequence(s) to classify, will be truncated if the model input is too large.\n * @param {string|string[]} candidate_labels The set of possible class labels to classify each sequence into.\n * Can be a single label, a string of comma-separated labels, or a list of labels.\n * @param {ZeroShotClassificationPipelineOptions} [options] The options to use for zero-shot classification.\n * @returns {Promise<ZeroShotClassificationOutput|ZeroShotClassificationOutput[]>} An array or object containing the predicted labels and scores.\n * \n * @typedef {TextPipelineConstructorArgs & ZeroShotClassificationPipelineCallback & Disposable} ZeroShotClassificationPipelineType\n */\n\n/**\n * NLI-based zero-shot classification pipeline using a `ModelForSequenceClassification`\n * trained on NLI (natural language inference) tasks. Equivalent of `text-classification`\n * pipelines, but these models don't require a hardcoded number of potential classes, they\n * can be chosen at runtime. It usually means it's slower but it is **much** more flexible.\n * \n * **Example:** Zero shot classification with `Xenova/mobilebert-uncased-mnli`.\n * ```javascript\n * const classifier = await pipeline('zero-shot-classification', 'Xenova/mobilebert-uncased-mnli');\n * const text = 'Last week I upgraded my iOS version and ever since then my phone has been overheating whenever I use your app.';\n * const labels = [ 'mobile', 'billing', 'website', 'account access' ];\n * const output = await classifier(text, labels);\n * // {\n * //   sequence: 'Last week I upgraded my iOS version and ever since then my phone has been overheating whenever I use your app.',\n * //   labels: [ 'mobile', 'website', 'billing', 'account access' ],\n * //   scores: [ 0.5562091040482018, 0.1843621307860853, 0.13942646639336376, 0.12000229877234923 ]\n * // }\n * ```\n * \n * **Example:** Zero shot classification with `Xenova/nli-deberta-v3-xsmall` (multi-label).\n * ```javascript\n * const classifier = await pipeline('zero-shot-classification', 'Xenova/nli-deberta-v3-xsmall');\n * const text = 'I have a problem with my iphone that needs to be resolved asap!';\n * const labels = [ 'urgent', 'not urgent', 'phone', 'tablet', 'computer' ];\n * const output = await classifier(text, labels, { multi_label: true });\n * // {\n * //   sequence: 'I have a problem with my iphone that needs to be resolved asap!',\n * //   labels: [ 'urgent', 'phone', 'computer', 'tablet', 'not urgent' ],\n * //   scores: [ 0.9958870956360275, 0.9923963400697035, 0.002333537946160235, 0.0015134138567598765, 0.0010699384208377163 ]\n * // }\n * ```\n */\nclass ZeroShotClassificationPipeline extends (/** @type {new (options: TextPipelineConstructorArgs) => ZeroShotClassificationPipelineType} */ (Pipeline)) {\n    /**\n     * Create a new ZeroShotClassificationPipeline.\n     * @param {TextPipelineConstructorArgs} options An object used to instantiate the pipeline.\n     */\n    constructor(options) {\n        super(options);\n\n        // Use model config to get label2id mapping\n        this.label2id = Object.fromEntries(\n            Object.entries((/** @type {any} */(this).model).config.label2id).map(\n                ([k, v]) => [k.toLowerCase(), v]\n            )\n        );\n\n        this.entailment_id = this.label2id['entailment'];\n        if (this.entailment_id === undefined) {\n            console.warn(\"Could not find 'entailment' in label2id mapping. Using 2 as entailment_id.\");\n            this.entailment_id = 2;\n        }\n\n        this.contradiction_id = this.label2id['contradiction'] ?? this.label2id['not_entailment'];\n        if (this.contradiction_id === undefined) {\n            console.warn(\"Could not find 'contradiction' in label2id mapping. Using 0 as contradiction_id.\");\n            this.contradiction_id = 0;\n        }\n    }\n\n    /** @type {ZeroShotClassificationPipelineCallback} */\n    async _call(texts, candidate_labels, {\n        hypothesis_template = \"This example is {}.\",\n        multi_label = false,\n    } = {}) {\n\n        const isBatched = Array.isArray(texts);\n        if (!isBatched) {\n            texts = [/** @type {string} */ (texts)];\n        }\n        if (!Array.isArray(candidate_labels)) {\n            candidate_labels = [candidate_labels];\n        }\n\n        // Insert labels into hypothesis template\n        const hypotheses = candidate_labels.map(\n            x => hypothesis_template.replace('{}', x)\n        );\n\n        // How to perform the softmax over the logits:\n        //  - true:  softmax over the entailment vs. contradiction dim for each label independently\n        //  - false: softmax the \"entailment\" logits over all candidate labels\n        const softmaxEach = multi_label || candidate_labels.length === 1;\n\n        /** @type {ZeroShotClassificationOutput[]} */\n        const toReturn = [];\n        for (const premise of texts) {\n            const entails_logits = [];\n\n            for (const hypothesis of hypotheses) {\n                const inputs = this.tokenizer(premise, {\n                    text_pair: hypothesis,\n                    padding: true,\n                    truncation: true,\n                })\n                const outputs = await this.model(inputs)\n\n                if (softmaxEach) {\n                    entails_logits.push([\n                        outputs.logits.data[this.contradiction_id],\n                        outputs.logits.data[this.entailment_id]\n                    ])\n                } else {\n                    entails_logits.push(outputs.logits.data[this.entailment_id])\n                }\n            }\n\n            /** @type {number[]} */\n            const scores = softmaxEach\n                ? entails_logits.map(x => (0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_4__.softmax)(x)[1])\n                : (0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_4__.softmax)(entails_logits);\n\n            // Sort by scores (desc) and return scores with indices\n            const scores_sorted = scores\n                .map((x, i) => [x, i])\n                .sort((a, b) => (b[0] - a[0]));\n\n            toReturn.push({\n                sequence: premise,\n                labels: scores_sorted.map(x => candidate_labels[x[1]]),\n                scores: scores_sorted.map(x => x[0]),\n            });\n        }\n        return isBatched ? toReturn : toReturn[0];\n    }\n}\n\n/**\n * @typedef {Object} FeatureExtractionPipelineOptions Parameters specific to feature extraction pipelines.\n * @property {'none'|'mean'|'cls'} [pooling=\"none\"] The pooling method to use.\n * @property {boolean} [normalize=false] Whether or not to normalize the embeddings in the last dimension.\n * \n * @callback FeatureExtractionPipelineCallback Extract the features of the input(s).\n * @param {string|string[]} texts One or several texts (or one list of texts) to get the features of.\n * @param {FeatureExtractionPipelineOptions} [options] The options to use for feature extraction.\n * @returns {Promise<Tensor>} The features computed by the model.\n * \n * @typedef {TextPipelineConstructorArgs & FeatureExtractionPipelineCallback & Disposable} FeatureExtractionPipelineType\n */\n\n/**\n * Feature extraction pipeline using no model head. This pipeline extracts the hidden\n * states from the base transformer, which can be used as features in downstream tasks.\n * \n * **Example:** Run feature extraction with `bert-base-uncased` (without pooling/normalization).\n * ```javascript\n * const extractor = await pipeline('feature-extraction', 'Xenova/bert-base-uncased', { revision: 'default' });\n * const output = await extractor('This is a simple test.');\n * // Tensor {\n * //   type: 'float32',\n * //   data: Float32Array [0.05939924716949463, 0.021655935794115067, ...],\n * //   dims: [1, 8, 768]\n * // }\n * ```\n * \n * **Example:** Run feature extraction with `bert-base-uncased` (with pooling/normalization).\n * ```javascript\n * const extractor = await pipeline('feature-extraction', 'Xenova/bert-base-uncased', { revision: 'default' });\n * const output = await extractor('This is a simple test.', { pooling: 'mean', normalize: true });\n * // Tensor {\n * //   type: 'float32',\n * //   data: Float32Array [0.03373778983950615, -0.010106077417731285, ...],\n * //   dims: [1, 768]\n * // }\n * ```\n * \n * **Example:** Calculating embeddings with `sentence-transformers` models.\n * ```javascript\n * const extractor = await pipeline('feature-extraction', 'Xenova/all-MiniLM-L6-v2');\n * const output = await extractor('This is a simple test.', { pooling: 'mean', normalize: true });\n * // Tensor {\n * //   type: 'float32',\n * //   data: Float32Array [0.09094982594251633, -0.014774246141314507, ...],\n * //   dims: [1, 384]\n * // }\n * ```\n */\nclass FeatureExtractionPipeline extends (/** @type {new (options: TextPipelineConstructorArgs) => FeatureExtractionPipelineType} */ (Pipeline)) {\n    /**\n     * Create a new FeatureExtractionPipeline.\n     * @param {TextPipelineConstructorArgs} options An object used to instantiate the pipeline.\n     */\n    constructor(options) {\n        super(options);\n    }\n\n    /** @type {FeatureExtractionPipelineCallback} */\n    async _call(texts, {\n        pooling = /** @type {'none'} */('none'),\n        normalize = false,\n    } = {}) {\n\n        // Run tokenization\n        const model_inputs = this.tokenizer(texts, {\n            padding: true,\n            truncation: true,\n        });\n\n        // Run model\n        const outputs = await this.model(model_inputs)\n\n        // TODO: Provide warning to the user that they might be using model which was not exported\n        // specifically for feature extraction\n        // console.log(this.model.config)\n        // console.log(outputs)\n\n        /** @type {Tensor} */\n        let result = outputs.last_hidden_state ?? outputs.logits;\n        if (pooling === 'none') {\n            // Skip pooling\n        } else if (pooling === 'mean') {\n            result = (0,_utils_tensor_js__WEBPACK_IMPORTED_MODULE_6__.mean_pooling)(result, model_inputs.attention_mask);\n        } else if (pooling === 'cls') {\n            result = result.slice(null, 0);\n        } else {\n            throw Error(`Pooling method '${pooling}' not supported.`);\n        }\n\n        if (normalize) {\n            result = result.normalize(2, -1);\n        }\n\n        return result;\n    }\n}\n\n// TODO\n// export class SentenceSimilarityPipeline extends Pipeline {\n// }\n\n/**\n * @typedef {Object} AudioClassificationSingle\n * @property {string} label The label predicted.\n * @property {number} score The corresponding probability.\n * @typedef {AudioClassificationSingle[]} AudioClassificationOutput\n * \n * @typedef {Object} AudioClassificationPipelineOptions Parameters specific to audio classification pipelines.\n * @property {number} [topk=null] The number of top labels that will be returned by the pipeline.\n * If the provided number is `null` or higher than the number of labels available in the model configuration,\n * it will default to the number of labels.\n * \n * @callback AudioClassificationPipelineCallback Classify the sequence(s) given as inputs.\n * @param {AudioPipelineInputs} audio The input audio file(s) to be classified. The input is either:\n * - `string` or `URL` that is the filename/URL of the audio file, the file will be read at the processor's sampling rate\n * to get the waveform using the [`AudioContext`](https://developer.mozilla.org/en-US/docs/Web/API/AudioContext) API.\n * If `AudioContext` is not available, you should pass the raw waveform in as a Float32Array of shape `(n, )`.\n * - `Float32Array` or `Float64Array` of shape `(n, )`, representing the raw audio at the correct sampling rate (no further check will be done).\n * @param {AudioClassificationPipelineOptions} [options] The options to use for audio classification.\n * @returns {Promise<AudioClassificationOutput|AudioClassificationOutput[]>} An array or object containing the predicted labels and scores.\n * \n * @typedef {AudioPipelineConstructorArgs & AudioClassificationPipelineCallback & Disposable} AudioClassificationPipelineType\n */\n\n/**\n * Audio classification pipeline using any `AutoModelForAudioClassification`.\n * This pipeline predicts the class of a raw waveform or an audio file.\n * \n * **Example:** Perform audio classification with `Xenova/wav2vec2-large-xlsr-53-gender-recognition-librispeech`.\n * ```javascript\n * const classifier = await pipeline('audio-classification', 'Xenova/wav2vec2-large-xlsr-53-gender-recognition-librispeech');\n * const url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/jfk.wav';\n * const output = await classifier(url);\n * // [\n * //   { label: 'male', score: 0.9981542229652405 },\n * //   { label: 'female', score: 0.001845747814513743 }\n * // ]\n * ```\n * \n * **Example:** Perform audio classification with `Xenova/ast-finetuned-audioset-10-10-0.4593` and return top 4 results.\n * ```javascript\n * const classifier = await pipeline('audio-classification', 'Xenova/ast-finetuned-audioset-10-10-0.4593');\n * const url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/cat_meow.wav';\n * const output = await classifier(url, { topk: 4 });\n * // [\n * //   { label: 'Meow', score: 0.5617874264717102 },\n * //   { label: 'Cat', score: 0.22365376353263855 },\n * //   { label: 'Domestic animals, pets', score: 0.1141069084405899 },\n * //   { label: 'Animal', score: 0.08985692262649536 },\n * // ]\n * ```\n */\nclass AudioClassificationPipeline extends (/** @type {new (options: AudioPipelineConstructorArgs) => AudioClassificationPipelineType} */ (Pipeline)) {\n\n    /**\n     * Create a new AudioClassificationPipeline.\n     * @param {AudioPipelineConstructorArgs} options An object used to instantiate the pipeline.\n     */\n    constructor(options) {\n        super(options);\n    }\n\n    /** @type {AudioClassificationPipelineCallback} */\n    async _call(audio, {\n        topk = null\n    } = {}) {\n\n        const single = !Array.isArray(audio);\n\n        const sampling_rate = this.processor.feature_extractor.config.sampling_rate;\n        const preparedAudios = await prepareAudios(audio, sampling_rate);\n\n        const id2label = this.model.config.id2label;\n\n        const toReturn = [];\n        for (const aud of preparedAudios) {\n            const inputs = await this.processor(aud);\n            const output = await this.model(inputs);\n            const logits = output.logits[0];\n\n            const scores = (0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_4__.getTopItems)((0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_4__.softmax)(logits.data), topk);\n\n            const vals = scores.map(x => ({\n                label: /** @type {string} */ (id2label[x[0]]),\n                score: /** @type {number} */ (x[1]),\n            }));\n\n            if (topk === 1) {\n                toReturn.push(...vals);\n            } else {\n                toReturn.push(vals);\n            }\n        }\n        return !single || topk === 1 ? /** @type {AudioClassificationOutput} */ (toReturn) : /** @type {AudioClassificationOutput[]} */ (toReturn)[0];\n    }\n}\n\n/**\n * @typedef {Object} ZeroShotAudioClassificationOutput\n * @property {string} label The label identified by the model. It is one of the suggested `candidate_label`.\n * @property {number} score The score attributed by the model for that label (between 0 and 1).\n * \n * @typedef {Object} ZeroShotAudioClassificationPipelineOptions Parameters specific to zero-shot audio classification pipelines.\n * @property {string} [hypothesis_template=\"This is a sound of {}.\"] The sentence used in conjunction with `candidate_labels`\n * to attempt the audio classification by replacing the placeholder with the candidate_labels.\n * Then likelihood is estimated by using `logits_per_audio`.\n * \n * @callback ZeroShotAudioClassificationPipelineCallback Classify the sequence(s) given as inputs.\n * @param {AudioPipelineInputs} audio The input audio file(s) to be classified. The input is either:\n * - `string` or `URL` that is the filename/URL of the audio file, the file will be read at the processor's sampling rate\n * to get the waveform using the [`AudioContext`](https://developer.mozilla.org/en-US/docs/Web/API/AudioContext) API.\n * If `AudioContext` is not available, you should pass the raw waveform in as a Float32Array of shape `(n, )`.\n * - `Float32Array` or `Float64Array` of shape `(n, )`, representing the raw audio at the correct sampling rate (no further check will be done).\n * @param {string[]} candidate_labels The candidate labels for this audio.\n * @param {ZeroShotAudioClassificationPipelineOptions} [options] The options to use for zero-shot audio classification.\n * @returns {Promise<ZeroShotAudioClassificationOutput[]|ZeroShotAudioClassificationOutput[][]>} An array of objects containing the predicted labels and scores.\n * \n * @typedef {TextAudioPipelineConstructorArgs & ZeroShotAudioClassificationPipelineCallback & Disposable} ZeroShotAudioClassificationPipelineType\n */\n\n/**\n * Zero shot audio classification pipeline using `ClapModel`. This pipeline predicts the class of an audio when you\n * provide an audio and a set of `candidate_labels`.\n * \n * **Example**: Perform zero-shot audio classification with `Xenova/clap-htsat-unfused`.\n * ```javascript\n * const classifier = await pipeline('zero-shot-audio-classification', 'Xenova/clap-htsat-unfused');\n * const audio = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/dog_barking.wav';\n * const candidate_labels = ['dog', 'vaccum cleaner'];\n * const scores = await classifier(audio, candidate_labels);\n * // [\n * //   { score: 0.9993992447853088, label: 'dog' },\n * //   { score: 0.0006007603369653225, label: 'vaccum cleaner' }\n * // ]\n * ```\n */\nclass ZeroShotAudioClassificationPipeline extends (/** @type {new (options: TextAudioPipelineConstructorArgs) => ZeroShotAudioClassificationPipelineType} */ (Pipeline)) {\n\n    /**\n     * Create a new ZeroShotAudioClassificationPipeline.\n     * @param {TextAudioPipelineConstructorArgs} options An object used to instantiate the pipeline.\n     */\n    constructor(options) {\n        super(options);\n    }\n\n    /** @type {ZeroShotAudioClassificationPipelineCallback} */\n    async _call(audio, candidate_labels, {\n        hypothesis_template = \"This is a sound of {}.\"\n    } = {}) {\n\n        const single = !Array.isArray(audio);\n        if (single) {\n            audio = [/** @type {AudioInput} */ (audio)];\n        }\n\n        // Insert label into hypothesis template \n        const texts = candidate_labels.map(\n            x => hypothesis_template.replace('{}', x)\n        );\n\n        // Run tokenization\n        const text_inputs = this.tokenizer(texts, {\n            padding: true,\n            truncation: true,\n        });\n\n        const sampling_rate = this.processor.feature_extractor.config.sampling_rate;\n        const preparedAudios = await prepareAudios(audio, sampling_rate);\n\n        const toReturn = [];\n        for (const aud of preparedAudios) {\n            const audio_inputs = await this.processor(aud);\n\n            // Run model with both text and audio inputs\n            const output = await this.model({ ...text_inputs, ...audio_inputs });\n\n            // Compute softmax per audio\n            const probs = (0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_4__.softmax)(output.logits_per_audio.data);\n\n            toReturn.push([...probs].map((x, i) => ({\n                score: x,\n                label: candidate_labels[i]\n            })));\n        }\n        return single ? toReturn[0] : toReturn;\n    }\n}\n\n/**\n * @typedef {{stride: number[], input_features: Tensor, is_last: boolean, tokens?: number[], token_timestamps?: number[]}} ChunkCallbackItem\n * @callback ChunkCallback\n * @param {ChunkCallbackItem} chunk The chunk to process.\n */\n\n/**\n * @typedef {Object} Chunk\n * @property {[number, number]} timestamp The start and end timestamp of the chunk in seconds.\n * @property {string} text The recognized text.\n */\n\n/**\n * @typedef {Object} AutomaticSpeechRecognitionOutput\n * @property {string} text The recognized text.\n * @property {Chunk[]} [chunks] When using `return_timestamps`, the `chunks` will become a list\n * containing all the various text chunks identified by the model.\n * \n * @typedef {Object} AutomaticSpeechRecognitionSpecificParams Parameters specific to automatic-speech-recognition pipelines.\n * @property {boolean|'word'} [kwargs.return_timestamps] Whether to return timestamps or not. Default is `false`.\n * @property {number} [kwargs.chunk_length_s] The length of audio chunks to process in seconds. Default is 0 (no chunking).\n * @property {number} [kwargs.stride_length_s] The length of overlap between consecutive audio chunks in seconds. If not provided, defaults to `chunk_length_s / 6`.\n * @property {ChunkCallback} [kwargs.chunk_callback] Callback function to be called with each chunk processed.\n * @property {boolean} [kwargs.force_full_sequences] Whether to force outputting full sequences or not. Default is `false`.\n * @property {string} [kwargs.language] The source language. Default is `null`, meaning it should be auto-detected. Use this to potentially improve performance if the source language is known.\n * @property {string} [kwargs.task] The task to perform. Default is `null`, meaning it should be auto-detected.\n * @property {number[][]} [kwargs.forced_decoder_ids] A list of pairs of integers which indicates a mapping from generation indices to token indices\n * that will be forced before sampling. For example, [[1, 123]] means the second generated token will always be a token of index 123.\n * @property {number} [num_frames] The number of frames in the input audio.\n * @typedef {import('./utils/generation.js').GenerationConfigType & AutomaticSpeechRecognitionSpecificParams} AutomaticSpeechRecognitionConfig\n * \n * @callback AutomaticSpeechRecognitionPipelineCallback Transcribe the audio sequence(s) given as inputs to text.\n * @param {AudioPipelineInputs} audio The input audio file(s) to be transcribed. The input is either:\n * - `string` or `URL` that is the filename/URL of the audio file, the file will be read at the processor's sampling rate\n * to get the waveform using the [`AudioContext`](https://developer.mozilla.org/en-US/docs/Web/API/AudioContext) API.\n * If `AudioContext` is not available, you should pass the raw waveform in as a Float32Array of shape `(n, )`.\n * - `Float32Array` or `Float64Array` of shape `(n, )`, representing the raw audio at the correct sampling rate (no further check will be done).\n * @param {AutomaticSpeechRecognitionConfig} [options] Additional keyword arguments to pass along to the generate method of the model.\n * @returns {Promise<AutomaticSpeechRecognitionOutput|AutomaticSpeechRecognitionOutput[]>} An object containing the transcription text and optionally timestamps if `return_timestamps` is `true`.\n * \n * @typedef {TextAudioPipelineConstructorArgs & AutomaticSpeechRecognitionPipelineCallback & Disposable} AutomaticSpeechRecognitionPipelineType\n */\n\n/**\n * Pipeline that aims at extracting spoken text contained within some audio.\n *\n * **Example:** Transcribe English.\n * ```javascript\n * const transcriber = await pipeline('automatic-speech-recognition', 'Xenova/whisper-tiny.en');\n * const url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/jfk.wav';\n * const output = await transcriber(url);\n * // { text: \" And so my fellow Americans ask not what your country can do for you, ask what you can do for your country.\" }\n * ```\n * \n * **Example:** Transcribe English w/ timestamps.\n * ```javascript\n * const transcriber = await pipeline('automatic-speech-recognition', 'Xenova/whisper-tiny.en');\n * const url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/jfk.wav';\n * const output = await transcriber(url, { return_timestamps: true });\n * // {\n * //   text: \" And so my fellow Americans ask not what your country can do for you, ask what you can do for your country.\"\n * //   chunks: [\n * //     { timestamp: [0, 8],  text: \" And so my fellow Americans ask not what your country can do for you\" }\n * //     { timestamp: [8, 11], text: \" ask what you can do for your country.\" }\n * //   ]\n * // }\n * ```\n * \n * **Example:** Transcribe English w/ word-level timestamps.\n * ```javascript\n * const transcriber = await pipeline('automatic-speech-recognition', 'Xenova/whisper-tiny.en');\n * const url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/jfk.wav';\n * const output = await transcriber(url, { return_timestamps: 'word' });\n * // {\n * //   \"text\": \" And so my fellow Americans ask not what your country can do for you ask what you can do for your country.\",\n * //   \"chunks\": [\n * //     { \"text\": \" And\", \"timestamp\": [0, 0.78] },\n * //     { \"text\": \" so\", \"timestamp\": [0.78, 1.06] },\n * //     { \"text\": \" my\", \"timestamp\": [1.06, 1.46] },\n * //     ...\n * //     { \"text\": \" for\", \"timestamp\": [9.72, 9.92] },\n * //     { \"text\": \" your\", \"timestamp\": [9.92, 10.22] },\n * //     { \"text\": \" country.\", \"timestamp\": [10.22, 13.5] }\n * //   ]\n * // }\n * ```\n * \n * **Example:** Transcribe French.\n * ```javascript\n * const transcriber = await pipeline('automatic-speech-recognition', 'Xenova/whisper-small');\n * const url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/french-audio.mp3';\n * const output = await transcriber(url, { language: 'french', task: 'transcribe' });\n * // { text: \" J'adore, j'aime, je n'aime pas, je dteste.\" }\n * ```\n * \n * **Example:** Translate French to English.\n * ```javascript\n * const transcriber = await pipeline('automatic-speech-recognition', 'Xenova/whisper-small');\n * const url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/french-audio.mp3';\n * const output = await transcriber(url, { language: 'french', task: 'translate' });\n * // { text: \" I love, I like, I don't like, I hate.\" }\n * ```\n * \n * **Example:** Transcribe/translate audio longer than 30 seconds.\n * ```javascript\n * const transcriber = await pipeline('automatic-speech-recognition', 'Xenova/whisper-tiny.en');\n * const url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/ted_60.wav';\n * const output = await transcriber(url, { chunk_length_s: 30, stride_length_s: 5 });\n * // { text: \" So in college, I was a government major, which means [...] So I'd start off light and I'd bump it up\" }\n * ```\n */\nclass AutomaticSpeechRecognitionPipeline extends (/** @type {new (options: TextAudioPipelineConstructorArgs) => AutomaticSpeechRecognitionPipelineType} */ (Pipeline)) {\n\n    /**\n     * Create a new AutomaticSpeechRecognitionPipeline.\n     * @param {TextAudioPipelineConstructorArgs} options An object used to instantiate the pipeline.\n     */\n    constructor(options) {\n        super(options);\n    }\n\n    /** @type {AutomaticSpeechRecognitionPipelineCallback} */\n    async _call(audio, kwargs = {}) {\n        switch (this.model.config.model_type) {\n            case 'whisper':\n                return this._call_whisper(audio, kwargs)\n            case 'wav2vec2':\n            case 'wav2vec2-bert':\n            case 'hubert':\n                return this._call_wav2vec2(audio, kwargs)\n            default:\n                throw new Error(`AutomaticSpeechRecognitionPipeline does not support model type '${this.model.config.model_type}'.`)\n        }\n    }\n\n    /**\n     * @type {AutomaticSpeechRecognitionPipelineCallback}\n     * @private\n     */\n    async _call_wav2vec2(audio, kwargs = {}) {\n        // TODO use kwargs\n\n        if (kwargs.language) {\n            console.warn('`language` parameter is not yet supported for `wav2vec2` models, defaulting to \"English\".');\n        }\n        if (kwargs.task) {\n            console.warn('`task` parameter is not yet supported for `wav2vec2` models, defaulting to \"transcribe\".');\n        }\n\n        const single = !Array.isArray(audio);\n        if (single) {\n            audio = [/** @type {AudioInput} */ (audio)];\n        }\n\n        const sampling_rate = this.processor.feature_extractor.config.sampling_rate;\n        const preparedAudios = await prepareAudios(audio, sampling_rate);\n\n        const toReturn = [];\n        for (const aud of preparedAudios) {\n            const inputs = await this.processor(aud);\n            const output = await this.model(inputs);\n            const logits = output.logits[0];\n\n            const predicted_ids = [];\n            for (const item of logits) {\n                predicted_ids.push((0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_4__.max)(item.data)[1])\n            }\n            const predicted_sentences = this.tokenizer.decode(predicted_ids)\n            toReturn.push({ text: predicted_sentences })\n        }\n        return single ? toReturn[0] : toReturn;\n    }\n\n    /**\n     * @type {AutomaticSpeechRecognitionPipelineCallback}\n     * @private\n     */\n    async _call_whisper(audio, kwargs = {}) {\n\n        const return_timestamps = kwargs.return_timestamps ?? false;\n        const chunk_length_s = kwargs.chunk_length_s ?? 0;\n        const chunk_callback = kwargs.chunk_callback ?? null;\n        const force_full_sequences = kwargs.force_full_sequences ?? false;\n        let stride_length_s = kwargs.stride_length_s ?? null;\n\n        if (return_timestamps === 'word') {\n            kwargs['return_token_timestamps'] = true;\n        }\n\n        const language = (0,_utils_core_js__WEBPACK_IMPORTED_MODULE_3__.pop)(kwargs, 'language', null);\n        const task = (0,_utils_core_js__WEBPACK_IMPORTED_MODULE_3__.pop)(kwargs, 'task', null);\n\n        if (language || task || return_timestamps) {\n            if (kwargs.forced_decoder_ids) {\n                throw new Error(\"Cannot specify `language`/`task`/`return_timestamps` and `forced_decoder_ids` at the same time.\")\n            }\n            // @ts-ignore\n            const decoder_prompt_ids = this.tokenizer.get_decoder_prompt_ids({ language, task, no_timestamps: !return_timestamps })\n            if (decoder_prompt_ids.length > 0) {\n                kwargs.forced_decoder_ids = decoder_prompt_ids;\n            }\n        }\n\n        const single = !Array.isArray(audio);\n        if (single) {\n            audio = [/** @type {AudioInput} */ (audio)];\n        }\n\n        const time_precision = this.processor.feature_extractor.config.chunk_length / this.model.config.max_source_positions;\n        const hop_length = this.processor.feature_extractor.config.hop_length;\n\n        const sampling_rate = this.processor.feature_extractor.config.sampling_rate;\n        const preparedAudios = await prepareAudios(audio, sampling_rate);\n\n        const toReturn = [];\n        for (const aud of preparedAudios) {\n            /** @type {ChunkCallbackItem[]} */\n            let chunks = [];\n            if (chunk_length_s > 0) {\n                if (stride_length_s === null) {\n                    stride_length_s = chunk_length_s / 6;\n                } else if (chunk_length_s <= stride_length_s) {\n                    throw Error(\"`chunk_length_s` must be larger than `stride_length_s`.\")\n                }\n\n                // TODO support different stride_length_s (for left and right)\n\n                const window = sampling_rate * chunk_length_s;\n                const stride = sampling_rate * stride_length_s;\n                const jump = window - 2 * stride;\n                let offset = 0;\n\n                // Create subarrays of audio with overlaps\n\n                while (offset < aud.length) {\n                    const subarr = aud.subarray(offset, offset + window);\n                    const feature = await this.processor(subarr);\n\n                    const isFirst = offset === 0;\n                    const isLast = offset + jump >= aud.length;\n                    chunks.push({\n                        stride: [\n                            subarr.length,\n                            isFirst ? 0 : stride,\n                            isLast ? 0 : stride\n                        ],\n                        input_features: feature.input_features,\n                        is_last: isLast\n                    })\n                    offset += jump;\n                }\n\n            } else {\n                chunks = [{\n                    stride: [aud.length, 0, 0],\n                    input_features: (await this.processor(aud)).input_features,\n                    is_last: true\n                }]\n            }\n\n            // Generate for each set of input features\n            for (const chunk of chunks) {\n                kwargs.num_frames = Math.floor(chunk.stride[0] / hop_length);\n\n                // NOTE: doing sequentially for now\n                const data = await this.model.generate(chunk.input_features, kwargs);\n\n                // TODO: Right now we only get top beam\n                if (return_timestamps === 'word') {\n                    chunk.tokens = data.sequences[0];\n                    chunk.token_timestamps = data.token_timestamps.tolist()[0].map(\n                        (/** @type {number} */ x) => (0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_4__.round)(x, 2)\n                    );\n\n                } else {\n                    chunk.tokens = data[0];\n                }\n\n                // convert stride to seconds\n                chunk.stride = chunk.stride.map(x => x / sampling_rate);\n\n                if (chunk_callback !== null) {\n                    chunk_callback(chunk)\n                }\n            }\n\n            // Merge text chunks\n            // @ts-ignore\n            const [full_text, optional] = this.tokenizer._decode_asr(chunks, {\n                time_precision, return_timestamps, force_full_sequences\n            });\n\n            toReturn.push({ text: full_text, ...optional })\n        }\n        return single ? toReturn[0] : toReturn;\n    }\n}\n\n/**\n * @typedef {Object} ImageToTextSingle\n * @property {string} generated_text The generated text.\n * @typedef {ImageToTextSingle[]} ImageToTextOutput\n * \n * @callback ImageToTextPipelineCallback Assign labels to the image(s) passed as inputs.\n * @param {ImagePipelineInputs} texts The images to be captioned.\n * @param {import('./utils/generation.js').GenerationConfigType} [options] Additional keyword arguments to pass along to the generate method of the model.\n * @returns {Promise<ImageToTextOutput|ImageToTextOutput[]>} An object (or array of objects) containing the generated text(s).\n * \n * @typedef {TextImagePipelineConstructorArgs & ImageToTextPipelineCallback & Disposable} ImageToTextPipelineType\n */\n\n/**\n * Image To Text pipeline using a `AutoModelForVision2Seq`. This pipeline predicts a caption for a given image.\n * \n * **Example:** Generate a caption for an image w/ `Xenova/vit-gpt2-image-captioning`.\n * ```javascript\n * const captioner = await pipeline('image-to-text', 'Xenova/vit-gpt2-image-captioning');\n * const url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/cats.jpg';\n * const output = await captioner(url);\n * // [{ generated_text: 'a cat laying on a couch with another cat' }]\n * ```\n * \n * **Example:** Optical Character Recognition (OCR) w/ `Xenova/trocr-small-handwritten`.\n * ```javascript\n * const captioner = await pipeline('image-to-text', 'Xenova/trocr-small-handwritten');\n * const url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/handwriting.jpg';\n * const output = await captioner(url);\n * // [{ generated_text: 'Mr. Brown commented icily.' }]\n * ```\n */\nclass ImageToTextPipeline extends (/** @type {new (options: TextImagePipelineConstructorArgs) => ImageToTextPipelineType} */ (Pipeline)) {\n\n    /**\n     * Create a new ImageToTextPipeline.\n     * @param {TextImagePipelineConstructorArgs} options An object used to instantiate the pipeline.\n     */\n    constructor(options) {\n        super(options);\n    }\n\n    /** @type {ImageToTextPipelineCallback} */\n    async _call(images, generate_kwargs = {}) {\n\n        const isBatched = Array.isArray(images);\n        const preparedImages = await prepareImages(images);\n\n        const { pixel_values } = await this.processor(preparedImages);\n\n        const toReturn = [];\n        for (const batch of pixel_values) {\n            batch.dims = [1, ...batch.dims]\n            const output = await this.model.generate(batch, generate_kwargs);\n            const decoded = this.tokenizer.batch_decode(output, {\n                skip_special_tokens: true,\n            }).map(x => ({ generated_text: x.trim() }))\n            toReturn.push(decoded);\n        }\n\n        return isBatched ? toReturn : toReturn[0];\n    }\n}\n\n/**\n * @typedef {Object} ImageClassificationSingle\n * @property {string} label The label identified by the model.\n * @property {number} score The score attributed by the model for that label.\n * @typedef {ImageClassificationSingle[]} ImageClassificationOutput\n * \n * @typedef {Object} ImageClassificationPipelineOptions Parameters specific to image classification pipelines.\n * @property {number} [topk=1] The number of top labels that will be returned by the pipeline. \n * \n * @callback ImageClassificationPipelineCallback Assign labels to the image(s) passed as inputs.\n * @param {ImagePipelineInputs} images The input images(s) to be classified.\n * @param {ImageClassificationPipelineOptions} [options] The options to use for image classification.\n * @returns {Promise<ImageClassificationOutput|ImageClassificationOutput[]>} An array or object containing the predicted labels and scores.\n * \n * @typedef {ImagePipelineConstructorArgs & ImageClassificationPipelineCallback & Disposable} ImageClassificationPipelineType\n */\n\n/**\n * Image classification pipeline using any `AutoModelForImageClassification`.\n * This pipeline predicts the class of an image.\n * \n * **Example:** Classify an image.\n * ```javascript\n * const classifier = await pipeline('image-classification', 'Xenova/vit-base-patch16-224');\n * const url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/tiger.jpg';\n * const output = await classifier(url);\n * // [\n * //   { label: 'tiger, Panthera tigris', score: 0.632695734500885 },\n * // ]\n * ```\n * \n * **Example:** Classify an image and return top `n` classes.\n * ```javascript\n * const classifier = await pipeline('image-classification', 'Xenova/vit-base-patch16-224');\n * const url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/tiger.jpg';\n * const output = await classifier(url, { topk: 3 });\n * // [\n * //   { label: 'tiger, Panthera tigris', score: 0.632695734500885 },\n * //   { label: 'tiger cat', score: 0.3634825646877289 },\n * //   { label: 'lion, king of beasts, Panthera leo', score: 0.00045060308184474707 },\n * // ]\n * ```\n * \n * **Example:** Classify an image and return all classes.\n * ```javascript\n * const classifier = await pipeline('image-classification', 'Xenova/vit-base-patch16-224');\n * const url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/tiger.jpg';\n * const output = await classifier(url, { topk: 0 });\n * // [\n * //   { label: 'tiger, Panthera tigris', score: 0.632695734500885 },\n * //   { label: 'tiger cat', score: 0.3634825646877289 },\n * //   { label: 'lion, king of beasts, Panthera leo', score: 0.00045060308184474707 },\n * //   { label: 'jaguar, panther, Panthera onca, Felis onca', score: 0.00035465499968267977 },\n * //   ...\n * // ]\n * ```\n */\nclass ImageClassificationPipeline extends (/** @type {new (options: ImagePipelineConstructorArgs) => ImageClassificationPipelineType} */ (Pipeline)) {\n\n    /**\n     * Create a new ImageClassificationPipeline.\n     * @param {ImagePipelineConstructorArgs} options An object used to instantiate the pipeline.\n     */\n    constructor(options) {\n        super(options);\n    }\n\n    /** @type {ImageClassificationPipelineCallback} */\n    async _call(images, {\n        topk = 1\n    } = {}) {\n\n        const isBatched = Array.isArray(images);\n        const preparedImages = await prepareImages(images);\n\n        const { pixel_values } = await this.processor(preparedImages);\n        const output = await this.model({ pixel_values });\n\n        const id2label = this.model.config.id2label;\n        const toReturn = [];\n        for (const batch of output.logits) {\n            const scores = (0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_4__.getTopItems)((0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_4__.softmax)(batch.data), topk);\n\n            const vals = scores.map(x => ({\n                label: id2label[x[0]],\n                score: x[1],\n            }));\n            if (topk === 1) {\n                toReturn.push(...vals);\n            } else {\n                toReturn.push(vals);\n            }\n        }\n\n        return isBatched || topk === 1 ? /** @type {ImageClassificationOutput} */ (toReturn) : /** @type {ImageClassificationOutput[]} */ (toReturn)[0];\n    }\n\n}\n\n/**\n * @typedef {Object} ImageSegmentationPipelineOutput\n * @property {string} label The label of the segment.\n * @property {number|null} score The score of the segment.\n * @property {RawImage} mask The mask of the segment.\n * \n * @typedef {Object} ImageSegmentationPipelineOptions Parameters specific to image segmentation pipelines.\n * @property {number} [threshold=0.5] Probability threshold to filter out predicted masks.\n * @property {number} [mask_threshold=0.5] Threshold to use when turning the predicted masks into binary values.\n * @property {number} [overlap_mask_area_threshold=0.8] Mask overlap threshold to eliminate small, disconnected segments.\n * @property {null|string} [subtask=null] Segmentation task to be performed. One of [`panoptic`, `instance`, and `semantic`],\n * depending on model capabilities. If not set, the pipeline will attempt to resolve (in that order).\n * @property {number[]} [label_ids_to_fuse=null] List of label ids to fuse. If not set, do not fuse any labels.\n * @property {number[][]} [target_sizes=null] List of target sizes for the input images. If not set, use the original image sizes.\n * \n * @callback ImageSegmentationPipelineCallback Segment the input images.\n * @param {ImagePipelineInputs} images The input images.\n * @param {ImageSegmentationPipelineOptions} [options] The options to use for image segmentation.\n * @returns {Promise<ImageSegmentationPipelineOutput[]>} The annotated segments.\n * \n * @typedef {ImagePipelineConstructorArgs & ImageSegmentationPipelineCallback & Disposable} ImageSegmentationPipelineType\n */\n\n/**\n * Image segmentation pipeline using any `AutoModelForXXXSegmentation`.\n * This pipeline predicts masks of objects and their classes.\n * \n * **Example:** Perform image segmentation with `Xenova/detr-resnet-50-panoptic`.\n * ```javascript\n * const segmenter = await pipeline('image-segmentation', 'Xenova/detr-resnet-50-panoptic');\n * const url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/cats.jpg';\n * const output = await segmenter(url);\n * // [\n * //   { label: 'remote', score: 0.9984649419784546, mask: RawImage { ... } },\n * //   { label: 'cat', score: 0.9994316101074219, mask: RawImage { ... } }\n * // ]\n * ```\n */\nclass ImageSegmentationPipeline extends (/** @type {new (options: ImagePipelineConstructorArgs) => ImageSegmentationPipelineType} */ (Pipeline)) {\n    /**\n     * Create a new ImageSegmentationPipeline.\n     * @param {ImagePipelineConstructorArgs} options An object used to instantiate the pipeline.\n     */\n    constructor(options) {\n        super(options);\n\n        this.subtasks_mapping = {\n            // Mapping of subtasks to their corresponding post-processing function names.\n            panoptic: 'post_process_panoptic_segmentation',\n            instance: 'post_process_instance_segmentation',\n            semantic: 'post_process_semantic_segmentation'\n        }\n    }\n\n    /** @type {ImageSegmentationPipelineCallback} */\n    async _call(images, {\n        threshold = 0.5,\n        mask_threshold = 0.5,\n        overlap_mask_area_threshold = 0.8,\n        label_ids_to_fuse = null,\n        target_sizes = null,\n        subtask = null,\n    } = {}) {\n        const isBatched = Array.isArray(images);\n\n        if (isBatched && images.length !== 1) {\n            throw Error(\"Image segmentation pipeline currently only supports a batch size of 1.\");\n        }\n\n        const preparedImages = await prepareImages(images);\n        const imageSizes = preparedImages.map(x => [x.height, x.width]);\n\n        const { pixel_values, pixel_mask } = await this.processor(preparedImages);\n        const output = await this.model({ pixel_values, pixel_mask });\n\n        let fn = null;\n        if (subtask !== null) {\n            fn = this.subtasks_mapping[subtask];\n        } else {\n            for (let [task, func] of Object.entries(this.subtasks_mapping)) {\n                if (func in this.processor.feature_extractor) {\n                    fn = this.processor.feature_extractor[func].bind(this.processor.feature_extractor);\n                    subtask = task;\n                    break;\n                }\n            }\n        }\n\n        const id2label = this.model.config.id2label;\n\n        /** @type {ImageSegmentationPipelineOutput[]} */\n        const annotation = [];\n        if (subtask === 'panoptic' || subtask === 'instance') {\n            const processed = fn(\n                output,\n                threshold,\n                mask_threshold,\n                overlap_mask_area_threshold,\n                label_ids_to_fuse,\n                target_sizes ?? imageSizes, // TODO FIX?\n            )[0];\n\n            const segmentation = processed.segmentation;\n\n            for (const segment of processed.segments_info) {\n                const maskData = new Uint8ClampedArray(segmentation.data.length);\n                for (let i = 0; i < segmentation.data.length; ++i) {\n                    if (segmentation.data[i] === segment.id) {\n                        maskData[i] = 255;\n                    }\n                }\n\n                const mask = new _utils_image_js__WEBPACK_IMPORTED_MODULE_7__.RawImage(maskData, segmentation.dims[1], segmentation.dims[0], 1)\n\n                annotation.push({\n                    score: segment.score,\n                    label: id2label[segment.label_id],\n                    mask: mask\n                })\n            }\n\n        } else if (subtask === 'semantic') {\n            const { segmentation, labels } = fn(output, target_sizes ?? imageSizes)[0];\n\n            for (const label of labels) {\n                const maskData = new Uint8ClampedArray(segmentation.data.length);\n                for (let i = 0; i < segmentation.data.length; ++i) {\n                    if (segmentation.data[i] === label) {\n                        maskData[i] = 255;\n                    }\n                }\n\n                const mask = new _utils_image_js__WEBPACK_IMPORTED_MODULE_7__.RawImage(maskData, segmentation.dims[1], segmentation.dims[0], 1);\n\n                annotation.push({\n                    score: null,\n                    label: id2label[label],\n                    mask: mask\n                });\n            }\n        } else {\n            throw Error(`Subtask ${subtask} not supported.`);\n        }\n\n        return annotation;\n    }\n}\n\n/**\n * @typedef {Object} ZeroShotImageClassificationOutput\n * @property {string} label The label identified by the model. It is one of the suggested `candidate_label`.\n * @property {number} score The score attributed by the model for that label (between 0 and 1).\n * \n * @typedef {Object} ZeroShotImageClassificationPipelineOptions Parameters specific to zero-shot image classification pipelines.\n * @property {string} [hypothesis_template=\"This is a photo of {}\"] The sentence used in conjunction with `candidate_labels`\n * to attempt the image classification by replacing the placeholder with the candidate_labels.\n * Then likelihood is estimated by using `logits_per_image`.\n * \n * @callback ZeroShotImageClassificationPipelineCallback Assign labels to the image(s) passed as inputs.\n * @param {ImagePipelineInputs} images The input images.\n * @param {string[]} candidate_labels The candidate labels for this image.\n * @param {ZeroShotImageClassificationPipelineOptions} [options] The options to use for zero-shot image classification.\n * @returns {Promise<ZeroShotImageClassificationOutput[]|ZeroShotImageClassificationOutput[][]>} An array of objects containing the predicted labels and scores.\n * \n * @typedef {TextImagePipelineConstructorArgs & ZeroShotImageClassificationPipelineCallback & Disposable} ZeroShotImageClassificationPipelineType\n */\n\n/**\n * Zero shot image classification pipeline. This pipeline predicts the class of\n * an image when you provide an image and a set of `candidate_labels`.\n * \n * **Example:** Zero shot image classification w/ `Xenova/clip-vit-base-patch32`.\n * ```javascript\n * const classifier = await pipeline('zero-shot-image-classification', 'Xenova/clip-vit-base-patch32');\n * const url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/tiger.jpg';\n * const output = await classifier(url, ['tiger', 'horse', 'dog']);\n * // [\n * //   { score: 0.9993917942047119, label: 'tiger' },\n * //   { score: 0.0003519294841680676, label: 'horse' },\n * //   { score: 0.0002562698791734874, label: 'dog' }\n * // ]\n * ```\n */\nclass ZeroShotImageClassificationPipeline extends (/** @type {new (options: TextImagePipelineConstructorArgs) => ZeroShotImageClassificationPipelineType} */ (Pipeline)) {\n    /**\n     * Create a new ZeroShotImageClassificationPipeline.\n     * @param {TextImagePipelineConstructorArgs} options An object used to instantiate the pipeline.\n     */\n    constructor(options) {\n        super(options);\n    }\n\n    /** @type {ZeroShotImageClassificationPipelineCallback} */\n    async _call(images, candidate_labels, {\n        hypothesis_template = \"This is a photo of {}\"\n    } = {}) {\n\n        const isBatched = Array.isArray(images);\n        const preparedImages = await prepareImages(images);\n\n        // Insert label into hypothesis template \n        const texts = candidate_labels.map(\n            x => hypothesis_template.replace('{}', x)\n        );\n\n        // Run tokenization\n        const text_inputs = this.tokenizer(texts, {\n            padding: this.model.config.model_type === 'siglip' ? 'max_length' : true,\n            truncation: true,\n        });\n\n        // Run processor\n        const { pixel_values } = await this.processor(preparedImages);\n\n        // Run model with both text and pixel inputs\n        const output = await this.model({ ...text_inputs, pixel_values });\n\n        const function_to_apply =\n            this.model.config.model_type === 'siglip'\n                ? batch => batch.sigmoid().data\n                : batch => (0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_4__.softmax)(batch.data);\n\n        // Compare each image with each candidate label\n        const toReturn = [];\n        for (const batch of output.logits_per_image) {\n            // Compute softmax per image\n            const probs = function_to_apply(batch);\n\n            const result = [...probs].map((x, i) => ({\n                score: x,\n                label: candidate_labels[i]\n            }));\n            result.sort((a, b) => b.score - a.score); // sort by score in descending order\n            toReturn.push(result);\n        }\n\n        return isBatched ? toReturn : toReturn[0];\n    }\n}\n\n\n/**\n * @typedef {Object} ObjectDetectionPipelineSingle\n * @property {string} label The class label identified by the model.\n * @property {number} score The score attributed by the model for that label.\n * @property {BoundingBox} box The bounding box of detected object in image's original size, or as a percentage if `percentage` is set to true.\n * @typedef {ObjectDetectionPipelineSingle[]} ObjectDetectionPipelineOutput\n * \n * @typedef {Object} ObjectDetectionPipelineOptions Parameters specific to object detection pipelines.\n * @property {number} [threshold=0.9] The threshold used to filter boxes by score.\n * @property {boolean} [percentage=false] Whether to return the boxes coordinates in percentage (true) or in pixels (false).\n * \n * @callback ObjectDetectionPipelineCallback Detect objects (bounding boxes & classes) in the image(s) passed as inputs.\n * @param {ImagePipelineInputs} images The input images.\n * @param {ObjectDetectionPipelineOptions} [options] The options to use for object detection.\n * @returns {Promise<ObjectDetectionPipelineOutput|ObjectDetectionPipelineOutput[]>} A list of objects or a list of list of objects. \n * \n * @typedef {ImagePipelineConstructorArgs & ObjectDetectionPipelineCallback & Disposable} ObjectDetectionPipelineType\n */\n\n/**\n * Object detection pipeline using any `AutoModelForObjectDetection`.\n * This pipeline predicts bounding boxes of objects and their classes.\n * \n * **Example:** Run object-detection with `Xenova/detr-resnet-50`.\n * ```javascript\n * const detector = await pipeline('object-detection', 'Xenova/detr-resnet-50');\n * const img = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/cats.jpg';\n * const output = await detector(img, { threshold: 0.9 });\n * // [{\n * //   score: 0.9976370930671692,\n * //   label: \"remote\",\n * //   box: { xmin: 31, ymin: 68, xmax: 190, ymax: 118 }\n * // },\n * // ...\n * // {\n * //   score: 0.9984092116355896,\n * //   label: \"cat\",\n * //   box: { xmin: 331, ymin: 19, xmax: 649, ymax: 371 }\n * // }]\n * ```\n */\nclass ObjectDetectionPipeline extends (/** @type {new (options: ImagePipelineConstructorArgs) => ObjectDetectionPipelineType} */ (Pipeline)) {\n\n    /**\n     * Create a new ObjectDetectionPipeline.\n     * @param {ImagePipelineConstructorArgs} options An object used to instantiate the pipeline.\n     */\n    constructor(options) {\n        super(options);\n    }\n\n    /** @type {ObjectDetectionPipelineCallback} */\n    async _call(images, {\n        threshold = 0.9,\n        percentage = false,\n    } = {}) {\n\n        const isBatched = Array.isArray(images);\n\n        if (isBatched && images.length !== 1) {\n            throw Error(\"Object detection pipeline currently only supports a batch size of 1.\");\n        }\n        const preparedImages = await prepareImages(images);\n\n        const imageSizes = percentage ? null : preparedImages.map(x => [x.height, x.width]);\n\n        const { pixel_values, pixel_mask } = await this.processor(preparedImages);\n        const output = await this.model({ pixel_values, pixel_mask });\n\n        // @ts-ignore\n        const processed = this.processor.feature_extractor.post_process_object_detection(output, threshold, imageSizes);\n\n        // Add labels\n        const id2label = this.model.config.id2label;\n\n        // Format output\n        /** @type {ObjectDetectionPipelineOutput[]} */\n        const result = processed.map(batch => (\n            batch.boxes.map((box, i) => ({\n                score: batch.scores[i],\n                label: id2label[batch.classes[i]],\n                box: get_bounding_box(box, !percentage),\n            }))\n        ))\n\n        return isBatched ? result : result[0];\n    }\n}\n\n\n/**\n * @typedef {Object} ZeroShotObjectDetectionOutput\n * @property {string} label Text query corresponding to the found object.\n * @property {number} score Score corresponding to the object (between 0 and 1).\n * @property {BoundingBox} box Bounding box of the detected object in image's original size, or as a percentage if `percentage` is set to true.\n * \n * @typedef {Object} ZeroShotObjectDetectionPipelineOptions Parameters specific to zero-shot object detection pipelines.\n * @property {number} [threshold=0.1] The probability necessary to make a prediction.\n * @property {number} [topk=null] The number of top predictions that will be returned by the pipeline.\n * If the provided number is `null` or higher than the number of predictions available, it will default\n * to the number of predictions.\n * @property {boolean} [percentage=false] Whether to return the boxes coordinates in percentage (true) or in pixels (false).\n * \n * @callback ZeroShotObjectDetectionPipelineCallback Detect objects (bounding boxes & classes) in the image(s) passed as inputs.\n * @param {ImagePipelineInputs} images The input images.\n * @param {string[]} candidate_labels What the model should recognize in the image.\n * @param {ZeroShotObjectDetectionPipelineOptions} [options] The options to use for zero-shot object detection.\n * @returns {Promise<ZeroShotObjectDetectionOutput[]|ZeroShotObjectDetectionOutput[][]>} An array of objects containing the predicted labels, scores, and bounding boxes.\n * \n * @typedef {TextImagePipelineConstructorArgs & ZeroShotObjectDetectionPipelineCallback & Disposable} ZeroShotObjectDetectionPipelineType\n */\n\n/**\n * Zero-shot object detection pipeline. This pipeline predicts bounding boxes of\n * objects when you provide an image and a set of `candidate_labels`.\n * \n * **Example:** Zero-shot object detection w/ `Xenova/owlvit-base-patch32`.\n * ```javascript\n * const detector = await pipeline('zero-shot-object-detection', 'Xenova/owlvit-base-patch32');\n * const url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/astronaut.png';\n * const candidate_labels = ['human face', 'rocket', 'helmet', 'american flag'];\n * const output = await detector(url, candidate_labels);\n * // [\n * //   {\n * //     score: 0.24392342567443848,\n * //     label: 'human face',\n * //     box: { xmin: 180, ymin: 67, xmax: 274, ymax: 175 }\n * //   },\n * //   {\n * //     score: 0.15129457414150238,\n * //     label: 'american flag',\n * //     box: { xmin: 0, ymin: 4, xmax: 106, ymax: 513 }\n * //   },\n * //   {\n * //     score: 0.13649864494800568,\n * //     label: 'helmet',\n * //     box: { xmin: 277, ymin: 337, xmax: 511, ymax: 511 }\n * //   },\n * //   {\n * //     score: 0.10262022167444229,\n * //     label: 'rocket',\n * //     box: { xmin: 352, ymin: -1, xmax: 463, ymax: 287 }\n * //   }\n * // ]\n * ```\n * \n * **Example:** Zero-shot object detection w/ `Xenova/owlvit-base-patch32` (returning top 4 matches and setting a threshold).\n * ```javascript\n * const detector = await pipeline('zero-shot-object-detection', 'Xenova/owlvit-base-patch32');\n * const url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/beach.png';\n * const candidate_labels = ['hat', 'book', 'sunglasses', 'camera'];\n * const output = await detector(url, candidate_labels, { topk: 4, threshold: 0.05 });\n * // [\n * //   {\n * //     score: 0.1606510728597641,\n * //     label: 'sunglasses',\n * //     box: { xmin: 347, ymin: 229, xmax: 429, ymax: 264 }\n * //   },\n * //   {\n * //     score: 0.08935828506946564,\n * //     label: 'hat',\n * //     box: { xmin: 38, ymin: 174, xmax: 258, ymax: 364 }\n * //   },\n * //   {\n * //     score: 0.08530698716640472,\n * //     label: 'camera',\n * //     box: { xmin: 187, ymin: 350, xmax: 260, ymax: 411 }\n * //   },\n * //   {\n * //     score: 0.08349756896495819,\n * //     label: 'book',\n * //     box: { xmin: 261, ymin: 280, xmax: 494, ymax: 425 }\n * //   }\n * // ]\n * ```\n */\nclass ZeroShotObjectDetectionPipeline extends (/** @type {new (options: TextImagePipelineConstructorArgs) => ZeroShotObjectDetectionPipelineType} */ (Pipeline)) {\n\n    /**\n     * Create a new ZeroShotObjectDetectionPipeline.\n     * @param {TextImagePipelineConstructorArgs} options An object used to instantiate the pipeline.\n     */\n    constructor(options) {\n        super(options);\n    }\n\n    /** @type {ZeroShotObjectDetectionPipelineCallback} */\n    async _call(images, candidate_labels, {\n        threshold = 0.1,\n        topk = null,\n        percentage = false,\n    } = {}) {\n\n        const isBatched = Array.isArray(images);\n        const preparedImages = await prepareImages(images);\n\n        // Run tokenization\n        const text_inputs = this.tokenizer(candidate_labels, {\n            padding: true,\n            truncation: true,\n        });\n\n        // Run processor\n        const model_inputs = await this.processor(preparedImages);\n\n        // Since non-maximum suppression is performed for exporting, we need to\n        // process each image separately. For more information, see:\n        // https://github.com/huggingface/optimum/blob/e3b7efb1257c011db907ef40ab340e795cc5684c/optimum/exporters/onnx/model_configs.py#L1028-L1032\n        const toReturn = [];\n        for (let i = 0; i < preparedImages.length; ++i) {\n            const image = preparedImages[i];\n            const imageSize = percentage ? null : [[image.height, image.width]];\n            const pixel_values = model_inputs.pixel_values[i].unsqueeze_(0);\n\n            // Run model with both text and pixel inputs\n            const output = await this.model({ ...text_inputs, pixel_values });\n\n            // @ts-ignore\n            const processed = this.processor.feature_extractor.post_process_object_detection(output, threshold, imageSize, true)[0];\n            let result = processed.boxes.map((box, i) => ({\n                score: processed.scores[i],\n                label: candidate_labels[processed.classes[i]],\n                box: get_bounding_box(box, !percentage),\n            })).sort((a, b) => b.score - a.score);\n            if (topk !== null) {\n                result = result.slice(0, topk);\n            }\n            toReturn.push(result)\n        }\n\n        return isBatched ? toReturn : toReturn[0];\n    }\n}\n\n/**\n * @typedef {Object} DocumentQuestionAnsweringSingle\n * @property {string} answer The generated text.\n * @typedef {DocumentQuestionAnsweringSingle[]} DocumentQuestionAnsweringOutput\n * \n * @callback DocumentQuestionAnsweringPipelineCallback Answer the question given as input by using the document.\n * @param {ImageInput} image The image of the document to use.\n * @param {string} question A question to ask of the document.\n * @param {import('./utils/generation.js').GenerationConfigType} [options] Additional keyword arguments to pass along to the generate method of the model.\n * @returns {Promise<DocumentQuestionAnsweringOutput|DocumentQuestionAnsweringOutput[]>} An object (or array of objects) containing the answer(s).\n * \n * @typedef {TextImagePipelineConstructorArgs & DocumentQuestionAnsweringPipelineCallback & Disposable} DocumentQuestionAnsweringPipelineType\n */\n\n/**\n * Document Question Answering pipeline using any `AutoModelForDocumentQuestionAnswering`.\n * The inputs/outputs are similar to the (extractive) question answering pipeline; however,\n * the pipeline takes an image (and optional OCR'd words/boxes) as input instead of text context.\n * \n * **Example:** Answer questions about a document with `Xenova/donut-base-finetuned-docvqa`.\n * ```javascript\n * const qa_pipeline = await pipeline('document-question-answering', 'Xenova/donut-base-finetuned-docvqa');\n * const image = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/invoice.png';\n * const question = 'What is the invoice number?';\n * const output = await qa_pipeline(image, question);\n * // [{ answer: 'us-001' }]\n * ```\n */\nclass DocumentQuestionAnsweringPipeline extends (/** @type {new (options: TextImagePipelineConstructorArgs) => DocumentQuestionAnsweringPipelineType} */ (Pipeline)) {\n\n    /**\n     * Create a new DocumentQuestionAnsweringPipeline.\n     * @param {TextImagePipelineConstructorArgs} options An object used to instantiate the pipeline.\n     */\n    constructor(options) {\n        super(options);\n    }\n\n    /** @type {DocumentQuestionAnsweringPipelineCallback} */\n    async _call(image, question, generate_kwargs = {}) {\n\n        // NOTE: For now, we only support a batch size of 1\n\n        // Preprocess image\n        const preparedImage = (await prepareImages(image))[0];\n        const { pixel_values } = await this.processor(preparedImage);\n\n        // Run tokenization\n        const task_prompt = `<s_docvqa><s_question>${question}</s_question><s_answer>`;\n        const decoder_input_ids = this.tokenizer(task_prompt, {\n            add_special_tokens: false,\n            padding: true,\n            truncation: true,\n        }).input_ids;\n\n        // Run model\n        const output = await this.model.generate(\n            pixel_values,\n            {\n                ...generate_kwargs,\n                decoder_input_ids,\n                max_length: this.model.config.decoder.max_position_embeddings,\n            }\n        );\n\n        // Decode output\n        const decoded = this.tokenizer.batch_decode(output)[0];\n\n        // Parse answer\n        const match = decoded.match(/<s_answer>(.*?)<\\/s_answer>/);\n        let answer = null;\n        if (match && match.length >= 2) {\n            answer = match[1].trim();\n        }\n        return [{ answer }];\n    }\n}\n\n\n/**\n * @typedef {Object} VocoderOptions\n * @property {PreTrainedModel} [vocoder] The vocoder used by the pipeline (if the model uses one). If not provided, use the default HifiGan vocoder.\n * @typedef {TextAudioPipelineConstructorArgs & VocoderOptions} TextToAudioPipelineConstructorArgs\n */\n\n/**\n * @typedef {Object} TextToAudioOutput\n * @property {Float32Array} audio The generated audio waveform.\n * @property {number} sampling_rate The sampling rate of the generated audio waveform.\n * \n * @typedef {Object} TextToAudioPipelineOptions Parameters specific to text-to-audio pipelines.\n * @property {Tensor|Float32Array|string|URL} [speaker_embeddings=null] The speaker embeddings (if the model requires it).\n * \n * @callback TextToAudioPipelineCallback Generates speech/audio from the inputs.\n * @param {string|string[]} texts The text(s) to generate.\n * @param {TextToAudioPipelineOptions} options Parameters passed to the model generation/forward method.\n * @returns {Promise<TextToAudioOutput>} An object containing the generated audio and sampling rate.\n * \n * @typedef {TextToAudioPipelineConstructorArgs & TextToAudioPipelineCallback & Disposable} TextToAudioPipelineType\n */\n\n/**\n * Text-to-audio generation pipeline using any `AutoModelForTextToWaveform` or `AutoModelForTextToSpectrogram`.\n * This pipeline generates an audio file from an input text and optional other conditional inputs.\n * \n * **Example:** Generate audio from text with `Xenova/speecht5_tts`.\n * ```javascript\n * const synthesizer = await pipeline('text-to-speech', 'Xenova/speecht5_tts', { quantized: false });\n * const speaker_embeddings = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/speaker_embeddings.bin';\n * const out = await synthesizer('Hello, my dog is cute', { speaker_embeddings });\n * // {\n * //   audio: Float32Array(26112) [-0.00005657337896991521, 0.00020583874720614403, ...],\n * //   sampling_rate: 16000\n * // }\n * ```\n * \n * You can then save the audio to a .wav file with the `wavefile` package:\n * ```javascript\n * import wavefile from 'wavefile';\n * import fs from 'fs';\n * \n * const wav = new wavefile.WaveFile();\n * wav.fromScratch(1, out.sampling_rate, '32f', out.audio);\n * fs.writeFileSync('out.wav', wav.toBuffer());\n * ```\n * \n * **Example:** Multilingual speech generation with `Xenova/mms-tts-fra`. See [here](https://huggingface.co/models?pipeline_tag=text-to-speech&other=vits&sort=trending) for the full list of available languages (1107).\n * ```javascript\n * const synthesizer = await pipeline('text-to-speech', 'Xenova/mms-tts-fra');\n * const out = await synthesizer('Bonjour');\n * // {\n * //   audio: Float32Array(23808) [-0.00037693005288019776, 0.0003325853613205254, ...],\n * //   sampling_rate: 16000\n * // }\n * ```\n */\nclass TextToAudioPipeline extends (/** @type {new (options: TextToAudioPipelineConstructorArgs) => TextToAudioPipelineType} */ (Pipeline)) {\n    DEFAULT_VOCODER_ID = \"Xenova/speecht5_hifigan\"\n\n    /**\n     * Create a new TextToAudioPipeline.\n     * @param {TextToAudioPipelineConstructorArgs} options An object used to instantiate the pipeline.\n     */\n    constructor(options) {\n        super(options);\n\n        // TODO: Find a better way for `pipeline` to set the default vocoder\n        this.vocoder = options.vocoder ?? null;\n    }\n\n\n    /** @type {TextToAudioPipelineCallback} */\n    async _call(text_inputs, {\n        speaker_embeddings = null,\n    } = {}) {\n\n        // If this.processor is not set, we are using a `AutoModelForTextToWaveform` model\n        if (this.processor) {\n            return this._call_text_to_spectrogram(text_inputs, { speaker_embeddings });\n        } else {\n            return this._call_text_to_waveform(text_inputs);\n        }\n    }\n\n    async _call_text_to_waveform(text_inputs) {\n\n        // Run tokenization\n        const inputs = this.tokenizer(text_inputs, {\n            padding: true,\n            truncation: true,\n        });\n\n        // Generate waveform\n        const { waveform } = await this.model(inputs);\n\n        const sampling_rate = this.model.config.sampling_rate;\n        return {\n            audio: waveform.data,\n            sampling_rate,\n        }\n    }\n\n    async _call_text_to_spectrogram(text_inputs, { speaker_embeddings }) {\n\n        // Load vocoder, if not provided\n        if (!this.vocoder) {\n            console.log('No vocoder specified, using default HifiGan vocoder.');\n            this.vocoder = await _models_js__WEBPACK_IMPORTED_MODULE_1__.AutoModel.from_pretrained(this.DEFAULT_VOCODER_ID, { quantized: false });\n        }\n\n        // Load speaker embeddings as Float32Array from path/URL\n        if (typeof speaker_embeddings === 'string' || speaker_embeddings instanceof URL) {\n            // Load from URL with fetch\n            speaker_embeddings = new Float32Array(\n                await (await fetch(speaker_embeddings)).arrayBuffer()\n            );\n        }\n\n        if (speaker_embeddings instanceof Float32Array) {\n            speaker_embeddings = new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_6__.Tensor(\n                'float32',\n                speaker_embeddings,\n                [1, speaker_embeddings.length]\n            )\n        } else if (!(speaker_embeddings instanceof _utils_tensor_js__WEBPACK_IMPORTED_MODULE_6__.Tensor)) {\n            throw new Error(\"Speaker embeddings must be a `Tensor`, `Float32Array`, `string`, or `URL`.\")\n        }\n\n        // Run tokenization\n        const { input_ids } = this.tokenizer(text_inputs, {\n            padding: true,\n            truncation: true,\n        });\n\n        // NOTE: At this point, we are guaranteed that `speaker_embeddings` is a `Tensor`\n        // @ts-ignore\n        const { waveform } = await this.model.generate_speech(input_ids, speaker_embeddings, { vocoder: this.vocoder });\n\n        const sampling_rate = this.processor.feature_extractor.config.sampling_rate;\n        return {\n            audio: waveform.data,\n            sampling_rate,\n        }\n    }\n}\n\n/**\n * @callback ImageToImagePipelineCallback Transform the image(s) passed as inputs.\n * @param {ImagePipelineInputs} images The images to transform.\n * @returns {Promise<RawImage|RawImage[]>} The transformed image or list of images.\n * \n * @typedef {ImagePipelineConstructorArgs & ImageToImagePipelineCallback & Disposable} ImageToImagePipelineType\n */\n\n/**\n * Image to Image pipeline using any `AutoModelForImageToImage`. This pipeline generates an image based on a previous image input.\n * \n * **Example:** Super-resolution w/ `Xenova/swin2SR-classical-sr-x2-64`\n * ```javascript\n * const upscaler = await pipeline('image-to-image', 'Xenova/swin2SR-classical-sr-x2-64');\n * const url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/butterfly.jpg';\n * const output = await upscaler(url);\n * // RawImage {\n * //   data: Uint8Array(786432) [ 41, 31, 24,  43, ... ],\n * //   width: 512,\n * //   height: 512,\n * //   channels: 3\n * // }\n * ```\n */\nclass ImageToImagePipeline extends (/** @type {new (options: ImagePipelineConstructorArgs) => ImageToImagePipelineType} */ (Pipeline)) {\n    /**\n     * Create a new ImageToImagePipeline.\n     * @param {ImagePipelineConstructorArgs} options An object used to instantiate the pipeline.\n     */\n    constructor(options) {\n        super(options);\n    }\n\n    /** @type {ImageToImagePipelineCallback} */\n    async _call(images) {\n\n        const preparedImages = await prepareImages(images);\n        const inputs = await this.processor(preparedImages);\n        const outputs = await this.model(inputs);\n\n        /** @type {RawImage[]} */\n        const toReturn = [];\n        for (const batch of outputs.reconstruction) {\n            const output = batch.squeeze().clamp_(0, 1).mul_(255).round_().to('uint8');\n            toReturn.push(_utils_image_js__WEBPACK_IMPORTED_MODULE_7__.RawImage.fromTensor(output));\n        }\n\n        return toReturn.length > 1 ? toReturn : toReturn[0];\n    }\n}\n\n/**\n * @typedef {Object} DepthEstimationPipelineOutput\n * @property {Tensor} predicted_depth The raw depth map predicted by the model.\n * @property {RawImage} depth The processed depth map as an image (with the same size as the input image).\n * \n * @callback DepthEstimationPipelineCallback Predicts the depth for the image(s) passed as inputs.\n * @param {ImagePipelineInputs} images The images to compute depth for.\n * @returns {Promise<DepthEstimationPipelineOutput|DepthEstimationPipelineOutput[]>} An image or a list of images containing result(s).\n * \n * @typedef {ImagePipelineConstructorArgs & DepthEstimationPipelineCallback & Disposable} DepthEstimationPipelineType\n */\n\n/**\n * Depth estimation pipeline using any `AutoModelForDepthEstimation`. This pipeline predicts the depth of an image.\n * \n * **Example:** Depth estimation w/ `Xenova/dpt-hybrid-midas`\n * ```javascript\n * const depth_estimator = await pipeline('depth-estimation', 'Xenova/dpt-hybrid-midas');\n * const url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/cats.jpg';\n * const out = await depth_estimator(url);\n * // {\n * //   predicted_depth: Tensor {\n * //     dims: [ 384, 384 ],\n * //     type: 'float32',\n * //     data: Float32Array(147456) [ 542.859130859375, 545.2833862304688, 546.1649169921875, ... ],\n * //     size: 147456\n * //   },\n * //   depth: RawImage {\n * //     data: Uint8Array(307200) [ 86, 86, 86, ... ],\n * //     width: 640,\n * //     height: 480,\n * //     channels: 1\n * //   }\n * // }\n * ```\n */\nclass DepthEstimationPipeline extends (/** @type {new (options: ImagePipelineConstructorArgs) => DepthEstimationPipelineType} */ (Pipeline)) {\n    /**\n     * Create a new DepthEstimationPipeline.\n     * @param {ImagePipelineConstructorArgs} options An object used to instantiate the pipeline.\n     */\n    constructor(options) {\n        super(options);\n    }\n\n    /** @type {DepthEstimationPipelineCallback} */\n    async _call(images) {\n\n        const preparedImages = await prepareImages(images);\n\n        const inputs = await this.processor(preparedImages);\n        const { predicted_depth } = await this.model(inputs);\n\n        const toReturn = [];\n        for (let i = 0; i < preparedImages.length; ++i) {\n            const prediction = (0,_utils_tensor_js__WEBPACK_IMPORTED_MODULE_6__.interpolate)(predicted_depth[i], preparedImages[i].size.reverse(), 'bilinear', false);\n            const formatted = prediction.mul_(255 / (0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_4__.max)(prediction.data)[0]).to('uint8');\n            toReturn.push({\n                predicted_depth: predicted_depth[i],\n                depth: _utils_image_js__WEBPACK_IMPORTED_MODULE_7__.RawImage.fromTensor(formatted),\n            });\n        }\n\n        return toReturn.length > 1 ? toReturn : toReturn[0];\n    }\n}\n\nconst SUPPORTED_TASKS = Object.freeze({\n    \"text-classification\": {\n        \"tokenizer\": _tokenizers_js__WEBPACK_IMPORTED_MODULE_0__.AutoTokenizer,\n        \"pipeline\": TextClassificationPipeline,\n        \"model\": _models_js__WEBPACK_IMPORTED_MODULE_1__.AutoModelForSequenceClassification,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"distilbert-base-uncased-finetuned-sst-2-english\",\n            \"model\": \"Xenova/distilbert-base-uncased-finetuned-sst-2-english\",\n        },\n        \"type\": \"text\",\n    },\n    \"token-classification\": {\n        \"tokenizer\": _tokenizers_js__WEBPACK_IMPORTED_MODULE_0__.AutoTokenizer,\n        \"pipeline\": TokenClassificationPipeline,\n        \"model\": _models_js__WEBPACK_IMPORTED_MODULE_1__.AutoModelForTokenClassification,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"Davlan/bert-base-multilingual-cased-ner-hrl\",\n            \"model\": \"Xenova/bert-base-multilingual-cased-ner-hrl\",\n        },\n        \"type\": \"text\",\n    },\n    \"question-answering\": {\n        \"tokenizer\": _tokenizers_js__WEBPACK_IMPORTED_MODULE_0__.AutoTokenizer,\n        \"pipeline\": QuestionAnsweringPipeline,\n        \"model\": _models_js__WEBPACK_IMPORTED_MODULE_1__.AutoModelForQuestionAnswering,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"distilbert-base-cased-distilled-squad\",\n            \"model\": \"Xenova/distilbert-base-cased-distilled-squad\",\n        },\n        \"type\": \"text\",\n    },\n\n    \"fill-mask\": {\n        \"tokenizer\": _tokenizers_js__WEBPACK_IMPORTED_MODULE_0__.AutoTokenizer,\n        \"pipeline\": FillMaskPipeline,\n        \"model\": _models_js__WEBPACK_IMPORTED_MODULE_1__.AutoModelForMaskedLM,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"bert-base-uncased\",\n            \"model\": \"Xenova/bert-base-uncased\",\n        },\n        \"type\": \"text\",\n    },\n    \"summarization\": {\n        \"tokenizer\": _tokenizers_js__WEBPACK_IMPORTED_MODULE_0__.AutoTokenizer,\n        \"pipeline\": SummarizationPipeline,\n        \"model\": _models_js__WEBPACK_IMPORTED_MODULE_1__.AutoModelForSeq2SeqLM,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"sshleifer/distilbart-cnn-6-6\",\n            \"model\": \"Xenova/distilbart-cnn-6-6\",\n        },\n        \"type\": \"text\",\n    },\n    \"translation\": {\n        \"tokenizer\": _tokenizers_js__WEBPACK_IMPORTED_MODULE_0__.AutoTokenizer,\n        \"pipeline\": TranslationPipeline,\n        \"model\": _models_js__WEBPACK_IMPORTED_MODULE_1__.AutoModelForSeq2SeqLM,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"t5-small\",\n            \"model\": \"Xenova/t5-small\",\n        },\n        \"type\": \"text\",\n    },\n    \"text2text-generation\": {\n        \"tokenizer\": _tokenizers_js__WEBPACK_IMPORTED_MODULE_0__.AutoTokenizer,\n        \"pipeline\": Text2TextGenerationPipeline,\n        \"model\": _models_js__WEBPACK_IMPORTED_MODULE_1__.AutoModelForSeq2SeqLM,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"google/flan-t5-small\",\n            \"model\": \"Xenova/flan-t5-small\",\n        },\n        \"type\": \"text\",\n    },\n    \"text-generation\": {\n        \"tokenizer\": _tokenizers_js__WEBPACK_IMPORTED_MODULE_0__.AutoTokenizer,\n        \"pipeline\": TextGenerationPipeline,\n        \"model\": _models_js__WEBPACK_IMPORTED_MODULE_1__.AutoModelForCausalLM,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"gpt2\",\n            \"model\": \"Xenova/gpt2\",\n        },\n        \"type\": \"text\",\n    },\n    \"zero-shot-classification\": {\n        \"tokenizer\": _tokenizers_js__WEBPACK_IMPORTED_MODULE_0__.AutoTokenizer,\n        \"pipeline\": ZeroShotClassificationPipeline,\n        \"model\": _models_js__WEBPACK_IMPORTED_MODULE_1__.AutoModelForSequenceClassification,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"typeform/distilbert-base-uncased-mnli\",\n            \"model\": \"Xenova/distilbert-base-uncased-mnli\",\n        },\n        \"type\": \"text\",\n    },\n    \"audio-classification\": {\n        \"pipeline\": AudioClassificationPipeline,\n        \"model\": _models_js__WEBPACK_IMPORTED_MODULE_1__.AutoModelForAudioClassification,\n        \"processor\": _processors_js__WEBPACK_IMPORTED_MODULE_2__.AutoProcessor,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"superb/wav2vec2-base-superb-ks\",\n            \"model\": \"Xenova/wav2vec2-base-superb-ks\",\n        },\n        \"type\": \"audio\",\n    },\n    \"zero-shot-audio-classification\": {\n        \"tokenizer\": _tokenizers_js__WEBPACK_IMPORTED_MODULE_0__.AutoTokenizer,\n        \"pipeline\": ZeroShotAudioClassificationPipeline,\n        \"model\": _models_js__WEBPACK_IMPORTED_MODULE_1__.AutoModel,\n        \"processor\": _processors_js__WEBPACK_IMPORTED_MODULE_2__.AutoProcessor,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"laion/clap-htsat-fused\",\n            \"model\": \"Xenova/clap-htsat-unfused\",\n        },\n        \"type\": \"multimodal\",\n    },\n    \"automatic-speech-recognition\": {\n        \"tokenizer\": _tokenizers_js__WEBPACK_IMPORTED_MODULE_0__.AutoTokenizer,\n        \"pipeline\": AutomaticSpeechRecognitionPipeline,\n        \"model\": [_models_js__WEBPACK_IMPORTED_MODULE_1__.AutoModelForSpeechSeq2Seq, _models_js__WEBPACK_IMPORTED_MODULE_1__.AutoModelForCTC],\n        \"processor\": _processors_js__WEBPACK_IMPORTED_MODULE_2__.AutoProcessor,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"openai/whisper-tiny.en\",\n            \"model\": \"Xenova/whisper-tiny.en\",\n        },\n        \"type\": \"multimodal\",\n    },\n    \"text-to-audio\": {\n        \"tokenizer\": _tokenizers_js__WEBPACK_IMPORTED_MODULE_0__.AutoTokenizer,\n        \"pipeline\": TextToAudioPipeline,\n        \"model\": [_models_js__WEBPACK_IMPORTED_MODULE_1__.AutoModelForTextToWaveform, _models_js__WEBPACK_IMPORTED_MODULE_1__.AutoModelForTextToSpectrogram],\n        \"processor\": [_processors_js__WEBPACK_IMPORTED_MODULE_2__.AutoProcessor, /* Some don't use a processor */ null],\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"microsoft/speecht5_tts\",\n            \"model\": \"Xenova/speecht5_tts\",\n        },\n        \"type\": \"text\",\n    },\n    \"image-to-text\": {\n        \"tokenizer\": _tokenizers_js__WEBPACK_IMPORTED_MODULE_0__.AutoTokenizer,\n        \"pipeline\": ImageToTextPipeline,\n        \"model\": _models_js__WEBPACK_IMPORTED_MODULE_1__.AutoModelForVision2Seq,\n        \"processor\": _processors_js__WEBPACK_IMPORTED_MODULE_2__.AutoProcessor,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"nlpconnect/vit-gpt2-image-captioning\",\n            \"model\": \"Xenova/vit-gpt2-image-captioning\",\n        },\n        \"type\": \"multimodal\",\n    },\n\n    \"image-classification\": {\n        // no tokenizer\n        \"pipeline\": ImageClassificationPipeline,\n        \"model\": _models_js__WEBPACK_IMPORTED_MODULE_1__.AutoModelForImageClassification,\n        \"processor\": _processors_js__WEBPACK_IMPORTED_MODULE_2__.AutoProcessor,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"google/vit-base-patch16-224\",\n            \"model\": \"Xenova/vit-base-patch16-224\",\n        },\n        \"type\": \"multimodal\",\n    },\n\n    \"image-segmentation\": {\n        // no tokenizer\n        \"pipeline\": ImageSegmentationPipeline,\n        \"model\": [_models_js__WEBPACK_IMPORTED_MODULE_1__.AutoModelForImageSegmentation, _models_js__WEBPACK_IMPORTED_MODULE_1__.AutoModelForSemanticSegmentation],\n        \"processor\": _processors_js__WEBPACK_IMPORTED_MODULE_2__.AutoProcessor,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"facebook/detr-resnet-50-panoptic\",\n            \"model\": \"Xenova/detr-resnet-50-panoptic\",\n        },\n        \"type\": \"multimodal\",\n    },\n\n    \"zero-shot-image-classification\": {\n        \"tokenizer\": _tokenizers_js__WEBPACK_IMPORTED_MODULE_0__.AutoTokenizer,\n        \"pipeline\": ZeroShotImageClassificationPipeline,\n        \"model\": _models_js__WEBPACK_IMPORTED_MODULE_1__.AutoModel,\n        \"processor\": _processors_js__WEBPACK_IMPORTED_MODULE_2__.AutoProcessor,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"openai/clip-vit-base-patch32\",\n            \"model\": \"Xenova/clip-vit-base-patch32\",\n        },\n        \"type\": \"multimodal\",\n    },\n\n    \"object-detection\": {\n        // no tokenizer\n        \"pipeline\": ObjectDetectionPipeline,\n        \"model\": _models_js__WEBPACK_IMPORTED_MODULE_1__.AutoModelForObjectDetection,\n        \"processor\": _processors_js__WEBPACK_IMPORTED_MODULE_2__.AutoProcessor,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"facebook/detr-resnet-50\",\n            \"model\": \"Xenova/detr-resnet-50\",\n        },\n        \"type\": \"multimodal\",\n    },\n    \"zero-shot-object-detection\": {\n        \"tokenizer\": _tokenizers_js__WEBPACK_IMPORTED_MODULE_0__.AutoTokenizer,\n        \"pipeline\": ZeroShotObjectDetectionPipeline,\n        \"model\": _models_js__WEBPACK_IMPORTED_MODULE_1__.AutoModelForZeroShotObjectDetection,\n        \"processor\": _processors_js__WEBPACK_IMPORTED_MODULE_2__.AutoProcessor,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"google/owlvit-base-patch32\",\n            \"model\": \"Xenova/owlvit-base-patch32\",\n        },\n        \"type\": \"multimodal\",\n    },\n    \"document-question-answering\": {\n        \"tokenizer\": _tokenizers_js__WEBPACK_IMPORTED_MODULE_0__.AutoTokenizer,\n        \"pipeline\": DocumentQuestionAnsweringPipeline,\n        \"model\": _models_js__WEBPACK_IMPORTED_MODULE_1__.AutoModelForDocumentQuestionAnswering,\n        \"processor\": _processors_js__WEBPACK_IMPORTED_MODULE_2__.AutoProcessor,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"naver-clova-ix/donut-base-finetuned-docvqa\",\n            \"model\": \"Xenova/donut-base-finetuned-docvqa\",\n        },\n        \"type\": \"multimodal\",\n    },\n    \"image-to-image\": {\n        // no tokenizer\n        \"pipeline\": ImageToImagePipeline,\n        \"model\": _models_js__WEBPACK_IMPORTED_MODULE_1__.AutoModelForImageToImage,\n        \"processor\": _processors_js__WEBPACK_IMPORTED_MODULE_2__.AutoProcessor,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"caidas/swin2SR-classical-sr-x2-64\",\n            \"model\": \"Xenova/swin2SR-classical-sr-x2-64\",\n        },\n        \"type\": \"image\",\n    },\n    \"depth-estimation\": {\n        // no tokenizer\n        \"pipeline\": DepthEstimationPipeline,\n        \"model\": _models_js__WEBPACK_IMPORTED_MODULE_1__.AutoModelForDepthEstimation,\n        \"processor\": _processors_js__WEBPACK_IMPORTED_MODULE_2__.AutoProcessor,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"Intel/dpt-large\",\n            \"model\": \"Xenova/dpt-large\",\n        },\n        \"type\": \"image\",\n    },\n\n    // This task serves as a useful interface for dealing with sentence-transformers (https://huggingface.co/sentence-transformers).\n    \"feature-extraction\": {\n        \"tokenizer\": _tokenizers_js__WEBPACK_IMPORTED_MODULE_0__.AutoTokenizer,\n        \"pipeline\": FeatureExtractionPipeline,\n        \"model\": _models_js__WEBPACK_IMPORTED_MODULE_1__.AutoModel,\n        \"default\": {\n            // TODO: replace with original\n            // \"model\": \"sentence-transformers/all-MiniLM-L6-v2\",\n            \"model\": \"Xenova/all-MiniLM-L6-v2\",\n        },\n        \"type\": \"text\",\n    },\n})\n\n\n// TODO: Add types for TASK_ALIASES\nconst TASK_ALIASES = Object.freeze({\n    \"sentiment-analysis\": \"text-classification\",\n    \"ner\": \"token-classification\",\n    // \"vqa\": \"visual-question-answering\", // TODO: Add\n    \"asr\": \"automatic-speech-recognition\",\n    \"text-to-speech\": \"text-to-audio\",\n\n    // Add for backwards compatibility\n    \"embeddings\": \"feature-extraction\",\n});\n\n/**\n * @typedef {keyof typeof SUPPORTED_TASKS} TaskType\n * @typedef {keyof typeof TASK_ALIASES} AliasType\n * @typedef {TaskType | AliasType} PipelineType All possible pipeline types.\n * @typedef {{[K in TaskType]: InstanceType<typeof SUPPORTED_TASKS[K][\"pipeline\"]>}} SupportedTasks A mapping of pipeline names to their corresponding pipeline classes.\n * @typedef {{[K in AliasType]: InstanceType<typeof SUPPORTED_TASKS[TASK_ALIASES[K]][\"pipeline\"]>}} AliasTasks A mapping from pipeline aliases to their corresponding pipeline classes.\n * @typedef {SupportedTasks & AliasTasks} AllTasks A mapping from all pipeline names and aliases to their corresponding pipeline classes.\n */\n\n/**\n * Utility factory method to build a `Pipeline` object.\n * \n * @template {PipelineType} T The type of pipeline to return.\n * @param {T} task The task defining which pipeline will be returned. Currently accepted tasks are:\n *  - `\"audio-classification\"`: will return a `AudioClassificationPipeline`.\n *  - `\"automatic-speech-recognition\"`: will return a `AutomaticSpeechRecognitionPipeline`.\n *  - `\"depth-estimation\"`: will return a `DepthEstimationPipeline`.\n *  - `\"document-question-answering\"`: will return a `DocumentQuestionAnsweringPipeline`.\n *  - `\"feature-extraction\"`: will return a `FeatureExtractionPipeline`.\n *  - `\"fill-mask\"`: will return a `FillMaskPipeline`.\n *  - `\"image-classification\"`: will return a `ImageClassificationPipeline`.\n *  - `\"image-segmentation\"`: will return a `ImageSegmentationPipeline`.\n *  - `\"image-to-text\"`: will return a `ImageToTextPipeline`.\n *  - `\"object-detection\"`: will return a `ObjectDetectionPipeline`.\n *  - `\"question-answering\"`: will return a `QuestionAnsweringPipeline`.\n *  - `\"summarization\"`: will return a `SummarizationPipeline`.\n *  - `\"text2text-generation\"`: will return a `Text2TextGenerationPipeline`.\n *  - `\"text-classification\"` (alias \"sentiment-analysis\" available): will return a `TextClassificationPipeline`.\n *  - `\"text-generation\"`: will return a `TextGenerationPipeline`.\n *  - `\"token-classification\"` (alias \"ner\" available): will return a `TokenClassificationPipeline`.\n *  - `\"translation\"`: will return a `TranslationPipeline`.\n *  - `\"translation_xx_to_yy\"`: will return a `TranslationPipeline`.\n *  - `\"zero-shot-classification\"`: will return a `ZeroShotClassificationPipeline`.\n *  - `\"zero-shot-audio-classification\"`: will return a `ZeroShotAudioClassificationPipeline`.\n *  - `\"zero-shot-image-classification\"`: will return a `ZeroShotImageClassificationPipeline`.\n *  - `\"zero-shot-object-detection\"`: will return a `ZeroShotObjectDetectionPipeline`.\n * @param {string} [model=null] The name of the pre-trained model to use. If not specified, the default model for the task will be used.\n * @param {import('./utils/hub.js').PretrainedOptions} [options] Optional parameters for the pipeline.\n * @returns {Promise<AllTasks[T]>} A Pipeline object for the specified task.\n * @throws {Error} If an unsupported pipeline is requested.\n */\nasync function pipeline(\n    task,\n    model = null,\n    {\n        quantized = true,\n        progress_callback = null,\n        config = null,\n        cache_dir = null,\n        local_files_only = false,\n        revision = 'main',\n    } = {}\n) {\n    // Helper method to construct pipeline\n\n    // Apply aliases\n    // @ts-ignore\n    task = TASK_ALIASES[task] ?? task;\n\n    // Get pipeline info\n    const pipelineInfo = SUPPORTED_TASKS[task.split('_', 1)[0]];\n    if (!pipelineInfo) {\n        throw Error(`Unsupported pipeline: ${task}. Must be one of [${Object.keys(SUPPORTED_TASKS)}]`)\n    }\n\n    // Use model if specified, otherwise, use default\n    if (!model) {\n        model = pipelineInfo.default.model\n        console.log(`No model specified. Using default model: \"${model}\".`);\n    }\n\n    const pretrainedOptions = {\n        quantized,\n        progress_callback,\n        config,\n        cache_dir,\n        local_files_only,\n        revision,\n    }\n\n    const classes = new Map([\n        ['tokenizer', pipelineInfo.tokenizer],\n        ['model', pipelineInfo.model],\n        ['processor', pipelineInfo.processor],\n    ]);\n\n    // Load model, tokenizer, and processor (if they exist)\n    const results = await loadItems(classes, model, pretrainedOptions);\n    results.task = task;\n\n    (0,_utils_core_js__WEBPACK_IMPORTED_MODULE_3__.dispatchCallback)(progress_callback, {\n        'status': 'ready',\n        'task': task,\n        'model': model,\n    });\n\n    const pipelineClass = pipelineInfo.pipeline;\n    return new pipelineClass(results);\n}\n\n\n/**\n * Helper function to get applicable model, tokenizer, or processor classes for a given model.\n * @param {Map<string, any>} mapping The mapping of names to classes, arrays of classes, or null.\n * @param {string} model The name of the model to load.\n * @param {import('./utils/hub.js').PretrainedOptions} pretrainedOptions The options to pass to the `from_pretrained` method.\n * @private\n */\nasync function loadItems(mapping, model, pretrainedOptions) {\n\n    const result = Object.create(null);\n\n    /**@type {Promise[]} */\n    const promises = [];\n    for (let [name, cls] of mapping.entries()) {\n        if (!cls) continue;\n\n        /**@type {Promise} */\n        let promise;\n        if (Array.isArray(cls)) {\n            promise = new Promise(async (resolve, reject) => {\n                let e;\n                for (let c of cls) {\n                    if (c === null) {\n                        // If null, we resolve it immediately, meaning the relevant\n                        // class was not found, but it is optional.\n                        resolve(null);\n                        return;\n                    }\n                    try {\n                        resolve(await c.from_pretrained(model, pretrainedOptions));\n                        return;\n                    } catch (err) {\n                        e = err;\n                    }\n                }\n                reject(e);\n            })\n        } else {\n            promise = cls.from_pretrained(model, pretrainedOptions);\n        }\n\n        result[name] = promise;\n        promises.push(promise);\n    }\n\n    // Wait for all promises to resolve (in parallel)\n    await Promise.all(promises);\n\n    // Then assign to result\n    for (let [name, promise] of Object.entries(result)) {\n        result[name] = await promise;\n    }\n\n    return result;\n}\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@xenova/transformers/src/pipelines.js?");

/***/ }),

/***/ "./node_modules/@xenova/transformers/src/processors.js":
/*!*************************************************************!*\
  !*** ./node_modules/@xenova/transformers/src/processors.js ***!
  \*************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   ASTFeatureExtractor: () => (/* binding */ ASTFeatureExtractor),\n/* harmony export */   AutoProcessor: () => (/* binding */ AutoProcessor),\n/* harmony export */   BeitFeatureExtractor: () => (/* binding */ BeitFeatureExtractor),\n/* harmony export */   BitImageProcessor: () => (/* binding */ BitImageProcessor),\n/* harmony export */   CLIPFeatureExtractor: () => (/* binding */ CLIPFeatureExtractor),\n/* harmony export */   ChineseCLIPFeatureExtractor: () => (/* binding */ ChineseCLIPFeatureExtractor),\n/* harmony export */   ClapFeatureExtractor: () => (/* binding */ ClapFeatureExtractor),\n/* harmony export */   ConvNextFeatureExtractor: () => (/* binding */ ConvNextFeatureExtractor),\n/* harmony export */   ConvNextImageProcessor: () => (/* binding */ ConvNextImageProcessor),\n/* harmony export */   DPTFeatureExtractor: () => (/* binding */ DPTFeatureExtractor),\n/* harmony export */   DPTImageProcessor: () => (/* binding */ DPTImageProcessor),\n/* harmony export */   DeiTFeatureExtractor: () => (/* binding */ DeiTFeatureExtractor),\n/* harmony export */   DetrFeatureExtractor: () => (/* binding */ DetrFeatureExtractor),\n/* harmony export */   DonutFeatureExtractor: () => (/* binding */ DonutFeatureExtractor),\n/* harmony export */   FeatureExtractor: () => (/* binding */ FeatureExtractor),\n/* harmony export */   GLPNFeatureExtractor: () => (/* binding */ GLPNFeatureExtractor),\n/* harmony export */   ImageFeatureExtractor: () => (/* binding */ ImageFeatureExtractor),\n/* harmony export */   MobileViTFeatureExtractor: () => (/* binding */ MobileViTFeatureExtractor),\n/* harmony export */   NougatImageProcessor: () => (/* binding */ NougatImageProcessor),\n/* harmony export */   OwlViTFeatureExtractor: () => (/* binding */ OwlViTFeatureExtractor),\n/* harmony export */   OwlViTProcessor: () => (/* binding */ OwlViTProcessor),\n/* harmony export */   Owlv2ImageProcessor: () => (/* binding */ Owlv2ImageProcessor),\n/* harmony export */   Processor: () => (/* binding */ Processor),\n/* harmony export */   SamImageProcessor: () => (/* binding */ SamImageProcessor),\n/* harmony export */   SamProcessor: () => (/* binding */ SamProcessor),\n/* harmony export */   SeamlessM4TFeatureExtractor: () => (/* binding */ SeamlessM4TFeatureExtractor),\n/* harmony export */   SegformerFeatureExtractor: () => (/* binding */ SegformerFeatureExtractor),\n/* harmony export */   SiglipImageProcessor: () => (/* binding */ SiglipImageProcessor),\n/* harmony export */   SpeechT5FeatureExtractor: () => (/* binding */ SpeechT5FeatureExtractor),\n/* harmony export */   SpeechT5Processor: () => (/* binding */ SpeechT5Processor),\n/* harmony export */   Swin2SRImageProcessor: () => (/* binding */ Swin2SRImageProcessor),\n/* harmony export */   ViTFeatureExtractor: () => (/* binding */ ViTFeatureExtractor),\n/* harmony export */   ViTImageProcessor: () => (/* binding */ ViTImageProcessor),\n/* harmony export */   VitMatteImageProcessor: () => (/* binding */ VitMatteImageProcessor),\n/* harmony export */   Wav2Vec2FeatureExtractor: () => (/* binding */ Wav2Vec2FeatureExtractor),\n/* harmony export */   Wav2Vec2ProcessorWithLM: () => (/* binding */ Wav2Vec2ProcessorWithLM),\n/* harmony export */   WhisperFeatureExtractor: () => (/* binding */ WhisperFeatureExtractor),\n/* harmony export */   WhisperProcessor: () => (/* binding */ WhisperProcessor),\n/* harmony export */   YolosFeatureExtractor: () => (/* binding */ YolosFeatureExtractor)\n/* harmony export */ });\n/* harmony import */ var _utils_core_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./utils/core.js */ \"./node_modules/@xenova/transformers/src/utils/core.js\");\n/* harmony import */ var _utils_hub_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./utils/hub.js */ \"./node_modules/@xenova/transformers/src/utils/hub.js\");\n/* harmony import */ var _utils_maths_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./utils/maths.js */ \"./node_modules/@xenova/transformers/src/utils/maths.js\");\n/* harmony import */ var _utils_tensor_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./utils/tensor.js */ \"./node_modules/@xenova/transformers/src/utils/tensor.js\");\n/* harmony import */ var _utils_image_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./utils/image.js */ \"./node_modules/@xenova/transformers/src/utils/image.js\");\n/* harmony import */ var _utils_audio_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./utils/audio.js */ \"./node_modules/@xenova/transformers/src/utils/audio.js\");\n\n/**\n * @file Processors are used to prepare non-textual inputs (e.g., image or audio) for a model.\n * \n * **Example:** Using a `WhisperProcessor` to prepare an audio input for a model.\n * ```javascript\n * import { AutoProcessor, read_audio } from '@xenova/transformers';\n *\n * let processor = await AutoProcessor.from_pretrained('openai/whisper-tiny.en');\n * let audio = await read_audio('https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac', 16000);\n * let { input_features } = await processor(audio);\n * // Tensor {\n * //   data: Float32Array(240000) [0.4752984642982483, 0.5597258806228638, 0.56434166431427, ...],\n * //   dims: [1, 80, 3000],\n * //   type: 'float32',\n * //   size: 240000,\n * // }\n * ```\n * \n * @module processors\n */\n\n\n\n\n\n\n\n\n\n\n\n\n\n// Helper functions\n\n/**\n * Converts bounding boxes from center format to corners format.\n * \n * @param {number[]} arr The coordinate for the center of the box and its width, height dimensions (center_x, center_y, width, height)\n * @returns {number[]} The coodinates for the top-left and bottom-right corners of the box (top_left_x, top_left_y, bottom_right_x, bottom_right_y)\n */\nfunction center_to_corners_format([centerX, centerY, width, height]) {\n    return [\n        centerX - width / 2,\n        centerY - height / 2,\n        centerX + width / 2,\n        centerY + height / 2\n    ];\n}\n\n/**\n * Post-processes the outputs of the model (for object detection).\n * @param {Object} outputs The outputs of the model that must be post-processed\n * @param {Tensor} outputs.logits The logits\n * @param {Tensor} outputs.pred_boxes The predicted boxes.\n * @param {number} [threshold=0.5] The threshold to use for the scores.\n * @param {number[][]} [target_sizes=null] The sizes of the original images.\n * @param {boolean} [is_zero_shot=false] Whether zero-shot object detection was performed.\n * @return {Object[]} An array of objects containing the post-processed outputs.\n * @private\n */\nfunction post_process_object_detection(outputs, threshold = 0.5, target_sizes = null, is_zero_shot = false) {\n    const out_logits = outputs.logits;\n    const out_bbox = outputs.pred_boxes;\n    const [batch_size, num_boxes, num_classes] = out_logits.dims;\n\n    if (target_sizes !== null && target_sizes.length !== batch_size) {\n        throw Error(\"Make sure that you pass in as many target sizes as the batch dimension of the logits\")\n    }\n    let toReturn = [];\n    for (let i = 0; i < batch_size; ++i) {\n        let target_size = target_sizes !== null ? target_sizes[i] : null;\n        let info = {\n            boxes: [],\n            classes: [],\n            scores: []\n        }\n        let logits = out_logits[i];\n        let bbox = out_bbox[i];\n\n        for (let j = 0; j < num_boxes; ++j) {\n            let logit = logits[j];\n\n            let indices = [];\n            let probs;\n            if (is_zero_shot) {\n                // Get indices of classes with high enough probability\n                probs = logit.sigmoid().data;\n                for (let k = 0; k < probs.length; ++k) {\n                    if (probs[k] > threshold) {\n                        indices.push(k);\n                    }\n                }\n\n            } else {\n                // Get most probable class\n                let maxIndex = (0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_2__.max)(logit.data)[1];\n\n                if (maxIndex === num_classes - 1) {\n                    // This is the background class, skip it\n                    continue;\n                }\n                indices.push(maxIndex);\n\n                // Compute softmax over classes\n                probs = (0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_2__.softmax)(logit.data);\n            }\n\n            for (const index of indices) {\n\n                // Some class has a high enough probability\n                /** @type {number[]} */\n                let box = bbox[j].data;\n\n                // convert to [x0, y0, x1, y1] format\n                box = center_to_corners_format(box)\n                if (target_size !== null) {\n                    box = box.map((x, i) => x * target_size[(i + 1) % 2])\n                }\n\n                info.boxes.push(box);\n                info.classes.push(index);\n                info.scores.push(probs[index]);\n            }\n        }\n        toReturn.push(info);\n    }\n    return toReturn;\n}\n\n/**\n * Named tuple to indicate the order we are using is (height x width), even though\n * the Graphics industry standard is (width x height).\n * @typedef {[height: number, width: number]} HeightWidth\n */\n\n/**\n * Helper function to validate audio inputs.\n * @param {any} audio The audio data.\n * @param {string} feature_extractor The name of the feature extractor.\n * @private\n */\nfunction validate_audio_inputs(audio, feature_extractor) {\n    if (!(audio instanceof Float32Array || audio instanceof Float64Array)) {\n        throw new Error(\n            `${feature_extractor} expects input to be a Float32Array or a Float64Array, but got ${audio?.constructor?.name ?? typeof audio} instead.` +\n            `If using the feature extractor directly, remember to use \\`read_audio(url, sampling_rate)\\` to obtain the raw audio data of the file/url.`\n        )\n    }\n}\n\n/**\n * Helper function to constrain a value to be a multiple of a number.\n * @param {number} val The value to constrain.\n * @param {number} multiple The number to constrain to.\n * @param {number} [minVal=0] The minimum value to constrain to.\n * @param {number} [maxVal=null] The maximum value to constrain to.\n * @returns {number} The constrained value.\n * @private\n */\nfunction constraint_to_multiple_of(val, multiple, minVal = 0, maxVal = null) {\n    let x = Math.round(val / multiple) * multiple;\n\n    if (maxVal !== null && x > maxVal) {\n        x = Math.floor(val / multiple) * multiple;\n    }\n\n    if (x < minVal) {\n        x = Math.ceil(val / multiple) * multiple;\n    }\n\n    return x;\n}\n\n/**\n * Rounds the height and width down to the closest multiple of size_divisibility\n * @param {[number, number]} size The size of the image\n * @param {number} divisor The divisor to use.\n * @returns {[number, number]} The rounded size.\n */\nfunction enforce_size_divisibility([width, height], divisor) {\n    return [\n        Math.floor(width / divisor) * divisor,\n        Math.floor(height / divisor) * divisor\n    ];\n}\n\n\n/**\n * Base class for feature extractors.\n *\n * @extends Callable\n */\nclass FeatureExtractor extends _utils_core_js__WEBPACK_IMPORTED_MODULE_0__.Callable {\n    /**\n     * Constructs a new FeatureExtractor instance.\n     *\n     * @param {Object} config The configuration for the feature extractor.\n     */\n    constructor(config) {\n        super();\n        this.config = config\n    }\n}\n\n/**\n * @typedef {object} ImageFeatureExtractorResult\n * @property {Tensor} pixel_values The pixel values of the batched preprocessed images.\n * @property {HeightWidth[]} original_sizes Array of two-dimensional tuples like [[480, 640]].\n * @property {HeightWidth[]} reshaped_input_sizes Array of two-dimensional tuples like [[1000, 1330]].\n */\n\n/**\n * Feature extractor for image models.\n *\n * @extends FeatureExtractor\n */\nclass ImageFeatureExtractor extends FeatureExtractor {\n\n    /**\n     * Constructs a new ImageFeatureExtractor instance.\n     *\n     * @param {Object} config The configuration for the feature extractor.\n     * @param {number[]} config.image_mean The mean values for image normalization.\n     * @param {number[]} config.image_std The standard deviation values for image normalization.\n     * @param {boolean} config.do_rescale Whether to rescale the image pixel values to the [0,1] range.\n     * @param {number} config.rescale_factor The factor to use for rescaling the image pixel values.\n     * @param {boolean} config.do_normalize Whether to normalize the image pixel values.\n     * @param {boolean} config.do_resize Whether to resize the image.\n     * @param {number} config.resample What method to use for resampling.\n     * @param {number|Object} config.size The size to resize the image to.\n     */\n    constructor(config) {\n        super(config);\n\n        this.image_mean = this.config.image_mean ?? this.config.mean;\n        this.image_std = this.config.image_std ?? this.config.std;\n\n        this.resample = this.config.resample ?? 2; // 2 => bilinear\n        this.do_rescale = this.config.do_rescale ?? true;\n        this.rescale_factor = this.config.rescale_factor ?? (1 / 255);\n        this.do_normalize = this.config.do_normalize;\n\n        this.do_resize = this.config.do_resize;\n        this.do_thumbnail = this.config.do_thumbnail;\n        this.size = this.config.size;\n        this.size_divisibility = this.config.size_divisibility ?? this.config.size_divisor;\n\n        this.do_center_crop = this.config.do_center_crop;\n        this.crop_size = this.config.crop_size;\n        this.do_convert_rgb = this.config.do_convert_rgb ?? true;\n        this.do_crop_margin = this.config.do_crop_margin;\n\n        this.pad_size = this.config.pad_size;\n        this.do_pad = this.config.do_pad;\n\n        if (this.do_pad && !this.pad_size && this.size && this.size.width !== undefined && this.size.height !== undefined) {\n            // Should pad, but no pad size specified\n            // We infer the pad size from the resize size\n            this.pad_size = this.size\n        }\n    }\n\n    /**\n     * Resize the image to make a thumbnail. The image is resized so that no dimension is larger than any\n     * corresponding dimension of the specified size.\n     * @param {RawImage} image The image to be resized.\n     * @param {{height:number, width:number}} size The size `{\"height\": h, \"width\": w}` to resize the image to.\n     * @param {string | 0 | 1 | 2 | 3 | 4 | 5} [resample=2] The resampling filter to use.\n     * @returns {Promise<RawImage>} The resized image.\n     */\n    async thumbnail(image, size, resample = 2) {\n        const input_height = image.height;\n        const input_width = image.width;\n\n        const output_height = size.height;\n        const output_width = size.width;\n\n        // We always resize to the smallest of either the input or output size.\n        let height = Math.min(input_height, output_height)\n        let width = Math.min(input_width, output_width)\n\n        if (height === input_height && width === input_width) {\n            return image;\n        }\n        if (input_height > input_width) {\n            width = Math.floor(input_width * height / input_height);\n        } else if (input_width > input_height) {\n            height = Math.floor(input_height * width / input_width);\n        }\n        return await image.resize(width, height, { resample });\n    }\n\n\n    /**\n     * Crops the margin of the image. Gray pixels are considered margin (i.e., pixels with a value below the threshold).\n     * @param {RawImage} image The image to be cropped.\n     * @param {number} gray_threshold Value below which pixels are considered to be gray.\n     * @returns {Promise<RawImage>} The cropped image.\n     */\n    async crop_margin(image, gray_threshold = 200) {\n\n        const gray_image = image.clone().grayscale();\n\n        const minValue = (0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_2__.min)(gray_image.data)[0];\n        const maxValue = (0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_2__.max)(gray_image.data)[0];\n        const diff = maxValue - minValue;\n\n        if (diff === 0) {\n            return image;\n        }\n\n        const threshold = gray_threshold / 255;\n\n        let x_min = gray_image.width, y_min = gray_image.height, x_max = 0, y_max = 0;\n        for (let j = 0; j < gray_image.height; ++j) {\n            const row = j * gray_image.width;\n            for (let i = 0; i < gray_image.width; ++i) {\n                if ((gray_image.data[row + i] - minValue) / diff < threshold) {\n                    // We have a non-zero pixel, so we update the min/max values accordingly\n                    x_min = Math.min(x_min, i);\n                    y_min = Math.min(y_min, j);\n                    x_max = Math.max(x_max, i);\n                    y_max = Math.max(y_max, j);\n                }\n            }\n        }\n\n        image = await image.crop([x_min, y_min, x_max, y_max]);\n        return image;\n    }\n\n    /**\n     * Pad the image by a certain amount.\n     * @param {Float32Array} pixelData The pixel data to pad.\n     * @param {number[]} imgDims The dimensions of the image.\n     * @param {{width:number; height:number}|number} padSize The dimensions of the padded image.\n     * @param {Object} options The options for padding.\n     * @param {'constant'|'symmetric'} [options.mode='constant'] The type of padding to add.\n     * @param {boolean} [options.center=false] Whether to center the image.\n     * @param {number} [options.constant_values=0] The constant value to use for padding.\n     * @returns {[Float32Array, number[]]} The padded pixel data and image dimensions.\n     */\n    pad_image(pixelData, imgDims, padSize, {\n        mode = 'constant',\n        center = false,\n        constant_values = 0,\n    } = {}) {\n        const [imageWidth, imageHeight, imageChannels] = imgDims;\n\n        let paddedImageWidth, paddedImageHeight;\n        if (typeof padSize === 'number') {\n            paddedImageWidth = padSize;\n            paddedImageHeight = padSize;\n        } else {\n            paddedImageWidth = padSize.width;\n            paddedImageHeight = padSize.height;\n        }\n\n        // Only add padding if there is a difference in size\n        if (paddedImageWidth !== imageWidth || paddedImageHeight !== imageHeight) {\n            const paddedPixelData = new Float32Array(paddedImageWidth * paddedImageHeight * imageChannels);\n            if (Array.isArray(constant_values)) {\n                // Fill with constant values, cycling through the array\n                for (let i = 0; i < paddedPixelData.length; ++i) {\n                    paddedPixelData[i] = constant_values[i % imageChannels];\n                }\n            } else if (constant_values !== 0) {\n                paddedPixelData.fill(constant_values);\n            }\n\n            const [left, top] = center\n                ? [Math.floor((paddedImageWidth - imageWidth) / 2), Math.floor((paddedImageHeight - imageHeight) / 2)]\n                : [0, 0];\n\n            // Copy the original image into the padded image\n            for (let i = 0; i < imageHeight; ++i) {\n                const a = (i + top) * paddedImageWidth;\n                const b = i * imageWidth;\n                for (let j = 0; j < imageWidth; ++j) {\n                    const c = (a + j + left) * imageChannels;\n                    const d = (b + j) * imageChannels;\n                    for (let k = 0; k < imageChannels; ++k) {\n                        paddedPixelData[c + k] = pixelData[d + k];\n                    }\n                }\n            }\n\n            if (mode === 'symmetric') {\n                if (center) {\n                    throw new Error('`center` padding is not supported when `mode` is set to `symmetric`.');\n                    // TODO: Implement this\n                }\n                const h1 = imageHeight - 1;\n                const w1 = imageWidth - 1;\n                for (let i = 0; i < paddedImageHeight; ++i) {\n                    const a = i * paddedImageWidth;\n                    const b = (0,_utils_core_js__WEBPACK_IMPORTED_MODULE_0__.calculateReflectOffset)(i, h1) * imageWidth;\n\n                    for (let j = 0; j < paddedImageWidth; ++j) {\n                        if (i < imageHeight && j < imageWidth) continue; // Do not overwrite original image\n                        const c = (a + j) * imageChannels;\n                        const d = (b + (0,_utils_core_js__WEBPACK_IMPORTED_MODULE_0__.calculateReflectOffset)(j, w1)) * imageChannels;\n\n                        // Copy channel-wise\n                        for (let k = 0; k < imageChannels; ++k) {\n                            paddedPixelData[c + k] = pixelData[d + k];\n                        }\n                    }\n                }\n            }\n\n\n            // Update pixel data and image dimensions\n            pixelData = paddedPixelData;\n            imgDims = [paddedImageHeight, paddedImageWidth, imageChannels]\n        }\n        return [pixelData, imgDims];\n    }\n\n    /**\n     * Rescale the image' pixel values by `this.rescale_factor`.\n     * @param {Float32Array} pixelData The pixel data to rescale.\n     * @returns {void}\n     */\n    rescale(pixelData) {\n        for (let i = 0; i < pixelData.length; ++i) {\n            pixelData[i] = this.rescale_factor * pixelData[i];\n        }\n    }\n\n    /**\n     * Find the target (width, height) dimension of the output image after\n     * resizing given the input image and the desired size.\n     * @param {RawImage} image The image to resize.\n     * @param {any} size The size to use for resizing the image. \n     * @returns {[number, number]} The target (width, height) dimension of the output image after resizing.\n     */\n    get_resize_output_image_size(image, size) {\n        // `size` comes in many forms, so we need to handle them all here:\n        // 1. `size` is an integer, in which case we resize the image to be a square \n\n        const [srcWidth, srcHeight] = image.size;\n\n        let shortest_edge;\n        let longest_edge;\n\n        if (this.do_thumbnail) {\n            // NOTE: custom logic for `Donut` models\n            const { height, width } = size;\n            shortest_edge = Math.min(height, width)\n        }\n        // Support both formats for backwards compatibility\n        else if (Number.isInteger(size)) {\n            shortest_edge = size;\n            longest_edge = this.config.max_size ?? shortest_edge;\n\n        } else if (size !== undefined) {\n            // Extract known properties from `size`\n            shortest_edge = size.shortest_edge;\n            longest_edge = size.longest_edge;\n        }\n\n        // If `longest_edge` and `shortest_edge` are set, maintain aspect ratio and resize to `shortest_edge`\n        // while keeping the largest dimension <= `longest_edge`\n        if (shortest_edge !== undefined || longest_edge !== undefined) {\n            // http://opensourcehacker.com/2011/12/01/calculate-aspect-ratio-conserving-resize-for-images-in-javascript/\n            // Try resize so that shortest edge is `shortest_edge` (target)\n            const shortResizeFactor = shortest_edge === undefined\n                ? 1 // If `shortest_edge` is not set, don't upscale\n                : Math.max(shortest_edge / srcWidth, shortest_edge / srcHeight);\n\n            const newWidth = srcWidth * shortResizeFactor;\n            const newHeight = srcHeight * shortResizeFactor;\n\n            // The new width and height might be greater than `longest_edge`, so\n            // we downscale again to ensure the largest dimension is `longest_edge` \n            const longResizeFactor = longest_edge === undefined\n                ? 1 // If `longest_edge` is not set, don't downscale\n                : Math.min(longest_edge / newWidth, longest_edge / newHeight);\n\n            // To avoid certain floating point precision issues, we round to 2 decimal places\n            let finalWidth = Math.floor(Number((newWidth * longResizeFactor).toFixed(2)));\n            let finalHeight = Math.floor(Number((newHeight * longResizeFactor).toFixed(2)));\n\n            if (this.size_divisibility !== undefined) {\n                [finalWidth, finalHeight] = enforce_size_divisibility([finalWidth, finalHeight], this.size_divisibility)\n            }\n            return [finalWidth, finalHeight];\n\n        } else if (size !== undefined && size.width !== undefined && size.height !== undefined) {\n            // If `width` and `height` are set, resize to those dimensions\n\n            let newWidth = size.width;\n            let newHeight = size.height;\n\n            // Custom for DPT models\n            if (this.config.keep_aspect_ratio && this.config.ensure_multiple_of) {\n\n                // determine new height and width\n                let scale_height = size.height / srcHeight;\n                let scale_width = size.width / srcWidth;\n\n                // scale as little as possible\n                if (Math.abs(1 - scale_width) < Math.abs(1 - scale_height)) {\n                    // fit width\n                    scale_height = scale_width;\n                } else {\n                    // fit height\n                    scale_width = scale_height;\n                }\n\n                newHeight = constraint_to_multiple_of(scale_height * srcHeight, this.config.ensure_multiple_of);\n                newWidth = constraint_to_multiple_of(scale_width * srcWidth, this.config.ensure_multiple_of);\n            }\n\n            return [newWidth, newHeight];\n\n        } else if (this.size_divisibility !== undefined) {\n            return enforce_size_divisibility([srcWidth, srcHeight], this.size_divisibility);\n        } else {\n            throw new Error(`Could not resize image due to unsupported \\`this.size\\` option in config: ${JSON.stringify(size)}`);\n        }\n    }\n\n    /**\n     * Resizes the image.\n     * @param {RawImage} image The image to resize.\n     * @returns {Promise<RawImage>} The resized image.\n     */\n    async resize(image) {\n        const [newWidth, newHeight] = this.get_resize_output_image_size(image, this.size);\n        return await image.resize(newWidth, newHeight, {\n            resample: this.resample,\n        });\n    }\n\n    /**\n     * @typedef {object} PreprocessedImage\n     * @property {HeightWidth} original_size The original size of the image.\n     * @property {HeightWidth} reshaped_input_size The reshaped input size of the image.\n     * @property {Tensor} pixel_values The pixel values of the preprocessed image.\n     */\n\n    /**\n     * Preprocesses the given image.\n     *\n     * @param {RawImage} image The image to preprocess.\n     * @param {Object} overrides The overrides for the preprocessing options.\n     * @returns {Promise<PreprocessedImage>} The preprocessed image.\n     */\n    async preprocess(image, {\n        do_normalize = null,\n        do_pad = null,\n        do_convert_rgb = null,\n        do_convert_grayscale = null,\n    } = {}) {\n        if (this.do_crop_margin) {\n            // NOTE: Specific to nougat processors. This is done before resizing,\n            // and can be interpreted as a pre-preprocessing step.\n            image = await this.crop_margin(image);\n        }\n\n        const [srcWidth, srcHeight] = image.size; // original image size\n\n        // Convert image to RGB if specified in config.\n        if (do_convert_rgb ?? this.do_convert_rgb) {\n            image = image.rgb();\n        } else if (do_convert_grayscale) {\n            image = image.grayscale();\n        }\n\n        // TODO:\n        // For efficiency reasons, it might be best to merge the resize and center crop operations into one.\n\n        // Resize all images\n        if (this.do_resize) {\n            image = await this.resize(image);\n        }\n\n        // Resize the image using thumbnail method.\n        if (this.do_thumbnail) {\n            image = await this.thumbnail(image, this.size, this.resample);\n        }\n\n        if (this.do_center_crop) {\n\n            let crop_width;\n            let crop_height;\n            if (Number.isInteger(this.crop_size)) {\n                crop_width = this.crop_size;\n                crop_height = this.crop_size;\n            } else {\n                crop_width = this.crop_size.width;\n                crop_height = this.crop_size.height;\n            }\n\n            image = await image.center_crop(crop_width, crop_height);\n        }\n\n        /** @type {HeightWidth} */\n        const reshaped_input_size = [image.height, image.width];\n\n        let pixelData = Float32Array.from(image.data);\n        let imgDims = [image.height, image.width, image.channels];\n\n        if (this.do_rescale) {\n            this.rescale(pixelData);\n        }\n\n        if (do_normalize ?? this.do_normalize) {\n            let image_mean = this.image_mean;\n            if (!Array.isArray(this.image_mean)) {\n                image_mean = new Array(image.channels).fill(image_mean);\n            }\n\n            let image_std = this.image_std;\n            if (!Array.isArray(this.image_std)) {\n                image_std = new Array(image.channels).fill(image_mean);\n            }\n\n            if (image_mean.length !== image.channels || image_std.length !== image.channels) {\n                throw new Error(`When set to arrays, the length of \\`image_mean\\` (${image_mean.length}) and \\`image_std\\` (${image_std.length}) must match the number of channels in the image (${image.channels}).`);\n            }\n\n            for (let i = 0; i < pixelData.length; i += image.channels) {\n                for (let j = 0; j < image.channels; ++j) {\n                    pixelData[i + j] = (pixelData[i + j] - this.image_mean[j]) / this.image_std[j];\n                }\n            }\n        }\n\n        // do padding after rescaling/normalizing\n        if (do_pad ?? (this.do_pad && this.pad_size)) {\n            const padded = this.pad_image(pixelData, [image.width, image.height, image.channels], this.pad_size);\n            [pixelData, imgDims] = padded; // Update pixel data and image dimensions\n        }\n\n        // Create HWC tensor\n        const img = new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_3__.Tensor('float32', pixelData, imgDims);\n\n        // convert to channel dimension format:\n        const transposed = (0,_utils_tensor_js__WEBPACK_IMPORTED_MODULE_3__.transpose)(img, [2, 0, 1]); // hwc -> chw\n\n        return {\n            original_size: [srcHeight, srcWidth],\n            reshaped_input_size: reshaped_input_size,\n            pixel_values: transposed,\n        }\n    }\n\n    /**\n     * Calls the feature extraction process on an array of images,\n     * preprocesses each image, and concatenates the resulting\n     * features into a single Tensor.\n     * @param {RawImage[]} images The image(s) to extract features from.\n     * @param {...any} args Additional arguments.\n     * @returns {Promise<ImageFeatureExtractorResult>} An object containing the concatenated pixel values (and other metadata) of the preprocessed images.\n     */\n    async _call(images, ...args) {\n        if (!Array.isArray(images)) {\n            images = [images];\n        }\n        /** @type {PreprocessedImage[]} */\n        const imageData = await Promise.all(images.map(x => this.preprocess(x)));\n\n        // Stack pixel values\n        const pixel_values = (0,_utils_tensor_js__WEBPACK_IMPORTED_MODULE_3__.stack)(imageData.map(x => x.pixel_values), 0);\n\n        return {\n            pixel_values: pixel_values,\n\n            // Original sizes of images\n            original_sizes: imageData.map(x => x.original_size),\n\n            // Reshaped sizes of images, before padding or cropping\n            reshaped_input_sizes: imageData.map(x => x.reshaped_input_size),\n        }\n    }\n\n}\n\nclass SegformerFeatureExtractor extends ImageFeatureExtractor {\n\n    /**\n     * Converts the output of `SegformerForSemanticSegmentation` into semantic segmentation maps.\n     * @param {*} outputs Raw outputs of the model.\n     * @param {number[][]} [target_sizes=null] List of tuples corresponding to the requested final size\n     * (height, width) of each prediction. If unset, predictions will not be resized.\n     * @returns {{segmentation: Tensor; labels: number[]}[]} The semantic segmentation maps.\n     */\n    post_process_semantic_segmentation(outputs, target_sizes = null) {\n\n        const logits = outputs.logits;\n        const batch_size = logits.dims[0];\n\n        if (target_sizes !== null && target_sizes.length !== batch_size) {\n            throw Error(\"Make sure that you pass in as many target sizes as the batch dimension of the logits\")\n        }\n\n        const toReturn = [];\n        for (let i = 0; i < batch_size; ++i) {\n            const target_size = target_sizes !== null ? target_sizes[i] : null;\n\n            let data = logits[i];\n\n            // 1. If target_size is not null, we need to resize the masks to the target size\n            if (target_size !== null) {\n                // resize the masks to the target size\n                data = (0,_utils_tensor_js__WEBPACK_IMPORTED_MODULE_3__.interpolate)(data, target_size, 'bilinear', false);\n            }\n            const [height, width] = target_size ?? data.dims.slice(-2);\n\n            const segmentation = new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_3__.Tensor(\n                'int32',\n                new Int32Array(height * width),\n                [height, width]\n            );\n\n            // Buffer to store current largest value\n            const buffer = data[0].data;\n            for (let j = 1; j < data.dims[0]; ++j) {\n                const row = data[j].data;\n                for (let k = 0; k < row.length; ++k) {\n                    if (row[k] > buffer[k]) {\n                        buffer[k] = row[k];\n                        segmentation.data[k] = j;\n                    }\n                }\n            }\n\n            // Store which objects have labels\n            // This is much more efficient that creating a set of the final values\n            const hasLabel = new Array(data.dims[0]);\n            const out = segmentation.data;\n            for (let j = 0; j < out.length; ++j) {\n                const index = out[j];\n                hasLabel[index] = index;\n            }\n            /** @type {number[]} The unique list of labels that were detected */\n            const labels = hasLabel.filter(x => x !== undefined);\n\n            toReturn.push({ segmentation, labels });\n        }\n        return toReturn;\n    }\n}\nclass DPTImageProcessor extends ImageFeatureExtractor { }\nclass BitImageProcessor extends ImageFeatureExtractor { }\nclass DPTFeatureExtractor extends ImageFeatureExtractor { }\nclass GLPNFeatureExtractor extends ImageFeatureExtractor { }\nclass CLIPFeatureExtractor extends ImageFeatureExtractor { }\nclass ChineseCLIPFeatureExtractor extends ImageFeatureExtractor { }\nclass SiglipImageProcessor extends ImageFeatureExtractor { }\nclass ConvNextFeatureExtractor extends ImageFeatureExtractor {\n    constructor(config) {\n        super(config);\n\n        /**\n         * Percentage of the image to crop. Only has an effect if this.size < 384.\n         */\n        this.crop_pct = this.config.crop_pct ?? (224 / 256);\n    }\n\n    async resize(image) {\n        const shortest_edge = this.size?.shortest_edge;\n        if (shortest_edge === undefined) {\n            throw new Error(`Size dictionary must contain 'shortest_edge' key.`);\n        }\n\n        if (shortest_edge < 384) {\n            // maintain same ratio, resizing shortest edge to shortest_edge/crop_pct\n            const resize_shortest_edge = Math.floor(shortest_edge / this.crop_pct);\n\n            const [newWidth, newHeight] = this.get_resize_output_image_size(image, {\n                shortest_edge: resize_shortest_edge,\n            });\n\n            image = await image.resize(newWidth, newHeight, {\n                resample: this.resample,\n            });\n\n            // then crop to (shortest_edge, shortest_edge)\n            image = await image.center_crop(shortest_edge, shortest_edge);\n        } else {\n            // warping (no cropping) when evaluated at 384 or larger\n            image = await image.resize(shortest_edge, shortest_edge, {\n                resample: this.resample,\n            });\n        }\n\n        return image;\n    }\n}\nclass ConvNextImageProcessor extends ConvNextFeatureExtractor { }  // NOTE extends ConvNextFeatureExtractor\nclass ViTFeatureExtractor extends ImageFeatureExtractor { }\nclass ViTImageProcessor extends ImageFeatureExtractor { }\n\nclass MobileViTFeatureExtractor extends ImageFeatureExtractor { }\nclass OwlViTFeatureExtractor extends ImageFeatureExtractor {\n    /** @type {post_process_object_detection} */\n    post_process_object_detection(...args) {\n        return post_process_object_detection(...args);\n    }\n}\nclass Owlv2ImageProcessor extends OwlViTFeatureExtractor { } // NOTE extends OwlViTFeatureExtractor\n\nclass DeiTFeatureExtractor extends ImageFeatureExtractor { }\nclass BeitFeatureExtractor extends ImageFeatureExtractor { }\nclass DonutFeatureExtractor extends ImageFeatureExtractor {\n    pad_image(pixelData, imgDims, padSize, options = {}) {\n        const [imageWidth, imageHeight, imageChannels] = imgDims;\n\n        let image_mean = this.image_mean;\n        if (!Array.isArray(this.image_mean)) {\n            image_mean = new Array(imageChannels).fill(image_mean);\n        }\n\n        let image_std = this.image_std;\n        if (!Array.isArray(image_std)) {\n            image_std = new Array(imageChannels).fill(image_mean);\n        }\n\n        const constant_values = image_mean.map((x, i) => - x / this.image_std[i]);\n\n        return super.pad_image(pixelData, imgDims, padSize, {\n            center: true,\n\n            // Since normalization is done after padding, we need to use certain constant values to ensure the same behaviour is observed.\n            // For more information, see https://github.com/huggingface/transformers/blob/main/src/transformers/models/donut/image_processing_donut.py#L433-L451\n            constant_values: constant_values,\n            ...options,\n        });\n    }\n}\nclass NougatImageProcessor extends DonutFeatureExtractor { } // NOTE extends DonutFeatureExtractor\n\n/**\n * @typedef {object} DetrFeatureExtractorResultProps\n * @property {Tensor} pixel_mask\n * @typedef {ImageFeatureExtractorResult & DetrFeatureExtractorResultProps} DetrFeatureExtractorResult\n */\n\n/**\n * Detr Feature Extractor.\n *\n * @extends ImageFeatureExtractor\n */\nclass DetrFeatureExtractor extends ImageFeatureExtractor {\n    /**\n     * Calls the feature extraction process on an array of images, preprocesses\n     * each image, and concatenates the resulting features into a single Tensor.\n     * @param {RawImage[]} images The image(s) to extract features from.\n     * @returns {Promise<DetrFeatureExtractorResult>} An object containing the concatenated pixel values of the preprocessed images.\n     */\n    async _call(images) {\n        const result = await super._call(images);\n\n        // TODO support differently-sized images, for now assume all images are the same size.\n        // TODO support different mask sizes (not just 64x64)\n        // Currently, just fill pixel mask with 1s\n        const maskSize = [result.pixel_values.dims[0], 64, 64];\n        const pixel_mask = new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_3__.Tensor(\n            'int64',\n            new BigInt64Array(maskSize.reduce((a, b) => a * b)).fill(1n),\n            maskSize\n        );\n\n        return { ...result, pixel_mask };\n    }\n\n    /**\n     * Post-processes the outputs of the model (for object detection).\n     * @param {Object} outputs The outputs of the model that must be post-processed\n     * @param {Tensor} outputs.logits The logits\n     * @param {Tensor} outputs.pred_boxes The predicted boxes.\n     * @return {Object[]} An array of objects containing the post-processed outputs.\n     */\n\n    /** @type {post_process_object_detection} */\n    post_process_object_detection(...args) {\n        return post_process_object_detection(...args);\n    }\n\n    /**\n     * Binarize the given masks using `object_mask_threshold`, it returns the associated values of `masks`, `scores` and `labels`.\n     * @param {Tensor} class_logits The class logits.\n     * @param {Tensor} mask_logits The mask logits.\n     * @param {number} object_mask_threshold A number between 0 and 1 used to binarize the masks.\n     * @param {number} num_labels The number of labels.\n     * @returns {[Tensor[], number[], number[]]} The binarized masks, the scores, and the labels.\n     */\n    remove_low_and_no_objects(class_logits, mask_logits, object_mask_threshold, num_labels) {\n\n        let mask_probs_item = [];\n        let pred_scores_item = [];\n        let pred_labels_item = [];\n\n        for (let j = 0; j < class_logits.dims[0]; ++j) {\n            let cls = class_logits[j];\n            let mask = mask_logits[j];\n\n            let pred_label = (0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_2__.max)(cls.data)[1];\n            if (pred_label === num_labels) {\n                // Is the background, so we ignore it\n                continue;\n            }\n\n            let scores = (0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_2__.softmax)(cls.data);\n            let pred_score = scores[pred_label];\n            if (pred_score > object_mask_threshold) {\n                mask_probs_item.push(mask);\n                pred_scores_item.push(pred_score);\n                pred_labels_item.push(pred_label);\n            }\n        }\n\n        return [mask_probs_item, pred_scores_item, pred_labels_item];\n\n    }\n\n    /**\n     * Checks whether the segment is valid or not.\n     * @param {Int32Array} mask_labels Labels for each pixel in the mask.\n     * @param {Tensor[]} mask_probs Probabilities for each pixel in the masks.\n     * @param {number} k The class id of the segment.\n     * @param {number} mask_threshold The mask threshold.\n     * @param {number} overlap_mask_area_threshold The overlap mask area threshold.\n     * @returns {[boolean, number[]]} Whether the segment is valid or not, and the indices of the valid labels.\n     */\n    check_segment_validity(\n        mask_labels,\n        mask_probs,\n        k,\n        mask_threshold = 0.5,\n        overlap_mask_area_threshold = 0.8\n    ) {\n        // mask_k is a 1D array of indices, indicating where the mask is equal to k\n        let mask_k = [];\n        let mask_k_area = 0;\n        let original_area = 0;\n\n        // Compute the area of all the stuff in query k\n        for (let i = 0; i < mask_labels.length; ++i) {\n            if (mask_labels[i] === k) {\n                mask_k.push(i);\n                ++mask_k_area;\n            }\n\n            if (mask_probs[k].data[i] >= mask_threshold) {\n                ++original_area;\n            }\n        }\n        let mask_exists = mask_k_area > 0 && original_area > 0;\n\n        // Eliminate disconnected tiny segments\n        if (mask_exists) {\n            // Perform additional check\n            let area_ratio = mask_k_area / original_area;\n            mask_exists = area_ratio > overlap_mask_area_threshold;\n        }\n\n        return [mask_exists, mask_k]\n    }\n\n    /**\n     * Computes the segments.\n     * @param {Tensor[]} mask_probs The mask probabilities.\n     * @param {number[]} pred_scores The predicted scores.\n     * @param {number[]} pred_labels The predicted labels.\n     * @param {number} mask_threshold The mask threshold.\n     * @param {number} overlap_mask_area_threshold The overlap mask area threshold.\n     * @param {Set<number>} label_ids_to_fuse The label ids to fuse.\n     * @param {number[]} target_size The target size of the image.\n     * @returns {[Tensor, Array<{id: number, label_id: number, score: number}>]} The computed segments.\n     */\n    compute_segments(\n        mask_probs,\n        pred_scores,\n        pred_labels,\n        mask_threshold,\n        overlap_mask_area_threshold,\n        label_ids_to_fuse = null,\n        target_size = null,\n    ) {\n        let [height, width] = target_size ?? mask_probs[0].dims;\n\n        let segmentation = new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_3__.Tensor(\n            'int32',\n            new Int32Array(height * width),\n            [height, width]\n        );\n        let segments = [];\n\n        // 1. If target_size is not null, we need to resize the masks to the target size\n        if (target_size !== null) {\n            // resize the masks to the target size\n            for (let i = 0; i < mask_probs.length; ++i) {\n                mask_probs[i] = (0,_utils_tensor_js__WEBPACK_IMPORTED_MODULE_3__.interpolate)(mask_probs[i], target_size, 'bilinear', false);\n            }\n        }\n\n        // 2. Weigh each mask by its prediction score\n        // NOTE: `mask_probs` is updated in-place\n        // \n        // Temporary storage for the best label/scores for each pixel ([height, width]):\n        let mask_labels = new Int32Array(mask_probs[0].data.length);\n        let bestScores = new Float32Array(mask_probs[0].data.length);\n\n        for (let i = 0; i < mask_probs.length; ++i) {\n            let score = pred_scores[i];\n\n            for (let j = 0; j < mask_probs[i].data.length; ++j) {\n                mask_probs[i].data[j] *= score\n                if (mask_probs[i].data[j] > bestScores[j]) {\n                    mask_labels[j] = i;\n                    bestScores[j] = mask_probs[i].data[j];\n                }\n            }\n        }\n\n        let current_segment_id = 0;\n\n        // let stuff_memory_list = {}\n        for (let k = 0; k < pred_labels.length; ++k) {\n            let pred_class = pred_labels[k];\n\n            // TODO add `should_fuse`\n            // let should_fuse = pred_class in label_ids_to_fuse\n\n            // Check if mask exists and large enough to be a segment\n            let [mask_exists, mask_k] = this.check_segment_validity(\n                mask_labels,\n                mask_probs,\n                k,\n                mask_threshold,\n                overlap_mask_area_threshold\n            )\n\n            if (!mask_exists) {\n                // Nothing to see here\n                continue;\n            }\n\n            // TODO\n            // if (pred_class in stuff_memory_list) {\n            //     current_segment_id = stuff_memory_list[pred_class]\n            // } else {\n            //     current_segment_id += 1;\n            // }\n            ++current_segment_id;\n\n\n            // Add current object segment to final segmentation map\n            for (let index of mask_k) {\n                segmentation.data[index] = current_segment_id;\n            }\n\n            segments.push({\n                id: current_segment_id,\n                label_id: pred_class,\n                // was_fused: should_fuse, TODO\n                score: pred_scores[k],\n            })\n\n            // TODO\n            // if(should_fuse){\n            //     stuff_memory_list[pred_class] = current_segment_id\n            // }\n        }\n\n        return [segmentation, segments];\n    }\n\n    /**\n     * Post-process the model output to generate the final panoptic segmentation.\n     * @param {*} outputs The model output to post process\n     * @param {number} [threshold=0.5] The probability score threshold to keep predicted instance masks.\n     * @param {number} [mask_threshold=0.5] Threshold to use when turning the predicted masks into binary values.\n     * @param {number} [overlap_mask_area_threshold=0.8] The overlap mask area threshold to merge or discard small disconnected parts within each binary instance mask.\n     * @param {Set<number>} [label_ids_to_fuse=null] The labels in this state will have all their instances be fused together.\n     * @param {number[][]} [target_sizes=null] The target sizes to resize the masks to.\n     * @returns {Array<{ segmentation: Tensor, segments_info: Array<{id: number, label_id: number, score: number}>}>}\n     */\n    post_process_panoptic_segmentation(\n        outputs,\n        threshold = 0.5,\n        mask_threshold = 0.5,\n        overlap_mask_area_threshold = 0.8,\n        label_ids_to_fuse = null,\n        target_sizes = null,\n    ) {\n        if (label_ids_to_fuse === null) {\n            console.warn(\"`label_ids_to_fuse` unset. No instance will be fused.\")\n            label_ids_to_fuse = new Set();\n        }\n\n        const class_queries_logits = outputs.logits; // [batch_size, num_queries, num_classes+1]\n        const masks_queries_logits = outputs.pred_masks; // [batch_size, num_queries, height, width]\n\n        const mask_probs = masks_queries_logits.sigmoid()  // [batch_size, num_queries, height, width]\n\n        let [batch_size, num_queries, num_labels] = class_queries_logits.dims;\n        num_labels -= 1; // Remove last class (background)\n\n        if (target_sizes !== null && target_sizes.length !== batch_size) {\n            throw Error(\"Make sure that you pass in as many target sizes as the batch dimension of the logits\")\n        }\n\n        let toReturn = [];\n        for (let i = 0; i < batch_size; ++i) {\n            let target_size = target_sizes !== null ? target_sizes[i] : null;\n\n            let class_logits = class_queries_logits[i];\n            let mask_logits = mask_probs[i];\n\n            let [mask_probs_item, pred_scores_item, pred_labels_item] = this.remove_low_and_no_objects(class_logits, mask_logits, threshold, num_labels);\n\n            if (pred_labels_item.length === 0) {\n                // No mask found\n                let [height, width] = target_size ?? mask_logits.dims.slice(-2);\n\n                let segmentation = new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_3__.Tensor(\n                    'int32',\n                    new Int32Array(height * width).fill(-1),\n                    [height, width]\n                )\n                toReturn.push({\n                    segmentation: segmentation,\n                    segments_info: []\n                });\n                continue;\n            }\n\n\n            // Get segmentation map and segment information of batch item\n            let [segmentation, segments] = this.compute_segments(\n                mask_probs_item,\n                pred_scores_item,\n                pred_labels_item,\n                mask_threshold,\n                overlap_mask_area_threshold,\n                label_ids_to_fuse,\n                target_size,\n            )\n\n            toReturn.push({\n                segmentation: segmentation,\n                segments_info: segments\n            })\n        }\n\n        return toReturn;\n    }\n\n    post_process_instance_segmentation() {\n        // TODO\n        throw Error(\"Not implemented yet\");\n    }\n}\n\nclass YolosFeatureExtractor extends ImageFeatureExtractor {\n    /** @type {post_process_object_detection} */\n    post_process_object_detection(...args) {\n        return post_process_object_detection(...args);\n    }\n}\n\n/**\n * @typedef {object} SamImageProcessorResult\n * @property {Tensor} pixel_values\n * @property {HeightWidth[]} original_sizes\n * @property {HeightWidth[]} reshaped_input_sizes\n * @property {Tensor} [input_points]\n * @property {Tensor} [input_labels]\n */\n\nclass SamImageProcessor extends ImageFeatureExtractor {\n\n    /**\n     * \n     * @param {any} input_points \n     * @param {HeightWidth[]} original_sizes \n     * @param {HeightWidth[]} reshaped_input_sizes \n     * @returns {Tensor}\n     */\n    reshape_input_points(input_points, original_sizes, reshaped_input_sizes) {\n\n        // Make deep copy to avoid altering user's input\n        input_points = structuredClone(input_points);\n        let shape = (0,_utils_core_js__WEBPACK_IMPORTED_MODULE_0__.calculateDimensions)(input_points);\n\n        // TODO: add support for 2D input_points\n        if (shape.length === 3) {\n            // Correct user's input\n            shape = [1, ...shape];\n            input_points = [input_points];\n        } else if (shape.length !== 4) {\n            throw Error(\"The input_points must be a 4D tensor of shape `batch_size`, `point_batch_size`, `nb_points_per_image`, `2`.\")\n        }\n\n        // Reshape input points\n        for (let i = 0; i < input_points.length; ++i) { // batch_size\n            let originalImageSize = original_sizes[i];\n            let reshapedImageSize = reshaped_input_sizes[i];\n\n            let resizeFactors = [\n                reshapedImageSize[0] / originalImageSize[0],\n                reshapedImageSize[1] / originalImageSize[1]\n            ]\n\n            for (let j = 0; j < input_points[i].length; ++j) { // point_batch_size\n                for (let k = 0; k < input_points[i][j].length; ++k) { // nb_points_per_image\n                    for (let w = 0; w < input_points[i][j][k].length; ++w) { // 2\n                        input_points[i][j][k][w] *= resizeFactors[w];\n                    }\n                }\n            }\n        }\n\n        return new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_3__.Tensor(\n            'float32',\n            Float32Array.from(input_points.flat(Infinity)),\n            shape\n        )\n\n    }\n\n    /**\n     * \n     * @param {any} input_labels \n     * @param {Tensor} input_points \n     * @returns {Tensor}\n     */\n    add_input_labels(input_labels, input_points) {\n        let shape = (0,_utils_core_js__WEBPACK_IMPORTED_MODULE_0__.calculateDimensions)(input_labels);\n        if (shape.length === 2) {\n            // Correct user's input\n            shape = [1, ...shape];\n            input_labels = [input_labels];\n        } else if (shape.length !== 3) {\n            throw Error(\"The input_points must be a 4D tensor of shape `batch_size`, `point_batch_size`, `nb_points_per_image`, `2`.\")\n        }\n\n        if (shape.some((x, i) => x !== input_points.dims[i])) {\n            throw Error(`The first ${shape.length} dimensions of 'input_points' and 'input_labels' must be the same.`)\n        }\n        return new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_3__.Tensor(\n            'int64',\n            input_labels.flat(Infinity).map(BigInt),\n            shape,\n        )\n    }\n    /**\n     * @param {any[]} images The URL(s) of the image(s) to extract features from.\n     * @param {any} [input_points] A 3D or 4D array, representing the input points provided by the user.\n     * - 3D: `[point_batch_size, nb_points_per_image, 2]`. In this case, `batch_size` is assumed to be 1.\n     * - 4D: `[batch_size, point_batch_size, nb_points_per_image, 2]`.\n     * @param {any} [input_labels] A 2D or 3D array, representing the input labels for the points, used by the prompt encoder to encode the prompt.\n     * - 2D: `[point_batch_size, nb_points_per_image]`. In this case, `batch_size` is assumed to be 1.\n     * - 3D: `[batch_size, point_batch_size, nb_points_per_image]`.\n     * @returns {Promise<SamImageProcessorResult>}\n     */\n    async _call(images, input_points = null, input_labels = null) {\n        // TODO allow user to use preprocessed images\n        /** @type {SamImageProcessorResult} */\n        const processed = await super._call(images);\n\n        if (input_points) {\n            processed.input_points = this.reshape_input_points(\n                input_points, processed.original_sizes, processed.reshaped_input_sizes\n            );\n        }\n\n        if (input_labels) {\n            if (!processed.input_points) {\n                throw Error(\"`input_points` must be provided if `input_labels` are provided.\")\n            }\n            processed.input_labels = this.add_input_labels(input_labels, processed.input_points);\n        }\n\n        return processed;\n    }\n\n    /**\n     * Remove padding and upscale masks to the original image size.\n     * @param {Tensor} masks Batched masks from the mask_decoder in (batch_size, num_channels, height, width) format.\n     * @param {number[][]} original_sizes The original sizes of each image before it was resized to the model's expected input shape, in (height, width) format.\n     * @param {number[][]} reshaped_input_sizes The size of each image as it is fed to the model, in (height, width) format. Used to remove padding.\n     * @param {Object} options Optional parameters for post-processing.\n     * @param {number} [options.mask_threshold] The threshold to use for binarizing the masks.\n     * @param {boolean} [options.binarize] Whether to binarize the masks.\n     * @param {Object} [options.pad_size] The target size the images were padded to before being passed to the model. If `null`, the target size is assumed to be the processor's `pad_size`.\n     * @param {number} [options.pad_size.height] The height the images were padded to.\n     * @param {number} [options.pad_size.width] The width the images were padded to.\n     * @returns {Tensor[]} Batched masks in batch_size, num_channels, height, width) format, where (height, width) is given by original_size.\n     */\n    post_process_masks(masks, original_sizes, reshaped_input_sizes, {\n        mask_threshold = 0.0,\n        binarize = true,\n        pad_size = null,\n    } = {}) {\n        // masks: [1, 1, 3, 256, 256]\n\n        const output_masks = [];\n\n        pad_size = pad_size ?? this.pad_size;\n\n        const target_image_size = [pad_size.height, pad_size.width];\n\n        for (let i = 0; i < original_sizes.length; ++i) {\n            const original_size = original_sizes[i];\n            const reshaped_input_size = reshaped_input_sizes[i];\n\n            const mask = masks[i]; // [b, c, h, w]\n\n            // TODO: improve\n            const interpolated_masks = [];\n            for (let j = 0; j < mask.dims[0]; ++j) {\n                const m = mask[j]; // 3d tensor\n\n                // Upscale mask to padded size\n                let interpolated_mask = (0,_utils_tensor_js__WEBPACK_IMPORTED_MODULE_3__.interpolate)(m, target_image_size, 'bilinear', false);\n\n                // Crop mask\n                interpolated_mask = interpolated_mask.slice(null, [0, reshaped_input_size[0]], [0, reshaped_input_size[1]]);\n\n                // Downscale mask\n                interpolated_mask = (0,_utils_tensor_js__WEBPACK_IMPORTED_MODULE_3__.interpolate)(interpolated_mask, original_size, 'bilinear', false);\n\n                if (binarize) {\n                    const binarizedMaskData = new Uint8Array(interpolated_mask.data.length);\n                    for (let i = 0; i < interpolated_mask.data.length; ++i) {\n                        if (interpolated_mask.data[i] > mask_threshold) {\n                            binarizedMaskData[i] = 1;\n                        }\n                    }\n                    interpolated_mask = new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_3__.Tensor(\n                        'bool',\n                        binarizedMaskData,\n                        interpolated_mask.dims\n                    )\n                }\n\n                interpolated_masks.push(interpolated_mask);\n            }\n\n            output_masks.push((0,_utils_tensor_js__WEBPACK_IMPORTED_MODULE_3__.stack)(interpolated_masks));\n        }\n\n        return output_masks;\n    }\n}\n\nclass Swin2SRImageProcessor extends ImageFeatureExtractor {\n    pad_image(pixelData, imgDims, padSize, options = {}) {\n        // NOTE: In this case, `padSize` represents the size of the sliding window for the local attention.\n        // In other words, the image is padded so that its width and height are multiples of `padSize`.\n        const [imageWidth, imageHeight, imageChannels] = imgDims;\n\n        return super.pad_image(pixelData, imgDims, {\n            // NOTE: For Swin2SR models, the original python implementation adds padding even when the image's width/height is already\n            // a multiple of `pad_size`. However, this is most likely a bug (PR: https://github.com/mv-lab/swin2sr/pull/19).\n            // For this reason, we only add padding when the image's width/height is not a multiple of `pad_size`.\n            width: imageWidth + (padSize - imageWidth % padSize) % padSize,\n            height: imageHeight + (padSize - imageHeight % padSize) % padSize,\n        }, {\n            mode: 'symmetric',\n            center: false,\n            constant_values: -1,\n            ...options,\n        })\n    }\n}\n\nclass VitMatteImageProcessor extends ImageFeatureExtractor {\n    /**\n     * Calls the feature extraction process on an array of images, preprocesses\n     * each image, and concatenates the resulting features into a single Tensor.\n     * @param {RawImage[]} images The image(s) to extract features from.\n     * @param {RawImage[]} trimaps The trimaps(s) to extract features from.\n     * @returns {Promise<ImageFeatureExtractorResult>} An object containing the concatenated pixel values of the preprocessed images.\n     */\n    async _call(images, trimaps) {\n        if (!Array.isArray(images)) {\n            images = [images];\n        }\n        if (!Array.isArray(trimaps)) {\n            trimaps = [trimaps];\n        }\n\n        const imageData = await Promise.all(images.map(x => this.preprocess(x)));\n        const trimapData = await Promise.all(trimaps.map(x => this.preprocess(x, {\n            do_normalize: false,\n            do_convert_rgb: false,\n            do_convert_grayscale: true,\n        })));\n\n\n        // Stack pixel values\n        const pixel_values = (0,_utils_tensor_js__WEBPACK_IMPORTED_MODULE_3__.stack)(imageData.map(\n            // Concatenate images and trimaps\n            (x, i) => (0,_utils_tensor_js__WEBPACK_IMPORTED_MODULE_3__.cat)([x.pixel_values, trimapData[i].pixel_values], 0)\n        ), 0);\n\n        return {\n            pixel_values: pixel_values,\n\n            // Original sizes of images\n            original_sizes: imageData.map(x => x.original_size),\n\n            // Reshaped sizes of images, before padding or cropping\n            reshaped_input_sizes: imageData.map(x => x.reshaped_input_size),\n        }\n    }\n}\n\nclass WhisperFeatureExtractor extends FeatureExtractor {\n\n    constructor(config) {\n        super(config);\n\n        // Prefer given `mel_filters` from preprocessor_config.json, or calculate them if they don't exist.\n        this.config.mel_filters ??= (0,_utils_audio_js__WEBPACK_IMPORTED_MODULE_5__.mel_filter_bank)(\n            Math.floor(1 + this.config.n_fft / 2), // num_frequency_bins\n            this.config.feature_size, // num_mel_filters\n            0.0, // min_frequency\n            8000.0, // max_frequency\n            this.config.sampling_rate, // sampling_rate\n            \"slaney\", // norm\n            \"slaney\", // mel_scale\n        );\n\n        this.window = (0,_utils_audio_js__WEBPACK_IMPORTED_MODULE_5__.window_function)(this.config.n_fft, 'hann');\n    }\n\n    /**\n     * Computes the log-Mel spectrogram of the provided audio waveform.\n     * @param {Float32Array|Float64Array} waveform The audio waveform to process.\n     * @returns {{data: Float32Array, dims: number[]}} An object containing the log-Mel spectrogram data as a Float32Array and its dimensions as an array of numbers.\n     */\n    _extract_fbank_features(waveform) {\n        const { data, dims } = (0,_utils_audio_js__WEBPACK_IMPORTED_MODULE_5__.spectrogram)(\n            waveform,\n            this.window, // window\n            this.config.n_fft, // frame_length\n            this.config.hop_length, // hop_length\n            {\n                power: 2.0,\n                mel_filters: this.config.mel_filters,\n                log_mel: 'log10',\n\n                // Custom\n                max_num_frames: this.config.nb_max_frames, // 3000\n            }\n        )\n\n        const maxValue = (0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_2__.max)(data)[0];\n\n        for (let i = 0; i < data.length; ++i) {\n            data[i] = (Math.max(data[i], maxValue - 8.0) + 4.0) / 4.0;\n        }\n\n        return { data, dims };\n    }\n\n    /**\n     * Asynchronously extracts features from a given audio using the provided configuration.\n     * @param {Float32Array|Float64Array} audio The audio data as a Float32Array/Float64Array.\n     * @returns {Promise<{ input_features: Tensor }>} A Promise resolving to an object containing the extracted input features as a Tensor.\n     */\n    async _call(audio) {\n        validate_audio_inputs(audio, 'WhisperFeatureExtractor');\n\n        let waveform;\n        if (audio.length > this.config.n_samples) {\n            console.warn(\n                \"Attempting to extract features for audio longer than 30 seconds. \" +\n                \"If using a pipeline to extract transcript from a long audio clip, \" +\n                \"remember to specify `chunk_length_s` and/or `stride_length_s`.\"\n            );\n            waveform = audio.slice(0, this.config.n_samples);\n        } else {\n            // pad with zeros\n            waveform = new Float32Array(this.config.n_samples);\n            waveform.set(audio);\n        }\n\n        const { data, dims } = this._extract_fbank_features(waveform);\n\n        return {\n            input_features: new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_3__.Tensor('float32',\n                data,\n                [1, ...dims]\n            )\n        };\n    }\n}\n\nclass Wav2Vec2FeatureExtractor extends FeatureExtractor {\n\n    /**\n     * @param {Float32Array} input_values \n     * @returns {Float32Array} \n     */\n    _zero_mean_unit_var_norm(input_values) {\n        // TODO support batch?\n        const sum = input_values.reduce((a, b) => a + b, 0);\n        const mean = sum / input_values.length;\n        const variance = input_values.reduce((a, b) => a + (b - mean) ** 2, 0) / input_values.length;\n        return input_values.map(x => (x - mean) / Math.sqrt(variance + 1e-7));\n    }\n\n    /**\n     * Asynchronously extracts features from a given audio using the provided configuration.\n     * @param {Float32Array|Float64Array} audio The audio data as a Float32Array/Float64Array.\n     * @returns {Promise<{ input_values: Tensor; attention_mask: Tensor }>} A Promise resolving to an object containing the extracted input features and attention mask as Tensors.\n     */\n    async _call(audio) {\n        validate_audio_inputs(audio, 'Wav2Vec2FeatureExtractor');\n\n        if (audio instanceof Float64Array) {\n            audio = new Float32Array(audio);\n        }\n\n        let input_values = audio;\n\n        // zero-mean and unit-variance normalization\n        if (this.config.do_normalize) {\n            input_values = this._zero_mean_unit_var_norm(input_values);\n        }\n\n        // TODO: allow user to pass in attention mask\n        const shape = [1, input_values.length];\n        return {\n            input_values: new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_3__.Tensor('float32', input_values, shape),\n            attention_mask: new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_3__.Tensor('int64', new BigInt64Array(input_values.length).fill(1n), shape)\n        };\n    }\n}\n\nclass SeamlessM4TFeatureExtractor extends FeatureExtractor {\n\n    constructor(config) {\n        super(config);\n\n        const sampling_rate = this.config.sampling_rate;\n        const mel_filters = (0,_utils_audio_js__WEBPACK_IMPORTED_MODULE_5__.mel_filter_bank)(\n            256, // num_frequency_bins\n            this.config.num_mel_bins, // num_mel_filters\n            20, // min_frequency\n            Math.floor(sampling_rate / 2), // max_frequency\n            sampling_rate, // sampling_rate\n            null, // norm\n            \"kaldi\", // mel_scale\n            true, // triangularize_in_mel_space\n        );\n\n        // Do padding:\n        for (let i = 0; i < mel_filters.length; ++i) {\n            mel_filters[i].push(0);\n        }\n        this.mel_filters = mel_filters;\n\n        this.window = (0,_utils_audio_js__WEBPACK_IMPORTED_MODULE_5__.window_function)(400, 'povey', {\n            periodic: false,\n        })\n    }\n\n    /**\n     * Computes the log-Mel spectrogram of the provided audio waveform.\n     * @param {Float32Array|Float64Array} waveform The audio waveform to process.\n     * @param {number} max_length The maximum number of frames to return.\n     * @returns {{data: Float32Array, dims: number[]}} An object containing the log-Mel spectrogram data as a Float32Array and its dimensions as an array of numbers.\n     */\n    _extract_fbank_features(waveform, max_length) {\n        // NOTE: We don't pad/truncate since that is passed in as `max_num_frames`\n\n        // Kaldi compliance: 16-bit signed integers\n        // 32768 == 2 ** 15\n        waveform = waveform.map((/** @type {number} */ x) => x * 32768)\n\n        return (0,_utils_audio_js__WEBPACK_IMPORTED_MODULE_5__.spectrogram)(\n            waveform,\n            this.window, // window\n            400, // frame_length\n            160, // hop_length\n            {\n                fft_length: 512,\n                power: 2.0,\n                center: false,\n                preemphasis: 0.97,\n                mel_filters: this.mel_filters,\n                log_mel: 'log',\n                mel_floor: 1.192092955078125e-07,\n                remove_dc_offset: true,\n\n                // Custom\n                max_num_frames: max_length,\n                transpose: true,\n            }\n        )\n    }\n\n    /**\n     * Asynchronously extracts features from a given audio using the provided configuration.\n     * @param {Float32Array|Float64Array} audio The audio data as a Float32Array/Float64Array.\n     * @param {Object} options Optional parameters for feature extraction.\n     * @param {boolean} [options.padding=true] Whether to pad the sequence to a multiple of `pad_to_multiple_of`.\n     * @param {number} [options.pad_to_multiple_of=2] The number to pad the sequence to a multiple of.\n     * @param {boolean} [options.do_normalize_per_mel_bins=true] Whether or not to zero-mean unit-variance normalize the input per mel-channel.\n     * @param {boolean} [options.return_attention_mask=true] Whether to return the attention mask.\n     * @returns {Promise<{ input_features: Tensor, attention_mask?: Tensor }>} A Promise resolving to an object containing the extracted input features and attention masks as Tensors.\n     */\n    async _call(audio, {\n        padding = true,\n        pad_to_multiple_of = 2,\n        do_normalize_per_mel_bins = true,\n        return_attention_mask = true,\n    } = {}) {\n        validate_audio_inputs(audio, 'SeamlessM4TFeatureExtractor');\n\n        let features = this._extract_fbank_features(audio, this.config.max_length);\n\n        if (do_normalize_per_mel_bins) {\n            const [num_features, feature_size] = features.dims;\n            for (let i = 0; i < feature_size; ++i) {\n                let sum = 0;\n                for (let j = 0; j < num_features; ++j) {\n                    sum += features.data[j * feature_size + i];\n                }\n\n                const mean = sum / num_features;\n\n                let variance = 0;\n                for (let j = 0; j < num_features; ++j) {\n                    variance += (features.data[j * feature_size + i] - mean) ** 2;\n                }\n                variance /= num_features - 1; // NOTE: We use ddof=1\n\n                const std = Math.sqrt(variance + 1e-7);\n                for (let j = 0; j < num_features; ++j) {\n                    const index = j * feature_size + i;\n                    features.data[index] = (features.data[index] - mean) / std;\n                }\n            }\n        }\n\n        let padded_attention_mask;\n        if (padding) {\n            const [num_frames, num_channels] = features.dims;\n\n            const pad_size = num_frames % pad_to_multiple_of;\n            if (pad_size > 0) {\n                const padded_data = new Float32Array(num_channels * (num_frames + pad_size));\n                padded_data.set(features.data)\n                padded_data.fill(this.config.padding_value, features.data.length)\n\n                const numPaddedFrames = num_frames + pad_size;\n                features = {\n                    data: padded_data,\n                    dims: [numPaddedFrames, num_channels],\n                }\n\n                if (return_attention_mask) {\n                    padded_attention_mask = new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_3__.Tensor(\n                        'int64',\n                        new BigInt64Array(numPaddedFrames),\n                        [1, numPaddedFrames],\n                    )\n                    padded_attention_mask.data.fill(1n, 0, num_frames);\n                }\n            }\n        }\n\n        const [num_frames, num_channels] = features.dims;\n\n        const stride = this.config.stride;\n        const remainder = num_frames % stride;\n        if (remainder !== 0) {\n            throw new Error(`The number of frames (${num_frames}) must be a multiple of the stride (${stride}).`)\n        }\n\n        const input_features = new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_3__.Tensor('float32',\n            features.data,\n            features.dims,\n        ).view(\n            1,\n            Math.floor(num_frames / stride),\n            num_channels * stride,\n        );\n\n        const result = { input_features }\n\n        if (return_attention_mask) {\n            const reshapedNumFrames = input_features.dims[1];\n\n            const attention_mask = new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_3__.Tensor(\n                'int64',\n                new BigInt64Array(reshapedNumFrames),\n                [1, reshapedNumFrames],\n            );\n            if (padded_attention_mask) {\n                for (let i = 1, j = 0; i < num_frames; i += stride, ++j) {\n                    attention_mask.data[j] = padded_attention_mask.data[i];\n                }\n            } else {\n                attention_mask.data.fill(1n);\n            }\n\n            result.attention_mask = attention_mask;\n        }\n\n        return result;\n    }\n}\n\nclass ASTFeatureExtractor extends FeatureExtractor {\n\n\n    constructor(config) {\n        super(config);\n\n        const sampling_rate = this.config.sampling_rate;\n        const mel_filters = (0,_utils_audio_js__WEBPACK_IMPORTED_MODULE_5__.mel_filter_bank)(\n            256, // num_frequency_bins\n            this.config.num_mel_bins, // num_mel_filters\n            20, // min_frequency\n            Math.floor(sampling_rate / 2), // max_frequency\n            sampling_rate, // sampling_rate\n            null, // norm\n            \"kaldi\", // mel_scale\n            true, // triangularize_in_mel_space\n        );\n\n        // Do padding:\n        for (let i = 0; i < mel_filters.length; ++i) {\n            mel_filters[i].push(0);\n        }\n        this.mel_filters = mel_filters;\n\n        this.window = (0,_utils_audio_js__WEBPACK_IMPORTED_MODULE_5__.window_function)(400, 'hann', {\n            periodic: false,\n        })\n\n        this.mean = this.config.mean;\n        this.std = this.config.std;\n    }\n\n    /**\n     * Computes the log-Mel spectrogram of the provided audio waveform.\n     * @param {Float32Array|Float64Array} waveform The audio waveform to process.\n     * @param {number} max_length The maximum number of frames to return.\n     * @returns {{data: Float32Array, dims: number[]}} An object containing the log-Mel spectrogram data as a Float32Array and its dimensions as an array of numbers.\n     */\n    _extract_fbank_features(waveform, max_length) {\n        // NOTE: We don't pad/truncate since that is passed in as `max_num_frames`\n        return (0,_utils_audio_js__WEBPACK_IMPORTED_MODULE_5__.spectrogram)(\n            waveform,\n            this.window, // window\n            400, // frame_length\n            160, // hop_length\n            {\n                fft_length: 512,\n                power: 2.0,\n                center: false,\n                preemphasis: 0.97,\n                mel_filters: this.mel_filters,\n                log_mel: 'log',\n                mel_floor: 1.192092955078125e-07,\n                remove_dc_offset: true,\n\n                // Custom\n                max_num_frames: max_length,\n                transpose: true,\n            }\n        )\n    }\n\n\n    /**\n     * Asynchronously extracts features from a given audio using the provided configuration.\n     * @param {Float32Array|Float64Array} audio The audio data as a Float32Array/Float64Array.\n     * @returns {Promise<{ input_values: Tensor }>} A Promise resolving to an object containing the extracted input features as a Tensor.\n     */\n    async _call(audio) {\n        validate_audio_inputs(audio, 'ASTFeatureExtractor');\n\n        const features = this._extract_fbank_features(audio, this.config.max_length);\n        if (this.config.do_normalize) {\n            // Normalize the input audio spectrogram to have mean=0, std=0.5\n            const denom = this.std * 2;\n            for (let i = 0; i < features.data.length; ++i) {\n                features.data[i] = (features.data[i] - this.mean) / denom;\n            }\n        }\n\n        return {\n            input_values: new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_3__.Tensor('float32',\n                features.data,\n                [1, ...features.dims]\n            )\n        };\n    }\n}\n\nclass ClapFeatureExtractor extends FeatureExtractor {\n\n    constructor(config) {\n        super(config);\n\n        this.mel_filters = (0,_utils_audio_js__WEBPACK_IMPORTED_MODULE_5__.mel_filter_bank)(\n            this.config.nb_frequency_bins, // num_frequency_bins\n            this.config.feature_size, // num_mel_filters\n            this.config.frequency_min, // min_frequency\n            this.config.frequency_max, // max_frequency\n            this.config.sampling_rate, // sampling_rate\n            null, // norm\n            \"htk\", // mel_scale\n        );\n\n        this.mel_filters_slaney = (0,_utils_audio_js__WEBPACK_IMPORTED_MODULE_5__.mel_filter_bank)(\n            this.config.nb_frequency_bins, // num_frequency_bins\n            this.config.feature_size, // num_mel_filters\n            this.config.frequency_min, // min_frequency\n            this.config.frequency_max, // max_frequency\n            this.config.sampling_rate, // sampling_rate\n            \"slaney\", // norm\n            \"slaney\", // mel_scale\n        );\n\n        this.window = (0,_utils_audio_js__WEBPACK_IMPORTED_MODULE_5__.window_function)(this.config.fft_window_size, 'hann')\n\n    }\n\n\n    /**\n     * Extracts the mel spectrogram and prepares it for the mode based on the `truncation` and `padding` arguments.\n     * \n     * Four different path are possible:\n     *   - `truncation=\"fusion\"` and the length of the waveform is greater than the max length: the mel spectrogram\n     *     will be computed on the entire audio. 3 random crops and a dowsampled version of the full mel spectrogram\n     *     are then stacked together. They will later be used for `feature_fusion`.\n     *   - `truncation=\"rand_trunc\"` and the length of the waveform is smaller than the max length: the audio is\n     *     padded based on `padding`.\n     *   - `truncation=\"fusion\"` and the length of the waveform is smaller than the max length: the audio is padded\n     *     based on `padding`, and is repeated `4` times.\n     *   - `truncation=\"rand_trunc\"` and the length of the waveform is greater than the max length: the mel\n     *     spectrogram will be computed on a random crop of the waveform.\n     * \n     * @param {Float32Array|Float64Array} waveform The input waveform.\n     * @param {number} max_length The maximum length of the waveform.\n     * @param {string} truncation The truncation strategy to use.\n     * @param {string} padding The padding strategy to use.\n     * @returns {{ data: Float32Array; dims: number[]; longer: boolean; }} An object containing the mel spectrogram data as a Float32Array, its dimensions as an array of numbers, and a boolean indicating whether the waveform was longer than the max length.\n     */\n    _get_input_mel(waveform, max_length, truncation, padding) {\n\n        /** @type {{ data: Float32Array; dims: number[]}} */\n        let input_mel;\n        let longer = false;\n        const diff = waveform.length - max_length;\n        if (diff > 0) {\n            if (truncation === 'rand_trunc') {\n                longer = true;\n                const idx = Math.floor(Math.random() * (diff + 1));\n                waveform = waveform.subarray(idx, idx + max_length);\n\n                input_mel = this._extract_fbank_features(waveform, this.mel_filters_slaney, this.config.nb_max_samples);\n                input_mel.dims = [1, ...input_mel.dims]; // \"unsqueeze\"\n            } else {\n                // TODO implement fusion strategy\n                throw new Error(`Truncation strategy \"${truncation}\" not implemented`)\n            }\n        } else {\n            if (diff < 0) {\n                let padded = new Float64Array(max_length); // already padded with zeros\n                padded.set(waveform);\n\n                if (padding === 'repeat') {\n                    for (let i = waveform.length; i < max_length; i += waveform.length) {\n                        padded.set(waveform.subarray(0, Math.min(waveform.length, max_length - i)), i);\n                    }\n                } else if (padding === 'repeatpad') {\n                    for (let i = waveform.length; i < -diff; i += waveform.length) {\n                        padded.set(waveform, i);\n                    }\n                }\n                waveform = padded;\n            }\n\n            if (truncation === 'fusion') {\n                throw new Error(`Truncation strategy \"${truncation}\" not implemented`)\n            }\n\n            input_mel = this._extract_fbank_features(waveform, this.mel_filters_slaney, this.config.nb_max_samples);\n            input_mel.dims = [1, ...input_mel.dims]; // \"unsqueeze\"\n        }\n\n        return {\n            ...input_mel,\n            longer,\n        }\n    }\n\n    /**\n     * Compute the log-mel spectrogram of the provided `waveform` using the Hann window.\n     * In CLAP, two different filter banks are used depending on the truncation pattern:\n     *  - `self.mel_filters`: they correspond to the default parameters of `torchaudio` which can be obtained from\n     *    calling `torchaudio.transforms.MelSpectrogram().mel_scale.fb`. These filters are used when `truncation`\n     *    is set to `\"fusion\"`.\n     *  - `self.mel_filteres_slaney` : they correspond to the default parameters of `librosa` which used\n     *    `librosa.filters.mel` when computing the mel spectrogram. These filters were only used in the original\n     *    implementation when the truncation mode is not `\"fusion\"`.\n     * \n     * @param {Float32Array|Float64Array} waveform The audio waveform to process.\n     * @param {number[][]} mel_filters The mel filters to use.\n     * @param {number} [max_length=null] The maximum number of frames to return.\n     * @returns {{data: Float32Array, dims: number[]}} An object containing the log-Mel spectrogram data as a Float32Array and its dimensions as an array of numbers.\n     */\n    _extract_fbank_features(waveform, mel_filters, max_length = null) {\n        // NOTE: We don't pad/truncate since that is passed in as `max_num_frames`\n        return (0,_utils_audio_js__WEBPACK_IMPORTED_MODULE_5__.spectrogram)(\n            waveform,\n            this.window, // window\n            this.config.fft_window_size, // frame_length\n            this.config.hop_length, // hop_length\n            {\n                power: 2.0,\n                mel_filters,\n                log_mel: 'dB',\n\n                // Custom\n                max_num_frames: max_length,\n                do_pad: false,\n                transpose: true,\n            }\n        )\n    }\n\n\n    /**\n     * Asynchronously extracts features from a given audio using the provided configuration.\n     * @param {Float32Array|Float64Array} audio The audio data as a Float32Array/Float64Array.\n     * @returns {Promise<{ input_features: Tensor }>} A Promise resolving to an object containing the extracted input features as a Tensor.\n     */\n    async _call(audio, {\n        max_length = null,\n    } = {}) {\n        validate_audio_inputs(audio, 'ClapFeatureExtractor');\n\n        // convert to mel spectrogram, truncate and pad if needed.\n        const padded_inputs = this._get_input_mel(\n            audio,\n            max_length ?? this.config.nb_max_samples,\n            this.config.truncation,\n            this.config.padding,\n        );\n\n\n        return {\n            input_features: new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_3__.Tensor('float32',\n                padded_inputs.data,\n                [1, ...padded_inputs.dims]\n            )\n        };\n    }\n}\n\n\n\nclass SpeechT5FeatureExtractor extends FeatureExtractor { }\n\n/**\n * Represents a Processor that extracts features from an input.\n * @extends Callable\n */\nclass Processor extends _utils_core_js__WEBPACK_IMPORTED_MODULE_0__.Callable {\n    /**\n     * Creates a new Processor with the given feature extractor.\n     * @param {FeatureExtractor} feature_extractor The function used to extract features from the input.\n     */\n    constructor(feature_extractor) {\n        super();\n        this.feature_extractor = feature_extractor;\n        // TODO use tokenizer here?\n    }\n\n    /**\n     * Calls the feature_extractor function with the given input.\n     * @param {any} input The input to extract features from.\n     * @param {...any} args Additional arguments.\n     * @returns {Promise<any>} A Promise that resolves with the extracted features.\n     */\n    async _call(input, ...args) {\n        return await this.feature_extractor(input, ...args);\n    }\n}\n\nclass SamProcessor extends Processor {\n    /**\n     * @borrows SamImageProcessor#_call as _call\n     */\n    async _call(...args) {\n        return await this.feature_extractor(...args);\n    }\n\n    /**\n     * @borrows SamImageProcessor#post_process_masks as post_process_masks\n     */\n    post_process_masks(...args) {\n        // @ts-ignore\n        return this.feature_extractor.post_process_masks(...args);\n    }\n    /**\n     * @borrows SamImageProcessor#reshape_input_points as reshape_input_points\n     */\n    reshape_input_points(...args) {\n        // @ts-ignore\n        return this.feature_extractor.reshape_input_points(...args);\n    }\n}\n\n/**\n * Represents a WhisperProcessor that extracts features from an audio input.\n * @extends Processor\n */\nclass WhisperProcessor extends Processor {\n    /**\n     * Calls the feature_extractor function with the given audio input.\n     * @param {any} audio The audio input to extract features from.\n     * @returns {Promise<any>} A Promise that resolves with the extracted features.\n     */\n    async _call(audio) {\n        return await this.feature_extractor(audio)\n    }\n}\n\n\nclass Wav2Vec2ProcessorWithLM extends Processor {\n    /**\n     * Calls the feature_extractor function with the given audio input.\n     * @param {any} audio The audio input to extract features from.\n     * @returns {Promise<any>} A Promise that resolves with the extracted features.\n     */\n    async _call(audio) {\n        return await this.feature_extractor(audio)\n    }\n}\n\nclass SpeechT5Processor extends Processor {\n    /**\n     * Calls the feature_extractor function with the given input.\n     * @param {any} input The input to extract features from.\n     * @returns {Promise<any>} A Promise that resolves with the extracted features.\n     */\n    async _call(input) {\n        return await this.feature_extractor(input)\n    }\n}\n\nclass OwlViTProcessor extends Processor { }\n\n\n//////////////////////////////////////////////////\n/**\n * Helper class which is used to instantiate pretrained processors with the `from_pretrained` function.\n * The chosen processor class is determined by the type specified in the processor config.\n * \n * **Example:** Load a processor using `from_pretrained`.\n * ```javascript\n * let processor = await AutoProcessor.from_pretrained('openai/whisper-tiny.en');\n * ```\n * \n * **Example:** Run an image through a processor.\n * ```javascript\n * let processor = await AutoProcessor.from_pretrained('Xenova/clip-vit-base-patch16');\n * let image = await RawImage.read('https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/football-match.jpg');\n * let image_inputs = await processor(image);\n * // {\n * //   \"pixel_values\": {\n * //     \"dims\": [ 1, 3, 224, 224 ],\n * //     \"type\": \"float32\",\n * //     \"data\": Float32Array [ -1.558687686920166, -1.558687686920166, -1.5440893173217773, ... ],\n * //     \"size\": 150528\n * //   },\n * //   \"original_sizes\": [\n * //     [ 533, 800 ]\n * //   ],\n * //   \"reshaped_input_sizes\": [\n * //     [ 224, 224 ]\n * //   ]\n * // }\n * ```\n */\nclass AutoProcessor {\n    static FEATURE_EXTRACTOR_CLASS_MAPPING = {\n        ImageFeatureExtractor,\n        WhisperFeatureExtractor,\n        ViTFeatureExtractor,\n        MobileViTFeatureExtractor,\n        OwlViTFeatureExtractor,\n        Owlv2ImageProcessor,\n        CLIPFeatureExtractor,\n        ChineseCLIPFeatureExtractor,\n        SiglipImageProcessor,\n        ConvNextFeatureExtractor,\n        ConvNextImageProcessor,\n        SegformerFeatureExtractor,\n        BitImageProcessor,\n        DPTImageProcessor,\n        DPTFeatureExtractor,\n        GLPNFeatureExtractor,\n        BeitFeatureExtractor,\n        DeiTFeatureExtractor,\n        DetrFeatureExtractor,\n        YolosFeatureExtractor,\n        DonutFeatureExtractor,\n        NougatImageProcessor,\n\n        ViTImageProcessor,\n        VitMatteImageProcessor,\n        SamImageProcessor,\n        Swin2SRImageProcessor,\n        Wav2Vec2FeatureExtractor,\n        SeamlessM4TFeatureExtractor,\n        SpeechT5FeatureExtractor,\n        ASTFeatureExtractor,\n        ClapFeatureExtractor,\n    }\n\n    static PROCESSOR_CLASS_MAPPING = {\n        WhisperProcessor,\n        Wav2Vec2ProcessorWithLM,\n        SamProcessor,\n        SpeechT5Processor,\n        OwlViTProcessor,\n    }\n\n    /**\n     * Instantiate one of the processor classes of the library from a pretrained model.\n     * \n     * The processor class to instantiate is selected based on the `feature_extractor_type` property of the config object\n     * (either passed as an argument or loaded from `pretrained_model_name_or_path` if possible)\n     * \n     * @param {string} pretrained_model_name_or_path The name or path of the pretrained model. Can be either:\n     * - A string, the *model id* of a pretrained processor hosted inside a model repo on huggingface.co.\n     *   Valid model ids can be located at the root-level, like `bert-base-uncased`, or namespaced under a\n     *   user or organization name, like `dbmdz/bert-base-german-cased`.\n     * - A path to a *directory* containing processor files, e.g., `./my_model_directory/`.\n     * @param {import('./utils/hub.js').PretrainedOptions} options Additional options for loading the processor.\n     * \n     * @returns {Promise<Processor>} A new instance of the Processor class.\n     */\n    static async from_pretrained(pretrained_model_name_or_path, {\n        progress_callback = null,\n        config = null,\n        cache_dir = null,\n        local_files_only = false,\n        revision = 'main',\n    } = {}) {\n\n        let preprocessorConfig = config ?? await (0,_utils_hub_js__WEBPACK_IMPORTED_MODULE_1__.getModelJSON)(pretrained_model_name_or_path, 'preprocessor_config.json', true, {\n            progress_callback,\n            config,\n            cache_dir,\n            local_files_only,\n            revision,\n        })\n\n        // Determine feature extractor class\n        // TODO: Ensure backwards compatibility with old configs\n        let key = preprocessorConfig.feature_extractor_type ?? preprocessorConfig.image_processor_type;\n        let feature_extractor_class = this.FEATURE_EXTRACTOR_CLASS_MAPPING[key];\n\n        if (!feature_extractor_class) {\n            if (preprocessorConfig.size !== undefined) {\n                // Assume ImageFeatureExtractor\n                console.warn(`Feature extractor type \"${key}\" not found, assuming ImageFeatureExtractor due to size parameter in config.`);\n                feature_extractor_class = ImageFeatureExtractor;\n            } else {\n                throw new Error(`Unknown Feature Extractor type: ${key}`);\n            }\n        }\n\n        // If no associated processor class, use default\n        let processor_class = this.PROCESSOR_CLASS_MAPPING[preprocessorConfig.processor_class] ?? Processor;\n\n        // Instantiate processor and feature extractor\n        let feature_extractor = new feature_extractor_class(preprocessorConfig);\n        return new processor_class(feature_extractor);\n    }\n}\n//////////////////////////////////////////////////\n\n\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@xenova/transformers/src/processors.js?");

/***/ }),

/***/ "./node_modules/@xenova/transformers/src/tokenizers.js":
/*!*************************************************************!*\
  !*** ./node_modules/@xenova/transformers/src/tokenizers.js ***!
  \*************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   AlbertTokenizer: () => (/* binding */ AlbertTokenizer),\n/* harmony export */   AutoTokenizer: () => (/* binding */ AutoTokenizer),\n/* harmony export */   BartTokenizer: () => (/* binding */ BartTokenizer),\n/* harmony export */   BertTokenizer: () => (/* binding */ BertTokenizer),\n/* harmony export */   BlenderbotSmallTokenizer: () => (/* binding */ BlenderbotSmallTokenizer),\n/* harmony export */   BlenderbotTokenizer: () => (/* binding */ BlenderbotTokenizer),\n/* harmony export */   BloomTokenizer: () => (/* binding */ BloomTokenizer),\n/* harmony export */   CLIPTokenizer: () => (/* binding */ CLIPTokenizer),\n/* harmony export */   CamembertTokenizer: () => (/* binding */ CamembertTokenizer),\n/* harmony export */   CodeGenTokenizer: () => (/* binding */ CodeGenTokenizer),\n/* harmony export */   CodeLlamaTokenizer: () => (/* binding */ CodeLlamaTokenizer),\n/* harmony export */   ConvBertTokenizer: () => (/* binding */ ConvBertTokenizer),\n/* harmony export */   DebertaTokenizer: () => (/* binding */ DebertaTokenizer),\n/* harmony export */   DebertaV2Tokenizer: () => (/* binding */ DebertaV2Tokenizer),\n/* harmony export */   DistilBertTokenizer: () => (/* binding */ DistilBertTokenizer),\n/* harmony export */   ElectraTokenizer: () => (/* binding */ ElectraTokenizer),\n/* harmony export */   EsmTokenizer: () => (/* binding */ EsmTokenizer),\n/* harmony export */   FalconTokenizer: () => (/* binding */ FalconTokenizer),\n/* harmony export */   GPT2Tokenizer: () => (/* binding */ GPT2Tokenizer),\n/* harmony export */   GPTNeoXTokenizer: () => (/* binding */ GPTNeoXTokenizer),\n/* harmony export */   GemmaTokenizer: () => (/* binding */ GemmaTokenizer),\n/* harmony export */   HerbertTokenizer: () => (/* binding */ HerbertTokenizer),\n/* harmony export */   LlamaTokenizer: () => (/* binding */ LlamaTokenizer),\n/* harmony export */   M2M100Tokenizer: () => (/* binding */ M2M100Tokenizer),\n/* harmony export */   MBart50Tokenizer: () => (/* binding */ MBart50Tokenizer),\n/* harmony export */   MBartTokenizer: () => (/* binding */ MBartTokenizer),\n/* harmony export */   MPNetTokenizer: () => (/* binding */ MPNetTokenizer),\n/* harmony export */   MarianTokenizer: () => (/* binding */ MarianTokenizer),\n/* harmony export */   MobileBertTokenizer: () => (/* binding */ MobileBertTokenizer),\n/* harmony export */   NllbTokenizer: () => (/* binding */ NllbTokenizer),\n/* harmony export */   NougatTokenizer: () => (/* binding */ NougatTokenizer),\n/* harmony export */   PreTrainedTokenizer: () => (/* binding */ PreTrainedTokenizer),\n/* harmony export */   Qwen2Tokenizer: () => (/* binding */ Qwen2Tokenizer),\n/* harmony export */   RoFormerTokenizer: () => (/* binding */ RoFormerTokenizer),\n/* harmony export */   RobertaTokenizer: () => (/* binding */ RobertaTokenizer),\n/* harmony export */   SiglipTokenizer: () => (/* binding */ SiglipTokenizer),\n/* harmony export */   SpeechT5Tokenizer: () => (/* binding */ SpeechT5Tokenizer),\n/* harmony export */   SqueezeBertTokenizer: () => (/* binding */ SqueezeBertTokenizer),\n/* harmony export */   T5Tokenizer: () => (/* binding */ T5Tokenizer),\n/* harmony export */   TokenizerModel: () => (/* binding */ TokenizerModel),\n/* harmony export */   VitsTokenizer: () => (/* binding */ VitsTokenizer),\n/* harmony export */   Wav2Vec2CTCTokenizer: () => (/* binding */ Wav2Vec2CTCTokenizer),\n/* harmony export */   WhisperTokenizer: () => (/* binding */ WhisperTokenizer),\n/* harmony export */   XLMRobertaTokenizer: () => (/* binding */ XLMRobertaTokenizer),\n/* harmony export */   XLMTokenizer: () => (/* binding */ XLMTokenizer)\n/* harmony export */ });\n/* harmony import */ var _utils_core_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./utils/core.js */ \"./node_modules/@xenova/transformers/src/utils/core.js\");\n/* harmony import */ var _utils_hub_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./utils/hub.js */ \"./node_modules/@xenova/transformers/src/utils/hub.js\");\n/* harmony import */ var _utils_maths_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./utils/maths.js */ \"./node_modules/@xenova/transformers/src/utils/maths.js\");\n/* harmony import */ var _utils_tensor_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./utils/tensor.js */ \"./node_modules/@xenova/transformers/src/utils/tensor.js\");\n/* harmony import */ var _utils_data_structures_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./utils/data-structures.js */ \"./node_modules/@xenova/transformers/src/utils/data-structures.js\");\n/* harmony import */ var _huggingface_jinja__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! @huggingface/jinja */ \"./node_modules/@huggingface/jinja/dist/index.js\");\n\n/**\n * @file Tokenizers are used to prepare textual inputs for a model.\n * \n * **Example:** Create an `AutoTokenizer` and use it to tokenize a sentence.\n * This will automatically detect the tokenizer type based on the tokenizer class defined in `tokenizer.json`.\n * ```javascript\n * import { AutoTokenizer } from '@xenova/transformers';\n * \n * const tokenizer = await AutoTokenizer.from_pretrained('Xenova/bert-base-uncased');\n * const { input_ids } = await tokenizer('I love transformers!');\n * // Tensor {\n * //   data: BigInt64Array(6) [101n, 1045n, 2293n, 19081n, 999n, 102n],\n * //   dims: [1, 6],\n * //   type: 'int64',\n * //   size: 6,\n * // }\n * ```\n * \n * @module tokenizers\n */\n\n\n\n\n\n\n\n\n\n\n\n\n\n/**\n * @typedef {Object} TokenizerProperties Additional tokenizer-specific properties.\n * @property {boolean} [legacy=false] Whether or not the `legacy` behavior of the tokenizer should be used.\n * @typedef {import('./utils/hub.js').PretrainedOptions & TokenizerProperties} PretrainedTokenizerOptions\n */\n\n/**\n * Loads a tokenizer from the specified path.\n * @param {string} pretrained_model_name_or_path The path to the tokenizer directory.\n * @param {PretrainedTokenizerOptions} options Additional options for loading the tokenizer.\n * @returns {Promise<any[]>} A promise that resolves with information about the loaded tokenizer.\n */\nasync function loadTokenizer(pretrained_model_name_or_path, options) {\n\n    const info = await Promise.all([\n        (0,_utils_hub_js__WEBPACK_IMPORTED_MODULE_1__.getModelJSON)(pretrained_model_name_or_path, 'tokenizer.json', true, options),\n        (0,_utils_hub_js__WEBPACK_IMPORTED_MODULE_1__.getModelJSON)(pretrained_model_name_or_path, 'tokenizer_config.json', true, options),\n    ])\n\n    // Override legacy option if `options.legacy` is not null\n    if (options.legacy !== null) {\n        info[1].legacy = options.legacy;\n    }\n    return info;\n}\n\n\n/**\n * Helper function to split a string on a regex, but keep the delimiters.\n * This is required, because the JavaScript `.split()` method does not keep the delimiters,\n * and wrapping in a capturing group causes issues with existing capturing groups (due to nesting).\n * @param {string} text The text to split.\n * @param {RegExp} regex The regex to split on.\n * @returns {string[]} The split string.\n */\nfunction regexSplit(text, regex) {\n    const result = [];\n    let prev = 0;\n    for (const match of text.matchAll(regex)) {\n        const fullMatch = match[0];\n        if (prev < match.index) {\n            result.push(text.slice(prev, match.index));\n        }\n        if (fullMatch.length > 0) {\n            result.push(fullMatch);\n        }\n        prev = match.index + fullMatch.length;\n    }\n    if (prev < text.length) {\n        result.push(text.slice(prev));\n    }\n    return result;\n}\n\n\n/**\n * Helper method to construct a pattern from a config object.\n * @param {Object} pattern The pattern object.\n * @param {boolean} invert Whether to invert the pattern.\n * @returns {RegExp|null} The compiled pattern.\n */\nfunction createPattern(pattern, invert = true) {\n\n    if (pattern.Regex !== undefined) {\n        // In certain cases, the pattern may contain unnecessary escape sequences (e.g., \\# or \\& or \\~).\n        // i.e., valid in Python (where the patterns are exported from) but invalid in JavaScript (where the patterns are parsed).\n        // This isn't an issue when creating the regex w/o the 'u' flag, but it is when the 'u' flag is used.\n        // For this reason, it is necessary to remove these backslashes before creating the regex.\n        // See https://stackoverflow.com/a/63007777/13989043 for more information\n        let regex = pattern.Regex.replace(/\\\\([#&~])/g, '$1'); // TODO: add more characters to this list if necessary\n\n        // We also handle special cases where the regex contains invalid (non-JS compatible) syntax.\n        for (const [key, value] of PROBLEMATIC_REGEX_MAP) {\n            regex = regex.replaceAll(key, value);\n        }\n\n        return new RegExp(regex, 'gu');\n\n    } else if (pattern.String !== undefined) {\n        const escaped = (0,_utils_core_js__WEBPACK_IMPORTED_MODULE_0__.escapeRegExp)(pattern.String);\n        // NOTE: if invert is true, we wrap the pattern in a group so that it is kept when performing .split()\n        return new RegExp(invert ? escaped : `(${escaped})`, 'gu');\n\n    } else {\n        console.warn('Unknown pattern type:', pattern)\n        return null;\n    }\n}\n\n/**\n * Helper function to convert an Object to a Map\n * @param {Object} obj The object to convert.\n * @returns {Map<string, any>} The map.\n */\nfunction objectToMap(obj) {\n    return new Map(Object.entries(obj));\n}\n\n/**\n * Helper function to convert a tensor to a list before decoding.\n * @param {Tensor} tensor The tensor to convert.\n * @returns {number[]} The tensor as a list.\n */\nfunction prepareTensorForDecode(tensor) {\n    const dims = tensor.dims;\n    switch (dims.length) {\n        case 1:\n            return tensor.tolist();\n        case 2:\n            if (dims[0] !== 1) {\n                throw new Error('Unable to decode tensor with `batch size !== 1`. Use `tokenizer.batch_decode(...)` for batched inputs.');\n            }\n            return tensor.tolist()[0];\n        default:\n            throw new Error(`Expected tensor to have 1-2 dimensions, got ${dims.length}.`)\n    }\n}\n\n/**\n * Clean up a list of simple English tokenization artifacts like spaces before punctuations and abbreviated forms\n * @param {string} text The text to clean up.\n * @returns {string} The cleaned up text.\n */\nfunction clean_up_tokenization(text) {\n    // Clean up a list of simple English tokenization artifacts\n    // like spaces before punctuations and abbreviated forms\n    return text.replace(/ \\./g, '.')\n        .replace(/ \\?/g, '?')\n        .replace(/ \\!/g, '!')\n        .replace(/ ,/g, ',')\n        .replace(/ \\' /g, \"'\")\n        .replace(/ n\\'t/g, \"n't\")\n        .replace(/ \\'m/g, \"'m\")\n        .replace(/ \\'s/g, \"'s\")\n        .replace(/ \\'ve/g, \"'ve\")\n        .replace(/ \\'re/g, \"'re\");\n}\n\n/**\n * Helper function to remove accents from a string.\n * @param {string} text The text to remove accents from.\n * @returns {string} The text with accents removed.\n */\nfunction remove_accents(text) {\n    return text.replace(/[\\u0300-\\u036f]/g, '');\n}\n\n/**\n * Helper function to lowercase a string and remove accents.\n * @param {string} text The text to lowercase and remove accents from.\n * @returns {string} The lowercased text with accents removed.\n */\nfunction lowercase_and_remove_accent(text) {\n    return remove_accents(text.toLowerCase());\n}\n\n/**\n * Helper function to fuse consecutive values in an array equal to the specified value.\n * @param {string[]} arr The input array\n * @param {any} value The value to fuse on.\n * @param {Map<string, any>} mapping The mapping from input domain to value.\n */\nfunction fuse(arr, value, mapping) {\n    const fused = [];\n    let i = 0;\n    while (i < arr.length) {\n        fused.push(arr[i])\n        if ((mapping.get(arr[i]) ?? value) !== value) {\n            ++i;\n            continue;\n        }\n\n        while (i < arr.length && (mapping.get(arr[i]) ?? value) === value) {\n            ++i;\n        }\n    }\n\n    return fused;\n}\n\n/**\n * Split a string on whitespace.\n * @param {string} text The text to split.\n * @returns {string[]} The split string.\n */\nfunction whitespace_split(text) {\n    return text.match(/\\S+/g) || [];\n}\n\nconst PUNCTUATION_REGEX = '\\\\p{P}\\\\u0021-\\\\u002F\\\\u003A-\\\\u0040\\\\u005B-\\\\u0060\\\\u007B-\\\\u007E';\n\n// A mapping of regex patterns to their equivalent (but longer) JS-compatible versions.\nconst PROBLEMATIC_REGEX_MAP = new Map([\n    // This uses the case insensitive group modifier, which is not supported in JavaScript.\n    // When parsing the regex, an \"Invalid group\" error is thrown.\n    [\"(?i:'s|'t|'re|'ve|'m|'ll|'d)\", \"(?:'([sS]|[tT]|[rR][eE]|[vV][eE]|[mM]|[lL][lL]|[dD]))\"],\n])\n\n\n/**\n * Represent a token added by the user on top of the existing Model vocabulary.\n * AddedToken can be configured to specify the behavior they should have in various situations like:\n *   - Whether they should only match single words\n *   - Whether to include any whitespace on its left or right\n */\nclass AddedToken {\n    /**\n     * Creates a new instance of AddedToken.\n     * @param {Object} config Added token configuration object.\n     * @param {string} config.content The content of the added token.\n     * @param {number} config.id The id of the added token.\n     * @param {boolean} [config.single_word=false] Whether this token must be a single word or can break words.\n     * @param {boolean} [config.lstrip=false] Whether this token should strip whitespaces on its left.\n     * @param {boolean} [config.rstrip=false] Whether this token should strip whitespaces on its right.\n     * @param {boolean} [config.normalized=false] Whether this token should be normalized.\n     * @param {boolean} [config.special=false] Whether this token is special.\n     */\n    constructor(config) {\n        this.content = config.content;\n        this.id = config.id;\n        this.single_word = config.single_word ?? false;\n        this.lstrip = config.lstrip ?? false;\n        this.rstrip = config.rstrip ?? false;\n        this.special = config.special ?? false;\n        this.normalized = config.normalized ?? null;\n    }\n}\n\n/**\n * Abstract base class for tokenizer models.\n *\n * @extends Callable\n */\nclass TokenizerModel extends _utils_core_js__WEBPACK_IMPORTED_MODULE_0__.Callable {\n    /**\n     * Creates a new instance of TokenizerModel.\n     * @param {Object} config The configuration object for the TokenizerModel.\n     */\n    constructor(config) {\n        super();\n        this.config = config;\n\n        /** @type {string[]} */\n        this.vocab = [];\n\n        /**\n         * A mapping of tokens to ids.\n         * @type {Map<string, number>}\n         */\n        this.tokens_to_ids = new Map();\n\n        this.unk_token_id = undefined;\n        this.unk_token = undefined;\n        this.end_of_word_suffix = undefined;\n\n        /** @type {boolean} Whether to fuse unknown tokens when encoding. Defaults to false. */\n        this.fuse_unk = this.config.fuse_unk ?? false;\n    }\n\n    /**\n     * Instantiates a new TokenizerModel instance based on the configuration object provided.\n     * @param {Object} config The configuration object for the TokenizerModel.\n     * @param {...*} args Optional arguments to pass to the specific TokenizerModel constructor.\n     * @returns {TokenizerModel} A new instance of a TokenizerModel.\n     * @throws Will throw an error if the TokenizerModel type in the config is not recognized.\n     */\n    static fromConfig(config, ...args) {\n        switch (config.type) {\n            case 'WordPiece':\n                return new WordPieceTokenizer(config);\n            case 'Unigram':\n                // @ts-ignore\n                return new Unigram(config, ...args);\n\n            case 'BPE':\n                return new BPE(config);\n\n            default:\n                if (config.vocab) {\n                    // @ts-ignore\n                    return new LegacyTokenizerModel(config, ...args);\n                }\n                throw new Error(`Unknown TokenizerModel type: ${config.type}`);\n        }\n    }\n\n    /**\n     * Internal function to call the TokenizerModel instance.\n     * @param {string[]} tokens The tokens to encode.\n     * @returns {string[]} The encoded token IDs.\n     */\n    _call(tokens) {\n        let ids = this.encode(tokens);\n        if (this.fuse_unk) {\n            // Fuse unknown tokens\n            ids = fuse(ids, this.unk_token_id, this.tokens_to_ids);\n        }\n        return ids;\n    }\n\n    /**\n     * Encodes a list of tokens into a list of token IDs.\n     * @param {string[]} tokens The tokens to encode.\n     * @returns {string[]} The encoded tokens.\n     * @throws Will throw an error if not implemented in a subclass.\n     */\n    encode(tokens) {\n        throw Error(\"encode should be implemented in subclass.\")\n    }\n\n    /**\n     * Converts a list of tokens into a list of token IDs.\n     * @param {string[]} tokens The tokens to convert.\n     * @returns {number[]} The converted token IDs.\n     */\n    convert_tokens_to_ids(tokens) {\n        return tokens.map(t => this.tokens_to_ids.get(t) ?? this.unk_token_id);\n    }\n\n    /**\n     * Converts a list of token IDs into a list of tokens.\n     * @param {number[]} ids The token IDs to convert.\n     * @returns {string[]} The converted tokens.\n     */\n    convert_ids_to_tokens(ids) {\n        return ids.map(i => this.vocab[i] ?? this.unk_token);\n    }\n}\n\n/**\n * A subclass of TokenizerModel that uses WordPiece encoding to encode tokens.\n * @extends TokenizerModel\n */\nclass WordPieceTokenizer extends TokenizerModel {\n    /**\n     * @param {Object} config The configuration object.\n     * @param {Object} config.vocab A mapping of tokens to ids.\n     * @param {string} config.unk_token The unknown token string.\n     * @param {string} config.continuing_subword_prefix The prefix to use for continuing subwords.\n     * @param {number} [config.max_input_chars_per_word=100] The maximum number of characters per word.\n     */\n    constructor(config) {\n        super(config);\n        /**\n         * A mapping of tokens to ids.\n         * @type {Map<string, number>}\n         */\n        this.tokens_to_ids = objectToMap(config.vocab);\n\n        /**\n         * The id of the unknown token.\n         * @type {number}\n         */\n        this.unk_token_id = this.tokens_to_ids.get(config.unk_token);\n\n        /**\n         * The unknown token string.\n         * @type {string}\n         */\n        this.unk_token = config.unk_token;\n\n        /**\n         * The maximum number of characters allowed per word.\n         * @type {number}\n         */\n        this.max_input_chars_per_word = config.max_input_chars_per_word ?? 100;\n\n        /**\n         * An array of tokens.\n         * @type {string[]}\n         */\n        this.vocab = new Array(this.tokens_to_ids.size);\n        for (const [key, value] of this.tokens_to_ids) {\n            this.vocab[value] = key;\n        }\n    }\n\n    /**\n     * Encodes an array of tokens using WordPiece encoding.\n     * @param {string[]} tokens The tokens to encode.\n     * @returns {string[]} An array of encoded tokens.\n     */\n    encode(tokens) {\n        const outputTokens = [];\n        for (const token of tokens) {\n            const chars = [...token];\n            if (chars.length > this.max_input_chars_per_word) {\n                outputTokens.push(this.unk_token);\n                continue;\n            }\n\n            let isUnknown = false;\n            let start = 0;\n            const subTokens = [];\n\n            while (start < chars.length) {\n                let end = chars.length;\n                let currentSubstring = null;\n                while (start < end) {\n                    let substr = chars.slice(start, end).join('');\n\n                    if (start > 0) {\n                        substr = this.config.continuing_subword_prefix + substr;\n                    }\n                    if (this.tokens_to_ids.has(substr)) {\n                        currentSubstring = substr;\n                        break;\n                    }\n\n                    --end;\n                }\n                if (currentSubstring === null) {\n                    isUnknown = true;\n                    break;\n                }\n                subTokens.push(currentSubstring);\n                start = end;\n            }\n            if (isUnknown) {\n                outputTokens.push(this.unk_token);\n            } else {\n                outputTokens.push(...subTokens);\n            }\n        }\n\n        return outputTokens;\n    }\n\n}\n\n/**\n * Class representing a Unigram tokenizer model.\n * @extends TokenizerModel\n */\nclass Unigram extends TokenizerModel {\n    /**\n     * Create a new Unigram tokenizer model.\n     * @param {Object} config The configuration object for the Unigram model.\n     * @param {number} config.unk_id The ID of the unknown token\n     * @param {any[][]} config.vocab A 2D array representing a mapping of tokens to scores.\n     * @param {Object} moreConfig Additional configuration object for the Unigram model.\n     */\n    constructor(config, moreConfig) {\n        super(config);\n\n        const vocabSize = config.vocab.length;\n        this.vocab = new Array(vocabSize);\n        this.scores = new Array(vocabSize);\n        for (let i = 0; i < vocabSize; ++i) {\n            const piece = config.vocab[i];\n            this.vocab[i] = piece[0];\n            this.scores[i] = piece[1];\n        }\n\n        this.unk_token_id = config.unk_id;\n        this.unk_token = this.vocab[config.unk_id];\n\n        this.tokens_to_ids = new Map(this.vocab.map((x, i) => [x, i]));\n        this.bosToken = ' '; // beginning of a sentence token\n\n        this.bosTokenId = this.tokens_to_ids.get(this.bosToken); // NOTE: may be undefined\n        this.eosToken = moreConfig.eos_token;\n\n        this.eosTokenId = this.tokens_to_ids.get(this.eosToken);\n        this.unkToken = this.vocab[this.unk_token_id];\n\n        this.minScore = (0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_2__.min)(this.scores)[0];\n\n        this.unkScore = this.minScore - 10.0;\n        this.scores[this.unk_token_id] = this.unkScore;\n\n        this.trie = new _utils_data_structures_js__WEBPACK_IMPORTED_MODULE_4__.CharTrie();\n        this.trie.extend(this.vocab);\n\n        // NOTE: `fuse_unk` is hardcoded to true for Unigram models\n        // See: https://github.com/huggingface/tokenizers/blob/b58227c7f1ccf8b73ee2268354336da56d91e492/tokenizers/src/models/unigram/model.rs#L119\n        this.fuse_unk = true;\n    }\n\n    /**\n     * Populates lattice nodes.\n     * @param {TokenLattice} lattice The token lattice to populate with nodes.\n     */\n    populateNodes(lattice) {\n        const sentence = lattice.sentence;\n        const len = sentence.length;\n        let beginPos = 0;\n        while (beginPos < len) {\n            const mblen = 1;\n            let hasSingleNode = false;\n            const tokens = [];\n\n            for (let token of this.trie.commonPrefixSearch(sentence.slice(beginPos))) {\n                tokens.push(token);\n                const tokenId = this.tokens_to_ids.get(token);\n                const tokenScore = this.scores[tokenId];\n                const n = token.length;\n                lattice.insert(beginPos, n, tokenScore, tokenId);\n                if (!hasSingleNode && n === mblen) {\n                    hasSingleNode = true;\n                }\n            }\n            if (!hasSingleNode) {\n                lattice.insert(beginPos, mblen, this.unkScore, this.unk_token_id);\n            }\n            beginPos += mblen;\n        }\n    }\n\n    /**\n     * Encodes an array of tokens into an array of subtokens using the unigram model.\n     *\n     * @param {string} normalized The normalized string.\n     * @returns {string[]} An array of subtokens obtained by encoding the input tokens using the unigram model.\n     */\n    tokenize(normalized) {\n        const lattice = new _utils_data_structures_js__WEBPACK_IMPORTED_MODULE_4__.TokenLattice(normalized, this.bosTokenId, this.eosTokenId);\n        this.populateNodes(lattice);\n        return lattice.tokens();\n    }\n\n    /**\n     * Encodes an array of tokens using Unigram encoding.\n     * @param {string[]} tokens The tokens to encode.\n     * @returns {string[]} An array of encoded tokens.\n     */\n    encode(tokens) {\n        const toReturn = [];\n        for (const token of tokens) {\n            const tokenized = this.tokenize(token);\n            toReturn.push(...tokenized);\n        }\n        return toReturn;\n    }\n\n}\n\n/**\n * Returns list of utf-8 byte and a mapping to unicode strings.\n * Specifically avoids mapping to whitespace/control characters the BPE code barfs on.\n * @returns {Object} Object with utf-8 byte keys and unicode string values.\n */\nconst BYTES_TO_UNICODE = (() => {\n    // Returns list of utf-8 byte and a mapping to unicode strings.\n    // We specifically avoids mapping to whitespace/control characters\n    // the bpe code barfs on.\n\n    const bs = [\n        ...Array.from({ length: \"~\".charCodeAt(0) - \"!\".charCodeAt(0) + 1 }, (_, i) => i + \"!\".charCodeAt(0)),\n        ...Array.from({ length: \"\".charCodeAt(0) - \"\".charCodeAt(0) + 1 }, (_, i) => i + \"\".charCodeAt(0)),\n        ...Array.from({ length: \"\".charCodeAt(0) - \"\".charCodeAt(0) + 1 }, (_, i) => i + \"\".charCodeAt(0)),\n    ];\n    const cs = bs.slice();\n    let n = 0;\n    for (let b = 0; b < 256; ++b) {\n        if (!bs.includes(b)) {\n            bs.push(b);\n            cs.push(256 + n);\n            n += 1;\n        }\n    }\n    const ccs = cs.map(n => String.fromCharCode(n));\n    return Object.fromEntries(bs.map((b, i) => [b, ccs[i]]));\n})();\n\nconst UNICODE_TO_BYTES = (0,_utils_core_js__WEBPACK_IMPORTED_MODULE_0__.reverseDictionary)(BYTES_TO_UNICODE);\n\n\n/**\n * @typedef {Object} BPENode\n * @property {string} token The token associated with the node\n * @property {number} bias A positional bias for the node.\n * @property {number} [score] The score of the node.\n * @property {BPENode} [prev] The previous node in the linked list.\n * @property {BPENode} [next] The next node in the linked list.\n */\n\n/**\n * BPE class for encoding text into Byte-Pair-Encoding (BPE) tokens.\n * @extends TokenizerModel\n */\nclass BPE extends TokenizerModel {\n    /**\n     * Create a BPE instance.\n     * @param {Object} config The configuration object for BPE.\n     * @param {Object} config.vocab A mapping of tokens to ids.\n     * @param {string} config.unk_token The unknown token used for out of vocabulary words.\n     * @param {string} config.end_of_word_suffix The suffix to place at the end of each word.\n     * @param {string} [config.continuing_subword_suffix] The suffix to insert between words.\n     * @param {Array} config.merges An array of BPE merges as strings.\n     */\n    constructor(config) {\n        super(config);\n\n        this.BPE_SPLIT_TOKEN = ' ';\n\n        /** @type {Map<string, number>} */\n        this.tokens_to_ids = objectToMap(config.vocab);\n\n        this.unk_token_id = this.tokens_to_ids.get(config.unk_token);\n        this.unk_token = config.unk_token;\n\n        this.vocab = new Array(this.tokens_to_ids.size);\n        for (const [key, value] of this.tokens_to_ids) {\n            this.vocab[value] = key;\n        }\n\n        this.bpe_ranks = new Map(config.merges.map((x, i) => [x, i]));\n        this.merges = config.merges.map(x => x.split(this.BPE_SPLIT_TOKEN));\n\n        this.end_of_word_suffix = config.end_of_word_suffix;\n\n        // NOTE: `continuing_subword_suffix` is custom (to support `BlenderbotSmallTokenizer`)\n        this.continuing_subword_suffix = config.continuing_subword_suffix ?? null;\n\n        this.byte_fallback = this.config.byte_fallback ?? false;\n\n        if (this.byte_fallback) {\n            this.text_encoder = new TextEncoder();\n        }\n\n        /** @type {Map<string, string[]>} */\n        this.cache = new Map();\n    }\n\n    /**\n     * Apply Byte-Pair-Encoding (BPE) to a given token. Efficient heap-based priority\n     * queue implementation adapted from https://github.com/belladoreai/llama-tokenizer-js.\n     * @param {string} token The token to encode.\n     * @returns {string[]} The BPE encoded tokens.\n     */\n    bpe(token) {\n        if (token.length === 0) {\n            return [];\n        }\n\n        const cached = this.cache.get(token);\n        if (cached !== undefined) {\n            return cached;\n        }\n\n        const word = Array.from(token);\n        if (this.end_of_word_suffix) {\n            word[word.length - 1] += this.end_of_word_suffix;\n        }\n\n        let result = [];\n        if (word.length > 1) {\n            // Create a priority queue to store the nodes that will be merged.\n            // The comparator function compares the scores of the nodes.\n            const queue = new _utils_data_structures_js__WEBPACK_IMPORTED_MODULE_4__.PriorityQueue((a, b) => a.score < b.score);\n\n            // Construct a doubly-linked list of nodes that will be inserted into the priority queue,\n            // starting with the individual characters. We also populate each node with a positional\n            // bias to break ties in the priority queue.\n            let startingNode = {\n                token: word[0],\n                bias: 0,\n                prev: null,\n                next: null,\n            }\n\n            let previousNode = startingNode\n            for (let i = 1; i < word.length; ++i) {\n                const currentNode = {\n                    bias: i / word.length, // Add fractional component to break ties\n                    token: word[i],\n                    prev: previousNode,\n                    next: null,\n                }\n                previousNode.next = currentNode\n                this._add_node(queue, previousNode)\n                previousNode = currentNode\n            }\n\n            while (!queue.isEmpty()) {\n                // Get the next node with the highest priority\n                const node = queue.pop();\n\n                // Check that this merge is still possible\n                if (node.deleted || !node.next || node.next.deleted) continue;\n\n                // Here, we mark the current node (left side of the merge) and the next node (right side of the merge) as deleted.\n                // This is because they will both be replaced by a new node representing the merge result.\n                node.deleted = true;\n                node.next.deleted = true;\n\n                // Next, we fix the node that comes before the current node (i.e., left side of the merge).\n                if (node.prev) {\n\n                    // Make a shallow copy of the previous node\n                    const newPreviousNode = { ...node.prev };\n\n                    // Mark the old previous node as deleted. This avoids erroneous merges later,\n                    // because there may still be references to this node in the priority queue.\n                    node.prev.deleted = true;\n                    node.prev = newPreviousNode;\n\n                    // Update the reference of the previous node, by pointing its previous node to this new previous node.\n                    if (newPreviousNode.prev) {\n                        newPreviousNode.prev.next = newPreviousNode;\n                    } else {\n                        // If the previous of the previous node does not exist, it means that\n                        // `newPreviousNode` must be the new `startingNode`.\n                        startingNode = newPreviousNode;\n                    }\n                }\n\n                // Create a new node which represents the result of the merge.\n                const merged = {\n                    token: node.token + node.next.token,\n                    bias: node.bias,\n                    prev: node.prev,\n                    next: node.next.next,\n                }\n\n                // We now consider where we can add the new merged node to the priority queue:\n                // 1. prev <-> merged\n                if (merged.prev) {\n                    merged.prev.next = merged;\n                    this._add_node(queue, merged.prev);\n                } else {\n                    // If `merged.prev` does not exist, then `merged` must be the new `startingNode`.\n                    startingNode = merged;\n                }\n\n                // 2. merged <-> next\n                if (merged.next) {\n                    merged.next.prev = merged;\n                    this._add_node(queue, merged);\n                }\n            }\n\n            // Traverse the linked list, starting from the `startingNode`, and collect the tokens.\n            for (let currentNode = startingNode; currentNode !== null; currentNode = currentNode.next) {\n                result.push(currentNode.token);\n            }\n        } else {\n            result = word;\n        }\n\n        // Possibly append suffix\n        if (this.continuing_subword_suffix) {\n            // Do not append suffix to the last token\n            for (let i = 0; i < result.length - 1; ++i) {\n                result[i] += this.continuing_subword_suffix;\n            }\n        }\n\n        // Save the result to the cache\n        this.cache.set(token, result);\n\n        return result;\n    }\n\n\n    /**\n     * Helper function to add a node to the priority queue.\n     * @param {PriorityQueue} queue \n     * @param {BPENode} node\n     * @private\n     */\n    _add_node(queue, node) {\n        // `score` is a measure of the merge priority: lower means higher priority\n        // We use the BPE rank as a measure of priority (i.e., the local of the merge in the merges list)\n        // We also add a fractional component to the score to break ties (with the earlier character having higher priority)\n        const rank = this.bpe_ranks.get(node.token + this.BPE_SPLIT_TOKEN + node.next.token);\n        if (rank !== undefined) {\n            node.score = rank + node.bias;\n            queue.push(node);\n        }\n    }\n\n    /**\n     * Encodes the input sequence of tokens using the BPE algorithm and returns the resulting subword tokens.\n     * @param {string[]} tokens The input sequence of tokens to encode.\n     * @returns {string[]} The resulting subword tokens after applying the BPE algorithm to the input sequence of tokens.\n     */\n    encode(tokens) {\n        const outputTokens = [];\n\n        for (const token of tokens) {\n            const bpe_token_list = this.bpe(token);\n\n            for (const t of bpe_token_list) {\n                if (this.tokens_to_ids.has(t)) {\n                    outputTokens.push(t);\n                } else {\n                    if (this.byte_fallback) {\n                        outputTokens.push(\n                            ...Array.from(this.text_encoder.encode(t))\n                                .map(x => `<0x${x.toString(16).toUpperCase().padStart(2, '0')}>`)\n                        );\n                    } else {\n                        outputTokens.push(this.unk_token);\n                    }\n                }\n            }\n        }\n\n        return outputTokens;\n    }\n\n}\n\n/**\n * Legacy tokenizer class for tokenizers with only a vocabulary.\n */\nclass LegacyTokenizerModel extends TokenizerModel {\n    /**\n     * Create a LegacyTokenizerModel instance.\n     * @param {Object} config The configuration object for LegacyTokenizerModel.\n     * @param {Object} config.vocab A (possibly nested) mapping of tokens to ids.\n     * @param {Object} moreConfig Additional configuration object for the LegacyTokenizerModel model.\n     */\n    constructor(config, moreConfig) {\n        super(config);\n\n        /**@type {Map<string, number>} */\n        this.tokens_to_ids = objectToMap(\n            moreConfig.target_lang\n                ? config.vocab[moreConfig.target_lang]\n                : config.vocab\n        );\n\n        this.bos_token = moreConfig.bos_token;\n        this.bos_token_id = this.tokens_to_ids.get(this.bos_token);\n\n        this.eos_token = moreConfig.eos_token;\n        this.eos_token_id = this.tokens_to_ids.get(this.eos_token);\n\n        this.pad_token = moreConfig.pad_token;\n        this.pad_token_id = this.tokens_to_ids.get(this.pad_token);\n\n        this.unk_token = moreConfig.unk_token;\n        this.unk_token_id = this.tokens_to_ids.get(this.unk_token);\n\n        this.vocab = new Array(this.tokens_to_ids.size);\n        for (const [key, value] of this.tokens_to_ids) {\n            this.vocab[value] = key;\n        }\n    }\n\n    encode(tokens) {\n        return tokens;\n    }\n}\n\n\n/**\n * A base class for text normalization.\n * @abstract\n */\nclass Normalizer extends _utils_core_js__WEBPACK_IMPORTED_MODULE_0__.Callable {\n    /**\n     * @param {Object} config The configuration object for the normalizer.\n     */\n    constructor(config) {\n        super();\n        this.config = config;\n    }\n\n    /**\n     * Factory method for creating normalizers from config objects.\n     * @static\n     * @param {Object} config The configuration object for the normalizer.\n     * @returns {Normalizer} A Normalizer object.\n     * @throws {Error} If an unknown Normalizer type is specified in the config.\n     */\n    static fromConfig(config) {\n        if (config === null) return null;\n        switch (config.type) {\n            case 'BertNormalizer':\n                return new BertNormalizer(config);\n            case 'Precompiled':\n                return new Precompiled(config);\n            case 'Sequence':\n                return new NormalizerSequence(config);\n            case 'Replace':\n                return new Replace(config);\n            case 'NFC':\n                return new NFC(config);\n            case 'NFKC':\n                return new NFKC(config);\n            case 'NFKD':\n                return new NFKD(config);\n            case 'Strip':\n                return new StripNormalizer(config);\n            case 'StripAccents':\n                return new StripAccents(config);\n            case 'Lowercase':\n                return new Lowercase(config);\n            case 'Prepend':\n                return new Prepend(config);\n            default:\n                throw new Error(`Unknown Normalizer type: ${config.type}`);\n        }\n    }\n\n    /**\n     * Normalize the input text.\n     * @abstract\n     * @param {string} text The text to normalize.\n     * @returns {string} The normalized text.\n     * @throws {Error} If this method is not implemented in a subclass.\n     */\n    normalize(text) {\n        throw Error(\"normalize should be implemented in subclass.\")\n    }\n\n    /**\n     * Alias for {@link Normalizer#normalize}.\n     * @param {string} text The text to normalize.\n     * @returns {string} The normalized text.\n     */\n    _call(text) {\n        return this.normalize(text);\n    }\n\n}\n\n/**\n * Replace normalizer that replaces occurrences of a pattern with a given string or regular expression.\n * @extends Normalizer\n */\nclass Replace extends Normalizer {\n    /**\n     * Normalize the input text by replacing the pattern with the content.\n     * @param {string} text The input text to be normalized.\n     * @returns {string} The normalized text after replacing the pattern with the content.\n     */\n    normalize(text) {\n        const pattern = createPattern(this.config.pattern);\n        return pattern === null\n            ? text\n            : text.replaceAll(pattern, this.config.content);\n    }\n}\n\n/**\n * A normalizer that applies Unicode normalization form C (NFC) to the input text.\n * @extends Normalizer\n */\nclass NFC extends Normalizer {\n    /**\n     * Normalize the input text by applying Unicode normalization form C (NFC).\n     * @param {string} text The input text to be normalized.\n     * @returns {string} The normalized text.\n     */\n    normalize(text) {\n        text = text.normalize('NFC')\n        return text;\n    }\n}\n\n/**\n * NFKC Normalizer.\n * @extends Normalizer\n */\nclass NFKC extends Normalizer {\n    /**\n     * Normalize text using NFKC normalization.\n     * @param {string} text The text to be normalized.\n     * @returns {string} The normalized text.\n     */\n    normalize(text) {\n        text = text.normalize('NFKC')\n        return text;\n    }\n}\n/**\n * NFKD Normalizer.\n * @extends Normalizer\n */\nclass NFKD extends Normalizer {\n    /**\n     * Normalize text using NFKD normalization.\n     * @param {string} text The text to be normalized.\n     * @returns {string} The normalized text.\n     */\n    normalize(text) {\n        text = text.normalize('NFKD')\n        return text;\n    }\n}\n\n/**\n * A normalizer that strips leading and/or trailing whitespace from the input text.\n */\nclass StripNormalizer extends Normalizer {\n    /**\n     * Strip leading and/or trailing whitespace from the input text.\n     * @param {string} text The input text.\n     * @returns {string} The normalized text.\n     */\n    normalize(text) {\n        if (this.config.strip_left && this.config.strip_right) {\n            // Fast path to avoid an extra trim call\n            text = text.trim();\n        } else {\n            if (this.config.strip_left) {\n                text = text.trimStart();\n            }\n            if (this.config.strip_right) {\n                text = text.trimEnd();\n            }\n        }\n        return text;\n    }\n}\n\n/**\n * StripAccents normalizer removes all accents from the text.\n * @extends Normalizer\n */\nclass StripAccents extends Normalizer {\n    /**\n     * Remove all accents from the text.\n     * @param {string} text The input text.\n     * @returns {string} The normalized text without accents.\n     */\n    normalize(text) {\n        text = remove_accents(text);\n        return text;\n    }\n}\n\n/**\n * A Normalizer that lowercases the input string.\n * @extends Normalizer\n */\nclass Lowercase extends Normalizer {\n    /**\n     * Lowercases the input string.\n     * @param {string} text The text to normalize.\n     * @returns {string} The normalized text.\n     */\n    normalize(text) {\n        text = text.toLowerCase();\n        return text;\n    }\n}\n\n/**\n * A Normalizer that prepends a string to the input string.\n * @extends Normalizer\n */\nclass Prepend extends Normalizer {\n    /**\n     * Prepends the input string.\n     * @param {string} text The text to normalize.\n     * @returns {string} The normalized text.\n     */\n    normalize(text) {\n        text = this.config.prepend + text;\n        return text;\n    }\n}\n\n/**\n * A Normalizer that applies a sequence of Normalizers.\n * @extends Normalizer\n */\nclass NormalizerSequence extends Normalizer {\n    /**\n   * Create a new instance of NormalizerSequence.\n   * @param {Object} config The configuration object.\n   * @param {Object[]} config.normalizers An array of Normalizer configuration objects.\n   */\n    constructor(config) {\n        super(config);\n        this.normalizers = config.normalizers.map(x => Normalizer.fromConfig(x));\n    }\n    /**\n    * Apply a sequence of Normalizers to the input text.\n    * @param {string} text The text to normalize.\n    * @returns {string} The normalized text.\n    */\n    normalize(text) {\n        return this.normalizers.reduce((t, normalizer) => {\n            return normalizer.normalize(t);\n        }, text);\n    }\n}\n\n/**\n * A class representing a normalizer used in BERT tokenization.\n * @extends Normalizer\n */\nclass BertNormalizer extends Normalizer {\n    /**\n     * Adds whitespace around any CJK (Chinese, Japanese, or Korean) character in the input text.\n     *\n     * @param {string} text The input text to tokenize.\n     * @returns {string} The tokenized text with whitespace added around CJK characters.\n     */\n    _tokenize_chinese_chars(text) {\n        /* Adds whitespace around any CJK character. */\n        const output = [];\n        for (let i = 0; i < text.length; ++i) {\n            const char = text[i];\n            const cp = char.charCodeAt(0);\n            if (this._is_chinese_char(cp)) {\n                output.push(\" \");\n                output.push(char);\n                output.push(\" \");\n            } else {\n                output.push(char);\n            }\n        }\n        return output.join(\"\");\n    }\n\n    /**\n     * Checks whether the given Unicode codepoint represents a CJK (Chinese, Japanese, or Korean) character.\n     *\n     * A \"chinese character\" is defined as anything in the CJK Unicode block:\n     * https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)\n     *\n     * Note that the CJK Unicode block is NOT all Japanese and Korean characters, despite its name.\n     * The modern Korean Hangul alphabet is a different block, as is Japanese Hiragana and Katakana.\n     * Those alphabets are used to write space-separated words, so they are not treated specially\n     * and are handled like all other languages.\n     *\n     * @param {number} cp The Unicode codepoint to check.\n     * @returns {boolean} True if the codepoint represents a CJK character, false otherwise.\n     */\n    _is_chinese_char(cp) {\n        return (\n            (cp >= 0x4E00 && cp <= 0x9FFF)\n            || (cp >= 0x3400 && cp <= 0x4DBF)\n            || (cp >= 0x20000 && cp <= 0x2A6DF)\n            || (cp >= 0x2A700 && cp <= 0x2B73F)\n            || (cp >= 0x2B740 && cp <= 0x2B81F)\n            || (cp >= 0x2B820 && cp <= 0x2CEAF)\n            || (cp >= 0xF900 && cp <= 0xFAFF)\n            || (cp >= 0x2F800 && cp <= 0x2FA1F)\n        )\n    }\n    /**\n     * Strips accents from the given text.\n     * @param {string} text The text to strip accents from.\n     * @returns {string} The text with accents removed.\n     */\n    stripAccents(text) {\n        return text.normalize('NFD').replace(/[\\u0300-\\u036f]/g, '');\n    }\n\n\n    /**\n     * Checks whether `char` is a control character.\n     * @param {string} char The character to check.\n     * @returns {boolean} Whether `char` is a control character.\n     * @private\n     */\n    _is_control(char) {\n        switch (char) {\n            case '\\t':\n            case '\\n':\n            case '\\r':\n                // These are technically control characters but we count them as whitespace characters.\n                return false;\n\n            default:\n                // Check if unicode category starts with C:\n                // Cc - Control\n                // Cf - Format\n                // Co - Private Use\n                // Cs - Surrogate\n                return /^\\p{Cc}|\\p{Cf}|\\p{Co}|\\p{Cs}$/u.test(char);\n        }\n    }\n\n    /**\n     * Performs invalid character removal and whitespace cleanup on text.\n     * @param {string} text The text to clean.\n     * @returns {string} The cleaned text.\n     * @private\n     */\n    _clean_text(text) {\n        const output = [];\n        for (const char of text) {\n            const cp = char.charCodeAt(0);\n            if (cp === 0 || cp === 0xFFFD || this._is_control(char)) {\n                continue;\n            }\n            if (/^\\s$/.test(char)) { // is whitespace\n                output.push(\" \");\n            } else {\n                output.push(char);\n            }\n        }\n        return output.join(\"\");\n    }\n    /**\n     * Normalizes the given text based on the configuration.\n     * @param {string} text The text to normalize.\n     * @returns {string} The normalized text.\n     */\n    normalize(text) {\n        if (this.config.clean_text) {\n            text = this._clean_text(text);\n        }\n\n        if (this.config.handle_chinese_chars) {\n            text = this._tokenize_chinese_chars(text);\n        }\n\n        if (this.config.lowercase) {\n            text = text.toLowerCase();\n\n            if (this.config.strip_accents !== false) {\n                text = this.stripAccents(text);\n            }\n        } else if (this.config.strip_accents) {\n            text = this.stripAccents(text);\n        }\n\n        return text;\n    }\n}\n\n/**\n * A callable class representing a pre-tokenizer used in tokenization. Subclasses\n * should implement the `pre_tokenize_text` method to define the specific pre-tokenization logic.\n * @extends Callable\n */\nclass PreTokenizer extends _utils_core_js__WEBPACK_IMPORTED_MODULE_0__.Callable {\n    /**\n   * Factory method that returns an instance of a subclass of `PreTokenizer` based on the provided configuration.\n   *\n   * @static\n   * @param {Object} config A configuration object for the pre-tokenizer.\n   * @returns {PreTokenizer} An instance of a subclass of `PreTokenizer`.\n   * @throws {Error} If the provided configuration object does not correspond to any known pre-tokenizer.\n   */\n    static fromConfig(config) {\n        if (config === null) return null;\n\n        switch (config.type) {\n            case 'BertPreTokenizer':\n                return new BertPreTokenizer(config);\n            case 'Sequence':\n                return new PreTokenizerSequence(config);\n            case 'Whitespace':\n                return new WhitespacePreTokenizer(config);\n            case 'WhitespaceSplit':\n                return new WhitespaceSplit(config);\n            case 'Metaspace':\n                return new MetaspacePreTokenizer(config);\n\n            case 'ByteLevel':\n                return new ByteLevelPreTokenizer(config);\n            case 'Split':\n                return new SplitPreTokenizer(config);\n            case 'Punctuation':\n                return new PunctuationPreTokenizer(config);\n            case 'Digits':\n                return new DigitsPreTokenizer(config);\n            case 'Replace':\n                return new ReplacePreTokenizer(config);\n            default:\n                throw new Error(`Unknown PreTokenizer type: ${config.type}`);\n        }\n    }\n\n    /**\n     * Method that should be implemented by subclasses to define the specific pre-tokenization logic.\n     *\n     * @abstract\n     * @param {string} text The text to pre-tokenize.\n     * @param {Object} [options] Additional options for the pre-tokenization logic.\n     * @returns {string[]} The pre-tokenized text.\n     * @throws {Error} If the method is not implemented in the subclass.\n     */\n    pre_tokenize_text(text, options) {\n        throw Error(\"pre_tokenize_text should be implemented in subclass.\")\n    }\n\n    /**\n     * Tokenizes the given text into pre-tokens.\n     * @param {string|string[]} text The text or array of texts to pre-tokenize.\n     * @param {Object} [options] Additional options for the pre-tokenization logic.\n     * @returns {string[]} An array of pre-tokens.\n     */\n    pre_tokenize(text, options) {\n        return (Array.isArray(text)\n            ? text.map(x => this.pre_tokenize_text(x, options))\n            : this.pre_tokenize_text(text, options)\n        ).flat();\n    }\n\n    /**\n     * Alias for {@link PreTokenizer#pre_tokenize}.\n     * @param {string|string[]} text The text or array of texts to pre-tokenize.\n     * @param {Object} [options] Additional options for the pre-tokenization logic.\n     * @returns {string[]} An array of pre-tokens.\n     */\n    _call(text, options) {\n        return this.pre_tokenize(text, options);\n    }\n}\n\n/**\n * @extends PreTokenizer\n */\nclass BertPreTokenizer extends PreTokenizer {\n    /**\n     * A PreTokenizer that splits text into wordpieces using a basic tokenization scheme\n     * similar to that used in the original implementation of BERT.\n     * \n     * @param {Object} config The configuration object.\n     */\n    constructor(config) {\n        super();\n        // Construct a pattern which matches the rust implementation:\n        // https://github.com/huggingface/tokenizers/blob/b4fcc9ce6e4ad5806e82826f816acfdfdc4fcc67/tokenizers/src/pre_tokenizers/bert.rs#L11\n        // Equivalent to removing whitespace and splitting on punctuation (both \\p{P} and other ascii characters)\n        this.pattern = new RegExp(`[^\\\\s${PUNCTUATION_REGEX}]+|[${PUNCTUATION_REGEX}]`, 'gu');\n    }\n    /**\n     * Tokenizes a single text using the BERT pre-tokenization scheme.\n     * \n     * @param {string} text The text to tokenize.\n     * @param {Object} [options] Additional options for the pre-tokenization logic.\n     * @returns {string[]} An array of tokens.\n     */\n    pre_tokenize_text(text, options) {\n        return text.trim().match(this.pattern) || [];\n    }\n}\n\n/**\n * A pre-tokenizer that splits text into Byte-Pair-Encoding (BPE) subwords.\n * @extends PreTokenizer\n */\nclass ByteLevelPreTokenizer extends PreTokenizer {\n    /**\n     * Creates a new instance of the `ByteLevelPreTokenizer` class.\n     * @param {Object} config The configuration object.\n     */\n    constructor(config) {\n        super();\n        this.config = config;\n\n        /**\n         * @type {boolean} Whether to add a leading space to the first word.\n         * This allows to treat the leading word just as any other word.\n         */\n        this.add_prefix_space = this.config.add_prefix_space;\n\n        /**\n         * @type {boolean} Whether the post processing step should trim offsets\n         * to avoid including whitespaces.\n         * @todo Use this in the pretokenization step.\n         */\n        this.trim_offsets = this.config.trim_offsets;\n\n        /**\n         * @type {boolean} Whether to use the standard GPT2 regex for whitespace splitting.\n         * Set it to False if you want to use your own splitting. Defaults to true.\n         */\n        this.use_regex = this.config.use_regex ?? true;\n        this.pattern = /'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+/gu;\n\n        this.byte_encoder = BYTES_TO_UNICODE;\n        this.text_encoder = new TextEncoder();\n    }\n\n    /**\n     * Tokenizes a single piece of text using byte-level tokenization.\n     * @param {string} text The text to tokenize.\n     * @param {Object} [options] Additional options for the pre-tokenization logic.\n     * @returns {string[]} An array of tokens.\n     */\n    pre_tokenize_text(text, options) {\n        // Add a leading space if the option is enabled\n        if (this.add_prefix_space && !text.startsWith(' ')) {\n            text = ' ' + text;\n        }\n\n        // Split on whitespace and punctuation\n        const tokens = this.use_regex ? (text.match(this.pattern) || []) : [text];\n\n        // Maps all our bytes to unicode strings, avoiding control tokens of the BPE (spaces in our case)\n        return tokens.map(\n            token => Array.from(this.text_encoder.encode(token), byte => this.byte_encoder[byte]).join('')\n        );\n    }\n}\n\n/**\n * @typedef {'removed'|'isolated'|'mergedWithPrevious'|'mergedWithNext'|'contiguous'} SplitDelimiterBehavior\n */\n\n/**\n * Splits text using a given pattern.\n * @extends PreTokenizer\n */\nclass SplitPreTokenizer extends PreTokenizer {\n    /**\n     * @param {Object} config The configuration options for the pre-tokenizer.\n     * @param {Object} config.pattern The pattern used to split the text. Can be a string or a regex object.\n     * @param {string|undefined} config.pattern.String The string to use for splitting. Only defined if the pattern is a string.\n     * @param {string|undefined} config.pattern.Regex The regex to use for splitting. Only defined if the pattern is a regex.\n     * @param {SplitDelimiterBehavior} config.behavior The behavior to use when splitting.\n     * @param {boolean} config.invert Whether to split (invert=false) or match (invert=true) the pattern.\n     */\n    constructor(config) {\n        super();\n        this.config = config;\n        // TODO support all behaviours (config.behavior)\n\n        this.pattern = createPattern(this.config.pattern, this.config.invert);\n    }\n\n    /**\n     * Tokenizes text by splitting it using the given pattern.\n     * @param {string} text The text to tokenize.\n     * @param {Object} [options] Additional options for the pre-tokenization logic.\n     * @returns {string[]} An array of tokens.\n     */\n    pre_tokenize_text(text, options) {\n        if (this.pattern === null) {\n            return [];\n        }\n\n        if (this.config.invert) {\n            return text.match(this.pattern) || [];\n        } else {\n            return regexSplit(text, this.pattern);\n        }\n    }\n}\n\n/**\n * Splits text based on punctuation.\n * @extends PreTokenizer\n */\nclass PunctuationPreTokenizer extends PreTokenizer {\n    /**\n     * @param {Object} config The configuration options for the pre-tokenizer.\n     * @param {SplitDelimiterBehavior} config.behavior The behavior to use when splitting.\n     */\n    constructor(config) {\n        super();\n        this.config = config;\n        this.pattern = new RegExp(`[^${PUNCTUATION_REGEX}]+|[${PUNCTUATION_REGEX}]+`, 'gu');\n    }\n\n    /**\n     * Tokenizes text by splitting it using the given pattern.\n     * @param {string} text The text to tokenize.\n     * @param {Object} [options] Additional options for the pre-tokenization logic.\n     * @returns {string[]} An array of tokens.\n     */\n    pre_tokenize_text(text, options) {\n        return text.match(this.pattern) || [];\n    }\n}\n\n\n/**\n * Splits text based on digits.\n * @extends PreTokenizer\n */\nclass DigitsPreTokenizer extends PreTokenizer {\n    /**\n     * @param {Object} config The configuration options for the pre-tokenizer.\n     * @param {boolean} config.individual_digits Whether to split on individual digits.\n     */\n    constructor(config) {\n        super();\n        this.config = config;\n\n        // Construct a pattern which matches the rust implementation:\n        const digit_pattern = `[^\\\\d]+|\\\\d${this.config.individual_digits ? '' : '+'}`;\n        this.pattern = new RegExp(digit_pattern, 'gu');\n    }\n\n    /**\n     * Tokenizes text by splitting it using the given pattern.\n     * @param {string} text The text to tokenize.\n     * @param {Object} [options] Additional options for the pre-tokenization logic.\n     * @returns {string[]} An array of tokens.\n     */\n    pre_tokenize_text(text, options) {\n        return text.match(this.pattern) || [];\n    }\n}\n\n/**\n * @typedef {Object} PostProcessedOutput\n * @property {string[]} tokens List of token produced by the post-processor.\n * @property {number[]} [token_type_ids] List of token type ids produced by the post-processor.\n */\n\n\n/**\n * @typedef {Object} EncodingSingle\n * @property {number[]} input_ids List of token ids to be fed to a model.\n * @property {number[]} attention_mask List of token type ids to be fed to a model\n * @property {number[]} [token_type_ids] List of indices specifying which tokens should be attended to by the model\n */\n\n\n/**\n * @extends Callable\n */\nclass PostProcessor extends _utils_core_js__WEBPACK_IMPORTED_MODULE_0__.Callable {\n\n    /**\n     * @param {Object} config The configuration for the post-processor.\n     */\n    constructor(config) {\n        super();\n        this.config = config;\n    }\n\n    /**\n     * Factory method to create a PostProcessor object from a configuration object.\n     *\n     * @param {Object} config Configuration object representing a PostProcessor.\n     * @returns {PostProcessor} A PostProcessor object created from the given configuration.\n     * @throws {Error} If an unknown PostProcessor type is encountered.\n     */\n    static fromConfig(config) {\n        if (config === null) return null;\n        switch (config.type) {\n            case 'TemplateProcessing':\n                return new TemplateProcessing(config);\n\n            case 'ByteLevel':\n                return new ByteLevelPostProcessor(config);\n\n            case 'RobertaProcessing':\n                return new RobertaProcessing(config);\n            case 'BertProcessing':\n                return new BertProcessing(config);\n\n            default:\n                throw new Error(`Unknown PostProcessor type: ${config.type}`);\n        }\n    }\n\n    /**\n     * Method to be implemented in subclass to apply post-processing on the given tokens.\n     *\n     * @param {Array} tokens The input tokens to be post-processed.\n     * @param {...*} args Additional arguments required by the post-processing logic.\n     * @returns {PostProcessedOutput} The post-processed tokens.\n     * @throws {Error} If the method is not implemented in subclass.\n     */\n    post_process(tokens, ...args) {\n        throw Error(\"post_process should be implemented in subclass.\")\n    }\n\n    /**\n     * Alias for {@link PostProcessor#post_process}.\n     * @param {Array} tokens The text or array of texts to post-process.\n     * @param {...*} args Additional arguments required by the post-processing logic.\n     * @returns {PostProcessedOutput} The post-processed tokens.\n     */\n    _call(tokens, ...args) {\n        return this.post_process(tokens, ...args);\n    }\n}\n\n/**\n * A post-processor that adds special tokens to the beginning and end of the input.\n */\nclass BertProcessing extends PostProcessor {\n    /**\n     * @param {Object} config The configuration for the post-processor.\n     * @param {string[]} config.cls The special tokens to add to the beginning of the input.\n     * @param {string[]} config.sep The special tokens to add to the end of the input.\n     */\n    constructor(config) {\n        super(config);\n        // TODO use all of config: add_prefix_space, trim_offsets\n\n        this.cls = config.cls[0];\n        this.sep = config.sep[0];\n    }\n\n    /**\n     * Adds the special tokens to the beginning and end of the input.\n     * @param {string[]} tokens The input tokens.\n     * @param {string[]} [tokens_pair=null] An optional second set of input tokens.\n     * @returns {PostProcessedOutput} The post-processed tokens with the special tokens added to the beginning and end.\n     */\n    post_process(tokens, tokens_pair = null, {\n        add_special_tokens = true,\n    } = {}) {\n        if (add_special_tokens) {\n            tokens = (0,_utils_core_js__WEBPACK_IMPORTED_MODULE_0__.mergeArrays)([this.cls], tokens, [this.sep]);\n        }\n\n        let token_type_ids = new Array(tokens.length).fill(0);\n        if (tokens_pair !== null) {\n            // NOTE: It is intended to add 2 EOS tokens after the first set of tokens\n            // https://github.com/huggingface/tokenizers/issues/983\n            const middle = (add_special_tokens && this instanceof RobertaProcessing)\n                ? [this.sep]\n                : [];\n            const after = add_special_tokens ? [this.sep] : [];\n\n            tokens = (0,_utils_core_js__WEBPACK_IMPORTED_MODULE_0__.mergeArrays)(tokens, middle, tokens_pair, after);\n            token_type_ids = (0,_utils_core_js__WEBPACK_IMPORTED_MODULE_0__.mergeArrays)(token_type_ids, new Array(tokens_pair.length + middle.length + after.length).fill(1));\n        }\n        return { tokens, token_type_ids };\n    }\n}\nclass RobertaProcessing extends BertProcessing { } // NOTE: extends BertProcessing\n\n/**\n * Post processor that replaces special tokens in a template with actual tokens.\n * @extends PostProcessor\n */\nclass TemplateProcessing extends PostProcessor {\n    /**\n     * Creates a new instance of `TemplateProcessing`.\n     * @param {Object} config The configuration options for the post processor.\n     * @param {Array} config.single The template for a single sequence of tokens.\n     * @param {Array} config.pair The template for a pair of sequences of tokens.\n     */\n    constructor(config) {\n        super(config);\n\n        this.single = config.single;\n        this.pair = config.pair;\n    }\n\n    /**\n     * Replaces special tokens in the template with actual tokens.\n     * @param {string[]} tokens The list of tokens for the first sequence.\n     * @param {string[]} [tokens_pair=null] The list of tokens for the second sequence (optional).\n     * @returns {PostProcessedOutput} An object containing the list of tokens with the special tokens replaced with actual tokens.\n     */\n    post_process(tokens, tokens_pair = null, {\n        add_special_tokens = true,\n    } = {}) {\n        const type = tokens_pair === null ? this.single : this.pair\n\n        let processedTokens = [];\n        let types = [];\n        for (const item of type) {\n            if ('SpecialToken' in item) {\n                if (add_special_tokens) {\n                    processedTokens.push(item.SpecialToken.id);\n                    types.push(item.SpecialToken.type_id);\n                }\n            } else if ('Sequence' in item) {\n                if (item.Sequence.id === 'A') {\n                    processedTokens = (0,_utils_core_js__WEBPACK_IMPORTED_MODULE_0__.mergeArrays)(processedTokens, tokens);\n                    types = (0,_utils_core_js__WEBPACK_IMPORTED_MODULE_0__.mergeArrays)(types, new Array(tokens.length).fill(item.Sequence.type_id));\n\n                } else if (item.Sequence.id === 'B') {\n                    processedTokens = (0,_utils_core_js__WEBPACK_IMPORTED_MODULE_0__.mergeArrays)(processedTokens, tokens_pair);\n                    types = (0,_utils_core_js__WEBPACK_IMPORTED_MODULE_0__.mergeArrays)(types, new Array(tokens_pair.length).fill(item.Sequence.type_id));\n                }\n            }\n        }\n        return { tokens: processedTokens, token_type_ids: types };\n    }\n}\n\n/**\n * A PostProcessor that returns the given tokens as is.\n * @extends PostProcessor\n */\nclass ByteLevelPostProcessor extends PostProcessor {\n    /**\n     * Post process the given tokens.\n     * @param {string[]} tokens The list of tokens for the first sequence.\n     * @param {string[]} [tokens_pair=null] The list of tokens for the second sequence (optional).\n     * @returns {PostProcessedOutput} An object containing the post-processed tokens.\n     */\n    post_process(tokens, tokens_pair = null) {\n        if (tokens_pair) {\n            tokens = (0,_utils_core_js__WEBPACK_IMPORTED_MODULE_0__.mergeArrays)(tokens, tokens_pair);\n        }\n        return { tokens };\n    }\n}\n\n/**\n * The base class for token decoders.\n * @extends Callable\n */\nclass Decoder extends _utils_core_js__WEBPACK_IMPORTED_MODULE_0__.Callable {\n\n    /**\n    * Creates an instance of `Decoder`.\n    *\n    * @param {Object} config The configuration object.\n    */\n    constructor(config) {\n        super();\n        this.config = config;\n\n        /** @type {AddedToken[]} */\n        this.added_tokens = [];\n        this.end_of_word_suffix = null;\n        this.trim_offsets = config.trim_offsets;\n    }\n\n    /**\n   * Creates a decoder instance based on the provided configuration.\n   *\n   * @param {Object} config The configuration object.\n   * @returns {Decoder} A decoder instance.\n   * @throws {Error} If an unknown decoder type is provided.\n   */\n    static fromConfig(config) {\n        if (config === null) return null;\n        switch (config.type) {\n            case 'WordPiece':\n                return new WordPieceDecoder(config);\n            case 'Metaspace':\n                return new MetaspaceDecoder(config);\n            case 'ByteLevel':\n                return new ByteLevelDecoder(config);\n\n            case 'Replace':\n                return new ReplaceDecoder(config);\n            case 'ByteFallback':\n                return new ByteFallback(config);\n            case 'Fuse':\n                return new FuseDecoder(config);\n            case 'Strip':\n                return new StripDecoder(config);\n\n            case 'Sequence':\n                return new DecoderSequence(config);\n\n            case 'CTC':\n                return new CTCDecoder(config);\n            case 'BPEDecoder':\n                return new BPEDecoder(config);\n            default:\n                throw new Error(`Unknown Decoder type: ${config.type}`);\n        }\n    }\n\n    /**\n    * Calls the `decode` method.\n    *\n    * @param {string[]} tokens The list of tokens.\n    * @returns {string} The decoded string.\n    */\n    _call(tokens) {\n        return this.decode(tokens);\n    }\n\n    /**\n    * Decodes a list of tokens.\n    * @param {string[]} tokens The list of tokens.\n    * @returns {string} The decoded string.\n    */\n    decode(tokens) {\n        return this.decode_chain(tokens).join('');\n    }\n\n    /**\n     * Apply the decoder to a list of tokens.\n     * \n     * @param {string[]} tokens The list of tokens.\n     * @returns {string[]} The decoded list of tokens.\n     * @throws {Error} If the `decode_chain` method is not implemented in the subclass.\n     */\n    decode_chain(tokens) {\n        throw Error(\"`decode_chain` should be implemented in subclass.\")\n    }\n\n}\n\nclass ReplaceDecoder extends Decoder {\n\n    /** @type {Decoder['decode_chain']} */\n    decode_chain(tokens) {\n        const pattern = createPattern(this.config.pattern);\n        return pattern === null\n            ? tokens\n            : tokens.map(token => token.replaceAll(pattern, this.config.content))\n    }\n}\n\n\nclass ByteFallback extends Decoder {\n    constructor(config) {\n        super(config);\n\n        this.text_decoder = new TextDecoder();\n    }\n\n    /** @type {Decoder['decode_chain']} */\n    decode_chain(tokens) {\n\n        const new_tokens = [];\n        let previous_byte_tokens = [];\n\n        for (const token of tokens) {\n            let bytes = null;\n            if (token.length === 6 && token.startsWith('<0x') && token.endsWith('>')) {\n                const byte = parseInt(token.slice(3, 5), 16);\n                if (!isNaN(byte)) {\n                    bytes = byte;\n                }\n            }\n            if (bytes !== null) {\n                previous_byte_tokens.push(bytes);\n            } else {\n                if (previous_byte_tokens.length > 0) {\n                    const string = this.text_decoder.decode(Uint8Array.from(previous_byte_tokens));\n                    new_tokens.push(string);\n                    previous_byte_tokens = [];\n                }\n                new_tokens.push(token);\n            }\n        }\n        if (previous_byte_tokens.length > 0) {\n            const string = this.text_decoder.decode(Uint8Array.from(previous_byte_tokens));\n            new_tokens.push(string);\n            previous_byte_tokens = [];\n        }\n\n        return new_tokens;\n    }\n}\n\n/**\n * Fuse simply fuses all tokens into one big string.\n * It's usually the last decoding step anyway, but this decoder\n * exists incase some decoders need to happen after that step\n */\nclass FuseDecoder extends Decoder {\n\n    /** @type {Decoder['decode_chain']} */\n    decode_chain(tokens) {\n        return [tokens.join('')];\n    }\n}\n\n\nclass StripDecoder extends Decoder {\n    constructor(config) {\n        super(config);\n\n        this.content = this.config.content;\n        this.start = this.config.start;\n        this.stop = this.config.stop;\n    }\n\n    /** @type {Decoder['decode_chain']} */\n    decode_chain(tokens) {\n        return tokens.map(token => {\n            let start_cut = 0;\n            for (let i = 0; i < this.start; ++i) {\n                if (token[i] === this.content) {\n                    start_cut = i + 1;\n                    continue;\n                } else {\n                    break;\n                }\n            }\n\n            let stop_cut = token.length;\n            for (let i = 0; i < this.stop; ++i) {\n                const index = token.length - i - 1;\n                if (token[index] === this.content) {\n                    stop_cut = index;\n                    continue;\n                } else {\n                    break;\n                }\n            }\n\n            return token.slice(start_cut, stop_cut)\n        });\n    }\n}\n\n/**\n * A decoder that decodes a list of WordPiece tokens into a single string.\n * @extends Decoder\n */\nclass WordPieceDecoder extends Decoder {\n\n    /**\n     * Creates a new instance of WordPieceDecoder.\n     * @param {Object} config The configuration object.\n     * @param {string} config.prefix The prefix used for WordPiece encoding.\n     * @param {boolean} config.cleanup Whether to cleanup the decoded string.\n     */\n    constructor(config) {\n        super(config);\n        this.cleanup = config.cleanup;\n    }\n\n    /** @type {Decoder['decode_chain']} */\n    decode_chain(tokens) {\n        return tokens.map((token, i) => {\n            if (i !== 0) {\n                if (token.startsWith(this.config.prefix)) {\n                    // NOTE: .replace() is intended; only replace first occurrence\n                    token = token.replace(this.config.prefix, '');\n                } else {\n                    token = ' ' + token;\n                }\n            }\n            if (this.cleanup) {\n                token = clean_up_tokenization(token)\n            }\n\n            return token;\n        });\n    }\n}\n\n/**\n * Byte-level decoder for tokenization output. Inherits from the `Decoder` class.\n * @extends Decoder\n */\nclass ByteLevelDecoder extends Decoder {\n\n    /**\n     * Create a `ByteLevelDecoder` object.\n     * @param {Object} config Configuration object.\n     */\n    constructor(config) {\n        super(config);\n\n        this.byte_decoder = UNICODE_TO_BYTES;\n        this.text_decoder = new TextDecoder(\"utf-8\", {\n            fatal: false,\n            ignoreBOM: true,\n        });\n\n        this.end_of_word_suffix = null;\n    }\n\n    /**\n     * Convert an array of tokens to string by decoding each byte.\n     * @param {string[]} tokens Array of tokens to be decoded.\n     * @returns {string} The decoded string.\n     */\n    convert_tokens_to_string(tokens) {\n        const text = tokens.join('');\n        const byteArray = new Uint8Array([...text].map(c => this.byte_decoder[c]));\n        const decoded_text = this.text_decoder.decode(byteArray);\n        return decoded_text;\n    }\n\n    /** @type {Decoder['decode_chain']} */\n    decode_chain(tokens) {\n        // TODO move to base class (like HF)\n        // tokens === filtered_tokens\n\n        // To avoid mixing byte-level and unicode for byte-level BPT\n        // we need to build string separately for added tokens and byte-level tokens\n        // cf. https://github.com/huggingface/transformers/issues/1133\n        const sub_texts = [];\n        let current_sub_text = [];\n        for (const token of tokens) {\n            // tokens sent here are already filtered, so we don't need to do this\n            // if (skip_special_tokens && this.all_special_ids.includes(token)) {\n            //     continue;\n            // }\n\n            if (this.added_tokens.find(x => x.content === token) !== undefined) {\n                if (current_sub_text.length > 0) {\n                    sub_texts.push(this.convert_tokens_to_string(current_sub_text));\n                    current_sub_text = [];\n                }\n                sub_texts.push(token);\n            } else {\n                current_sub_text.push(token);\n            }\n        }\n        if (current_sub_text.length > 0) {\n            sub_texts.push(this.convert_tokens_to_string(current_sub_text));\n        }\n\n        // TODO add spaces_between_special_tokens and clean_up_tokenization_spaces options\n\n        return sub_texts;\n    }\n}\n\n/**\n * The CTC (Connectionist Temporal Classification) decoder.\n * See https://github.com/huggingface/tokenizers/blob/bb38f390a61883fc2f29d659af696f428d1cda6b/tokenizers/src/decoders/ctc.rs\n */\nclass CTCDecoder extends Decoder {\n\n    constructor(config) {\n        super(config);\n\n        this.pad_token = this.config.pad_token;\n        this.word_delimiter_token = this.config.word_delimiter_token;\n        this.cleanup = this.config.cleanup;\n    }\n    /**\n     * Converts a connectionist-temporal-classification (CTC) output tokens into a single string.\n     * @param {string[]} tokens Array of tokens to be decoded.\n     * @returns {string} The decoded string.\n     */\n    convert_tokens_to_string(tokens) {\n        if (tokens.length === 0) return '';\n\n        // group same tokens into non-repeating tokens in CTC style decoding\n        const grouped_tokens = [tokens[0]];\n        for (let i = 1; i < tokens.length; ++i) {\n            if (tokens[i] !== grouped_tokens.at(-1)) {\n                grouped_tokens.push(tokens[i]);\n            }\n        }\n\n        // filter self.pad_token which is used as CTC-blank token\n        const filtered_tokens = grouped_tokens.filter(token => token !== this.pad_token);\n\n        let text = filtered_tokens.join('');\n        if (this.cleanup) {\n            // cleanup and replace delimiter token\n            text = clean_up_tokenization(text)\n                .replaceAll(this.word_delimiter_token, ' ')\n                .trim();\n        }\n        return text;\n    }\n\n\n    /** @type {Decoder['decode_chain']} */\n    decode_chain(tokens) {\n        return [this.convert_tokens_to_string(tokens)];\n    }\n}\n\n/**\n * Apply a sequence of decoders.\n * @extends Decoder\n */\nclass DecoderSequence extends Decoder {\n\n    /**\n     * Creates a new instance of DecoderSequence.\n     * @param {Object} config The configuration object.\n     * @param {Decoder[]} config.decoders The list of decoders to apply.\n     */\n    constructor(config) {\n        super(config);\n        this.decoders = config.decoders.map(x => Decoder.fromConfig(x));\n    }\n\n    /** @type {Decoder['decode_chain']} */\n    decode_chain(tokens) {\n        // Use reduce to apply each decoder to the tokens\n        return this.decoders.reduce((toks, decoder) => {\n            return decoder.decode_chain(toks);\n        }, tokens);\n    }\n\n}\n\nclass BPEDecoder extends Decoder {\n    constructor(config) {\n        super(config);\n\n        this.suffix = this.config.suffix;\n    }\n    /** @type {Decoder['decode_chain']} */\n    decode_chain(tokens) {\n        return tokens.map((token, i) => {\n            return token.replaceAll(this.suffix, (i === tokens.length - 1) ? '' : ' ')\n        });\n    }\n}\n\n// Custom decoder for VITS\nclass VitsDecoder extends Decoder {\n    /** @type {Decoder['decode_chain']} */\n    decode_chain(tokens) {\n        let decoded = '';\n        for (let i = 1; i < tokens.length; i += 2) {\n            decoded += tokens[i];\n        }\n        return [decoded];\n    }\n}\n\n\n/**\n * This PreTokenizer replaces spaces with the given replacement character, adds a prefix space if requested,\n * and returns a list of tokens.\n * @extends PreTokenizer\n */\nclass MetaspacePreTokenizer extends PreTokenizer {\n    /**\n     * @param {Object} config The configuration object for the MetaspacePreTokenizer.\n     * @param {boolean} config.add_prefix_space Whether to add a prefix space to the first token.\n     * @param {string} config.replacement The character to replace spaces with.\n     * @param {string} [config.str_rep=config.replacement] An optional string representation of the replacement character.\n     * @param {'first'|'never'|'always'} [config.prepend_scheme='always'] The metaspace prepending scheme.\n     */\n    constructor(config) {\n        super();\n\n        this.addPrefixSpace = config.add_prefix_space;\n        this.replacement = config.replacement;\n        this.strRep = config.str_rep || this.replacement;\n        this.prepend_scheme = config.prepend_scheme ?? 'always';\n    }\n\n    /**\n     * This method takes a string, replaces spaces with the replacement character,\n     * adds a prefix space if requested, and returns a new list of tokens.\n     * @param {string} text The text to pre-tokenize.\n     * @param {Object} [options] The options for the pre-tokenization.\n     * @param {number} [options.section_index] The index of the section to pre-tokenize.\n     * @returns {string[]} A new list of pre-tokenized tokens.\n     */\n    pre_tokenize_text(text, {\n        section_index = undefined,\n    } = {}) {\n\n        let normalized = text.replaceAll(' ', this.strRep);\n\n        if (\n            // We add a prefix space if:\n            //  (1) The addPrefixSpace option is enabled and the normalized\n            //      token does not already start with the replacement character.\n            (this.addPrefixSpace && !normalized.startsWith(this.replacement))\n\n            // and (2) either:\n            //  (a) prepend_scheme is 'always'\n            //  (b) prepend_scheme is 'first' and this is the first section\n            && (\n                this.prepend_scheme === 'always' ||\n                (this.prepend_scheme === 'first' && section_index === 0)\n            )\n        ) {\n            normalized = this.strRep + normalized;\n        }\n        return [normalized];\n    }\n}\n\n/**\n * MetaspaceDecoder class extends the Decoder class and decodes Metaspace tokenization.\n * @extends Decoder\n */\nclass MetaspaceDecoder extends Decoder {\n    /**\n     * Constructs a new MetaspaceDecoder object.\n     * @param {Object} config The configuration object for the MetaspaceDecoder.\n     * @param {boolean} config.add_prefix_space Whether to add a prefix space to the decoded string.\n     * @param {string} config.replacement The string to replace spaces with.\n     */\n    constructor(config) {\n        super(config);\n\n        this.addPrefixSpace = config.add_prefix_space;\n        this.replacement = config.replacement;\n    }\n\n    /** @type {Decoder['decode_chain']} */\n    decode_chain(tokens) {\n        const result = [];\n        for (let i = 0; i < tokens.length; ++i) {\n            let normalized = tokens[i].replaceAll(this.replacement, ' ');\n            if (this.addPrefixSpace && i == 0 && normalized.startsWith(' ')) {\n                normalized = normalized.substring(1);\n            }\n            result.push(normalized);\n        }\n        return result;\n    }\n}\n\n/**\n * A normalizer that applies a precompiled charsmap.\n * This is useful for applying complex normalizations in C++ and exposing them to JavaScript.\n * @extends Normalizer\n * @param {Object} config The configuration object for the Precompiled normalizer.\n * @param {Object} config.precompiled_charsmap The precompiled charsmap object.\n */\nclass Precompiled extends Normalizer {\n    /**\n     * Create a new instance of Precompiled normalizer.\n     * @param {Object} config The configuration object.\n     * @param {any} config.precompiled_charsmap Precompiled chars mapping.\n     */\n    constructor(config) {\n        super(config);\n        this.charsmap = config.precompiled_charsmap;\n    }\n\n    /**\n     * Normalizes the given text by applying the precompiled charsmap.\n     * @param {string} text The text to normalize.\n     * @returns {string} The normalized text.\n     */\n    normalize(text) {\n        // As stated in the sentencepiece normalization docs (https://github.com/google/sentencepiece/blob/master/doc/normalization.md#use-pre-defined-normalization-rule),\n        // there are 5 pre-defined normalization rules:\n        //  1. nmt_nfkc: NFKC normalization with some additional normalization around spaces. (default)\n        //  2. nfkc: original NFKC normalization.\n        //  3. nmt_nfkc_cf: nmt_nfkc + Unicode case folding (mostly lower casing)\n        //  4. nfkc_cf: nfkc + Unicode case folding.\n        //  5. identity: no normalization\n        // \n        // For now, we only implement the default (nmt_nfkc).\n        // See https://raw.githubusercontent.com/google/sentencepiece/master/data/nmt_nfkc.tsv for the full list of rules.\n        // TODO: detect when a different `this.charsmap` is used.\n\n        text = text.replace(/[\\u0001-\\u0008\\u000B\\u000E-\\u001F\\u007F\\u008F\\u009F]/gm, ''); // Remove control characters\n        text = text.replace(/[\\u0009\\u000A\\u000C\\u000D\\u1680\\u200B\\u200C\\u200E\\u200F\\u2028\\u2029\\u2581\\uFEFF\\uFFFD]/gm, '\\u0020'); // Replace certain characters with a space\n\n        if (text.includes('\\uFF5E')) {\n            // To match the sentencepiece implementation 100%, we must handle a very strange edge-case.\n            // For some reason, the \"Fullwidth Tilde\" character (\\uFF5E) should not be converted to the standard Tilde character (\\u007E).\n            // However, NFKC normalization does do this conversion. As a result, we split the string on the Fullwidth Tilde character,\n            // perform NFKC normalization on each substring, and then join them back together with the Fullwidth Tilde character.\n            const parts = text.split('\\uFF5E');\n            text = parts.map(part => part.normalize('NFKC')).join('\\uFF5E');\n        } else {\n            text = text.normalize('NFKC');\n        }\n\n        return text;\n    }\n}\n\n/**\n * A pre-tokenizer that applies a sequence of pre-tokenizers to the input text.\n * @extends PreTokenizer\n */\nclass PreTokenizerSequence extends PreTokenizer {\n    /**\n     * Creates an instance of PreTokenizerSequence.\n     * @param {Object} config The configuration object for the pre-tokenizer sequence.\n     * @param {Object[]} config.pretokenizers An array of pre-tokenizer configurations.\n     */\n    constructor(config) {\n        super();\n        this.tokenizers = config.pretokenizers.map(x => PreTokenizer.fromConfig(x));\n    }\n\n    /**\n     * Applies each pre-tokenizer in the sequence to the input text in turn.\n     * @param {string} text The text to pre-tokenize.\n     * @param {Object} [options] Additional options for the pre-tokenization logic.\n     * @returns {string[]} The pre-tokenized text.\n     */\n    pre_tokenize_text(text, options) {\n        // Use reduce to apply each tokenizer to the text\n        return this.tokenizers.reduce((preTokenizedText, tokenizer) => {\n            return tokenizer.pre_tokenize(preTokenizedText, options);\n        }, [text]);\n    }\n}\n\n/**\n * Splits on word boundaries (using the following regular expression: `\\w+|[^\\w\\s]+`).\n */\nclass WhitespacePreTokenizer extends PreTokenizer {\n    /**\n     * Creates an instance of WhitespacePreTokenizer.\n     * @param {Object} config The configuration object for the pre-tokenizer.\n     */\n    constructor(config) {\n        super();\n    }\n    /**\n     * Pre-tokenizes the input text by splitting it on word boundaries.\n     * @param {string} text The text to be pre-tokenized.\n     * @param {Object} [options] Additional options for the pre-tokenization logic.\n     * @returns {string[]} An array of tokens produced by splitting the input text on whitespace.\n     */\n    pre_tokenize_text(text, options) {\n        return text.match(/\\w+|[^\\w\\s]+/g) || [];\n    }\n}\n\n/**\n * Splits a string of text by whitespace characters into individual tokens.\n * @extends PreTokenizer\n */\nclass WhitespaceSplit extends PreTokenizer {\n    /**\n     * Creates an instance of WhitespaceSplit.\n     * @param {Object} config The configuration object for the pre-tokenizer.\n     */\n    constructor(config) {\n        super();\n    }\n    /**\n     * Pre-tokenizes the input text by splitting it on whitespace characters.\n     * @param {string} text The text to be pre-tokenized.\n     * @param {Object} [options] Additional options for the pre-tokenization logic.\n     * @returns {string[]} An array of tokens produced by splitting the input text on whitespace.\n     */\n    pre_tokenize_text(text, options) {\n        return whitespace_split(text);\n    }\n}\n\n// NOTE: `ReplacePreTokenizer` is custom (to support `BlenderbotSmallTokenizer`)\nclass ReplacePreTokenizer extends PreTokenizer {\n    /**\n     * @param {Object} config The configuration options for the pre-tokenizer.\n     * @param {Object} config.pattern The pattern used to split the text. Can be a string or a regex object.\n     * @param {string} config.content What to replace the pattern with.\n     */\n    constructor(config) {\n        super();\n        this.config = config;\n        this.pattern = createPattern(this.config.pattern);\n        this.content = this.config.content;\n    }\n\n    /**\n     * Pre-tokenizes the input text by replacing certain characters.\n     * @param {string} text The text to be pre-tokenized.\n     * @param {Object} [options] Additional options for the pre-tokenization logic.\n     * @returns {string[]} An array of tokens produced by replacing certain characters.\n     */\n    pre_tokenize_text(text, options) {\n        if (this.pattern === null) {\n            return [text];\n        }\n        return [text.replaceAll(this.pattern, this.config.content)];\n    }\n}\n\nconst SPECIAL_TOKEN_ATTRIBUTES = [\n    'bos_token',\n    'eos_token',\n    'unk_token',\n    'sep_token',\n    'pad_token',\n    'cls_token',\n    'mask_token',\n    // additional_special_tokens (TODO)\n]\n\n/**\n * \n * Helper function for padding values of an object, which are each arrays.\n * NOTE: No additional checks are made here for validity of arguments.\n * @param {Record<string, any[]>} item The input object.\n * @param {number} length The length to pad to.\n * @param {(key: string) => any} value_fn Determine the value to fill the array, based on its key.\n * @param {'right'|'left'} side Which side to pad the array.\n * @private\n */\nfunction padHelper(item, length, value_fn, side) {\n    for (const key of Object.keys(item)) {\n        const diff = length - item[key].length;\n        const value = value_fn(key);\n\n        const padData = new Array(diff).fill(value);\n        item[key] = side === 'right'\n            ? (0,_utils_core_js__WEBPACK_IMPORTED_MODULE_0__.mergeArrays)(item[key], padData)\n            : (0,_utils_core_js__WEBPACK_IMPORTED_MODULE_0__.mergeArrays)(padData, item[key]);\n    }\n}\n\n/**\n * Helper function for truncating values of an object, which are each arrays.\n * NOTE: No additional checks are made here for validity of arguments.\n * @param {Record<string, any[]>} item The input object.\n * @param {number} length The length to truncate to.\n * @private\n */\nfunction truncateHelper(item, length) {\n    // Setting .length to a lower value truncates the array in-place:\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/length\n    for (const key of Object.keys(item)) {\n        item[key].length = length;\n    }\n}\n\n\nclass PreTrainedTokenizer extends _utils_core_js__WEBPACK_IMPORTED_MODULE_0__.Callable {\n    return_token_type_ids = false;\n\n    _default_chat_template = `{% for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}`;\n\n    /**\n     * Create a new PreTrainedTokenizer instance.\n     * @param {Object} tokenizerJSON The JSON of the tokenizer.\n     * @param {Object} tokenizerConfig The config of the tokenizer.\n     */\n    constructor(tokenizerJSON, tokenizerConfig) {\n        super();\n\n        this._tokenizer_config = tokenizerConfig;\n\n        // Construct parts of the tokenizer from the JSON\n        this.normalizer = Normalizer.fromConfig(tokenizerJSON.normalizer);\n        this.pre_tokenizer = PreTokenizer.fromConfig(tokenizerJSON.pre_tokenizer);\n        this.model = TokenizerModel.fromConfig(tokenizerJSON.model, tokenizerConfig);\n        this.post_processor = PostProcessor.fromConfig(tokenizerJSON.post_processor);\n        this.decoder = Decoder.fromConfig(tokenizerJSON.decoder);\n\n        // Add added_tokens to model\n        this.special_tokens = [];\n        this.all_special_ids = [];\n\n        /** @type {AddedToken[]} */\n        this.added_tokens = [];\n        for (const addedToken of tokenizerJSON.added_tokens) {\n            const token = new AddedToken(addedToken);\n            this.added_tokens.push(token);\n\n            this.model.tokens_to_ids.set(token.content, token.id);\n            this.model.vocab[token.id] = token.content;\n\n            if (token.special) {\n                this.special_tokens.push(token.content);\n                this.all_special_ids.push(token.id);\n            }\n        }\n\n        // Update additional_special_tokens\n        this.additional_special_tokens = tokenizerConfig.additional_special_tokens ?? [];\n        this.special_tokens.push(...this.additional_special_tokens);\n        this.special_tokens = [...new Set(this.special_tokens)]; // Remove duplicates\n\n        if (this.decoder) {\n            // Slight hack, but it prevents code duplication:\n            this.decoder.added_tokens = this.added_tokens;\n\n            // Another slight hack to add `end_of_word_suffix` (if present) to the decoder\n            // This is needed for cases where BPE model and ByteLevel decoder are used\n            // For more information, see https://github.com/xenova/transformers.js/issues/74\n            // TODO: save this to the decoder when exporting?\n            this.decoder.end_of_word_suffix = this.model.end_of_word_suffix;\n        }\n\n\n        this.added_tokens_regex = this.added_tokens.length > 0 ? new RegExp(\n            this.added_tokens.map(x => `${x.lstrip ? '\\\\s*' : ''}(${(0,_utils_core_js__WEBPACK_IMPORTED_MODULE_0__.escapeRegExp)(x.content)})${x.rstrip ? '\\\\s*' : ''}`).join('|')\n        ) : null;\n\n        // Set mask token if present (otherwise will be undefined, which is fine)\n        this.mask_token = this.getToken('mask_token');\n        this.mask_token_id = this.model.tokens_to_ids.get(this.mask_token);\n\n        this.pad_token = this.getToken('pad_token', 'eos_token');\n        this.pad_token_id = this.model.tokens_to_ids.get(this.pad_token);\n\n        this.sep_token = this.getToken('sep_token');\n        this.sep_token_id = this.model.tokens_to_ids.get(this.sep_token);\n\n        this.unk_token = this.getToken('unk_token');\n        this.unk_token_id = this.model.tokens_to_ids.get(this.unk_token);\n\n        this.model_max_length = tokenizerConfig.model_max_length;\n\n        /** @type {boolean} Whether or not to strip the text when tokenizing (removing excess spaces before and after the string). */\n        this.remove_space = tokenizerConfig.remove_space;\n\n        this.clean_up_tokenization_spaces = tokenizerConfig.clean_up_tokenization_spaces ?? true;\n        this.do_lowercase_and_remove_accent = tokenizerConfig.do_lowercase_and_remove_accent ?? false;\n\n        // TODO allow user to change this\n        /** @type {'right'|'left'} */\n        this.padding_side = 'right';\n\n        this.legacy = false;\n\n        this.chat_template = tokenizerConfig.chat_template ?? null;\n        this._compiled_template_cache = new Map();\n    }\n\n    /**\n     * Returns the value of the first matching key in the tokenizer config object.\n     * @param {...string} keys One or more keys to search for in the tokenizer config object.\n     * @returns {string|null} The value associated with the first matching key, or null if no match is found.\n     * @throws {Error} If an object is found for a matching key and its __type property is not \"AddedToken\".\n     */\n    getToken(...keys) {\n        for (const key of keys) {\n            const item = this._tokenizer_config[key];\n\n            if (!item) continue;\n\n            if (typeof item === 'object') {\n                if (item.__type === 'AddedToken') {\n                    return item.content;\n                } else {\n                    throw Error(`Unknown token: ${item}`);\n                }\n            } else {\n                return item;\n            }\n        }\n        return null;\n    }\n\n    /**\n     * Loads a pre-trained tokenizer from the given `pretrained_model_name_or_path`. \n     * \n     * @param {string} pretrained_model_name_or_path The path to the pre-trained tokenizer.\n     * @param {PretrainedTokenizerOptions} options Additional options for loading the tokenizer.\n     * \n     * @throws {Error} Throws an error if the tokenizer.json or tokenizer_config.json files are not found in the `pretrained_model_name_or_path`.\n     * @returns {Promise<PreTrainedTokenizer>} A new instance of the `PreTrainedTokenizer` class.\n     */\n    static async from_pretrained(pretrained_model_name_or_path, {\n        progress_callback = null,\n        config = null,\n        cache_dir = null,\n        local_files_only = false,\n        revision = 'main',\n        legacy = null,\n    } = {}) {\n\n        const info = await loadTokenizer(pretrained_model_name_or_path, {\n            progress_callback,\n            config,\n            cache_dir,\n            local_files_only,\n            revision,\n            legacy,\n        })\n\n        // @ts-ignore\n        return new this(...info);\n    }\n\n    /**\n     * @typedef {number[]|number[][]|Tensor} BatchEncodingItem\n     * \n     * @typedef {Object} BatchEncoding Holds the output of the tokenizer's call function.\n     * @property {BatchEncodingItem} input_ids List of token ids to be fed to a model.\n     * @property {BatchEncodingItem} attention_mask List of indices specifying which tokens should be attended to by the model.\n     * @property {BatchEncodingItem} [token_type_ids] List of token type ids to be fed to a model.\n     */\n\n    /**\n     * Encode/tokenize the given text(s).\n     * @param {string|string[]} text The text to tokenize.\n     * @param {Object} options An optional object containing the following properties:\n     * @param {string|string[]} [options.text_pair=null] Optional second sequence to be encoded. If set, must be the same type as text.\n     * @param {boolean|'max_length'} [options.padding=false] Whether to pad the input sequences.\n     * @param {boolean} [options.add_special_tokens=true] Whether or not to add the special tokens associated with the corresponding model.\n     * @param {boolean} [options.truncation=null] Whether to truncate the input sequences.\n     * @param {number} [options.max_length=null] Maximum length of the returned list and optionally padding length.\n     * @param {boolean} [options.return_tensor=true] Whether to return the results as Tensors or arrays.\n     * @returns {BatchEncoding} Object to be passed to the model.\n     */\n    _call(\n        // Required positional arguments\n        text,\n\n        // Optional keyword arguments\n        {\n            text_pair = null,\n            add_special_tokens = true,\n            padding = false,\n            truncation = null,\n            max_length = null,\n            return_tensor = true, // Different to HF\n        } = {},\n    ) {\n\n        const isBatched = Array.isArray(text);\n\n        /** @type {EncodingSingle[]} */\n        let encodedTokens;\n\n        if (isBatched) {\n            if (text.length === 0) {\n                throw Error('text array must be non-empty')\n            }\n\n            if (text_pair !== null) {\n                if (!Array.isArray(text_pair)) {\n                    throw Error('text_pair must also be an array')\n\n                } else if (text.length !== text_pair.length) {\n                    throw Error('text and text_pair must have the same length')\n                }\n\n                encodedTokens = text.map(\n                    (t, i) => this._encode_plus(t, text_pair[i], { add_special_tokens })\n                )\n\n            } else {\n                encodedTokens = text.map(x => this._encode_plus(x, null, { add_special_tokens }));\n            }\n\n        } else {\n            if (text === null) {\n                throw Error('text may not be null')\n            }\n\n            if (Array.isArray(text_pair)) {\n                throw Error('When specifying `text_pair`, since `text` is a string, `text_pair` must also be a string (i.e., not an array).')\n            }\n\n            // For single input, we just wrap in an array, and then unwrap later.\n            encodedTokens = [this._encode_plus(text, text_pair, { add_special_tokens })];\n        }\n        // At this point, tokens is batched: [batch_size, tokens]\n        // However, array may be jagged. So, we pad to max_length\n\n        if (max_length === null) {\n            if (padding === 'max_length') {\n                max_length = this.model_max_length;\n            } else {\n                // Calculate max length from sequences\n                max_length = (0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_2__.max)(encodedTokens.map(x => x.input_ids.length))[0];\n            }\n        } else {\n            if (!truncation) {\n                console.warn(`Truncation was not explicitly activated but \\`max_length\\` is provided a specific value, please use \\`truncation=true\\` to explicitly truncate examples to max length.`)\n            }\n        }\n\n        // Ensure it is less than model max length\n        max_length = Math.min(max_length, this.model_max_length)\n\n        if (padding || truncation) {\n\n            // Perform padding and/or truncation\n            for (let i = 0; i < encodedTokens.length; ++i) {\n                if (encodedTokens[i].input_ids.length === max_length) {\n                    continue;\n\n                } else if (encodedTokens[i].input_ids.length > max_length) {\n                    // possibly truncate\n                    if (truncation) {\n                        truncateHelper(encodedTokens[i], max_length);\n                    }\n\n                } else { // t.length < max_length\n                    // possibly pad\n                    if (padding) {\n                        padHelper(\n                            encodedTokens[i],\n                            max_length,\n                            key => key === 'input_ids' ? this.pad_token_id : 0,\n                            this.padding_side\n                        );\n                    }\n                }\n            }\n        }\n\n        const result = {};\n\n        if (return_tensor) {\n            if (!(padding && truncation)) {\n                // Not, guaranteed that all items have same length, so\n                // we perform additional check\n\n                if (\n                    encodedTokens.some(x => {\n                        for (const key of Object.keys(x)) {\n                            if (x[key].length !== encodedTokens[0][key]?.length) {\n                                return true;\n                            }\n                        }\n                        return false;\n                    })\n                ) {\n                    throw Error(\n                        \"Unable to create tensor, you should probably activate truncation and/or padding \" +\n                        \"with 'padding=true' and 'truncation=true' to have batched tensors with the same length.\"\n                    )\n                }\n            }\n\n            // Now we actually convert to tensor\n            // NOTE: In the same way as the python library, we return a batched tensor, regardless of\n            // whether we have a single input or multiple inputs.\n            const dims = [encodedTokens.length, encodedTokens[0].input_ids.length];\n\n            for (const key of Object.keys(encodedTokens[0])) {\n                result[key] = new _utils_tensor_js__WEBPACK_IMPORTED_MODULE_3__.Tensor('int64',\n                    BigInt64Array.from(encodedTokens.flatMap(x => x[key]).map(BigInt)),\n                    dims\n                );\n            }\n\n        } else {\n            for (const key of Object.keys(encodedTokens[0])) {\n                result[key] = encodedTokens.map(x => x[key]);\n            }\n\n            // If not returning a tensor, we match the input type\n            if (!isBatched) {\n                // Input was not batched, so we unwrap\n                for (const key of Object.keys(result)) {\n                    result[key] = result[key][0];\n                }\n            }\n        }\n\n        return /** @type {BatchEncoding} */(result);\n    }\n\n    /**\n     * Encodes a single text using the preprocessor pipeline of the tokenizer.\n     *\n     * @param {string|null} text The text to encode.\n     * @returns {string[]|null} The encoded tokens.\n     */\n    _encode_text(text) {\n        if (text === null) return null;\n\n        // Actual function which does encoding, for a single text\n        // First, we take care of special tokens. Needed to avoid issues arising from\n        // normalization and/or pretokenization (which may not preserve special tokens)\n        const sections = this.added_tokens_regex ? text.split(this.added_tokens_regex).filter(x => x) : [text];\n\n        const tokens = sections.map((x, section_index) => {\n            const addedToken = this.added_tokens.find(t => t.content === x);\n            if (addedToken !== undefined) {\n                // Ignore added tokens\n                return x\n            } else {\n                if (this.remove_space === true) {\n                    x = x.trim().split(/\\s+/).join(' ');\n                }\n                if (this.do_lowercase_and_remove_accent) {\n                    x = lowercase_and_remove_accent(x);\n                }\n\n                if (this.normalizer !== null) {\n                    x = this.normalizer(x);\n                }\n\n                // If, after normalization, this section is empty (e.g., trimming whitespace),\n                // we return an empty array\n                if (x.length === 0) {\n                    return [];\n                }\n\n                const sectionTokens = (this.pre_tokenizer !== null) ? this.pre_tokenizer(x, {\n                    section_index,\n                }) : [x];\n\n                const tokens = this.model(sectionTokens);\n\n                return tokens;\n            }\n        }).flat();\n\n        return tokens;\n    }\n\n    /**\n     * Encodes a single text or a pair of texts using the model's tokenizer.\n     *\n     * @param {string} text The text to encode.\n     * @param {string|null} text_pair The optional second text to encode.\n     * @param {Object} options An optional object containing the following properties:\n     * @param {boolean} [options.add_special_tokens=true] Whether or not to add the special tokens associated with the corresponding model.\n     * @returns {EncodingSingle} An object containing the encoded text.\n     * @private\n     */\n    _encode_plus(text, text_pair = null, {\n        add_special_tokens = true,\n    } = {}) {\n        // Function called by users to encode possibly multiple texts\n        const tokens = this._encode_text(text);\n        const tokens2 = this._encode_text(text_pair);\n\n        const combinedTokens = this.post_processor\n            ? this.post_processor(tokens, tokens2, { add_special_tokens })\n            : { tokens: (0,_utils_core_js__WEBPACK_IMPORTED_MODULE_0__.mergeArrays)(tokens ?? [], tokens2 ?? []) };\n\n        const input_ids = this.model.convert_tokens_to_ids(combinedTokens.tokens);\n\n        const result = {\n            input_ids,\n            attention_mask: new Array(input_ids.length).fill(1),\n        }\n        if (this.return_token_type_ids && combinedTokens.token_type_ids) {\n            result.token_type_ids = combinedTokens.token_type_ids;\n        }\n        return result;\n    }\n\n    /**\n     * Encodes a single text or a pair of texts using the model's tokenizer.\n     *\n     * @param {string} text The text to encode.\n     * @param {string|null} text_pair The optional second text to encode.\n     * @param {Object} options An optional object containing the following properties:\n     * @param {boolean} [options.add_special_tokens=true] Whether or not to add the special tokens associated with the corresponding model.\n     * @returns {number[]} An array of token IDs representing the encoded text(s).\n     */\n    encode(text, text_pair = null, {\n        add_special_tokens = true,\n    } = {}) {\n        const { input_ids } = this._encode_plus(text, text_pair, {\n            add_special_tokens,\n        });\n        return input_ids;\n    }\n\n    /**\n     * Decode a batch of tokenized sequences.\n     * @param {number[][]|Tensor} batch List/Tensor of tokenized input sequences.\n     * @param {Object} decode_args (Optional) Object with decoding arguments.\n     * @returns {string[]} List of decoded sequences.\n     */\n    batch_decode(batch, decode_args = {}) {\n        if (batch instanceof _utils_tensor_js__WEBPACK_IMPORTED_MODULE_3__.Tensor) {\n            batch = batch.tolist();\n        }\n        return batch.map(x => this.decode(x, decode_args));\n    }\n\n    /**\n     * Decodes a sequence of token IDs back to a string.\n     *\n     * @param {number[]|Tensor} token_ids List/Tensor of token IDs to decode.\n     * @param {Object} [decode_args={}]\n     * @param {boolean} [decode_args.skip_special_tokens=false] If true, special tokens are removed from the output string.\n     * @param {boolean} [decode_args.clean_up_tokenization_spaces=true] If true, spaces before punctuations and abbreviated forms are removed.\n     *\n     * @returns {string} The decoded string.\n     * @throws {Error} If `token_ids` is not a non-empty array of integers.\n     */\n    decode(\n        token_ids,\n        decode_args = {},\n    ) {\n        if (token_ids instanceof _utils_tensor_js__WEBPACK_IMPORTED_MODULE_3__.Tensor) {\n            token_ids = prepareTensorForDecode(token_ids);\n        }\n\n        if (!Array.isArray(token_ids) || token_ids.length === 0 || !(0,_utils_core_js__WEBPACK_IMPORTED_MODULE_0__.isIntegralNumber)(token_ids[0])) {\n            throw Error(\"token_ids must be a non-empty array of integers.\");\n        }\n\n        return this.decode_single(token_ids, decode_args)\n    }\n\n    /**\n     * Decode a single list of token ids to a string.\n     * @param {number[]} token_ids List of token ids to decode\n     * @param {Object} decode_args Optional arguments for decoding\n     * @param {boolean} [decode_args.skip_special_tokens=false] Whether to skip special tokens during decoding\n     * @param {boolean} [decode_args.clean_up_tokenization_spaces=null] Whether to clean up tokenization spaces during decoding.\n     * If null, the value is set to `this.decoder.cleanup` if it exists, falling back to `this.clean_up_tokenization_spaces` if it exists, falling back to `true`.\n     * @returns {string} The decoded string\n     */\n    decode_single(\n        token_ids,\n        {\n            skip_special_tokens = false,\n            clean_up_tokenization_spaces = null,\n        }\n    ) {\n        let tokens = this.model.convert_ids_to_tokens(token_ids);\n        if (skip_special_tokens) {\n            tokens = tokens.filter(x => !this.special_tokens.includes(x));\n        }\n\n        // If `this.decoder` is null, we just join tokens with a space:\n        // https://github.com/huggingface/tokenizers/blob/8edec536a737cb04494b454805be16c020abb14f/tokenizers/src/tokenizer/mod.rs#L835\n        /** @type {string} */\n        let decoded = this.decoder ? this.decoder(tokens) : tokens.join(' ');\n\n        // Slight hack, but prevents having to pass `skip_special_tokens` to\n        // each call to `decode`, which would lead to code duplication.\n        if (this.decoder && this.decoder.end_of_word_suffix) {\n            decoded = decoded.replaceAll(this.decoder.end_of_word_suffix, ' ');\n            if (skip_special_tokens) {\n                decoded = decoded.trim();\n            }\n        }\n\n        if (clean_up_tokenization_spaces ?? this.clean_up_tokenization_spaces) {\n            decoded = clean_up_tokenization(decoded);\n        }\n\n        return decoded;\n    }\n\n    get default_chat_template() {\n        if (!this._warned_about_chat_template) {\n            console.warn(\n                \"No chat template is defined for this tokenizer - using a default chat template \" +\n                \"that implements the ChatML format. If the default is not appropriate for \" +\n                \"your model, please set `tokenizer.chat_template` to an appropriate template. \" +\n                \"See https://huggingface.co/docs/transformers/main/chat_templating for more information.\"\n            )\n            this._warned_about_chat_template = true; // TODO move to logger.warning_once()\n        }\n\n        return this._default_chat_template;\n    }\n\n    /**\n     * @typedef {Object} Message\n     * @property {string} role The role of the message (e.g., \"user\" or \"assistant\" or \"system\").\n     * @property {string} content The content of the message.\n     */\n\n    /**\n     * Converts a list of message objects with `\"role\"` and `\"content\"` keys to a list of token\n     * ids. This method is intended for use with chat models, and will read the tokenizer's chat_template attribute to\n     * determine the format and control tokens to use when converting. When chat_template is None, it will fall back\n     * to the default_chat_template specified at the class level.\n     * \n     * See [here](https://huggingface.co/docs/transformers/chat_templating) for more information.\n     * \n     * **Example:** Applying a chat template to a conversation.\n     * \n     * ```javascript\n     * import { AutoTokenizer } from \"@xenova/transformers\";\n     * \n     * const tokenizer = await AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\");\n     * \n     * const chat = [\n     *   { \"role\": \"user\", \"content\": \"Hello, how are you?\" },\n     *   { \"role\": \"assistant\", \"content\": \"I'm doing great. How can I help you today?\" },\n     *   { \"role\": \"user\", \"content\": \"I'd like to show off how chat templating works!\" },\n     * ]\n     * \n     * const text = tokenizer.apply_chat_template(chat, { tokenize: false });\n     * // \"<s>[INST] Hello, how are you? [/INST]I'm doing great. How can I help you today?</s> [INST] I'd like to show off how chat templating works! [/INST]\"\n     * \n     * const input_ids = tokenizer.apply_chat_template(chat, { tokenize: true, return_tensor: false });\n     * // [1, 733, 16289, 28793, 22557, 28725, 910, 460, 368, 28804, 733, 28748, 16289, 28793, 28737, 28742, 28719, 2548, 1598, 28723, 1602, 541, 315, 1316, 368, 3154, 28804, 2, 28705, 733, 16289, 28793, 315, 28742, 28715, 737, 298, 1347, 805, 910, 10706, 5752, 1077, 3791, 28808, 733, 28748, 16289, 28793]\n     * ```\n     * \n     * @param {Message[]} conversation A list of message objects with `\"role\"` and `\"content\"` keys.\n     * @param {Object} options An optional object containing the following properties:\n     * @param {string} [options.chat_template=null] A Jinja template to use for this conversion. If\n     * this is not passed, the model's default chat template will be used instead.\n     * @param {boolean} [options.add_generation_prompt=false] Whether to end the prompt with the token(s) that indicate\n     * the start of an assistant message. This is useful when you want to generate a response from the model.\n     * Note that this argument will be passed to the chat template, and so it must be supported in the\n     * template for this argument to have any effect.\n     * @param {boolean} [options.tokenize=true] Whether to tokenize the output. If false, the output will be a string.\n     * @param {boolean} [options.padding=false] Whether to pad sequences to the maximum length. Has no effect if tokenize is false.\n     * @param {boolean} [options.truncation=false] Whether to truncate sequences to the maximum length. Has no effect if tokenize is false.\n     * @param {number} [options.max_length=null] Maximum length (in tokens) to use for padding or truncation. Has no effect if tokenize is false.\n     * If not specified, the tokenizer's `max_length` attribute will be used as a default.\n     * @param {boolean} [options.return_tensor=true] Whether to return the output as a Tensor or an Array. Has no effect if tokenize is false.\n     * @returns {string | Tensor | number[]| number[][]} The tokenized output.\n     */\n    apply_chat_template(conversation, {\n        chat_template = null,\n        add_generation_prompt = false,\n        tokenize = true,\n        padding = false,\n        truncation = false,\n        max_length = null,\n        return_tensor = true,\n    } = {}) {\n\n        chat_template ??= this.chat_template ?? this.default_chat_template;\n\n        // Compilation function uses a cache to avoid recompiling the same template\n        let compiledTemplate = this._compiled_template_cache.get(chat_template);\n        if (compiledTemplate === undefined) {\n            compiledTemplate = new _huggingface_jinja__WEBPACK_IMPORTED_MODULE_5__.Template(chat_template);\n            this._compiled_template_cache.set(chat_template, compiledTemplate);\n        }\n\n        const special_tokens_map = Object.create(null);\n        for (const key of SPECIAL_TOKEN_ATTRIBUTES) {\n            const value = this.getToken(key);\n            if (value) {\n                special_tokens_map[key] = value;\n            }\n        }\n\n        const rendered = compiledTemplate.render({\n            messages: conversation,\n            add_generation_prompt: add_generation_prompt,\n\n            ...special_tokens_map,\n        });\n\n        if (tokenize) {\n            return this._call(rendered, {\n                add_special_tokens: false,\n                padding,\n                truncation,\n                max_length,\n                return_tensor,\n            }).input_ids;\n        }\n\n        return rendered;\n    }\n}\n\n/**\n * BertTokenizer is a class used to tokenize text for BERT models.\n * @extends PreTrainedTokenizer\n */\nclass BertTokenizer extends PreTrainedTokenizer {\n    return_token_type_ids = true;\n}\n/**\n * Albert tokenizer\n * @extends PreTrainedTokenizer\n */\nclass AlbertTokenizer extends PreTrainedTokenizer {\n    return_token_type_ids = true;\n}\nclass MobileBertTokenizer extends PreTrainedTokenizer {\n    return_token_type_ids = true;\n}\nclass SqueezeBertTokenizer extends PreTrainedTokenizer {\n    return_token_type_ids = true;\n}\nclass DebertaTokenizer extends PreTrainedTokenizer {\n    return_token_type_ids = true;\n}\nclass DebertaV2Tokenizer extends PreTrainedTokenizer {\n    return_token_type_ids = true;\n}\nclass HerbertTokenizer extends PreTrainedTokenizer {\n    return_token_type_ids = true;\n}\nclass ConvBertTokenizer extends PreTrainedTokenizer {\n    return_token_type_ids = true;\n}\nclass RoFormerTokenizer extends PreTrainedTokenizer {\n    return_token_type_ids = true;\n}\nclass DistilBertTokenizer extends PreTrainedTokenizer { }\nclass CamembertTokenizer extends PreTrainedTokenizer { }\nclass XLMTokenizer extends PreTrainedTokenizer {\n    return_token_type_ids = true;\n\n    constructor(tokenizerJSON, tokenizerConfig) {\n        super(tokenizerJSON, tokenizerConfig);\n        console.warn('WARNING: `XLMTokenizer` is not yet supported by Hugging Face\\'s \"fast\" tokenizers library. Therefore, you may experience slightly inaccurate results.')\n    }\n}\nclass ElectraTokenizer extends PreTrainedTokenizer {\n    return_token_type_ids = true;\n}\n\nclass T5Tokenizer extends PreTrainedTokenizer { }\nclass GPT2Tokenizer extends PreTrainedTokenizer {\n    _default_chat_template = `{% for message in messages %}\" \"{{ message.content }}{{ eos_token }}\" \"{% endfor %}`\n}\nclass BartTokenizer extends PreTrainedTokenizer { }\nclass MBartTokenizer extends PreTrainedTokenizer {\n    constructor(tokenizerJSON, tokenizerConfig) {\n        super(tokenizerJSON, tokenizerConfig);\n\n        this.languageRegex = /^[a-z]{2}_[A-Z]{2}$/;\n        this.language_codes = this.special_tokens.filter(x => this.languageRegex.test(x));\n        this.lang_to_token = x => x; // Identity function\n    }\n\n    /**\n     * Helper function to build translation inputs for an `MBartTokenizer`.\n     * @param {string|string[]} raw_inputs The text to tokenize.\n     * @param {Object} tokenizer_options Options to be sent to the tokenizer\n     * @param {Object} generate_kwargs Generation options.\n     * @returns {Object} Object to be passed to the model.\n     */\n    _build_translation_inputs(raw_inputs, tokenizer_options, generate_kwargs) {\n        return _build_translation_inputs(this, raw_inputs, tokenizer_options, generate_kwargs);\n    }\n}\nclass MBart50Tokenizer extends MBartTokenizer { } // NOTE: extends MBartTokenizer\n\nclass RobertaTokenizer extends PreTrainedTokenizer { }\n\nclass BloomTokenizer extends GPT2Tokenizer { // NOTE: `GPT2Tokenizer` to get the correct chat template\n\n    constructor(tokenizerJSON, tokenizerConfig) {\n        // Override the default (invalid) regex of the pretokenizer.\n        // For more information, see https://github.com/xenova/transformers.js/issues/94\n        const splitChars = '.,!?\\u2026\\u3002\\uff0c\\u3001\\u0964\\u06d4\\u060c';\n        const patternObject = tokenizerJSON.pre_tokenizer?.pretokenizers[0]?.pattern;\n        if (patternObject && patternObject.Regex === ` ?[^(\\\\s|[${splitChars}])]+`) {\n            patternObject.Regex = ` ?[^\\\\s${splitChars}]+`;\n        }\n        super(tokenizerJSON, tokenizerConfig);\n    }\n}\n\nconst SPIECE_UNDERLINE = \"\";\n\nclass LlamaTokenizer extends PreTrainedTokenizer {\n    _default_chat_template = `{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% elif USE_DEFAULT_PROMPT == true and not '<<SYS>>' in messages[0]['content'] %}{% set loop_messages = messages %}{% set system_message = 'DEFAULT_SYSTEM_MESSAGE' %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if loop.index0 == 0 and system_message != false %}{% set content = '<<SYS>>\\n' + system_message + '\\n<</SYS>>\\n\\n' + message['content'] %}{% else %}{% set content = message['content'] %}{% endif %}{% if message['role'] == 'user' %}{{ bos_token + '[INST] ' + content.strip() + ' [/INST]' }}{% elif message['role'] == 'system' %}{{ '<<SYS>>\\n' + content.strip() + '\\n<</SYS>>\\n\\n' }}{% elif message['role'] == 'assistant' %}{{ ' '  + content.strip() + ' ' + eos_token }}{% endif %}{% endfor %}`\n\n    DEFAULT_SYSTEM_PROMPT =\n        \"You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your \" +\n        \"answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure \" +\n        \"that your responses are socially unbiased and positive in nature.\\n\\n\" +\n        \"If a question does not make any sense, or is not factually coherent, explain why instead of answering something not \" +\n        \"correct. If you don't know the answer to a question, please don't share false information.\"\n\n    constructor(tokenizerJSON, tokenizerConfig) {\n        super(tokenizerJSON, tokenizerConfig);\n        this.use_default_system_prompt = tokenizerConfig.use_default_system_prompt ?? false;\n\n        this.legacy = tokenizerConfig.legacy ?? true;\n        if (!this.legacy) {\n            // See https://github.com/huggingface/transformers/pull/24565 for more information\n            this.normalizer = null;\n            this.pre_tokenizer = new MetaspacePreTokenizer({\n                replacement: SPIECE_UNDERLINE,\n                add_prefix_space: true,\n                prepend_scheme: \"first\",\n            });\n        }\n    }\n\n    /**\n     * Helper function to handle legacy encoding of SPM tokenizers.\n     * Adapted from https://github.com/huggingface/transformers/blob/e6dcf8abd6f65bb4b6dfc1831b20d9ba49ce00e2/src/transformers/models/t5/tokenization_t5.py#L374-L387\n     * @param {string} text The text to encode.\n     * @returns {string[]} The encoded tokens.\n     */\n    _encode_text(text) {\n        if (text === null) return null;\n\n        if (this.legacy || text.length === 0) {\n            return super._encode_text(text);\n        }\n\n        let tokens = super._encode_text(SPIECE_UNDERLINE + text.replaceAll(SPIECE_UNDERLINE, \" \"));\n        if (tokens.length > 1 && tokens[0] === SPIECE_UNDERLINE && this.special_tokens.includes(tokens[1])) {\n            tokens = tokens.slice(1);\n        }\n        return tokens;\n    }\n\n    get default_chat_template() {\n        return super.default_chat_template\n            .replaceAll('USE_DEFAULT_PROMPT', this.use_default_system_prompt ? 'true' : 'false')\n            .replaceAll('DEFAULT_SYSTEM_MESSAGE', this.DEFAULT_SYSTEM_PROMPT.replaceAll(\"\\n\", \"\\\\n\").replaceAll(\"'\", \"\\\\'\"));\n    }\n}\nclass CodeLlamaTokenizer extends LlamaTokenizer { } // NOTE: `LlamaTokenizer` to get the correct chat template\n\nclass XLMRobertaTokenizer extends PreTrainedTokenizer { }\nclass MPNetTokenizer extends PreTrainedTokenizer { }\n\nclass FalconTokenizer extends PreTrainedTokenizer { }\n\nclass GPTNeoXTokenizer extends PreTrainedTokenizer { }\n\nclass EsmTokenizer extends PreTrainedTokenizer { }\n\nclass Qwen2Tokenizer extends PreTrainedTokenizer { }\n\nclass GemmaTokenizer extends PreTrainedTokenizer {\n    _default_chat_template = \"{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\\n' + message['content'] | trim + '<end_of_turn>\\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\\n'}}{% endif %}\"\n}\n\n/**\n * Helper function to build translation inputs for an `NllbTokenizer` or `M2M100Tokenizer`.\n * @param {PreTrainedTokenizer} self The tokenizer instance.\n * @param {string|string[]} raw_inputs The text to tokenize.\n * @param {Object} tokenizer_options Options to be sent to the tokenizer\n * @param {Object} generate_kwargs Generation options.\n * @returns {Object} Object to be passed to the model.\n * @private\n */\nfunction _build_translation_inputs(self, raw_inputs, tokenizer_options, generate_kwargs) {\n    if (!('language_codes' in self) || !Array.isArray(self.language_codes)) {\n        throw new Error('Tokenizer must have `language_codes` attribute set and it should be an array of language ids.')\n    }\n    if (!('languageRegex' in self) || !(self.languageRegex instanceof RegExp)) {\n        throw new Error('Tokenizer must have `languageRegex` attribute set and it should be a regular expression.')\n    }\n    if (!('lang_to_token' in self) || typeof self.lang_to_token !== 'function') {\n        throw new Error('Tokenizer must have `lang_to_token` attribute set and it should be a function.')\n    }\n    const src_lang_token = generate_kwargs.src_lang;\n    const tgt_lang_token = generate_kwargs.tgt_lang;\n\n    // Check that the target language is valid:\n    if (!self.language_codes.includes(tgt_lang_token)) {\n        throw new Error(`Target language code \"${tgt_lang_token}\" is not valid. Must be one of: {${self.language_codes.join(', ')}}`);\n    }\n\n    // Allow `src_lang` to be optional. If not set, we'll use the tokenizer's default.\n    if (src_lang_token !== undefined) {\n        // Check that the source language is valid:\n        if (!self.language_codes.includes(src_lang_token)) {\n            throw new Error(`Source language code \"${src_lang_token}\" is not valid. Must be one of: {${self.language_codes.join(', ')}}`);\n        }\n\n        // In the same way as the Python library, we override the post-processor\n        // to force the source language to be first:\n        for (const item of self.post_processor.config.single) {\n            if ('SpecialToken' in item && self.languageRegex.test(item.SpecialToken.id)) {\n                item.SpecialToken.id = self.lang_to_token(src_lang_token);\n                break;\n            }\n        }\n        // TODO: Do the same for pair?\n    }\n\n    // Override the `forced_bos_token_id` to force the correct language\n    generate_kwargs.forced_bos_token_id = self.model.convert_tokens_to_ids([self.lang_to_token(tgt_lang_token)])[0];\n\n    return self._call(raw_inputs, tokenizer_options);\n}\n\n/**\n * The NllbTokenizer class is used to tokenize text for NLLB (\"No Language Left Behind\") models.\n * \n * No Language Left Behind (NLLB) is a first-of-its-kind, AI breakthrough project\n * that open-sources models capable of delivering high-quality translations directly\n * between any pair of 200+ languages  including low-resource languages like Asturian,\n * Luganda, Urdu and more. It aims to help people communicate with anyone, anywhere,\n * regardless of their language preferences. For more information, check out their\n * [paper](https://arxiv.org/abs/2207.04672).\n * \n * For a list of supported languages (along with their language codes),\n * @see {@link https://github.com/facebookresearch/flores/blob/main/flores200/README.md#languages-in-flores-200}\n */\nclass NllbTokenizer extends PreTrainedTokenizer {\n\n    constructor(tokenizerJSON, tokenizerConfig) {\n        super(tokenizerJSON, tokenizerConfig);\n\n        this.languageRegex = /^[a-z]{3}_[A-Z][a-z]{3}$/;\n        this.language_codes = this.special_tokens.filter(x => this.languageRegex.test(x));\n        this.lang_to_token = x => x; // Identity function\n    }\n\n    /**\n     * Helper function to build translation inputs for an `NllbTokenizer`.\n     * @param {string|string[]} raw_inputs The text to tokenize.\n     * @param {Object} tokenizer_options Options to be sent to the tokenizer\n     * @param {Object} generate_kwargs Generation options.\n     * @returns {Object} Object to be passed to the model.\n     */\n    _build_translation_inputs(raw_inputs, tokenizer_options, generate_kwargs) {\n        return _build_translation_inputs(this, raw_inputs, tokenizer_options, generate_kwargs);\n    }\n}\n\n/**\n * The M2M100Tokenizer class is used to tokenize text for M2M100 (\"Many-to-Many\") models.\n * \n * M2M100 is a multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many\n * multilingual translation. It was introduced in this [paper](https://arxiv.org/abs/2010.11125)\n * and first released in [this](https://github.com/pytorch/fairseq/tree/master/examples/m2m_100) repository.\n * \n * For a list of supported languages (along with their language codes),\n * @see {@link https://huggingface.co/facebook/m2m100_418M#languages-covered}\n */\nclass M2M100Tokenizer extends PreTrainedTokenizer {\n    constructor(tokenizerJSON, tokenizerConfig) {\n        super(tokenizerJSON, tokenizerConfig);\n\n        this.languageRegex = /^__[a-z]{2,3}__$/;\n        this.language_codes = this.special_tokens\n            .filter(x => this.languageRegex.test(x))\n            .map(x => x.slice(2, -2));\n        this.lang_to_token = x => `__${x}__`;\n    }\n\n    /**\n     * Helper function to build translation inputs for an `M2M100Tokenizer`.\n     * @param {string|string[]} raw_inputs The text to tokenize.\n     * @param {Object} tokenizer_options Options to be sent to the tokenizer\n     * @param {Object} generate_kwargs Generation options.\n     * @returns {Object} Object to be passed to the model.\n     */\n    _build_translation_inputs(raw_inputs, tokenizer_options, generate_kwargs) {\n        return _build_translation_inputs(this, raw_inputs, tokenizer_options, generate_kwargs);\n    }\n}\n\n\nconst WHISPER_LANGUAGES = [\n    [\"en\", \"english\"],\n    [\"zh\", \"chinese\"],\n    [\"de\", \"german\"],\n    [\"es\", \"spanish\"],\n    [\"ru\", \"russian\"],\n    [\"ko\", \"korean\"],\n    [\"fr\", \"french\"],\n    [\"ja\", \"japanese\"],\n    [\"pt\", \"portuguese\"],\n    [\"tr\", \"turkish\"],\n    [\"pl\", \"polish\"],\n    [\"ca\", \"catalan\"],\n    [\"nl\", \"dutch\"],\n    [\"ar\", \"arabic\"],\n    [\"sv\", \"swedish\"],\n    [\"it\", \"italian\"],\n    [\"id\", \"indonesian\"],\n    [\"hi\", \"hindi\"],\n    [\"fi\", \"finnish\"],\n    [\"vi\", \"vietnamese\"],\n    [\"he\", \"hebrew\"],\n    [\"uk\", \"ukrainian\"],\n    [\"el\", \"greek\"],\n    [\"ms\", \"malay\"],\n    [\"cs\", \"czech\"],\n    [\"ro\", \"romanian\"],\n    [\"da\", \"danish\"],\n    [\"hu\", \"hungarian\"],\n    [\"ta\", \"tamil\"],\n    [\"no\", \"norwegian\"],\n    [\"th\", \"thai\"],\n    [\"ur\", \"urdu\"],\n    [\"hr\", \"croatian\"],\n    [\"bg\", \"bulgarian\"],\n    [\"lt\", \"lithuanian\"],\n    [\"la\", \"latin\"],\n    [\"mi\", \"maori\"],\n    [\"ml\", \"malayalam\"],\n    [\"cy\", \"welsh\"],\n    [\"sk\", \"slovak\"],\n    [\"te\", \"telugu\"],\n    [\"fa\", \"persian\"],\n    [\"lv\", \"latvian\"],\n    [\"bn\", \"bengali\"],\n    [\"sr\", \"serbian\"],\n    [\"az\", \"azerbaijani\"],\n    [\"sl\", \"slovenian\"],\n    [\"kn\", \"kannada\"],\n    [\"et\", \"estonian\"],\n    [\"mk\", \"macedonian\"],\n    [\"br\", \"breton\"],\n    [\"eu\", \"basque\"],\n    [\"is\", \"icelandic\"],\n    [\"hy\", \"armenian\"],\n    [\"ne\", \"nepali\"],\n    [\"mn\", \"mongolian\"],\n    [\"bs\", \"bosnian\"],\n    [\"kk\", \"kazakh\"],\n    [\"sq\", \"albanian\"],\n    [\"sw\", \"swahili\"],\n    [\"gl\", \"galician\"],\n    [\"mr\", \"marathi\"],\n    [\"pa\", \"punjabi\"],\n    [\"si\", \"sinhala\"],\n    [\"km\", \"khmer\"],\n    [\"sn\", \"shona\"],\n    [\"yo\", \"yoruba\"],\n    [\"so\", \"somali\"],\n    [\"af\", \"afrikaans\"],\n    [\"oc\", \"occitan\"],\n    [\"ka\", \"georgian\"],\n    [\"be\", \"belarusian\"],\n    [\"tg\", \"tajik\"],\n    [\"sd\", \"sindhi\"],\n    [\"gu\", \"gujarati\"],\n    [\"am\", \"amharic\"],\n    [\"yi\", \"yiddish\"],\n    [\"lo\", \"lao\"],\n    [\"uz\", \"uzbek\"],\n    [\"fo\", \"faroese\"],\n    [\"ht\", \"haitian creole\"],\n    [\"ps\", \"pashto\"],\n    [\"tk\", \"turkmen\"],\n    [\"nn\", \"nynorsk\"],\n    [\"mt\", \"maltese\"],\n    [\"sa\", \"sanskrit\"],\n    [\"lb\", \"luxembourgish\"],\n    [\"my\", \"myanmar\"],\n    [\"bo\", \"tibetan\"],\n    [\"tl\", \"tagalog\"],\n    [\"mg\", \"malagasy\"],\n    [\"as\", \"assamese\"],\n    [\"tt\", \"tatar\"],\n    [\"haw\", \"hawaiian\"],\n    [\"ln\", \"lingala\"],\n    [\"ha\", \"hausa\"],\n    [\"ba\", \"bashkir\"],\n    [\"jw\", \"javanese\"],\n    [\"su\", \"sundanese\"],\n]\n\n// @ts-ignore\nconst WHISPER_LANGUAGE_MAPPING = new Map(WHISPER_LANGUAGES);\n// @ts-ignore\nconst WHISPER_TO_LANGUAGE_CODE_MAPPING = new Map([\n    ...WHISPER_LANGUAGES.map(([k, v]) => [v, k]),\n    ...[\n        [\"burmese\", \"my\"],\n        [\"valencian\", \"ca\"],\n        [\"flemish\", \"nl\"],\n        [\"haitian\", \"ht\"],\n        [\"letzeburgesch\", \"lb\"],\n        [\"pushto\", \"ps\"],\n        [\"panjabi\", \"pa\"],\n        [\"moldavian\", \"ro\"],\n        [\"moldovan\", \"ro\"],\n        [\"sinhalese\", \"si\"],\n        [\"castilian\", \"es\"],\n    ]\n]);\n\n/**\n * WhisperTokenizer tokenizer\n * @extends PreTrainedTokenizer\n */\nclass WhisperTokenizer extends PreTrainedTokenizer {\n    _default_chat_template = `{% for message in messages %}\" \"{{ message.content }}{{ eos_token }}\" \"{% endfor %}`;\n\n    /**\n     * Decodes automatic speech recognition (ASR) sequences.\n     * @param {Array<{tokens: number[], token_timestamps?: number[], stride: number[]}>} sequences The sequences to decode.\n     * @param {Object} options The options to use for decoding.\n     * @returns {Array<string|{chunks?: undefined|Array<{language: string|null, timestamp: Array<number|null>, text: string}>}>} The decoded sequences.\n     */\n    _decode_asr(sequences, {\n        return_timestamps = false,\n        return_language = false,\n        time_precision = null,\n        force_full_sequences = true\n    } = {}) {\n        // Set force_full_sequences=false if you want streaming\n        // TODO add support for `return_language`\n\n        // Internal method meant to only be used by asr pipeline.\n        // Handles all the little quirks specific to whisper to handle\n        // the various options not allowed in other seq2seq models\n\n        // =========== Overview ============\n        // - iterate over all outputs\n        // - all tokens within output\n        // - Each token can be\n        //   - language token\n        //   - special token\n        //   - timestamp token\n        //   - text token\n        // - We accumulate the text tokens.\n        // - We split on end timestamps\n        // - Lots of complexity comes from stride and timestamps\n\n        if (time_precision === null) {\n            throw Error(\"Must specify time_precision\")\n        }\n        let last_language = null;\n\n        const returnWordTimestamps = return_timestamps === \"word\";\n\n        function new_chunk() {\n            return { \"language\": last_language, \"timestamp\": [null, null], \"text\": \"\" };\n        }\n\n        // Welcome to the state machine!\n        const chunks = [];\n        let chunk = new_chunk();\n        let time_offset = 0.0;\n        const timestamp_begin = this.model.convert_tokens_to_ids([\"<|notimestamps|>\"])[0] + 1;\n\n        let previous_tokens = [];\n        let previous_token_timestamps = [];\n\n        let skip = false;\n        let right_stride_start = null;\n\n\n        const all_special_ids = new Set(this.all_special_ids);\n\n        for (const output of sequences) {\n            // NOTE: python version has batches, so it uses [0]\n            const token_ids = output.tokens;\n            const token_timestamps = returnWordTimestamps ? output.token_timestamps : null;\n\n            // These keep track of timestamps within strides, which need\n            // to be skipped and resolve all tokens in a single chunk.\n            let last_timestamp = null;\n            let first_timestamp = timestamp_begin;\n\n            if (\"stride\" in output) {\n                const [chunk_len, stride_left, stride_right] = output.stride;\n\n                // Offset the timings to account for the other `model_outputs`.\n                time_offset -= stride_left;\n                right_stride_start = chunk_len - stride_right;\n\n                // Keeping track of timestamps within strides\n                // We're going to NOT split on those, and delay until we're\n                // out of BOTH stride. Otherwise lots of issues occur and\n                // corner cases\n                if (stride_left) {\n                    first_timestamp = stride_left / time_precision + timestamp_begin;\n                }\n\n                if (stride_right) {\n                    for (let i = token_ids.length - 1; i >= 0; --i) {\n                        const token = token_ids[i];\n                        if (token >= timestamp_begin) {\n                            // There can be several token in the right stride\n                            // But the last one is ALWAYS going to be skipped\n                            if (last_timestamp !== null && (token - timestamp_begin) * time_precision < right_stride_start) {\n                                break;\n                            }\n                            last_timestamp = token;\n                        }\n                    }\n                }\n            }\n\n            let current_tokens = [];\n            let current_token_timestamps = [];\n\n            // - all tokens within output\n            for (let i = 0; i < token_ids.length; ++i) {\n                const token = token_ids[i];\n                // 4 possible states for each token\n                // - 1/ Language code\n                // - 2/ all other special tokens (which we ignore)\n                // - 3/ Timestamp\n                // - 4/ Regular text\n\n                if (all_special_ids.has(token)) {\n                    const text = this.decode([token]);\n                    const language = WHISPER_LANGUAGE_MAPPING.get(text.slice(2, -2));\n\n                    if (language !== undefined) {\n                        // 1/ Indeed some language\n                        // TODO Handle when language is different from the previous\n                        // one, and we cannot use timestamped tokens to create chunks\n                        if (last_language !== null && language !== last_language && !return_timestamps) {\n                            previous_tokens.push(current_tokens);\n                            const resolved_tokens = this.findLongestCommonSequence(previous_tokens)[0];\n                            const resolved_text = this.decode(resolved_tokens);\n                            chunk.text = resolved_text;\n                            chunks.push(chunk);\n\n                            // Flush all our temporary context\n                            previous_tokens = [];\n                            current_tokens = [];\n                            chunk = new_chunk();\n                        }\n\n                        last_language = chunk.language = language;\n                    } else {\n                        // 2/ This is a regular special token, ignoring it\n                    }\n                } else if (token >= timestamp_begin) {\n                    // 3/ Timestamp token\n                    const time = (token - timestamp_begin) * time_precision + time_offset;\n                    const rounded_time = (0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_2__.round)(time, 2);\n\n                    if (last_timestamp !== null && token >= last_timestamp) {\n                        // Whisper outputted a timestamp token, but it falls within\n                        // our stride, so we're going to skip it for the time being\n                        // and resolve this later\n                        // Skip is necessary because timestamp tokens always come\n                        // by pair, so we need to skip the next one too (which would mark the start of another chunk).\n                        skip = true;\n                    } else if (skip || (previous_tokens.length > 0 && token < first_timestamp)) {\n                        skip = false;\n                    } else if (chunk.timestamp[0] === null) {\n                        chunk.timestamp[0] = rounded_time;\n                    } else {\n                        // This is the end of the timestamp chunk\n                        if (rounded_time === chunk.timestamp[0]) {\n                            // This is a bug in timestamp token output\n                            // where we're taking the duplicate token\n                            // as a stop where it should be a start.\n                            // This is an issue in the underlying model output\n                            // Let's just skip it so it becomes de-factor a start agin\n                        } else {\n                            chunk.timestamp[1] = rounded_time;\n\n                            // Handling merges\n                            previous_tokens.push(current_tokens)\n\n                            if (returnWordTimestamps) {\n                                previous_token_timestamps.push(current_token_timestamps);\n                            }\n                            const [resolved_tokens, resolved_token_timestamps] = this.findLongestCommonSequence(\n                                previous_tokens, previous_token_timestamps\n                            )\n\n                            const resolved_text = this.decode(resolved_tokens)\n                            chunk.text = resolved_text\n\n                            if (returnWordTimestamps) {\n                                chunk.words = this.collateWordTimestamps(\n                                    resolved_tokens, resolved_token_timestamps, last_language,\n                                )\n                            }\n\n                            chunks.push(chunk)\n\n                            // Flush all our temporary context\n                            previous_tokens = []\n                            current_tokens = []\n                            previous_token_timestamps = []\n                            current_token_timestamps = []\n                            chunk = new_chunk()\n                        }\n                    }\n\n                } else {\n                    // 4/ Regular token\n                    // We just append to the list of all tokens so we can handle\n                    // merges later and decode into text.\n                    current_tokens.push(token)\n\n                    if (returnWordTimestamps) {\n                        let start_time = (0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_2__.round)(token_timestamps[i] + time_offset, 2);\n\n                        let end_time;\n                        if (i + 1 < token_timestamps.length) {\n                            end_time = (0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_2__.round)(token_timestamps[i + 1] + time_offset, 2);\n                        } else {\n                            // should never happen\n                            end_time = null;\n                        }\n                        current_token_timestamps.push([start_time, end_time]);\n                    }\n\n                }\n            }\n\n            if ('stride' in output) {\n                const [chunk_len, stride_left, stride_right] = output.stride;\n                time_offset += chunk_len - stride_right\n            }\n\n            // Leftover tokens\n            if (current_tokens.length > 0) {\n                previous_tokens.push(current_tokens)\n                if (returnWordTimestamps) {\n                    previous_token_timestamps.push(current_token_timestamps);\n                }\n            } else if (previous_tokens.every(p => p.length === 0)) {\n                // Flushing previous tokens (END)\"\n                chunk = new_chunk()\n                previous_tokens = []\n                current_tokens = []\n                previous_token_timestamps = [];\n                current_token_timestamps = [];\n            }\n\n        }\n\n        if (previous_tokens.length > 0) {\n            if (force_full_sequences && return_timestamps) {\n                // Last token should always be timestamps, so there shouldn't be\n                // leftover\n                throw new Error(\n                    \"Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. \" +\n                    \"Also make sure WhisperTimeStampLogitsProcessor was used during generation.\"\n                );\n            }\n\n            // Happens when we don't use timestamps\n            const [resolved_tokens, resolved_token_timestamps] = this.findLongestCommonSequence(previous_tokens, previous_token_timestamps);\n\n            // Flushing previous tokens (FINAL)\n            const resolved_text = this.decode(resolved_tokens);\n            chunk.text = resolved_text;\n            if (returnWordTimestamps) {\n                chunk.words = this.collateWordTimestamps(\n                    resolved_tokens, resolved_token_timestamps, last_language,\n                )\n            }\n            chunks.push(chunk);\n        }\n\n        let optional = Object.create(null);\n\n        // Preparing and cleaning up the pipeline output\n        const full_text = chunks.map(chunk => chunk.text).join('');\n        if (return_timestamps || return_language) {\n            for (let i = 0; i < chunks.length; ++i) {\n                const chunk = chunks[i];\n                if (!return_timestamps) {\n                    delete chunk[\"timestamp\"];\n                }\n\n                if (!return_language) {\n                    delete chunk[\"language\"];\n                }\n            }\n            if (returnWordTimestamps) {\n                const new_chunks = [];\n                for (const chunk of chunks) {\n                    for (const word of chunk.words) {\n                        new_chunks.push(word);\n                    }\n                }\n                optional = { \"chunks\": new_chunks };\n            } else {\n                optional = { \"chunks\": chunks };\n            }\n        }\n        return [full_text, optional];\n\n    }\n\n    /**\n     * Finds the longest common sequence among the provided sequences.\n     * @param {number[][]} sequences An array of sequences of token ids to compare.\n     * @returns {number[][]} The longest common sequence found.\n     * @throws {Error} If there is a bug within the function.\n     * @private\n     */\n    findLongestCommonSequence(sequences, token_timestamp_sequences = null) {\n        // It would be much harder to do O(n) because of fault tolerance.\n        // We actually have a really good property which is that the total sequence\n        // MUST be those subsequences in order.\n        // If token_timestamp_sequences is provided, will split those sequences in\n        // exactly the same way.\n        let leftSequence = sequences[0];\n        let leftLength = leftSequence.length;\n        let totalSequence = [];\n\n        const use_token_timestamp_sequences = Array.isArray(token_timestamp_sequences) && token_timestamp_sequences.length > 0;\n        let total_token_timestamp_sequence = use_token_timestamp_sequences ? [] : null;\n        let left_token_timestamp_sequence = use_token_timestamp_sequences ? token_timestamp_sequences[0] : null;\n        for (let i = 1; i < sequences.length; ++i) {\n            const rightSequence = sequences[i];\n            let max = 0.0;\n            let maxIndices = [leftLength, leftLength, 0, 0];\n            // Here we're sliding matches\n            // [a, b, c, d]\n            //          [c, d, f]\n            // =        [c] == [d]\n\n            // [a, b, c, d]\n            //       [c, d, f]\n            // =     [c, d] == [c, d]\n\n\n            // [a, b, c, d]\n            //    [c, d, f]\n\n            // =  [b, c, d] == [c, d, f]\n\n            // [a, b, c, d]\n            // [c, d, f]\n\n            // [a, b, c] == [c, d, f]\n\n            // [a, b, c, d]\n            // [d, f]\n\n            // [a, b] == [d, f]\n\n            // [a, b, c, d]\n            // [f]\n\n            // [a] == [f]\n\n            const rightLength = rightSequence.length;\n            for (let j = 1; j < leftLength + rightLength; ++j) {\n                const eps = j / 10000.0;\n                const leftStart = Math.max(0, leftLength - j);\n                const leftStop = Math.min(leftLength, leftLength + rightLength - j);\n                const left = leftSequence.slice(leftStart, leftStop);\n                const rightStart = Math.max(0, j - leftLength);\n                const rightStop = Math.min(rightLength, j);\n                const right = rightSequence.slice(rightStart, rightStop);\n                if (left.length !== right.length) {\n                    throw new Error(\"There is a bug within whisper `decode_asr` function, please report it. Dropping to prevent bad inference.\");\n                }\n                const matches = left.filter((elem, idx) => elem === right[idx]).length;\n                const matching = matches / j + eps;\n                if (matches > 1 && matching > max) {\n                    max = matching;\n                    maxIndices = [leftStart, leftStop, rightStart, rightStop];\n                }\n            }\n            const [leftStart, leftStop, rightStart, rightStop] = maxIndices;\n            const leftMid = Math.floor((leftStop + leftStart) / 2);\n            const rightMid = Math.floor((rightStop + rightStart) / 2);\n            totalSequence.push(...leftSequence.slice(0, leftMid));\n            leftSequence = rightSequence.slice(rightMid);\n            leftLength = leftSequence.length;\n\n            if (use_token_timestamp_sequences) {\n                total_token_timestamp_sequence.push(...left_token_timestamp_sequence.slice(0, leftMid));\n                left_token_timestamp_sequence = token_timestamp_sequences[i].slice(rightMid);\n            }\n        }\n        totalSequence.push(...leftSequence);\n\n        if (use_token_timestamp_sequences) {\n            total_token_timestamp_sequence.push(...left_token_timestamp_sequence);\n            return [totalSequence, total_token_timestamp_sequence];\n        } else {\n            return [totalSequence, []];\n        }\n    }\n\n    /** @private */\n    collateWordTimestamps(tokens, token_timestamps, language) {\n\n        const [words, _, token_indices] = this.combineTokensIntoWords(tokens, language);\n\n        const timings = [];\n        for (let i = 0; i < words.length; ++i) {\n            const indices = token_indices[i];\n            timings.push({\n                text: words[i],\n                timestamp: [\n                    token_timestamps[indices.at(0)][0],\n                    token_timestamps[indices.at(-1)][1],\n                ],\n            });\n        }\n        return timings;\n    }\n\n    /**\n     * Groups tokens by word. Returns a tuple containing a list of strings with the words,\n     * and a list of `token_id` sequences with the tokens making up each word.\n     * @param {number[]} tokens \n     * @param {string} [language] \n     * @param {string} prepend_punctionations \n     * @param {string} append_punctuations \n     * \n     * @private\n     */\n    combineTokensIntoWords(tokens, language, prepend_punctionations = \"\\\"'([{-\", append_punctuations = \"\\\"'.,!?:)]}\") {\n        language = language ?? 'english';\n\n        let words, word_tokens, token_indices;\n\n        if ([\"chinese\", \"japanese\", \"thai\", \"lao\", \"myanmar\"].includes(language)) {\n            // These languages don't typically use spaces.\n            [words, word_tokens, token_indices] = this.splitTokensOnUnicode(tokens)\n        } else {\n            [words, word_tokens, token_indices] = this.splitTokensOnSpaces(tokens)\n        }\n\n        return this.mergePunctuations(words, word_tokens, token_indices, prepend_punctionations, append_punctuations);\n    }\n\n    /** @type {PreTrainedTokenizer['decode']} */\n    decode(\n        token_ids,\n        decode_args,\n    ) {\n        let text;\n        // @ts-ignore\n        if (decode_args && decode_args.decode_with_timestamps) {\n            if (token_ids instanceof _utils_tensor_js__WEBPACK_IMPORTED_MODULE_3__.Tensor) {\n                token_ids = prepareTensorForDecode(token_ids);\n            }\n            text = this.decodeWithTimestamps(token_ids, decode_args);\n        } else {\n            text = super.decode(token_ids, decode_args);\n        }\n        // TODO: implement offsets\n        // if (decode_args.output_offsets) {\n        //     let offsets = this.computeOffsets\n        // }\n        return text;\n    }\n\n    /**\n     * @param {number[]} token_ids List of token IDs to decode.\n     * @param {Object} decode_args Optional arguments for decoding\n     * @private\n     */\n    decodeWithTimestamps(token_ids, decode_args) {\n        const time_precision = decode_args?.time_precision ?? 0.02;\n\n        const timestamp_begin = Array.from(this.all_special_ids).at(-1) + 1;\n        /**@type {Array} */\n        let outputs = [[]];\n        for (const token of token_ids) {\n            if (token >= timestamp_begin) {\n                const timestamp = (0,_utils_maths_js__WEBPACK_IMPORTED_MODULE_2__.round)((token - timestamp_begin) * time_precision, 2);\n                outputs.push(`<|${timestamp}|>`);\n                outputs.push([]);\n            } else {\n                outputs[outputs.length - 1].push(token);\n            }\n        }\n        outputs = outputs.map(\n            s => {\n                if (typeof s === 'string') {\n                    return s;\n                } else {\n                    return super.decode(s, decode_args);\n                }\n            }\n        )\n\n        return outputs.join('');\n    }\n\n    /**\n     * Combine tokens into words by splitting at any position where the tokens are decoded as valid unicode points.\n     * @param {number[]} tokens \n     * @returns {*}\n     * @private\n     */\n    splitTokensOnUnicode(tokens) {\n        const decoded_full = this.decode(tokens, {\n            // @ts-ignore\n            decode_with_timestamps: true,\n        });\n        const replacement_char = '\\uFFFD';\n\n        const words = []\n        const word_tokens = []\n        const token_indices = []\n        let current_tokens = []\n        let current_indices = []\n        let unicode_offset = 0\n\n        for (let token_idx = 0; token_idx < tokens.length; ++token_idx) {\n            const token = tokens[token_idx];\n\n            current_tokens.push(token);\n            current_indices.push(token_idx);\n\n            const decoded = this.decode(current_tokens, {\n                // @ts-ignore\n                decode_with_timestamps: true,\n            });\n\n            if (!decoded.includes(replacement_char) || decoded_full[unicode_offset + decoded.indexOf(replacement_char)] === replacement_char) {\n                words.push(decoded)\n                word_tokens.push(current_tokens)\n                token_indices.push(current_indices)\n                current_tokens = []\n                current_indices = []\n                unicode_offset += decoded.length;\n            }\n\n        }\n\n        return [words, word_tokens, token_indices]\n    }\n\n    /**\n     * Combine tokens into words by splitting at whitespace and punctuation tokens.\n     * @param {number[]} tokens \n     * @private\n     */\n    splitTokensOnSpaces(tokens) {\n\n        const [subwords, subword_tokens_list, subword_indices_list] = this.splitTokensOnUnicode(tokens);\n\n        const words = []\n        const word_tokens = []\n        const token_indices = []\n\n        const punctuationRegex = new RegExp(`^[${PUNCTUATION_REGEX}]$`, 'gu');\n\n        for (let i = 0; i < subwords.length; ++i) {\n\n            const subword = subwords[i];\n            const subword_tokens = subword_tokens_list[i];\n            const subword_indices = subword_indices_list[i];\n\n            // @ts-ignore\n            const special = subword_tokens[0] >= this.model.tokens_to_ids.get('<|endoftext|>');\n            const with_space = subword.startsWith(' ');\n            const trimmed = subword.trim();\n            const punctuation = punctuationRegex.test(trimmed);\n\n            if (special || with_space || punctuation || words.length === 0) {\n                words.push(subword);\n                word_tokens.push(subword_tokens);\n                token_indices.push(subword_indices);\n            } else {\n                const ix = words.length - 1;\n                words[ix] += subword;\n                word_tokens[ix].push(...subword_tokens);\n                token_indices[ix].push(...subword_indices);\n            }\n        }\n\n        return [words, word_tokens, token_indices];\n\n    }\n\n    /**\n     * Merges punctuation tokens with neighboring words.\n     * @param {string[]} words \n     * @param {number[][]} tokens \n     * @param {number[][]} indices \n     * @param {string} prepended \n     * @param {string} appended \n     * @private\n     */\n    mergePunctuations(words, tokens, indices, prepended, appended) {\n\n        const newWords = structuredClone(words);\n        const newTokens = structuredClone(tokens);\n        const newIndices = structuredClone(indices);\n\n\n        // prepend punctuations\n        let i = newWords.length - 2;\n        let j = newWords.length - 1;\n\n        while (i >= 0) {\n            if (newWords[i].startsWith(' ') && prepended.includes(newWords[i].trim())) {\n                newWords[j] = newWords[i] + newWords[j];\n                newTokens[j] = (0,_utils_core_js__WEBPACK_IMPORTED_MODULE_0__.mergeArrays)(newTokens[i], newTokens[j]);\n                newIndices[j] = (0,_utils_core_js__WEBPACK_IMPORTED_MODULE_0__.mergeArrays)(newIndices[i], newIndices[j]);\n                newWords[i] = '';\n                newTokens[i] = [];\n                newIndices[i] = [];\n            } else {\n                j = i;\n            }\n            --i;\n        }\n\n        // append punctuations\n        i = 0;\n        j = 1;\n        while (j < newWords.length) {\n            if (!newWords[i].endsWith(' ') && appended.includes(newWords[j])) {\n                newWords[i] += newWords[j];\n                newTokens[i] = (0,_utils_core_js__WEBPACK_IMPORTED_MODULE_0__.mergeArrays)(newTokens[i], newTokens[j]);\n                newIndices[i] = (0,_utils_core_js__WEBPACK_IMPORTED_MODULE_0__.mergeArrays)(newIndices[i], newIndices[j]);\n                newWords[j] = '';\n                newTokens[j] = [];\n                newIndices[j] = [];\n            } else {\n                i = j;\n            }\n            ++j;\n        }\n\n        return [\n            newWords.filter(x => x),\n            newTokens.filter(x => x.length > 0),\n            newIndices.filter(x => x.length > 0),\n        ]\n    }\n\n    /**\n     * Helper function to build translation inputs for a `WhisperTokenizer`,\n     * depending on the language, task, and whether to predict timestamp tokens.\n     * \n     * Used to override the prefix tokens appended to the start of the label sequence.\n     * \n     * **Example: Get ids for a language**\n     * ```javascript\n     * // instantiate the tokenizer and set the prefix token to Spanish\n     * const tokenizer = await WhisperTokenizer.from_pretrained('Xenova/whisper-tiny');\n     * const forced_decoder_ids = tokenizer.get_decoder_prompt_ids({ language: 'spanish' });\n     * // [(1, 50262), (2, 50363)]\n     * ```\n     * \n     * @param {Object} options Options to generate the decoder prompt.\n     * @param {string} [options.language] The language of the transcription text.\n     * The corresponding language id token is appended to the start of the sequence for multilingual\n     * speech recognition and speech translation tasks, e.g. for \"Spanish\" the token \"<|es|>\" is appended\n     * to the start of sequence.\n     * @param {string} [options.task] Task identifier to append at the start of sequence (if any).\n     * This should be used for mulitlingual fine-tuning, with \"transcribe\" for speech recognition and\n     * \"translate\" for speech translation.\n     * @param {boolean} [options.no_timestamps] Whether to add the <|notimestamps|> token at the start of the sequence.\n     * @returns {number[][]} The decoder prompt ids.\n     */\n    get_decoder_prompt_ids({\n        language = null,\n        task = null,\n        no_timestamps = true,\n    } = {}) {\n\n        // <|lang_id|> <|task|> <|notimestamps|>\n\n        const forced_decoder_ids = [];\n\n        if (language) {\n            // User wishes to specify the language\n            language = language.toLowerCase();\n\n            // Map to code from user-friendly name (e.g., \"english\" -> \"en\")\n            let language_code = WHISPER_TO_LANGUAGE_CODE_MAPPING.get(language);\n\n            if (language_code === undefined) {\n                // User provided something that is not a language name\n\n                if (WHISPER_LANGUAGE_MAPPING.has(language)) {\n                    // User provided the language code directly (e.g., \"en\")\n                    language_code = language;\n\n                } else {\n                    // User provided something that is not a language code or name\n                    const is_language_code = language.length === 2;\n                    const langs = is_language_code ? WHISPER_LANGUAGE_MAPPING.keys() : WHISPER_LANGUAGE_MAPPING.values();\n\n                    throw new Error(`Language \"${language}\" is not supported. Must be one of: ${JSON.stringify(langs)}`);\n                }\n            }\n\n            const language_token_id = this.model.tokens_to_ids.get(`<|${language_code}|>`);\n            if (language_token_id === undefined) {\n                throw new Error(`Unable to find language \"${language_code}\" in model vocabulary. Please report this issue at https://github.com/xenova/transformers.js/issues/new/choose.`)\n            }\n\n            forced_decoder_ids.push(language_token_id);\n        } else {\n            // No token will be forced, which leaves the model to predict the language\n            forced_decoder_ids.push(null);\n        }\n\n        if (task) {\n            task = task.toLowerCase();\n            if (task !== 'transcribe' && task !== 'translate') {\n                throw new Error(`Task \"${task}\" is not supported. Must be one of: [\"transcribe\", \"translate\"]`);\n            }\n\n            const task_token_id = this.model.tokens_to_ids.get(`<|${task}|>`);\n            if (task_token_id === undefined) {\n                throw new Error(`Unable to find task \"${task}\" in model vocabulary. Please report this issue at https://github.com/xenova/transformers.js/issues/new/choose.`)\n            }\n\n            forced_decoder_ids.push(task_token_id);\n        } else {\n            // No token will be forced, which leaves the model to predict the task\n            forced_decoder_ids.push(null);\n        }\n\n        if (no_timestamps) {\n            const no_timestamps_id = this.model.tokens_to_ids.get(`<|notimestamps|>`);\n            if (no_timestamps_id === undefined) {\n                throw new Error('Unable to find \"<|notimestamps|>\" in model vocabulary. Please report this issue at https://github.com/xenova/transformers.js/issues/new/choose.')\n            }\n\n            forced_decoder_ids.push(no_timestamps_id);\n        }\n\n        return forced_decoder_ids.map((x, i) => [i + 1, x]).filter(x => x[1] !== null);\n\n    }\n}\nclass CodeGenTokenizer extends PreTrainedTokenizer { }\nclass CLIPTokenizer extends PreTrainedTokenizer { }\nclass SiglipTokenizer extends PreTrainedTokenizer { }\n\n/**\n * @todo This model is not yet supported by Hugging Face's \"fast\" tokenizers library (https://github.com/huggingface/tokenizers).\n * Therefore, this implementation (which is based on fast tokenizers) may produce slightly inaccurate results.\n */\nclass MarianTokenizer extends PreTrainedTokenizer {\n    /**\n     * Create a new MarianTokenizer instance.\n     * @param {Object} tokenizerJSON The JSON of the tokenizer.\n     * @param {Object} tokenizerConfig The config of the tokenizer.\n     */\n    constructor(tokenizerJSON, tokenizerConfig) {\n        super(tokenizerJSON, tokenizerConfig);\n\n        this.languageRegex = /^(>>\\w+<<)\\s*/g;\n\n        this.supported_language_codes = this.model.vocab.filter(\n            x => this.languageRegex.test(x)\n        );\n\n        console.warn('WARNING: `MarianTokenizer` is not yet supported by Hugging Face\\'s \"fast\" tokenizers library. Therefore, you may experience slightly inaccurate results.')\n    }\n\n    /**\n     * Encodes a single text. Overriding this method is necessary since the language codes\n     * must be removed before encoding with sentencepiece model.\n     * @see https://github.com/huggingface/transformers/blob/12d51db243a00726a548a43cc333390ebae731e3/src/transformers/models/marian/tokenization_marian.py#L204-L213\n     *\n     * @param {string|null} text The text to encode.\n     * @returns {Array} The encoded tokens.\n     */\n    _encode_text(text) {\n        if (text === null) return null;\n\n        // Check if text starts with language code:\n        const [matchInfo, ...remainder] = text.trim().split(this.languageRegex);\n\n        if (remainder.length === 0) {\n            // No language code, encode normally\n            return super._encode_text(matchInfo);\n\n        } else if (remainder.length === 2) {\n            // Text starts with language code, so we do not encode it with sentencepiece.\n            const [language, text] = remainder;\n\n            if (!this.supported_language_codes.includes(language)) {\n                console.warn(`Unsupported language code \"${language}\" detected, which may lead to unexpected behavior. Should be one of: ${JSON.stringify(this.supported_language_codes)}`)\n            }\n            return (0,_utils_core_js__WEBPACK_IMPORTED_MODULE_0__.mergeArrays)([language], super._encode_text(text));\n        }\n    }\n\n}\n\nclass Wav2Vec2CTCTokenizer extends PreTrainedTokenizer { }\n\nclass BlenderbotTokenizer extends PreTrainedTokenizer {\n    _default_chat_template = `{% for message in messages %}{% if message['role'] == 'user' %}{{ ' ' }}{% endif %}{{ message['content'] }}{% if not loop.last %}{{ '  ' }}{% endif %}{% endfor %}{{ eos_token }}`;\n}\nclass BlenderbotSmallTokenizer extends BlenderbotTokenizer { } // NOTE `BlenderbotTokenizer` to get the correct chat template\n\nclass SpeechT5Tokenizer extends PreTrainedTokenizer { }\n\nclass NougatTokenizer extends PreTrainedTokenizer { }\n\nclass VitsTokenizer extends PreTrainedTokenizer {\n\n    constructor(tokenizerJSON, tokenizerConfig) {\n        super(tokenizerJSON, tokenizerConfig);\n\n        // Custom decoder function\n        this.decoder = new VitsDecoder({});\n    }\n}\n/**\n * Helper class which is used to instantiate pretrained tokenizers with the `from_pretrained` function.\n * The chosen tokenizer class is determined by the type specified in the tokenizer config.\n * \n * @example\n * const tokenizer = await AutoTokenizer.from_pretrained('Xenova/bert-base-uncased');\n */\nclass AutoTokenizer {\n    static TOKENIZER_CLASS_MAPPING = {\n        T5Tokenizer,\n        DistilBertTokenizer,\n        CamembertTokenizer,\n        DebertaTokenizer,\n        DebertaV2Tokenizer,\n        BertTokenizer,\n        HerbertTokenizer,\n        ConvBertTokenizer,\n        RoFormerTokenizer,\n        XLMTokenizer,\n        ElectraTokenizer,\n        MobileBertTokenizer,\n        SqueezeBertTokenizer,\n        AlbertTokenizer,\n        GPT2Tokenizer,\n        BartTokenizer,\n        MBartTokenizer,\n        MBart50Tokenizer,\n        RobertaTokenizer,\n        WhisperTokenizer,\n        CodeGenTokenizer,\n        CLIPTokenizer,\n        SiglipTokenizer,\n        MarianTokenizer,\n        BloomTokenizer,\n        NllbTokenizer,\n        M2M100Tokenizer,\n        LlamaTokenizer,\n        CodeLlamaTokenizer,\n        XLMRobertaTokenizer,\n        MPNetTokenizer,\n        FalconTokenizer,\n        GPTNeoXTokenizer,\n        EsmTokenizer,\n        Wav2Vec2CTCTokenizer,\n        BlenderbotTokenizer,\n        BlenderbotSmallTokenizer,\n        SpeechT5Tokenizer,\n        NougatTokenizer,\n        VitsTokenizer,\n        Qwen2Tokenizer,\n        GemmaTokenizer,\n\n        // Base case:\n        PreTrainedTokenizer,\n    }\n\n\n    /**\n     * Instantiate one of the tokenizer classes of the library from a pretrained model.\n     * \n     * The tokenizer class to instantiate is selected based on the `tokenizer_class` property of the config object\n     * (either passed as an argument or loaded from `pretrained_model_name_or_path` if possible)\n     * \n     * @param {string} pretrained_model_name_or_path The name or path of the pretrained model. Can be either:\n     * - A string, the *model id* of a pretrained tokenizer hosted inside a model repo on huggingface.co.\n     *   Valid model ids can be located at the root-level, like `bert-base-uncased`, or namespaced under a\n     *   user or organization name, like `dbmdz/bert-base-german-cased`.\n     * - A path to a *directory* containing tokenizer files, e.g., `./my_model_directory/`.\n     * @param {PretrainedTokenizerOptions} options Additional options for loading the tokenizer.\n     * \n     * @returns {Promise<PreTrainedTokenizer>} A new instance of the PreTrainedTokenizer class.\n     */\n    static async from_pretrained(pretrained_model_name_or_path, {\n        quantized = true,\n        progress_callback = null,\n        config = null,\n        cache_dir = null,\n        local_files_only = false,\n        revision = 'main',\n        legacy = null,\n    } = {}) {\n\n        const [tokenizerJSON, tokenizerConfig] = await loadTokenizer(pretrained_model_name_or_path, {\n            quantized,\n            progress_callback,\n            config,\n            cache_dir,\n            local_files_only,\n            revision,\n            legacy,\n        })\n\n        // Some tokenizers are saved with the \"Fast\" suffix, so we remove that if present.\n        const tokenizerName = tokenizerConfig.tokenizer_class?.replace(/Fast$/, '') ?? 'PreTrainedTokenizer';\n\n        let cls = this.TOKENIZER_CLASS_MAPPING[tokenizerName];\n        if (!cls) {\n            console.warn(`Unknown tokenizer class \"${tokenizerName}\", attempting to construct from base class.`);\n            cls = PreTrainedTokenizer;\n        }\n        return new cls(tokenizerJSON, tokenizerConfig);\n    }\n}\n\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@xenova/transformers/src/tokenizers.js?");

/***/ }),

/***/ "./node_modules/@xenova/transformers/src/transformers.js":
/*!***************************************************************!*\
  !*** ./node_modules/@xenova/transformers/src/transformers.js ***!
  \***************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   ASTFeatureExtractor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.ASTFeatureExtractor),\n/* harmony export */   ASTForAudioClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ASTForAudioClassification),\n/* harmony export */   ASTModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ASTModel),\n/* harmony export */   ASTPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ASTPreTrainedModel),\n/* harmony export */   AlbertForMaskedLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.AlbertForMaskedLM),\n/* harmony export */   AlbertForQuestionAnswering: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.AlbertForQuestionAnswering),\n/* harmony export */   AlbertForSequenceClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.AlbertForSequenceClassification),\n/* harmony export */   AlbertModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.AlbertModel),\n/* harmony export */   AlbertPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.AlbertPreTrainedModel),\n/* harmony export */   AlbertTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.AlbertTokenizer),\n/* harmony export */   AudioClassificationPipeline: () => (/* reexport safe */ _pipelines_js__WEBPACK_IMPORTED_MODULE_0__.AudioClassificationPipeline),\n/* harmony export */   AutoConfig: () => (/* reexport safe */ _configs_js__WEBPACK_IMPORTED_MODULE_5__.AutoConfig),\n/* harmony export */   AutoModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.AutoModel),\n/* harmony export */   AutoModelForAudioClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.AutoModelForAudioClassification),\n/* harmony export */   AutoModelForCTC: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.AutoModelForCTC),\n/* harmony export */   AutoModelForCausalLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.AutoModelForCausalLM),\n/* harmony export */   AutoModelForDepthEstimation: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.AutoModelForDepthEstimation),\n/* harmony export */   AutoModelForDocumentQuestionAnswering: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.AutoModelForDocumentQuestionAnswering),\n/* harmony export */   AutoModelForImageClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.AutoModelForImageClassification),\n/* harmony export */   AutoModelForImageMatting: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.AutoModelForImageMatting),\n/* harmony export */   AutoModelForImageSegmentation: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.AutoModelForImageSegmentation),\n/* harmony export */   AutoModelForImageToImage: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.AutoModelForImageToImage),\n/* harmony export */   AutoModelForMaskGeneration: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.AutoModelForMaskGeneration),\n/* harmony export */   AutoModelForMaskedLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.AutoModelForMaskedLM),\n/* harmony export */   AutoModelForObjectDetection: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.AutoModelForObjectDetection),\n/* harmony export */   AutoModelForQuestionAnswering: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.AutoModelForQuestionAnswering),\n/* harmony export */   AutoModelForSemanticSegmentation: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.AutoModelForSemanticSegmentation),\n/* harmony export */   AutoModelForSeq2SeqLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.AutoModelForSeq2SeqLM),\n/* harmony export */   AutoModelForSequenceClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.AutoModelForSequenceClassification),\n/* harmony export */   AutoModelForSpeechSeq2Seq: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.AutoModelForSpeechSeq2Seq),\n/* harmony export */   AutoModelForTextToSpectrogram: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.AutoModelForTextToSpectrogram),\n/* harmony export */   AutoModelForTextToWaveform: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.AutoModelForTextToWaveform),\n/* harmony export */   AutoModelForTokenClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.AutoModelForTokenClassification),\n/* harmony export */   AutoModelForVision2Seq: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.AutoModelForVision2Seq),\n/* harmony export */   AutoModelForZeroShotObjectDetection: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.AutoModelForZeroShotObjectDetection),\n/* harmony export */   AutoProcessor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.AutoProcessor),\n/* harmony export */   AutoTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.AutoTokenizer),\n/* harmony export */   AutomaticSpeechRecognitionPipeline: () => (/* reexport safe */ _pipelines_js__WEBPACK_IMPORTED_MODULE_0__.AutomaticSpeechRecognitionPipeline),\n/* harmony export */   BartForConditionalGeneration: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.BartForConditionalGeneration),\n/* harmony export */   BartForSequenceClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.BartForSequenceClassification),\n/* harmony export */   BartModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.BartModel),\n/* harmony export */   BartPretrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.BartPretrainedModel),\n/* harmony export */   BartTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.BartTokenizer),\n/* harmony export */   BaseModelOutput: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.BaseModelOutput),\n/* harmony export */   BeitFeatureExtractor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.BeitFeatureExtractor),\n/* harmony export */   BeitForImageClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.BeitForImageClassification),\n/* harmony export */   BeitModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.BeitModel),\n/* harmony export */   BeitPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.BeitPreTrainedModel),\n/* harmony export */   BertForMaskedLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.BertForMaskedLM),\n/* harmony export */   BertForQuestionAnswering: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.BertForQuestionAnswering),\n/* harmony export */   BertForSequenceClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.BertForSequenceClassification),\n/* harmony export */   BertForTokenClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.BertForTokenClassification),\n/* harmony export */   BertModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.BertModel),\n/* harmony export */   BertPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.BertPreTrainedModel),\n/* harmony export */   BertTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.BertTokenizer),\n/* harmony export */   BitImageProcessor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.BitImageProcessor),\n/* harmony export */   BlenderbotForConditionalGeneration: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.BlenderbotForConditionalGeneration),\n/* harmony export */   BlenderbotModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.BlenderbotModel),\n/* harmony export */   BlenderbotPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.BlenderbotPreTrainedModel),\n/* harmony export */   BlenderbotSmallForConditionalGeneration: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.BlenderbotSmallForConditionalGeneration),\n/* harmony export */   BlenderbotSmallModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.BlenderbotSmallModel),\n/* harmony export */   BlenderbotSmallPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.BlenderbotSmallPreTrainedModel),\n/* harmony export */   BlenderbotSmallTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.BlenderbotSmallTokenizer),\n/* harmony export */   BlenderbotTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.BlenderbotTokenizer),\n/* harmony export */   BloomForCausalLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.BloomForCausalLM),\n/* harmony export */   BloomModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.BloomModel),\n/* harmony export */   BloomPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.BloomPreTrainedModel),\n/* harmony export */   BloomTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.BloomTokenizer),\n/* harmony export */   CLIPFeatureExtractor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.CLIPFeatureExtractor),\n/* harmony export */   CLIPModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.CLIPModel),\n/* harmony export */   CLIPPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.CLIPPreTrainedModel),\n/* harmony export */   CLIPSegForImageSegmentation: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.CLIPSegForImageSegmentation),\n/* harmony export */   CLIPSegModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.CLIPSegModel),\n/* harmony export */   CLIPSegPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.CLIPSegPreTrainedModel),\n/* harmony export */   CLIPTextModelWithProjection: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.CLIPTextModelWithProjection),\n/* harmony export */   CLIPTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.CLIPTokenizer),\n/* harmony export */   CLIPVisionModelWithProjection: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.CLIPVisionModelWithProjection),\n/* harmony export */   CamembertForMaskedLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.CamembertForMaskedLM),\n/* harmony export */   CamembertForQuestionAnswering: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.CamembertForQuestionAnswering),\n/* harmony export */   CamembertForSequenceClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.CamembertForSequenceClassification),\n/* harmony export */   CamembertForTokenClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.CamembertForTokenClassification),\n/* harmony export */   CamembertModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.CamembertModel),\n/* harmony export */   CamembertPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.CamembertPreTrainedModel),\n/* harmony export */   CamembertTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.CamembertTokenizer),\n/* harmony export */   CausalLMOutput: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.CausalLMOutput),\n/* harmony export */   CausalLMOutputWithPast: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.CausalLMOutputWithPast),\n/* harmony export */   ChineseCLIPFeatureExtractor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.ChineseCLIPFeatureExtractor),\n/* harmony export */   ChineseCLIPModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ChineseCLIPModel),\n/* harmony export */   ChineseCLIPPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ChineseCLIPPreTrainedModel),\n/* harmony export */   ClapAudioModelWithProjection: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ClapAudioModelWithProjection),\n/* harmony export */   ClapFeatureExtractor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.ClapFeatureExtractor),\n/* harmony export */   ClapModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ClapModel),\n/* harmony export */   ClapPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ClapPreTrainedModel),\n/* harmony export */   ClapTextModelWithProjection: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ClapTextModelWithProjection),\n/* harmony export */   CodeGenForCausalLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.CodeGenForCausalLM),\n/* harmony export */   CodeGenModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.CodeGenModel),\n/* harmony export */   CodeGenPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.CodeGenPreTrainedModel),\n/* harmony export */   CodeGenTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.CodeGenTokenizer),\n/* harmony export */   CodeLlamaTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.CodeLlamaTokenizer),\n/* harmony export */   ConvBertForMaskedLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ConvBertForMaskedLM),\n/* harmony export */   ConvBertForQuestionAnswering: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ConvBertForQuestionAnswering),\n/* harmony export */   ConvBertForSequenceClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ConvBertForSequenceClassification),\n/* harmony export */   ConvBertForTokenClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ConvBertForTokenClassification),\n/* harmony export */   ConvBertModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ConvBertModel),\n/* harmony export */   ConvBertPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ConvBertPreTrainedModel),\n/* harmony export */   ConvBertTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.ConvBertTokenizer),\n/* harmony export */   ConvNextFeatureExtractor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.ConvNextFeatureExtractor),\n/* harmony export */   ConvNextForImageClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ConvNextForImageClassification),\n/* harmony export */   ConvNextImageProcessor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.ConvNextImageProcessor),\n/* harmony export */   ConvNextModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ConvNextModel),\n/* harmony export */   ConvNextPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ConvNextPreTrainedModel),\n/* harmony export */   ConvNextV2ForImageClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ConvNextV2ForImageClassification),\n/* harmony export */   ConvNextV2Model: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ConvNextV2Model),\n/* harmony export */   ConvNextV2PreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ConvNextV2PreTrainedModel),\n/* harmony export */   DPTFeatureExtractor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.DPTFeatureExtractor),\n/* harmony export */   DPTForDepthEstimation: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DPTForDepthEstimation),\n/* harmony export */   DPTImageProcessor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.DPTImageProcessor),\n/* harmony export */   DPTModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DPTModel),\n/* harmony export */   DPTPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DPTPreTrainedModel),\n/* harmony export */   DebertaForMaskedLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DebertaForMaskedLM),\n/* harmony export */   DebertaForQuestionAnswering: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DebertaForQuestionAnswering),\n/* harmony export */   DebertaForSequenceClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DebertaForSequenceClassification),\n/* harmony export */   DebertaForTokenClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DebertaForTokenClassification),\n/* harmony export */   DebertaModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DebertaModel),\n/* harmony export */   DebertaPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DebertaPreTrainedModel),\n/* harmony export */   DebertaTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.DebertaTokenizer),\n/* harmony export */   DebertaV2ForMaskedLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DebertaV2ForMaskedLM),\n/* harmony export */   DebertaV2ForQuestionAnswering: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DebertaV2ForQuestionAnswering),\n/* harmony export */   DebertaV2ForSequenceClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DebertaV2ForSequenceClassification),\n/* harmony export */   DebertaV2ForTokenClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DebertaV2ForTokenClassification),\n/* harmony export */   DebertaV2Model: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DebertaV2Model),\n/* harmony export */   DebertaV2PreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DebertaV2PreTrainedModel),\n/* harmony export */   DebertaV2Tokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.DebertaV2Tokenizer),\n/* harmony export */   DeiTFeatureExtractor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.DeiTFeatureExtractor),\n/* harmony export */   DeiTForImageClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DeiTForImageClassification),\n/* harmony export */   DeiTModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DeiTModel),\n/* harmony export */   DeiTPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DeiTPreTrainedModel),\n/* harmony export */   DepthAnythingForDepthEstimation: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DepthAnythingForDepthEstimation),\n/* harmony export */   DepthAnythingPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DepthAnythingPreTrainedModel),\n/* harmony export */   DepthEstimationPipeline: () => (/* reexport safe */ _pipelines_js__WEBPACK_IMPORTED_MODULE_0__.DepthEstimationPipeline),\n/* harmony export */   DetrFeatureExtractor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.DetrFeatureExtractor),\n/* harmony export */   DetrForObjectDetection: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DetrForObjectDetection),\n/* harmony export */   DetrForSegmentation: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DetrForSegmentation),\n/* harmony export */   DetrModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DetrModel),\n/* harmony export */   DetrObjectDetectionOutput: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DetrObjectDetectionOutput),\n/* harmony export */   DetrPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DetrPreTrainedModel),\n/* harmony export */   DetrSegmentationOutput: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DetrSegmentationOutput),\n/* harmony export */   Dinov2ForImageClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.Dinov2ForImageClassification),\n/* harmony export */   Dinov2Model: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.Dinov2Model),\n/* harmony export */   Dinov2PreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.Dinov2PreTrainedModel),\n/* harmony export */   DistilBertForMaskedLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DistilBertForMaskedLM),\n/* harmony export */   DistilBertForQuestionAnswering: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DistilBertForQuestionAnswering),\n/* harmony export */   DistilBertForSequenceClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DistilBertForSequenceClassification),\n/* harmony export */   DistilBertForTokenClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DistilBertForTokenClassification),\n/* harmony export */   DistilBertModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DistilBertModel),\n/* harmony export */   DistilBertPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DistilBertPreTrainedModel),\n/* harmony export */   DistilBertTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.DistilBertTokenizer),\n/* harmony export */   DocumentQuestionAnsweringPipeline: () => (/* reexport safe */ _pipelines_js__WEBPACK_IMPORTED_MODULE_0__.DocumentQuestionAnsweringPipeline),\n/* harmony export */   DonutFeatureExtractor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.DonutFeatureExtractor),\n/* harmony export */   DonutSwinModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DonutSwinModel),\n/* harmony export */   DonutSwinPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.DonutSwinPreTrainedModel),\n/* harmony export */   ElectraForMaskedLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ElectraForMaskedLM),\n/* harmony export */   ElectraForQuestionAnswering: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ElectraForQuestionAnswering),\n/* harmony export */   ElectraForSequenceClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ElectraForSequenceClassification),\n/* harmony export */   ElectraForTokenClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ElectraForTokenClassification),\n/* harmony export */   ElectraModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ElectraModel),\n/* harmony export */   ElectraPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ElectraPreTrainedModel),\n/* harmony export */   ElectraTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.ElectraTokenizer),\n/* harmony export */   EsmForMaskedLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.EsmForMaskedLM),\n/* harmony export */   EsmForSequenceClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.EsmForSequenceClassification),\n/* harmony export */   EsmForTokenClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.EsmForTokenClassification),\n/* harmony export */   EsmModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.EsmModel),\n/* harmony export */   EsmPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.EsmPreTrainedModel),\n/* harmony export */   EsmTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.EsmTokenizer),\n/* harmony export */   FFT: () => (/* reexport safe */ _utils_maths_js__WEBPACK_IMPORTED_MODULE_9__.FFT),\n/* harmony export */   FalconForCausalLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.FalconForCausalLM),\n/* harmony export */   FalconModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.FalconModel),\n/* harmony export */   FalconPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.FalconPreTrainedModel),\n/* harmony export */   FalconTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.FalconTokenizer),\n/* harmony export */   FeatureExtractionPipeline: () => (/* reexport safe */ _pipelines_js__WEBPACK_IMPORTED_MODULE_0__.FeatureExtractionPipeline),\n/* harmony export */   FeatureExtractor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.FeatureExtractor),\n/* harmony export */   FillMaskPipeline: () => (/* reexport safe */ _pipelines_js__WEBPACK_IMPORTED_MODULE_0__.FillMaskPipeline),\n/* harmony export */   GLPNFeatureExtractor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.GLPNFeatureExtractor),\n/* harmony export */   GLPNForDepthEstimation: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.GLPNForDepthEstimation),\n/* harmony export */   GLPNModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.GLPNModel),\n/* harmony export */   GLPNPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.GLPNPreTrainedModel),\n/* harmony export */   GPT2LMHeadModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.GPT2LMHeadModel),\n/* harmony export */   GPT2Model: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.GPT2Model),\n/* harmony export */   GPT2PreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.GPT2PreTrainedModel),\n/* harmony export */   GPT2Tokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.GPT2Tokenizer),\n/* harmony export */   GPTBigCodeForCausalLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.GPTBigCodeForCausalLM),\n/* harmony export */   GPTBigCodeModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.GPTBigCodeModel),\n/* harmony export */   GPTBigCodePreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.GPTBigCodePreTrainedModel),\n/* harmony export */   GPTJForCausalLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.GPTJForCausalLM),\n/* harmony export */   GPTJModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.GPTJModel),\n/* harmony export */   GPTJPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.GPTJPreTrainedModel),\n/* harmony export */   GPTNeoForCausalLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.GPTNeoForCausalLM),\n/* harmony export */   GPTNeoModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.GPTNeoModel),\n/* harmony export */   GPTNeoPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.GPTNeoPreTrainedModel),\n/* harmony export */   GPTNeoXForCausalLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.GPTNeoXForCausalLM),\n/* harmony export */   GPTNeoXModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.GPTNeoXModel),\n/* harmony export */   GPTNeoXPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.GPTNeoXPreTrainedModel),\n/* harmony export */   GPTNeoXTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.GPTNeoXTokenizer),\n/* harmony export */   GemmaTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.GemmaTokenizer),\n/* harmony export */   HerbertTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.HerbertTokenizer),\n/* harmony export */   HubertForCTC: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.HubertForCTC),\n/* harmony export */   HubertForSequenceClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.HubertForSequenceClassification),\n/* harmony export */   HubertModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.HubertModel),\n/* harmony export */   HubertPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.HubertPreTrainedModel),\n/* harmony export */   ImageClassificationPipeline: () => (/* reexport safe */ _pipelines_js__WEBPACK_IMPORTED_MODULE_0__.ImageClassificationPipeline),\n/* harmony export */   ImageFeatureExtractor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.ImageFeatureExtractor),\n/* harmony export */   ImageMattingOutput: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ImageMattingOutput),\n/* harmony export */   ImageSegmentationPipeline: () => (/* reexport safe */ _pipelines_js__WEBPACK_IMPORTED_MODULE_0__.ImageSegmentationPipeline),\n/* harmony export */   ImageToImagePipeline: () => (/* reexport safe */ _pipelines_js__WEBPACK_IMPORTED_MODULE_0__.ImageToImagePipeline),\n/* harmony export */   ImageToTextPipeline: () => (/* reexport safe */ _pipelines_js__WEBPACK_IMPORTED_MODULE_0__.ImageToTextPipeline),\n/* harmony export */   LlamaForCausalLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.LlamaForCausalLM),\n/* harmony export */   LlamaModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.LlamaModel),\n/* harmony export */   LlamaPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.LlamaPreTrainedModel),\n/* harmony export */   LlamaTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.LlamaTokenizer),\n/* harmony export */   LongT5ForConditionalGeneration: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.LongT5ForConditionalGeneration),\n/* harmony export */   LongT5Model: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.LongT5Model),\n/* harmony export */   LongT5PreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.LongT5PreTrainedModel),\n/* harmony export */   M2M100ForConditionalGeneration: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.M2M100ForConditionalGeneration),\n/* harmony export */   M2M100Model: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.M2M100Model),\n/* harmony export */   M2M100PreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.M2M100PreTrainedModel),\n/* harmony export */   M2M100Tokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.M2M100Tokenizer),\n/* harmony export */   MBart50Tokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.MBart50Tokenizer),\n/* harmony export */   MBartForCausalLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MBartForCausalLM),\n/* harmony export */   MBartForConditionalGeneration: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MBartForConditionalGeneration),\n/* harmony export */   MBartForSequenceClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MBartForSequenceClassification),\n/* harmony export */   MBartModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MBartModel),\n/* harmony export */   MBartPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MBartPreTrainedModel),\n/* harmony export */   MBartTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.MBartTokenizer),\n/* harmony export */   MPNetForMaskedLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MPNetForMaskedLM),\n/* harmony export */   MPNetForQuestionAnswering: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MPNetForQuestionAnswering),\n/* harmony export */   MPNetForSequenceClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MPNetForSequenceClassification),\n/* harmony export */   MPNetForTokenClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MPNetForTokenClassification),\n/* harmony export */   MPNetModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MPNetModel),\n/* harmony export */   MPNetPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MPNetPreTrainedModel),\n/* harmony export */   MPNetTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.MPNetTokenizer),\n/* harmony export */   MT5ForConditionalGeneration: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MT5ForConditionalGeneration),\n/* harmony export */   MT5Model: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MT5Model),\n/* harmony export */   MT5PreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MT5PreTrainedModel),\n/* harmony export */   MarianMTModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MarianMTModel),\n/* harmony export */   MarianModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MarianModel),\n/* harmony export */   MarianPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MarianPreTrainedModel),\n/* harmony export */   MarianTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.MarianTokenizer),\n/* harmony export */   MaskedLMOutput: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MaskedLMOutput),\n/* harmony export */   MistralForCausalLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MistralForCausalLM),\n/* harmony export */   MistralModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MistralModel),\n/* harmony export */   MistralPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MistralPreTrainedModel),\n/* harmony export */   MobileBertForMaskedLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MobileBertForMaskedLM),\n/* harmony export */   MobileBertForQuestionAnswering: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MobileBertForQuestionAnswering),\n/* harmony export */   MobileBertForSequenceClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MobileBertForSequenceClassification),\n/* harmony export */   MobileBertModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MobileBertModel),\n/* harmony export */   MobileBertPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MobileBertPreTrainedModel),\n/* harmony export */   MobileBertTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.MobileBertTokenizer),\n/* harmony export */   MobileViTFeatureExtractor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.MobileViTFeatureExtractor),\n/* harmony export */   MobileViTForImageClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MobileViTForImageClassification),\n/* harmony export */   MobileViTModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MobileViTModel),\n/* harmony export */   MobileViTPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MobileViTPreTrainedModel),\n/* harmony export */   ModelOutput: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ModelOutput),\n/* harmony export */   MptForCausalLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MptForCausalLM),\n/* harmony export */   MptModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MptModel),\n/* harmony export */   MptPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.MptPreTrainedModel),\n/* harmony export */   NllbTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.NllbTokenizer),\n/* harmony export */   NomicBertModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.NomicBertModel),\n/* harmony export */   NomicBertPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.NomicBertPreTrainedModel),\n/* harmony export */   NougatImageProcessor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.NougatImageProcessor),\n/* harmony export */   NougatTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.NougatTokenizer),\n/* harmony export */   OPTForCausalLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.OPTForCausalLM),\n/* harmony export */   OPTModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.OPTModel),\n/* harmony export */   OPTPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.OPTPreTrainedModel),\n/* harmony export */   ObjectDetectionPipeline: () => (/* reexport safe */ _pipelines_js__WEBPACK_IMPORTED_MODULE_0__.ObjectDetectionPipeline),\n/* harmony export */   OwlViTFeatureExtractor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.OwlViTFeatureExtractor),\n/* harmony export */   OwlViTForObjectDetection: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.OwlViTForObjectDetection),\n/* harmony export */   OwlViTModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.OwlViTModel),\n/* harmony export */   OwlViTPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.OwlViTPreTrainedModel),\n/* harmony export */   OwlViTProcessor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.OwlViTProcessor),\n/* harmony export */   Owlv2ForObjectDetection: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.Owlv2ForObjectDetection),\n/* harmony export */   Owlv2ImageProcessor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.Owlv2ImageProcessor),\n/* harmony export */   Owlv2Model: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.Owlv2Model),\n/* harmony export */   Owlv2PreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.Owlv2PreTrainedModel),\n/* harmony export */   PhiForCausalLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.PhiForCausalLM),\n/* harmony export */   PhiModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.PhiModel),\n/* harmony export */   PhiPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.PhiPreTrainedModel),\n/* harmony export */   Pipeline: () => (/* reexport safe */ _pipelines_js__WEBPACK_IMPORTED_MODULE_0__.Pipeline),\n/* harmony export */   PreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.PreTrainedModel),\n/* harmony export */   PreTrainedTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.PreTrainedTokenizer),\n/* harmony export */   PretrainedConfig: () => (/* reexport safe */ _configs_js__WEBPACK_IMPORTED_MODULE_5__.PretrainedConfig),\n/* harmony export */   PretrainedMixin: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.PretrainedMixin),\n/* harmony export */   Processor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.Processor),\n/* harmony export */   QuestionAnsweringModelOutput: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.QuestionAnsweringModelOutput),\n/* harmony export */   QuestionAnsweringPipeline: () => (/* reexport safe */ _pipelines_js__WEBPACK_IMPORTED_MODULE_0__.QuestionAnsweringPipeline),\n/* harmony export */   Qwen2ForCausalLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.Qwen2ForCausalLM),\n/* harmony export */   Qwen2Model: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.Qwen2Model),\n/* harmony export */   Qwen2PreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.Qwen2PreTrainedModel),\n/* harmony export */   Qwen2Tokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.Qwen2Tokenizer),\n/* harmony export */   RawImage: () => (/* reexport safe */ _utils_image_js__WEBPACK_IMPORTED_MODULE_7__.RawImage),\n/* harmony export */   ResNetForImageClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ResNetForImageClassification),\n/* harmony export */   ResNetModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ResNetModel),\n/* harmony export */   ResNetPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ResNetPreTrainedModel),\n/* harmony export */   RoFormerForMaskedLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.RoFormerForMaskedLM),\n/* harmony export */   RoFormerForQuestionAnswering: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.RoFormerForQuestionAnswering),\n/* harmony export */   RoFormerForSequenceClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.RoFormerForSequenceClassification),\n/* harmony export */   RoFormerForTokenClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.RoFormerForTokenClassification),\n/* harmony export */   RoFormerModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.RoFormerModel),\n/* harmony export */   RoFormerPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.RoFormerPreTrainedModel),\n/* harmony export */   RoFormerTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.RoFormerTokenizer),\n/* harmony export */   RobertaForMaskedLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.RobertaForMaskedLM),\n/* harmony export */   RobertaForQuestionAnswering: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.RobertaForQuestionAnswering),\n/* harmony export */   RobertaForSequenceClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.RobertaForSequenceClassification),\n/* harmony export */   RobertaForTokenClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.RobertaForTokenClassification),\n/* harmony export */   RobertaModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.RobertaModel),\n/* harmony export */   RobertaPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.RobertaPreTrainedModel),\n/* harmony export */   RobertaTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.RobertaTokenizer),\n/* harmony export */   SamImageProcessor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.SamImageProcessor),\n/* harmony export */   SamImageSegmentationOutput: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.SamImageSegmentationOutput),\n/* harmony export */   SamModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.SamModel),\n/* harmony export */   SamPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.SamPreTrainedModel),\n/* harmony export */   SamProcessor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.SamProcessor),\n/* harmony export */   SeamlessM4TFeatureExtractor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.SeamlessM4TFeatureExtractor),\n/* harmony export */   SegformerFeatureExtractor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.SegformerFeatureExtractor),\n/* harmony export */   SegformerForImageClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.SegformerForImageClassification),\n/* harmony export */   SegformerForSemanticSegmentation: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.SegformerForSemanticSegmentation),\n/* harmony export */   SegformerModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.SegformerModel),\n/* harmony export */   SegformerPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.SegformerPreTrainedModel),\n/* harmony export */   Seq2SeqLMOutput: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.Seq2SeqLMOutput),\n/* harmony export */   SequenceClassifierOutput: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.SequenceClassifierOutput),\n/* harmony export */   SiglipImageProcessor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.SiglipImageProcessor),\n/* harmony export */   SiglipModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.SiglipModel),\n/* harmony export */   SiglipPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.SiglipPreTrainedModel),\n/* harmony export */   SiglipTextModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.SiglipTextModel),\n/* harmony export */   SiglipTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.SiglipTokenizer),\n/* harmony export */   SiglipVisionModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.SiglipVisionModel),\n/* harmony export */   SpeechT5FeatureExtractor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.SpeechT5FeatureExtractor),\n/* harmony export */   SpeechT5ForSpeechToText: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.SpeechT5ForSpeechToText),\n/* harmony export */   SpeechT5ForTextToSpeech: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.SpeechT5ForTextToSpeech),\n/* harmony export */   SpeechT5HifiGan: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.SpeechT5HifiGan),\n/* harmony export */   SpeechT5Model: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.SpeechT5Model),\n/* harmony export */   SpeechT5PreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.SpeechT5PreTrainedModel),\n/* harmony export */   SpeechT5Processor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.SpeechT5Processor),\n/* harmony export */   SpeechT5Tokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.SpeechT5Tokenizer),\n/* harmony export */   SqueezeBertForMaskedLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.SqueezeBertForMaskedLM),\n/* harmony export */   SqueezeBertForQuestionAnswering: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.SqueezeBertForQuestionAnswering),\n/* harmony export */   SqueezeBertForSequenceClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.SqueezeBertForSequenceClassification),\n/* harmony export */   SqueezeBertModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.SqueezeBertModel),\n/* harmony export */   SqueezeBertPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.SqueezeBertPreTrainedModel),\n/* harmony export */   SqueezeBertTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.SqueezeBertTokenizer),\n/* harmony export */   SummarizationPipeline: () => (/* reexport safe */ _pipelines_js__WEBPACK_IMPORTED_MODULE_0__.SummarizationPipeline),\n/* harmony export */   Swin2SRForImageSuperResolution: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.Swin2SRForImageSuperResolution),\n/* harmony export */   Swin2SRImageProcessor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.Swin2SRImageProcessor),\n/* harmony export */   Swin2SRModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.Swin2SRModel),\n/* harmony export */   Swin2SRPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.Swin2SRPreTrainedModel),\n/* harmony export */   SwinForImageClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.SwinForImageClassification),\n/* harmony export */   SwinModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.SwinModel),\n/* harmony export */   SwinPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.SwinPreTrainedModel),\n/* harmony export */   T5ForConditionalGeneration: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.T5ForConditionalGeneration),\n/* harmony export */   T5Model: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.T5Model),\n/* harmony export */   T5PreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.T5PreTrainedModel),\n/* harmony export */   T5Tokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.T5Tokenizer),\n/* harmony export */   TableTransformerForObjectDetection: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.TableTransformerForObjectDetection),\n/* harmony export */   TableTransformerModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.TableTransformerModel),\n/* harmony export */   TableTransformerObjectDetectionOutput: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.TableTransformerObjectDetectionOutput),\n/* harmony export */   TableTransformerPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.TableTransformerPreTrainedModel),\n/* harmony export */   Tensor: () => (/* reexport safe */ _utils_tensor_js__WEBPACK_IMPORTED_MODULE_8__.Tensor),\n/* harmony export */   Text2TextGenerationPipeline: () => (/* reexport safe */ _pipelines_js__WEBPACK_IMPORTED_MODULE_0__.Text2TextGenerationPipeline),\n/* harmony export */   TextClassificationPipeline: () => (/* reexport safe */ _pipelines_js__WEBPACK_IMPORTED_MODULE_0__.TextClassificationPipeline),\n/* harmony export */   TextGenerationPipeline: () => (/* reexport safe */ _pipelines_js__WEBPACK_IMPORTED_MODULE_0__.TextGenerationPipeline),\n/* harmony export */   TextToAudioPipeline: () => (/* reexport safe */ _pipelines_js__WEBPACK_IMPORTED_MODULE_0__.TextToAudioPipeline),\n/* harmony export */   TokenClassificationPipeline: () => (/* reexport safe */ _pipelines_js__WEBPACK_IMPORTED_MODULE_0__.TokenClassificationPipeline),\n/* harmony export */   TokenClassifierOutput: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.TokenClassifierOutput),\n/* harmony export */   TokenizerModel: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.TokenizerModel),\n/* harmony export */   TrOCRForCausalLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.TrOCRForCausalLM),\n/* harmony export */   TrOCRPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.TrOCRPreTrainedModel),\n/* harmony export */   TranslationPipeline: () => (/* reexport safe */ _pipelines_js__WEBPACK_IMPORTED_MODULE_0__.TranslationPipeline),\n/* harmony export */   ViTFeatureExtractor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.ViTFeatureExtractor),\n/* harmony export */   ViTForImageClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ViTForImageClassification),\n/* harmony export */   ViTImageProcessor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.ViTImageProcessor),\n/* harmony export */   ViTModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ViTModel),\n/* harmony export */   ViTPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.ViTPreTrainedModel),\n/* harmony export */   VisionEncoderDecoderModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.VisionEncoderDecoderModel),\n/* harmony export */   VitMatteForImageMatting: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.VitMatteForImageMatting),\n/* harmony export */   VitMatteImageProcessor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.VitMatteImageProcessor),\n/* harmony export */   VitMattePreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.VitMattePreTrainedModel),\n/* harmony export */   VitsModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.VitsModel),\n/* harmony export */   VitsModelOutput: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.VitsModelOutput),\n/* harmony export */   VitsPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.VitsPreTrainedModel),\n/* harmony export */   VitsTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.VitsTokenizer),\n/* harmony export */   Wav2Vec2BertForCTC: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.Wav2Vec2BertForCTC),\n/* harmony export */   Wav2Vec2BertForSequenceClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.Wav2Vec2BertForSequenceClassification),\n/* harmony export */   Wav2Vec2BertModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.Wav2Vec2BertModel),\n/* harmony export */   Wav2Vec2BertPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.Wav2Vec2BertPreTrainedModel),\n/* harmony export */   Wav2Vec2CTCTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.Wav2Vec2CTCTokenizer),\n/* harmony export */   Wav2Vec2FeatureExtractor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.Wav2Vec2FeatureExtractor),\n/* harmony export */   Wav2Vec2ForCTC: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.Wav2Vec2ForCTC),\n/* harmony export */   Wav2Vec2ForSequenceClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.Wav2Vec2ForSequenceClassification),\n/* harmony export */   Wav2Vec2Model: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.Wav2Vec2Model),\n/* harmony export */   Wav2Vec2PreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.Wav2Vec2PreTrainedModel),\n/* harmony export */   Wav2Vec2ProcessorWithLM: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.Wav2Vec2ProcessorWithLM),\n/* harmony export */   WavLMForCTC: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.WavLMForCTC),\n/* harmony export */   WavLMForSequenceClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.WavLMForSequenceClassification),\n/* harmony export */   WavLMModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.WavLMModel),\n/* harmony export */   WavLMPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.WavLMPreTrainedModel),\n/* harmony export */   WhisperFeatureExtractor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.WhisperFeatureExtractor),\n/* harmony export */   WhisperForConditionalGeneration: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.WhisperForConditionalGeneration),\n/* harmony export */   WhisperModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.WhisperModel),\n/* harmony export */   WhisperPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.WhisperPreTrainedModel),\n/* harmony export */   WhisperProcessor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.WhisperProcessor),\n/* harmony export */   WhisperTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.WhisperTokenizer),\n/* harmony export */   XLMForQuestionAnswering: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.XLMForQuestionAnswering),\n/* harmony export */   XLMForSequenceClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.XLMForSequenceClassification),\n/* harmony export */   XLMForTokenClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.XLMForTokenClassification),\n/* harmony export */   XLMModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.XLMModel),\n/* harmony export */   XLMPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.XLMPreTrainedModel),\n/* harmony export */   XLMRobertaForMaskedLM: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.XLMRobertaForMaskedLM),\n/* harmony export */   XLMRobertaForQuestionAnswering: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.XLMRobertaForQuestionAnswering),\n/* harmony export */   XLMRobertaForSequenceClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.XLMRobertaForSequenceClassification),\n/* harmony export */   XLMRobertaForTokenClassification: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.XLMRobertaForTokenClassification),\n/* harmony export */   XLMRobertaModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.XLMRobertaModel),\n/* harmony export */   XLMRobertaPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.XLMRobertaPreTrainedModel),\n/* harmony export */   XLMRobertaTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.XLMRobertaTokenizer),\n/* harmony export */   XLMTokenizer: () => (/* reexport safe */ _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__.XLMTokenizer),\n/* harmony export */   XLMWithLMHeadModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.XLMWithLMHeadModel),\n/* harmony export */   YolosFeatureExtractor: () => (/* reexport safe */ _processors_js__WEBPACK_IMPORTED_MODULE_4__.YolosFeatureExtractor),\n/* harmony export */   YolosForObjectDetection: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.YolosForObjectDetection),\n/* harmony export */   YolosModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.YolosModel),\n/* harmony export */   YolosObjectDetectionOutput: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.YolosObjectDetectionOutput),\n/* harmony export */   YolosPreTrainedModel: () => (/* reexport safe */ _models_js__WEBPACK_IMPORTED_MODULE_2__.YolosPreTrainedModel),\n/* harmony export */   ZeroShotAudioClassificationPipeline: () => (/* reexport safe */ _pipelines_js__WEBPACK_IMPORTED_MODULE_0__.ZeroShotAudioClassificationPipeline),\n/* harmony export */   ZeroShotClassificationPipeline: () => (/* reexport safe */ _pipelines_js__WEBPACK_IMPORTED_MODULE_0__.ZeroShotClassificationPipeline),\n/* harmony export */   ZeroShotImageClassificationPipeline: () => (/* reexport safe */ _pipelines_js__WEBPACK_IMPORTED_MODULE_0__.ZeroShotImageClassificationPipeline),\n/* harmony export */   ZeroShotObjectDetectionPipeline: () => (/* reexport safe */ _pipelines_js__WEBPACK_IMPORTED_MODULE_0__.ZeroShotObjectDetectionPipeline),\n/* harmony export */   cat: () => (/* reexport safe */ _utils_tensor_js__WEBPACK_IMPORTED_MODULE_8__.cat),\n/* harmony export */   cos_sim: () => (/* reexport safe */ _utils_maths_js__WEBPACK_IMPORTED_MODULE_9__.cos_sim),\n/* harmony export */   dot: () => (/* reexport safe */ _utils_maths_js__WEBPACK_IMPORTED_MODULE_9__.dot),\n/* harmony export */   dynamicTimeWarping: () => (/* reexport safe */ _utils_tensor_js__WEBPACK_IMPORTED_MODULE_8__.dynamicTimeWarping),\n/* harmony export */   env: () => (/* reexport safe */ _env_js__WEBPACK_IMPORTED_MODULE_1__.env),\n/* harmony export */   getTopItems: () => (/* reexport safe */ _utils_maths_js__WEBPACK_IMPORTED_MODULE_9__.getTopItems),\n/* harmony export */   hanning: () => (/* reexport safe */ _utils_audio_js__WEBPACK_IMPORTED_MODULE_6__.hanning),\n/* harmony export */   interpolate: () => (/* reexport safe */ _utils_tensor_js__WEBPACK_IMPORTED_MODULE_8__.interpolate),\n/* harmony export */   interpolate_data: () => (/* reexport safe */ _utils_maths_js__WEBPACK_IMPORTED_MODULE_9__.interpolate_data),\n/* harmony export */   layer_norm: () => (/* reexport safe */ _utils_tensor_js__WEBPACK_IMPORTED_MODULE_8__.layer_norm),\n/* harmony export */   log_softmax: () => (/* reexport safe */ _utils_maths_js__WEBPACK_IMPORTED_MODULE_9__.log_softmax),\n/* harmony export */   magnitude: () => (/* reexport safe */ _utils_maths_js__WEBPACK_IMPORTED_MODULE_9__.magnitude),\n/* harmony export */   max: () => (/* reexport safe */ _utils_maths_js__WEBPACK_IMPORTED_MODULE_9__.max),\n/* harmony export */   mean: () => (/* reexport safe */ _utils_tensor_js__WEBPACK_IMPORTED_MODULE_8__.mean),\n/* harmony export */   mean_pooling: () => (/* reexport safe */ _utils_tensor_js__WEBPACK_IMPORTED_MODULE_8__.mean_pooling),\n/* harmony export */   medianFilter: () => (/* reexport safe */ _utils_maths_js__WEBPACK_IMPORTED_MODULE_9__.medianFilter),\n/* harmony export */   mel_filter_bank: () => (/* reexport safe */ _utils_audio_js__WEBPACK_IMPORTED_MODULE_6__.mel_filter_bank),\n/* harmony export */   min: () => (/* reexport safe */ _utils_maths_js__WEBPACK_IMPORTED_MODULE_9__.min),\n/* harmony export */   ones: () => (/* reexport safe */ _utils_tensor_js__WEBPACK_IMPORTED_MODULE_8__.ones),\n/* harmony export */   ones_like: () => (/* reexport safe */ _utils_tensor_js__WEBPACK_IMPORTED_MODULE_8__.ones_like),\n/* harmony export */   pipeline: () => (/* reexport safe */ _pipelines_js__WEBPACK_IMPORTED_MODULE_0__.pipeline),\n/* harmony export */   read_audio: () => (/* reexport safe */ _utils_audio_js__WEBPACK_IMPORTED_MODULE_6__.read_audio),\n/* harmony export */   round: () => (/* reexport safe */ _utils_maths_js__WEBPACK_IMPORTED_MODULE_9__.round),\n/* harmony export */   softmax: () => (/* reexport safe */ _utils_maths_js__WEBPACK_IMPORTED_MODULE_9__.softmax),\n/* harmony export */   spectrogram: () => (/* reexport safe */ _utils_audio_js__WEBPACK_IMPORTED_MODULE_6__.spectrogram),\n/* harmony export */   stack: () => (/* reexport safe */ _utils_tensor_js__WEBPACK_IMPORTED_MODULE_8__.stack),\n/* harmony export */   std_mean: () => (/* reexport safe */ _utils_tensor_js__WEBPACK_IMPORTED_MODULE_8__.std_mean),\n/* harmony export */   transpose: () => (/* reexport safe */ _utils_tensor_js__WEBPACK_IMPORTED_MODULE_8__.transpose),\n/* harmony export */   transpose_data: () => (/* reexport safe */ _utils_maths_js__WEBPACK_IMPORTED_MODULE_9__.transpose_data),\n/* harmony export */   window_function: () => (/* reexport safe */ _utils_audio_js__WEBPACK_IMPORTED_MODULE_6__.window_function)\n/* harmony export */ });\n/* harmony import */ var _pipelines_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./pipelines.js */ \"./node_modules/@xenova/transformers/src/pipelines.js\");\n/* harmony import */ var _env_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./env.js */ \"./node_modules/@xenova/transformers/src/env.js\");\n/* harmony import */ var _models_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./models.js */ \"./node_modules/@xenova/transformers/src/models.js\");\n/* harmony import */ var _tokenizers_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./tokenizers.js */ \"./node_modules/@xenova/transformers/src/tokenizers.js\");\n/* harmony import */ var _processors_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./processors.js */ \"./node_modules/@xenova/transformers/src/processors.js\");\n/* harmony import */ var _configs_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./configs.js */ \"./node_modules/@xenova/transformers/src/configs.js\");\n/* harmony import */ var _utils_audio_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./utils/audio.js */ \"./node_modules/@xenova/transformers/src/utils/audio.js\");\n/* harmony import */ var _utils_image_js__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./utils/image.js */ \"./node_modules/@xenova/transformers/src/utils/image.js\");\n/* harmony import */ var _utils_tensor_js__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./utils/tensor.js */ \"./node_modules/@xenova/transformers/src/utils/tensor.js\");\n/* harmony import */ var _utils_maths_js__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./utils/maths.js */ \"./node_modules/@xenova/transformers/src/utils/maths.js\");\n/**\n * @file Entry point for the Transformers.js library. Only the exports from this file\n * are available to the end user, and are grouped as follows:\n * \n * 1. [Pipelines](./pipelines)\n * 2. [Environment variables](./env)\n * 3. [Models](./models)\n * 4. [Tokenizers](./tokenizers)\n * 5. [Processors](./processors)\n * \n * @module transformers\n */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@xenova/transformers/src/transformers.js?");

/***/ }),

/***/ "./node_modules/@xenova/transformers/src/utils/audio.js":
/*!**************************************************************!*\
  !*** ./node_modules/@xenova/transformers/src/utils/audio.js ***!
  \**************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   hanning: () => (/* binding */ hanning),\n/* harmony export */   mel_filter_bank: () => (/* binding */ mel_filter_bank),\n/* harmony export */   read_audio: () => (/* binding */ read_audio),\n/* harmony export */   spectrogram: () => (/* binding */ spectrogram),\n/* harmony export */   window_function: () => (/* binding */ window_function)\n/* harmony export */ });\n/* harmony import */ var _hub_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./hub.js */ \"./node_modules/@xenova/transformers/src/utils/hub.js\");\n/* harmony import */ var _maths_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./maths.js */ \"./node_modules/@xenova/transformers/src/utils/maths.js\");\n/* harmony import */ var _core_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./core.js */ \"./node_modules/@xenova/transformers/src/utils/core.js\");\n/**\n * @file Helper module for audio processing. \n * \n * These functions and classes are only used internally, \n * meaning an end-user shouldn't need to access anything here.\n * \n * @module utils/audio\n */\n\n\n\n\n\n\n/**\n * Helper function to read audio from a path/URL.\n * @param {string|URL} url The path/URL to load the audio from.\n * @param {number} sampling_rate The sampling rate to use when decoding the audio.\n * @returns {Promise<Float32Array>} The decoded audio as a `Float32Array`.\n */\nasync function read_audio(url, sampling_rate) {\n    if (typeof AudioContext === 'undefined') {\n        // Running in node or an environment without AudioContext\n        throw Error(\n            \"Unable to load audio from path/URL since `AudioContext` is not available in your environment. \" +\n            \"Instead, audio data should be passed directly to the pipeline/processor. \" +\n            \"For more information and some example code, see https://huggingface.co/docs/transformers.js/guides/node-audio-processing.\"\n        )\n    }\n\n    const response = await (await (0,_hub_js__WEBPACK_IMPORTED_MODULE_0__.getFile)(url)).arrayBuffer();\n    const audioCTX = new AudioContext({ sampleRate: sampling_rate });\n    if (typeof sampling_rate === 'undefined') {\n        console.warn(`No sampling rate provided, using default of ${audioCTX.sampleRate}Hz.`)\n    }\n    const decoded = await audioCTX.decodeAudioData(response);\n\n    /** @type {Float32Array} */\n    let audio;\n\n    // We now replicate HuggingFace's `ffmpeg_read` method:\n    if (decoded.numberOfChannels === 2) {\n        // When downmixing a stereo audio file to mono using the -ac 1 option in FFmpeg,\n        // the audio signal is summed across both channels to create a single mono channel.\n        // However, if the audio is at full scale (i.e. the highest possible volume level),\n        // the summing of the two channels can cause the audio signal to clip or distort.\n\n        // To prevent this clipping, FFmpeg applies a scaling factor of 1/sqrt(2) (~ 0.707)\n        // to the audio signal before summing the two channels. This scaling factor ensures\n        // that the combined audio signal will not exceed the maximum possible level, even\n        // if both channels are at full scale.\n\n        // After applying this scaling factor, the audio signal from both channels is summed\n        // to create a single mono channel. It's worth noting that this scaling factor is\n        // only applied when downmixing stereo audio to mono using the -ac 1 option in FFmpeg.\n        // If you're using a different downmixing method, or if you're not downmixing the\n        // audio at all, this scaling factor may not be needed.\n        const SCALING_FACTOR = Math.sqrt(2);\n\n        const left = decoded.getChannelData(0);\n        const right = decoded.getChannelData(1);\n\n        audio = new Float32Array(left.length);\n        for (let i = 0; i < decoded.length; ++i) {\n            audio[i] = SCALING_FACTOR * (left[i] + right[i]) / 2;\n        }\n\n    } else {\n        // If the audio is not stereo, we can just use the first channel:\n        audio = decoded.getChannelData(0);\n    }\n\n    return audio;\n}\n\n/**\n * Generates a Hanning window of length M.\n *\n * @param {number} M The length of the Hanning window to generate.\n * @returns {Float64Array} The generated Hanning window.\n */\nfunction hanning(M) {\n    if (M < 1) {\n        return new Float64Array();\n    }\n    if (M === 1) {\n        return new Float64Array([1]);\n    }\n    const denom = M - 1;\n    const factor = Math.PI / denom;\n    const cos_vals = new Float64Array(M);\n    for (let i = 0; i < M; ++i) {\n        const n = 2 * i - denom;\n        cos_vals[i] = 0.5 + 0.5 * Math.cos(factor * n);\n    }\n    return cos_vals;\n}\n\nconst HERTZ_TO_MEL_MAPPING = {\n    \"htk\": (/** @type {number} */ freq) => 2595.0 * Math.log10(1.0 + (freq / 700.0)),\n    \"kaldi\": (/** @type {number} */ freq) => 1127.0 * Math.log(1.0 + (freq / 700.0)),\n    \"slaney\": (/** @type {number} */ freq, min_log_hertz = 1000.0, min_log_mel = 15.0, logstep = 27.0 / Math.log(6.4)) =>\n        freq >= min_log_hertz\n            ? min_log_mel + Math.log(freq / min_log_hertz) * logstep\n            : 3.0 * freq / 200.0,\n}\n\n/**\n * @template {Float32Array|Float64Array|number} T \n * @param {T} freq \n * @param {string} [mel_scale]\n * @returns {T}\n */\nfunction hertz_to_mel(freq, mel_scale = \"htk\") {\n    const fn = HERTZ_TO_MEL_MAPPING[mel_scale];\n    if (!fn) {\n        throw new Error('mel_scale should be one of \"htk\", \"slaney\" or \"kaldi\".');\n    }\n\n    return typeof freq === 'number' ? fn(freq) : freq.map(x => fn(x));\n}\n\nconst MEL_TO_HERTZ_MAPPING = {\n    \"htk\": (/** @type {number} */ mels) => 700.0 * (10.0 ** (mels / 2595.0) - 1.0),\n    \"kaldi\": (/** @type {number} */ mels) => 700.0 * (Math.exp(mels / 1127.0) - 1.0),\n    \"slaney\": (/** @type {number} */ mels, min_log_hertz = 1000.0, min_log_mel = 15.0, logstep = Math.log(6.4) / 27.0) => mels >= min_log_mel\n        ? min_log_hertz * Math.exp(logstep * (mels - min_log_mel))\n        : 200.0 * mels / 3.0,\n}\n\n/**\n * @template {Float32Array|Float64Array|number} T \n * @param {T} mels \n * @param {string} [mel_scale]\n * @returns {T}\n */\nfunction mel_to_hertz(mels, mel_scale = \"htk\") {\n    const fn = MEL_TO_HERTZ_MAPPING[mel_scale];\n    if (!fn) {\n        throw new Error('mel_scale should be one of \"htk\", \"slaney\" or \"kaldi\".');\n    }\n\n    return typeof mels === 'number' ? fn(mels) : mels.map(x => fn(x));\n}\n\n/**\n* Creates a triangular filter bank.\n*\n* Adapted from torchaudio and librosa.\n*\n* @param {Float64Array} fft_freqs Discrete frequencies of the FFT bins in Hz, of shape `(num_frequency_bins,)`.\n* @param {Float64Array} filter_freqs Center frequencies of the triangular filters to create, in Hz, of shape `(num_mel_filters,)`.\n* @returns {number[][]} of shape `(num_frequency_bins, num_mel_filters)`.\n*/\nfunction _create_triangular_filter_bank(fft_freqs, filter_freqs) {\n    const filter_diff = Float64Array.from(\n        { length: filter_freqs.length - 1 },\n        (_, i) => filter_freqs[i + 1] - filter_freqs[i]\n    );\n\n    const slopes = Array.from({\n        length: fft_freqs.length\n    }, () => new Array(filter_freqs.length));\n\n    for (let j = 0; j < fft_freqs.length; ++j) {\n        const slope = slopes[j];\n        for (let i = 0; i < filter_freqs.length; ++i) {\n            slope[i] = filter_freqs[i] - fft_freqs[j];\n        }\n    }\n\n    const numFreqs = filter_freqs.length - 2;\n    const ret = Array.from({ length: numFreqs }, () => new Array(fft_freqs.length));\n\n    for (let j = 0; j < fft_freqs.length; ++j) { // 201\n        const slope = slopes[j];\n        for (let i = 0; i < numFreqs; ++i) { // 80\n            const down = -slope[i] / filter_diff[i];\n            const up = slope[i + 2] / filter_diff[i + 1];\n            ret[i][j] = Math.max(0, Math.min(down, up));\n        }\n    }\n    return ret;\n}\n\n/**\n * Return evenly spaced numbers over a specified interval.\n * @param {number} start The starting value of the sequence.\n * @param {number} end The end value of the sequence.\n * @param {number} num Number of samples to generate.\n * @returns `num` evenly spaced samples, calculated over the interval `[start, stop]`.\n */\nfunction linspace(start, end, num) {\n    const step = (end - start) / (num - 1);\n    return Float64Array.from({ length: num }, (_, i) => start + step * i);\n}\n\n/**\n * Creates a frequency bin conversion matrix used to obtain a mel spectrogram. This is called a *mel filter bank*, and\n * various implementation exist, which differ in the number of filters, the shape of the filters, the way the filters\n * are spaced, the bandwidth of the filters, and the manner in which the spectrum is warped. The goal of these\n * features is to approximate the non-linear human perception of the variation in pitch with respect to the frequency.\n * @param {number} num_frequency_bins Number of frequencies used to compute the spectrogram (should be the same as in `stft`).\n * @param {number} num_mel_filters Number of mel filters to generate.\n * @param {number} min_frequency Lowest frequency of interest in Hz.\n * @param {number} max_frequency Highest frequency of interest in Hz. This should not exceed `sampling_rate / 2`.\n * @param {number} sampling_rate Sample rate of the audio waveform.\n * @param {string} [norm] If `\"slaney\"`, divide the triangular mel weights by the width of the mel band (area normalization).\n * @param {string} [mel_scale] The mel frequency scale to use, `\"htk\"` or `\"slaney\"`.\n * @param {boolean} [triangularize_in_mel_space] If this option is enabled, the triangular filter is applied in mel space rather than frequency space.\n * This should be set to `true` in order to get the same results as `torchaudio` when computing mel filters.\n * @returns {number[][]} Triangular filter bank matrix, which is a 2D array of shape (`num_frequency_bins`, `num_mel_filters`).\n * This is a projection matrix to go from a spectrogram to a mel spectrogram.\n */\nfunction mel_filter_bank(\n    num_frequency_bins,\n    num_mel_filters,\n    min_frequency,\n    max_frequency,\n    sampling_rate,\n    norm = null,\n    mel_scale = \"htk\",\n    triangularize_in_mel_space = false,\n) {\n    if (norm !== null && norm !== \"slaney\") {\n        throw new Error('norm must be one of null or \"slaney\"');\n    }\n\n    const mel_min = hertz_to_mel(min_frequency, mel_scale);\n    const mel_max = hertz_to_mel(max_frequency, mel_scale);\n    const mel_freqs = linspace(mel_min, mel_max, num_mel_filters + 2);\n\n    let filter_freqs = mel_to_hertz(mel_freqs, mel_scale);\n    let fft_freqs; // frequencies of FFT bins in Hz\n\n    if (triangularize_in_mel_space) {\n        const fft_bin_width = sampling_rate / (num_frequency_bins * 2);\n        fft_freqs = hertz_to_mel(Float64Array.from({ length: num_frequency_bins }, (_, i) => i * fft_bin_width), mel_scale);\n        filter_freqs = mel_freqs;\n    } else {\n        fft_freqs = linspace(0, Math.floor(sampling_rate / 2), num_frequency_bins);\n    }\n\n    const mel_filters = _create_triangular_filter_bank(fft_freqs, filter_freqs);\n\n    if (norm !== null && norm === \"slaney\") {\n        // Slaney-style mel is scaled to be approx constant energy per channel\n        for (let i = 0; i < num_mel_filters; ++i) {\n            const filter = mel_filters[i];\n            const enorm = 2.0 / (filter_freqs[i + 2] - filter_freqs[i]);\n            for (let j = 0; j < num_frequency_bins; ++j) {\n                // Apply this enorm to all frequency bins\n                filter[j] *= enorm;\n            }\n        }\n    }\n\n    // TODO warn if there is a zero row\n\n    return mel_filters;\n\n}\n\n/**\n * @template {Float32Array|Float64Array} T\n * Pads an array with a reflected version of itself on both ends.\n * @param {T} array The array to pad.\n * @param {number} left The amount of padding to add to the left.\n * @param {number} right The amount of padding to add to the right.\n * @returns {T} The padded array.\n */\nfunction padReflect(array, left, right) {\n    // @ts-ignore\n    const padded = new array.constructor(array.length + left + right);\n    const w = array.length - 1;\n\n    for (let i = 0; i < array.length; ++i) {\n        padded[left + i] = array[i];\n    }\n\n    for (let i = 1; i <= left; ++i) {\n        padded[left - i] = array[(0,_core_js__WEBPACK_IMPORTED_MODULE_2__.calculateReflectOffset)(i, w)];\n    }\n\n    for (let i = 1; i <= right; ++i) {\n        padded[w + left + i] = array[(0,_core_js__WEBPACK_IMPORTED_MODULE_2__.calculateReflectOffset)(w - i, w)];\n    }\n\n    return padded;\n}\n\n/**\n * Helper function to compute `amplitude_to_db` and `power_to_db`.\n * @template {Float32Array|Float64Array} T\n * @param {T} spectrogram \n * @param {number} factor \n * @param {number} reference \n * @param {number} min_value \n * @param {number} db_range \n * @returns {T}\n */\nfunction _db_conversion_helper(spectrogram, factor, reference, min_value, db_range) {\n    if (reference <= 0) {\n        throw new Error('reference must be greater than zero');\n    }\n\n    if (min_value <= 0) {\n        throw new Error('min_value must be greater than zero');\n    }\n\n    reference = Math.max(min_value, reference);\n\n    const logReference = Math.log10(reference);\n    for (let i = 0; i < spectrogram.length; ++i) {\n        spectrogram[i] = factor * Math.log10(Math.max(min_value, spectrogram[i]) - logReference)\n    }\n\n    if (db_range !== null) {\n        if (db_range <= 0) {\n            throw new Error('db_range must be greater than zero');\n        }\n        const maxValue = (0,_maths_js__WEBPACK_IMPORTED_MODULE_1__.max)(spectrogram)[0] - db_range;\n        for (let i = 0; i < spectrogram.length; ++i) {\n            spectrogram[i] = Math.max(spectrogram[i], maxValue);\n        }\n    }\n\n    return spectrogram;\n}\n\n/**\n * Converts an amplitude spectrogram to the decibel scale. This computes `20 * log10(spectrogram / reference)`,\n * using basic logarithm properties for numerical stability. NOTE: Operates in-place.\n * \n * The motivation behind applying the log function on the (mel) spectrogram is that humans do not hear loudness on a\n * linear scale. Generally to double the perceived volume of a sound we need to put 8 times as much energy into it.\n * This means that large variations in energy may not sound all that different if the sound is loud to begin with.\n * This compression operation makes the (mel) spectrogram features match more closely what humans actually hear.\n * \n * @template {Float32Array|Float64Array} T\n * @param {T} spectrogram The input amplitude (mel) spectrogram.\n * @param {number} [reference=1.0] Sets the input spectrogram value that corresponds to 0 dB.\n * For example, use `np.max(spectrogram)` to set the loudest part to 0 dB. Must be greater than zero.\n * @param {number} [min_value=1e-5] The spectrogram will be clipped to this minimum value before conversion to decibels,\n * to avoid taking `log(0)`. The default of `1e-5` corresponds to a minimum of -100 dB. Must be greater than zero.\n * @param {number} [db_range=null] Sets the maximum dynamic range in decibels. For example, if `db_range = 80`, the\n * difference between the peak value and the smallest value will never be more than 80 dB. Must be greater than zero.\n * @returns {T} The modified spectrogram in decibels.\n */\nfunction amplitude_to_db(spectrogram, reference = 1.0, min_value = 1e-5, db_range = null) {\n    return _db_conversion_helper(spectrogram, 20.0, reference, min_value, db_range);\n}\n\n/**\n * Converts a power spectrogram to the decibel scale. This computes `10 * log10(spectrogram / reference)`,\n * using basic logarithm properties for numerical stability. NOTE: Operates in-place.\n * \n * The motivation behind applying the log function on the (mel) spectrogram is that humans do not hear loudness on a\n * linear scale. Generally to double the perceived volume of a sound we need to put 8 times as much energy into it.\n * This means that large variations in energy may not sound all that different if the sound is loud to begin with.\n * This compression operation makes the (mel) spectrogram features match more closely what humans actually hear.\n * \n * Based on the implementation of `librosa.power_to_db`.\n * \n * @template {Float32Array|Float64Array} T\n * @param {T} spectrogram The input power (mel) spectrogram. Note that a power spectrogram has the amplitudes squared!\n * @param {number} [reference=1.0] Sets the input spectrogram value that corresponds to 0 dB.\n * For example, use `np.max(spectrogram)` to set the loudest part to 0 dB. Must be greater than zero.\n * @param {number} [min_value=1e-10] The spectrogram will be clipped to this minimum value before conversion to decibels,\n * to avoid taking `log(0)`. The default of `1e-10` corresponds to a minimum of -100 dB. Must be greater than zero.\n * @param {number} [db_range=null] Sets the maximum dynamic range in decibels. For example, if `db_range = 80`, the\n * difference between the peak value and the smallest value will never be more than 80 dB. Must be greater than zero.\n * @returns {T} The modified spectrogram in decibels.\n */\nfunction power_to_db(spectrogram, reference = 1.0, min_value = 1e-10, db_range = null) {\n    return _db_conversion_helper(spectrogram, 10.0, reference, min_value, db_range);\n}\n\n/**\n * Calculates a spectrogram over one waveform using the Short-Time Fourier Transform.\n * \n * This function can create the following kinds of spectrograms:\n *   - amplitude spectrogram (`power = 1.0`)\n *   - power spectrogram (`power = 2.0`)\n *   - complex-valued spectrogram (`power = None`)\n *   - log spectrogram (use `log_mel` argument)\n *   - mel spectrogram (provide `mel_filters`)\n *   - log-mel spectrogram (provide `mel_filters` and `log_mel`)\n *\n * In this implementation, the window is assumed to be zero-padded to have the same size as the analysis frame.\n * A padded window can be obtained from `window_function()`. The FFT input buffer may be larger than the analysis frame, \n * typically the next power of two.\n * \n * @param {Float32Array|Float64Array} waveform The input waveform of shape `(length,)`. This must be a single real-valued, mono waveform.\n * @param {Float32Array|Float64Array} window The windowing function to apply of shape `(frame_length,)`, including zero-padding if necessary. The actual window length may be\n * shorter than `frame_length`, but we're assuming the array has already been zero-padded.\n * @param {number} frame_length The length of the analysis frames in samples (a.k.a., `fft_length`).\n * @param {number} hop_length The stride between successive analysis frames in samples.\n * @param {Object} options\n * @param {number} [options.fft_length=null] The size of the FFT buffer in samples. This determines how many frequency bins the spectrogram will have.\n * For optimal speed, this should be a power of two. If `null`, uses `frame_length`.\n * @param {number} [options.power=1.0] If 1.0, returns the amplitude spectrogram. If 2.0, returns the power spectrogram. If `null`, returns complex numbers.\n * @param {boolean} [options.center=true] Whether to pad the waveform so that frame `t` is centered around time `t * hop_length`. If `false`, frame\n * `t` will start at time `t * hop_length`.\n * @param {string} [options.pad_mode=\"reflect\"] Padding mode used when `center` is `true`. Possible values are: `\"constant\"` (pad with zeros),\n * `\"edge\"` (pad with edge values), `\"reflect\"` (pads with mirrored values).\n * @param {boolean} [options.onesided=true] If `true`, only computes the positive frequencies and returns a spectrogram containing `fft_length // 2 + 1`\n * frequency bins. If `false`, also computes the negative frequencies and returns `fft_length` frequency bins.\n * @param {number} [options.preemphasis=null] Coefficient for a low-pass filter that applies pre-emphasis before the DFT.\n * @param {number[][]} [options.mel_filters=null] The mel filter bank of shape `(num_freq_bins, num_mel_filters)`.\n * If supplied, applies this filter bank to create a mel spectrogram.\n * @param {number} [options.mel_floor=1e-10] Minimum value of mel frequency banks.\n * @param {string} [options.log_mel=null] How to convert the spectrogram to log scale. Possible options are:\n * `null` (don't convert), `\"log\"` (take the natural logarithm) `\"log10\"` (take the base-10 logarithm), `\"dB\"` (convert to decibels).\n * Can only be used when `power` is not `null`.\n * @param {number} [options.reference=1.0] Sets the input spectrogram value that corresponds to 0 dB. For example, use `max(spectrogram)[0]` to set\n * the loudest part to 0 dB. Must be greater than zero.\n * @param {number} [options.min_value=1e-10] The spectrogram will be clipped to this minimum value before conversion to decibels, to avoid taking `log(0)`.\n * For a power spectrogram, the default of `1e-10` corresponds to a minimum of -100 dB. For an amplitude spectrogram, the value `1e-5` corresponds to -100 dB.\n * Must be greater than zero.\n * @param {number} [options.db_range=null] Sets the maximum dynamic range in decibels. For example, if `db_range = 80`, the difference between the\n * peak value and the smallest value will never be more than 80 dB. Must be greater than zero.\n * @param {boolean} [options.remove_dc_offset=null] Subtract mean from waveform on each frame, applied before pre-emphasis. This should be set to `true` in\n * order to get the same results as `torchaudio.compliance.kaldi.fbank` when computing mel filters.\n * @param {number} [options.max_num_frames=null] If provided, limits the number of frames to compute to this value.\n * @param {boolean} [options.do_pad=true] If `true`, pads the output spectrogram to have `max_num_frames` frames.\n * @param {boolean} [options.transpose=false] If `true`, the returned spectrogram will have shape `(num_frames, num_frequency_bins/num_mel_filters)`. If `false`, the returned spectrogram will have shape `(num_frequency_bins/num_mel_filters, num_frames)`.\n * @returns {{data: Float32Array, dims: number[]}} Spectrogram of shape `(num_frequency_bins, length)` (regular spectrogram) or shape `(num_mel_filters, length)` (mel spectrogram).\n */\nfunction spectrogram(\n    waveform,\n    window,\n    frame_length,\n    hop_length,\n    {\n        fft_length = null,\n        power = 1.0,\n        center = true,\n        pad_mode = \"reflect\",\n        onesided = true,\n        preemphasis = null,\n        mel_filters = null,\n        mel_floor = 1e-10,\n        log_mel = null,\n        reference = 1.0,\n        min_value = 1e-10,\n        db_range = null,\n        remove_dc_offset = null,\n\n        // Custom parameters for efficiency reasons\n        max_num_frames = null,\n        do_pad = true,\n        transpose = false,\n    } = {}\n) {\n    const window_length = window.length;\n    if (fft_length === null) {\n        fft_length = frame_length;\n    }\n    if (frame_length > fft_length) {\n        throw Error(`frame_length (${frame_length}) may not be larger than fft_length (${fft_length})`)\n    }\n\n    if (window_length !== frame_length) {\n        throw new Error(`Length of the window (${window_length}) must equal frame_length (${frame_length})`);\n    }\n\n    if (hop_length <= 0) {\n        throw new Error(\"hop_length must be greater than zero\");\n    }\n\n    if (center) {\n        if (pad_mode !== 'reflect') {\n            throw new Error(`pad_mode=\"${pad_mode}\" not implemented yet.`)\n        }\n        const half_window = Math.floor((fft_length - 1) / 2) + 1;\n        waveform = padReflect(waveform, half_window, half_window);\n    }\n\n    // split waveform into frames of frame_length size\n    const num_frames = Math.floor(1 + Math.floor((waveform.length - frame_length) / hop_length))\n\n    const num_frequency_bins = onesided ? Math.floor(fft_length / 2) + 1 : fft_length\n\n    let d1 = num_frames;\n    let d1Max = num_frames;\n\n    // If maximum number of frames is provided, we must either pad or truncate\n    if (max_num_frames !== null) {\n        if (max_num_frames > num_frames) { // input is too short, so we pad\n            if (do_pad) {\n                d1Max = max_num_frames;\n            }\n        } else { // input is too long, so we truncate\n            d1Max = d1 = max_num_frames;\n        }\n    }\n\n    // Preallocate arrays to store output.\n    const fft = new _maths_js__WEBPACK_IMPORTED_MODULE_1__.FFT(fft_length);\n    const inputBuffer = new Float64Array(fft_length);\n    const outputBuffer = new Float64Array(fft.outputBufferSize);\n    const magnitudes = new Array(d1);\n\n    for (let i = 0; i < d1; ++i) {\n        // Populate buffer with waveform data\n        const offset = i * hop_length;\n        for (let j = 0; j < frame_length; ++j) {\n            inputBuffer[j] = waveform[offset + j];\n        }\n\n        if (remove_dc_offset) {\n            let sum = 0;\n            for (let j = 0; j < frame_length; ++j) {\n                sum += inputBuffer[j];\n            }\n            const mean = sum / frame_length;\n            for (let j = 0; j < frame_length; ++j) {\n                inputBuffer[j] -= mean;\n            }\n        }\n\n        if (preemphasis !== null) {\n            // Done in reverse to avoid copies and distructive modification\n            for (let j = frame_length - 1; j >= 1; --j) {\n                inputBuffer[j] -= preemphasis * inputBuffer[j - 1];\n            }\n            inputBuffer[0] *= 1 - preemphasis;\n        }\n\n        for (let j = 0; j < window.length; ++j) {\n            inputBuffer[j] *= window[j];\n        }\n\n        fft.realTransform(outputBuffer, inputBuffer);\n\n        // compute magnitudes\n        const row = new Array(num_frequency_bins);\n        for (let j = 0; j < row.length; ++j) {\n            const j2 = j << 1;\n            row[j] = outputBuffer[j2] ** 2 + outputBuffer[j2 + 1] ** 2;\n        }\n        magnitudes[i] = row;\n    }\n\n    // TODO what should happen if power is None?\n    // https://github.com/huggingface/transformers/issues/27772\n    if (power !== null && power !== 2) {\n        // slight optimization to not sqrt\n        const pow = 2 / power; // we use 2 since we already squared\n        for (let i = 0; i < magnitudes.length; ++i) {\n            const magnitude = magnitudes[i];\n            for (let j = 0; j < magnitude.length; ++j) {\n                magnitude[j] **= pow;\n            }\n        }\n    }\n\n    // TODO: What if `mel_filters` is null?\n    const num_mel_filters = mel_filters.length;\n\n    // Only here do we create Float32Array\n    const mel_spec = new Float32Array(num_mel_filters * d1Max);\n\n    // Perform matrix muliplication:\n    // mel_spec = mel_filters @ magnitudes.T\n    //  - mel_filters.shape=(80, 201)\n    //  - magnitudes.shape=(3000, 201) => - magnitudes.T.shape=(201, 3000)\n    //  - mel_spec.shape=(80, 3000)\n    const dims = transpose ? [d1Max, num_mel_filters] : [num_mel_filters, d1Max];\n    for (let i = 0; i < num_mel_filters; ++i) { // num melfilters (e.g., 80)\n        const filter = mel_filters[i];\n        for (let j = 0; j < d1; ++j) { // num frames (e.g., 3000)\n            const magnitude = magnitudes[j];\n\n            let sum = 0;\n            for (let k = 0; k < num_frequency_bins; ++k) { // num frequency bins (e.g., 201)\n                sum += filter[k] * magnitude[k];\n            }\n\n            mel_spec[\n                transpose\n                    ? j * num_mel_filters + i\n                    : i * d1 + j\n            ] = Math.max(mel_floor, sum);\n        }\n    }\n\n    if (power !== null && log_mel !== null) {\n        const o = Math.min(mel_spec.length, d1 * num_mel_filters);\n        switch (log_mel) {\n            case 'log':\n                for (let i = 0; i < o; ++i) {\n                    mel_spec[i] = Math.log(mel_spec[i]);\n                }\n                break;\n            case 'log10':\n                for (let i = 0; i < o; ++i) {\n                    mel_spec[i] = Math.log10(mel_spec[i]);\n                }\n                break;\n            case 'dB':\n                if (power === 1.0) {\n                    // NOTE: operates in-place\n                    amplitude_to_db(mel_spec, reference, min_value, db_range);\n                } else if (power === 2.0) {\n                    power_to_db(mel_spec, reference, min_value, db_range);\n                } else {\n                    throw new Error(`Cannot use log_mel option '${log_mel}' with power ${power}`)\n                }\n                break;\n            default:\n                throw new Error(`log_mel must be one of null, 'log', 'log10' or 'dB'. Got '${log_mel}'`);\n        }\n    }\n\n    return { data: mel_spec, dims };\n}\n\n/**\n * Returns an array containing the specified window.\n * @param {number} window_length The length of the window in samples.\n * @param {string} name The name of the window function.\n * @param {Object} options Additional options.\n * @param {boolean} [options.periodic=true] Whether the window is periodic or symmetric.\n * @param {number} [options.frame_length=null] The length of the analysis frames in samples.\n * Provide a value for `frame_length` if the window is smaller than the frame length, so that it will be zero-padded.\n * @param {boolean} [options.center=true] Whether to center the window inside the FFT buffer. Only used when `frame_length` is provided.\n * @returns {Float64Array} The window of shape `(window_length,)` or `(frame_length,)`.\n */\nfunction window_function(window_length, name, {\n    periodic = true,\n    frame_length = null,\n    center = true,\n} = {}) {\n    const length = periodic ? window_length + 1 : window_length;\n    let window;\n    switch (name) {\n        case 'boxcar':\n            window = new Float64Array(length).fill(1.0);\n            break;\n        case 'hann':\n        case 'hann_window':\n            window = hanning(length);\n            break;\n        case 'povey':\n            window = hanning(length).map(x => Math.pow(x, 0.85));\n            break;\n        default:\n            throw new Error(`Unknown window type ${name}.`);\n    }\n    if (periodic) {\n        window = window.subarray(0, window_length);\n    }\n    if (frame_length === null) {\n        return window;\n    }\n    if (window_length > frame_length) {\n        throw new Error(`Length of the window (${window_length}) may not be larger than frame_length (${frame_length})`);\n    }\n\n    return window;\n}\n\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@xenova/transformers/src/utils/audio.js?");

/***/ }),

/***/ "./node_modules/@xenova/transformers/src/utils/core.js":
/*!*************************************************************!*\
  !*** ./node_modules/@xenova/transformers/src/utils/core.js ***!
  \*************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Callable: () => (/* binding */ Callable),\n/* harmony export */   calculateDimensions: () => (/* binding */ calculateDimensions),\n/* harmony export */   calculateReflectOffset: () => (/* binding */ calculateReflectOffset),\n/* harmony export */   dispatchCallback: () => (/* binding */ dispatchCallback),\n/* harmony export */   escapeRegExp: () => (/* binding */ escapeRegExp),\n/* harmony export */   exists: () => (/* binding */ exists),\n/* harmony export */   isIntegralNumber: () => (/* binding */ isIntegralNumber),\n/* harmony export */   isTypedArray: () => (/* binding */ isTypedArray),\n/* harmony export */   mergeArrays: () => (/* binding */ mergeArrays),\n/* harmony export */   pop: () => (/* binding */ pop),\n/* harmony export */   product: () => (/* binding */ product),\n/* harmony export */   reverseDictionary: () => (/* binding */ reverseDictionary)\n/* harmony export */ });\n\n/**\n * @file Core utility functions/classes for Transformers.js.\n * \n * These are only used internally, meaning an end-user shouldn't\n * need to access anything here.\n * \n * @module utils/core\n */\n\n/**\n * Helper function to dispatch progress callbacks.\n *\n * @param {Function} progress_callback The progress callback function to dispatch.\n * @param {any} data The data to pass to the progress callback function.\n * @returns {void}\n * @private\n */\nfunction dispatchCallback(progress_callback, data) {\n    if (progress_callback) progress_callback(data);\n}\n\n/**\n * Reverses the keys and values of an object.\n *\n * @param {Object} data The object to reverse.\n * @returns {Object} The reversed object.\n * @see https://ultimatecourses.com/blog/reverse-object-keys-and-values-in-javascript\n */\nfunction reverseDictionary(data) {\n    // https://ultimatecourses.com/blog/reverse-object-keys-and-values-in-javascript\n    return Object.fromEntries(Object.entries(data).map(([key, value]) => [value, key]));\n}\n\n/**\n * Escapes regular expression special characters from a string by replacing them with their escaped counterparts.\n *\n * @param {string} string The string to escape.\n * @returns {string} The escaped string.\n */\nfunction escapeRegExp(string) {\n    return string.replace(/[.*+?^${}()|[\\]\\\\]/g, '\\\\$&'); // $& means the whole matched string\n}\n\n/**\n * A base class for creating callable objects.\n * \n * @type {new () => {(...args: any[]): any, _call(...args: any[]): any}}\n */\nconst Callable = /** @type {any} */ (class {\n    /**\n    * Creates a new instance of the Callable class.\n    */\n    constructor() {\n        /**\n         * Creates a closure that delegates to a private method '_call' with the given arguments.\n         * @type {any}\n         * @param {...any} args Zero or more arguments to pass to the '_call' method.\n         * @returns {*} The result of calling the '_call' method.\n         */\n        let closure = function (...args) {\n            return closure._call(...args)\n        }\n        return Object.setPrototypeOf(closure, new.target.prototype)\n    }\n\n    /**\n     * This method should be implemented in subclasses to provide the\n     * functionality of the callable object.\n     *\n     * @param {any[]} args\n     * @throws {Error} If the subclass does not implement the `_call` method.\n     */\n    _call(...args) {\n        throw Error('Must implement _call method in subclass')\n    }\n});\n\n/**\n * Check if a value is a typed array.\n * @param {*} val The value to check.\n * @returns {boolean} True if the value is a `TypedArray`, false otherwise.\n * \n * Adapted from https://stackoverflow.com/a/71091338/13989043\n */\nfunction isTypedArray(val) {\n    return val?.prototype?.__proto__?.constructor?.name === 'TypedArray';\n}\n\n\n/**\n * Check if a value is an integer.\n * @param {*} x The value to check.\n * @returns {boolean} True if the value is a string, false otherwise.\n */\nfunction isIntegralNumber(x) {\n    return Number.isInteger(x) || typeof x === 'bigint'\n}\n\n/**\n * Check if a value is exists.\n * @param {*} x The value to check.\n * @returns {boolean} True if the value exists, false otherwise.\n */\nfunction exists(x) {\n    return x !== undefined && x !== null;\n}\n\n/**\n * Calculates the dimensions of a nested array.\n *\n * @param {any[]} arr The nested array to calculate dimensions for.\n * @returns {number[]} An array containing the dimensions of the input array.\n */\nfunction calculateDimensions(arr) {\n    const dimensions = [];\n    let current = arr;\n    while (Array.isArray(current)) {\n        dimensions.push(current.length);\n        current = current[0];\n    }\n    return dimensions;\n}\n\n/**\n * Replicate python's .pop() method for objects.\n * @param {Object} obj The object to pop from.\n * @param {string} key The key to pop.\n * @param {*} defaultValue The default value to return if the key does not exist.\n * @returns {*} The value of the popped key.\n * @throws {Error} If the key does not exist and no default value is provided.\n */\nfunction pop(obj, key, defaultValue = undefined) {\n    const value = obj[key];\n    if (value !== undefined) {\n        delete obj[key];\n        return value;\n    }\n    if (defaultValue === undefined) {\n        throw Error(`Key ${key} does not exist in object.`)\n    }\n    return defaultValue;\n}\n\n/**\n * Efficiently merge arrays, creating a new copy.\n * Adapted from https://stackoverflow.com/a/6768642/13989043\n * @param  {Array[]} arrs Arrays to merge.\n * @returns {Array} The merged array.\n */\nfunction mergeArrays(...arrs) {\n    return Array.prototype.concat.apply([], arrs);\n}\n\n/**\n * Compute the Cartesian product of given arrays\n * @param {...Array} a Arrays to compute the product\n * @returns {Array} Returns the computed Cartesian product as an array\n * @private\n */\nfunction product(...a) {\n    // Cartesian product of items\n    // Adapted from https://stackoverflow.com/a/43053803\n    return a.reduce((a, b) => a.flatMap(d => b.map(e => [d, e])));\n}\n\n/**\n * Calculates the index offset for a given index and window size.\n * @param {number} i The index.\n * @param {number} w The window size.\n * @returns {number} The index offset.\n */\nfunction calculateReflectOffset(i, w) {\n    return Math.abs((i + w) % (2 * w) - w);\n}\n\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@xenova/transformers/src/utils/core.js?");

/***/ }),

/***/ "./node_modules/@xenova/transformers/src/utils/data-structures.js":
/*!************************************************************************!*\
  !*** ./node_modules/@xenova/transformers/src/utils/data-structures.js ***!
  \************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   CharTrie: () => (/* binding */ CharTrie),\n/* harmony export */   PriorityQueue: () => (/* binding */ PriorityQueue),\n/* harmony export */   TokenLattice: () => (/* binding */ TokenLattice)\n/* harmony export */ });\n\n/**\n * @file Custom data structures.\n * \n * These are only used internally, meaning an end-user shouldn't\n * need to access anything here.\n * \n * @module utils/data-structures\n */\n\n\n/**\n * Efficient Heap-based Implementation of a Priority Queue.\n * It uses an array-based binary heap, where the root is at index `0`, and the\n * children of node `i` are located at indices `2i + 1` and `2i + 2`, respectively.\n * \n * Adapted from the following sources:\n * - https://stackoverflow.com/a/42919752/13989043 (original)\n * - https://github.com/belladoreai/llama-tokenizer-js (minor improvements)\n */\nclass PriorityQueue {\n\n    /**\n     * Create a new PriorityQueue.\n     * @param {Function} comparator Comparator function to determine priority. Defaults to a MaxHeap.\n     */\n    constructor(comparator = (a, b) => a > b) {\n        this._heap = [];\n        this._comparator = comparator;\n    }\n\n    /**\n     * The size of the queue\n     */\n    get size() {\n        return this._heap.length;\n    }\n\n    /**\n     * Check if the queue is empty.\n     * @returns {boolean} `true` if the queue is empty, `false` otherwise.\n     */\n    isEmpty() {\n        return this.size === 0;\n    }\n\n    /**\n     * Return the element with the highest priority in the queue.\n     * @returns {any} The highest priority element in the queue.\n     */\n    peek() {\n        return this._heap[0];\n    }\n\n    /**\n     * Add one or more elements to the queue.\n     * @param  {...any} values The values to push into the queue.\n     * @returns {number} The new size of the queue.\n     */\n    push(...values) {\n        return this.extend(values);\n    }\n\n    /**\n     * Add multiple elements to the queue.\n     * @param {any[]} values The values to push into the queue.\n     * @returns {number} The new size of the queue.\n     */\n    extend(values) {\n        for (const value of values) {\n            this._heap.push(value);\n            this._siftUp();\n        }\n        return this.size;\n    }\n\n    /**\n     * Remove and return the element with the highest priority in the queue.\n     * @returns {any} The element with the highest priority in the queue.\n     */\n    pop() {\n        const poppedValue = this.peek();\n        const bottom = this.size - 1;\n        if (bottom > 0) {\n            this._swap(0, bottom);\n        }\n        this._heap.pop();\n        this._siftDown();\n        return poppedValue;\n    }\n\n    /**\n     * Replace the element with the highest priority in the queue with a new value.\n     * @param {*} value The new value.\n     * @returns {*} The replaced value.\n     */\n    replace(value) {\n        const replacedValue = this.peek();\n        this._heap[0] = value;\n        this._siftDown();\n        return replacedValue;\n    }\n\n    /**\n     * Compute the index for the parent of the node at index `i`.\n     * @param {number} i The index of the node to get the parent of.\n     * @returns {number} The index of the parent node.\n     * @private\n     */\n    _parent(i) {\n        return ((i + 1) >>> 1) - 1;\n    }\n\n    /**\n     * Compute the index for the left child of the node at index `i`.\n     * @param {number} i The index of the node to get the left child of.\n     * @returns {number} The index of the left child.\n     * @private\n     */\n    _left(i) {\n        return (i << 1) + 1;\n    }\n\n    /**\n     * Compute the index for the right child of the node at index `i`.\n     * @param {number} i The index of the node to get the right child of.\n     * @returns {number} The index of the right child.\n     * @private\n     */\n    _right(i) {\n        return (i + 1) << 1;\n    }\n\n    /**\n     * Check if the element at index `i` is greater than the element at index `j`.\n     * @param {number} i The index of the first element to compare.\n     * @param {number} j The index of the second element to compare.\n     * @returns {boolean} `true` if the element at index `i` is greater than the element at index `j`, `false` otherwise.\n     * @private\n     */\n    _greater(i, j) {\n        return this._comparator(this._heap[i], this._heap[j]);\n    }\n\n    /**\n     * Swap the elements at indices `i` and `j`.\n     * @param {number} i The index of the first element to swap.\n     * @param {number} j The index of the second element to swap.\n     * @private\n     */\n    _swap(i, j) {\n        const temp = this._heap[i];\n        this._heap[i] = this._heap[j];\n        this._heap[j] = temp;\n    }\n\n    /**\n     * Maintain the heap property by updating positions in the heap,\n     * starting at the last element and moving up the heap.\n     * @private\n     */\n    _siftUp() {\n        let node = this.size - 1;\n        while (node > 0 && this._greater(node, this._parent(node))) {\n            this._swap(node, this._parent(node));\n            node = this._parent(node);\n        }\n    }\n    /**\n     * Maintain the heap property by updating positions in the heap,\n     * starting at the first element and moving down the heap.\n     * @private\n     */\n    _siftDown() {\n        let node = 0;\n        while (\n            (this._left(node) < this.size && this._greater(this._left(node), node)) ||\n            (this._right(node) < this.size && this._greater(this._right(node), node))\n        ) {\n            const maxChild = (this._right(node) < this.size && this._greater(this._right(node), this._left(node)))\n                ? this._right(node)\n                : this._left(node);\n            this._swap(node, maxChild);\n            node = maxChild;\n        }\n    }\n}\n\n/**\n * A trie structure to efficiently store and search for strings.\n */\nclass CharTrie {\n    constructor() {\n        this.root = CharTrieNode.default();\n    }\n\n    /**\n     * Adds one or more `texts` to the trie.\n     * @param {string[]} texts The strings to add to the trie.\n     */\n    extend(texts) {\n        for (let text of texts) {\n            this.push(text);\n        }\n    }\n\n    /**\n     * Adds text to the trie.\n     * @param {string} text The string to add to the trie.\n     */\n    push(text) {\n        let node = this.root;\n        for (let ch of text) {\n            let child = node.children.get(ch);\n            if (child === undefined) {\n                child = CharTrieNode.default();\n                node.children.set(ch, child);\n            }\n            node = child;\n        }\n        node.isLeaf = true;\n    }\n\n    /**\n     * Searches the trie for all strings with a common prefix of `text`.\n     * @param {string} text The common prefix to search for.\n     * @yields {string} Each string in the trie that has `text` as a prefix.\n     */\n    *commonPrefixSearch(text) {\n        let node = this.root;\n        let prefix = \"\";\n        for (let i = 0; i < text.length && node !== undefined; ++i) {\n            const ch = text[i];\n            prefix += ch;\n            node = node.children.get(ch);\n            if (node !== undefined && node.isLeaf) {\n                yield prefix;\n            }\n        }\n    }\n}\n\n/**\n * Represents a node in a character trie.\n */\nclass CharTrieNode {\n    /**\n     * Create a new CharTrieNode.\n     * @param {boolean} isLeaf Whether the node is a leaf node or not.\n     * @param {Map<string, CharTrieNode>} children A map containing the node's children, where the key is a character and the value is a `CharTrieNode`.\n     */\n    constructor(isLeaf, children) {\n        this.isLeaf = isLeaf;\n        this.children = children;\n    }\n\n    /**\n     * Returns a new `CharTrieNode` instance with default values.\n     * @returns {CharTrieNode} A new `CharTrieNode` instance with `isLeaf` set to `false` and an empty `children` map.\n     */\n    static default() {\n        return new CharTrieNode(false, new Map());\n    }\n}\n\n/**\n * A lattice data structure to be used for tokenization.\n */\nclass TokenLattice {\n    /**\n     * Creates a new TokenLattice instance.\n     *\n     * @param {string} sentence The input sentence to be tokenized.\n     * @param {number} bosTokenId The beginning-of-sequence token ID.\n     * @param {number} eosTokenId The end-of-sequence token ID.\n     */\n    constructor(sentence, bosTokenId, eosTokenId) {\n        this.sentence = sentence;\n        this.len = sentence.length;\n        this.bosTokenId = bosTokenId;\n        this.eosTokenId = eosTokenId;\n        this.nodes = [];\n        this.beginNodes = Array.from({ length: this.len + 1 }, () => []);\n        this.endNodes = Array.from({ length: this.len + 1 }, () => []);\n\n        const bos = new TokenLatticeNode(this.bosTokenId, 0, 0, 0, 0.0);\n        const eos = new TokenLatticeNode(this.eosTokenId, 1, this.len, 0, 0.0);\n        this.nodes.push(bos.clone());\n        this.nodes.push(eos.clone());\n        this.beginNodes[this.len].push(eos);\n        this.endNodes[0].push(bos);\n    }\n\n    /**\n     * Inserts a new token node into the token lattice.\n     *\n     * @param {number} pos The starting position of the token.\n     * @param {number} length The length of the token.\n     * @param {number} score The score of the token.\n     * @param {number} tokenId The token ID of the token.\n     */\n    insert(pos, length, score, tokenId) {\n        const nodeId = this.nodes.length;\n        const node = new TokenLatticeNode(tokenId, nodeId, pos, length, score);\n        this.beginNodes[pos].push(node);\n        this.endNodes[pos + length].push(node);\n        this.nodes.push(node);\n    }\n\n    /**\n     * Implements the Viterbi algorithm to compute the most likely sequence of tokens.\n     *\n     * @returns {TokenLatticeNode[]} The array of nodes representing the most likely sequence of tokens.\n     */\n    viterbi() {\n        const len = this.len;\n        let pos = 0;\n        while (pos <= len) {\n            if (this.beginNodes[pos].length == 0) {\n                return [];\n            }\n            for (let rnode of this.beginNodes[pos]) {\n                rnode.prev = null;\n                let bestScore = 0.0;\n                let bestNode = null;\n                for (let lnode of this.endNodes[pos]) {\n                    const score = lnode.backtraceScore + rnode.score;\n                    if (bestNode === null || score > bestScore) {\n                        bestNode = lnode.clone();\n                        bestScore = score;\n                    }\n                }\n\n                if (bestNode !== null) {\n                    rnode.prev = bestNode;\n                    rnode.backtraceScore = bestScore;\n                } else {\n                    return [];\n                }\n            }\n            ++pos;\n        }\n\n        const results = [];\n        const root = this.beginNodes[len][0];\n        const prev = root.prev;\n        if (prev === null) {\n            return [];\n        }\n\n        let node = prev.clone();\n        while (node.prev !== null) {\n            results.push(node.clone());\n            const n = node.clone();\n            node = n.prev.clone();\n        }\n\n        results.reverse();\n        return results;\n    }\n\n    /**\n     * @param {TokenLatticeNode} node\n     * @returns {string} The array of nodes representing the most likely sequence of tokens.\n     */\n    piece(node) {\n        return this.sentence.slice(node.pos, node.pos + node.length);\n    }\n\n    /**\n     * @returns {Array} The array of nodes representing the most likely sequence of tokens.\n     */\n    tokens() {\n        const nodes = this.viterbi();\n        return nodes.map(x => this.piece(x));\n    }\n\n    /**\n     * @returns {Array} The array of nodes representing the most likely sequence of tokens.\n     */\n    tokenIds() {\n        const nodes = this.viterbi();\n        return nodes.map(x => x.tokenId);\n    }\n}\nclass TokenLatticeNode {\n    /**\n     * Represents a node in a token lattice for a given sentence.\n     * @param {number} tokenId The ID of the token associated with this node.\n     * @param {number} nodeId The ID of this node.\n     * @param {number} pos The starting position of the token in the sentence.\n     * @param {number} length The length of the token.\n     * @param {number} score The score associated with the token.\n     */\n    constructor(tokenId, nodeId, pos, length, score) {\n        this.tokenId = tokenId;\n        this.nodeId = nodeId;\n        this.pos = pos;\n        this.length = length;\n        this.score = score;\n        this.prev = null;\n        this.backtraceScore = 0.0;\n    }\n\n    /**\n     * Returns a clone of this node.\n     * @returns {TokenLatticeNode} A clone of this node.\n     */\n    clone() {\n        const n = new TokenLatticeNode(this.tokenId, this.nodeId, this.pos, this.length, this.score);\n        n.prev = this.prev;\n        n.backtraceScore = this.backtraceScore;\n        return n;\n    }\n}\n\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@xenova/transformers/src/utils/data-structures.js?");

/***/ }),

/***/ "./node_modules/@xenova/transformers/src/utils/generation.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@xenova/transformers/src/utils/generation.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   ForceTokensLogitsProcessor: () => (/* binding */ ForceTokensLogitsProcessor),\n/* harmony export */   ForcedBOSTokenLogitsProcessor: () => (/* binding */ ForcedBOSTokenLogitsProcessor),\n/* harmony export */   ForcedEOSTokenLogitsProcessor: () => (/* binding */ ForcedEOSTokenLogitsProcessor),\n/* harmony export */   GenerationConfig: () => (/* binding */ GenerationConfig),\n/* harmony export */   LogitsProcessor: () => (/* binding */ LogitsProcessor),\n/* harmony export */   LogitsProcessorList: () => (/* binding */ LogitsProcessorList),\n/* harmony export */   MinLengthLogitsProcessor: () => (/* binding */ MinLengthLogitsProcessor),\n/* harmony export */   MinNewTokensLengthLogitsProcessor: () => (/* binding */ MinNewTokensLengthLogitsProcessor),\n/* harmony export */   NoBadWordsLogitsProcessor: () => (/* binding */ NoBadWordsLogitsProcessor),\n/* harmony export */   NoRepeatNGramLogitsProcessor: () => (/* binding */ NoRepeatNGramLogitsProcessor),\n/* harmony export */   RepetitionPenaltyLogitsProcessor: () => (/* binding */ RepetitionPenaltyLogitsProcessor),\n/* harmony export */   Sampler: () => (/* binding */ Sampler),\n/* harmony export */   SuppressTokensAtBeginLogitsProcessor: () => (/* binding */ SuppressTokensAtBeginLogitsProcessor),\n/* harmony export */   WhisperTimeStampLogitsProcessor: () => (/* binding */ WhisperTimeStampLogitsProcessor)\n/* harmony export */ });\n/* harmony import */ var _tensor_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./tensor.js */ \"./node_modules/@xenova/transformers/src/utils/tensor.js\");\n/* harmony import */ var _core_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./core.js */ \"./node_modules/@xenova/transformers/src/utils/core.js\");\n/* harmony import */ var _maths_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./maths.js */ \"./node_modules/@xenova/transformers/src/utils/maths.js\");\n\n/**\n * @file Classes, functions, and utilities for generation.\n * \n * @todo Describe how to create a custom `GenerationConfig`.\n * \n * @module utils/generation\n */\n\n\n\n\n/**\n * A class representing a list of logits processors. A logits processor is a function that modifies the logits\n * output of a language model. This class provides methods for adding new processors and applying all processors to a\n * batch of logits.\n *\n * @extends Callable\n */\nclass LogitsProcessorList extends _core_js__WEBPACK_IMPORTED_MODULE_1__.Callable {\n    /**\n     * Constructs a new instance of `LogitsProcessorList`.\n     */\n    constructor() {\n        super();\n        this.processors = [];\n    }\n\n    /**\n     * Adds a new logits processor to the list.\n     *\n     * @param {LogitsProcessor} item The logits processor function to add.\n     */\n    push(item) {\n        this.processors.push(item);\n    }\n\n    /**\n     * Adds multiple logits processors to the list.\n     *\n     * @param {LogitsProcessor[]} items The logits processor functions to add.\n     */\n    extend(items) {\n        this.processors.push(...items);\n    }\n\n    /**\n     * Applies all logits processors in the list to a batch of logits, modifying them in-place.\n     *\n     * @param {number[]} input_ids The input IDs for the language model.\n     * @param {number[][]} batchedLogits A 2D array of logits, where each row corresponds to a single\n     *                                                input sequence in the batch.\n     */\n    _call(input_ids, batchedLogits) {\n        // NOTE: This is different from the Python code, since vanilla JS does not support vectorized operations. \n        // As a result, we apply each processor to each item in the batch.\n        for (let logits of batchedLogits) {\n            // Modifies logits inplace\n            this.processors.forEach(\n                func => func(input_ids, logits)\n            )\n        }\n    }\n\n    [Symbol.iterator]() {\n        return this.processors.values();\n    }\n}\n\n/**\n * Base class for processing logits.\n * @extends Callable\n */\nclass LogitsProcessor extends _core_js__WEBPACK_IMPORTED_MODULE_1__.Callable {\n    /**\n     * Apply the processor to the input logits.\n     *\n     * @abstract\n     * @param {Array} input_ids The input ids.\n     * @param {Tensor} logits The logits to process.\n     * @throws {Error} Throws an error if `_call` is not implemented in the subclass.\n     */\n    _call(input_ids, logits) {\n        throw Error(\"`_call` should be implemented in a subclass\")\n    }\n}\n\n/**\n * A logits processor that forces a specific token to be generated by the decoder.\n * \n * @extends LogitsProcessor\n */\nclass ForceTokensLogitsProcessor extends LogitsProcessor {\n    /**\n     * Constructs a new instance of `ForceTokensLogitsProcessor`.\n     * \n     * @param {Array} forced_decoder_ids The ids of tokens that should be forced.\n     */\n    constructor(forced_decoder_ids) {\n        super();\n        this.force_token_map = Object.fromEntries(forced_decoder_ids ?? []);\n    }\n\n    /**\n     * Apply the processor to the input logits.\n     *\n     * @param {Array} input_ids The input ids.\n     * @param {Tensor} logits The logits to process.\n     * @returns {Tensor} The processed logits.\n     */\n    _call(input_ids, logits) {\n        let map = this.force_token_map[input_ids.length];\n        if ((0,_core_js__WEBPACK_IMPORTED_MODULE_1__.exists)(map)) { // There exists a mapping\n            logits.data.fill(-Infinity)\n            logits.data[map] = 0;\n        }\n        return logits;\n    }\n}\n\n/**\n * A LogitsProcessor that forces a BOS token at the beginning of the generated sequence.\n * @extends LogitsProcessor\n */\nclass ForcedBOSTokenLogitsProcessor extends LogitsProcessor {\n    /**\n     * Create a ForcedBOSTokenLogitsProcessor.\n     * @param {number} bos_token_id The ID of the beginning-of-sequence token to be forced.\n     */\n    constructor(bos_token_id) {\n        super();\n        this.bos_token_id = bos_token_id;\n    }\n\n    /**\n     * Apply the BOS token forcing to the logits.\n     * @param {Array} input_ids The input IDs.\n     * @param {Object} logits The logits.\n     * @returns {Object} The logits with BOS token forcing.\n     */\n    _call(input_ids, logits) {\n        if (input_ids.length === 1) {\n            logits.data.fill(-Infinity)\n            logits.data[this.bos_token_id] = 0;\n        }\n        return logits;\n    }\n}\n\n/**\n * A logits processor that forces end-of-sequence token probability to 1.\n * \n * @extends LogitsProcessor\n */\nclass ForcedEOSTokenLogitsProcessor extends LogitsProcessor {\n    /**\n     * Create a ForcedEOSTokenLogitsProcessor.\n     * @param {number} max_length Max length of the sequence.\n     * @param {number|number[]} forced_eos_token_id The ID of the end-of-sequence token to be forced.\n     */\n    constructor(max_length, forced_eos_token_id) {\n        super();\n        this.max_length = max_length;\n        this.forced_eos_token_id = forced_eos_token_id;\n    }\n\n    /**\n     * Apply the processor to input_ids and logits.\n     * \n     * @param {number[]} input_ids The input ids.\n     * @param {Tensor} logits The logits tensor.\n     */\n    _call(input_ids, logits) {\n        // console.log('call ForcedEOSTokenLogitsProcessor')\n        // TODO\n    }\n}\n\n/**\n * A LogitsProcessor that suppresses a list of tokens as soon as the `generate` function starts\n * generating using `begin_index` tokens. This should ensure that the tokens defined by\n * `begin_suppress_tokens` at not sampled at the begining of the generation.\n * @extends LogitsProcessor\n */\nclass SuppressTokensAtBeginLogitsProcessor extends LogitsProcessor {\n    /**\n     * Create a SuppressTokensAtBeginLogitsProcessor.\n     * @param {number[]} begin_suppress_tokens The IDs of the tokens to suppress.\n     * @param {number} begin_index The number of tokens to generate before suppressing tokens.\n     */\n    constructor(begin_suppress_tokens, begin_index) {\n        super();\n        this.begin_suppress_tokens = begin_suppress_tokens;\n        this.begin_index = begin_index;\n    }\n\n    /**\n     * Apply the BOS token forcing to the logits.\n     * @param {Array} input_ids The input IDs.\n     * @param {Object} logits The logits.\n     * @returns {Object} The logits with BOS token forcing.\n     */\n    _call(input_ids, logits) {\n        if (input_ids.length === this.begin_index) {\n            for (let token_id of this.begin_suppress_tokens) {\n                logits.data[token_id] = -Infinity;\n            }\n        }\n        return logits;\n    }\n}\n\n/**\n * A LogitsProcessor that handles adding timestamps to generated text.\n * @extends LogitsProcessor\n */\nclass WhisperTimeStampLogitsProcessor extends LogitsProcessor {\n    /**\n     * Constructs a new WhisperTimeStampLogitsProcessor.\n     * @param {Object} generate_config The config object passed to the `generate()` method of a transformer model.\n     * @param {number} generate_config.eos_token_id The ID of the end-of-sequence token.\n     * @param {number} generate_config.no_timestamps_token_id The ID of the token used to indicate that a token should not have a timestamp.\n     * @param {number[][]} [generate_config.forced_decoder_ids] An array of two-element arrays representing decoder IDs that are forced to appear in the output. The second element of each array indicates whether the token is a timestamp.\n     * @param {number} [generate_config.max_initial_timestamp_index] The maximum index at which an initial timestamp can appear.\n     */\n    constructor(generate_config) {\n        super();\n        this.eos_token_id = generate_config.eos_token_id;\n        this.no_timestamps_token_id = generate_config.no_timestamps_token_id;\n        this.timestamp_begin = this.no_timestamps_token_id + 1;\n\n        this.begin_index = (generate_config.forced_decoder_ids || []).length + 2;\n        if (generate_config.forced_decoder_ids.slice(-1)[0][1] === this.no_timestamps_token_id) {\n            this.begin_index -= 1;\n        }\n        this.max_initial_timestamp_index = generate_config.max_initial_timestamp_index;\n\n    }\n\n    /**\n     * Modify the logits to handle timestamp tokens.\n     * @param {Array} input_ids The input sequence of tokens.\n     * @param {Tensor} logits The logits output by the model.\n     * @returns {Tensor} The modified logits.\n     */\n    _call(input_ids, logits) {\n        const logitsData = /** @type {Float32Array} */(logits.data);\n\n        // suppress <|notimestamps|> which is handled by without_timestamps\n        logitsData[this.no_timestamps_token_id] = -Infinity;\n\n        if (input_ids.length === this.begin_index - 1) {\n            logitsData.fill(-Infinity);\n            logitsData[this.timestamp_begin] = 0;\n            return logits;\n        }\n\n        // timestamps have to appear in pairs, except directly before eos_token; mask logits accordingly\n        const seq = input_ids.slice(this.begin_index);\n        const last_was_timestamp = seq.length >= 1 && seq[seq.length - 1] >= this.timestamp_begin;\n        const penultimate_was_timestamp = seq.length < 2 || seq[seq.length - 2] >= this.timestamp_begin;\n\n        if (last_was_timestamp) {\n            if (penultimate_was_timestamp) { // has to be non-timestamp\n                logitsData.subarray(this.timestamp_begin).fill(-Infinity);\n            } else { // cannot be normal text tokens\n                logitsData.subarray(0, this.eos_token_id).fill(-Infinity);\n            }\n        }\n\n        // apply the `max_initial_timestamp` option\n        if (input_ids.length === this.begin_index && this.max_initial_timestamp_index !== null) {\n            const last_allowed = this.timestamp_begin + this.max_initial_timestamp_index;\n            logitsData.subarray(last_allowed + 1).fill(-Infinity);\n        }\n\n        // if sum of probability over timestamps is above any other token, sample timestamp\n        const logprobs = (0,_maths_js__WEBPACK_IMPORTED_MODULE_2__.log_softmax)(logitsData);\n        const timestamp_logprob = Math.log(logprobs.subarray(this.timestamp_begin).map(Math.exp).reduce((a, b) => a + b));\n        const max_text_token_logprob = (0,_maths_js__WEBPACK_IMPORTED_MODULE_2__.max)(logprobs.subarray(0, this.timestamp_begin))[0];\n\n        if (timestamp_logprob > max_text_token_logprob) {\n            logitsData.subarray(0, this.timestamp_begin).fill(-Infinity);\n        }\n\n        return logits;\n    }\n}\n\n/**\n * A logits processor that disallows ngrams of a certain size to be repeated.\n * \n * @extends LogitsProcessor\n */\nclass NoRepeatNGramLogitsProcessor extends LogitsProcessor {\n    /**\n     * Create a NoRepeatNGramLogitsProcessor.\n     * @param {number} no_repeat_ngram_size The no-repeat-ngram size. All ngrams of this size can only occur once.\n     */\n    constructor(no_repeat_ngram_size) {\n        super();\n        this.no_repeat_ngram_size = no_repeat_ngram_size;\n    }\n\n    /**\n     * Generate n-grams from a sequence of token ids.\n     * @param {number[]} prevInputIds List of previous input ids\n     * @returns {Map<string, number[]>} Map of generated n-grams\n     */\n    getNgrams(prevInputIds) {\n        const curLen = prevInputIds.length;\n\n        /**@type {number[][]} */\n        const ngrams = [];\n        for (let j = 0; j < curLen + 1 - this.no_repeat_ngram_size; ++j) {\n            const ngram = [];\n            for (let k = 0; k < this.no_repeat_ngram_size; ++k) {\n                ngram.push(prevInputIds[j + k]);\n            }\n            ngrams.push(ngram);\n        }\n\n        /** @type {Map<string, number[]>} */\n        const generatedNgram = new Map();\n        for (const ngram of ngrams) {\n            const prevNgram = ngram.slice(0, ngram.length - 1);\n            const prevNgramKey = JSON.stringify(prevNgram);\n            const prevNgramValue = generatedNgram.get(prevNgramKey) ?? [];\n            prevNgramValue.push(ngram[ngram.length - 1]);\n            generatedNgram.set(prevNgramKey, prevNgramValue);\n        }\n        return generatedNgram;\n    }\n\n    /**\n     * Generate n-grams from a sequence of token ids.\n     * @param {Map<string, number[]>} bannedNgrams Map of banned n-grams\n     * @param {number[]} prevInputIds List of previous input ids\n     * @returns {number[]} Map of generated n-grams\n     */\n    getGeneratedNgrams(bannedNgrams, prevInputIds) {\n        const ngramIdx = prevInputIds.slice(prevInputIds.length + 1 - this.no_repeat_ngram_size, prevInputIds.length);\n        const banned = bannedNgrams.get(JSON.stringify(ngramIdx)) ?? [];\n        return banned;\n    }\n\n    /**\n     * Calculate banned n-gram tokens\n     * @param {number[]} prevInputIds List of previous input ids\n     * @returns {number[]} Map of generated n-grams\n     */\n    calcBannedNgramTokens(prevInputIds) {\n        const bannedTokens = [];\n        if (prevInputIds.length + 1 < this.no_repeat_ngram_size) {\n            // return no banned tokens if we haven't generated no_repeat_ngram_size tokens yet\n            return bannedTokens;\n\n        } else {\n            const generatedNgrams = this.getNgrams(prevInputIds);\n            const bannedTokens = this.getGeneratedNgrams(generatedNgrams, prevInputIds);\n            return bannedTokens;\n        }\n    }\n\n    /**\n     * Apply the no-repeat-ngram processor to the logits.\n     * @param {Array} input_ids The input IDs.\n     * @param {Object} logits The logits.\n     * @returns {Object} The logits with no-repeat-ngram processing.\n     */\n    _call(input_ids, logits) {\n        const bannedTokens = this.calcBannedNgramTokens(input_ids);\n\n        for (const token of bannedTokens) {\n            logits.data[token] = -Infinity;\n        }\n        return logits;\n    }\n}\n\n/**\n * A logits processor that penalises repeated output tokens.\n * \n * @extends LogitsProcessor\n */\nclass RepetitionPenaltyLogitsProcessor extends LogitsProcessor {\n    /**\n     * Create a RepetitionPenaltyLogitsProcessor.\n     * @param {number} penalty The penalty to apply for repeated tokens.\n     */\n    constructor(penalty) {\n        super();\n        this.penalty = penalty;\n    }\n\n    /**\n     * Apply the repetition penalty to the logits.\n     * @param {Array} input_ids The input IDs.\n     * @param {Object} logits The logits.\n     * @returns {Object} The logits with repetition penalty processing.\n     */\n    _call(input_ids, logits) {\n        // Modify the logits corresponding to each element in `input_ids`.\n        // As a consequence, the logits corresponding to tokens that appear\n        // many times in the output will be penalised more.\n        for (const input_id of input_ids) {\n            if (logits.data[input_id] < 0) {\n                logits.data[input_id] *= this.penalty;\n            } else {\n                logits.data[input_id] /= this.penalty;\n            }\n        }\n        return logits\n    }\n}\n\n/**\n * A logits processor that enforces a minimum number of tokens.\n * \n * @extends LogitsProcessor\n */\nclass MinLengthLogitsProcessor extends LogitsProcessor {\n    /**\n     * Create a MinLengthLogitsProcessor.\n     * @param {number} min_length The minimum length below which the score of `eos_token_id` is set to negative infinity.\n     * @param {number|number[]} eos_token_id The ID/IDs of the end-of-sequence token.\n     */\n    constructor(min_length, eos_token_id) {\n        super();\n        this.min_length = min_length;\n        this.eos_token_id = Array.isArray(eos_token_id) ? eos_token_id : [eos_token_id];\n    }\n\n    /**\n     * Apply logit processor.\n     * @param {Array} input_ids The input IDs.\n     * @param {Object} logits The logits.\n     * @returns {Object} The processed logits.\n     */\n    _call(input_ids, logits) {\n        if (input_ids.length < this.min_length) {\n            for (const eos_token of this.eos_token_id) {\n                logits.data[eos_token] = -Infinity;\n            }\n        }\n\n        return logits\n    }\n}\n\n/**\n * A logits processor that enforces a minimum number of new tokens.\n * \n * @extends LogitsProcessor\n */\nclass MinNewTokensLengthLogitsProcessor extends LogitsProcessor {\n    /**\n     * Create a MinNewTokensLengthLogitsProcessor.\n     * @param {number} prompt_length_to_skip The input tokens length.\n     * @param {number} min_new_tokens The minimum *new* tokens length below which the score of `eos_token_id` is set to negative infinity.\n     * @param {number|number[]} eos_token_id The ID/IDs of the end-of-sequence token.\n     */\n    constructor(prompt_length_to_skip, min_new_tokens, eos_token_id) {\n        super();\n        this.prompt_length_to_skip = prompt_length_to_skip;\n        this.min_new_tokens = min_new_tokens;\n        this.eos_token_id = Array.isArray(eos_token_id) ? eos_token_id : [eos_token_id];\n    }\n\n    /**\n     * Apply logit processor.\n     * @param {Array} input_ids The input IDs.\n     * @param {Object} logits The logits.\n     * @returns {Object} The processed logits.\n     */\n    _call(input_ids, logits) {\n        const new_tokens_length = input_ids.length - this.prompt_length_to_skip;\n        if (new_tokens_length < this.min_new_tokens) {\n            for (const eos_token of this.eos_token_id) {\n                logits.data[eos_token] = -Infinity;\n            }\n        }\n\n        return logits\n    }\n}\n\nclass NoBadWordsLogitsProcessor extends LogitsProcessor {\n    /**\n     * Create a `NoBadWordsLogitsProcessor`.\n     * @param {number[][]} bad_words_ids List of list of token ids that are not allowed to be generated.\n     * @param {number|number[]} eos_token_id The id of the *end-of-sequence* token. Optionally, use a list to set multiple *end-of-sequence* tokens.\n     */\n    constructor(bad_words_ids, eos_token_id) {\n        super();\n        this.bad_words_ids = bad_words_ids;\n        this.eos_token_id = Array.isArray(eos_token_id) ? eos_token_id : [eos_token_id];\n    }\n\n    /**\n     * Apply logit processor.\n     * @param {Array} input_ids The input IDs.\n     * @param {Object} logits The logits.\n     * @returns {Object} The processed logits.\n     */\n    _call(input_ids, logits) {\n\n        for (const bad_word_ids of this.bad_words_ids) {\n            // Whether to modify the logits of the last token in the bad word id sequence\n            let mark = true;\n\n            // For each bad word in the list, if the current sequence of input ids ends with this sequence (excluding the last),\n            // then we set the logits of the last bad word id to -Infinity.\n            for (let i = 1; i <= bad_word_ids.length - 1 && bad_word_ids.length < input_ids.length; ++i) {\n\n                if (bad_word_ids.at(-i - 1) !== input_ids.at(-i)) {\n                    // We have found a mismatch\n                    mark = false;\n                    break;\n                }\n            }\n            if (mark) {\n                logits.data[bad_word_ids.at(-1)] = -Infinity;\n            }\n        }\n\n        return logits\n    }\n}\n\n/**\n * @typedef {Object} GenerationConfigType The default configuration parameters.\n * @property {number} [max_length=20] The maximum length the generated tokens can have. Corresponds to the length of the input prompt + `max_new_tokens`. Its effect is overridden by `max_new_tokens`, if also set.\n * @property {number} [max_new_tokens=null] The maximum numbers of tokens to generate, ignoring the number of tokens in the prompt.\n * @property {number} [min_length=0] The minimum length of the sequence to be generated. Corresponds to the length of the input prompt + `min_new_tokens`. Its effect is overridden by `min_new_tokens`, if also set.\n * @property {number} [min_new_tokens=null] The minimum numbers of tokens to generate, ignoring the number of tokens in the prompt.\n * @property {boolean|\"never\"} [early_stopping=false] Controls the stopping condition for beam-based methods, like beam-search. It accepts the following values:\n * - `true`, where the generation stops as soon as there are `num_beams` complete candidates;\n * - `false`, where an heuristic is applied and the generation stops when is it very unlikely to find better candidates;\n * - `\"never\"`, where the beam search procedure only stops when there cannot be better candidates (canonical beam search algorithm).\n * @property {number} [max_time=null] The maximum amount of time you allow the computation to run for in seconds. Generation will still finish the current pass after allocated time has been passed.\n *\n * @property {boolean} [do_sample=false] Whether or not to use sampling; use greedy decoding otherwise.\n * @property {number} [num_beams=1] Number of beams for beam search. 1 means no beam search.\n * @property {number} [num_beam_groups=1] Number of groups to divide `num_beams` into in order to ensure diversity among different groups of beams. See [this paper](https://arxiv.org/pdf/1610.02424.pdf) for more details.\n * @property {number} [penalty_alpha=null] The values balance the model confidence and the degeneration penalty in contrastive search decoding.\n * @property {boolean} [use_cache=true] Whether or not the model should use the past last key/values attentions (if applicable to the model) to speed up decoding.\n *\n * @property {number} [temperature=1.0] The value used to modulate the next token probabilities.\n * @property {number} [top_k=50] The number of highest probability vocabulary tokens to keep for top-k-filtering.\n * @property {number} [top_p=1.0] If set to float < 1, only the smallest set of most probable tokens with probabilities that add up to `top_p` or higher are kept for generation.\n * @property {number} [typical_p=1.0] Local typicality measures how similar the conditional probability of predicting a target token next is to the expected conditional probability of predicting a random token next, given the partial text already generated. If set to float < 1, the smallest set of the most locally typical tokens with probabilities that add up to `typical_p` or higher are kept for generation. See [this paper](https://arxiv.org/pdf/2202.00666.pdf) for more details.\n * @property {number} [epsilon_cutoff=0.0] If set to float strictly between 0 and 1, only tokens with a conditional probability greater than `epsilon_cutoff` will be sampled. In the paper, suggested values range from 3e-4 to 9e-4, depending on the size of the model. See [Truncation Sampling as Language Model Desmoothing](https://arxiv.org/abs/2210.15191) for more details.\n * @property {number} [eta_cutoff=0.0] Eta sampling is a hybrid of locally typical sampling and epsilon sampling. If set to float strictly between 0 and 1, a token is only considered if it is greater than either `eta_cutoff` or `sqrt(eta_cutoff) * exp(-entropy(softmax(next_token_logits)))`. The latter term is intuitively the expected next token probability, scaled by `sqrt(eta_cutoff)`. In the paper, suggested values range from 3e-4 to 2e-3, depending on the size of the model. See [Truncation Sampling as Language Model Desmoothing](https://arxiv.org/abs/2210.15191) for more details.\n * @property {number} [diversity_penalty=0.0] This value is subtracted from a beam's score if it generates a token same as any beam from other group at a particular time. Note that `diversity_penalty` is only effective if `group beam search` is enabled.\n * @property {number} [repetition_penalty=1.0] The parameter for repetition penalty. 1.0 means no penalty. See [this paper](https://arxiv.org/pdf/1909.05858.pdf) for more details.\n * @property {number} [encoder_repetition_penalty=1.0] The paramater for encoder_repetition_penalty. An exponential penalty on sequences that are not in the original input. 1.0 means no penalty.\n * @property {number} [length_penalty=1.0] Exponential penalty to the length that is used with beam-based generation. It is applied as an exponent to the sequence length, which in turn is used to divide the score of the sequence. Since the score is the log likelihood of the sequence (i.e. negative), `length_penalty` > 0.0 promotes longer sequences, while `length_penalty` < 0.0 encourages shorter sequences.\n * @property {number} [no_repeat_ngram_size=0] If set to int > 0, all ngrams of that size can only occur once.\n * @property {number[][]} [bad_words_ids=null] List of token ids that are not allowed to be generated. In order to get the token ids of the words that should not appear in the generated text, use `(await tokenizer(bad_words, {add_prefix_space: true, add_special_tokens: false})).input_ids`.\n * @property {number[][]|number[][][]} [force_words_ids=null] List of token ids that must be generated. If given a `number[][]`, this is treated as a simple list of words that must be included, the opposite to `bad_words_ids`. If given `number[][][]`, this triggers a [disjunctive constraint](https://github.com/huggingface/transformers/issues/14081), where one can allow different forms of each word.\n * @property {boolean} [renormalize_logits=false] Whether to renormalize the logits after applying all the logits processors or warpers (including the custom ones). It's highly recommended to set this flag to `true` as the search algorithms suppose the score logits are normalized but some logit processors or warpers break the normalization.\n * @property {Object[]} [constraints=null] Custom constraints that can be added to the generation to ensure that the output will contain the use of certain tokens as defined by `Constraint` objects, in the most sensible way possible.\n * \n * @property {number} [forced_bos_token_id=null] The id of the token to force as the first generated token after the `decoder_start_token_id`. Useful for multilingual models like mBART where the first generated token needs to be the target language token.\n * @property {number|number[]} [forced_eos_token_id=null] The id of the token to force as the last generated token when `max_length` is reached. Optionally, use a list to set multiple *end-of-sequence* tokens.\n * @property {boolean} [remove_invalid_values=false] Whether to remove possible *nan* and *inf* outputs of the model to prevent the generation method to crash. Note that using `remove_invalid_values` can slow down generation.\n * @property {number[]} [exponential_decay_length_penalty=null] This Tuple adds an exponentially increasing length penalty, after a certain amount of tokens have been generated. The tuple shall consist of: `(start_index, decay_factor)` where `start_index` indicates where penalty starts and `decay_factor` represents the factor of exponential decay.\n * @property {number[]} [suppress_tokens=null] A list of tokens that will be suppressed at generation. The `SupressTokens` logit processor will set their log probs to `-inf` so that they are not sampled.\n * @property {number[]} [begin_suppress_tokens=null] A list of tokens that will be suppressed at the beginning of the generation. The `SupressBeginTokens` logit processor will set their log probs to `-inf` so that they are not sampled.\n * @property {number[][]} [forced_decoder_ids=null] A list of pairs of integers which indicates a mapping from generation indices to token indices that will be forced before sampling. For example, `[[1, 123]]` means the second generated token will always be a token of index 123.\n * \n * @property {number} [num_return_sequences=1] The number of independently computed returned sequences for each element in the batch.\n * @property {boolean} [output_attentions=false] Whether or not to return the attentions tensors of all attention layers. See `attentions` under returned tensors for more details.\n * @property {boolean} [output_hidden_states=false] Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors for more details.\n * @property {boolean} [output_scores=false] Whether or not to return the prediction scores. See `scores` under returned tensors for more details.\n * @property {boolean} [return_dict_in_generate=false] Whether or not to return a `ModelOutput` instead of a plain tuple.\n * \n * @property {number} [pad_token_id=null] The id of the *padding* token.\n * @property {number} [bos_token_id=null] The id of the *beginning-of-sequence* token.\n * @property {number|number[]} [eos_token_id=null] The id of the *end-of-sequence* token. Optionally, use a list to set multiple *end-of-sequence* tokens.\n * \n * @property {number} [encoder_no_repeat_ngram_size=0] If set to int > 0, all ngrams of that size that occur in the `encoder_input_ids` cannot occur in the `decoder_input_ids`.\n * @property {number} [decoder_start_token_id=null] If an encoder-decoder model starts decoding with a different token than *bos*, the id of that token.\n * \n * @property {Object} [generation_kwargs={}] Additional generation kwargs will be forwarded to the `generate` function of the model. Kwargs that are not present in `generate`'s signature will be used in the model forward pass.\n */\n\n/**\n * Class that holds a configuration for a generation task.\n * @type {new (kwargs?: GenerationConfigType) => GenerationConfigType}\n */\nconst GenerationConfig = /** @type {any} */ (class {\n\n    /**\n     * Create a new GenerationConfig object.\n     * @param {GenerationConfigType} kwargs \n     */\n    constructor(kwargs = {}) {\n        // Parameters that control the length of the output\n        this.max_length = kwargs.max_length ?? 20;\n        this.max_new_tokens = kwargs.max_new_tokens ?? null;\n        this.min_length = kwargs.min_length ?? 0;\n        this.min_new_tokens = kwargs.min_new_tokens ?? null;\n        this.early_stopping = kwargs.early_stopping ?? false;\n        this.max_time = kwargs.max_time ?? null;\n\n        // Parameters that control the generation strategy used\n        this.do_sample = kwargs.do_sample ?? false;\n        this.num_beams = kwargs.num_beams ?? 1;\n        this.num_beam_groups = kwargs.num_beam_groups ?? 1;\n        this.penalty_alpha = kwargs.penalty_alpha ?? null;\n        this.use_cache = kwargs.use_cache ?? true;\n\n        // Parameters for manipulation of the model output logits\n        this.temperature = kwargs.temperature ?? 1.0;\n        this.top_k = kwargs.top_k ?? 50;\n        this.top_p = kwargs.top_p ?? 1.0;\n        this.typical_p = kwargs.typical_p ?? 1.0;\n        this.epsilon_cutoff = kwargs.epsilon_cutoff ?? 0.0;\n        this.eta_cutoff = kwargs.eta_cutoff ?? 0.0;\n        this.diversity_penalty = kwargs.diversity_penalty ?? 0.0;\n        this.repetition_penalty = kwargs.repetition_penalty ?? 1.0;\n        this.encoder_repetition_penalty = kwargs.encoder_repetition_penalty ?? 1.0;\n        this.length_penalty = kwargs.length_penalty ?? 1.0;\n        this.no_repeat_ngram_size = kwargs.no_repeat_ngram_size ?? 0;\n        this.bad_words_ids = kwargs.bad_words_ids ?? null;\n        this.force_words_ids = kwargs.force_words_ids ?? null;\n        this.renormalize_logits = kwargs.renormalize_logits ?? false;\n        this.constraints = kwargs.constraints ?? null;\n        this.forced_bos_token_id = kwargs.forced_bos_token_id ?? null;\n        this.forced_eos_token_id = kwargs.forced_eos_token_id ?? null;\n        this.remove_invalid_values = kwargs.remove_invalid_values ?? false;\n        this.exponential_decay_length_penalty = kwargs.exponential_decay_length_penalty ?? null;\n        this.suppress_tokens = kwargs.suppress_tokens ?? null;\n        this.begin_suppress_tokens = kwargs.begin_suppress_tokens ?? null;\n        this.forced_decoder_ids = kwargs.forced_decoder_ids ?? null;\n\n        // Parameters that define the output variables of `generate`\n        this.num_return_sequences = kwargs.num_return_sequences ?? 1;\n        this.output_attentions = kwargs.output_attentions ?? false;\n        this.output_hidden_states = kwargs.output_hidden_states ?? false;\n        this.output_scores = kwargs.output_scores ?? false;\n        this.return_dict_in_generate = kwargs.return_dict_in_generate ?? false;\n\n        // Special tokens that can be used at generation time\n        this.pad_token_id = kwargs.pad_token_id ?? null;\n        this.bos_token_id = kwargs.bos_token_id ?? null;\n        this.eos_token_id = kwargs.eos_token_id ?? null;\n\n        // Generation parameters exclusive to encoder-decoder models\n        this.encoder_no_repeat_ngram_size = kwargs.encoder_no_repeat_ngram_size ?? 0;\n        this.decoder_start_token_id = kwargs.decoder_start_token_id ?? null;\n\n        // Wild card\n        this.generation_kwargs = kwargs.generation_kwargs ?? {};\n    }\n});\n\n/**\n * Sampler is a base class for all sampling methods used for text generation.\n */\nclass Sampler extends _core_js__WEBPACK_IMPORTED_MODULE_1__.Callable {\n    /**\n     * Creates a new Sampler object with the specified generation config.\n     * @param {GenerationConfigType} generation_config The generation config.\n     */\n    constructor(generation_config) {\n        super();\n        this.generation_config = generation_config;\n    }\n\n    /**\n     * Executes the sampler, using the specified logits.\n     * @param {Tensor} logits\n     * @param {number} index\n     * @returns {void}\n     */\n    _call(logits, index = -1) {\n        // Sample from logits, of dims [batch, sequence_length, vocab_size].\n        // If index is specified, sample from [batch, index, vocab_size].\n        return this.sample(logits, index);\n    }\n\n    /**\n     * Abstract method for sampling the logits.\n     * @param {Tensor} logits\n     * @param {number} index\n     * @throws {Error}\n     */\n    sample(logits, index) {\n        throw Error(\"sample should be implemented in subclasses.\")\n    }\n\n    /**\n     * Returns the specified logits as an array, with temperature applied.\n     * @param {Tensor} logits\n     * @param {number} index\n     * @returns {Float32Array}\n     */\n    getLogits(logits, index) {\n        let vocabSize = logits.dims.at(-1);\n\n        let logs = /** @type {Float32Array} */(logits.data);\n\n        if (index === -1) {\n            logs = logs.slice(-vocabSize);\n        } else {\n            let startIndex = index * vocabSize;\n            logs = logs.slice(startIndex, startIndex + vocabSize);\n        }\n\n        // add temperature\n        if (this.generation_config.temperature > 0) {\n            logs = logs.map(x => x / this.generation_config.temperature)\n        }\n        return logs;\n    }\n\n    /**\n     * Selects an item randomly based on the specified probabilities.\n     * @param {Array} probabilities An array of probabilities to use for selection.\n     * @returns {number} The index of the selected item.\n     */\n    randomSelect(probabilities) {\n        // Return index of chosen item\n        let sumProbabilities = probabilities.reduce((acc, curr) => acc + curr, 0);\n\n        let r = Math.random() * sumProbabilities;\n        for (let i = 0; i < probabilities.length; ++i) {\n            r -= probabilities[i];\n            if (r <= 0) {\n                return i;\n            }\n        }\n        return 0; // return first (most probable) as a fallback\n    }\n\n    /**\n     * Returns a Sampler object based on the specified options.\n     * @param {GenerationConfigType} generation_config An object containing options for the sampler.\n     * @returns {Sampler} A Sampler object.\n     */\n    static getSampler(generation_config) {\n        // - *greedy decoding*: `num_beams=1` and `do_sample=False`\n        // - *contrastive search*: `penalty_alpha>0` and `top_k>1`\n        // - *multinomial sampling*: `num_beams=1` and `do_sample=True`\n        // - *beam-search decoding*: `num_beams>1` and `do_sample=False`\n        // - *beam-search multinomial sampling*: `num_beams>1` and `do_sample=True`\n        // - *diverse beam-search decoding*: `num_beams>1` and `num_beam_groups>1`\n        // - *constrained beam-search decoding*: `constraints!=None` or `force_words_ids!=None`\n\n        // NOTE: beam search is implemented directly into the generation function\n        if (generation_config.do_sample) {\n            return new MultinomialSampler(generation_config);\n\n        } else if (generation_config.num_beams > 1) {\n            return new BeamSearchSampler(generation_config);\n\n        } else {\n            if (generation_config.num_return_sequences > 1) {\n                throw Error(`num_return_sequences has to be 1 when doing greedy search, but is ${generation_config.num_return_sequences}.`)\n            }\n            return new GreedySampler(generation_config);\n        }\n    }\n}\n\n/**\n * Class representing a Greedy Sampler.\n * @extends Sampler\n */\nclass GreedySampler extends Sampler {\n    /**\n     * Sample the maximum probability of a given logits tensor.\n     * @param {Tensor} logits\n     * @param {number} [index=-1]\n     * @returns {Array} An array with a single tuple, containing the index of the maximum value and a meaningless score (since this is a greedy search).\n     */\n    sample(logits, index = -1) {\n        // NOTE: no need to do log_softmax here since we only take the maximum\n        let logs = this.getLogits(logits, index);\n        let argmax = (0,_maths_js__WEBPACK_IMPORTED_MODULE_2__.max)(logs)[1];\n\n        // Note: score is meaningless in this context, since we are performing\n        // greedy search (p = 1 => log(p) = 0)\n        return [\n            [argmax, 0]\n        ];\n    }\n}\n\n/**\n * Class representing a MultinomialSampler.\n * @extends Sampler\n */\nclass MultinomialSampler extends Sampler {\n\n    /**\n     * Sample from the logits.\n     * @param {Tensor} logits\n     * @param {number} index\n     * @returns {Array}\n     */\n    sample(logits, index = -1) {\n        let k = logits.dims.at(-1); // defaults to vocab size\n        if (this.generation_config.top_k > 0) {\n            k = Math.min(this.generation_config.top_k, k);\n        }\n\n        // Get logits of nth token\n        const logs = this.getLogits(logits, index);\n\n        // Get top k tokens\n        const topLogits = (0,_maths_js__WEBPACK_IMPORTED_MODULE_2__.getTopItems)(logs, k);\n\n        // Compute softmax over logits\n        const probabilities = (0,_maths_js__WEBPACK_IMPORTED_MODULE_2__.softmax)(topLogits.map(x => x[1]));\n\n        return Array.from({ length: this.generation_config.num_beams }, () => {\n            const sampledIndex = this.randomSelect(probabilities);\n            return [\n                topLogits[sampledIndex][0], // token id\n                Math.log(probabilities[sampledIndex]), // score\n            ];\n        });\n    }\n}\n\n\n/**\n * Class representing a BeamSearchSampler.\n * @extends Sampler\n */\nclass BeamSearchSampler extends Sampler {\n\n    /**\n     * Sample from the logits.\n     * @param {Tensor} logits\n     * @param {number} index\n     * @returns {Array}\n     */\n    sample(logits, index = -1) {\n        let k = logits.dims.at(-1); // defaults to vocab size\n        if (this.generation_config.top_k > 0) {\n            k = Math.min(this.generation_config.top_k, k);\n        }\n\n        // Get logits of nth token\n        const logs = this.getLogits(logits, index);\n\n        // Get top k tokens\n        const topLogits = (0,_maths_js__WEBPACK_IMPORTED_MODULE_2__.getTopItems)(logs, k);\n\n        // Compute softmax over logits\n        const probabilities = (0,_maths_js__WEBPACK_IMPORTED_MODULE_2__.softmax)(topLogits.map(x => x[1]));\n\n        return Array.from({ length: this.generation_config.num_beams }, (_, i) => {\n            return [\n                topLogits[i][0], // token id\n                Math.log(probabilities[i]), // score\n            ];\n        });\n    }\n}\n\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@xenova/transformers/src/utils/generation.js?");

/***/ }),

/***/ "./node_modules/@xenova/transformers/src/utils/hub.js":
/*!************************************************************!*\
  !*** ./node_modules/@xenova/transformers/src/utils/hub.js ***!
  \************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getFile: () => (/* binding */ getFile),\n/* harmony export */   getModelFile: () => (/* binding */ getModelFile),\n/* harmony export */   getModelJSON: () => (/* binding */ getModelJSON)\n/* harmony export */ });\n/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! fs */ \"?0a40\");\n/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! path */ \"?61c2\");\n/* harmony import */ var stream_web__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! stream/web */ \"?66bb\");\n/* harmony import */ var _env_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../env.js */ \"./node_modules/@xenova/transformers/src/env.js\");\n/* harmony import */ var _core_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./core.js */ \"./node_modules/@xenova/transformers/src/utils/core.js\");\n\n/**\n * @file Utility functions to interact with the Hugging Face Hub (https://huggingface.co/models)\n * \n * @module utils/hub\n */\n\n\n\n\n\n\n\n\nif (!globalThis.ReadableStream) {\n    // @ts-ignore\n    globalThis.ReadableStream = stream_web__WEBPACK_IMPORTED_MODULE_2__.ReadableStream; // ReadableStream is not a global with Node 16\n}\n\n/**\n * @typedef {Object} PretrainedOptions Options for loading a pretrained model.     \n * @property {boolean?} [quantized=true] Whether to load the 8-bit quantized version of the model (only applicable when loading model files).\n * @property {function} [progress_callback=null] If specified, this function will be called during model construction, to provide the user with progress updates.\n * @property {Object} [config=null] Configuration for the model to use instead of an automatically loaded configuration. Configuration can be automatically loaded when:\n * - The model is a model provided by the library (loaded with the *model id* string of a pretrained model).\n * - The model is loaded by supplying a local directory as `pretrained_model_name_or_path` and a configuration JSON file named *config.json* is found in the directory.\n * @property {string} [cache_dir=null] Path to a directory in which a downloaded pretrained model configuration should be cached if the standard cache should not be used.\n * @property {boolean} [local_files_only=false] Whether or not to only look at local files (e.g., not try downloading the model).\n * @property {string} [revision='main'] The specific model version to use. It can be a branch name, a tag name, or a commit id,\n * since we use a git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any identifier allowed by git.\n * NOTE: This setting is ignored for local requests.\n * @property {string} [model_file_name=null] If specified, load the model with this name (excluding the .onnx suffix). Currently only valid for encoder- or decoder-only models.\n */\n\nclass FileResponse {\n    /**\n     * Mapping from file extensions to MIME types.\n     */\n    _CONTENT_TYPE_MAP = {\n        'txt': 'text/plain',\n        'html': 'text/html',\n        'css': 'text/css',\n        'js': 'text/javascript',\n        'json': 'application/json',\n        'png': 'image/png',\n        'jpg': 'image/jpeg',\n        'jpeg': 'image/jpeg',\n        'gif': 'image/gif',\n    }\n    /**\n     * Creates a new `FileResponse` object.\n     * @param {string|URL} filePath\n     */\n    constructor(filePath) {\n        this.filePath = filePath;\n        this.headers = new Headers();\n\n        this.exists = fs__WEBPACK_IMPORTED_MODULE_0__.existsSync(filePath);\n        if (this.exists) {\n            this.status = 200;\n            this.statusText = 'OK';\n\n            let stats = fs__WEBPACK_IMPORTED_MODULE_0__.statSync(filePath);\n            this.headers.set('content-length', stats.size.toString());\n\n            this.updateContentType();\n\n            let self = this;\n            this.body = new ReadableStream({\n                start(controller) {\n                    self.arrayBuffer().then(buffer => {\n                        controller.enqueue(new Uint8Array(buffer));\n                        controller.close();\n                    })\n                }\n            });\n        } else {\n            this.status = 404;\n            this.statusText = 'Not Found';\n            this.body = null;\n        }\n    }\n\n    /**\n     * Updates the 'content-type' header property of the response based on the extension of\n     * the file specified by the filePath property of the current object.\n     * @returns {void}\n     */\n    updateContentType() {\n        // Set content-type header based on file extension\n        const extension = this.filePath.toString().split('.').pop().toLowerCase();\n        this.headers.set('content-type', this._CONTENT_TYPE_MAP[extension] ?? 'application/octet-stream');\n    }\n\n    /**\n     * Clone the current FileResponse object.\n     * @returns {FileResponse} A new FileResponse object with the same properties as the current object.\n     */\n    clone() {\n        let response = new FileResponse(this.filePath);\n        response.exists = this.exists;\n        response.status = this.status;\n        response.statusText = this.statusText;\n        response.headers = new Headers(this.headers);\n        return response;\n    }\n\n    /**\n     * Reads the contents of the file specified by the filePath property and returns a Promise that\n     * resolves with an ArrayBuffer containing the file's contents.\n     * @returns {Promise<ArrayBuffer>} A Promise that resolves with an ArrayBuffer containing the file's contents.\n     * @throws {Error} If the file cannot be read.\n     */\n    async arrayBuffer() {\n        const data = await fs__WEBPACK_IMPORTED_MODULE_0__.promises.readFile(this.filePath);\n        return data.buffer;\n    }\n\n    /**\n     * Reads the contents of the file specified by the filePath property and returns a Promise that\n     * resolves with a Blob containing the file's contents.\n     * @returns {Promise<Blob>} A Promise that resolves with a Blob containing the file's contents.\n     * @throws {Error} If the file cannot be read.\n     */\n    async blob() {\n        const data = await fs__WEBPACK_IMPORTED_MODULE_0__.promises.readFile(this.filePath);\n        return new Blob([data], { type: this.headers.get('content-type') });\n    }\n\n    /**\n     * Reads the contents of the file specified by the filePath property and returns a Promise that\n     * resolves with a string containing the file's contents.\n     * @returns {Promise<string>} A Promise that resolves with a string containing the file's contents.\n     * @throws {Error} If the file cannot be read.\n     */\n    async text() {\n        const data = await fs__WEBPACK_IMPORTED_MODULE_0__.promises.readFile(this.filePath, 'utf8');\n        return data;\n    }\n\n    /**\n     * Reads the contents of the file specified by the filePath property and returns a Promise that\n     * resolves with a parsed JavaScript object containing the file's contents.\n     * \n     * @returns {Promise<Object>} A Promise that resolves with a parsed JavaScript object containing the file's contents.\n     * @throws {Error} If the file cannot be read.\n     */\n    async json() {\n        return JSON.parse(await this.text());\n    }\n}\n\n/**\n * Determines whether the given string is a valid HTTP or HTTPS URL.\n * @param {string|URL} string The string to test for validity as an HTTP or HTTPS URL.\n * @param {string[]} [validHosts=null] A list of valid hostnames. If specified, the URL's hostname must be in this list.\n * @returns {boolean} True if the string is a valid HTTP or HTTPS URL, false otherwise.\n */\nfunction isValidHttpUrl(string, validHosts = null) {\n    // https://stackoverflow.com/a/43467144\n    let url;\n    try {\n        url = new URL(string);\n    } catch (_) {\n        return false;\n    }\n    if (validHosts && !validHosts.includes(url.hostname)) {\n        return false;\n    }\n    return url.protocol === \"http:\" || url.protocol === \"https:\";\n}\n\n/**\n * Helper function to get a file, using either the Fetch API or FileSystem API.\n *\n * @param {URL|string} urlOrPath The URL/path of the file to get.\n * @returns {Promise<FileResponse|Response>} A promise that resolves to a FileResponse object (if the file is retrieved using the FileSystem API), or a Response object (if the file is retrieved using the Fetch API).\n */\nasync function getFile(urlOrPath) {\n\n    if (_env_js__WEBPACK_IMPORTED_MODULE_3__.env.useFS && !isValidHttpUrl(urlOrPath)) {\n        return new FileResponse(urlOrPath);\n\n    } else if (typeof process !== 'undefined' && process?.release?.name === 'node') {\n        const IS_CI = !!process.env?.TESTING_REMOTELY;\n        const version = _env_js__WEBPACK_IMPORTED_MODULE_3__.env.version;\n\n        const headers = new Headers();\n        headers.set('User-Agent', `transformers.js/${version}; is_ci/${IS_CI};`);\n\n        // Check whether we are making a request to the Hugging Face Hub.\n        const isHFURL = isValidHttpUrl(urlOrPath, ['huggingface.co', 'hf.co']);\n        if (isHFURL) {\n            // If an access token is present in the environment variables,\n            // we add it to the request headers.\n            // NOTE: We keep `HF_ACCESS_TOKEN` for backwards compatibility (as a fallback).\n            const token = process.env?.HF_TOKEN ?? process.env?.HF_ACCESS_TOKEN;\n            if (token) {\n                headers.set('Authorization', `Bearer ${token}`);\n            }\n        }\n        return fetch(urlOrPath, { headers });\n    } else {\n        // Running in a browser-environment, so we use default headers\n        // NOTE: We do not allow passing authorization headers in the browser,\n        // since this would require exposing the token to the client.\n        return fetch(urlOrPath);\n    }\n}\n\nconst ERROR_MAPPING = {\n    // 4xx errors (https://developer.mozilla.org/en-US/docs/Web/HTTP/Status#client_error_responses)\n    400: 'Bad request error occurred while trying to load file',\n    401: 'Unauthorized access to file',\n    403: 'Forbidden access to file',\n    404: 'Could not locate file',\n    408: 'Request timeout error occurred while trying to load file',\n\n    // 5xx errors (https://developer.mozilla.org/en-US/docs/Web/HTTP/Status#server_error_responses)\n    500: 'Internal server error error occurred while trying to load file',\n    502: 'Bad gateway error occurred while trying to load file',\n    503: 'Service unavailable error occurred while trying to load file',\n    504: 'Gateway timeout error occurred while trying to load file',\n}\n/**\n * Helper method to handle fatal errors that occur while trying to load a file from the Hugging Face Hub.\n * @param {number} status The HTTP status code of the error.\n * @param {string} remoteURL The URL of the file that could not be loaded.\n * @param {boolean} fatal Whether to raise an error if the file could not be loaded.\n * @returns {null} Returns `null` if `fatal = true`.\n * @throws {Error} If `fatal = false`.\n */\nfunction handleError(status, remoteURL, fatal) {\n    if (!fatal) {\n        // File was not loaded correctly, but it is optional.\n        // TODO in future, cache the response?\n        return null;\n    }\n\n    const message = ERROR_MAPPING[status] ?? `Error (${status}) occurred while trying to load file`;\n    throw Error(`${message}: \"${remoteURL}\".`);\n}\n\nclass FileCache {\n    /**\n     * Instantiate a `FileCache` object.\n     * @param {string} path \n     */\n    constructor(path) {\n        this.path = path;\n    }\n\n    /**\n     * Checks whether the given request is in the cache.\n     * @param {string} request \n     * @returns {Promise<FileResponse | undefined>}\n     */\n    async match(request) {\n\n        let filePath = path__WEBPACK_IMPORTED_MODULE_1__.join(this.path, request);\n        let file = new FileResponse(filePath);\n\n        if (file.exists) {\n            return file;\n        } else {\n            return undefined;\n        }\n    }\n\n    /**\n     * Adds the given response to the cache.\n     * @param {string} request \n     * @param {Response|FileResponse} response \n     * @returns {Promise<void>}\n     */\n    async put(request, response) {\n        const buffer = Buffer.from(await response.arrayBuffer());\n\n        let outputPath = path__WEBPACK_IMPORTED_MODULE_1__.join(this.path, request);\n\n        try {\n            await fs__WEBPACK_IMPORTED_MODULE_0__.promises.mkdir(path__WEBPACK_IMPORTED_MODULE_1__.dirname(outputPath), { recursive: true });\n            await fs__WEBPACK_IMPORTED_MODULE_0__.promises.writeFile(outputPath, buffer);\n\n        } catch (err) {\n            console.warn('An error occurred while writing the file to cache:', err)\n        }\n    }\n\n    // TODO add the rest?\n    // addAll(requests: RequestInfo[]): Promise<void>;\n    // delete(request: RequestInfo | URL, options?: CacheQueryOptions): Promise<boolean>;\n    // keys(request?: RequestInfo | URL, options?: CacheQueryOptions): Promise<ReadonlyArray<Request>>;\n    // match(request: RequestInfo | URL, options?: CacheQueryOptions): Promise<Response | undefined>;\n    // matchAll(request?: RequestInfo | URL, options?: CacheQueryOptions): Promise<ReadonlyArray<Response>>;\n}\n\n/**\n * \n * @param {FileCache|Cache} cache The cache to search\n * @param {string[]} names The names of the item to search for\n * @returns {Promise<FileResponse|Response|undefined>} The item from the cache, or undefined if not found.\n */\nasync function tryCache(cache, ...names) {\n    for (let name of names) {\n        try {\n            let result = await cache.match(name);\n            if (result) return result;\n        } catch (e) {\n            continue;\n        }\n    }\n    return undefined;\n}\n\n/**\n * \n * Retrieves a file from either a remote URL using the Fetch API or from the local file system using the FileSystem API.\n * If the filesystem is available and `env.useCache = true`, the file will be downloaded and cached.\n * \n * @param {string} path_or_repo_id This can be either:\n * - a string, the *model id* of a model repo on huggingface.co.\n * - a path to a *directory* potentially containing the file.\n * @param {string} filename The name of the file to locate in `path_or_repo`.\n * @param {boolean} [fatal=true] Whether to throw an error if the file is not found.\n * @param {PretrainedOptions} [options] An object containing optional parameters.\n * \n * @throws Will throw an error if the file is not found and `fatal` is true.\n * @returns {Promise} A Promise that resolves with the file content as a buffer.\n */\nasync function getModelFile(path_or_repo_id, filename, fatal = true, options = {}) {\n\n    if (!_env_js__WEBPACK_IMPORTED_MODULE_3__.env.allowLocalModels) {\n        // User has disabled local models, so we just make sure other settings are correct.\n\n        if (options.local_files_only) {\n            throw Error(\"Invalid configuration detected: local models are disabled (`env.allowLocalModels=false`) but you have requested to only use local models (`local_files_only=true`).\")\n        } else if (!_env_js__WEBPACK_IMPORTED_MODULE_3__.env.allowRemoteModels) {\n            throw Error(\"Invalid configuration detected: both local and remote models are disabled. Fix by setting `env.allowLocalModels` or `env.allowRemoteModels` to `true`.\")\n        }\n    }\n\n    // Initiate file retrieval\n    (0,_core_js__WEBPACK_IMPORTED_MODULE_4__.dispatchCallback)(options.progress_callback, {\n        status: 'initiate',\n        name: path_or_repo_id,\n        file: filename\n    })\n\n    // First, check if the a caching backend is available\n    // If no caching mechanism available, will download the file every time\n    let cache;\n    if (!cache && _env_js__WEBPACK_IMPORTED_MODULE_3__.env.useBrowserCache) {\n        if (typeof caches === 'undefined') {\n            throw Error('Browser cache is not available in this environment.')\n        }\n        try {\n            // In some cases, the browser cache may be visible, but not accessible due to security restrictions.\n            // For example, when running an application in an iframe, if a user attempts to load the page in\n            // incognito mode, the following error is thrown: `DOMException: Failed to execute 'open' on 'CacheStorage':\n            // An attempt was made to break through the security policy of the user agent.`\n            // So, instead of crashing, we just ignore the error and continue without using the cache.\n            cache = await caches.open('transformers-cache');\n        } catch (e) {\n            console.warn('An error occurred while opening the browser cache:', e);\n        }\n    }\n\n    if (!cache && _env_js__WEBPACK_IMPORTED_MODULE_3__.env.useFSCache) {\n        // TODO throw error if not available\n\n        // If `cache_dir` is not specified, use the default cache directory\n        cache = new FileCache(options.cache_dir ?? _env_js__WEBPACK_IMPORTED_MODULE_3__.env.cacheDir);\n    }\n\n    if (!cache && _env_js__WEBPACK_IMPORTED_MODULE_3__.env.useCustomCache) {\n        // Allow the user to specify a custom cache system.\n        if (!_env_js__WEBPACK_IMPORTED_MODULE_3__.env.customCache) {\n            throw Error('`env.useCustomCache=true`, but `env.customCache` is not defined.')\n        }\n\n        // Check that the required methods are defined:\n        if (!_env_js__WEBPACK_IMPORTED_MODULE_3__.env.customCache.match || !_env_js__WEBPACK_IMPORTED_MODULE_3__.env.customCache.put) {\n            throw new Error(\n                \"`env.customCache` must be an object which implements the `match` and `put` functions of the Web Cache API. \" +\n                \"For more information, see https://developer.mozilla.org/en-US/docs/Web/API/Cache\"\n            )\n        }\n        cache = _env_js__WEBPACK_IMPORTED_MODULE_3__.env.customCache;\n    }\n\n    const revision = options.revision ?? 'main';\n\n    let requestURL = pathJoin(path_or_repo_id, filename);\n    let localPath = pathJoin(_env_js__WEBPACK_IMPORTED_MODULE_3__.env.localModelPath, requestURL);\n\n    let remoteURL = pathJoin(\n        _env_js__WEBPACK_IMPORTED_MODULE_3__.env.remoteHost,\n        _env_js__WEBPACK_IMPORTED_MODULE_3__.env.remotePathTemplate\n            .replaceAll('{model}', path_or_repo_id)\n            .replaceAll('{revision}', encodeURIComponent(revision)),\n        filename\n    );\n\n    // Choose cache key for filesystem cache\n    // When using the main revision (default), we use the request URL as the cache key.\n    // If a specific revision is requested, we account for this in the cache key.\n    let fsCacheKey = revision === 'main' ? requestURL : pathJoin(path_or_repo_id, revision, filename);\n\n    /** @type {string} */\n    let cacheKey;\n    let proposedCacheKey = cache instanceof FileCache ? fsCacheKey : remoteURL;\n\n    // Whether to cache the final response in the end.\n    let toCacheResponse = false;\n\n    /** @type {Response|FileResponse|undefined} */\n    let response;\n\n    if (cache) {\n        // A caching system is available, so we try to get the file from it.\n        //  1. We first try to get from cache using the local path. In some environments (like deno),\n        //     non-URL cache keys are not allowed. In these cases, `response` will be undefined.\n        //  2. If no response is found, we try to get from cache using the remote URL or file system cache.\n        response = await tryCache(cache, localPath, proposedCacheKey);\n    }\n\n    const cacheHit = response !== undefined;\n\n    if (response === undefined) {\n        // Caching not available, or file is not cached, so we perform the request\n\n        if (_env_js__WEBPACK_IMPORTED_MODULE_3__.env.allowLocalModels) {\n            // Accessing local models is enabled, so we try to get the file locally.\n            // If request is a valid HTTP URL, we skip the local file check. Otherwise, we try to get the file locally.\n            const isURL = isValidHttpUrl(requestURL);\n            if (!isURL) {\n                try {\n                    response = await getFile(localPath);\n                    cacheKey = localPath; // Update the cache key to be the local path\n                } catch (e) {\n                    // Something went wrong while trying to get the file locally.\n                    // NOTE: error handling is done in the next step (since `response` will be undefined)\n                    console.warn(`Unable to load from local path \"${localPath}\": \"${e}\"`);\n                }\n            } else if (options.local_files_only) {\n                throw new Error(`\\`local_files_only=true\\`, but attempted to load a remote file from: ${requestURL}.`);\n            } else if (!_env_js__WEBPACK_IMPORTED_MODULE_3__.env.allowRemoteModels) {\n                throw new Error(`\\`env.allowRemoteModels=false\\`, but attempted to load a remote file from: ${requestURL}.`);\n            }\n        }\n\n        if (response === undefined || response.status === 404) {\n            // File not found locally. This means either:\n            // - The user has disabled local file access (`env.allowLocalModels=false`)\n            // - the path is a valid HTTP url (`response === undefined`)\n            // - the path is not a valid HTTP url and the file is not present on the file system or local server (`response.status === 404`)\n\n            if (options.local_files_only || !_env_js__WEBPACK_IMPORTED_MODULE_3__.env.allowRemoteModels) {\n                // User requested local files only, but the file is not found locally.\n                if (fatal) {\n                    throw Error(`\\`local_files_only=true\\` or \\`env.allowRemoteModels=false\\` and file was not found locally at \"${localPath}\".`);\n                } else {\n                    // File not found, but this file is optional.\n                    // TODO in future, cache the response?\n                    return null;\n                }\n            }\n\n            // File not found locally, so we try to download it from the remote server\n            response = await getFile(remoteURL);\n\n            if (response.status !== 200) {\n                return handleError(response.status, remoteURL, fatal);\n            }\n\n            // Success! We use the proposed cache key from earlier\n            cacheKey = proposedCacheKey;\n        }\n\n        // Only cache the response if:\n        toCacheResponse =\n            cache                              // 1. A caching system is available\n            && typeof Response !== 'undefined' // 2. `Response` is defined (i.e., we are in a browser-like environment)\n            && response instanceof Response    // 3. result is a `Response` object (i.e., not a `FileResponse`)\n            && response.status === 200         // 4. request was successful (status code 200)\n    }\n\n    // Start downloading\n    (0,_core_js__WEBPACK_IMPORTED_MODULE_4__.dispatchCallback)(options.progress_callback, {\n        status: 'download',\n        name: path_or_repo_id,\n        file: filename\n    })\n\n    const progressInfo = {\n        status: 'progress',\n        name: path_or_repo_id,\n        file: filename\n    }\n\n    /** @type {Uint8Array} */\n    let buffer;\n\n    if (!options.progress_callback) {\n        // If no progress callback is specified, we can use the `.arrayBuffer()`\n        // method to read the response.\n        buffer = new Uint8Array(await response.arrayBuffer());\n\n    } else if (\n        cacheHit // The item is being read from the cache\n        &&\n        typeof navigator !== 'undefined' && /firefox/i.test(navigator.userAgent) // We are in Firefox\n    ) {\n        // Due to bug in Firefox, we cannot display progress when loading from cache.\n        // Fortunately, since this should be instantaneous, this should not impact users too much.\n        buffer = new Uint8Array(await response.arrayBuffer());\n\n        // For completeness, we still fire the final progress callback\n        (0,_core_js__WEBPACK_IMPORTED_MODULE_4__.dispatchCallback)(options.progress_callback, {\n            ...progressInfo,\n            progress: 100,\n            loaded: buffer.length,\n            total: buffer.length,\n        })\n    } else {\n        buffer = await readResponse(response, data => {\n            (0,_core_js__WEBPACK_IMPORTED_MODULE_4__.dispatchCallback)(options.progress_callback, {\n                ...progressInfo,\n                ...data,\n            })\n        })\n    }\n\n    if (\n        // Only cache web responses\n        // i.e., do not cache FileResponses (prevents duplication)\n        toCacheResponse && cacheKey\n        &&\n        // Check again whether request is in cache. If not, we add the response to the cache\n        (await cache.match(cacheKey) === undefined)\n    ) {\n        // NOTE: We use `new Response(buffer, ...)` instead of `response.clone()` to handle LFS files\n        await cache.put(cacheKey, new Response(buffer, {\n            headers: response.headers\n        }))\n            .catch(err => {\n                // Do not crash if unable to add to cache (e.g., QuotaExceededError).\n                // Rather, log a warning and proceed with execution.\n                console.warn(`Unable to add response to browser cache: ${err}.`);\n            });\n\n    }\n\n    (0,_core_js__WEBPACK_IMPORTED_MODULE_4__.dispatchCallback)(options.progress_callback, {\n        status: 'done',\n        name: path_or_repo_id,\n        file: filename\n    });\n\n    return buffer;\n}\n\n/**\n * Fetches a JSON file from a given path and file name.\n *\n * @param {string} modelPath The path to the directory containing the file.\n * @param {string} fileName The name of the file to fetch.\n * @param {boolean} [fatal=true] Whether to throw an error if the file is not found.\n * @param {PretrainedOptions} [options] An object containing optional parameters.\n * @returns {Promise<Object>} The JSON data parsed into a JavaScript object.\n * @throws Will throw an error if the file is not found and `fatal` is true.\n */\nasync function getModelJSON(modelPath, fileName, fatal = true, options = {}) {\n    let buffer = await getModelFile(modelPath, fileName, fatal, options);\n    if (buffer === null) {\n        // Return empty object\n        return {}\n    }\n\n    let decoder = new TextDecoder('utf-8');\n    let jsonData = decoder.decode(buffer);\n\n    return JSON.parse(jsonData);\n}\n\n/**\n * Read and track progress when reading a Response object\n *\n * @param {any} response The Response object to read\n * @param {function} progress_callback The function to call with progress updates\n * @returns {Promise<Uint8Array>} A Promise that resolves with the Uint8Array buffer\n */\nasync function readResponse(response, progress_callback) {\n\n    const contentLength = response.headers.get('Content-Length');\n    if (contentLength === null) {\n        console.warn('Unable to determine content-length from response headers. Will expand buffer when needed.')\n    }\n    let total = parseInt(contentLength ?? '0');\n    let buffer = new Uint8Array(total);\n    let loaded = 0;\n\n    const reader = response.body.getReader();\n    async function read() {\n        const { done, value } = await reader.read();\n        if (done) return;\n\n        let newLoaded = loaded + value.length;\n        if (newLoaded > total) {\n            total = newLoaded;\n\n            // Adding the new data will overflow buffer.\n            // In this case, we extend the buffer\n            let newBuffer = new Uint8Array(total);\n\n            // copy contents\n            newBuffer.set(buffer);\n\n            buffer = newBuffer;\n        }\n        buffer.set(value, loaded)\n        loaded = newLoaded;\n\n        const progress = (loaded / total) * 100;\n\n        // Call your function here\n        progress_callback({\n            progress: progress,\n            loaded: loaded,\n            total: total,\n        })\n\n        return read();\n    }\n\n    // Actually read\n    await read();\n\n    return buffer;\n}\n\n/**\n * Joins multiple parts of a path into a single path, while handling leading and trailing slashes.\n *\n * @param {...string} parts Multiple parts of a path.\n * @returns {string} A string representing the joined path.\n */\nfunction pathJoin(...parts) {\n    // https://stackoverflow.com/a/55142565\n    parts = parts.map((part, index) => {\n        if (index) {\n            part = part.replace(new RegExp('^/'), '');\n        }\n        if (index !== parts.length - 1) {\n            part = part.replace(new RegExp('/$'), '');\n        }\n        return part;\n    })\n    return parts.join('/');\n}\n\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@xenova/transformers/src/utils/hub.js?");

/***/ }),

/***/ "./node_modules/@xenova/transformers/src/utils/image.js":
/*!**************************************************************!*\
  !*** ./node_modules/@xenova/transformers/src/utils/image.js ***!
  \**************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   RawImage: () => (/* binding */ RawImage)\n/* harmony export */ });\n/* harmony import */ var _hub_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./hub.js */ \"./node_modules/@xenova/transformers/src/utils/hub.js\");\n/* harmony import */ var _env_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../env.js */ \"./node_modules/@xenova/transformers/src/env.js\");\n/* harmony import */ var sharp__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! sharp */ \"?0740\");\n\n/**\n * @file Helper module for image processing. \n * \n * These functions and classes are only used internally, \n * meaning an end-user shouldn't need to access anything here.\n * \n * @module utils/image\n */\n\n\n\n\n// Will be empty (or not used) if running in browser or web-worker\n\n\nconst BROWSER_ENV = typeof self !== 'undefined';\nconst WEBWORKER_ENV = BROWSER_ENV && self.constructor.name === 'DedicatedWorkerGlobalScope';\n\nlet createCanvasFunction;\nlet ImageDataClass;\nlet loadImageFunction;\nif (BROWSER_ENV) {\n    // Running in browser or web-worker\n    createCanvasFunction = (/** @type {number} */ width, /** @type {number} */ height) => {\n        if (!self.OffscreenCanvas) {\n            throw new Error('OffscreenCanvas not supported by this browser.');\n        }\n        return new self.OffscreenCanvas(width, height)\n    };\n    loadImageFunction = self.createImageBitmap;\n    ImageDataClass = self.ImageData;\n\n} else if (sharp__WEBPACK_IMPORTED_MODULE_2__) {\n    // Running in Node.js, electron, or other non-browser environment\n\n    loadImageFunction = async (/**@type {sharp.Sharp}*/img) => {\n        const metadata = await img.metadata();\n        const rawChannels = metadata.channels;\n\n        let { data, info } = await img.raw().toBuffer({ resolveWithObject: true });\n\n        const newImage = new RawImage(new Uint8ClampedArray(data), info.width, info.height, info.channels);\n        if (rawChannels !== undefined && rawChannels !== info.channels) {\n            // Make sure the new image has the same number of channels as the input image.\n            // This is necessary for grayscale images.\n            newImage.convert(rawChannels);\n        }\n        return newImage;\n    }\n\n} else {\n    throw new Error('Unable to load image processing library.');\n}\n\n\n// Defined here: https://github.com/python-pillow/Pillow/blob/a405e8406b83f8bfb8916e93971edc7407b8b1ff/src/libImaging/Imaging.h#L262-L268\nconst RESAMPLING_MAPPING = {\n    0: 'nearest',\n    1: 'lanczos',\n    2: 'bilinear',\n    3: 'bicubic',\n    4: 'box',\n    5: 'hamming',\n}\n\n/**\n * Mapping from file extensions to MIME types.\n */\nconst CONTENT_TYPE_MAP = new Map([\n    ['png', 'image/png'],\n    ['jpg', 'image/jpeg'],\n    ['jpeg', 'image/jpeg'],\n    ['gif', 'image/gif'],\n]);\n\nclass RawImage {\n\n    /**\n     * Create a new `RawImage` object.\n     * @param {Uint8ClampedArray|Uint8Array} data The pixel data.\n     * @param {number} width The width of the image.\n     * @param {number} height The height of the image.\n     * @param {1|2|3|4} channels The number of channels.\n     */\n    constructor(data, width, height, channels) {\n        this.data = data;\n        this.width = width;\n        this.height = height;\n        this.channels = channels;\n    }\n\n    /** \n     * Returns the size of the image (width, height).\n     * @returns {[number, number]} The size of the image (width, height).\n     */\n    get size() {\n        return [this.width, this.height];\n    }\n\n    /**\n     * Helper method for reading an image from a variety of input types.\n     * @param {RawImage|string|URL} input \n     * @returns The image object.\n     * \n     * **Example:** Read image from a URL.\n     * ```javascript\n     * let image = await RawImage.read('https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/football-match.jpg');\n     * // RawImage {\n     * //   \"data\": Uint8ClampedArray [ 25, 25, 25, 19, 19, 19, ... ],\n     * //   \"width\": 800,\n     * //   \"height\": 533,\n     * //   \"channels\": 3\n     * // }\n     * ```\n     */\n    static async read(input) {\n        if (input instanceof RawImage) {\n            return input;\n        } else if (typeof input === 'string' || input instanceof URL) {\n            return await this.fromURL(input);\n        } else {\n            throw new Error(`Unsupported input type: ${typeof input}`);\n        }\n    }\n\n\n    /**\n     * Read an image from a URL or file path.\n     * @param {string|URL} url The URL or file path to read the image from.\n     * @returns {Promise<RawImage>} The image object.\n     */\n    static async fromURL(url) {\n        let response = await (0,_hub_js__WEBPACK_IMPORTED_MODULE_0__.getFile)(url);\n        if (response.status !== 200) {\n            throw new Error(`Unable to read image from \"${url}\" (${response.status} ${response.statusText})`);\n        }\n        let blob = await response.blob();\n        return this.fromBlob(blob);\n    }\n\n    /**\n     * Helper method to create a new Image from a blob.\n     * @param {Blob} blob The blob to read the image from.\n     * @returns {Promise<RawImage>} The image object.\n     */\n    static async fromBlob(blob) {\n        if (BROWSER_ENV) {\n            // Running in environment with canvas\n            let img = await loadImageFunction(blob);\n\n            const ctx = createCanvasFunction(img.width, img.height).getContext('2d');\n\n            // Draw image to context\n            ctx.drawImage(img, 0, 0);\n\n            return new this(ctx.getImageData(0, 0, img.width, img.height).data, img.width, img.height, 4);\n\n        } else {\n            // Use sharp.js to read (and possible resize) the image.\n            let img = sharp__WEBPACK_IMPORTED_MODULE_2__(await blob.arrayBuffer());\n\n            return await loadImageFunction(img);\n        }\n    }\n\n    /**\n     * Helper method to create a new Image from a tensor\n     * @param {import('./tensor.js').Tensor} tensor \n     */\n    static fromTensor(tensor, channel_format = 'CHW') {\n        if (tensor.dims.length !== 3) {\n            throw new Error(`Tensor should have 3 dimensions, but has ${tensor.dims.length} dimensions.`);\n        }\n\n        if (channel_format === 'CHW') {\n            tensor = tensor.transpose(1, 2, 0);\n        } else if (channel_format === 'HWC') {\n            // Do nothing\n        } else {\n            throw new Error(`Unsupported channel format: ${channel_format}`);\n        }\n        if (!(tensor.data instanceof Uint8ClampedArray || tensor.data instanceof Uint8Array)) {\n            throw new Error(`Unsupported tensor type: ${tensor.type}`);\n        }\n        switch (tensor.dims[2]) {\n            case 1:\n            case 2:\n            case 3:\n            case 4:\n                return new RawImage(tensor.data, tensor.dims[1], tensor.dims[0], tensor.dims[2]);\n            default:\n                throw new Error(`Unsupported number of channels: ${tensor.dims[2]}`);\n        }\n    }\n\n    /**\n     * Convert the image to grayscale format.\n     * @returns {RawImage} `this` to support chaining.\n     */\n    grayscale() {\n        if (this.channels === 1) {\n            return this;\n        }\n\n        let newData = new Uint8ClampedArray(this.width * this.height * 1);\n        switch (this.channels) {\n            case 3: // rgb to grayscale\n            case 4: // rgba to grayscale\n                for (let i = 0, offset = 0; i < this.data.length; i += this.channels) {\n                    const red = this.data[i];\n                    const green = this.data[i + 1];\n                    const blue = this.data[i + 2];\n\n                    newData[offset++] = Math.round(0.2989 * red + 0.5870 * green + 0.1140 * blue);\n                }\n                break;\n            default:\n                throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`);\n        }\n        return this._update(newData, this.width, this.height, 1);\n    }\n\n    /**\n     * Convert the image to RGB format.\n     * @returns {RawImage} `this` to support chaining.\n     */\n    rgb() {\n        if (this.channels === 3) {\n            return this;\n        }\n\n        let newData = new Uint8ClampedArray(this.width * this.height * 3);\n\n        switch (this.channels) {\n            case 1: // grayscale to rgb\n                for (let i = 0, offset = 0; i < this.data.length; ++i) {\n                    newData[offset++] = this.data[i];\n                    newData[offset++] = this.data[i];\n                    newData[offset++] = this.data[i];\n                }\n                break;\n            case 4: // rgba to rgb\n                for (let i = 0, offset = 0; i < this.data.length; i += 4) {\n                    newData[offset++] = this.data[i];\n                    newData[offset++] = this.data[i + 1];\n                    newData[offset++] = this.data[i + 2];\n                }\n                break;\n            default:\n                throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`);\n        }\n        return this._update(newData, this.width, this.height, 3);\n\n    }\n\n    /**\n     * Convert the image to RGBA format.\n     * @returns {RawImage} `this` to support chaining.\n     */\n    rgba() {\n        if (this.channels === 4) {\n            return this;\n        }\n\n        let newData = new Uint8ClampedArray(this.width * this.height * 4);\n\n        switch (this.channels) {\n            case 1: // grayscale to rgba\n                for (let i = 0, offset = 0; i < this.data.length; ++i) {\n                    newData[offset++] = this.data[i];\n                    newData[offset++] = this.data[i];\n                    newData[offset++] = this.data[i];\n                    newData[offset++] = 255;\n                }\n                break;\n            case 3: // rgb to rgba\n                for (let i = 0, offset = 0; i < this.data.length; i += 3) {\n                    newData[offset++] = this.data[i];\n                    newData[offset++] = this.data[i + 1];\n                    newData[offset++] = this.data[i + 2];\n                    newData[offset++] = 255;\n                }\n                break;\n            default:\n                throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`);\n        }\n\n        return this._update(newData, this.width, this.height, 4);\n    }\n\n    /**\n     * Resize the image to the given dimensions. This method uses the canvas API to perform the resizing.\n     * @param {number} width The width of the new image.\n     * @param {number} height The height of the new image.\n     * @param {Object} options Additional options for resizing.\n     * @param {0|1|2|3|4|5|string} [options.resample] The resampling method to use.\n     * @returns {Promise<RawImage>} `this` to support chaining.\n     */\n    async resize(width, height, {\n        resample = 2,\n    } = {}) {\n\n        // Ensure resample method is a string\n        let resampleMethod = RESAMPLING_MAPPING[resample] ?? resample;\n\n        if (BROWSER_ENV) {\n            // TODO use `resample` in browser environment\n\n            // Store number of channels before resizing\n            let numChannels = this.channels;\n\n            // Create canvas object for this image\n            let canvas = this.toCanvas();\n\n            // Actually perform resizing using the canvas API\n            const ctx = createCanvasFunction(width, height).getContext('2d');\n\n            // Draw image to context, resizing in the process\n            ctx.drawImage(canvas, 0, 0, width, height);\n\n            // Create image from the resized data\n            let resizedImage = new RawImage(ctx.getImageData(0, 0, width, height).data, width, height, 4);\n\n            // Convert back so that image has the same number of channels as before\n            return resizedImage.convert(numChannels);\n\n        } else {\n            // Create sharp image from raw data, and resize\n            let img = this.toSharp();\n\n            switch (resampleMethod) {\n                case 'box':\n                case 'hamming':\n                    if (resampleMethod === 'box' || resampleMethod === 'hamming') {\n                        console.warn(`Resampling method ${resampleMethod} is not yet supported. Using bilinear instead.`);\n                        resampleMethod = 'bilinear';\n                    }\n\n                case 'nearest':\n                case 'bilinear':\n                case 'bicubic':\n                    // Perform resizing using affine transform. \n                    // This matches how the python Pillow library does it.\n                    img = img.affine([width / this.width, 0, 0, height / this.height], {\n                        interpolator: resampleMethod\n                    });\n                    break;\n\n                case 'lanczos':\n                    // https://github.com/python-pillow/Pillow/discussions/5519\n                    // https://github.com/lovell/sharp/blob/main/docs/api-resize.md\n                    img = img.resize({\n                        width, height,\n                        fit: 'fill',\n                        kernel: 'lanczos3', // PIL Lanczos uses a kernel size of 3 \n                    });\n                    break;\n\n                default:\n                    throw new Error(`Resampling method ${resampleMethod} is not supported.`);\n            }\n\n            return await loadImageFunction(img);\n        }\n\n    }\n\n    async pad([left, right, top, bottom]) {\n        left = Math.max(left, 0);\n        right = Math.max(right, 0);\n        top = Math.max(top, 0);\n        bottom = Math.max(bottom, 0);\n\n        if (left === 0 && right === 0 && top === 0 && bottom === 0) {\n            // No padding needed\n            return this;\n        }\n\n        if (BROWSER_ENV) {\n            // Store number of channels before padding\n            let numChannels = this.channels;\n\n            // Create canvas object for this image\n            let canvas = this.toCanvas();\n\n            let newWidth = this.width + left + right;\n            let newHeight = this.height + top + bottom;\n\n            // Create a new canvas of the desired size.\n            const ctx = createCanvasFunction(newWidth, newHeight).getContext('2d');\n\n            // Draw image to context, padding in the process\n            ctx.drawImage(canvas,\n                0, 0, this.width, this.height,\n                left, top, newWidth, newHeight\n            );\n\n            // Create image from the padded data\n            let paddedImage = new RawImage(\n                ctx.getImageData(0, 0, newWidth, newHeight).data,\n                newWidth, newHeight, 4);\n\n            // Convert back so that image has the same number of channels as before\n            return paddedImage.convert(numChannels);\n\n        } else {\n            let img = this.toSharp().extend({ left, right, top, bottom });\n            return await loadImageFunction(img);\n        }\n    }\n\n    async crop([x_min, y_min, x_max, y_max]) {\n        // Ensure crop bounds are within the image\n        x_min = Math.max(x_min, 0);\n        y_min = Math.max(y_min, 0);\n        x_max = Math.min(x_max, this.width - 1);\n        y_max = Math.min(y_max, this.height - 1);\n\n        // Do nothing if the crop is the entire image\n        if (x_min === 0 && y_min === 0 && x_max === this.width - 1 && y_max === this.height - 1) {\n            return this;\n        }\n\n        const crop_width = x_max - x_min + 1;\n        const crop_height = y_max - y_min + 1;\n\n        if (BROWSER_ENV) {\n            // Store number of channels before resizing\n            const numChannels = this.channels;\n\n            // Create canvas object for this image\n            const canvas = this.toCanvas();\n\n            // Create a new canvas of the desired size. This is needed since if the \n            // image is too small, we need to pad it with black pixels.\n            const ctx = createCanvasFunction(crop_width, crop_height).getContext('2d');\n\n            // Draw image to context, cropping in the process\n            ctx.drawImage(canvas,\n                x_min, y_min, crop_width, crop_height,\n                0, 0, crop_width, crop_height\n            );\n\n            // Create image from the resized data\n            const resizedImage = new RawImage(ctx.getImageData(0, 0, crop_width, crop_height).data, crop_width, crop_height, 4);\n\n            // Convert back so that image has the same number of channels as before\n            return resizedImage.convert(numChannels);\n\n        } else {\n            // Create sharp image from raw data\n            const img = this.toSharp().extract({\n                left: x_min,\n                top: y_min,\n                width: crop_width,\n                height: crop_height,\n            });\n\n            return await loadImageFunction(img);\n        }\n\n    }\n\n    async center_crop(crop_width, crop_height) {\n        // If the image is already the desired size, return it\n        if (this.width === crop_width && this.height === crop_height) {\n            return this;\n        }\n\n        // Determine bounds of the image in the new canvas\n        let width_offset = (this.width - crop_width) / 2;\n        let height_offset = (this.height - crop_height) / 2;\n\n\n        if (BROWSER_ENV) {\n            // Store number of channels before resizing\n            let numChannels = this.channels;\n\n            // Create canvas object for this image\n            let canvas = this.toCanvas();\n\n            // Create a new canvas of the desired size. This is needed since if the \n            // image is too small, we need to pad it with black pixels.\n            const ctx = createCanvasFunction(crop_width, crop_height).getContext('2d');\n\n            let sourceX = 0;\n            let sourceY = 0;\n            let destX = 0;\n            let destY = 0;\n\n            if (width_offset >= 0) {\n                sourceX = width_offset;\n            } else {\n                destX = -width_offset;\n            }\n\n            if (height_offset >= 0) {\n                sourceY = height_offset;\n            } else {\n                destY = -height_offset;\n            }\n\n            // Draw image to context, cropping in the process\n            ctx.drawImage(canvas,\n                sourceX, sourceY, crop_width, crop_height,\n                destX, destY, crop_width, crop_height\n            );\n\n            // Create image from the resized data\n            let resizedImage = new RawImage(ctx.getImageData(0, 0, crop_width, crop_height).data, crop_width, crop_height, 4);\n\n            // Convert back so that image has the same number of channels as before\n            return resizedImage.convert(numChannels);\n\n        } else {\n            // Create sharp image from raw data\n            let img = this.toSharp();\n\n            if (width_offset >= 0 && height_offset >= 0) {\n                // Cropped image lies entirely within the original image\n                img = img.extract({\n                    left: Math.floor(width_offset),\n                    top: Math.floor(height_offset),\n                    width: crop_width,\n                    height: crop_height,\n                })\n            } else if (width_offset <= 0 && height_offset <= 0) {\n                // Cropped image lies entirely outside the original image,\n                // so we add padding\n                let top = Math.floor(-height_offset);\n                let left = Math.floor(-width_offset);\n                img = img.extend({\n                    top: top,\n                    left: left,\n\n                    // Ensures the resulting image has the desired dimensions\n                    right: crop_width - this.width - left,\n                    bottom: crop_height - this.height - top,\n                });\n            } else {\n                // Cropped image lies partially outside the original image.\n                // We first pad, then crop.\n\n                let y_padding = [0, 0];\n                let y_extract = 0;\n                if (height_offset < 0) {\n                    y_padding[0] = Math.floor(-height_offset);\n                    y_padding[1] = crop_height - this.height - y_padding[0];\n                } else {\n                    y_extract = Math.floor(height_offset);\n                }\n\n                let x_padding = [0, 0];\n                let x_extract = 0;\n                if (width_offset < 0) {\n                    x_padding[0] = Math.floor(-width_offset);\n                    x_padding[1] = crop_width - this.width - x_padding[0];\n                } else {\n                    x_extract = Math.floor(width_offset);\n                }\n\n                img = img.extend({\n                    top: y_padding[0],\n                    bottom: y_padding[1],\n                    left: x_padding[0],\n                    right: x_padding[1],\n                }).extract({\n                    left: x_extract,\n                    top: y_extract,\n                    width: crop_width,\n                    height: crop_height,\n                })\n            }\n\n            return await loadImageFunction(img);\n        }\n    }\n\n    async toBlob(type = 'image/png', quality = 1) {\n        if (!BROWSER_ENV) {\n            throw new Error('toBlob() is only supported in browser environments.')\n        }\n\n        const canvas = this.toCanvas();\n        return await canvas.convertToBlob({ type, quality });\n    }\n\n    toCanvas() {\n        if (!BROWSER_ENV) {\n            throw new Error('toCanvas() is only supported in browser environments.')\n        }\n\n        // Clone, and convert data to RGBA before drawing to canvas.\n        // This is because the canvas API only supports RGBA\n        let cloned = this.clone().rgba();\n\n        // Create canvas object for the cloned image\n        let clonedCanvas = createCanvasFunction(cloned.width, cloned.height);\n\n        // Draw image to context\n        let data = new ImageDataClass(cloned.data, cloned.width, cloned.height);\n        clonedCanvas.getContext('2d').putImageData(data, 0, 0);\n\n        return clonedCanvas;\n    }\n\n    /**\n     * Helper method to update the image data.\n     * @param {Uint8ClampedArray} data The new image data.\n     * @param {number} width The new width of the image.\n     * @param {number} height The new height of the image.\n     * @param {1|2|3|4|null} [channels] The new number of channels of the image.\n     * @private\n     */\n    _update(data, width, height, channels = null) {\n        this.data = data;\n        this.width = width;\n        this.height = height;\n        if (channels !== null) {\n            this.channels = channels;\n        }\n        return this;\n    }\n\n    /**\n     * Clone the image\n     * @returns {RawImage} The cloned image\n     */\n    clone() {\n        return new RawImage(this.data.slice(), this.width, this.height, this.channels);\n    }\n\n    /**\n     * Helper method for converting image to have a certain number of channels\n     * @param {number} numChannels The number of channels. Must be 1, 3, or 4.\n     * @returns {RawImage} `this` to support chaining.\n     */\n    convert(numChannels) {\n        if (this.channels === numChannels) return this; // Already correct number of channels\n\n        switch (numChannels) {\n            case 1:\n                this.grayscale();\n                break;\n            case 3:\n                this.rgb();\n                break;\n            case 4:\n                this.rgba();\n                break;\n            default:\n                throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`);\n        }\n        return this;\n    }\n\n    /**\n     * Save the image to the given path.\n     * @param {string} path The path to save the image to.\n     */\n    async save(path) {\n\n        if (BROWSER_ENV) {\n            if (WEBWORKER_ENV) {\n                throw new Error('Unable to save an image from a Web Worker.')\n            }\n\n            const extension = path.split('.').pop().toLowerCase();\n            const mime = CONTENT_TYPE_MAP.get(extension) ?? 'image/png';\n\n            // Convert image to Blob\n            const blob = await this.toBlob(mime);\n\n            // Convert the canvas content to a data URL\n            const dataURL = URL.createObjectURL(blob);\n\n            // Create an anchor element with the data URL as the href attribute\n            const downloadLink = document.createElement('a');\n            downloadLink.href = dataURL;\n\n            // Set the download attribute to specify the desired filename for the downloaded image\n            downloadLink.download = path;\n\n            // Trigger the download\n            downloadLink.click();\n\n            // Clean up: remove the anchor element from the DOM\n            downloadLink.remove();\n\n        } else if (!_env_js__WEBPACK_IMPORTED_MODULE_1__.env.useFS) {\n            throw new Error('Unable to save the image because filesystem is disabled in this environment.')\n\n        } else {\n            const img = this.toSharp();\n            return await img.toFile(path);\n        }\n    }\n\n    toSharp() {\n        if (BROWSER_ENV) {\n            throw new Error('toSharp() is only supported in server-side environments.')\n        }\n\n        return sharp__WEBPACK_IMPORTED_MODULE_2__(this.data, {\n            raw: {\n                width: this.width,\n                height: this.height,\n                channels: this.channels\n            }\n        });\n    }\n}\n\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@xenova/transformers/src/utils/image.js?");

/***/ }),

/***/ "./node_modules/@xenova/transformers/src/utils/maths.js":
/*!**************************************************************!*\
  !*** ./node_modules/@xenova/transformers/src/utils/maths.js ***!
  \**************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   FFT: () => (/* binding */ FFT),\n/* harmony export */   cos_sim: () => (/* binding */ cos_sim),\n/* harmony export */   dot: () => (/* binding */ dot),\n/* harmony export */   getTopItems: () => (/* binding */ getTopItems),\n/* harmony export */   interpolate_data: () => (/* binding */ interpolate_data),\n/* harmony export */   log_softmax: () => (/* binding */ log_softmax),\n/* harmony export */   magnitude: () => (/* binding */ magnitude),\n/* harmony export */   max: () => (/* binding */ max),\n/* harmony export */   medianFilter: () => (/* binding */ medianFilter),\n/* harmony export */   min: () => (/* binding */ min),\n/* harmony export */   round: () => (/* binding */ round),\n/* harmony export */   softmax: () => (/* binding */ softmax),\n/* harmony export */   transpose_data: () => (/* binding */ transpose_data)\n/* harmony export */ });\n\n/**\n * @file Helper module for mathematical processing. \n * \n * These functions and classes are only used internally, \n * meaning an end-user shouldn't need to access anything here.\n * \n * @module utils/maths\n */\n\n/**\n * @typedef {Int8Array | Uint8Array | Uint8ClampedArray | Int16Array | Uint16Array | Int32Array | Uint32Array | Float32Array | Float64Array} TypedArray\n * @typedef {BigInt64Array | BigUint64Array} BigTypedArray\n * @typedef {TypedArray | BigTypedArray} AnyTypedArray\n */\n\n/**\n * @param {TypedArray} input\n */\nfunction interpolate_data(input, [in_channels, in_height, in_width], [out_height, out_width], mode = 'bilinear', align_corners = false) {\n    // TODO use mode and align_corners\n\n    // Output image dimensions\n    const x_scale = out_width / in_width;\n    const y_scale = out_height / in_height;\n\n    // Output image\n    // @ts-ignore\n    const out_img = new input.constructor(out_height * out_width * in_channels);\n\n    // Pre-calculate strides\n    const inStride = in_height * in_width;\n    const outStride = out_height * out_width;\n\n    for (let i = 0; i < out_height; ++i) {\n        for (let j = 0; j < out_width; ++j) {\n            // Calculate output offset\n            const outOffset = i * out_width + j;\n\n            // Calculate input pixel coordinates\n            const x = (j + 0.5) / x_scale - 0.5;\n            const y = (i + 0.5) / y_scale - 0.5;\n\n            // Calculate the four nearest input pixels\n            // We also check if the input pixel coordinates are within the image bounds\n            let x1 = Math.floor(x);\n            let y1 = Math.floor(y);\n            const x2 = Math.min(x1 + 1, in_width - 1);\n            const y2 = Math.min(y1 + 1, in_height - 1);\n\n            x1 = Math.max(x1, 0);\n            y1 = Math.max(y1, 0);\n\n\n            // Calculate the fractional distances between the input pixel and the four nearest pixels\n            const s = x - x1;\n            const t = y - y1;\n\n            // Perform bilinear interpolation\n            const w1 = (1 - s) * (1 - t);\n            const w2 = s * (1 - t);\n            const w3 = (1 - s) * t;\n            const w4 = s * t;\n\n            // Calculate the four nearest input pixel indices\n            const yStride = y1 * in_width;\n            const xStride = y2 * in_width;\n            const idx1 = yStride + x1;\n            const idx2 = yStride + x2;\n            const idx3 = xStride + x1;\n            const idx4 = xStride + x2;\n\n            for (let k = 0; k < in_channels; ++k) {\n                // Calculate channel offset\n                const cOffset = k * inStride;\n\n                out_img[k * outStride + outOffset] =\n                    w1 * input[cOffset + idx1] +\n                    w2 * input[cOffset + idx2] +\n                    w3 * input[cOffset + idx3] +\n                    w4 * input[cOffset + idx4];\n            }\n        }\n    }\n\n    return out_img;\n}\n\n\n/**\n * Helper method to transpose a `AnyTypedArray` directly\n * @template {AnyTypedArray} T \n * @param {T} array \n * @param {number[]} dims \n * @param {number[]} axes \n * @returns {[T, number[]]} The transposed array and the new shape.\n */\nfunction transpose_data(array, dims, axes) {\n    // Calculate the new shape of the transposed array\n    // and the stride of the original array\n    const shape = new Array(axes.length);\n    const stride = new Array(axes.length);\n\n    for (let i = axes.length - 1, s = 1; i >= 0; --i) {\n        stride[i] = s;\n        shape[i] = dims[axes[i]];\n        s *= shape[i];\n    }\n\n    // Precompute inverse mapping of stride\n    const invStride = axes.map((_, i) => stride[axes.indexOf(i)]);\n\n    // Create the transposed array with the new shape\n    // @ts-ignore\n    const transposedData = new array.constructor(array.length);\n\n    // Transpose the original array to the new array\n    for (let i = 0; i < array.length; ++i) {\n        let newIndex = 0;\n        for (let j = dims.length - 1, k = i; j >= 0; --j) {\n            newIndex += (k % dims[j]) * invStride[j];\n            k = Math.floor(k / dims[j]);\n        }\n        transposedData[newIndex] = array[i];\n    }\n\n    return [transposedData, shape];\n}\n\n\n/**\n * Compute the softmax of an array of numbers.\n * @template {TypedArray|number[]} T\n * @param {T} arr The array of numbers to compute the softmax of.\n * @returns {T} The softmax array.\n */\nfunction softmax(arr) {\n    // Compute the maximum value in the array\n    const maxVal = max(arr)[0];\n\n    // Compute the exponentials of the array values\n    const exps = arr.map(x => Math.exp(x - maxVal));\n\n    // Compute the sum of the exponentials\n    // @ts-ignore\n    const sumExps = exps.reduce((acc, val) => acc + val, 0);\n\n    // Compute the softmax values\n    const softmaxArr = exps.map(x => x / sumExps);\n\n    return /** @type {T} */(softmaxArr);\n}\n\n/**\n * Calculates the logarithm of the softmax function for the input array.\n * @template {TypedArray|number[]} T\n * @param {T} arr The input array to calculate the log_softmax function for.\n * @returns {T} The resulting log_softmax array.\n */\nfunction log_softmax(arr) {\n    // Compute the softmax values\n    const softmaxArr = softmax(arr);\n\n    // Apply log formula to each element\n    const logSoftmaxArr = softmaxArr.map(x => Math.log(x));\n\n    return /** @type {T} */(logSoftmaxArr);\n}\n\n/**\n * Calculates the dot product of two arrays.\n * @param {number[]} arr1 The first array.\n * @param {number[]} arr2 The second array.\n * @returns {number} The dot product of arr1 and arr2.\n */\nfunction dot(arr1, arr2) {\n    return arr1.reduce((acc, val, i) => acc + val * arr2[i], 0);\n}\n\n\n/**\n * Get the top k items from an iterable, sorted by descending order\n * @param {any[]|TypedArray} items The items to be sorted\n * @param {number|null} [top_k=0] The number of top items to return (default: 0 = return all)\n * @returns {[number, any][]} The top k items, sorted by descending order\n */\nfunction getTopItems(items, top_k = 0) {\n    // if top == 0, return all\n\n    items = Array.from(items)\n        .map((x, i) => [i, x])            // Get indices ([index, score])\n        .sort((a, b) => b[1] - a[1])      // Sort by log probabilities\n\n    if (top_k !== null && top_k > 0) {\n        items = items.slice(0, top_k);    // Get top k items\n    }\n\n    return items\n}\n\n/**\n * Computes the cosine similarity between two arrays.\n *\n * @param {number[]} arr1 The first array.\n * @param {number[]} arr2 The second array.\n * @returns {number} The cosine similarity between the two arrays.\n */\nfunction cos_sim(arr1, arr2) {\n    // Calculate dot product of the two arrays\n    const dotProduct = dot(arr1, arr2);\n\n    // Calculate the magnitude of the first array\n    const magnitudeA = magnitude(arr1);\n\n    // Calculate the magnitude of the second array\n    const magnitudeB = magnitude(arr2);\n\n    // Calculate the cosine similarity\n    const cosineSimilarity = dotProduct / (magnitudeA * magnitudeB);\n\n    return cosineSimilarity;\n}\n\n/**\n * Calculates the magnitude of a given array.\n * @param {number[]} arr The array to calculate the magnitude of.\n * @returns {number} The magnitude of the array.\n */\nfunction magnitude(arr) {\n    return Math.sqrt(arr.reduce((acc, val) => acc + val * val, 0));\n}\n\n\n/**\n * Returns the value and index of the minimum element in an array.\n * @param {number[]|TypedArray} arr array of numbers.\n * @returns {number[]} the value and index of the minimum element, of the form: [valueOfMin, indexOfMin]\n * @throws {Error} If array is empty.\n */\nfunction min(arr) {\n    if (arr.length === 0) throw Error('Array must not be empty');\n    let min = arr[0];\n    let indexOfMin = 0;\n    for (let i = 1; i < arr.length; ++i) {\n        if (arr[i] < min) {\n            min = arr[i];\n            indexOfMin = i;\n        }\n    }\n    return [min, indexOfMin];\n}\n\n\n/**\n * Returns the value and index of the maximum element in an array.\n * @param {number[]|AnyTypedArray} arr array of numbers.\n * @returns {[number, number]} the value and index of the maximum element, of the form: [valueOfMax, indexOfMax]\n * @throws {Error} If array is empty.\n */\nfunction max(arr) {\n    if (arr.length === 0) throw Error('Array must not be empty');\n    let max = arr[0];\n    let indexOfMax = 0;\n    for (let i = 1; i < arr.length; ++i) {\n        if (arr[i] > max) {\n            max = arr[i];\n            indexOfMax = i;\n        }\n    }\n    return [Number(max), indexOfMax];\n}\n\nfunction isPowerOfTwo(number) {\n    // Check if the number is greater than 0 and has only one bit set to 1\n    return (number > 0) && ((number & (number - 1)) === 0);\n}\n\n/**\n * Implementation of Radix-4 FFT.\n * \n * P2FFT class provides functionality for performing Fast Fourier Transform on arrays\n * which are a power of two in length.\n * Code adapted from https://www.npmjs.com/package/fft.js\n */\nclass P2FFT {\n    /**\n     * @param {number} size The size of the input array. Must be a power of two larger than 1.\n     * @throws {Error} FFT size must be a power of two larger than 1.\n     */\n    constructor(size) {\n        this.size = size | 0; // convert to a 32-bit signed integer\n        if (this.size <= 1 || !isPowerOfTwo(this.size))\n            throw new Error('FFT size must be a power of two larger than 1');\n\n        this._csize = size << 1;\n\n        this.table = new Float64Array(this.size * 2);\n        for (let i = 0; i < this.table.length; i += 2) {\n            const angle = Math.PI * i / this.size;\n            this.table[i] = Math.cos(angle);\n            this.table[i + 1] = -Math.sin(angle);\n        }\n\n        // Find size's power of two\n        let power = 0;\n        for (let t = 1; this.size > t; t <<= 1)\n            ++power;\n\n        // Calculate initial step's width:\n        //   * If we are full radix-4, it is 2x smaller to give inital len=8\n        //   * Otherwise it is the same as `power` to give len=4\n        this._width = power % 2 === 0 ? power - 1 : power;\n\n        // Pre-compute bit-reversal patterns\n        this._bitrev = new Int32Array(1 << this._width);\n        for (let j = 0; j < this._bitrev.length; ++j) {\n            this._bitrev[j] = 0;\n            for (let shift = 0; shift < this._width; shift += 2) {\n                const revShift = this._width - shift - 2;\n                this._bitrev[j] |= ((j >>> shift) & 3) << revShift;\n            }\n        }\n    }\n\n    /**\n     * Create a complex number array with size `2 * size`\n     *\n     * @returns {Float64Array} A complex number array with size `2 * size`\n     */\n    createComplexArray() {\n        return new Float64Array(this._csize);\n    }\n\n    /**\n     * Converts a complex number representation stored in a Float64Array to an array of real numbers.\n     * \n     * @param {Float64Array} complex The complex number representation to be converted.\n     * @param {number[]} [storage] An optional array to store the result in.\n     * @returns {number[]} An array of real numbers representing the input complex number representation.\n     */\n    fromComplexArray(complex, storage) {\n        const res = storage || new Array(complex.length >>> 1);\n        for (let i = 0; i < complex.length; i += 2)\n            res[i >>> 1] = complex[i];\n        return res;\n    }\n\n    /**\n     * Convert a real-valued input array to a complex-valued output array.\n     * @param {Float64Array} input The real-valued input array.\n     * @param {Float64Array} [storage] Optional buffer to store the output array.\n     * @returns {Float64Array} The complex-valued output array.\n     */\n    toComplexArray(input, storage) {\n        const res = storage || this.createComplexArray();\n        for (let i = 0; i < res.length; i += 2) {\n            res[i] = input[i >>> 1];\n            res[i + 1] = 0;\n        }\n        return res;\n    }\n\n    /**\n     * Completes the spectrum by adding its mirrored negative frequency components.\n     * @param {Float64Array} spectrum The input spectrum.\n     * @returns {void}\n     */\n    completeSpectrum(spectrum) {\n        const size = this._csize;\n        const half = size >>> 1;\n        for (let i = 2; i < half; i += 2) {\n            spectrum[size - i] = spectrum[i];\n            spectrum[size - i + 1] = -spectrum[i + 1];\n        }\n    }\n\n    /**\n     * Performs a Fast Fourier Transform (FFT) on the given input data and stores the result in the output buffer.\n     * \n     * @param {Float64Array} out The output buffer to store the result.\n     * @param {Float64Array} data The input data to transform.\n     * \n     * @throws {Error} Input and output buffers must be different.\n     * \n     * @returns {void}\n     */\n    transform(out, data) {\n        if (out === data)\n            throw new Error('Input and output buffers must be different');\n\n        this._transform4(out, data, 1 /* DONE */);\n    }\n\n    /**\n     * Performs a real-valued forward FFT on the given input buffer and stores the result in the given output buffer.\n     * The input buffer must contain real values only, while the output buffer will contain complex values. The input and\n     * output buffers must be different.\n     *\n     * @param {Float64Array} out The output buffer.\n     * @param {Float64Array} data The input buffer containing real values.\n     *\n     * @throws {Error} If the input and output buffers are the same.\n     */\n    realTransform(out, data) {\n        if (out === data)\n            throw new Error('Input and output buffers must be different');\n\n        this._realTransform4(out, data, 1 /* DONE */);\n    }\n\n    /**\n     * Performs an inverse FFT transformation on the given `data` array, and stores the result in `out`.\n     * The `out` array must be a different buffer than the `data` array. The `out` array will contain the\n     * result of the transformation. The `data` array will not be modified.\n     * \n     * @param {Float64Array} out The output buffer for the transformed data.\n     * @param {Float64Array} data The input data to transform.\n     * @throws {Error} If `out` and `data` refer to the same buffer.\n     * @returns {void}\n     */\n    inverseTransform(out, data) {\n        if (out === data)\n            throw new Error('Input and output buffers must be different');\n\n        this._transform4(out, data, -1 /* DONE */);\n        for (let i = 0; i < out.length; ++i)\n            out[i] /= this.size;\n    }\n\n    /**\n     * Performs a radix-4 implementation of a discrete Fourier transform on a given set of data.\n     *\n     * @param {Float64Array} out The output buffer for the transformed data.\n     * @param {Float64Array} data The input buffer of data to be transformed.\n     * @param {number} inv A scaling factor to apply to the transform.\n     * @returns {void}\n     */\n    _transform4(out, data, inv) {\n        // radix-4 implementation\n\n        const size = this._csize;\n\n        // Initial step (permute and transform)\n        const width = this._width;\n        let step = 1 << width;\n        let len = (size / step) << 1;\n\n        let outOff;\n        let t;\n        const bitrev = this._bitrev;\n        if (len === 4) {\n            for (outOff = 0, t = 0; outOff < size; outOff += len, ++t) {\n                const off = bitrev[t];\n                this._singleTransform2(data, out, outOff, off, step);\n            }\n        } else {\n            // len === 8\n            for (outOff = 0, t = 0; outOff < size; outOff += len, ++t) {\n                const off = bitrev[t];\n                this._singleTransform4(data, out, outOff, off, step, inv);\n            }\n        }\n\n        // Loop through steps in decreasing order\n        for (step >>= 2; step >= 2; step >>= 2) {\n            len = (size / step) << 1;\n            const quarterLen = len >>> 2;\n\n            // Loop through offsets in the data\n            for (outOff = 0; outOff < size; outOff += len) {\n                // Full case\n                const limit = outOff + quarterLen - 1;\n                for (let i = outOff, k = 0; i < limit; i += 2, k += step) {\n                    const A = i;\n                    const B = A + quarterLen;\n                    const C = B + quarterLen;\n                    const D = C + quarterLen;\n\n                    // Original values\n                    const Ar = out[A];\n                    const Ai = out[A + 1];\n                    const Br = out[B];\n                    const Bi = out[B + 1];\n                    const Cr = out[C];\n                    const Ci = out[C + 1];\n                    const Dr = out[D];\n                    const Di = out[D + 1];\n\n                    const tableBr = this.table[k];\n                    const tableBi = inv * this.table[k + 1];\n                    const MBr = Br * tableBr - Bi * tableBi;\n                    const MBi = Br * tableBi + Bi * tableBr;\n\n                    const tableCr = this.table[2 * k];\n                    const tableCi = inv * this.table[2 * k + 1];\n                    const MCr = Cr * tableCr - Ci * tableCi;\n                    const MCi = Cr * tableCi + Ci * tableCr;\n\n                    const tableDr = this.table[3 * k];\n                    const tableDi = inv * this.table[3 * k + 1];\n                    const MDr = Dr * tableDr - Di * tableDi;\n                    const MDi = Dr * tableDi + Di * tableDr;\n\n                    // Pre-Final values\n                    const T0r = Ar + MCr;\n                    const T0i = Ai + MCi;\n                    const T1r = Ar - MCr;\n                    const T1i = Ai - MCi;\n                    const T2r = MBr + MDr;\n                    const T2i = MBi + MDi;\n                    const T3r = inv * (MBr - MDr);\n                    const T3i = inv * (MBi - MDi);\n\n                    // Final values\n                    out[A] = T0r + T2r;\n                    out[A + 1] = T0i + T2i;\n                    out[B] = T1r + T3i;\n                    out[B + 1] = T1i - T3r;\n                    out[C] = T0r - T2r;\n                    out[C + 1] = T0i - T2i;\n                    out[D] = T1r - T3i;\n                    out[D + 1] = T1i + T3r;\n                }\n            }\n        }\n    }\n\n    /**\n     * Performs a radix-2 implementation of a discrete Fourier transform on a given set of data.\n     *\n     * @param {Float64Array} data The input buffer of data to be transformed.\n     * @param {Float64Array} out The output buffer for the transformed data.\n     * @param {number} outOff The offset at which to write the output data.\n     * @param {number} off The offset at which to begin reading the input data.\n     * @param {number} step The step size for indexing the input data.\n     * @returns {void}\n     */\n    _singleTransform2(data, out, outOff, off, step) {\n        // radix-2 implementation\n        // NOTE: Only called for len=4\n\n        const evenR = data[off];\n        const evenI = data[off + 1];\n        const oddR = data[off + step];\n        const oddI = data[off + step + 1];\n\n        out[outOff] = evenR + oddR;\n        out[outOff + 1] = evenI + oddI;\n        out[outOff + 2] = evenR - oddR;\n        out[outOff + 3] = evenI - oddI;\n    }\n\n    /**\n     * Performs radix-4 transformation on input data of length 8\n     *\n     * @param {Float64Array} data Input data array of length 8\n     * @param {Float64Array} out Output data array of length 8\n     * @param {number} outOff Index of output array to start writing from\n     * @param {number} off Index of input array to start reading from\n     * @param {number} step Step size between elements in input array\n     * @param {number} inv Scaling factor for inverse transform\n     * \n     * @returns {void}\n     */\n    _singleTransform4(data, out, outOff, off, step, inv) {\n        // radix-4\n        // NOTE: Only called for len=8\n        const step2 = step * 2;\n        const step3 = step * 3;\n\n        // Original values\n        const Ar = data[off];\n        const Ai = data[off + 1];\n        const Br = data[off + step];\n        const Bi = data[off + step + 1];\n        const Cr = data[off + step2];\n        const Ci = data[off + step2 + 1];\n        const Dr = data[off + step3];\n        const Di = data[off + step3 + 1];\n\n        // Pre-Final values\n        const T0r = Ar + Cr;\n        const T0i = Ai + Ci;\n        const T1r = Ar - Cr;\n        const T1i = Ai - Ci;\n        const T2r = Br + Dr;\n        const T2i = Bi + Di;\n        const T3r = inv * (Br - Dr);\n        const T3i = inv * (Bi - Di);\n\n        // Final values\n        out[outOff] = T0r + T2r;\n        out[outOff + 1] = T0i + T2i;\n        out[outOff + 2] = T1r + T3i;\n        out[outOff + 3] = T1i - T3r;\n        out[outOff + 4] = T0r - T2r;\n        out[outOff + 5] = T0i - T2i;\n        out[outOff + 6] = T1r - T3i;\n        out[outOff + 7] = T1i + T3r;\n    }\n\n    /**\n     * Real input radix-4 implementation\n     * @param {Float64Array} out Output array for the transformed data\n     * @param {Float64Array} data Input array of real data to be transformed\n     * @param {number} inv The scale factor used to normalize the inverse transform\n     */\n    _realTransform4(out, data, inv) {\n        // Real input radix-4 implementation\n        const size = this._csize;\n\n        // Initial step (permute and transform)\n        const width = this._width;\n        let step = 1 << width;\n        let len = (size / step) << 1;\n\n        let outOff;\n        let t;\n        const bitrev = this._bitrev;\n        if (len === 4) {\n            for (outOff = 0, t = 0; outOff < size; outOff += len, ++t) {\n                const off = bitrev[t];\n                this._singleRealTransform2(data, out, outOff, off >>> 1, step >>> 1);\n            }\n        } else {\n            // len === 8\n            for (outOff = 0, t = 0; outOff < size; outOff += len, ++t) {\n                const off = bitrev[t];\n                this._singleRealTransform4(data, out, outOff, off >>> 1, step >>> 1, inv);\n            }\n        }\n\n        // TODO: Optimize once https://github.com/indutny/fft.js/issues/25 is fixed\n        // Loop through steps in decreasing order\n        for (step >>= 2; step >= 2; step >>= 2) {\n            len = (size / step) << 1;\n            const quarterLen = len >>> 2;\n\n            // Loop through offsets in the data\n            for (outOff = 0; outOff < size; outOff += len) {\n                // Full case\n                const limit = outOff + quarterLen - 1;\n                for (let i = outOff, k = 0; i < limit; i += 2, k += step) {\n                    const A = i;\n                    const B = A + quarterLen;\n                    const C = B + quarterLen;\n                    const D = C + quarterLen;\n\n                    // Original values\n                    const Ar = out[A];\n                    const Ai = out[A + 1];\n                    const Br = out[B];\n                    const Bi = out[B + 1];\n                    const Cr = out[C];\n                    const Ci = out[C + 1];\n                    const Dr = out[D];\n                    const Di = out[D + 1];\n\n                    const tableBr = this.table[k];\n                    const tableBi = inv * this.table[k + 1];\n                    const MBr = Br * tableBr - Bi * tableBi;\n                    const MBi = Br * tableBi + Bi * tableBr;\n\n                    const tableCr = this.table[2 * k];\n                    const tableCi = inv * this.table[2 * k + 1];\n                    const MCr = Cr * tableCr - Ci * tableCi;\n                    const MCi = Cr * tableCi + Ci * tableCr;\n\n                    const tableDr = this.table[3 * k];\n                    const tableDi = inv * this.table[3 * k + 1];\n                    const MDr = Dr * tableDr - Di * tableDi;\n                    const MDi = Dr * tableDi + Di * tableDr;\n\n                    // Pre-Final values\n                    const T0r = Ar + MCr;\n                    const T0i = Ai + MCi;\n                    const T1r = Ar - MCr;\n                    const T1i = Ai - MCi;\n                    const T2r = MBr + MDr;\n                    const T2i = MBi + MDi;\n                    const T3r = inv * (MBr - MDr);\n                    const T3i = inv * (MBi - MDi);\n\n                    // Final values\n                    out[A] = T0r + T2r;\n                    out[A + 1] = T0i + T2i;\n                    out[B] = T1r + T3i;\n                    out[B + 1] = T1i - T3r;\n                    out[C] = T0r - T2r;\n                    out[C + 1] = T0i - T2i;\n                    out[D] = T1r - T3i;\n                    out[D + 1] = T1i + T3r;\n                }\n            }\n        }\n    }\n\n    /**\n     * Performs a single real input radix-2 transformation on the provided data\n     * \n     * @param {Float64Array} data The input data array\n     * @param {Float64Array} out The output data array\n     * @param {number} outOff The output offset\n     * @param {number} off The input offset\n     * @param {number} step The step\n     * \n     * @returns {void}\n     */\n    _singleRealTransform2(data, out, outOff, off, step) {\n        // radix-2 implementation\n        // NOTE: Only called for len=4\n\n        const evenR = data[off];\n        const oddR = data[off + step];\n\n        out[outOff] = evenR + oddR;\n        out[outOff + 1] = 0;\n        out[outOff + 2] = evenR - oddR;\n        out[outOff + 3] = 0;\n    }\n\n    /**\n     * Computes a single real-valued transform using radix-4 algorithm.\n     * This method is only called for len=8.\n     *\n     * @param {Float64Array} data The input data array.\n     * @param {Float64Array} out The output data array.\n     * @param {number} outOff The offset into the output array.\n     * @param {number} off The offset into the input array.\n     * @param {number} step The step size for the input array.\n     * @param {number} inv The value of inverse.\n     */\n    _singleRealTransform4(data, out, outOff, off, step, inv) {\n        // radix-4\n        // NOTE: Only called for len=8\n        const step2 = step * 2;\n        const step3 = step * 3;\n\n        // Original values\n        const Ar = data[off];\n        const Br = data[off + step];\n        const Cr = data[off + step2];\n        const Dr = data[off + step3];\n\n        // Pre-Final values\n        const T0r = Ar + Cr;\n        const T1r = Ar - Cr;\n        const T2r = Br + Dr;\n        const T3r = inv * (Br - Dr);\n\n        // Final values\n        out[outOff] = T0r + T2r;\n        out[outOff + 1] = 0;\n        out[outOff + 2] = T1r;\n        out[outOff + 3] = -T3r;\n        out[outOff + 4] = T0r - T2r;\n        out[outOff + 5] = 0;\n        out[outOff + 6] = T1r;\n        out[outOff + 7] = T3r;\n    }\n}\n\n/**\n * NP2FFT class provides functionality for performing Fast Fourier Transform on arrays\n * which are not a power of two in length. In such cases, the chirp-z transform is used.\n * \n * For more information, see: https://math.stackexchange.com/questions/77118/non-power-of-2-ffts/77156#77156\n */\nclass NP2FFT {\n\n    /**\n     * Constructs a new NP2FFT object.\n     * @param {number} fft_length The length of the FFT\n     */\n    constructor(fft_length) {\n        // Helper variables\n        const a = 2 * (fft_length - 1);\n        const b = 2 * (2 * fft_length - 1);\n        const nextP2 = 2 ** (Math.ceil(Math.log2(b)))\n        this.bufferSize = nextP2;\n        this._a = a;\n\n        // Define buffers\n        // Compute chirp for transform\n        const chirp = new Float64Array(b);\n        const ichirp = new Float64Array(nextP2);\n        this._chirpBuffer = new Float64Array(nextP2);\n        this._buffer1 = new Float64Array(nextP2);\n        this._buffer2 = new Float64Array(nextP2);\n        this._outBuffer1 = new Float64Array(nextP2);\n        this._outBuffer2 = new Float64Array(nextP2);\n\n        // Compute complex exponentiation\n        const theta = -2 * Math.PI / fft_length;\n        const baseR = Math.cos(theta);\n        const baseI = Math.sin(theta);\n\n        // Precompute helper for chirp-z transform\n        for (let i = 0; i < b >> 1; ++i) {\n            // Compute complex power:\n            const e = (i + 1 - fft_length) ** 2 / 2.0;\n\n            // Compute the modulus and argument of the result\n            const result_mod = Math.sqrt(baseR ** 2 + baseI ** 2) ** e;\n            const result_arg = e * Math.atan2(baseI, baseR);\n\n            // Convert the result back to rectangular form\n            // and assign to chirp and ichirp\n            const i2 = 2 * i;\n            chirp[i2] = result_mod * Math.cos(result_arg);\n            chirp[i2 + 1] = result_mod * Math.sin(result_arg);\n\n            // conjugate\n            ichirp[i2] = chirp[i2];\n            ichirp[i2 + 1] = - chirp[i2 + 1];\n        }\n        this._slicedChirpBuffer = chirp.subarray(a, b);\n\n        // create object to perform Fast Fourier Transforms\n        // with `nextP2` complex numbers\n        this._f = new P2FFT(nextP2 >> 1);\n        this._f.transform(this._chirpBuffer, ichirp);\n    }\n\n    _transform(output, input, real) {\n        const ib1 = this._buffer1;\n        const ib2 = this._buffer2;\n        const ob2 = this._outBuffer1;\n        const ob3 = this._outBuffer2;\n        const cb = this._chirpBuffer;\n        const sb = this._slicedChirpBuffer;\n        const a = this._a;\n\n        if (real) {\n            // Real multiplication\n            for (let j = 0; j < sb.length; j += 2) {\n                const j2 = j + 1\n                const j3 = j >> 1;\n\n                const a_real = input[j3];\n                ib1[j] = a_real * sb[j];\n                ib1[j2] = a_real * sb[j2];\n            }\n        } else {\n            // Complex multiplication\n            for (let j = 0; j < sb.length; j += 2) {\n                const j2 = j + 1\n                ib1[j] = input[j] * sb[j] - input[j2] * sb[j2];\n                ib1[j2] = input[j] * sb[j2] + input[j2] * sb[j];\n            }\n        }\n        this._f.transform(ob2, ib1);\n\n        for (let j = 0; j < cb.length; j += 2) {\n            const j2 = j + 1;\n\n            ib2[j] = ob2[j] * cb[j] - ob2[j2] * cb[j2];\n            ib2[j2] = ob2[j] * cb[j2] + ob2[j2] * cb[j];\n        }\n        this._f.inverseTransform(ob3, ib2);\n\n        for (let j = 0; j < ob3.length; j += 2) {\n            const a_real = ob3[j + a];\n            const a_imag = ob3[j + a + 1];\n            const b_real = sb[j];\n            const b_imag = sb[j + 1];\n\n            output[j] = a_real * b_real - a_imag * b_imag;\n            output[j + 1] = a_real * b_imag + a_imag * b_real;\n        }\n    }\n\n    transform(output, input) {\n        this._transform(output, input, false);\n    }\n\n    realTransform(output, input) {\n        this._transform(output, input, true);\n    }\n}\n\nclass FFT {\n    constructor(fft_length) {\n        this.fft_length = fft_length;\n        this.isPowerOfTwo = isPowerOfTwo(fft_length);\n        if (this.isPowerOfTwo) {\n            this.fft = new P2FFT(fft_length);\n            this.outputBufferSize = 2 * fft_length;\n        } else {\n            this.fft = new NP2FFT(fft_length);\n            this.outputBufferSize = this.fft.bufferSize;\n        }\n    }\n\n    realTransform(out, input) {\n        this.fft.realTransform(out, input);\n    }\n\n    transform(out, input) {\n        this.fft.transform(out, input);\n    }\n}\n\n\n/**\n * Performs median filter on the provided data. Padding is done by mirroring the data.\n * @param {AnyTypedArray} data The input array\n * @param {number} windowSize The window size\n */\nfunction medianFilter(data, windowSize) {\n\n    if (windowSize % 2 === 0 || windowSize <= 0) {\n        throw new Error('Window size must be a positive odd number');\n    }\n\n    // @ts-ignore\n    const outputArray = new data.constructor(data.length);\n\n    // @ts-ignore\n    const buffer = new data.constructor(windowSize); // Reusable array for storing values\n\n    const halfWindowSize = Math.floor(windowSize / 2);\n\n    for (let i = 0; i < data.length; ++i) {\n        let valuesIndex = 0;\n\n        for (let j = -halfWindowSize; j <= halfWindowSize; ++j) {\n            let index = i + j;\n            if (index < 0) {\n                index = Math.abs(index);\n            } else if (index >= data.length) {\n                index = 2 * (data.length - 1) - index;\n            }\n\n            buffer[valuesIndex++] = data[index];\n        }\n\n        buffer.sort();\n        outputArray[i] = buffer[halfWindowSize];\n    }\n\n    return outputArray;\n}\n\n/**\n * Helper function to round a number to a given number of decimals\n * @param {number} num The number to round\n * @param {number} decimals The number of decimals\n * @returns {number} The rounded number\n */\nfunction round(num, decimals) {\n    const pow = Math.pow(10, decimals);\n    return Math.round(num * pow) / pow;\n}\n\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@xenova/transformers/src/utils/maths.js?");

/***/ }),

/***/ "./node_modules/@xenova/transformers/src/utils/tensor.js":
/*!***************************************************************!*\
  !*** ./node_modules/@xenova/transformers/src/utils/tensor.js ***!
  \***************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Tensor: () => (/* binding */ Tensor),\n/* harmony export */   cat: () => (/* binding */ cat),\n/* harmony export */   dynamicTimeWarping: () => (/* binding */ dynamicTimeWarping),\n/* harmony export */   interpolate: () => (/* binding */ interpolate),\n/* harmony export */   layer_norm: () => (/* binding */ layer_norm),\n/* harmony export */   mean: () => (/* binding */ mean),\n/* harmony export */   mean_pooling: () => (/* binding */ mean_pooling),\n/* harmony export */   ones: () => (/* binding */ ones),\n/* harmony export */   ones_like: () => (/* binding */ ones_like),\n/* harmony export */   stack: () => (/* binding */ stack),\n/* harmony export */   std_mean: () => (/* binding */ std_mean),\n/* harmony export */   transpose: () => (/* binding */ transpose)\n/* harmony export */ });\n/* harmony import */ var _backends_onnx_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../backends/onnx.js */ \"./node_modules/@xenova/transformers/src/backends/onnx.js\");\n/* harmony import */ var _maths_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./maths.js */ \"./node_modules/@xenova/transformers/src/utils/maths.js\");\n/**\n * @file Helper module for `Tensor` processing.\n * \n * These functions and classes are only used internally, \n * meaning an end-user shouldn't need to access anything here.\n * \n * @module utils/tensor\n */\n\n\n\n\n\n\nconst DataTypeMap = Object.freeze({\n    float32: Float32Array,\n    float64: Float64Array,\n    string: Array, // string[]\n    int8: Int8Array,\n    uint8: Uint8Array,\n    int16: Int16Array,\n    uint16: Uint16Array,\n    int32: Int32Array,\n    uint32: Uint32Array,\n    int64: BigInt64Array,\n    uint64: BigUint64Array,\n    bool: Uint8Array,\n});\n\n/**\n * @typedef {keyof typeof DataTypeMap} DataType\n * @typedef {import('./maths.js').AnyTypedArray | any[]} DataArray\n */\n\nconst ONNXTensor = _backends_onnx_js__WEBPACK_IMPORTED_MODULE_0__.ONNX.Tensor;\n\nclass Tensor {\n    /** @type {number[]} Dimensions of the tensor. */\n    dims;\n\n    /** @type {DataType} Type of the tensor. */\n    type;\n\n    /** @type {DataArray} The data stored in the tensor. */\n    data;\n\n    /** @type {number} The number of elements in the tensor. */\n    size;\n\n    /**\n     * Create a new Tensor or copy an existing Tensor.\n     * @param {[DataType, DataArray, number[]]|[import('onnxruntime-common').Tensor]} args\n     */\n    constructor(...args) {\n        if (args[0] instanceof ONNXTensor) {\n            // Create shallow copy\n            Object.assign(this, args[0]);\n\n        } else {\n            // Create new tensor\n            Object.assign(this, new ONNXTensor(\n                /** @type {DataType} */(args[0]),\n                /** @type {Exclude<import('./maths.js').AnyTypedArray, Uint8ClampedArray>} */(args[1]),\n                args[2]\n            ));\n        }\n\n        return new Proxy(this, {\n            get: (obj, key) => {\n                if (typeof key === 'string') {\n                    let index = Number(key);\n                    if (Number.isInteger(index)) {\n                        // key is an integer (i.e., index)\n                        return obj._getitem(index);\n                    }\n                }\n                // @ts-ignore\n                return obj[key];\n            },\n            set: (obj, key, value) => {\n                // TODO allow setting of data\n\n                // @ts-ignore\n                return obj[key] = value;\n            }\n        });\n    }\n\n    /**\n     * Returns an iterator object for iterating over the tensor data in row-major order.\n     * If the tensor has more than one dimension, the iterator will yield subarrays.\n     * @returns {Iterator} An iterator object for iterating over the tensor data in row-major order.\n     */\n    *[Symbol.iterator]() {\n        const [iterLength, ...iterDims] = this.dims;\n\n        if (iterDims.length > 0) {\n            const iterSize = iterDims.reduce((a, b) => a * b);\n            for (let i = 0; i < iterLength; ++i) {\n                yield this._subarray(i, iterSize, iterDims);\n            }\n        } else {\n            yield* this.data\n        }\n\n    }\n\n    /**\n     * Index into a Tensor object.\n     * @param {number} index The index to access.\n     * @returns {Tensor} The data at the specified index.\n     */\n    _getitem(index) {\n        const [iterLength, ...iterDims] = this.dims;\n\n        index = safeIndex(index, iterLength);\n\n        if (iterDims.length > 0) {\n            const iterSize = iterDims.reduce((a, b) => a * b);\n            return this._subarray(index, iterSize, iterDims);\n        } else {\n            return new Tensor(this.type, [this.data[index]], iterDims);\n        }\n    }\n\n    /**\n     * @param {number|bigint} item The item to search for in the tensor\n     * @returns {number} The index of the first occurrence of item in the tensor data.\n     */\n    indexOf(item) {\n        for (let index = 0; index < this.data.length; ++index) {\n            // Note: == instead of === so we can match Ints with BigInts\n            if (this.data[index] == item) {\n                return index;\n            }\n        }\n        return -1;\n    }\n\n    /**\n     * @param {number} index \n     * @param {number} iterSize \n     * @param {any} iterDims \n     * @returns {Tensor}\n     */\n    _subarray(index, iterSize, iterDims) {\n        const o1 = index * iterSize;\n        const o2 = (index + 1) * iterSize;\n\n        // We use subarray if available (typed array), otherwise we use slice (normal array)\n        const data =\n            ('subarray' in this.data)\n                ? this.data.subarray(o1, o2)\n                : this.data.slice(o1, o2);\n        return new Tensor(this.type, data, iterDims);\n    }\n\n    /**\n     * Returns the value of this tensor as a standard JavaScript Number. This only works\n     * for tensors with one element. For other cases, see `Tensor.tolist()`.\n     * @returns {number|bigint} The value of this tensor as a standard JavaScript Number.\n     * @throws {Error} If the tensor has more than one element.\n     */\n    item() {\n        if (this.data.length !== 1) {\n            throw new Error(`a Tensor with ${this.data.length} elements cannot be converted to Scalar`);\n        }\n        return this.data[0];\n    }\n\n    /**\n     * Convert tensor data to a n-dimensional JS list\n     * @returns {Array}\n     */\n    tolist() {\n        return reshape(this.data, this.dims)\n    }\n\n    /**\n     * Return a new Tensor with the sigmoid function applied to each element.\n     * @returns {Tensor} The tensor with the sigmoid function applied.\n     */\n    sigmoid() {\n        return this.clone().sigmoid_();\n    }\n\n    /**\n     * Applies the sigmoid function to the tensor in place.\n     * @returns {Tensor} Returns `this`.\n     */\n    sigmoid_() {\n        for (let i = 0; i < this.data.length; ++i) {\n            this.data[i] = 1 / (1 + Math.exp(-this.data[i]));\n        }\n        return this;\n    }\n\n    /**\n     * Return a new Tensor with every element multiplied by a constant.\n     * @param {number} val The value to multiply by.\n     * @returns {Tensor} The new tensor.\n     */\n    mul(val) {\n        return this.clone().mul_(val);\n    }\n\n    /**\n     * Multiply the tensor by a constant in place.\n     * @param {number} val The value to multiply by.\n     * @returns {Tensor} Returns `this`.\n     */\n    mul_(val) {\n        for (let i = 0; i < this.data.length; ++i) {\n            this.data[i] *= val;\n        }\n        return this;\n    }\n\n\n    /**\n     * Return a new Tensor with every element added by a constant.\n     * @param {number} val The value to add by.\n     * @returns {Tensor} The new tensor.\n     */\n    add(val) {\n        return this.clone().add_(val);\n    }\n\n    /**\n     * Add the tensor by a constant in place.\n     * @param {number} val The value to add by.\n     * @returns {Tensor} Returns `this`.\n     */\n    add_(val) {\n        for (let i = 0; i < this.data.length; ++i) {\n            this.data[i] += val;\n        }\n        return this;\n    }\n    clone() {\n        return new Tensor(this.type, this.data.slice(), this.dims.slice());\n    }\n\n    slice(...slices) {\n        // This allows for slicing with ranges and numbers\n        let newTensorDims = [];\n        let newOffsets = [];\n\n        // slices is an array of numbers or arrays of numbers\n        // e.g., slices = [0, [1, 3], null, [0, 3]]\n        for (let sliceIndex = 0; sliceIndex < this.dims.length; ++sliceIndex) {\n            let slice = slices[sliceIndex];\n\n            if (slice === null || slice === undefined) {\n                // null or undefined means take the whole dimension\n                newOffsets.push([0, this.dims[sliceIndex]]);\n                newTensorDims.push(this.dims[sliceIndex]);\n\n            } else if (typeof slice === 'number') {\n                slice = safeIndex(slice, this.dims[sliceIndex], sliceIndex);\n\n                // A number means take a single element\n                newOffsets.push([slice, slice + 1]);\n\n            } else if (Array.isArray(slice) && slice.length === 2) {\n                // An array of length 2 means take a range of elements\n\n                if (slice[0] > slice[1]) {\n                    throw new Error(`Invalid slice: ${slice}`);\n                }\n\n                let offsets = [\n                    Math.max(slice[0], 0),\n                    Math.min(slice[1], this.dims[sliceIndex])\n                ];\n\n                newOffsets.push(offsets);\n                newTensorDims.push(offsets[1] - offsets[0]);\n\n            } else {\n                throw new Error(`Invalid slice: ${slice}`);\n            }\n        }\n\n        let newDims = newOffsets.map(([start, end]) => end - start);\n        let newBufferSize = newDims.reduce((a, b) => a * b);\n\n        // Allocate memory\n        // @ts-ignore\n        let data = new this.data.constructor(newBufferSize);\n\n        // Precompute strides\n        const stride = this.stride();\n\n        for (let i = 0; i < newBufferSize; ++i) {\n            let originalIndex = 0;\n            for (let j = newDims.length - 1, num = i; j >= 0; --j) {\n                const size = newDims[j];\n                originalIndex += ((num % size) + newOffsets[j][0]) * stride[j];\n                num = Math.floor(num / size);\n            }\n            data[i] = this.data[originalIndex];\n        }\n        return new Tensor(this.type, data, newTensorDims);\n\n    }\n\n    /**\n     * Return a transposed version of this Tensor, according to the provided dimensions.\n     * @param  {...number} dims Dimensions to transpose.\n     * @returns {Tensor} The transposed tensor.\n     */\n    transpose(...dims) {\n        return transpose(this, dims);\n    }\n\n    // TODO: rename transpose to permute\n    // TODO: implement transpose\n\n    // TODO add .max() and .min() methods\n\n    /**\n     * Returns the sum of each row of the input tensor in the given dimension dim.\n     * \n     * @param {number} [dim=null] The dimension or dimensions to reduce. If `null`, all dimensions are reduced.\n     * @param {boolean} keepdim Whether the output tensor has `dim` retained or not.\n     * @returns The summed tensor\n     */\n    sum(dim = null, keepdim = false) {\n        return this.norm(1, dim, keepdim);\n    }\n\n    /**\n     * Returns the matrix norm or vector norm of a given tensor.\n     * @param {number|string} [p='fro'] The order of norm\n     * @param {number} [dim=null] Specifies which dimension of the tensor to calculate the norm across.\n     * If dim is None, the norm will be calculated across all dimensions of input.\n     * @param {boolean} [keepdim=false] Whether the output tensors have dim retained or not.\n     * @returns {Tensor} The norm of the tensor.\n     */\n    norm(p = 'fro', dim = null, keepdim = false) {\n        if (p === 'fro') {\n            // NOTE: Since we only support integer dims, Frobenius norm produces the same result as p=2.\n            p = 2;\n        } else if (typeof p === 'string') {\n            throw Error(`Unsupported norm: ${p}`);\n        }\n\n        if (dim === null) {\n            // @ts-ignore\n            let val = this.data.reduce((a, b) => a + (b ** p), 0) ** (1 / p);\n            return new Tensor(this.type, [val], []);\n        }\n\n        // Negative indexing\n        dim = safeIndex(dim, this.dims.length);\n\n        // Calculate the shape of the resulting array after summation\n        const resultDims = this.dims.slice(); // Copy the original dimensions\n        resultDims[dim] = 1; // Remove the specified axis\n\n        // Create a new array to store the accumulated values\n        // @ts-ignore\n        const result = new this.data.constructor(this.data.length / this.dims[dim]);\n\n        // Iterate over the data array\n        for (let i = 0; i < this.data.length; ++i) {\n\n            // Calculate the index in the resulting array\n            let resultIndex = 0;\n\n            for (let j = this.dims.length - 1, num = i, resultMultiplier = 1; j >= 0; --j) {\n                const size = this.dims[j];\n                if (j !== dim) {\n                    const index = num % size;\n                    resultIndex += index * resultMultiplier;\n                    resultMultiplier *= resultDims[j];\n                }\n                num = Math.floor(num / size);\n            }\n\n            // Accumulate the value at the current index\n            result[resultIndex] += (this.data[i]) ** p;\n        }\n\n        if (p !== 1) {\n            for (let i = 0; i < result.length; ++i) {\n                result[i] = result[i] ** (1 / p);\n            }\n        }\n\n        if (!keepdim) {\n            resultDims.splice(dim, 1);\n        }\n\n        return new Tensor(this.type, result, resultDims);\n    }\n\n    /**\n     * Performs `L_p` normalization of inputs over specified dimension. Operates in place.\n     * @param {number} [p=2] The exponent value in the norm formulation\n     * @param {number} [dim=1] The dimension to reduce\n     * @returns {Tensor} `this` for operation chaining.\n     */\n    normalize_(p = 2.0, dim = 1) {\n        dim = safeIndex(dim, this.dims.length);\n\n        const norm = this.norm(p, dim, true);\n\n        for (let i = 0; i < this.data.length; ++i) {\n\n            // Calculate the index in the resulting array\n            let resultIndex = 0;\n\n            for (let j = this.dims.length - 1, num = i, resultMultiplier = 1; j >= 0; --j) {\n                const size = this.dims[j];\n                if (j !== dim) {\n                    const index = num % size;\n                    resultIndex += index * resultMultiplier;\n                    resultMultiplier *= this.dims[j];\n                }\n                num = Math.floor(num / size);\n            }\n\n            // Divide by normalized value\n            this.data[i] /= norm.data[resultIndex];\n        }\n\n        return this;\n    }\n\n    /**\n     * Performs `L_p` normalization of inputs over specified dimension.\n     * @param {number} [p=2] The exponent value in the norm formulation\n     * @param {number} [dim=1] The dimension to reduce\n     * @returns {Tensor} The normalized tensor.\n     */\n    normalize(p = 2.0, dim = 1) {\n        return this.clone().normalize_(p, dim);\n    }\n\n    /**\n     * Compute and return the stride of this tensor.\n     * Stride is the jump necessary to go from one element to the next one in the specified dimension dim.\n     * @returns {number[]} The stride of this tensor.\n     */\n    stride() {\n        return dimsToStride(this.dims);\n    }\n\n    /**\n     * Returns a tensor with all specified dimensions of input of size 1 removed.\n     * \n     * NOTE: The returned tensor shares the storage with the input tensor, so changing the contents of one will change the contents of the other.\n     * If you would like a copy, use `tensor.clone()` before squeezing.\n     * \n     * @param {number} [dim=null] If given, the input will be squeezed only in the specified dimensions.\n     * @returns The squeezed tensor\n     */\n    squeeze(dim = null) {\n        return new Tensor(\n            this.type,\n            this.data,\n            calc_squeeze_dims(this.dims, dim)\n        )\n    }\n\n    /**\n     * In-place version of @see {@link Tensor.squeeze}\n     */\n    squeeze_(dim = null) {\n        this.dims = calc_squeeze_dims(this.dims, dim);\n        return this;\n    }\n\n    /**\n     * Returns a new tensor with a dimension of size one inserted at the specified position.\n     * \n     * NOTE: The returned tensor shares the same underlying data with this tensor.\n     * \n     * @param {number} dim The index at which to insert the singleton dimension\n     * @returns The unsqueezed tensor\n     */\n    unsqueeze(dim = null) {\n        return new Tensor(\n            this.type,\n            this.data,\n            calc_unsqueeze_dims(this.dims, dim)\n        );\n    }\n\n    /**\n     * In-place version of @see {@link Tensor.unsqueeze}\n     */\n    unsqueeze_(dim = null) {\n        this.dims = calc_unsqueeze_dims(this.dims, dim);\n        return this;\n    }\n\n    /**\n     * In-place version of @see {@link Tensor.flatten}\n     */\n    flatten_(start_dim = 0, end_dim = -1) {\n        // TODO validate inputs\n        end_dim = (end_dim + this.dims.length) % this.dims.length;\n\n        let dimsToKeepBefore = this.dims.slice(0, start_dim);\n        let dimsToFlatten = this.dims.slice(start_dim, end_dim + 1);\n        let dimsToKeepAfter = this.dims.slice(end_dim + 1);\n\n        this.dims = [...dimsToKeepBefore, dimsToFlatten.reduce((a, b) => a * b, 1), ...dimsToKeepAfter]\n        return this;\n    }\n\n    /**\n     * Flattens input by reshaping it into a one-dimensional tensor.\n     * If `start_dim` or `end_dim` are passed, only dimensions starting with `start_dim`\n     * and ending with `end_dim` are flattened. The order of elements in input is unchanged.\n     * @param {number} start_dim the first dim to flatten\n     * @param {number} end_dim the last dim to flatten\n     * @returns The flattened tensor.\n     */\n    flatten(start_dim = 0, end_dim = -1) {\n        return this.clone().flatten_(start_dim, end_dim);\n    }\n\n    /**\n     * Returns a new tensor with the same data as the `self` tensor but of a different `shape`.\n     * @param  {...number} dims the desired size\n     * @returns {Tensor} The tensor with the same data but different shape\n     */\n    view(...dims) {\n        // TODO: validate dims\n        let inferredIndex = -1;\n        for (let i = 0; i < dims.length; ++i) {\n            if (dims[i] === -1) {\n                if (inferredIndex !== -1) {\n                    throw new Error(\"Only one dimension can be inferred\");\n                }\n                inferredIndex = i;\n            }\n        }\n\n        if (inferredIndex !== -1) {\n            // Some dimension must be inferred\n            const productOther = dims.reduce((product, curr, index) => {\n                return index !== inferredIndex ? product * curr : product\n            }, 1);\n\n            dims[inferredIndex] = this.data.length / productOther;\n        }\n        return new Tensor(this.type, this.data, dims); // NOTE: uses same underlying storage\n    }\n\n    neg_() {\n        for (let i = 0; i < this.data.length; ++i) {\n            this.data[i] = -this.data[i];\n        }\n        return this;\n    }\n    neg() {\n        return this.clone().neg_();\n    }\n\n    /**\n     * In-place version of @see {@link Tensor.clamp}\n     */\n    clamp_(min, max) {\n        for (let i = 0; i < this.data.length; ++i) {\n            this.data[i] = Math.min(Math.max(this.data[i], min), max);\n        }\n        return this;\n    }\n\n    /**\n     * Clamps all elements in input into the range [ min, max ]\n     * @param {number} min lower-bound of the range to be clamped to\n     * @param {number} max upper-bound of the range to be clamped to\n     * @returns the output tensor.\n     */\n    clamp(min, max) {\n        return this.clone().clamp_(min, max);\n    }\n\n    /**\n     * In-place version of @see {@link Tensor.round}\n     */\n    round_() {\n        for (let i = 0; i < this.data.length; ++i) {\n            this.data[i] = Math.round(this.data[i]);\n        }\n        return this;\n    }\n\n    /**\n     * Rounds elements of input to the nearest integer.\n     * @returns the output tensor.\n     */\n    round() {\n        return this.clone().round_();\n    }\n\n    /**\n     * Performs Tensor dtype conversion.\n     * @param {DataType} type The desired data type.\n     * @returns {Tensor} The converted tensor.\n     */\n    to(type) {\n        // If the self Tensor already has the correct dtype, then self is returned.\n        if (this.type === type) return this;\n\n        // Otherwise, the returned tensor is a copy of self with the desired dtype.\n        if (!DataTypeMap.hasOwnProperty(type)) {\n            throw new Error(`Unsupported type: ${type}`);\n        }\n        // @ts-ignore\n        return new Tensor(type, DataTypeMap[type].from(this.data), this.dims);\n    }\n}\n\n/**\n * This creates a nested array of a given type and depth (see examples).\n * \n * @example\n *   NestArray<string, 1>; // string[]\n * @example\n *   NestArray<number, 2>; // number[][]\n * @example\n *   NestArray<string, 3>; // string[][][] etc.\n * @template T\n * @template {number} Depth\n * @template {never[]} [Acc=[]]\n * @typedef {Acc['length'] extends Depth ? T : NestArray<T[], Depth, [...Acc, never]>} NestArray\n */\n\n/**\n * Reshapes a 1-dimensional array into an n-dimensional array, according to the provided dimensions.\n *\n * @example\n *   reshape([10                    ], [1      ]); // Type: number[]      Value: [10]\n *   reshape([1, 2, 3, 4            ], [2, 2   ]); // Type: number[][]    Value: [[1, 2], [3, 4]]\n *   reshape([1, 2, 3, 4, 5, 6, 7, 8], [2, 2, 2]); // Type: number[][][]  Value: [[[1, 2], [3, 4]], [[5, 6], [7, 8]]]\n *   reshape([1, 2, 3, 4, 5, 6, 7, 8], [4, 2   ]); // Type: number[][]    Value: [[1, 2], [3, 4], [5, 6], [7, 8]]\n * @param {T[]|DataArray} data The input array to reshape.\n * @param {DIM} dimensions The target shape/dimensions.\n * @template T\n * @template {[number]|number[]} DIM\n * @returns {NestArray<T, DIM[\"length\"]>} The reshaped array.\n */\nfunction reshape(data, dimensions) {\n\n    const totalElements = data.length;\n    const dimensionSize = dimensions.reduce((a, b) => a * b);\n\n    if (totalElements !== dimensionSize) {\n        throw Error(`cannot reshape array of size ${totalElements} into shape (${dimensions})`);\n    }\n\n    /** @type {any} */\n    let reshapedArray = data;\n\n    for (let i = dimensions.length - 1; i >= 0; i--) {\n        reshapedArray = reshapedArray.reduce((acc, val) => {\n            let lastArray = acc[acc.length - 1];\n\n            if (lastArray.length < dimensions[i]) {\n                lastArray.push(val);\n            } else {\n                acc.push([val]);\n            }\n\n            return acc;\n        }, [[]]);\n    }\n\n    return reshapedArray[0];\n}\n\n/**\n * Transposes a tensor according to the provided axes.\n * @param {any} tensor The input tensor to transpose.\n * @param {Array} axes The axes to transpose the tensor along.\n * @returns {Tensor} The transposed tensor.\n */\nfunction transpose(tensor, axes) {\n    const [transposedData, shape] = (0,_maths_js__WEBPACK_IMPORTED_MODULE_1__.transpose_data)(tensor.data, tensor.dims, axes);\n    return new Tensor(tensor.type, transposedData, shape);\n}\n\n\n/**\n * Interpolates an Tensor to the given size.\n * @param {Tensor} input The input tensor to interpolate. Data must be channel-first (i.e., [c, h, w])\n * @param {number[]} size The output size of the image\n * @param {string} mode The interpolation mode\n * @param {boolean} align_corners Whether to align corners.\n * @returns {Tensor} The interpolated tensor.\n */\nfunction interpolate(input, [out_height, out_width], mode = 'bilinear', align_corners = false) {\n\n    // Input image dimensions\n    const in_channels = input.dims.at(-3) ?? 1;\n    const in_height = input.dims.at(-2);\n    const in_width = input.dims.at(-1);\n\n    let output = (0,_maths_js__WEBPACK_IMPORTED_MODULE_1__.interpolate_data)(\n        /** @type {import('./maths.js').TypedArray}*/(input.data),\n        [in_channels, in_height, in_width],\n        [out_height, out_width],\n        mode,\n        align_corners\n    );\n    return new Tensor(input.type, output, [in_channels, out_height, out_width]);\n}\n\n/**\n * Perform mean pooling of the last hidden state followed by a normalization step.\n * @param {Tensor} last_hidden_state Tensor of shape [batchSize, seqLength, embedDim]\n * @param {Tensor} attention_mask Tensor of shape [batchSize, seqLength]\n * @returns {Tensor} Returns a new Tensor of shape [batchSize, embedDim].\n */\nfunction mean_pooling(last_hidden_state, attention_mask) {\n    // last_hidden_state: [batchSize, seqLength, embedDim]\n    // attention_mask:    [batchSize, seqLength]\n\n    let shape = [last_hidden_state.dims[0], last_hidden_state.dims[2]];\n    // @ts-ignore\n    let returnedData = new last_hidden_state.data.constructor(shape[0] * shape[1]);\n    let [batchSize, seqLength, embedDim] = last_hidden_state.dims;\n\n    let outIndex = 0;\n    for (let i = 0; i < batchSize; ++i) {\n        let offset = i * embedDim * seqLength;\n\n        for (let k = 0; k < embedDim; ++k) {\n            let sum = 0;\n            let count = 0;\n\n            let attnMaskOffset = i * seqLength;\n            let offset2 = offset + k;\n            // Pool over all words in sequence\n            for (let j = 0; j < seqLength; ++j) {\n                // index into attention mask\n                let attn = Number(attention_mask.data[attnMaskOffset + j]);\n\n                count += attn;\n                sum += last_hidden_state.data[offset2 + j * embedDim] * attn;\n            }\n\n            let avg = sum / count;\n            returnedData[outIndex++] = avg;\n        }\n    }\n\n    return new Tensor(\n        last_hidden_state.type,\n        returnedData,\n        shape\n    )\n}\n\n/**\n * Apply Layer Normalization for last certain number of dimensions.\n * @param {Tensor} input The input tensor\n * @param {number[]} normalized_shape input shape from an expected input of size\n * @param {Object} options The options for the layer normalization\n * @param {number} [options.eps=1e-5] A value added to the denominator for numerical stability.\n * @returns {Tensor} The normalized tensor.\n */\nfunction layer_norm(input, normalized_shape, {\n    eps = 1e-5,\n} = {}) {\n    if (input.dims.length !== 2) {\n        throw new Error('`layer_norm` currently only supports 2D input.');\n    }\n\n    const [batchSize, featureDim] = input.dims;\n\n    if (normalized_shape.length !== 1 && normalized_shape[0] !== featureDim) {\n        throw new Error('`normalized_shape` must be a 1D array with shape `[input.dims[1]]`.');\n    }\n\n    const [std, mean] = std_mean(input, 1, 0, true);\n\n    // @ts-ignore\n    const returnedData = new input.data.constructor(input.data.length);\n\n    for (let i = 0; i < batchSize; ++i) {\n        const offset = i * featureDim;\n        for (let j = 0; j < featureDim; ++j) {\n            const offset2 = offset + j;\n            returnedData[offset2] = (input.data[offset2] - mean.data[i]) / (std.data[i] + eps);\n        }\n    }\n    return new Tensor(input.type, returnedData, input.dims);\n}\n\n/**\n * Helper function to calculate new dimensions when performing a squeeze operation.\n * @param {number[]} dims The dimensions of the tensor.\n * @param {number|number[]|null} dim The dimension(s) to squeeze.\n * @returns The new dimensions.\n * @private\n */\nfunction calc_squeeze_dims(dims, dim) {\n    dims = dims.slice();\n    if (dim === null) {\n        dims = dims.filter((d) => d !== 1);\n    } else if (typeof dim === 'number') {\n        if (dims[dim] === 1) {\n            dims.splice(dim, 1);\n        }\n    } else if (Array.isArray(dim)) {\n        dims = dims.filter((x, i) => {\n            return x !== 1 || !dim.includes(i);\n        });\n    }\n    return dims;\n}\n\n/**\n * Helper function to calculate new dimensions when performing an unsqueeze operation.\n * @param {number[]} dims The dimensions of the tensor.\n * @param {number} dim The dimension to unsqueeze.\n * @returns The new dimensions.\n * @private\n */\nfunction calc_unsqueeze_dims(dims, dim) {\n    // Dimension out of range (e.g., \"expected to be in range of [-4, 3], but got 4\")\n    // + 1 since we allow inserting at the end (i.e. dim = -1)\n    dim = safeIndex(dim, dims.length + 1);\n    dims = dims.slice();\n    // Insert 1 into specified dimension\n    dims.splice(dim, 0, 1);\n    return dims;\n}\n\n/**\n * Safely calculate the index for an array of a given size, allowing negative indexing.\n * @param {number} index The index that will be used.\n * @param {number} size The size of the array.\n * @param {number} [dimension=null] The dimension that the index is for (optional).\n * @returns {number} The index, guaranteed to be non-negative and less than `arrayLength`.\n * \n * @throws {Error} If the index is out of range.\n * @private\n */\nfunction safeIndex(index, size, dimension = null) {\n    if (index < -size || index >= size) {\n        throw new Error(`IndexError: index ${index} is out of bounds for dimension${dimension === null ? '' : ' ' + dimension} with size ${size}`);\n    }\n\n    if (index < 0) {\n        // Negative indexing, ensuring positive index\n        index = ((index % size) + size) % size;\n    }\n    return index;\n}\n\n/**\n * Concatenates an array of tensors along a specified dimension.\n * @param {Tensor[]} tensors The array of tensors to concatenate.\n * @param {number} dim The dimension to concatenate along.\n * @returns {Tensor} The concatenated tensor.\n */\nfunction cat(tensors, dim = 0) {\n    dim = safeIndex(dim, tensors[0].dims.length);\n\n    // TODO do validation of shapes\n\n    const resultDims = tensors[0].dims.slice();\n    resultDims[dim] = tensors.reduce((a, b) => a + b.dims[dim], 0);\n\n    // Create a new array to store the accumulated values\n    const resultSize = resultDims.reduce((a, b) => a * b, 1);\n    // @ts-ignore\n    const result = new tensors[0].data.constructor(resultSize);\n\n    // Create output tensor of same type as first\n    const resultType = tensors[0].type;\n\n    if (dim === 0) {\n        // Handle special case for performance reasons\n\n        let offset = 0;\n        for (let t of tensors) {\n            result.set(t.data, offset);\n            offset += t.data.length;\n        }\n\n    } else {\n\n        let currentDim = 0;\n\n        for (let t = 0; t < tensors.length; ++t) {\n            let tensor = tensors[t];\n\n            // Iterate over the data array\n            for (let i = 0; i < tensor.data.length; ++i) {\n                // Calculate the index in the resulting array\n                let resultIndex = 0;\n\n                for (let j = tensor.dims.length - 1, num = i, resultMultiplier = 1; j >= 0; --j) {\n                    const size = tensor.dims[j];\n                    let index = num % size;\n                    if (j === dim) {\n                        index += currentDim;\n                    }\n                    resultIndex += index * resultMultiplier;\n                    resultMultiplier *= resultDims[j];\n                    num = Math.floor(num / size);\n                }\n                // Accumulate the value at the current index\n                result[resultIndex] = tensor.data[i];\n            }\n\n            currentDim += tensor.dims[dim];\n        }\n    }\n    return new Tensor(resultType, result, resultDims);\n}\n\n/**\n * Stack an array of tensors along a specified dimension.\n * @param {Tensor[]} tensors The array of tensors to stack.\n * @param {number} dim The dimension to stack along.\n * @returns {Tensor} The stacked tensor.\n */\nfunction stack(tensors, dim = 0) {\n    // TODO do validation of shapes\n    // NOTE: stack expects each tensor to be equal size\n    return cat(tensors.map(t => t.unsqueeze(dim)), dim);\n}\n\n\n/**\n * Calculates the standard deviation and mean over the dimensions specified by dim. dim can be a single dimension or `null` to reduce over all dimensions.\n * @param {Tensor} input the input tenso\n * @param {number|null} dim the dimension to reduce. If None, all dimensions are reduced.\n * @param {number} correction difference between the sample size and sample degrees of freedom. Defaults to Bessel's correction, correction=1.\n * @param {boolean} keepdim whether the output tensor has dim retained or not.\n * @returns {Tensor[]} A tuple of (std, mean) tensors.\n */\nfunction std_mean(input, dim = null, correction = 1, keepdim = false) {\n\n    if (dim === null) {\n        // None to reduce over all dimensions.\n        // @ts-ignore\n        const sum = input.data.reduce((a, b) => a + b, 0);\n        const mean = sum / input.data.length;\n        // @ts-ignore\n        const std = Math.sqrt(input.data.reduce((a, b) => a + (b - mean) ** 2, 0) / (input.data.length - correction));\n\n        const meanTensor = new Tensor(input.type, [mean], [/* scalar */]);\n        const stdTensor = new Tensor(input.type, [std], [/* scalar */]);\n\n        return [stdTensor, meanTensor];\n    }\n\n    // Negative indexing\n    dim = safeIndex(dim, input.dims.length);\n\n    const meanTensor = mean(input, dim, keepdim);\n\n    // Calculate the shape of the resulting array after summation\n    const resultDims = input.dims.slice(); // Copy the original dimensions\n    resultDims[dim] = 1; // Remove the specified axis\n\n    // Create a new array to store the accumulated values\n    // @ts-ignore\n    const result = new input.data.constructor(input.data.length / input.dims[dim]);\n\n    // Iterate over the data array\n    for (let i = 0; i < input.data.length; ++i) {\n\n        // Calculate the index in the resulting array\n        let resultIndex = 0;\n\n        for (let j = input.dims.length - 1, num = i, resultMultiplier = 1; j >= 0; --j) {\n            const size = input.dims[j];\n            if (j !== dim) {\n                const index = num % size;\n                resultIndex += index * resultMultiplier;\n                resultMultiplier *= resultDims[j];\n            }\n            num = Math.floor(num / size);\n        }\n\n        // Accumulate the value at the current index\n        result[resultIndex] += (input.data[i] - meanTensor.data[resultIndex]) ** 2;\n    }\n\n    for (let i = 0; i < result.length; ++i) {\n        result[i] = Math.sqrt(result[i] / (input.dims[dim] - correction));\n    }\n\n    if (!keepdim) {\n        resultDims.splice(dim, 1);\n    }\n\n    const stdTensor = new Tensor(input.type, result, resultDims);\n\n    return [stdTensor, meanTensor];\n}\n\n\n/**\n * Returns the mean value of each row of the input tensor in the given dimension dim.\n * @param {Tensor} input the input tensor.\n * @param {number|null} dim the dimension to reduce.\n * @param {boolean} keepdim whether the output tensor has dim retained or not.\n * @returns A new tensor with means taken along the specified dimension.\n */\nfunction mean(input, dim = null, keepdim = false) {\n\n    if (dim === null) {\n        // None to reduce over all dimensions.\n        // @ts-ignore\n        let val = input.data.reduce((a, b) => a + b, 0);\n        return new Tensor(input.type, [val / input.data.length], [/* scalar */]);\n    }\n\n    // Negative indexing\n    dim = safeIndex(dim, input.dims.length);\n\n    // Calculate the shape of the resulting array after summation\n    const resultDims = input.dims.slice(); // Copy the original dimensions\n    resultDims[dim] = 1; // Remove the specified axis\n\n    // Create a new array to store the accumulated values\n    // @ts-ignore\n    const result = new input.data.constructor(input.data.length / input.dims[dim]);\n\n    // Iterate over the data array\n    for (let i = 0; i < input.data.length; ++i) {\n\n        // Calculate the index in the resulting array\n        let resultIndex = 0;\n\n        for (let j = input.dims.length - 1, num = i, resultMultiplier = 1; j >= 0; --j) {\n            const size = input.dims[j];\n            if (j !== dim) {\n                const index = num % size;\n                resultIndex += index * resultMultiplier;\n                resultMultiplier *= resultDims[j];\n            }\n            num = Math.floor(num / size);\n        }\n\n        // Accumulate the value at the current index\n        result[resultIndex] += input.data[i];\n    }\n\n    if (input.dims[dim] !== 1) {\n        for (let i = 0; i < result.length; ++i) {\n            result[i] = result[i] / input.dims[dim];\n        }\n    }\n\n    if (!keepdim) {\n        resultDims.splice(dim, 1);\n    }\n\n    return new Tensor(input.type, result, resultDims);\n}\n\n\n/**\n *\n * Measures similarity between two temporal sequences (e.g., input audio and output tokens\n * to generate token-level timestamps).\n * @param {Tensor} matrix \n * @returns {number[][]}\n */\nfunction dynamicTimeWarping(matrix) {\n    const [output_length, input_length] = matrix.dims;\n\n    const outputShape = [output_length + 1, input_length + 1];\n\n    const cost = new Tensor(\n        'float32',\n        new Float32Array(outputShape[0] * outputShape[1]).fill(Infinity),\n        outputShape\n    );\n\n    const trace = new Tensor(\n        'float32',\n        new Float32Array(outputShape[0] * outputShape[1]).fill(-1),\n        outputShape\n    )\n\n    // same as `cost[0][0] = 0`;\n    cost[0].data[0] = 0;\n\n    for (let j = 1; j < input_length + 1; ++j) {\n        for (let i = 1; i < output_length + 1; ++i) {\n\n            const c0 = cost[i - 1][j - 1].item();\n            const c1 = cost[i - 1][j].item();\n            const c2 = cost[i][j - 1].item();\n\n            let c, t;\n            if (c0 < c1 && c0 < c2) {\n                c = c0;\n                t = 0;\n            } else if (c1 < c0 && c1 < c2) {\n                c = c1;\n                t = 1;\n            } else {\n                c = c2;\n                t = 2;\n            }\n\n            cost[i].data[j] = matrix[i - 1][j - 1].item() + c;\n            trace[i].data[j] = t;\n        }\n    }\n\n    // backtrace\n    let i = output_length;\n    let j = input_length;\n\n    // @ts-ignore\n    trace.data.fill(2, 0, outputShape[1]) // trace[0, :] = 2\n    for (let i = 0; i < outputShape[0]; ++i) { // trace[:, 0] = 1\n        trace[i].data[0] = 1;\n    }\n\n    let text_indices = [];\n    let time_indices = [];\n\n    while (i > 0 || j > 0) {\n        text_indices.push(i - 1);\n        time_indices.push(j - 1);\n\n        const t = trace[i][j].item();\n        switch (t) {\n            case 0:\n                --i; --j;\n                break;\n            case 1:\n                --i;\n                break;\n            case 2:\n                --j;\n                break;\n            default:\n                throw new Error(\n                    `Internal error in dynamic time warping. Unexpected trace[${i}, ${j}]. Please file a bug report.`\n                )\n        }\n    }\n\n    text_indices.reverse();\n    time_indices.reverse();\n\n    return [text_indices, time_indices];\n\n}\n\nfunction dimsToStride(dims) {\n    const stride = new Array(dims.length);\n    for (let i = dims.length - 1, s2 = 1; i >= 0; --i) {\n        stride[i] = s2;\n        s2 *= dims[i];\n    }\n    return stride;\n}\n\n/**\n * Returns a tensor filled with the scalar value 1, with the shape defined by the variable argument size.\n * @param {number[]} size A sequence of integers defining the shape of the output tensor.\n */\nfunction ones(size) {\n    const numElements = size.reduce((a, b) => a * b, 1);\n    return new Tensor(\n        'int64',\n        new BigInt64Array(numElements).fill(1n),\n        size\n    )\n}\n\n/**\n * Returns a tensor filled with the scalar value 1, with the same size as input.\n * @param {Tensor} tensor The size of input will determine size of the output tensor.\n * @returns The ones tensor.\n */\nfunction ones_like(tensor) {\n    return ones(tensor.dims);\n}\n\n\n//# sourceURL=webpack://semanticfinder/./node_modules/@xenova/transformers/src/utils/tensor.js?");

/***/ }),

/***/ "./node_modules/marked/lib/marked.esm.js":
/*!***********************************************!*\
  !*** ./node_modules/marked/lib/marked.esm.js ***!
  \***********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Hooks: () => (/* binding */ _Hooks),\n/* harmony export */   Lexer: () => (/* binding */ _Lexer),\n/* harmony export */   Marked: () => (/* binding */ Marked),\n/* harmony export */   Parser: () => (/* binding */ _Parser),\n/* harmony export */   Renderer: () => (/* binding */ _Renderer),\n/* harmony export */   TextRenderer: () => (/* binding */ _TextRenderer),\n/* harmony export */   Tokenizer: () => (/* binding */ _Tokenizer),\n/* harmony export */   defaults: () => (/* binding */ _defaults),\n/* harmony export */   getDefaults: () => (/* binding */ _getDefaults),\n/* harmony export */   lexer: () => (/* binding */ lexer),\n/* harmony export */   marked: () => (/* binding */ marked),\n/* harmony export */   options: () => (/* binding */ options),\n/* harmony export */   parse: () => (/* binding */ parse),\n/* harmony export */   parseInline: () => (/* binding */ parseInline),\n/* harmony export */   parser: () => (/* binding */ parser),\n/* harmony export */   setOptions: () => (/* binding */ setOptions),\n/* harmony export */   use: () => (/* binding */ use),\n/* harmony export */   walkTokens: () => (/* binding */ walkTokens)\n/* harmony export */ });\n/**\n * marked v12.0.1 - a markdown parser\n * Copyright (c) 2011-2024, Christopher Jeffrey. (MIT Licensed)\n * https://github.com/markedjs/marked\n */\n\n/**\n * DO NOT EDIT THIS FILE\n * The code in this file is generated from files in ./src/\n */\n\n/**\n * Gets the original marked default options.\n */\nfunction _getDefaults() {\n    return {\n        async: false,\n        breaks: false,\n        extensions: null,\n        gfm: true,\n        hooks: null,\n        pedantic: false,\n        renderer: null,\n        silent: false,\n        tokenizer: null,\n        walkTokens: null\n    };\n}\nlet _defaults = _getDefaults();\nfunction changeDefaults(newDefaults) {\n    _defaults = newDefaults;\n}\n\n/**\n * Helpers\n */\nconst escapeTest = /[&<>\"']/;\nconst escapeReplace = new RegExp(escapeTest.source, 'g');\nconst escapeTestNoEncode = /[<>\"']|&(?!(#\\d{1,7}|#[Xx][a-fA-F0-9]{1,6}|\\w+);)/;\nconst escapeReplaceNoEncode = new RegExp(escapeTestNoEncode.source, 'g');\nconst escapeReplacements = {\n    '&': '&amp;',\n    '<': '&lt;',\n    '>': '&gt;',\n    '\"': '&quot;',\n    \"'\": '&#39;'\n};\nconst getEscapeReplacement = (ch) => escapeReplacements[ch];\nfunction escape$1(html, encode) {\n    if (encode) {\n        if (escapeTest.test(html)) {\n            return html.replace(escapeReplace, getEscapeReplacement);\n        }\n    }\n    else {\n        if (escapeTestNoEncode.test(html)) {\n            return html.replace(escapeReplaceNoEncode, getEscapeReplacement);\n        }\n    }\n    return html;\n}\nconst unescapeTest = /&(#(?:\\d+)|(?:#x[0-9A-Fa-f]+)|(?:\\w+));?/ig;\nfunction unescape(html) {\n    // explicitly match decimal, hex, and named HTML entities\n    return html.replace(unescapeTest, (_, n) => {\n        n = n.toLowerCase();\n        if (n === 'colon')\n            return ':';\n        if (n.charAt(0) === '#') {\n            return n.charAt(1) === 'x'\n                ? String.fromCharCode(parseInt(n.substring(2), 16))\n                : String.fromCharCode(+n.substring(1));\n        }\n        return '';\n    });\n}\nconst caret = /(^|[^\\[])\\^/g;\nfunction edit(regex, opt) {\n    let source = typeof regex === 'string' ? regex : regex.source;\n    opt = opt || '';\n    const obj = {\n        replace: (name, val) => {\n            let valSource = typeof val === 'string' ? val : val.source;\n            valSource = valSource.replace(caret, '$1');\n            source = source.replace(name, valSource);\n            return obj;\n        },\n        getRegex: () => {\n            return new RegExp(source, opt);\n        }\n    };\n    return obj;\n}\nfunction cleanUrl(href) {\n    try {\n        href = encodeURI(href).replace(/%25/g, '%');\n    }\n    catch (e) {\n        return null;\n    }\n    return href;\n}\nconst noopTest = { exec: () => null };\nfunction splitCells(tableRow, count) {\n    // ensure that every cell-delimiting pipe has a space\n    // before it to distinguish it from an escaped pipe\n    const row = tableRow.replace(/\\|/g, (match, offset, str) => {\n        let escaped = false;\n        let curr = offset;\n        while (--curr >= 0 && str[curr] === '\\\\')\n            escaped = !escaped;\n        if (escaped) {\n            // odd number of slashes means | is escaped\n            // so we leave it alone\n            return '|';\n        }\n        else {\n            // add space before unescaped |\n            return ' |';\n        }\n    }), cells = row.split(/ \\|/);\n    let i = 0;\n    // First/last cell in a row cannot be empty if it has no leading/trailing pipe\n    if (!cells[0].trim()) {\n        cells.shift();\n    }\n    if (cells.length > 0 && !cells[cells.length - 1].trim()) {\n        cells.pop();\n    }\n    if (count) {\n        if (cells.length > count) {\n            cells.splice(count);\n        }\n        else {\n            while (cells.length < count)\n                cells.push('');\n        }\n    }\n    for (; i < cells.length; i++) {\n        // leading or trailing whitespace is ignored per the gfm spec\n        cells[i] = cells[i].trim().replace(/\\\\\\|/g, '|');\n    }\n    return cells;\n}\n/**\n * Remove trailing 'c's. Equivalent to str.replace(/c*$/, '').\n * /c*$/ is vulnerable to REDOS.\n *\n * @param str\n * @param c\n * @param invert Remove suffix of non-c chars instead. Default falsey.\n */\nfunction rtrim(str, c, invert) {\n    const l = str.length;\n    if (l === 0) {\n        return '';\n    }\n    // Length of suffix matching the invert condition.\n    let suffLen = 0;\n    // Step left until we fail to match the invert condition.\n    while (suffLen < l) {\n        const currChar = str.charAt(l - suffLen - 1);\n        if (currChar === c && !invert) {\n            suffLen++;\n        }\n        else if (currChar !== c && invert) {\n            suffLen++;\n        }\n        else {\n            break;\n        }\n    }\n    return str.slice(0, l - suffLen);\n}\nfunction findClosingBracket(str, b) {\n    if (str.indexOf(b[1]) === -1) {\n        return -1;\n    }\n    let level = 0;\n    for (let i = 0; i < str.length; i++) {\n        if (str[i] === '\\\\') {\n            i++;\n        }\n        else if (str[i] === b[0]) {\n            level++;\n        }\n        else if (str[i] === b[1]) {\n            level--;\n            if (level < 0) {\n                return i;\n            }\n        }\n    }\n    return -1;\n}\n\nfunction outputLink(cap, link, raw, lexer) {\n    const href = link.href;\n    const title = link.title ? escape$1(link.title) : null;\n    const text = cap[1].replace(/\\\\([\\[\\]])/g, '$1');\n    if (cap[0].charAt(0) !== '!') {\n        lexer.state.inLink = true;\n        const token = {\n            type: 'link',\n            raw,\n            href,\n            title,\n            text,\n            tokens: lexer.inlineTokens(text)\n        };\n        lexer.state.inLink = false;\n        return token;\n    }\n    return {\n        type: 'image',\n        raw,\n        href,\n        title,\n        text: escape$1(text)\n    };\n}\nfunction indentCodeCompensation(raw, text) {\n    const matchIndentToCode = raw.match(/^(\\s+)(?:```)/);\n    if (matchIndentToCode === null) {\n        return text;\n    }\n    const indentToCode = matchIndentToCode[1];\n    return text\n        .split('\\n')\n        .map(node => {\n        const matchIndentInNode = node.match(/^\\s+/);\n        if (matchIndentInNode === null) {\n            return node;\n        }\n        const [indentInNode] = matchIndentInNode;\n        if (indentInNode.length >= indentToCode.length) {\n            return node.slice(indentToCode.length);\n        }\n        return node;\n    })\n        .join('\\n');\n}\n/**\n * Tokenizer\n */\nclass _Tokenizer {\n    options;\n    rules; // set by the lexer\n    lexer; // set by the lexer\n    constructor(options) {\n        this.options = options || _defaults;\n    }\n    space(src) {\n        const cap = this.rules.block.newline.exec(src);\n        if (cap && cap[0].length > 0) {\n            return {\n                type: 'space',\n                raw: cap[0]\n            };\n        }\n    }\n    code(src) {\n        const cap = this.rules.block.code.exec(src);\n        if (cap) {\n            const text = cap[0].replace(/^ {1,4}/gm, '');\n            return {\n                type: 'code',\n                raw: cap[0],\n                codeBlockStyle: 'indented',\n                text: !this.options.pedantic\n                    ? rtrim(text, '\\n')\n                    : text\n            };\n        }\n    }\n    fences(src) {\n        const cap = this.rules.block.fences.exec(src);\n        if (cap) {\n            const raw = cap[0];\n            const text = indentCodeCompensation(raw, cap[3] || '');\n            return {\n                type: 'code',\n                raw,\n                lang: cap[2] ? cap[2].trim().replace(this.rules.inline.anyPunctuation, '$1') : cap[2],\n                text\n            };\n        }\n    }\n    heading(src) {\n        const cap = this.rules.block.heading.exec(src);\n        if (cap) {\n            let text = cap[2].trim();\n            // remove trailing #s\n            if (/#$/.test(text)) {\n                const trimmed = rtrim(text, '#');\n                if (this.options.pedantic) {\n                    text = trimmed.trim();\n                }\n                else if (!trimmed || / $/.test(trimmed)) {\n                    // CommonMark requires space before trailing #s\n                    text = trimmed.trim();\n                }\n            }\n            return {\n                type: 'heading',\n                raw: cap[0],\n                depth: cap[1].length,\n                text,\n                tokens: this.lexer.inline(text)\n            };\n        }\n    }\n    hr(src) {\n        const cap = this.rules.block.hr.exec(src);\n        if (cap) {\n            return {\n                type: 'hr',\n                raw: cap[0]\n            };\n        }\n    }\n    blockquote(src) {\n        const cap = this.rules.block.blockquote.exec(src);\n        if (cap) {\n            const text = rtrim(cap[0].replace(/^ *>[ \\t]?/gm, ''), '\\n');\n            const top = this.lexer.state.top;\n            this.lexer.state.top = true;\n            const tokens = this.lexer.blockTokens(text);\n            this.lexer.state.top = top;\n            return {\n                type: 'blockquote',\n                raw: cap[0],\n                tokens,\n                text\n            };\n        }\n    }\n    list(src) {\n        let cap = this.rules.block.list.exec(src);\n        if (cap) {\n            let bull = cap[1].trim();\n            const isordered = bull.length > 1;\n            const list = {\n                type: 'list',\n                raw: '',\n                ordered: isordered,\n                start: isordered ? +bull.slice(0, -1) : '',\n                loose: false,\n                items: []\n            };\n            bull = isordered ? `\\\\d{1,9}\\\\${bull.slice(-1)}` : `\\\\${bull}`;\n            if (this.options.pedantic) {\n                bull = isordered ? bull : '[*+-]';\n            }\n            // Get next list item\n            const itemRegex = new RegExp(`^( {0,3}${bull})((?:[\\t ][^\\\\n]*)?(?:\\\\n|$))`);\n            let raw = '';\n            let itemContents = '';\n            let endsWithBlankLine = false;\n            // Check if current bullet point can start a new List Item\n            while (src) {\n                let endEarly = false;\n                if (!(cap = itemRegex.exec(src))) {\n                    break;\n                }\n                if (this.rules.block.hr.test(src)) { // End list if bullet was actually HR (possibly move into itemRegex?)\n                    break;\n                }\n                raw = cap[0];\n                src = src.substring(raw.length);\n                let line = cap[2].split('\\n', 1)[0].replace(/^\\t+/, (t) => ' '.repeat(3 * t.length));\n                let nextLine = src.split('\\n', 1)[0];\n                let indent = 0;\n                if (this.options.pedantic) {\n                    indent = 2;\n                    itemContents = line.trimStart();\n                }\n                else {\n                    indent = cap[2].search(/[^ ]/); // Find first non-space char\n                    indent = indent > 4 ? 1 : indent; // Treat indented code blocks (> 4 spaces) as having only 1 indent\n                    itemContents = line.slice(indent);\n                    indent += cap[1].length;\n                }\n                let blankLine = false;\n                if (!line && /^ *$/.test(nextLine)) { // Items begin with at most one blank line\n                    raw += nextLine + '\\n';\n                    src = src.substring(nextLine.length + 1);\n                    endEarly = true;\n                }\n                if (!endEarly) {\n                    const nextBulletRegex = new RegExp(`^ {0,${Math.min(3, indent - 1)}}(?:[*+-]|\\\\d{1,9}[.)])((?:[ \\t][^\\\\n]*)?(?:\\\\n|$))`);\n                    const hrRegex = new RegExp(`^ {0,${Math.min(3, indent - 1)}}((?:- *){3,}|(?:_ *){3,}|(?:\\\\* *){3,})(?:\\\\n+|$)`);\n                    const fencesBeginRegex = new RegExp(`^ {0,${Math.min(3, indent - 1)}}(?:\\`\\`\\`|~~~)`);\n                    const headingBeginRegex = new RegExp(`^ {0,${Math.min(3, indent - 1)}}#`);\n                    // Check if following lines should be included in List Item\n                    while (src) {\n                        const rawLine = src.split('\\n', 1)[0];\n                        nextLine = rawLine;\n                        // Re-align to follow commonmark nesting rules\n                        if (this.options.pedantic) {\n                            nextLine = nextLine.replace(/^ {1,4}(?=( {4})*[^ ])/g, '  ');\n                        }\n                        // End list item if found code fences\n                        if (fencesBeginRegex.test(nextLine)) {\n                            break;\n                        }\n                        // End list item if found start of new heading\n                        if (headingBeginRegex.test(nextLine)) {\n                            break;\n                        }\n                        // End list item if found start of new bullet\n                        if (nextBulletRegex.test(nextLine)) {\n                            break;\n                        }\n                        // Horizontal rule found\n                        if (hrRegex.test(src)) {\n                            break;\n                        }\n                        if (nextLine.search(/[^ ]/) >= indent || !nextLine.trim()) { // Dedent if possible\n                            itemContents += '\\n' + nextLine.slice(indent);\n                        }\n                        else {\n                            // not enough indentation\n                            if (blankLine) {\n                                break;\n                            }\n                            // paragraph continuation unless last line was a different block level element\n                            if (line.search(/[^ ]/) >= 4) { // indented code block\n                                break;\n                            }\n                            if (fencesBeginRegex.test(line)) {\n                                break;\n                            }\n                            if (headingBeginRegex.test(line)) {\n                                break;\n                            }\n                            if (hrRegex.test(line)) {\n                                break;\n                            }\n                            itemContents += '\\n' + nextLine;\n                        }\n                        if (!blankLine && !nextLine.trim()) { // Check if current line is blank\n                            blankLine = true;\n                        }\n                        raw += rawLine + '\\n';\n                        src = src.substring(rawLine.length + 1);\n                        line = nextLine.slice(indent);\n                    }\n                }\n                if (!list.loose) {\n                    // If the previous item ended with a blank line, the list is loose\n                    if (endsWithBlankLine) {\n                        list.loose = true;\n                    }\n                    else if (/\\n *\\n *$/.test(raw)) {\n                        endsWithBlankLine = true;\n                    }\n                }\n                let istask = null;\n                let ischecked;\n                // Check for task list items\n                if (this.options.gfm) {\n                    istask = /^\\[[ xX]\\] /.exec(itemContents);\n                    if (istask) {\n                        ischecked = istask[0] !== '[ ] ';\n                        itemContents = itemContents.replace(/^\\[[ xX]\\] +/, '');\n                    }\n                }\n                list.items.push({\n                    type: 'list_item',\n                    raw,\n                    task: !!istask,\n                    checked: ischecked,\n                    loose: false,\n                    text: itemContents,\n                    tokens: []\n                });\n                list.raw += raw;\n            }\n            // Do not consume newlines at end of final item. Alternatively, make itemRegex *start* with any newlines to simplify/speed up endsWithBlankLine logic\n            list.items[list.items.length - 1].raw = raw.trimEnd();\n            (list.items[list.items.length - 1]).text = itemContents.trimEnd();\n            list.raw = list.raw.trimEnd();\n            // Item child tokens handled here at end because we needed to have the final item to trim it first\n            for (let i = 0; i < list.items.length; i++) {\n                this.lexer.state.top = false;\n                list.items[i].tokens = this.lexer.blockTokens(list.items[i].text, []);\n                if (!list.loose) {\n                    // Check if list should be loose\n                    const spacers = list.items[i].tokens.filter(t => t.type === 'space');\n                    const hasMultipleLineBreaks = spacers.length > 0 && spacers.some(t => /\\n.*\\n/.test(t.raw));\n                    list.loose = hasMultipleLineBreaks;\n                }\n            }\n            // Set all items to loose if list is loose\n            if (list.loose) {\n                for (let i = 0; i < list.items.length; i++) {\n                    list.items[i].loose = true;\n                }\n            }\n            return list;\n        }\n    }\n    html(src) {\n        const cap = this.rules.block.html.exec(src);\n        if (cap) {\n            const token = {\n                type: 'html',\n                block: true,\n                raw: cap[0],\n                pre: cap[1] === 'pre' || cap[1] === 'script' || cap[1] === 'style',\n                text: cap[0]\n            };\n            return token;\n        }\n    }\n    def(src) {\n        const cap = this.rules.block.def.exec(src);\n        if (cap) {\n            const tag = cap[1].toLowerCase().replace(/\\s+/g, ' ');\n            const href = cap[2] ? cap[2].replace(/^<(.*)>$/, '$1').replace(this.rules.inline.anyPunctuation, '$1') : '';\n            const title = cap[3] ? cap[3].substring(1, cap[3].length - 1).replace(this.rules.inline.anyPunctuation, '$1') : cap[3];\n            return {\n                type: 'def',\n                tag,\n                raw: cap[0],\n                href,\n                title\n            };\n        }\n    }\n    table(src) {\n        const cap = this.rules.block.table.exec(src);\n        if (!cap) {\n            return;\n        }\n        if (!/[:|]/.test(cap[2])) {\n            // delimiter row must have a pipe (|) or colon (:) otherwise it is a setext heading\n            return;\n        }\n        const headers = splitCells(cap[1]);\n        const aligns = cap[2].replace(/^\\||\\| *$/g, '').split('|');\n        const rows = cap[3] && cap[3].trim() ? cap[3].replace(/\\n[ \\t]*$/, '').split('\\n') : [];\n        const item = {\n            type: 'table',\n            raw: cap[0],\n            header: [],\n            align: [],\n            rows: []\n        };\n        if (headers.length !== aligns.length) {\n            // header and align columns must be equal, rows can be different.\n            return;\n        }\n        for (const align of aligns) {\n            if (/^ *-+: *$/.test(align)) {\n                item.align.push('right');\n            }\n            else if (/^ *:-+: *$/.test(align)) {\n                item.align.push('center');\n            }\n            else if (/^ *:-+ *$/.test(align)) {\n                item.align.push('left');\n            }\n            else {\n                item.align.push(null);\n            }\n        }\n        for (const header of headers) {\n            item.header.push({\n                text: header,\n                tokens: this.lexer.inline(header)\n            });\n        }\n        for (const row of rows) {\n            item.rows.push(splitCells(row, item.header.length).map(cell => {\n                return {\n                    text: cell,\n                    tokens: this.lexer.inline(cell)\n                };\n            }));\n        }\n        return item;\n    }\n    lheading(src) {\n        const cap = this.rules.block.lheading.exec(src);\n        if (cap) {\n            return {\n                type: 'heading',\n                raw: cap[0],\n                depth: cap[2].charAt(0) === '=' ? 1 : 2,\n                text: cap[1],\n                tokens: this.lexer.inline(cap[1])\n            };\n        }\n    }\n    paragraph(src) {\n        const cap = this.rules.block.paragraph.exec(src);\n        if (cap) {\n            const text = cap[1].charAt(cap[1].length - 1) === '\\n'\n                ? cap[1].slice(0, -1)\n                : cap[1];\n            return {\n                type: 'paragraph',\n                raw: cap[0],\n                text,\n                tokens: this.lexer.inline(text)\n            };\n        }\n    }\n    text(src) {\n        const cap = this.rules.block.text.exec(src);\n        if (cap) {\n            return {\n                type: 'text',\n                raw: cap[0],\n                text: cap[0],\n                tokens: this.lexer.inline(cap[0])\n            };\n        }\n    }\n    escape(src) {\n        const cap = this.rules.inline.escape.exec(src);\n        if (cap) {\n            return {\n                type: 'escape',\n                raw: cap[0],\n                text: escape$1(cap[1])\n            };\n        }\n    }\n    tag(src) {\n        const cap = this.rules.inline.tag.exec(src);\n        if (cap) {\n            if (!this.lexer.state.inLink && /^<a /i.test(cap[0])) {\n                this.lexer.state.inLink = true;\n            }\n            else if (this.lexer.state.inLink && /^<\\/a>/i.test(cap[0])) {\n                this.lexer.state.inLink = false;\n            }\n            if (!this.lexer.state.inRawBlock && /^<(pre|code|kbd|script)(\\s|>)/i.test(cap[0])) {\n                this.lexer.state.inRawBlock = true;\n            }\n            else if (this.lexer.state.inRawBlock && /^<\\/(pre|code|kbd|script)(\\s|>)/i.test(cap[0])) {\n                this.lexer.state.inRawBlock = false;\n            }\n            return {\n                type: 'html',\n                raw: cap[0],\n                inLink: this.lexer.state.inLink,\n                inRawBlock: this.lexer.state.inRawBlock,\n                block: false,\n                text: cap[0]\n            };\n        }\n    }\n    link(src) {\n        const cap = this.rules.inline.link.exec(src);\n        if (cap) {\n            const trimmedUrl = cap[2].trim();\n            if (!this.options.pedantic && /^</.test(trimmedUrl)) {\n                // commonmark requires matching angle brackets\n                if (!(/>$/.test(trimmedUrl))) {\n                    return;\n                }\n                // ending angle bracket cannot be escaped\n                const rtrimSlash = rtrim(trimmedUrl.slice(0, -1), '\\\\');\n                if ((trimmedUrl.length - rtrimSlash.length) % 2 === 0) {\n                    return;\n                }\n            }\n            else {\n                // find closing parenthesis\n                const lastParenIndex = findClosingBracket(cap[2], '()');\n                if (lastParenIndex > -1) {\n                    const start = cap[0].indexOf('!') === 0 ? 5 : 4;\n                    const linkLen = start + cap[1].length + lastParenIndex;\n                    cap[2] = cap[2].substring(0, lastParenIndex);\n                    cap[0] = cap[0].substring(0, linkLen).trim();\n                    cap[3] = '';\n                }\n            }\n            let href = cap[2];\n            let title = '';\n            if (this.options.pedantic) {\n                // split pedantic href and title\n                const link = /^([^'\"]*[^\\s])\\s+(['\"])(.*)\\2/.exec(href);\n                if (link) {\n                    href = link[1];\n                    title = link[3];\n                }\n            }\n            else {\n                title = cap[3] ? cap[3].slice(1, -1) : '';\n            }\n            href = href.trim();\n            if (/^</.test(href)) {\n                if (this.options.pedantic && !(/>$/.test(trimmedUrl))) {\n                    // pedantic allows starting angle bracket without ending angle bracket\n                    href = href.slice(1);\n                }\n                else {\n                    href = href.slice(1, -1);\n                }\n            }\n            return outputLink(cap, {\n                href: href ? href.replace(this.rules.inline.anyPunctuation, '$1') : href,\n                title: title ? title.replace(this.rules.inline.anyPunctuation, '$1') : title\n            }, cap[0], this.lexer);\n        }\n    }\n    reflink(src, links) {\n        let cap;\n        if ((cap = this.rules.inline.reflink.exec(src))\n            || (cap = this.rules.inline.nolink.exec(src))) {\n            const linkString = (cap[2] || cap[1]).replace(/\\s+/g, ' ');\n            const link = links[linkString.toLowerCase()];\n            if (!link) {\n                const text = cap[0].charAt(0);\n                return {\n                    type: 'text',\n                    raw: text,\n                    text\n                };\n            }\n            return outputLink(cap, link, cap[0], this.lexer);\n        }\n    }\n    emStrong(src, maskedSrc, prevChar = '') {\n        let match = this.rules.inline.emStrongLDelim.exec(src);\n        if (!match)\n            return;\n        // _ can't be between two alphanumerics. \\p{L}\\p{N} includes non-english alphabet/numbers as well\n        if (match[3] && prevChar.match(/[\\p{L}\\p{N}]/u))\n            return;\n        const nextChar = match[1] || match[2] || '';\n        if (!nextChar || !prevChar || this.rules.inline.punctuation.exec(prevChar)) {\n            // unicode Regex counts emoji as 1 char; spread into array for proper count (used multiple times below)\n            const lLength = [...match[0]].length - 1;\n            let rDelim, rLength, delimTotal = lLength, midDelimTotal = 0;\n            const endReg = match[0][0] === '*' ? this.rules.inline.emStrongRDelimAst : this.rules.inline.emStrongRDelimUnd;\n            endReg.lastIndex = 0;\n            // Clip maskedSrc to same section of string as src (move to lexer?)\n            maskedSrc = maskedSrc.slice(-1 * src.length + lLength);\n            while ((match = endReg.exec(maskedSrc)) != null) {\n                rDelim = match[1] || match[2] || match[3] || match[4] || match[5] || match[6];\n                if (!rDelim)\n                    continue; // skip single * in __abc*abc__\n                rLength = [...rDelim].length;\n                if (match[3] || match[4]) { // found another Left Delim\n                    delimTotal += rLength;\n                    continue;\n                }\n                else if (match[5] || match[6]) { // either Left or Right Delim\n                    if (lLength % 3 && !((lLength + rLength) % 3)) {\n                        midDelimTotal += rLength;\n                        continue; // CommonMark Emphasis Rules 9-10\n                    }\n                }\n                delimTotal -= rLength;\n                if (delimTotal > 0)\n                    continue; // Haven't found enough closing delimiters\n                // Remove extra characters. *a*** -> *a*\n                rLength = Math.min(rLength, rLength + delimTotal + midDelimTotal);\n                // char length can be >1 for unicode characters;\n                const lastCharLength = [...match[0]][0].length;\n                const raw = src.slice(0, lLength + match.index + lastCharLength + rLength);\n                // Create `em` if smallest delimiter has odd char count. *a***\n                if (Math.min(lLength, rLength) % 2) {\n                    const text = raw.slice(1, -1);\n                    return {\n                        type: 'em',\n                        raw,\n                        text,\n                        tokens: this.lexer.inlineTokens(text)\n                    };\n                }\n                // Create 'strong' if smallest delimiter has even char count. **a***\n                const text = raw.slice(2, -2);\n                return {\n                    type: 'strong',\n                    raw,\n                    text,\n                    tokens: this.lexer.inlineTokens(text)\n                };\n            }\n        }\n    }\n    codespan(src) {\n        const cap = this.rules.inline.code.exec(src);\n        if (cap) {\n            let text = cap[2].replace(/\\n/g, ' ');\n            const hasNonSpaceChars = /[^ ]/.test(text);\n            const hasSpaceCharsOnBothEnds = /^ /.test(text) && / $/.test(text);\n            if (hasNonSpaceChars && hasSpaceCharsOnBothEnds) {\n                text = text.substring(1, text.length - 1);\n            }\n            text = escape$1(text, true);\n            return {\n                type: 'codespan',\n                raw: cap[0],\n                text\n            };\n        }\n    }\n    br(src) {\n        const cap = this.rules.inline.br.exec(src);\n        if (cap) {\n            return {\n                type: 'br',\n                raw: cap[0]\n            };\n        }\n    }\n    del(src) {\n        const cap = this.rules.inline.del.exec(src);\n        if (cap) {\n            return {\n                type: 'del',\n                raw: cap[0],\n                text: cap[2],\n                tokens: this.lexer.inlineTokens(cap[2])\n            };\n        }\n    }\n    autolink(src) {\n        const cap = this.rules.inline.autolink.exec(src);\n        if (cap) {\n            let text, href;\n            if (cap[2] === '@') {\n                text = escape$1(cap[1]);\n                href = 'mailto:' + text;\n            }\n            else {\n                text = escape$1(cap[1]);\n                href = text;\n            }\n            return {\n                type: 'link',\n                raw: cap[0],\n                text,\n                href,\n                tokens: [\n                    {\n                        type: 'text',\n                        raw: text,\n                        text\n                    }\n                ]\n            };\n        }\n    }\n    url(src) {\n        let cap;\n        if (cap = this.rules.inline.url.exec(src)) {\n            let text, href;\n            if (cap[2] === '@') {\n                text = escape$1(cap[0]);\n                href = 'mailto:' + text;\n            }\n            else {\n                // do extended autolink path validation\n                let prevCapZero;\n                do {\n                    prevCapZero = cap[0];\n                    cap[0] = this.rules.inline._backpedal.exec(cap[0])?.[0] ?? '';\n                } while (prevCapZero !== cap[0]);\n                text = escape$1(cap[0]);\n                if (cap[1] === 'www.') {\n                    href = 'http://' + cap[0];\n                }\n                else {\n                    href = cap[0];\n                }\n            }\n            return {\n                type: 'link',\n                raw: cap[0],\n                text,\n                href,\n                tokens: [\n                    {\n                        type: 'text',\n                        raw: text,\n                        text\n                    }\n                ]\n            };\n        }\n    }\n    inlineText(src) {\n        const cap = this.rules.inline.text.exec(src);\n        if (cap) {\n            let text;\n            if (this.lexer.state.inRawBlock) {\n                text = cap[0];\n            }\n            else {\n                text = escape$1(cap[0]);\n            }\n            return {\n                type: 'text',\n                raw: cap[0],\n                text\n            };\n        }\n    }\n}\n\n/**\n * Block-Level Grammar\n */\nconst newline = /^(?: *(?:\\n|$))+/;\nconst blockCode = /^( {4}[^\\n]+(?:\\n(?: *(?:\\n|$))*)?)+/;\nconst fences = /^ {0,3}(`{3,}(?=[^`\\n]*(?:\\n|$))|~{3,})([^\\n]*)(?:\\n|$)(?:|([\\s\\S]*?)(?:\\n|$))(?: {0,3}\\1[~`]* *(?=\\n|$)|$)/;\nconst hr = /^ {0,3}((?:-[\\t ]*){3,}|(?:_[ \\t]*){3,}|(?:\\*[ \\t]*){3,})(?:\\n+|$)/;\nconst heading = /^ {0,3}(#{1,6})(?=\\s|$)(.*)(?:\\n+|$)/;\nconst bullet = /(?:[*+-]|\\d{1,9}[.)])/;\nconst lheading = edit(/^(?!bull |blockCode|fences|blockquote|heading|html)((?:.|\\n(?!\\s*?\\n|bull |blockCode|fences|blockquote|heading|html))+?)\\n {0,3}(=+|-+) *(?:\\n+|$)/)\n    .replace(/bull/g, bullet) // lists can interrupt\n    .replace(/blockCode/g, / {4}/) // indented code blocks can interrupt\n    .replace(/fences/g, / {0,3}(?:`{3,}|~{3,})/) // fenced code blocks can interrupt\n    .replace(/blockquote/g, / {0,3}>/) // blockquote can interrupt\n    .replace(/heading/g, / {0,3}#{1,6}/) // ATX heading can interrupt\n    .replace(/html/g, / {0,3}<[^\\n>]+>\\n/) // block html can interrupt\n    .getRegex();\nconst _paragraph = /^([^\\n]+(?:\\n(?!hr|heading|lheading|blockquote|fences|list|html|table| +\\n)[^\\n]+)*)/;\nconst blockText = /^[^\\n]+/;\nconst _blockLabel = /(?!\\s*\\])(?:\\\\.|[^\\[\\]\\\\])+/;\nconst def = edit(/^ {0,3}\\[(label)\\]: *(?:\\n *)?([^<\\s][^\\s]*|<.*?>)(?:(?: +(?:\\n *)?| *\\n *)(title))? *(?:\\n+|$)/)\n    .replace('label', _blockLabel)\n    .replace('title', /(?:\"(?:\\\\\"?|[^\"\\\\])*\"|'[^'\\n]*(?:\\n[^'\\n]+)*\\n?'|\\([^()]*\\))/)\n    .getRegex();\nconst list = edit(/^( {0,3}bull)([ \\t][^\\n]+?)?(?:\\n|$)/)\n    .replace(/bull/g, bullet)\n    .getRegex();\nconst _tag = 'address|article|aside|base|basefont|blockquote|body|caption'\n    + '|center|col|colgroup|dd|details|dialog|dir|div|dl|dt|fieldset|figcaption'\n    + '|figure|footer|form|frame|frameset|h[1-6]|head|header|hr|html|iframe'\n    + '|legend|li|link|main|menu|menuitem|meta|nav|noframes|ol|optgroup|option'\n    + '|p|param|search|section|summary|table|tbody|td|tfoot|th|thead|title'\n    + '|tr|track|ul';\nconst _comment = /<!--(?:-?>|[\\s\\S]*?(?:-->|$))/;\nconst html = edit('^ {0,3}(?:' // optional indentation\n    + '<(script|pre|style|textarea)[\\\\s>][\\\\s\\\\S]*?(?:</\\\\1>[^\\\\n]*\\\\n+|$)' // (1)\n    + '|comment[^\\\\n]*(\\\\n+|$)' // (2)\n    + '|<\\\\?[\\\\s\\\\S]*?(?:\\\\?>\\\\n*|$)' // (3)\n    + '|<![A-Z][\\\\s\\\\S]*?(?:>\\\\n*|$)' // (4)\n    + '|<!\\\\[CDATA\\\\[[\\\\s\\\\S]*?(?:\\\\]\\\\]>\\\\n*|$)' // (5)\n    + '|</?(tag)(?: +|\\\\n|/?>)[\\\\s\\\\S]*?(?:(?:\\\\n *)+\\\\n|$)' // (6)\n    + '|<(?!script|pre|style|textarea)([a-z][\\\\w-]*)(?:attribute)*? */?>(?=[ \\\\t]*(?:\\\\n|$))[\\\\s\\\\S]*?(?:(?:\\\\n *)+\\\\n|$)' // (7) open tag\n    + '|</(?!script|pre|style|textarea)[a-z][\\\\w-]*\\\\s*>(?=[ \\\\t]*(?:\\\\n|$))[\\\\s\\\\S]*?(?:(?:\\\\n *)+\\\\n|$)' // (7) closing tag\n    + ')', 'i')\n    .replace('comment', _comment)\n    .replace('tag', _tag)\n    .replace('attribute', / +[a-zA-Z:_][\\w.:-]*(?: *= *\"[^\"\\n]*\"| *= *'[^'\\n]*'| *= *[^\\s\"'=<>`]+)?/)\n    .getRegex();\nconst paragraph = edit(_paragraph)\n    .replace('hr', hr)\n    .replace('heading', ' {0,3}#{1,6}(?:\\\\s|$)')\n    .replace('|lheading', '') // setex headings don't interrupt commonmark paragraphs\n    .replace('|table', '')\n    .replace('blockquote', ' {0,3}>')\n    .replace('fences', ' {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n')\n    .replace('list', ' {0,3}(?:[*+-]|1[.)]) ') // only lists starting from 1 can interrupt\n    .replace('html', '</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)')\n    .replace('tag', _tag) // pars can be interrupted by type (6) html blocks\n    .getRegex();\nconst blockquote = edit(/^( {0,3}> ?(paragraph|[^\\n]*)(?:\\n|$))+/)\n    .replace('paragraph', paragraph)\n    .getRegex();\n/**\n * Normal Block Grammar\n */\nconst blockNormal = {\n    blockquote,\n    code: blockCode,\n    def,\n    fences,\n    heading,\n    hr,\n    html,\n    lheading,\n    list,\n    newline,\n    paragraph,\n    table: noopTest,\n    text: blockText\n};\n/**\n * GFM Block Grammar\n */\nconst gfmTable = edit('^ *([^\\\\n ].*)\\\\n' // Header\n    + ' {0,3}((?:\\\\| *)?:?-+:? *(?:\\\\| *:?-+:? *)*(?:\\\\| *)?)' // Align\n    + '(?:\\\\n((?:(?! *\\\\n|hr|heading|blockquote|code|fences|list|html).*(?:\\\\n|$))*)\\\\n*|$)') // Cells\n    .replace('hr', hr)\n    .replace('heading', ' {0,3}#{1,6}(?:\\\\s|$)')\n    .replace('blockquote', ' {0,3}>')\n    .replace('code', ' {4}[^\\\\n]')\n    .replace('fences', ' {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n')\n    .replace('list', ' {0,3}(?:[*+-]|1[.)]) ') // only lists starting from 1 can interrupt\n    .replace('html', '</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)')\n    .replace('tag', _tag) // tables can be interrupted by type (6) html blocks\n    .getRegex();\nconst blockGfm = {\n    ...blockNormal,\n    table: gfmTable,\n    paragraph: edit(_paragraph)\n        .replace('hr', hr)\n        .replace('heading', ' {0,3}#{1,6}(?:\\\\s|$)')\n        .replace('|lheading', '') // setex headings don't interrupt commonmark paragraphs\n        .replace('table', gfmTable) // interrupt paragraphs with table\n        .replace('blockquote', ' {0,3}>')\n        .replace('fences', ' {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n')\n        .replace('list', ' {0,3}(?:[*+-]|1[.)]) ') // only lists starting from 1 can interrupt\n        .replace('html', '</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)')\n        .replace('tag', _tag) // pars can be interrupted by type (6) html blocks\n        .getRegex()\n};\n/**\n * Pedantic grammar (original John Gruber's loose markdown specification)\n */\nconst blockPedantic = {\n    ...blockNormal,\n    html: edit('^ *(?:comment *(?:\\\\n|\\\\s*$)'\n        + '|<(tag)[\\\\s\\\\S]+?</\\\\1> *(?:\\\\n{2,}|\\\\s*$)' // closed tag\n        + '|<tag(?:\"[^\"]*\"|\\'[^\\']*\\'|\\\\s[^\\'\"/>\\\\s]*)*?/?> *(?:\\\\n{2,}|\\\\s*$))')\n        .replace('comment', _comment)\n        .replace(/tag/g, '(?!(?:'\n        + 'a|em|strong|small|s|cite|q|dfn|abbr|data|time|code|var|samp|kbd|sub'\n        + '|sup|i|b|u|mark|ruby|rt|rp|bdi|bdo|span|br|wbr|ins|del|img)'\n        + '\\\\b)\\\\w+(?!:|[^\\\\w\\\\s@]*@)\\\\b')\n        .getRegex(),\n    def: /^ *\\[([^\\]]+)\\]: *<?([^\\s>]+)>?(?: +([\"(][^\\n]+[\")]))? *(?:\\n+|$)/,\n    heading: /^(#{1,6})(.*)(?:\\n+|$)/,\n    fences: noopTest, // fences not supported\n    lheading: /^(.+?)\\n {0,3}(=+|-+) *(?:\\n+|$)/,\n    paragraph: edit(_paragraph)\n        .replace('hr', hr)\n        .replace('heading', ' *#{1,6} *[^\\n]')\n        .replace('lheading', lheading)\n        .replace('|table', '')\n        .replace('blockquote', ' {0,3}>')\n        .replace('|fences', '')\n        .replace('|list', '')\n        .replace('|html', '')\n        .replace('|tag', '')\n        .getRegex()\n};\n/**\n * Inline-Level Grammar\n */\nconst escape = /^\\\\([!\"#$%&'()*+,\\-./:;<=>?@\\[\\]\\\\^_`{|}~])/;\nconst inlineCode = /^(`+)([^`]|[^`][\\s\\S]*?[^`])\\1(?!`)/;\nconst br = /^( {2,}|\\\\)\\n(?!\\s*$)/;\nconst inlineText = /^(`+|[^`])(?:(?= {2,}\\n)|[\\s\\S]*?(?:(?=[\\\\<!\\[`*_]|\\b_|$)|[^ ](?= {2,}\\n)))/;\n// list of unicode punctuation marks, plus any missing characters from CommonMark spec\nconst _punctuation = '\\\\p{P}\\\\p{S}';\nconst punctuation = edit(/^((?![*_])[\\spunctuation])/, 'u')\n    .replace(/punctuation/g, _punctuation).getRegex();\n// sequences em should skip over [title](link), `code`, <html>\nconst blockSkip = /\\[[^[\\]]*?\\]\\([^\\(\\)]*?\\)|`[^`]*?`|<[^<>]*?>/g;\nconst emStrongLDelim = edit(/^(?:\\*+(?:((?!\\*)[punct])|[^\\s*]))|^_+(?:((?!_)[punct])|([^\\s_]))/, 'u')\n    .replace(/punct/g, _punctuation)\n    .getRegex();\nconst emStrongRDelimAst = edit('^[^_*]*?__[^_*]*?\\\\*[^_*]*?(?=__)' // Skip orphan inside strong\n    + '|[^*]+(?=[^*])' // Consume to delim\n    + '|(?!\\\\*)[punct](\\\\*+)(?=[\\\\s]|$)' // (1) #*** can only be a Right Delimiter\n    + '|[^punct\\\\s](\\\\*+)(?!\\\\*)(?=[punct\\\\s]|$)' // (2) a***#, a*** can only be a Right Delimiter\n    + '|(?!\\\\*)[punct\\\\s](\\\\*+)(?=[^punct\\\\s])' // (3) #***a, ***a can only be Left Delimiter\n    + '|[\\\\s](\\\\*+)(?!\\\\*)(?=[punct])' // (4) ***# can only be Left Delimiter\n    + '|(?!\\\\*)[punct](\\\\*+)(?!\\\\*)(?=[punct])' // (5) #***# can be either Left or Right Delimiter\n    + '|[^punct\\\\s](\\\\*+)(?=[^punct\\\\s])', 'gu') // (6) a***a can be either Left or Right Delimiter\n    .replace(/punct/g, _punctuation)\n    .getRegex();\n// (6) Not allowed for _\nconst emStrongRDelimUnd = edit('^[^_*]*?\\\\*\\\\*[^_*]*?_[^_*]*?(?=\\\\*\\\\*)' // Skip orphan inside strong\n    + '|[^_]+(?=[^_])' // Consume to delim\n    + '|(?!_)[punct](_+)(?=[\\\\s]|$)' // (1) #___ can only be a Right Delimiter\n    + '|[^punct\\\\s](_+)(?!_)(?=[punct\\\\s]|$)' // (2) a___#, a___ can only be a Right Delimiter\n    + '|(?!_)[punct\\\\s](_+)(?=[^punct\\\\s])' // (3) #___a, ___a can only be Left Delimiter\n    + '|[\\\\s](_+)(?!_)(?=[punct])' // (4) ___# can only be Left Delimiter\n    + '|(?!_)[punct](_+)(?!_)(?=[punct])', 'gu') // (5) #___# can be either Left or Right Delimiter\n    .replace(/punct/g, _punctuation)\n    .getRegex();\nconst anyPunctuation = edit(/\\\\([punct])/, 'gu')\n    .replace(/punct/g, _punctuation)\n    .getRegex();\nconst autolink = edit(/^<(scheme:[^\\s\\x00-\\x1f<>]*|email)>/)\n    .replace('scheme', /[a-zA-Z][a-zA-Z0-9+.-]{1,31}/)\n    .replace('email', /[a-zA-Z0-9.!#$%&'*+/=?^_`{|}~-]+(@)[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)+(?![-_])/)\n    .getRegex();\nconst _inlineComment = edit(_comment).replace('(?:-->|$)', '-->').getRegex();\nconst tag = edit('^comment'\n    + '|^</[a-zA-Z][\\\\w:-]*\\\\s*>' // self-closing tag\n    + '|^<[a-zA-Z][\\\\w-]*(?:attribute)*?\\\\s*/?>' // open tag\n    + '|^<\\\\?[\\\\s\\\\S]*?\\\\?>' // processing instruction, e.g. <?php ?>\n    + '|^<![a-zA-Z]+\\\\s[\\\\s\\\\S]*?>' // declaration, e.g. <!DOCTYPE html>\n    + '|^<!\\\\[CDATA\\\\[[\\\\s\\\\S]*?\\\\]\\\\]>') // CDATA section\n    .replace('comment', _inlineComment)\n    .replace('attribute', /\\s+[a-zA-Z:_][\\w.:-]*(?:\\s*=\\s*\"[^\"]*\"|\\s*=\\s*'[^']*'|\\s*=\\s*[^\\s\"'=<>`]+)?/)\n    .getRegex();\nconst _inlineLabel = /(?:\\[(?:\\\\.|[^\\[\\]\\\\])*\\]|\\\\.|`[^`]*`|[^\\[\\]\\\\`])*?/;\nconst link = edit(/^!?\\[(label)\\]\\(\\s*(href)(?:\\s+(title))?\\s*\\)/)\n    .replace('label', _inlineLabel)\n    .replace('href', /<(?:\\\\.|[^\\n<>\\\\])+>|[^\\s\\x00-\\x1f]*/)\n    .replace('title', /\"(?:\\\\\"?|[^\"\\\\])*\"|'(?:\\\\'?|[^'\\\\])*'|\\((?:\\\\\\)?|[^)\\\\])*\\)/)\n    .getRegex();\nconst reflink = edit(/^!?\\[(label)\\]\\[(ref)\\]/)\n    .replace('label', _inlineLabel)\n    .replace('ref', _blockLabel)\n    .getRegex();\nconst nolink = edit(/^!?\\[(ref)\\](?:\\[\\])?/)\n    .replace('ref', _blockLabel)\n    .getRegex();\nconst reflinkSearch = edit('reflink|nolink(?!\\\\()', 'g')\n    .replace('reflink', reflink)\n    .replace('nolink', nolink)\n    .getRegex();\n/**\n * Normal Inline Grammar\n */\nconst inlineNormal = {\n    _backpedal: noopTest, // only used for GFM url\n    anyPunctuation,\n    autolink,\n    blockSkip,\n    br,\n    code: inlineCode,\n    del: noopTest,\n    emStrongLDelim,\n    emStrongRDelimAst,\n    emStrongRDelimUnd,\n    escape,\n    link,\n    nolink,\n    punctuation,\n    reflink,\n    reflinkSearch,\n    tag,\n    text: inlineText,\n    url: noopTest\n};\n/**\n * Pedantic Inline Grammar\n */\nconst inlinePedantic = {\n    ...inlineNormal,\n    link: edit(/^!?\\[(label)\\]\\((.*?)\\)/)\n        .replace('label', _inlineLabel)\n        .getRegex(),\n    reflink: edit(/^!?\\[(label)\\]\\s*\\[([^\\]]*)\\]/)\n        .replace('label', _inlineLabel)\n        .getRegex()\n};\n/**\n * GFM Inline Grammar\n */\nconst inlineGfm = {\n    ...inlineNormal,\n    escape: edit(escape).replace('])', '~|])').getRegex(),\n    url: edit(/^((?:ftp|https?):\\/\\/|www\\.)(?:[a-zA-Z0-9\\-]+\\.?)+[^\\s<]*|^email/, 'i')\n        .replace('email', /[A-Za-z0-9._+-]+(@)[a-zA-Z0-9-_]+(?:\\.[a-zA-Z0-9-_]*[a-zA-Z0-9])+(?![-_])/)\n        .getRegex(),\n    _backpedal: /(?:[^?!.,:;*_'\"~()&]+|\\([^)]*\\)|&(?![a-zA-Z0-9]+;$)|[?!.,:;*_'\"~)]+(?!$))+/,\n    del: /^(~~?)(?=[^\\s~])([\\s\\S]*?[^\\s~])\\1(?=[^~]|$)/,\n    text: /^([`~]+|[^`~])(?:(?= {2,}\\n)|(?=[a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-]+@)|[\\s\\S]*?(?:(?=[\\\\<!\\[`*~_]|\\b_|https?:\\/\\/|ftp:\\/\\/|www\\.|$)|[^ ](?= {2,}\\n)|[^a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-](?=[a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-]+@)))/\n};\n/**\n * GFM + Line Breaks Inline Grammar\n */\nconst inlineBreaks = {\n    ...inlineGfm,\n    br: edit(br).replace('{2,}', '*').getRegex(),\n    text: edit(inlineGfm.text)\n        .replace('\\\\b_', '\\\\b_| {2,}\\\\n')\n        .replace(/\\{2,\\}/g, '*')\n        .getRegex()\n};\n/**\n * exports\n */\nconst block = {\n    normal: blockNormal,\n    gfm: blockGfm,\n    pedantic: blockPedantic\n};\nconst inline = {\n    normal: inlineNormal,\n    gfm: inlineGfm,\n    breaks: inlineBreaks,\n    pedantic: inlinePedantic\n};\n\n/**\n * Block Lexer\n */\nclass _Lexer {\n    tokens;\n    options;\n    state;\n    tokenizer;\n    inlineQueue;\n    constructor(options) {\n        // TokenList cannot be created in one go\n        this.tokens = [];\n        this.tokens.links = Object.create(null);\n        this.options = options || _defaults;\n        this.options.tokenizer = this.options.tokenizer || new _Tokenizer();\n        this.tokenizer = this.options.tokenizer;\n        this.tokenizer.options = this.options;\n        this.tokenizer.lexer = this;\n        this.inlineQueue = [];\n        this.state = {\n            inLink: false,\n            inRawBlock: false,\n            top: true\n        };\n        const rules = {\n            block: block.normal,\n            inline: inline.normal\n        };\n        if (this.options.pedantic) {\n            rules.block = block.pedantic;\n            rules.inline = inline.pedantic;\n        }\n        else if (this.options.gfm) {\n            rules.block = block.gfm;\n            if (this.options.breaks) {\n                rules.inline = inline.breaks;\n            }\n            else {\n                rules.inline = inline.gfm;\n            }\n        }\n        this.tokenizer.rules = rules;\n    }\n    /**\n     * Expose Rules\n     */\n    static get rules() {\n        return {\n            block,\n            inline\n        };\n    }\n    /**\n     * Static Lex Method\n     */\n    static lex(src, options) {\n        const lexer = new _Lexer(options);\n        return lexer.lex(src);\n    }\n    /**\n     * Static Lex Inline Method\n     */\n    static lexInline(src, options) {\n        const lexer = new _Lexer(options);\n        return lexer.inlineTokens(src);\n    }\n    /**\n     * Preprocessing\n     */\n    lex(src) {\n        src = src\n            .replace(/\\r\\n|\\r/g, '\\n');\n        this.blockTokens(src, this.tokens);\n        for (let i = 0; i < this.inlineQueue.length; i++) {\n            const next = this.inlineQueue[i];\n            this.inlineTokens(next.src, next.tokens);\n        }\n        this.inlineQueue = [];\n        return this.tokens;\n    }\n    blockTokens(src, tokens = []) {\n        if (this.options.pedantic) {\n            src = src.replace(/\\t/g, '    ').replace(/^ +$/gm, '');\n        }\n        else {\n            src = src.replace(/^( *)(\\t+)/gm, (_, leading, tabs) => {\n                return leading + '    '.repeat(tabs.length);\n            });\n        }\n        let token;\n        let lastToken;\n        let cutSrc;\n        let lastParagraphClipped;\n        while (src) {\n            if (this.options.extensions\n                && this.options.extensions.block\n                && this.options.extensions.block.some((extTokenizer) => {\n                    if (token = extTokenizer.call({ lexer: this }, src, tokens)) {\n                        src = src.substring(token.raw.length);\n                        tokens.push(token);\n                        return true;\n                    }\n                    return false;\n                })) {\n                continue;\n            }\n            // newline\n            if (token = this.tokenizer.space(src)) {\n                src = src.substring(token.raw.length);\n                if (token.raw.length === 1 && tokens.length > 0) {\n                    // if there's a single \\n as a spacer, it's terminating the last line,\n                    // so move it there so that we don't get unnecessary paragraph tags\n                    tokens[tokens.length - 1].raw += '\\n';\n                }\n                else {\n                    tokens.push(token);\n                }\n                continue;\n            }\n            // code\n            if (token = this.tokenizer.code(src)) {\n                src = src.substring(token.raw.length);\n                lastToken = tokens[tokens.length - 1];\n                // An indented code block cannot interrupt a paragraph.\n                if (lastToken && (lastToken.type === 'paragraph' || lastToken.type === 'text')) {\n                    lastToken.raw += '\\n' + token.raw;\n                    lastToken.text += '\\n' + token.text;\n                    this.inlineQueue[this.inlineQueue.length - 1].src = lastToken.text;\n                }\n                else {\n                    tokens.push(token);\n                }\n                continue;\n            }\n            // fences\n            if (token = this.tokenizer.fences(src)) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // heading\n            if (token = this.tokenizer.heading(src)) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // hr\n            if (token = this.tokenizer.hr(src)) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // blockquote\n            if (token = this.tokenizer.blockquote(src)) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // list\n            if (token = this.tokenizer.list(src)) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // html\n            if (token = this.tokenizer.html(src)) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // def\n            if (token = this.tokenizer.def(src)) {\n                src = src.substring(token.raw.length);\n                lastToken = tokens[tokens.length - 1];\n                if (lastToken && (lastToken.type === 'paragraph' || lastToken.type === 'text')) {\n                    lastToken.raw += '\\n' + token.raw;\n                    lastToken.text += '\\n' + token.raw;\n                    this.inlineQueue[this.inlineQueue.length - 1].src = lastToken.text;\n                }\n                else if (!this.tokens.links[token.tag]) {\n                    this.tokens.links[token.tag] = {\n                        href: token.href,\n                        title: token.title\n                    };\n                }\n                continue;\n            }\n            // table (gfm)\n            if (token = this.tokenizer.table(src)) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // lheading\n            if (token = this.tokenizer.lheading(src)) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // top-level paragraph\n            // prevent paragraph consuming extensions by clipping 'src' to extension start\n            cutSrc = src;\n            if (this.options.extensions && this.options.extensions.startBlock) {\n                let startIndex = Infinity;\n                const tempSrc = src.slice(1);\n                let tempStart;\n                this.options.extensions.startBlock.forEach((getStartIndex) => {\n                    tempStart = getStartIndex.call({ lexer: this }, tempSrc);\n                    if (typeof tempStart === 'number' && tempStart >= 0) {\n                        startIndex = Math.min(startIndex, tempStart);\n                    }\n                });\n                if (startIndex < Infinity && startIndex >= 0) {\n                    cutSrc = src.substring(0, startIndex + 1);\n                }\n            }\n            if (this.state.top && (token = this.tokenizer.paragraph(cutSrc))) {\n                lastToken = tokens[tokens.length - 1];\n                if (lastParagraphClipped && lastToken.type === 'paragraph') {\n                    lastToken.raw += '\\n' + token.raw;\n                    lastToken.text += '\\n' + token.text;\n                    this.inlineQueue.pop();\n                    this.inlineQueue[this.inlineQueue.length - 1].src = lastToken.text;\n                }\n                else {\n                    tokens.push(token);\n                }\n                lastParagraphClipped = (cutSrc.length !== src.length);\n                src = src.substring(token.raw.length);\n                continue;\n            }\n            // text\n            if (token = this.tokenizer.text(src)) {\n                src = src.substring(token.raw.length);\n                lastToken = tokens[tokens.length - 1];\n                if (lastToken && lastToken.type === 'text') {\n                    lastToken.raw += '\\n' + token.raw;\n                    lastToken.text += '\\n' + token.text;\n                    this.inlineQueue.pop();\n                    this.inlineQueue[this.inlineQueue.length - 1].src = lastToken.text;\n                }\n                else {\n                    tokens.push(token);\n                }\n                continue;\n            }\n            if (src) {\n                const errMsg = 'Infinite loop on byte: ' + src.charCodeAt(0);\n                if (this.options.silent) {\n                    console.error(errMsg);\n                    break;\n                }\n                else {\n                    throw new Error(errMsg);\n                }\n            }\n        }\n        this.state.top = true;\n        return tokens;\n    }\n    inline(src, tokens = []) {\n        this.inlineQueue.push({ src, tokens });\n        return tokens;\n    }\n    /**\n     * Lexing/Compiling\n     */\n    inlineTokens(src, tokens = []) {\n        let token, lastToken, cutSrc;\n        // String with links masked to avoid interference with em and strong\n        let maskedSrc = src;\n        let match;\n        let keepPrevChar, prevChar;\n        // Mask out reflinks\n        if (this.tokens.links) {\n            const links = Object.keys(this.tokens.links);\n            if (links.length > 0) {\n                while ((match = this.tokenizer.rules.inline.reflinkSearch.exec(maskedSrc)) != null) {\n                    if (links.includes(match[0].slice(match[0].lastIndexOf('[') + 1, -1))) {\n                        maskedSrc = maskedSrc.slice(0, match.index) + '[' + 'a'.repeat(match[0].length - 2) + ']' + maskedSrc.slice(this.tokenizer.rules.inline.reflinkSearch.lastIndex);\n                    }\n                }\n            }\n        }\n        // Mask out other blocks\n        while ((match = this.tokenizer.rules.inline.blockSkip.exec(maskedSrc)) != null) {\n            maskedSrc = maskedSrc.slice(0, match.index) + '[' + 'a'.repeat(match[0].length - 2) + ']' + maskedSrc.slice(this.tokenizer.rules.inline.blockSkip.lastIndex);\n        }\n        // Mask out escaped characters\n        while ((match = this.tokenizer.rules.inline.anyPunctuation.exec(maskedSrc)) != null) {\n            maskedSrc = maskedSrc.slice(0, match.index) + '++' + maskedSrc.slice(this.tokenizer.rules.inline.anyPunctuation.lastIndex);\n        }\n        while (src) {\n            if (!keepPrevChar) {\n                prevChar = '';\n            }\n            keepPrevChar = false;\n            // extensions\n            if (this.options.extensions\n                && this.options.extensions.inline\n                && this.options.extensions.inline.some((extTokenizer) => {\n                    if (token = extTokenizer.call({ lexer: this }, src, tokens)) {\n                        src = src.substring(token.raw.length);\n                        tokens.push(token);\n                        return true;\n                    }\n                    return false;\n                })) {\n                continue;\n            }\n            // escape\n            if (token = this.tokenizer.escape(src)) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // tag\n            if (token = this.tokenizer.tag(src)) {\n                src = src.substring(token.raw.length);\n                lastToken = tokens[tokens.length - 1];\n                if (lastToken && token.type === 'text' && lastToken.type === 'text') {\n                    lastToken.raw += token.raw;\n                    lastToken.text += token.text;\n                }\n                else {\n                    tokens.push(token);\n                }\n                continue;\n            }\n            // link\n            if (token = this.tokenizer.link(src)) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // reflink, nolink\n            if (token = this.tokenizer.reflink(src, this.tokens.links)) {\n                src = src.substring(token.raw.length);\n                lastToken = tokens[tokens.length - 1];\n                if (lastToken && token.type === 'text' && lastToken.type === 'text') {\n                    lastToken.raw += token.raw;\n                    lastToken.text += token.text;\n                }\n                else {\n                    tokens.push(token);\n                }\n                continue;\n            }\n            // em & strong\n            if (token = this.tokenizer.emStrong(src, maskedSrc, prevChar)) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // code\n            if (token = this.tokenizer.codespan(src)) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // br\n            if (token = this.tokenizer.br(src)) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // del (gfm)\n            if (token = this.tokenizer.del(src)) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // autolink\n            if (token = this.tokenizer.autolink(src)) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // url (gfm)\n            if (!this.state.inLink && (token = this.tokenizer.url(src))) {\n                src = src.substring(token.raw.length);\n                tokens.push(token);\n                continue;\n            }\n            // text\n            // prevent inlineText consuming extensions by clipping 'src' to extension start\n            cutSrc = src;\n            if (this.options.extensions && this.options.extensions.startInline) {\n                let startIndex = Infinity;\n                const tempSrc = src.slice(1);\n                let tempStart;\n                this.options.extensions.startInline.forEach((getStartIndex) => {\n                    tempStart = getStartIndex.call({ lexer: this }, tempSrc);\n                    if (typeof tempStart === 'number' && tempStart >= 0) {\n                        startIndex = Math.min(startIndex, tempStart);\n                    }\n                });\n                if (startIndex < Infinity && startIndex >= 0) {\n                    cutSrc = src.substring(0, startIndex + 1);\n                }\n            }\n            if (token = this.tokenizer.inlineText(cutSrc)) {\n                src = src.substring(token.raw.length);\n                if (token.raw.slice(-1) !== '_') { // Track prevChar before string of ____ started\n                    prevChar = token.raw.slice(-1);\n                }\n                keepPrevChar = true;\n                lastToken = tokens[tokens.length - 1];\n                if (lastToken && lastToken.type === 'text') {\n                    lastToken.raw += token.raw;\n                    lastToken.text += token.text;\n                }\n                else {\n                    tokens.push(token);\n                }\n                continue;\n            }\n            if (src) {\n                const errMsg = 'Infinite loop on byte: ' + src.charCodeAt(0);\n                if (this.options.silent) {\n                    console.error(errMsg);\n                    break;\n                }\n                else {\n                    throw new Error(errMsg);\n                }\n            }\n        }\n        return tokens;\n    }\n}\n\n/**\n * Renderer\n */\nclass _Renderer {\n    options;\n    constructor(options) {\n        this.options = options || _defaults;\n    }\n    code(code, infostring, escaped) {\n        const lang = (infostring || '').match(/^\\S*/)?.[0];\n        code = code.replace(/\\n$/, '') + '\\n';\n        if (!lang) {\n            return '<pre><code>'\n                + (escaped ? code : escape$1(code, true))\n                + '</code></pre>\\n';\n        }\n        return '<pre><code class=\"language-'\n            + escape$1(lang)\n            + '\">'\n            + (escaped ? code : escape$1(code, true))\n            + '</code></pre>\\n';\n    }\n    blockquote(quote) {\n        return `<blockquote>\\n${quote}</blockquote>\\n`;\n    }\n    html(html, block) {\n        return html;\n    }\n    heading(text, level, raw) {\n        // ignore IDs\n        return `<h${level}>${text}</h${level}>\\n`;\n    }\n    hr() {\n        return '<hr>\\n';\n    }\n    list(body, ordered, start) {\n        const type = ordered ? 'ol' : 'ul';\n        const startatt = (ordered && start !== 1) ? (' start=\"' + start + '\"') : '';\n        return '<' + type + startatt + '>\\n' + body + '</' + type + '>\\n';\n    }\n    listitem(text, task, checked) {\n        return `<li>${text}</li>\\n`;\n    }\n    checkbox(checked) {\n        return '<input '\n            + (checked ? 'checked=\"\" ' : '')\n            + 'disabled=\"\" type=\"checkbox\">';\n    }\n    paragraph(text) {\n        return `<p>${text}</p>\\n`;\n    }\n    table(header, body) {\n        if (body)\n            body = `<tbody>${body}</tbody>`;\n        return '<table>\\n'\n            + '<thead>\\n'\n            + header\n            + '</thead>\\n'\n            + body\n            + '</table>\\n';\n    }\n    tablerow(content) {\n        return `<tr>\\n${content}</tr>\\n`;\n    }\n    tablecell(content, flags) {\n        const type = flags.header ? 'th' : 'td';\n        const tag = flags.align\n            ? `<${type} align=\"${flags.align}\">`\n            : `<${type}>`;\n        return tag + content + `</${type}>\\n`;\n    }\n    /**\n     * span level renderer\n     */\n    strong(text) {\n        return `<strong>${text}</strong>`;\n    }\n    em(text) {\n        return `<em>${text}</em>`;\n    }\n    codespan(text) {\n        return `<code>${text}</code>`;\n    }\n    br() {\n        return '<br>';\n    }\n    del(text) {\n        return `<del>${text}</del>`;\n    }\n    link(href, title, text) {\n        const cleanHref = cleanUrl(href);\n        if (cleanHref === null) {\n            return text;\n        }\n        href = cleanHref;\n        let out = '<a href=\"' + href + '\"';\n        if (title) {\n            out += ' title=\"' + title + '\"';\n        }\n        out += '>' + text + '</a>';\n        return out;\n    }\n    image(href, title, text) {\n        const cleanHref = cleanUrl(href);\n        if (cleanHref === null) {\n            return text;\n        }\n        href = cleanHref;\n        let out = `<img src=\"${href}\" alt=\"${text}\"`;\n        if (title) {\n            out += ` title=\"${title}\"`;\n        }\n        out += '>';\n        return out;\n    }\n    text(text) {\n        return text;\n    }\n}\n\n/**\n * TextRenderer\n * returns only the textual part of the token\n */\nclass _TextRenderer {\n    // no need for block level renderers\n    strong(text) {\n        return text;\n    }\n    em(text) {\n        return text;\n    }\n    codespan(text) {\n        return text;\n    }\n    del(text) {\n        return text;\n    }\n    html(text) {\n        return text;\n    }\n    text(text) {\n        return text;\n    }\n    link(href, title, text) {\n        return '' + text;\n    }\n    image(href, title, text) {\n        return '' + text;\n    }\n    br() {\n        return '';\n    }\n}\n\n/**\n * Parsing & Compiling\n */\nclass _Parser {\n    options;\n    renderer;\n    textRenderer;\n    constructor(options) {\n        this.options = options || _defaults;\n        this.options.renderer = this.options.renderer || new _Renderer();\n        this.renderer = this.options.renderer;\n        this.renderer.options = this.options;\n        this.textRenderer = new _TextRenderer();\n    }\n    /**\n     * Static Parse Method\n     */\n    static parse(tokens, options) {\n        const parser = new _Parser(options);\n        return parser.parse(tokens);\n    }\n    /**\n     * Static Parse Inline Method\n     */\n    static parseInline(tokens, options) {\n        const parser = new _Parser(options);\n        return parser.parseInline(tokens);\n    }\n    /**\n     * Parse Loop\n     */\n    parse(tokens, top = true) {\n        let out = '';\n        for (let i = 0; i < tokens.length; i++) {\n            const token = tokens[i];\n            // Run any renderer extensions\n            if (this.options.extensions && this.options.extensions.renderers && this.options.extensions.renderers[token.type]) {\n                const genericToken = token;\n                const ret = this.options.extensions.renderers[genericToken.type].call({ parser: this }, genericToken);\n                if (ret !== false || !['space', 'hr', 'heading', 'code', 'table', 'blockquote', 'list', 'html', 'paragraph', 'text'].includes(genericToken.type)) {\n                    out += ret || '';\n                    continue;\n                }\n            }\n            switch (token.type) {\n                case 'space': {\n                    continue;\n                }\n                case 'hr': {\n                    out += this.renderer.hr();\n                    continue;\n                }\n                case 'heading': {\n                    const headingToken = token;\n                    out += this.renderer.heading(this.parseInline(headingToken.tokens), headingToken.depth, unescape(this.parseInline(headingToken.tokens, this.textRenderer)));\n                    continue;\n                }\n                case 'code': {\n                    const codeToken = token;\n                    out += this.renderer.code(codeToken.text, codeToken.lang, !!codeToken.escaped);\n                    continue;\n                }\n                case 'table': {\n                    const tableToken = token;\n                    let header = '';\n                    // header\n                    let cell = '';\n                    for (let j = 0; j < tableToken.header.length; j++) {\n                        cell += this.renderer.tablecell(this.parseInline(tableToken.header[j].tokens), { header: true, align: tableToken.align[j] });\n                    }\n                    header += this.renderer.tablerow(cell);\n                    let body = '';\n                    for (let j = 0; j < tableToken.rows.length; j++) {\n                        const row = tableToken.rows[j];\n                        cell = '';\n                        for (let k = 0; k < row.length; k++) {\n                            cell += this.renderer.tablecell(this.parseInline(row[k].tokens), { header: false, align: tableToken.align[k] });\n                        }\n                        body += this.renderer.tablerow(cell);\n                    }\n                    out += this.renderer.table(header, body);\n                    continue;\n                }\n                case 'blockquote': {\n                    const blockquoteToken = token;\n                    const body = this.parse(blockquoteToken.tokens);\n                    out += this.renderer.blockquote(body);\n                    continue;\n                }\n                case 'list': {\n                    const listToken = token;\n                    const ordered = listToken.ordered;\n                    const start = listToken.start;\n                    const loose = listToken.loose;\n                    let body = '';\n                    for (let j = 0; j < listToken.items.length; j++) {\n                        const item = listToken.items[j];\n                        const checked = item.checked;\n                        const task = item.task;\n                        let itemBody = '';\n                        if (item.task) {\n                            const checkbox = this.renderer.checkbox(!!checked);\n                            if (loose) {\n                                if (item.tokens.length > 0 && item.tokens[0].type === 'paragraph') {\n                                    item.tokens[0].text = checkbox + ' ' + item.tokens[0].text;\n                                    if (item.tokens[0].tokens && item.tokens[0].tokens.length > 0 && item.tokens[0].tokens[0].type === 'text') {\n                                        item.tokens[0].tokens[0].text = checkbox + ' ' + item.tokens[0].tokens[0].text;\n                                    }\n                                }\n                                else {\n                                    item.tokens.unshift({\n                                        type: 'text',\n                                        text: checkbox + ' '\n                                    });\n                                }\n                            }\n                            else {\n                                itemBody += checkbox + ' ';\n                            }\n                        }\n                        itemBody += this.parse(item.tokens, loose);\n                        body += this.renderer.listitem(itemBody, task, !!checked);\n                    }\n                    out += this.renderer.list(body, ordered, start);\n                    continue;\n                }\n                case 'html': {\n                    const htmlToken = token;\n                    out += this.renderer.html(htmlToken.text, htmlToken.block);\n                    continue;\n                }\n                case 'paragraph': {\n                    const paragraphToken = token;\n                    out += this.renderer.paragraph(this.parseInline(paragraphToken.tokens));\n                    continue;\n                }\n                case 'text': {\n                    let textToken = token;\n                    let body = textToken.tokens ? this.parseInline(textToken.tokens) : textToken.text;\n                    while (i + 1 < tokens.length && tokens[i + 1].type === 'text') {\n                        textToken = tokens[++i];\n                        body += '\\n' + (textToken.tokens ? this.parseInline(textToken.tokens) : textToken.text);\n                    }\n                    out += top ? this.renderer.paragraph(body) : body;\n                    continue;\n                }\n                default: {\n                    const errMsg = 'Token with \"' + token.type + '\" type was not found.';\n                    if (this.options.silent) {\n                        console.error(errMsg);\n                        return '';\n                    }\n                    else {\n                        throw new Error(errMsg);\n                    }\n                }\n            }\n        }\n        return out;\n    }\n    /**\n     * Parse Inline Tokens\n     */\n    parseInline(tokens, renderer) {\n        renderer = renderer || this.renderer;\n        let out = '';\n        for (let i = 0; i < tokens.length; i++) {\n            const token = tokens[i];\n            // Run any renderer extensions\n            if (this.options.extensions && this.options.extensions.renderers && this.options.extensions.renderers[token.type]) {\n                const ret = this.options.extensions.renderers[token.type].call({ parser: this }, token);\n                if (ret !== false || !['escape', 'html', 'link', 'image', 'strong', 'em', 'codespan', 'br', 'del', 'text'].includes(token.type)) {\n                    out += ret || '';\n                    continue;\n                }\n            }\n            switch (token.type) {\n                case 'escape': {\n                    const escapeToken = token;\n                    out += renderer.text(escapeToken.text);\n                    break;\n                }\n                case 'html': {\n                    const tagToken = token;\n                    out += renderer.html(tagToken.text);\n                    break;\n                }\n                case 'link': {\n                    const linkToken = token;\n                    out += renderer.link(linkToken.href, linkToken.title, this.parseInline(linkToken.tokens, renderer));\n                    break;\n                }\n                case 'image': {\n                    const imageToken = token;\n                    out += renderer.image(imageToken.href, imageToken.title, imageToken.text);\n                    break;\n                }\n                case 'strong': {\n                    const strongToken = token;\n                    out += renderer.strong(this.parseInline(strongToken.tokens, renderer));\n                    break;\n                }\n                case 'em': {\n                    const emToken = token;\n                    out += renderer.em(this.parseInline(emToken.tokens, renderer));\n                    break;\n                }\n                case 'codespan': {\n                    const codespanToken = token;\n                    out += renderer.codespan(codespanToken.text);\n                    break;\n                }\n                case 'br': {\n                    out += renderer.br();\n                    break;\n                }\n                case 'del': {\n                    const delToken = token;\n                    out += renderer.del(this.parseInline(delToken.tokens, renderer));\n                    break;\n                }\n                case 'text': {\n                    const textToken = token;\n                    out += renderer.text(textToken.text);\n                    break;\n                }\n                default: {\n                    const errMsg = 'Token with \"' + token.type + '\" type was not found.';\n                    if (this.options.silent) {\n                        console.error(errMsg);\n                        return '';\n                    }\n                    else {\n                        throw new Error(errMsg);\n                    }\n                }\n            }\n        }\n        return out;\n    }\n}\n\nclass _Hooks {\n    options;\n    constructor(options) {\n        this.options = options || _defaults;\n    }\n    static passThroughHooks = new Set([\n        'preprocess',\n        'postprocess',\n        'processAllTokens'\n    ]);\n    /**\n     * Process markdown before marked\n     */\n    preprocess(markdown) {\n        return markdown;\n    }\n    /**\n     * Process HTML after marked is finished\n     */\n    postprocess(html) {\n        return html;\n    }\n    /**\n     * Process all tokens before walk tokens\n     */\n    processAllTokens(tokens) {\n        return tokens;\n    }\n}\n\nclass Marked {\n    defaults = _getDefaults();\n    options = this.setOptions;\n    parse = this.#parseMarkdown(_Lexer.lex, _Parser.parse);\n    parseInline = this.#parseMarkdown(_Lexer.lexInline, _Parser.parseInline);\n    Parser = _Parser;\n    Renderer = _Renderer;\n    TextRenderer = _TextRenderer;\n    Lexer = _Lexer;\n    Tokenizer = _Tokenizer;\n    Hooks = _Hooks;\n    constructor(...args) {\n        this.use(...args);\n    }\n    /**\n     * Run callback for every token\n     */\n    walkTokens(tokens, callback) {\n        let values = [];\n        for (const token of tokens) {\n            values = values.concat(callback.call(this, token));\n            switch (token.type) {\n                case 'table': {\n                    const tableToken = token;\n                    for (const cell of tableToken.header) {\n                        values = values.concat(this.walkTokens(cell.tokens, callback));\n                    }\n                    for (const row of tableToken.rows) {\n                        for (const cell of row) {\n                            values = values.concat(this.walkTokens(cell.tokens, callback));\n                        }\n                    }\n                    break;\n                }\n                case 'list': {\n                    const listToken = token;\n                    values = values.concat(this.walkTokens(listToken.items, callback));\n                    break;\n                }\n                default: {\n                    const genericToken = token;\n                    if (this.defaults.extensions?.childTokens?.[genericToken.type]) {\n                        this.defaults.extensions.childTokens[genericToken.type].forEach((childTokens) => {\n                            const tokens = genericToken[childTokens].flat(Infinity);\n                            values = values.concat(this.walkTokens(tokens, callback));\n                        });\n                    }\n                    else if (genericToken.tokens) {\n                        values = values.concat(this.walkTokens(genericToken.tokens, callback));\n                    }\n                }\n            }\n        }\n        return values;\n    }\n    use(...args) {\n        const extensions = this.defaults.extensions || { renderers: {}, childTokens: {} };\n        args.forEach((pack) => {\n            // copy options to new object\n            const opts = { ...pack };\n            // set async to true if it was set to true before\n            opts.async = this.defaults.async || opts.async || false;\n            // ==-- Parse \"addon\" extensions --== //\n            if (pack.extensions) {\n                pack.extensions.forEach((ext) => {\n                    if (!ext.name) {\n                        throw new Error('extension name required');\n                    }\n                    if ('renderer' in ext) { // Renderer extensions\n                        const prevRenderer = extensions.renderers[ext.name];\n                        if (prevRenderer) {\n                            // Replace extension with func to run new extension but fall back if false\n                            extensions.renderers[ext.name] = function (...args) {\n                                let ret = ext.renderer.apply(this, args);\n                                if (ret === false) {\n                                    ret = prevRenderer.apply(this, args);\n                                }\n                                return ret;\n                            };\n                        }\n                        else {\n                            extensions.renderers[ext.name] = ext.renderer;\n                        }\n                    }\n                    if ('tokenizer' in ext) { // Tokenizer Extensions\n                        if (!ext.level || (ext.level !== 'block' && ext.level !== 'inline')) {\n                            throw new Error(\"extension level must be 'block' or 'inline'\");\n                        }\n                        const extLevel = extensions[ext.level];\n                        if (extLevel) {\n                            extLevel.unshift(ext.tokenizer);\n                        }\n                        else {\n                            extensions[ext.level] = [ext.tokenizer];\n                        }\n                        if (ext.start) { // Function to check for start of token\n                            if (ext.level === 'block') {\n                                if (extensions.startBlock) {\n                                    extensions.startBlock.push(ext.start);\n                                }\n                                else {\n                                    extensions.startBlock = [ext.start];\n                                }\n                            }\n                            else if (ext.level === 'inline') {\n                                if (extensions.startInline) {\n                                    extensions.startInline.push(ext.start);\n                                }\n                                else {\n                                    extensions.startInline = [ext.start];\n                                }\n                            }\n                        }\n                    }\n                    if ('childTokens' in ext && ext.childTokens) { // Child tokens to be visited by walkTokens\n                        extensions.childTokens[ext.name] = ext.childTokens;\n                    }\n                });\n                opts.extensions = extensions;\n            }\n            // ==-- Parse \"overwrite\" extensions --== //\n            if (pack.renderer) {\n                const renderer = this.defaults.renderer || new _Renderer(this.defaults);\n                for (const prop in pack.renderer) {\n                    if (!(prop in renderer)) {\n                        throw new Error(`renderer '${prop}' does not exist`);\n                    }\n                    if (prop === 'options') {\n                        // ignore options property\n                        continue;\n                    }\n                    const rendererProp = prop;\n                    const rendererFunc = pack.renderer[rendererProp];\n                    const prevRenderer = renderer[rendererProp];\n                    // Replace renderer with func to run extension, but fall back if false\n                    renderer[rendererProp] = (...args) => {\n                        let ret = rendererFunc.apply(renderer, args);\n                        if (ret === false) {\n                            ret = prevRenderer.apply(renderer, args);\n                        }\n                        return ret || '';\n                    };\n                }\n                opts.renderer = renderer;\n            }\n            if (pack.tokenizer) {\n                const tokenizer = this.defaults.tokenizer || new _Tokenizer(this.defaults);\n                for (const prop in pack.tokenizer) {\n                    if (!(prop in tokenizer)) {\n                        throw new Error(`tokenizer '${prop}' does not exist`);\n                    }\n                    if (['options', 'rules', 'lexer'].includes(prop)) {\n                        // ignore options, rules, and lexer properties\n                        continue;\n                    }\n                    const tokenizerProp = prop;\n                    const tokenizerFunc = pack.tokenizer[tokenizerProp];\n                    const prevTokenizer = tokenizer[tokenizerProp];\n                    // Replace tokenizer with func to run extension, but fall back if false\n                    // @ts-expect-error cannot type tokenizer function dynamically\n                    tokenizer[tokenizerProp] = (...args) => {\n                        let ret = tokenizerFunc.apply(tokenizer, args);\n                        if (ret === false) {\n                            ret = prevTokenizer.apply(tokenizer, args);\n                        }\n                        return ret;\n                    };\n                }\n                opts.tokenizer = tokenizer;\n            }\n            // ==-- Parse Hooks extensions --== //\n            if (pack.hooks) {\n                const hooks = this.defaults.hooks || new _Hooks();\n                for (const prop in pack.hooks) {\n                    if (!(prop in hooks)) {\n                        throw new Error(`hook '${prop}' does not exist`);\n                    }\n                    if (prop === 'options') {\n                        // ignore options property\n                        continue;\n                    }\n                    const hooksProp = prop;\n                    const hooksFunc = pack.hooks[hooksProp];\n                    const prevHook = hooks[hooksProp];\n                    if (_Hooks.passThroughHooks.has(prop)) {\n                        // @ts-expect-error cannot type hook function dynamically\n                        hooks[hooksProp] = (arg) => {\n                            if (this.defaults.async) {\n                                return Promise.resolve(hooksFunc.call(hooks, arg)).then(ret => {\n                                    return prevHook.call(hooks, ret);\n                                });\n                            }\n                            const ret = hooksFunc.call(hooks, arg);\n                            return prevHook.call(hooks, ret);\n                        };\n                    }\n                    else {\n                        // @ts-expect-error cannot type hook function dynamically\n                        hooks[hooksProp] = (...args) => {\n                            let ret = hooksFunc.apply(hooks, args);\n                            if (ret === false) {\n                                ret = prevHook.apply(hooks, args);\n                            }\n                            return ret;\n                        };\n                    }\n                }\n                opts.hooks = hooks;\n            }\n            // ==-- Parse WalkTokens extensions --== //\n            if (pack.walkTokens) {\n                const walkTokens = this.defaults.walkTokens;\n                const packWalktokens = pack.walkTokens;\n                opts.walkTokens = function (token) {\n                    let values = [];\n                    values.push(packWalktokens.call(this, token));\n                    if (walkTokens) {\n                        values = values.concat(walkTokens.call(this, token));\n                    }\n                    return values;\n                };\n            }\n            this.defaults = { ...this.defaults, ...opts };\n        });\n        return this;\n    }\n    setOptions(opt) {\n        this.defaults = { ...this.defaults, ...opt };\n        return this;\n    }\n    lexer(src, options) {\n        return _Lexer.lex(src, options ?? this.defaults);\n    }\n    parser(tokens, options) {\n        return _Parser.parse(tokens, options ?? this.defaults);\n    }\n    #parseMarkdown(lexer, parser) {\n        return (src, options) => {\n            const origOpt = { ...options };\n            const opt = { ...this.defaults, ...origOpt };\n            // Show warning if an extension set async to true but the parse was called with async: false\n            if (this.defaults.async === true && origOpt.async === false) {\n                if (!opt.silent) {\n                    console.warn('marked(): The async option was set to true by an extension. The async: false option sent to parse will be ignored.');\n                }\n                opt.async = true;\n            }\n            const throwError = this.#onError(!!opt.silent, !!opt.async);\n            // throw error in case of non string input\n            if (typeof src === 'undefined' || src === null) {\n                return throwError(new Error('marked(): input parameter is undefined or null'));\n            }\n            if (typeof src !== 'string') {\n                return throwError(new Error('marked(): input parameter is of type '\n                    + Object.prototype.toString.call(src) + ', string expected'));\n            }\n            if (opt.hooks) {\n                opt.hooks.options = opt;\n            }\n            if (opt.async) {\n                return Promise.resolve(opt.hooks ? opt.hooks.preprocess(src) : src)\n                    .then(src => lexer(src, opt))\n                    .then(tokens => opt.hooks ? opt.hooks.processAllTokens(tokens) : tokens)\n                    .then(tokens => opt.walkTokens ? Promise.all(this.walkTokens(tokens, opt.walkTokens)).then(() => tokens) : tokens)\n                    .then(tokens => parser(tokens, opt))\n                    .then(html => opt.hooks ? opt.hooks.postprocess(html) : html)\n                    .catch(throwError);\n            }\n            try {\n                if (opt.hooks) {\n                    src = opt.hooks.preprocess(src);\n                }\n                let tokens = lexer(src, opt);\n                if (opt.hooks) {\n                    tokens = opt.hooks.processAllTokens(tokens);\n                }\n                if (opt.walkTokens) {\n                    this.walkTokens(tokens, opt.walkTokens);\n                }\n                let html = parser(tokens, opt);\n                if (opt.hooks) {\n                    html = opt.hooks.postprocess(html);\n                }\n                return html;\n            }\n            catch (e) {\n                return throwError(e);\n            }\n        };\n    }\n    #onError(silent, async) {\n        return (e) => {\n            e.message += '\\nPlease report this to https://github.com/markedjs/marked.';\n            if (silent) {\n                const msg = '<p>An error occurred:</p><pre>'\n                    + escape$1(e.message + '', true)\n                    + '</pre>';\n                if (async) {\n                    return Promise.resolve(msg);\n                }\n                return msg;\n            }\n            if (async) {\n                return Promise.reject(e);\n            }\n            throw e;\n        };\n    }\n}\n\nconst markedInstance = new Marked();\nfunction marked(src, opt) {\n    return markedInstance.parse(src, opt);\n}\n/**\n * Sets the default options.\n *\n * @param options Hash of options\n */\nmarked.options =\n    marked.setOptions = function (options) {\n        markedInstance.setOptions(options);\n        marked.defaults = markedInstance.defaults;\n        changeDefaults(marked.defaults);\n        return marked;\n    };\n/**\n * Gets the original marked default options.\n */\nmarked.getDefaults = _getDefaults;\nmarked.defaults = _defaults;\n/**\n * Use Extension\n */\nmarked.use = function (...args) {\n    markedInstance.use(...args);\n    marked.defaults = markedInstance.defaults;\n    changeDefaults(marked.defaults);\n    return marked;\n};\n/**\n * Run callback for every token\n */\nmarked.walkTokens = function (tokens, callback) {\n    return markedInstance.walkTokens(tokens, callback);\n};\n/**\n * Compiles markdown to HTML without enclosing `p` tag.\n *\n * @param src String of markdown source to be compiled\n * @param options Hash of options\n * @return String of compiled HTML\n */\nmarked.parseInline = markedInstance.parseInline;\n/**\n * Expose\n */\nmarked.Parser = _Parser;\nmarked.parser = _Parser.parse;\nmarked.Renderer = _Renderer;\nmarked.TextRenderer = _TextRenderer;\nmarked.Lexer = _Lexer;\nmarked.lexer = _Lexer.lex;\nmarked.Tokenizer = _Tokenizer;\nmarked.Hooks = _Hooks;\nmarked.parse = marked;\nconst options = marked.options;\nconst setOptions = marked.setOptions;\nconst use = marked.use;\nconst walkTokens = marked.walkTokens;\nconst parseInline = marked.parseInline;\nconst parse = marked;\nconst parser = _Parser.parse;\nconst lexer = _Lexer.lex;\n\n\n//# sourceMappingURL=marked.esm.js.map\n\n\n//# sourceURL=webpack://semanticfinder/./node_modules/marked/lib/marked.esm.js?");

/***/ }),

/***/ "./node_modules/ollama/dist/browser.js":
/*!*********************************************!*\
  !*** ./node_modules/ollama/dist/browser.js ***!
  \*********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Ollama: () => (/* binding */ Ollama),\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./utils.js */ \"./node_modules/ollama/dist/utils.js\");\n/* harmony import */ var whatwg_fetch__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! whatwg-fetch */ \"./node_modules/whatwg-fetch/fetch.js\");\n/* harmony import */ var _interfaces_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./interfaces.js */ \"./node_modules/ollama/dist/interfaces.js\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __asyncValues = (undefined && undefined.__asyncValues) || function (o) {\n    if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\n    var m = o[Symbol.asyncIterator], i;\n    return m ? m.call(o) : (o = typeof __values === \"function\" ? __values(o) : o[Symbol.iterator](), i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i);\n    function verb(n) { i[n] = o[n] && function (v) { return new Promise(function (resolve, reject) { v = o[n](v), settle(resolve, reject, v.done, v.value); }); }; }\n    function settle(resolve, reject, d, v) { Promise.resolve(v).then(function(v) { resolve({ value: v, done: d }); }, reject); }\n};\nvar __await = (undefined && undefined.__await) || function (v) { return this instanceof __await ? (this.v = v, this) : new __await(v); }\nvar __asyncGenerator = (undefined && undefined.__asyncGenerator) || function (thisArg, _arguments, generator) {\n    if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\n    var g = generator.apply(thisArg, _arguments || []), i, q = [];\n    return i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i;\n    function verb(n) { if (g[n]) i[n] = function (v) { return new Promise(function (a, b) { q.push([n, v, a, b]) > 1 || resume(n, v); }); }; }\n    function resume(n, v) { try { step(g[n](v)); } catch (e) { settle(q[0][3], e); } }\n    function step(r) { r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r); }\n    function fulfill(value) { resume(\"next\", value); }\n    function reject(value) { resume(\"throw\", value); }\n    function settle(f, v) { if (f(v), q.shift(), q.length) resume(q[0][0], q[0][1]); }\n};\n\n\nclass Ollama {\n    constructor(config) {\n        var _a;\n        this.config = {\n            host: '',\n        };\n        if (!(config === null || config === void 0 ? void 0 : config.proxy)) {\n            this.config.host = _utils_js__WEBPACK_IMPORTED_MODULE_0__.formatHost((_a = config === null || config === void 0 ? void 0 : config.host) !== null && _a !== void 0 ? _a : 'http://127.0.0.1:11434');\n        }\n        this.fetch = fetch;\n        if ((config === null || config === void 0 ? void 0 : config.fetch) != null) {\n            this.fetch = config.fetch;\n        }\n        this.abortController = new AbortController();\n    }\n    // Abort any ongoing requests to Ollama\n    abort() {\n        this.abortController.abort();\n        this.abortController = new AbortController();\n    }\n    processStreamableRequest(endpoint, request) {\n        var _a;\n        return __awaiter(this, void 0, void 0, function* () {\n            request.stream = (_a = request.stream) !== null && _a !== void 0 ? _a : false;\n            const response = yield _utils_js__WEBPACK_IMPORTED_MODULE_0__.post(this.fetch, `${this.config.host}/api/${endpoint}`, Object.assign({}, request), { signal: this.abortController.signal });\n            if (!response.body) {\n                throw new Error('Missing body');\n            }\n            const itr = _utils_js__WEBPACK_IMPORTED_MODULE_0__.parseJSON(response.body);\n            if (request.stream) {\n                return (function () {\n                    return __asyncGenerator(this, arguments, function* () {\n                        var _a, e_1, _b, _c;\n                        try {\n                            for (var _d = true, itr_1 = __asyncValues(itr), itr_1_1; itr_1_1 = yield __await(itr_1.next()), _a = itr_1_1.done, !_a;) {\n                                _c = itr_1_1.value;\n                                _d = false;\n                                try {\n                                    const message = _c;\n                                    if ('error' in message) {\n                                        throw new Error(message.error);\n                                    }\n                                    yield yield __await(message\n                                    // message will be done in the case of chat and generate\n                                    // message will be success in the case of a progress response (pull, push, create)\n                                    );\n                                    // message will be done in the case of chat and generate\n                                    // message will be success in the case of a progress response (pull, push, create)\n                                    if (message.done || message.status === 'success') {\n                                        return yield __await(void 0);\n                                    }\n                                }\n                                finally {\n                                    _d = true;\n                                }\n                            }\n                        }\n                        catch (e_1_1) { e_1 = { error: e_1_1 }; }\n                        finally {\n                            try {\n                                if (!_d && !_a && (_b = itr_1.return)) yield __await(_b.call(itr_1));\n                            }\n                            finally { if (e_1) throw e_1.error; }\n                        }\n                        throw new Error('Did not receive done or success response in stream.');\n                    });\n                })();\n            }\n            else {\n                const message = yield itr.next();\n                if (!message.value.done && message.value.status !== 'success') {\n                    throw new Error('Expected a completed response.');\n                }\n                return message.value;\n            }\n        });\n    }\n    encodeImage(image) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (typeof image !== 'string') {\n                // image is Uint8Array convert it to base64\n                const uint8Array = new Uint8Array(image);\n                const numberArray = Array.from(uint8Array);\n                const base64String = btoa(String.fromCharCode.apply(null, numberArray));\n                return base64String;\n            }\n            // the string may be base64 encoded\n            return image;\n        });\n    }\n    generate(request) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (request.images) {\n                request.images = yield Promise.all(request.images.map(this.encodeImage.bind(this)));\n            }\n            return this.processStreamableRequest('generate', request);\n        });\n    }\n    chat(request) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (request.messages) {\n                for (const message of request.messages) {\n                    if (message.images) {\n                        message.images = yield Promise.all(message.images.map(this.encodeImage.bind(this)));\n                    }\n                }\n            }\n            return this.processStreamableRequest('chat', request);\n        });\n    }\n    create(request) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.processStreamableRequest('create', {\n                name: request.model,\n                stream: request.stream,\n                modelfile: request.modelfile,\n            });\n        });\n    }\n    pull(request) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.processStreamableRequest('pull', {\n                name: request.model,\n                stream: request.stream,\n                insecure: request.insecure,\n            });\n        });\n    }\n    push(request) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.processStreamableRequest('push', {\n                name: request.model,\n                stream: request.stream,\n                insecure: request.insecure,\n            });\n        });\n    }\n    delete(request) {\n        return __awaiter(this, void 0, void 0, function* () {\n            yield _utils_js__WEBPACK_IMPORTED_MODULE_0__.del(this.fetch, `${this.config.host}/api/delete`, {\n                name: request.model,\n            });\n            return { status: 'success' };\n        });\n    }\n    copy(request) {\n        return __awaiter(this, void 0, void 0, function* () {\n            yield _utils_js__WEBPACK_IMPORTED_MODULE_0__.post(this.fetch, `${this.config.host}/api/copy`, Object.assign({}, request));\n            return { status: 'success' };\n        });\n    }\n    list() {\n        return __awaiter(this, void 0, void 0, function* () {\n            const response = yield _utils_js__WEBPACK_IMPORTED_MODULE_0__.get(this.fetch, `${this.config.host}/api/tags`);\n            const listResponse = (yield response.json());\n            return listResponse;\n        });\n    }\n    show(request) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const response = yield _utils_js__WEBPACK_IMPORTED_MODULE_0__.post(this.fetch, `${this.config.host}/api/show`, Object.assign({}, request));\n            const showResponse = (yield response.json());\n            return showResponse;\n        });\n    }\n    embeddings(request) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const response = yield _utils_js__WEBPACK_IMPORTED_MODULE_0__.post(this.fetch, `${this.config.host}/api/embeddings`, Object.assign({}, request));\n            const embeddingsResponse = (yield response.json());\n            return embeddingsResponse;\n        });\n    }\n}\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (new Ollama());\n// export all types from the main entry point so that packages importing types dont need to specify paths\n\n\n\n//# sourceURL=webpack://semanticfinder/./node_modules/ollama/dist/browser.js?");

/***/ }),

/***/ "./node_modules/ollama/dist/interfaces.js":
/*!************************************************!*\
  !*** ./node_modules/ollama/dist/interfaces.js ***!
  \************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n\n\n//# sourceURL=webpack://semanticfinder/./node_modules/ollama/dist/interfaces.js?");

/***/ }),

/***/ "./node_modules/ollama/dist/utils.js":
/*!*******************************************!*\
  !*** ./node_modules/ollama/dist/utils.js ***!
  \*******************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   del: () => (/* binding */ del),\n/* harmony export */   formatHost: () => (/* binding */ formatHost),\n/* harmony export */   get: () => (/* binding */ get),\n/* harmony export */   head: () => (/* binding */ head),\n/* harmony export */   parseJSON: () => (/* binding */ parseJSON),\n/* harmony export */   post: () => (/* binding */ post)\n/* harmony export */ });\n/* harmony import */ var _version_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./version.js */ \"./node_modules/ollama/dist/version.js\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __await = (undefined && undefined.__await) || function (v) { return this instanceof __await ? (this.v = v, this) : new __await(v); }\nvar __asyncGenerator = (undefined && undefined.__asyncGenerator) || function (thisArg, _arguments, generator) {\n    if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\n    var g = generator.apply(thisArg, _arguments || []), i, q = [];\n    return i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i;\n    function verb(n) { if (g[n]) i[n] = function (v) { return new Promise(function (a, b) { q.push([n, v, a, b]) > 1 || resume(n, v); }); }; }\n    function resume(n, v) { try { step(g[n](v)); } catch (e) { settle(q[0][3], e); } }\n    function step(r) { r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r); }\n    function fulfill(value) { resume(\"next\", value); }\n    function reject(value) { resume(\"throw\", value); }\n    function settle(f, v) { if (f(v), q.shift(), q.length) resume(q[0][0], q[0][1]); }\n};\n\nclass ResponseError extends Error {\n    constructor(error, status_code) {\n        super(error);\n        this.error = error;\n        this.status_code = status_code;\n        this.name = 'ResponseError';\n        if (Error.captureStackTrace) {\n            Error.captureStackTrace(this, ResponseError);\n        }\n    }\n}\nconst checkOk = (response) => __awaiter(void 0, void 0, void 0, function* () {\n    var _a;\n    if (!response.ok) {\n        let message = `Error ${response.status}: ${response.statusText}`;\n        let errorData = null;\n        if ((_a = response.headers.get('content-type')) === null || _a === void 0 ? void 0 : _a.includes('application/json')) {\n            try {\n                errorData = (yield response.json());\n                message = errorData.error || message;\n            }\n            catch (error) {\n                console.log('Failed to parse error response as JSON');\n            }\n        }\n        else {\n            try {\n                console.log('Getting text from response');\n                const textResponse = yield response.text();\n                message = textResponse || message;\n            }\n            catch (error) {\n                console.log('Failed to get text from error response');\n            }\n        }\n        throw new ResponseError(message, response.status);\n    }\n});\nfunction getPlatform() {\n    if (typeof window !== 'undefined' && window.navigator) {\n        return `${window.navigator.platform.toLowerCase()} Browser/${navigator.userAgent};`;\n    }\n    else if (typeof process !== 'undefined') {\n        return `${process.arch} ${process.platform} Node.js/${process.version}`;\n    }\n    return ''; // unknown\n}\nconst fetchWithHeaders = (fetch, url, options = {}) => __awaiter(void 0, void 0, void 0, function* () {\n    const defaultHeaders = {\n        'Content-Type': 'application/json',\n        Accept: 'application/json',\n        'User-Agent': `ollama-js/${_version_js__WEBPACK_IMPORTED_MODULE_0__.version} (${getPlatform()})`,\n    };\n    if (!options.headers) {\n        options.headers = {};\n    }\n    options.headers = Object.assign(Object.assign({}, defaultHeaders), options.headers);\n    return fetch(url, options);\n});\nconst get = (fetch, host) => __awaiter(void 0, void 0, void 0, function* () {\n    const response = yield fetchWithHeaders(fetch, host);\n    yield checkOk(response);\n    return response;\n});\nconst head = (fetch, host) => __awaiter(void 0, void 0, void 0, function* () {\n    const response = yield fetchWithHeaders(fetch, host, {\n        method: 'HEAD',\n    });\n    yield checkOk(response);\n    return response;\n});\nconst post = (fetch, host, data, options) => __awaiter(void 0, void 0, void 0, function* () {\n    const isRecord = (input) => {\n        return input !== null && typeof input === 'object' && !Array.isArray(input);\n    };\n    const formattedData = isRecord(data) ? JSON.stringify(data) : data;\n    const response = yield fetchWithHeaders(fetch, host, {\n        method: 'POST',\n        body: formattedData,\n        signal: options === null || options === void 0 ? void 0 : options.signal,\n    });\n    yield checkOk(response);\n    return response;\n});\nconst del = (fetch, host, data) => __awaiter(void 0, void 0, void 0, function* () {\n    const response = yield fetchWithHeaders(fetch, host, {\n        method: 'DELETE',\n        body: JSON.stringify(data),\n    });\n    yield checkOk(response);\n    return response;\n});\nconst parseJSON = function (itr) {\n    var _a;\n    return __asyncGenerator(this, arguments, function* () {\n        const decoder = new TextDecoder('utf-8');\n        let buffer = '';\n        const reader = itr.getReader();\n        while (true) {\n            const { done, value: chunk } = yield __await(reader.read());\n            if (done) {\n                break;\n            }\n            buffer += decoder.decode(chunk);\n            const parts = buffer.split('\\n');\n            buffer = (_a = parts.pop()) !== null && _a !== void 0 ? _a : '';\n            for (const part of parts) {\n                try {\n                    yield yield __await(JSON.parse(part));\n                }\n                catch (error) {\n                    console.warn('invalid json: ', part);\n                }\n            }\n        }\n        for (const part of buffer.split('\\n').filter((p) => p !== '')) {\n            try {\n                yield yield __await(JSON.parse(part));\n            }\n            catch (error) {\n                console.warn('invalid json: ', part);\n            }\n        }\n    });\n};\nconst formatHost = (host) => {\n    if (!host) {\n        return 'http://127.0.0.1:11434';\n    }\n    let isExplicitProtocol = host.includes('://');\n    if (host.startsWith(':')) {\n        // if host starts with ':', prepend the default hostname\n        host = `http://127.0.0.1${host}`;\n        isExplicitProtocol = false;\n    }\n    if (!isExplicitProtocol) {\n        host = `http://${host}`;\n    }\n    const url = new URL(host);\n    let port = url.port;\n    if (!port) {\n        if (!isExplicitProtocol) {\n            port = '11434';\n        }\n        else {\n            // Assign default ports based on the protocol\n            port = url.protocol === 'https:' ? '443' : '80';\n        }\n    }\n    let formattedHost = `${url.protocol}//${url.hostname}:${port}${url.pathname}`;\n    // remove trailing slashes\n    if (formattedHost.endsWith('/')) {\n        formattedHost = formattedHost.slice(0, -1);\n    }\n    return formattedHost;\n};\n\n\n//# sourceURL=webpack://semanticfinder/./node_modules/ollama/dist/utils.js?");

/***/ }),

/***/ "./node_modules/ollama/dist/version.js":
/*!*********************************************!*\
  !*** ./node_modules/ollama/dist/version.js ***!
  \*********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   version: () => (/* binding */ version)\n/* harmony export */ });\nconst version = '0.4.9';\n\n\n//# sourceURL=webpack://semanticfinder/./node_modules/ollama/dist/version.js?");

/***/ }),

/***/ "./node_modules/pako/dist/pako.esm.mjs":
/*!*********************************************!*\
  !*** ./node_modules/pako/dist/pako.esm.mjs ***!
  \*********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Deflate: () => (/* binding */ Deflate_1),\n/* harmony export */   Inflate: () => (/* binding */ Inflate_1),\n/* harmony export */   constants: () => (/* binding */ constants_1),\n/* harmony export */   \"default\": () => (/* binding */ pako),\n/* harmony export */   deflate: () => (/* binding */ deflate_1),\n/* harmony export */   deflateRaw: () => (/* binding */ deflateRaw_1),\n/* harmony export */   gzip: () => (/* binding */ gzip_1),\n/* harmony export */   inflate: () => (/* binding */ inflate_1),\n/* harmony export */   inflateRaw: () => (/* binding */ inflateRaw_1),\n/* harmony export */   ungzip: () => (/* binding */ ungzip_1)\n/* harmony export */ });\n\n/*! pako 2.1.0 https://github.com/nodeca/pako @license (MIT AND Zlib) */\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\n/* eslint-disable space-unary-ops */\n\n/* Public constants ==========================================================*/\n/* ===========================================================================*/\n\n\n//const Z_FILTERED          = 1;\n//const Z_HUFFMAN_ONLY      = 2;\n//const Z_RLE               = 3;\nconst Z_FIXED$1               = 4;\n//const Z_DEFAULT_STRATEGY  = 0;\n\n/* Possible values of the data_type field (though see inflate()) */\nconst Z_BINARY              = 0;\nconst Z_TEXT                = 1;\n//const Z_ASCII             = 1; // = Z_TEXT\nconst Z_UNKNOWN$1             = 2;\n\n/*============================================================================*/\n\n\nfunction zero$1(buf) { let len = buf.length; while (--len >= 0) { buf[len] = 0; } }\n\n// From zutil.h\n\nconst STORED_BLOCK = 0;\nconst STATIC_TREES = 1;\nconst DYN_TREES    = 2;\n/* The three kinds of block type */\n\nconst MIN_MATCH$1    = 3;\nconst MAX_MATCH$1    = 258;\n/* The minimum and maximum match lengths */\n\n// From deflate.h\n/* ===========================================================================\n * Internal compression state.\n */\n\nconst LENGTH_CODES$1  = 29;\n/* number of length codes, not counting the special END_BLOCK code */\n\nconst LITERALS$1      = 256;\n/* number of literal bytes 0..255 */\n\nconst L_CODES$1       = LITERALS$1 + 1 + LENGTH_CODES$1;\n/* number of Literal or Length codes, including the END_BLOCK code */\n\nconst D_CODES$1       = 30;\n/* number of distance codes */\n\nconst BL_CODES$1      = 19;\n/* number of codes used to transfer the bit lengths */\n\nconst HEAP_SIZE$1     = 2 * L_CODES$1 + 1;\n/* maximum heap size */\n\nconst MAX_BITS$1      = 15;\n/* All codes must not exceed MAX_BITS bits */\n\nconst Buf_size      = 16;\n/* size of bit buffer in bi_buf */\n\n\n/* ===========================================================================\n * Constants\n */\n\nconst MAX_BL_BITS = 7;\n/* Bit length codes must not exceed MAX_BL_BITS bits */\n\nconst END_BLOCK   = 256;\n/* end of block literal code */\n\nconst REP_3_6     = 16;\n/* repeat previous bit length 3-6 times (2 bits of repeat count) */\n\nconst REPZ_3_10   = 17;\n/* repeat a zero length 3-10 times  (3 bits of repeat count) */\n\nconst REPZ_11_138 = 18;\n/* repeat a zero length 11-138 times  (7 bits of repeat count) */\n\n/* eslint-disable comma-spacing,array-bracket-spacing */\nconst extra_lbits =   /* extra bits for each length code */\n  new Uint8Array([0,0,0,0,0,0,0,0,1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5,0]);\n\nconst extra_dbits =   /* extra bits for each distance code */\n  new Uint8Array([0,0,0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11,12,12,13,13]);\n\nconst extra_blbits =  /* extra bits for each bit length code */\n  new Uint8Array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,3,7]);\n\nconst bl_order =\n  new Uint8Array([16,17,18,0,8,7,9,6,10,5,11,4,12,3,13,2,14,1,15]);\n/* eslint-enable comma-spacing,array-bracket-spacing */\n\n/* The lengths of the bit length codes are sent in order of decreasing\n * probability, to avoid transmitting the lengths for unused bit length codes.\n */\n\n/* ===========================================================================\n * Local data. These are initialized only once.\n */\n\n// We pre-fill arrays with 0 to avoid uninitialized gaps\n\nconst DIST_CODE_LEN = 512; /* see definition of array dist_code below */\n\n// !!!! Use flat array instead of structure, Freq = i*2, Len = i*2+1\nconst static_ltree  = new Array((L_CODES$1 + 2) * 2);\nzero$1(static_ltree);\n/* The static literal tree. Since the bit lengths are imposed, there is no\n * need for the L_CODES extra codes used during heap construction. However\n * The codes 286 and 287 are needed to build a canonical tree (see _tr_init\n * below).\n */\n\nconst static_dtree  = new Array(D_CODES$1 * 2);\nzero$1(static_dtree);\n/* The static distance tree. (Actually a trivial tree since all codes use\n * 5 bits.)\n */\n\nconst _dist_code    = new Array(DIST_CODE_LEN);\nzero$1(_dist_code);\n/* Distance codes. The first 256 values correspond to the distances\n * 3 .. 258, the last 256 values correspond to the top 8 bits of\n * the 15 bit distances.\n */\n\nconst _length_code  = new Array(MAX_MATCH$1 - MIN_MATCH$1 + 1);\nzero$1(_length_code);\n/* length code for each normalized match length (0 == MIN_MATCH) */\n\nconst base_length   = new Array(LENGTH_CODES$1);\nzero$1(base_length);\n/* First normalized length for each code (0 = MIN_MATCH) */\n\nconst base_dist     = new Array(D_CODES$1);\nzero$1(base_dist);\n/* First normalized distance for each code (0 = distance of 1) */\n\n\nfunction StaticTreeDesc(static_tree, extra_bits, extra_base, elems, max_length) {\n\n  this.static_tree  = static_tree;  /* static tree or NULL */\n  this.extra_bits   = extra_bits;   /* extra bits for each code or NULL */\n  this.extra_base   = extra_base;   /* base index for extra_bits */\n  this.elems        = elems;        /* max number of elements in the tree */\n  this.max_length   = max_length;   /* max bit length for the codes */\n\n  // show if `static_tree` has data or dummy - needed for monomorphic objects\n  this.has_stree    = static_tree && static_tree.length;\n}\n\n\nlet static_l_desc;\nlet static_d_desc;\nlet static_bl_desc;\n\n\nfunction TreeDesc(dyn_tree, stat_desc) {\n  this.dyn_tree = dyn_tree;     /* the dynamic tree */\n  this.max_code = 0;            /* largest code with non zero frequency */\n  this.stat_desc = stat_desc;   /* the corresponding static tree */\n}\n\n\n\nconst d_code = (dist) => {\n\n  return dist < 256 ? _dist_code[dist] : _dist_code[256 + (dist >>> 7)];\n};\n\n\n/* ===========================================================================\n * Output a short LSB first on the stream.\n * IN assertion: there is enough room in pendingBuf.\n */\nconst put_short = (s, w) => {\n//    put_byte(s, (uch)((w) & 0xff));\n//    put_byte(s, (uch)((ush)(w) >> 8));\n  s.pending_buf[s.pending++] = (w) & 0xff;\n  s.pending_buf[s.pending++] = (w >>> 8) & 0xff;\n};\n\n\n/* ===========================================================================\n * Send a value on a given number of bits.\n * IN assertion: length <= 16 and value fits in length bits.\n */\nconst send_bits = (s, value, length) => {\n\n  if (s.bi_valid > (Buf_size - length)) {\n    s.bi_buf |= (value << s.bi_valid) & 0xffff;\n    put_short(s, s.bi_buf);\n    s.bi_buf = value >> (Buf_size - s.bi_valid);\n    s.bi_valid += length - Buf_size;\n  } else {\n    s.bi_buf |= (value << s.bi_valid) & 0xffff;\n    s.bi_valid += length;\n  }\n};\n\n\nconst send_code = (s, c, tree) => {\n\n  send_bits(s, tree[c * 2]/*.Code*/, tree[c * 2 + 1]/*.Len*/);\n};\n\n\n/* ===========================================================================\n * Reverse the first len bits of a code, using straightforward code (a faster\n * method would use a table)\n * IN assertion: 1 <= len <= 15\n */\nconst bi_reverse = (code, len) => {\n\n  let res = 0;\n  do {\n    res |= code & 1;\n    code >>>= 1;\n    res <<= 1;\n  } while (--len > 0);\n  return res >>> 1;\n};\n\n\n/* ===========================================================================\n * Flush the bit buffer, keeping at most 7 bits in it.\n */\nconst bi_flush = (s) => {\n\n  if (s.bi_valid === 16) {\n    put_short(s, s.bi_buf);\n    s.bi_buf = 0;\n    s.bi_valid = 0;\n\n  } else if (s.bi_valid >= 8) {\n    s.pending_buf[s.pending++] = s.bi_buf & 0xff;\n    s.bi_buf >>= 8;\n    s.bi_valid -= 8;\n  }\n};\n\n\n/* ===========================================================================\n * Compute the optimal bit lengths for a tree and update the total bit length\n * for the current block.\n * IN assertion: the fields freq and dad are set, heap[heap_max] and\n *    above are the tree nodes sorted by increasing frequency.\n * OUT assertions: the field len is set to the optimal bit length, the\n *     array bl_count contains the frequencies for each bit length.\n *     The length opt_len is updated; static_len is also updated if stree is\n *     not null.\n */\nconst gen_bitlen = (s, desc) => {\n//    deflate_state *s;\n//    tree_desc *desc;    /* the tree descriptor */\n\n  const tree            = desc.dyn_tree;\n  const max_code        = desc.max_code;\n  const stree           = desc.stat_desc.static_tree;\n  const has_stree       = desc.stat_desc.has_stree;\n  const extra           = desc.stat_desc.extra_bits;\n  const base            = desc.stat_desc.extra_base;\n  const max_length      = desc.stat_desc.max_length;\n  let h;              /* heap index */\n  let n, m;           /* iterate over the tree elements */\n  let bits;           /* bit length */\n  let xbits;          /* extra bits */\n  let f;              /* frequency */\n  let overflow = 0;   /* number of elements with bit length too large */\n\n  for (bits = 0; bits <= MAX_BITS$1; bits++) {\n    s.bl_count[bits] = 0;\n  }\n\n  /* In a first pass, compute the optimal bit lengths (which may\n   * overflow in the case of the bit length tree).\n   */\n  tree[s.heap[s.heap_max] * 2 + 1]/*.Len*/ = 0; /* root of the heap */\n\n  for (h = s.heap_max + 1; h < HEAP_SIZE$1; h++) {\n    n = s.heap[h];\n    bits = tree[tree[n * 2 + 1]/*.Dad*/ * 2 + 1]/*.Len*/ + 1;\n    if (bits > max_length) {\n      bits = max_length;\n      overflow++;\n    }\n    tree[n * 2 + 1]/*.Len*/ = bits;\n    /* We overwrite tree[n].Dad which is no longer needed */\n\n    if (n > max_code) { continue; } /* not a leaf node */\n\n    s.bl_count[bits]++;\n    xbits = 0;\n    if (n >= base) {\n      xbits = extra[n - base];\n    }\n    f = tree[n * 2]/*.Freq*/;\n    s.opt_len += f * (bits + xbits);\n    if (has_stree) {\n      s.static_len += f * (stree[n * 2 + 1]/*.Len*/ + xbits);\n    }\n  }\n  if (overflow === 0) { return; }\n\n  // Tracev((stderr,\"\\nbit length overflow\\n\"));\n  /* This happens for example on obj2 and pic of the Calgary corpus */\n\n  /* Find the first bit length which could increase: */\n  do {\n    bits = max_length - 1;\n    while (s.bl_count[bits] === 0) { bits--; }\n    s.bl_count[bits]--;      /* move one leaf down the tree */\n    s.bl_count[bits + 1] += 2; /* move one overflow item as its brother */\n    s.bl_count[max_length]--;\n    /* The brother of the overflow item also moves one step up,\n     * but this does not affect bl_count[max_length]\n     */\n    overflow -= 2;\n  } while (overflow > 0);\n\n  /* Now recompute all bit lengths, scanning in increasing frequency.\n   * h is still equal to HEAP_SIZE. (It is simpler to reconstruct all\n   * lengths instead of fixing only the wrong ones. This idea is taken\n   * from 'ar' written by Haruhiko Okumura.)\n   */\n  for (bits = max_length; bits !== 0; bits--) {\n    n = s.bl_count[bits];\n    while (n !== 0) {\n      m = s.heap[--h];\n      if (m > max_code) { continue; }\n      if (tree[m * 2 + 1]/*.Len*/ !== bits) {\n        // Tracev((stderr,\"code %d bits %d->%d\\n\", m, tree[m].Len, bits));\n        s.opt_len += (bits - tree[m * 2 + 1]/*.Len*/) * tree[m * 2]/*.Freq*/;\n        tree[m * 2 + 1]/*.Len*/ = bits;\n      }\n      n--;\n    }\n  }\n};\n\n\n/* ===========================================================================\n * Generate the codes for a given tree and bit counts (which need not be\n * optimal).\n * IN assertion: the array bl_count contains the bit length statistics for\n * the given tree and the field len is set for all tree elements.\n * OUT assertion: the field code is set for all tree elements of non\n *     zero code length.\n */\nconst gen_codes = (tree, max_code, bl_count) => {\n//    ct_data *tree;             /* the tree to decorate */\n//    int max_code;              /* largest code with non zero frequency */\n//    ushf *bl_count;            /* number of codes at each bit length */\n\n  const next_code = new Array(MAX_BITS$1 + 1); /* next code value for each bit length */\n  let code = 0;              /* running code value */\n  let bits;                  /* bit index */\n  let n;                     /* code index */\n\n  /* The distribution counts are first used to generate the code values\n   * without bit reversal.\n   */\n  for (bits = 1; bits <= MAX_BITS$1; bits++) {\n    code = (code + bl_count[bits - 1]) << 1;\n    next_code[bits] = code;\n  }\n  /* Check that the bit counts in bl_count are consistent. The last code\n   * must be all ones.\n   */\n  //Assert (code + bl_count[MAX_BITS]-1 == (1<<MAX_BITS)-1,\n  //        \"inconsistent bit counts\");\n  //Tracev((stderr,\"\\ngen_codes: max_code %d \", max_code));\n\n  for (n = 0;  n <= max_code; n++) {\n    let len = tree[n * 2 + 1]/*.Len*/;\n    if (len === 0) { continue; }\n    /* Now reverse the bits */\n    tree[n * 2]/*.Code*/ = bi_reverse(next_code[len]++, len);\n\n    //Tracecv(tree != static_ltree, (stderr,\"\\nn %3d %c l %2d c %4x (%x) \",\n    //     n, (isgraph(n) ? n : ' '), len, tree[n].Code, next_code[len]-1));\n  }\n};\n\n\n/* ===========================================================================\n * Initialize the various 'constant' tables.\n */\nconst tr_static_init = () => {\n\n  let n;        /* iterates over tree elements */\n  let bits;     /* bit counter */\n  let length;   /* length value */\n  let code;     /* code value */\n  let dist;     /* distance index */\n  const bl_count = new Array(MAX_BITS$1 + 1);\n  /* number of codes at each bit length for an optimal tree */\n\n  // do check in _tr_init()\n  //if (static_init_done) return;\n\n  /* For some embedded targets, global variables are not initialized: */\n/*#ifdef NO_INIT_GLOBAL_POINTERS\n  static_l_desc.static_tree = static_ltree;\n  static_l_desc.extra_bits = extra_lbits;\n  static_d_desc.static_tree = static_dtree;\n  static_d_desc.extra_bits = extra_dbits;\n  static_bl_desc.extra_bits = extra_blbits;\n#endif*/\n\n  /* Initialize the mapping length (0..255) -> length code (0..28) */\n  length = 0;\n  for (code = 0; code < LENGTH_CODES$1 - 1; code++) {\n    base_length[code] = length;\n    for (n = 0; n < (1 << extra_lbits[code]); n++) {\n      _length_code[length++] = code;\n    }\n  }\n  //Assert (length == 256, \"tr_static_init: length != 256\");\n  /* Note that the length 255 (match length 258) can be represented\n   * in two different ways: code 284 + 5 bits or code 285, so we\n   * overwrite length_code[255] to use the best encoding:\n   */\n  _length_code[length - 1] = code;\n\n  /* Initialize the mapping dist (0..32K) -> dist code (0..29) */\n  dist = 0;\n  for (code = 0; code < 16; code++) {\n    base_dist[code] = dist;\n    for (n = 0; n < (1 << extra_dbits[code]); n++) {\n      _dist_code[dist++] = code;\n    }\n  }\n  //Assert (dist == 256, \"tr_static_init: dist != 256\");\n  dist >>= 7; /* from now on, all distances are divided by 128 */\n  for (; code < D_CODES$1; code++) {\n    base_dist[code] = dist << 7;\n    for (n = 0; n < (1 << (extra_dbits[code] - 7)); n++) {\n      _dist_code[256 + dist++] = code;\n    }\n  }\n  //Assert (dist == 256, \"tr_static_init: 256+dist != 512\");\n\n  /* Construct the codes of the static literal tree */\n  for (bits = 0; bits <= MAX_BITS$1; bits++) {\n    bl_count[bits] = 0;\n  }\n\n  n = 0;\n  while (n <= 143) {\n    static_ltree[n * 2 + 1]/*.Len*/ = 8;\n    n++;\n    bl_count[8]++;\n  }\n  while (n <= 255) {\n    static_ltree[n * 2 + 1]/*.Len*/ = 9;\n    n++;\n    bl_count[9]++;\n  }\n  while (n <= 279) {\n    static_ltree[n * 2 + 1]/*.Len*/ = 7;\n    n++;\n    bl_count[7]++;\n  }\n  while (n <= 287) {\n    static_ltree[n * 2 + 1]/*.Len*/ = 8;\n    n++;\n    bl_count[8]++;\n  }\n  /* Codes 286 and 287 do not exist, but we must include them in the\n   * tree construction to get a canonical Huffman tree (longest code\n   * all ones)\n   */\n  gen_codes(static_ltree, L_CODES$1 + 1, bl_count);\n\n  /* The static distance tree is trivial: */\n  for (n = 0; n < D_CODES$1; n++) {\n    static_dtree[n * 2 + 1]/*.Len*/ = 5;\n    static_dtree[n * 2]/*.Code*/ = bi_reverse(n, 5);\n  }\n\n  // Now data ready and we can init static trees\n  static_l_desc = new StaticTreeDesc(static_ltree, extra_lbits, LITERALS$1 + 1, L_CODES$1, MAX_BITS$1);\n  static_d_desc = new StaticTreeDesc(static_dtree, extra_dbits, 0,          D_CODES$1, MAX_BITS$1);\n  static_bl_desc = new StaticTreeDesc(new Array(0), extra_blbits, 0,         BL_CODES$1, MAX_BL_BITS);\n\n  //static_init_done = true;\n};\n\n\n/* ===========================================================================\n * Initialize a new block.\n */\nconst init_block = (s) => {\n\n  let n; /* iterates over tree elements */\n\n  /* Initialize the trees. */\n  for (n = 0; n < L_CODES$1;  n++) { s.dyn_ltree[n * 2]/*.Freq*/ = 0; }\n  for (n = 0; n < D_CODES$1;  n++) { s.dyn_dtree[n * 2]/*.Freq*/ = 0; }\n  for (n = 0; n < BL_CODES$1; n++) { s.bl_tree[n * 2]/*.Freq*/ = 0; }\n\n  s.dyn_ltree[END_BLOCK * 2]/*.Freq*/ = 1;\n  s.opt_len = s.static_len = 0;\n  s.sym_next = s.matches = 0;\n};\n\n\n/* ===========================================================================\n * Flush the bit buffer and align the output on a byte boundary\n */\nconst bi_windup = (s) =>\n{\n  if (s.bi_valid > 8) {\n    put_short(s, s.bi_buf);\n  } else if (s.bi_valid > 0) {\n    //put_byte(s, (Byte)s->bi_buf);\n    s.pending_buf[s.pending++] = s.bi_buf;\n  }\n  s.bi_buf = 0;\n  s.bi_valid = 0;\n};\n\n/* ===========================================================================\n * Compares to subtrees, using the tree depth as tie breaker when\n * the subtrees have equal frequency. This minimizes the worst case length.\n */\nconst smaller = (tree, n, m, depth) => {\n\n  const _n2 = n * 2;\n  const _m2 = m * 2;\n  return (tree[_n2]/*.Freq*/ < tree[_m2]/*.Freq*/ ||\n         (tree[_n2]/*.Freq*/ === tree[_m2]/*.Freq*/ && depth[n] <= depth[m]));\n};\n\n/* ===========================================================================\n * Restore the heap property by moving down the tree starting at node k,\n * exchanging a node with the smallest of its two sons if necessary, stopping\n * when the heap property is re-established (each father smaller than its\n * two sons).\n */\nconst pqdownheap = (s, tree, k) => {\n//    deflate_state *s;\n//    ct_data *tree;  /* the tree to restore */\n//    int k;               /* node to move down */\n\n  const v = s.heap[k];\n  let j = k << 1;  /* left son of k */\n  while (j <= s.heap_len) {\n    /* Set j to the smallest of the two sons: */\n    if (j < s.heap_len &&\n      smaller(tree, s.heap[j + 1], s.heap[j], s.depth)) {\n      j++;\n    }\n    /* Exit if v is smaller than both sons */\n    if (smaller(tree, v, s.heap[j], s.depth)) { break; }\n\n    /* Exchange v with the smallest son */\n    s.heap[k] = s.heap[j];\n    k = j;\n\n    /* And continue down the tree, setting j to the left son of k */\n    j <<= 1;\n  }\n  s.heap[k] = v;\n};\n\n\n// inlined manually\n// const SMALLEST = 1;\n\n/* ===========================================================================\n * Send the block data compressed using the given Huffman trees\n */\nconst compress_block = (s, ltree, dtree) => {\n//    deflate_state *s;\n//    const ct_data *ltree; /* literal tree */\n//    const ct_data *dtree; /* distance tree */\n\n  let dist;           /* distance of matched string */\n  let lc;             /* match length or unmatched char (if dist == 0) */\n  let sx = 0;         /* running index in sym_buf */\n  let code;           /* the code to send */\n  let extra;          /* number of extra bits to send */\n\n  if (s.sym_next !== 0) {\n    do {\n      dist = s.pending_buf[s.sym_buf + sx++] & 0xff;\n      dist += (s.pending_buf[s.sym_buf + sx++] & 0xff) << 8;\n      lc = s.pending_buf[s.sym_buf + sx++];\n      if (dist === 0) {\n        send_code(s, lc, ltree); /* send a literal byte */\n        //Tracecv(isgraph(lc), (stderr,\" '%c' \", lc));\n      } else {\n        /* Here, lc is the match length - MIN_MATCH */\n        code = _length_code[lc];\n        send_code(s, code + LITERALS$1 + 1, ltree); /* send the length code */\n        extra = extra_lbits[code];\n        if (extra !== 0) {\n          lc -= base_length[code];\n          send_bits(s, lc, extra);       /* send the extra length bits */\n        }\n        dist--; /* dist is now the match distance - 1 */\n        code = d_code(dist);\n        //Assert (code < D_CODES, \"bad d_code\");\n\n        send_code(s, code, dtree);       /* send the distance code */\n        extra = extra_dbits[code];\n        if (extra !== 0) {\n          dist -= base_dist[code];\n          send_bits(s, dist, extra);   /* send the extra distance bits */\n        }\n      } /* literal or match pair ? */\n\n      /* Check that the overlay between pending_buf and sym_buf is ok: */\n      //Assert(s->pending < s->lit_bufsize + sx, \"pendingBuf overflow\");\n\n    } while (sx < s.sym_next);\n  }\n\n  send_code(s, END_BLOCK, ltree);\n};\n\n\n/* ===========================================================================\n * Construct one Huffman tree and assigns the code bit strings and lengths.\n * Update the total bit length for the current block.\n * IN assertion: the field freq is set for all tree elements.\n * OUT assertions: the fields len and code are set to the optimal bit length\n *     and corresponding code. The length opt_len is updated; static_len is\n *     also updated if stree is not null. The field max_code is set.\n */\nconst build_tree = (s, desc) => {\n//    deflate_state *s;\n//    tree_desc *desc; /* the tree descriptor */\n\n  const tree     = desc.dyn_tree;\n  const stree    = desc.stat_desc.static_tree;\n  const has_stree = desc.stat_desc.has_stree;\n  const elems    = desc.stat_desc.elems;\n  let n, m;          /* iterate over heap elements */\n  let max_code = -1; /* largest code with non zero frequency */\n  let node;          /* new node being created */\n\n  /* Construct the initial heap, with least frequent element in\n   * heap[SMALLEST]. The sons of heap[n] are heap[2*n] and heap[2*n+1].\n   * heap[0] is not used.\n   */\n  s.heap_len = 0;\n  s.heap_max = HEAP_SIZE$1;\n\n  for (n = 0; n < elems; n++) {\n    if (tree[n * 2]/*.Freq*/ !== 0) {\n      s.heap[++s.heap_len] = max_code = n;\n      s.depth[n] = 0;\n\n    } else {\n      tree[n * 2 + 1]/*.Len*/ = 0;\n    }\n  }\n\n  /* The pkzip format requires that at least one distance code exists,\n   * and that at least one bit should be sent even if there is only one\n   * possible code. So to avoid special checks later on we force at least\n   * two codes of non zero frequency.\n   */\n  while (s.heap_len < 2) {\n    node = s.heap[++s.heap_len] = (max_code < 2 ? ++max_code : 0);\n    tree[node * 2]/*.Freq*/ = 1;\n    s.depth[node] = 0;\n    s.opt_len--;\n\n    if (has_stree) {\n      s.static_len -= stree[node * 2 + 1]/*.Len*/;\n    }\n    /* node is 0 or 1 so it does not have extra bits */\n  }\n  desc.max_code = max_code;\n\n  /* The elements heap[heap_len/2+1 .. heap_len] are leaves of the tree,\n   * establish sub-heaps of increasing lengths:\n   */\n  for (n = (s.heap_len >> 1/*int /2*/); n >= 1; n--) { pqdownheap(s, tree, n); }\n\n  /* Construct the Huffman tree by repeatedly combining the least two\n   * frequent nodes.\n   */\n  node = elems;              /* next internal node of the tree */\n  do {\n    //pqremove(s, tree, n);  /* n = node of least frequency */\n    /*** pqremove ***/\n    n = s.heap[1/*SMALLEST*/];\n    s.heap[1/*SMALLEST*/] = s.heap[s.heap_len--];\n    pqdownheap(s, tree, 1/*SMALLEST*/);\n    /***/\n\n    m = s.heap[1/*SMALLEST*/]; /* m = node of next least frequency */\n\n    s.heap[--s.heap_max] = n; /* keep the nodes sorted by frequency */\n    s.heap[--s.heap_max] = m;\n\n    /* Create a new node father of n and m */\n    tree[node * 2]/*.Freq*/ = tree[n * 2]/*.Freq*/ + tree[m * 2]/*.Freq*/;\n    s.depth[node] = (s.depth[n] >= s.depth[m] ? s.depth[n] : s.depth[m]) + 1;\n    tree[n * 2 + 1]/*.Dad*/ = tree[m * 2 + 1]/*.Dad*/ = node;\n\n    /* and insert the new node in the heap */\n    s.heap[1/*SMALLEST*/] = node++;\n    pqdownheap(s, tree, 1/*SMALLEST*/);\n\n  } while (s.heap_len >= 2);\n\n  s.heap[--s.heap_max] = s.heap[1/*SMALLEST*/];\n\n  /* At this point, the fields freq and dad are set. We can now\n   * generate the bit lengths.\n   */\n  gen_bitlen(s, desc);\n\n  /* The field len is now set, we can generate the bit codes */\n  gen_codes(tree, max_code, s.bl_count);\n};\n\n\n/* ===========================================================================\n * Scan a literal or distance tree to determine the frequencies of the codes\n * in the bit length tree.\n */\nconst scan_tree = (s, tree, max_code) => {\n//    deflate_state *s;\n//    ct_data *tree;   /* the tree to be scanned */\n//    int max_code;    /* and its largest code of non zero frequency */\n\n  let n;                     /* iterates over all tree elements */\n  let prevlen = -1;          /* last emitted length */\n  let curlen;                /* length of current code */\n\n  let nextlen = tree[0 * 2 + 1]/*.Len*/; /* length of next code */\n\n  let count = 0;             /* repeat count of the current code */\n  let max_count = 7;         /* max repeat count */\n  let min_count = 4;         /* min repeat count */\n\n  if (nextlen === 0) {\n    max_count = 138;\n    min_count = 3;\n  }\n  tree[(max_code + 1) * 2 + 1]/*.Len*/ = 0xffff; /* guard */\n\n  for (n = 0; n <= max_code; n++) {\n    curlen = nextlen;\n    nextlen = tree[(n + 1) * 2 + 1]/*.Len*/;\n\n    if (++count < max_count && curlen === nextlen) {\n      continue;\n\n    } else if (count < min_count) {\n      s.bl_tree[curlen * 2]/*.Freq*/ += count;\n\n    } else if (curlen !== 0) {\n\n      if (curlen !== prevlen) { s.bl_tree[curlen * 2]/*.Freq*/++; }\n      s.bl_tree[REP_3_6 * 2]/*.Freq*/++;\n\n    } else if (count <= 10) {\n      s.bl_tree[REPZ_3_10 * 2]/*.Freq*/++;\n\n    } else {\n      s.bl_tree[REPZ_11_138 * 2]/*.Freq*/++;\n    }\n\n    count = 0;\n    prevlen = curlen;\n\n    if (nextlen === 0) {\n      max_count = 138;\n      min_count = 3;\n\n    } else if (curlen === nextlen) {\n      max_count = 6;\n      min_count = 3;\n\n    } else {\n      max_count = 7;\n      min_count = 4;\n    }\n  }\n};\n\n\n/* ===========================================================================\n * Send a literal or distance tree in compressed form, using the codes in\n * bl_tree.\n */\nconst send_tree = (s, tree, max_code) => {\n//    deflate_state *s;\n//    ct_data *tree; /* the tree to be scanned */\n//    int max_code;       /* and its largest code of non zero frequency */\n\n  let n;                     /* iterates over all tree elements */\n  let prevlen = -1;          /* last emitted length */\n  let curlen;                /* length of current code */\n\n  let nextlen = tree[0 * 2 + 1]/*.Len*/; /* length of next code */\n\n  let count = 0;             /* repeat count of the current code */\n  let max_count = 7;         /* max repeat count */\n  let min_count = 4;         /* min repeat count */\n\n  /* tree[max_code+1].Len = -1; */  /* guard already set */\n  if (nextlen === 0) {\n    max_count = 138;\n    min_count = 3;\n  }\n\n  for (n = 0; n <= max_code; n++) {\n    curlen = nextlen;\n    nextlen = tree[(n + 1) * 2 + 1]/*.Len*/;\n\n    if (++count < max_count && curlen === nextlen) {\n      continue;\n\n    } else if (count < min_count) {\n      do { send_code(s, curlen, s.bl_tree); } while (--count !== 0);\n\n    } else if (curlen !== 0) {\n      if (curlen !== prevlen) {\n        send_code(s, curlen, s.bl_tree);\n        count--;\n      }\n      //Assert(count >= 3 && count <= 6, \" 3_6?\");\n      send_code(s, REP_3_6, s.bl_tree);\n      send_bits(s, count - 3, 2);\n\n    } else if (count <= 10) {\n      send_code(s, REPZ_3_10, s.bl_tree);\n      send_bits(s, count - 3, 3);\n\n    } else {\n      send_code(s, REPZ_11_138, s.bl_tree);\n      send_bits(s, count - 11, 7);\n    }\n\n    count = 0;\n    prevlen = curlen;\n    if (nextlen === 0) {\n      max_count = 138;\n      min_count = 3;\n\n    } else if (curlen === nextlen) {\n      max_count = 6;\n      min_count = 3;\n\n    } else {\n      max_count = 7;\n      min_count = 4;\n    }\n  }\n};\n\n\n/* ===========================================================================\n * Construct the Huffman tree for the bit lengths and return the index in\n * bl_order of the last bit length code to send.\n */\nconst build_bl_tree = (s) => {\n\n  let max_blindex;  /* index of last bit length code of non zero freq */\n\n  /* Determine the bit length frequencies for literal and distance trees */\n  scan_tree(s, s.dyn_ltree, s.l_desc.max_code);\n  scan_tree(s, s.dyn_dtree, s.d_desc.max_code);\n\n  /* Build the bit length tree: */\n  build_tree(s, s.bl_desc);\n  /* opt_len now includes the length of the tree representations, except\n   * the lengths of the bit lengths codes and the 5+5+4 bits for the counts.\n   */\n\n  /* Determine the number of bit length codes to send. The pkzip format\n   * requires that at least 4 bit length codes be sent. (appnote.txt says\n   * 3 but the actual value used is 4.)\n   */\n  for (max_blindex = BL_CODES$1 - 1; max_blindex >= 3; max_blindex--) {\n    if (s.bl_tree[bl_order[max_blindex] * 2 + 1]/*.Len*/ !== 0) {\n      break;\n    }\n  }\n  /* Update opt_len to include the bit length tree and counts */\n  s.opt_len += 3 * (max_blindex + 1) + 5 + 5 + 4;\n  //Tracev((stderr, \"\\ndyn trees: dyn %ld, stat %ld\",\n  //        s->opt_len, s->static_len));\n\n  return max_blindex;\n};\n\n\n/* ===========================================================================\n * Send the header for a block using dynamic Huffman trees: the counts, the\n * lengths of the bit length codes, the literal tree and the distance tree.\n * IN assertion: lcodes >= 257, dcodes >= 1, blcodes >= 4.\n */\nconst send_all_trees = (s, lcodes, dcodes, blcodes) => {\n//    deflate_state *s;\n//    int lcodes, dcodes, blcodes; /* number of codes for each tree */\n\n  let rank;                    /* index in bl_order */\n\n  //Assert (lcodes >= 257 && dcodes >= 1 && blcodes >= 4, \"not enough codes\");\n  //Assert (lcodes <= L_CODES && dcodes <= D_CODES && blcodes <= BL_CODES,\n  //        \"too many codes\");\n  //Tracev((stderr, \"\\nbl counts: \"));\n  send_bits(s, lcodes - 257, 5); /* not +255 as stated in appnote.txt */\n  send_bits(s, dcodes - 1,   5);\n  send_bits(s, blcodes - 4,  4); /* not -3 as stated in appnote.txt */\n  for (rank = 0; rank < blcodes; rank++) {\n    //Tracev((stderr, \"\\nbl code %2d \", bl_order[rank]));\n    send_bits(s, s.bl_tree[bl_order[rank] * 2 + 1]/*.Len*/, 3);\n  }\n  //Tracev((stderr, \"\\nbl tree: sent %ld\", s->bits_sent));\n\n  send_tree(s, s.dyn_ltree, lcodes - 1); /* literal tree */\n  //Tracev((stderr, \"\\nlit tree: sent %ld\", s->bits_sent));\n\n  send_tree(s, s.dyn_dtree, dcodes - 1); /* distance tree */\n  //Tracev((stderr, \"\\ndist tree: sent %ld\", s->bits_sent));\n};\n\n\n/* ===========================================================================\n * Check if the data type is TEXT or BINARY, using the following algorithm:\n * - TEXT if the two conditions below are satisfied:\n *    a) There are no non-portable control characters belonging to the\n *       \"block list\" (0..6, 14..25, 28..31).\n *    b) There is at least one printable character belonging to the\n *       \"allow list\" (9 {TAB}, 10 {LF}, 13 {CR}, 32..255).\n * - BINARY otherwise.\n * - The following partially-portable control characters form a\n *   \"gray list\" that is ignored in this detection algorithm:\n *   (7 {BEL}, 8 {BS}, 11 {VT}, 12 {FF}, 26 {SUB}, 27 {ESC}).\n * IN assertion: the fields Freq of dyn_ltree are set.\n */\nconst detect_data_type = (s) => {\n  /* block_mask is the bit mask of block-listed bytes\n   * set bits 0..6, 14..25, and 28..31\n   * 0xf3ffc07f = binary 11110011111111111100000001111111\n   */\n  let block_mask = 0xf3ffc07f;\n  let n;\n\n  /* Check for non-textual (\"block-listed\") bytes. */\n  for (n = 0; n <= 31; n++, block_mask >>>= 1) {\n    if ((block_mask & 1) && (s.dyn_ltree[n * 2]/*.Freq*/ !== 0)) {\n      return Z_BINARY;\n    }\n  }\n\n  /* Check for textual (\"allow-listed\") bytes. */\n  if (s.dyn_ltree[9 * 2]/*.Freq*/ !== 0 || s.dyn_ltree[10 * 2]/*.Freq*/ !== 0 ||\n      s.dyn_ltree[13 * 2]/*.Freq*/ !== 0) {\n    return Z_TEXT;\n  }\n  for (n = 32; n < LITERALS$1; n++) {\n    if (s.dyn_ltree[n * 2]/*.Freq*/ !== 0) {\n      return Z_TEXT;\n    }\n  }\n\n  /* There are no \"block-listed\" or \"allow-listed\" bytes:\n   * this stream either is empty or has tolerated (\"gray-listed\") bytes only.\n   */\n  return Z_BINARY;\n};\n\n\nlet static_init_done = false;\n\n/* ===========================================================================\n * Initialize the tree data structures for a new zlib stream.\n */\nconst _tr_init$1 = (s) =>\n{\n\n  if (!static_init_done) {\n    tr_static_init();\n    static_init_done = true;\n  }\n\n  s.l_desc  = new TreeDesc(s.dyn_ltree, static_l_desc);\n  s.d_desc  = new TreeDesc(s.dyn_dtree, static_d_desc);\n  s.bl_desc = new TreeDesc(s.bl_tree, static_bl_desc);\n\n  s.bi_buf = 0;\n  s.bi_valid = 0;\n\n  /* Initialize the first block of the first file: */\n  init_block(s);\n};\n\n\n/* ===========================================================================\n * Send a stored block\n */\nconst _tr_stored_block$1 = (s, buf, stored_len, last) => {\n//DeflateState *s;\n//charf *buf;       /* input block */\n//ulg stored_len;   /* length of input block */\n//int last;         /* one if this is the last block for a file */\n\n  send_bits(s, (STORED_BLOCK << 1) + (last ? 1 : 0), 3);    /* send block type */\n  bi_windup(s);        /* align on byte boundary */\n  put_short(s, stored_len);\n  put_short(s, ~stored_len);\n  if (stored_len) {\n    s.pending_buf.set(s.window.subarray(buf, buf + stored_len), s.pending);\n  }\n  s.pending += stored_len;\n};\n\n\n/* ===========================================================================\n * Send one empty static block to give enough lookahead for inflate.\n * This takes 10 bits, of which 7 may remain in the bit buffer.\n */\nconst _tr_align$1 = (s) => {\n  send_bits(s, STATIC_TREES << 1, 3);\n  send_code(s, END_BLOCK, static_ltree);\n  bi_flush(s);\n};\n\n\n/* ===========================================================================\n * Determine the best encoding for the current block: dynamic trees, static\n * trees or store, and write out the encoded block.\n */\nconst _tr_flush_block$1 = (s, buf, stored_len, last) => {\n//DeflateState *s;\n//charf *buf;       /* input block, or NULL if too old */\n//ulg stored_len;   /* length of input block */\n//int last;         /* one if this is the last block for a file */\n\n  let opt_lenb, static_lenb;  /* opt_len and static_len in bytes */\n  let max_blindex = 0;        /* index of last bit length code of non zero freq */\n\n  /* Build the Huffman trees unless a stored block is forced */\n  if (s.level > 0) {\n\n    /* Check if the file is binary or text */\n    if (s.strm.data_type === Z_UNKNOWN$1) {\n      s.strm.data_type = detect_data_type(s);\n    }\n\n    /* Construct the literal and distance trees */\n    build_tree(s, s.l_desc);\n    // Tracev((stderr, \"\\nlit data: dyn %ld, stat %ld\", s->opt_len,\n    //        s->static_len));\n\n    build_tree(s, s.d_desc);\n    // Tracev((stderr, \"\\ndist data: dyn %ld, stat %ld\", s->opt_len,\n    //        s->static_len));\n    /* At this point, opt_len and static_len are the total bit lengths of\n     * the compressed block data, excluding the tree representations.\n     */\n\n    /* Build the bit length tree for the above two trees, and get the index\n     * in bl_order of the last bit length code to send.\n     */\n    max_blindex = build_bl_tree(s);\n\n    /* Determine the best encoding. Compute the block lengths in bytes. */\n    opt_lenb = (s.opt_len + 3 + 7) >>> 3;\n    static_lenb = (s.static_len + 3 + 7) >>> 3;\n\n    // Tracev((stderr, \"\\nopt %lu(%lu) stat %lu(%lu) stored %lu lit %u \",\n    //        opt_lenb, s->opt_len, static_lenb, s->static_len, stored_len,\n    //        s->sym_next / 3));\n\n    if (static_lenb <= opt_lenb) { opt_lenb = static_lenb; }\n\n  } else {\n    // Assert(buf != (char*)0, \"lost buf\");\n    opt_lenb = static_lenb = stored_len + 5; /* force a stored block */\n  }\n\n  if ((stored_len + 4 <= opt_lenb) && (buf !== -1)) {\n    /* 4: two words for the lengths */\n\n    /* The test buf != NULL is only necessary if LIT_BUFSIZE > WSIZE.\n     * Otherwise we can't have processed more than WSIZE input bytes since\n     * the last block flush, because compression would have been\n     * successful. If LIT_BUFSIZE <= WSIZE, it is never too late to\n     * transform a block into a stored block.\n     */\n    _tr_stored_block$1(s, buf, stored_len, last);\n\n  } else if (s.strategy === Z_FIXED$1 || static_lenb === opt_lenb) {\n\n    send_bits(s, (STATIC_TREES << 1) + (last ? 1 : 0), 3);\n    compress_block(s, static_ltree, static_dtree);\n\n  } else {\n    send_bits(s, (DYN_TREES << 1) + (last ? 1 : 0), 3);\n    send_all_trees(s, s.l_desc.max_code + 1, s.d_desc.max_code + 1, max_blindex + 1);\n    compress_block(s, s.dyn_ltree, s.dyn_dtree);\n  }\n  // Assert (s->compressed_len == s->bits_sent, \"bad compressed size\");\n  /* The above check is made mod 2^32, for files larger than 512 MB\n   * and uLong implemented on 32 bits.\n   */\n  init_block(s);\n\n  if (last) {\n    bi_windup(s);\n  }\n  // Tracev((stderr,\"\\ncomprlen %lu(%lu) \", s->compressed_len>>3,\n  //       s->compressed_len-7*last));\n};\n\n/* ===========================================================================\n * Save the match info and tally the frequency counts. Return true if\n * the current block must be flushed.\n */\nconst _tr_tally$1 = (s, dist, lc) => {\n//    deflate_state *s;\n//    unsigned dist;  /* distance of matched string */\n//    unsigned lc;    /* match length-MIN_MATCH or unmatched char (if dist==0) */\n\n  s.pending_buf[s.sym_buf + s.sym_next++] = dist;\n  s.pending_buf[s.sym_buf + s.sym_next++] = dist >> 8;\n  s.pending_buf[s.sym_buf + s.sym_next++] = lc;\n  if (dist === 0) {\n    /* lc is the unmatched char */\n    s.dyn_ltree[lc * 2]/*.Freq*/++;\n  } else {\n    s.matches++;\n    /* Here, lc is the match length - MIN_MATCH */\n    dist--;             /* dist = match distance - 1 */\n    //Assert((ush)dist < (ush)MAX_DIST(s) &&\n    //       (ush)lc <= (ush)(MAX_MATCH-MIN_MATCH) &&\n    //       (ush)d_code(dist) < (ush)D_CODES,  \"_tr_tally: bad match\");\n\n    s.dyn_ltree[(_length_code[lc] + LITERALS$1 + 1) * 2]/*.Freq*/++;\n    s.dyn_dtree[d_code(dist) * 2]/*.Freq*/++;\n  }\n\n  return (s.sym_next === s.sym_end);\n};\n\nvar _tr_init_1  = _tr_init$1;\nvar _tr_stored_block_1 = _tr_stored_block$1;\nvar _tr_flush_block_1  = _tr_flush_block$1;\nvar _tr_tally_1 = _tr_tally$1;\nvar _tr_align_1 = _tr_align$1;\n\nvar trees = {\n\t_tr_init: _tr_init_1,\n\t_tr_stored_block: _tr_stored_block_1,\n\t_tr_flush_block: _tr_flush_block_1,\n\t_tr_tally: _tr_tally_1,\n\t_tr_align: _tr_align_1\n};\n\n// Note: adler32 takes 12% for level 0 and 2% for level 6.\n// It isn't worth it to make additional optimizations as in original.\n// Small size is preferable.\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nconst adler32 = (adler, buf, len, pos) => {\n  let s1 = (adler & 0xffff) |0,\n      s2 = ((adler >>> 16) & 0xffff) |0,\n      n = 0;\n\n  while (len !== 0) {\n    // Set limit ~ twice less than 5552, to keep\n    // s2 in 31-bits, because we force signed ints.\n    // in other case %= will fail.\n    n = len > 2000 ? 2000 : len;\n    len -= n;\n\n    do {\n      s1 = (s1 + buf[pos++]) |0;\n      s2 = (s2 + s1) |0;\n    } while (--n);\n\n    s1 %= 65521;\n    s2 %= 65521;\n  }\n\n  return (s1 | (s2 << 16)) |0;\n};\n\n\nvar adler32_1 = adler32;\n\n// Note: we can't get significant speed boost here.\n// So write code to minimize size - no pregenerated tables\n// and array tools dependencies.\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\n// Use ordinary array, since untyped makes no boost here\nconst makeTable = () => {\n  let c, table = [];\n\n  for (var n = 0; n < 256; n++) {\n    c = n;\n    for (var k = 0; k < 8; k++) {\n      c = ((c & 1) ? (0xEDB88320 ^ (c >>> 1)) : (c >>> 1));\n    }\n    table[n] = c;\n  }\n\n  return table;\n};\n\n// Create table on load. Just 255 signed longs. Not a problem.\nconst crcTable = new Uint32Array(makeTable());\n\n\nconst crc32 = (crc, buf, len, pos) => {\n  const t = crcTable;\n  const end = pos + len;\n\n  crc ^= -1;\n\n  for (let i = pos; i < end; i++) {\n    crc = (crc >>> 8) ^ t[(crc ^ buf[i]) & 0xFF];\n  }\n\n  return (crc ^ (-1)); // >>> 0;\n};\n\n\nvar crc32_1 = crc32;\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nvar messages = {\n  2:      'need dictionary',     /* Z_NEED_DICT       2  */\n  1:      'stream end',          /* Z_STREAM_END      1  */\n  0:      '',                    /* Z_OK              0  */\n  '-1':   'file error',          /* Z_ERRNO         (-1) */\n  '-2':   'stream error',        /* Z_STREAM_ERROR  (-2) */\n  '-3':   'data error',          /* Z_DATA_ERROR    (-3) */\n  '-4':   'insufficient memory', /* Z_MEM_ERROR     (-4) */\n  '-5':   'buffer error',        /* Z_BUF_ERROR     (-5) */\n  '-6':   'incompatible version' /* Z_VERSION_ERROR (-6) */\n};\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nvar constants$2 = {\n\n  /* Allowed flush values; see deflate() and inflate() below for details */\n  Z_NO_FLUSH:         0,\n  Z_PARTIAL_FLUSH:    1,\n  Z_SYNC_FLUSH:       2,\n  Z_FULL_FLUSH:       3,\n  Z_FINISH:           4,\n  Z_BLOCK:            5,\n  Z_TREES:            6,\n\n  /* Return codes for the compression/decompression functions. Negative values\n  * are errors, positive values are used for special but normal events.\n  */\n  Z_OK:               0,\n  Z_STREAM_END:       1,\n  Z_NEED_DICT:        2,\n  Z_ERRNO:           -1,\n  Z_STREAM_ERROR:    -2,\n  Z_DATA_ERROR:      -3,\n  Z_MEM_ERROR:       -4,\n  Z_BUF_ERROR:       -5,\n  //Z_VERSION_ERROR: -6,\n\n  /* compression levels */\n  Z_NO_COMPRESSION:         0,\n  Z_BEST_SPEED:             1,\n  Z_BEST_COMPRESSION:       9,\n  Z_DEFAULT_COMPRESSION:   -1,\n\n\n  Z_FILTERED:               1,\n  Z_HUFFMAN_ONLY:           2,\n  Z_RLE:                    3,\n  Z_FIXED:                  4,\n  Z_DEFAULT_STRATEGY:       0,\n\n  /* Possible values of the data_type field (though see inflate()) */\n  Z_BINARY:                 0,\n  Z_TEXT:                   1,\n  //Z_ASCII:                1, // = Z_TEXT (deprecated)\n  Z_UNKNOWN:                2,\n\n  /* The deflate compression method */\n  Z_DEFLATED:               8\n  //Z_NULL:                 null // Use -1 or null inline, depending on var type\n};\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nconst { _tr_init, _tr_stored_block, _tr_flush_block, _tr_tally, _tr_align } = trees;\n\n\n\n\n/* Public constants ==========================================================*/\n/* ===========================================================================*/\n\nconst {\n  Z_NO_FLUSH: Z_NO_FLUSH$2, Z_PARTIAL_FLUSH, Z_FULL_FLUSH: Z_FULL_FLUSH$1, Z_FINISH: Z_FINISH$3, Z_BLOCK: Z_BLOCK$1,\n  Z_OK: Z_OK$3, Z_STREAM_END: Z_STREAM_END$3, Z_STREAM_ERROR: Z_STREAM_ERROR$2, Z_DATA_ERROR: Z_DATA_ERROR$2, Z_BUF_ERROR: Z_BUF_ERROR$1,\n  Z_DEFAULT_COMPRESSION: Z_DEFAULT_COMPRESSION$1,\n  Z_FILTERED, Z_HUFFMAN_ONLY, Z_RLE, Z_FIXED, Z_DEFAULT_STRATEGY: Z_DEFAULT_STRATEGY$1,\n  Z_UNKNOWN,\n  Z_DEFLATED: Z_DEFLATED$2\n} = constants$2;\n\n/*============================================================================*/\n\n\nconst MAX_MEM_LEVEL = 9;\n/* Maximum value for memLevel in deflateInit2 */\nconst MAX_WBITS$1 = 15;\n/* 32K LZ77 window */\nconst DEF_MEM_LEVEL = 8;\n\n\nconst LENGTH_CODES  = 29;\n/* number of length codes, not counting the special END_BLOCK code */\nconst LITERALS      = 256;\n/* number of literal bytes 0..255 */\nconst L_CODES       = LITERALS + 1 + LENGTH_CODES;\n/* number of Literal or Length codes, including the END_BLOCK code */\nconst D_CODES       = 30;\n/* number of distance codes */\nconst BL_CODES      = 19;\n/* number of codes used to transfer the bit lengths */\nconst HEAP_SIZE     = 2 * L_CODES + 1;\n/* maximum heap size */\nconst MAX_BITS  = 15;\n/* All codes must not exceed MAX_BITS bits */\n\nconst MIN_MATCH = 3;\nconst MAX_MATCH = 258;\nconst MIN_LOOKAHEAD = (MAX_MATCH + MIN_MATCH + 1);\n\nconst PRESET_DICT = 0x20;\n\nconst INIT_STATE    =  42;    /* zlib header -> BUSY_STATE */\n//#ifdef GZIP\nconst GZIP_STATE    =  57;    /* gzip header -> BUSY_STATE | EXTRA_STATE */\n//#endif\nconst EXTRA_STATE   =  69;    /* gzip extra block -> NAME_STATE */\nconst NAME_STATE    =  73;    /* gzip file name -> COMMENT_STATE */\nconst COMMENT_STATE =  91;    /* gzip comment -> HCRC_STATE */\nconst HCRC_STATE    = 103;    /* gzip header CRC -> BUSY_STATE */\nconst BUSY_STATE    = 113;    /* deflate -> FINISH_STATE */\nconst FINISH_STATE  = 666;    /* stream complete */\n\nconst BS_NEED_MORE      = 1; /* block not completed, need more input or more output */\nconst BS_BLOCK_DONE     = 2; /* block flush performed */\nconst BS_FINISH_STARTED = 3; /* finish started, need only more output at next deflate */\nconst BS_FINISH_DONE    = 4; /* finish done, accept no more input or output */\n\nconst OS_CODE = 0x03; // Unix :) . Don't detect, use this default.\n\nconst err = (strm, errorCode) => {\n  strm.msg = messages[errorCode];\n  return errorCode;\n};\n\nconst rank = (f) => {\n  return ((f) * 2) - ((f) > 4 ? 9 : 0);\n};\n\nconst zero = (buf) => {\n  let len = buf.length; while (--len >= 0) { buf[len] = 0; }\n};\n\n/* ===========================================================================\n * Slide the hash table when sliding the window down (could be avoided with 32\n * bit values at the expense of memory usage). We slide even when level == 0 to\n * keep the hash table consistent if we switch back to level > 0 later.\n */\nconst slide_hash = (s) => {\n  let n, m;\n  let p;\n  let wsize = s.w_size;\n\n  n = s.hash_size;\n  p = n;\n  do {\n    m = s.head[--p];\n    s.head[p] = (m >= wsize ? m - wsize : 0);\n  } while (--n);\n  n = wsize;\n//#ifndef FASTEST\n  p = n;\n  do {\n    m = s.prev[--p];\n    s.prev[p] = (m >= wsize ? m - wsize : 0);\n    /* If n is not on any hash chain, prev[n] is garbage but\n     * its value will never be used.\n     */\n  } while (--n);\n//#endif\n};\n\n/* eslint-disable new-cap */\nlet HASH_ZLIB = (s, prev, data) => ((prev << s.hash_shift) ^ data) & s.hash_mask;\n// This hash causes less collisions, https://github.com/nodeca/pako/issues/135\n// But breaks binary compatibility\n//let HASH_FAST = (s, prev, data) => ((prev << 8) + (prev >> 8) + (data << 4)) & s.hash_mask;\nlet HASH = HASH_ZLIB;\n\n\n/* =========================================================================\n * Flush as much pending output as possible. All deflate() output, except for\n * some deflate_stored() output, goes through this function so some\n * applications may wish to modify it to avoid allocating a large\n * strm->next_out buffer and copying into it. (See also read_buf()).\n */\nconst flush_pending = (strm) => {\n  const s = strm.state;\n\n  //_tr_flush_bits(s);\n  let len = s.pending;\n  if (len > strm.avail_out) {\n    len = strm.avail_out;\n  }\n  if (len === 0) { return; }\n\n  strm.output.set(s.pending_buf.subarray(s.pending_out, s.pending_out + len), strm.next_out);\n  strm.next_out  += len;\n  s.pending_out  += len;\n  strm.total_out += len;\n  strm.avail_out -= len;\n  s.pending      -= len;\n  if (s.pending === 0) {\n    s.pending_out = 0;\n  }\n};\n\n\nconst flush_block_only = (s, last) => {\n  _tr_flush_block(s, (s.block_start >= 0 ? s.block_start : -1), s.strstart - s.block_start, last);\n  s.block_start = s.strstart;\n  flush_pending(s.strm);\n};\n\n\nconst put_byte = (s, b) => {\n  s.pending_buf[s.pending++] = b;\n};\n\n\n/* =========================================================================\n * Put a short in the pending buffer. The 16-bit value is put in MSB order.\n * IN assertion: the stream state is correct and there is enough room in\n * pending_buf.\n */\nconst putShortMSB = (s, b) => {\n\n  //  put_byte(s, (Byte)(b >> 8));\n//  put_byte(s, (Byte)(b & 0xff));\n  s.pending_buf[s.pending++] = (b >>> 8) & 0xff;\n  s.pending_buf[s.pending++] = b & 0xff;\n};\n\n\n/* ===========================================================================\n * Read a new buffer from the current input stream, update the adler32\n * and total number of bytes read.  All deflate() input goes through\n * this function so some applications may wish to modify it to avoid\n * allocating a large strm->input buffer and copying from it.\n * (See also flush_pending()).\n */\nconst read_buf = (strm, buf, start, size) => {\n\n  let len = strm.avail_in;\n\n  if (len > size) { len = size; }\n  if (len === 0) { return 0; }\n\n  strm.avail_in -= len;\n\n  // zmemcpy(buf, strm->next_in, len);\n  buf.set(strm.input.subarray(strm.next_in, strm.next_in + len), start);\n  if (strm.state.wrap === 1) {\n    strm.adler = adler32_1(strm.adler, buf, len, start);\n  }\n\n  else if (strm.state.wrap === 2) {\n    strm.adler = crc32_1(strm.adler, buf, len, start);\n  }\n\n  strm.next_in += len;\n  strm.total_in += len;\n\n  return len;\n};\n\n\n/* ===========================================================================\n * Set match_start to the longest match starting at the given string and\n * return its length. Matches shorter or equal to prev_length are discarded,\n * in which case the result is equal to prev_length and match_start is\n * garbage.\n * IN assertions: cur_match is the head of the hash chain for the current\n *   string (strstart) and its distance is <= MAX_DIST, and prev_length >= 1\n * OUT assertion: the match length is not greater than s->lookahead.\n */\nconst longest_match = (s, cur_match) => {\n\n  let chain_length = s.max_chain_length;      /* max hash chain length */\n  let scan = s.strstart; /* current string */\n  let match;                       /* matched string */\n  let len;                           /* length of current match */\n  let best_len = s.prev_length;              /* best match length so far */\n  let nice_match = s.nice_match;             /* stop if match long enough */\n  const limit = (s.strstart > (s.w_size - MIN_LOOKAHEAD)) ?\n      s.strstart - (s.w_size - MIN_LOOKAHEAD) : 0/*NIL*/;\n\n  const _win = s.window; // shortcut\n\n  const wmask = s.w_mask;\n  const prev  = s.prev;\n\n  /* Stop when cur_match becomes <= limit. To simplify the code,\n   * we prevent matches with the string of window index 0.\n   */\n\n  const strend = s.strstart + MAX_MATCH;\n  let scan_end1  = _win[scan + best_len - 1];\n  let scan_end   = _win[scan + best_len];\n\n  /* The code is optimized for HASH_BITS >= 8 and MAX_MATCH-2 multiple of 16.\n   * It is easy to get rid of this optimization if necessary.\n   */\n  // Assert(s->hash_bits >= 8 && MAX_MATCH == 258, \"Code too clever\");\n\n  /* Do not waste too much time if we already have a good match: */\n  if (s.prev_length >= s.good_match) {\n    chain_length >>= 2;\n  }\n  /* Do not look for matches beyond the end of the input. This is necessary\n   * to make deflate deterministic.\n   */\n  if (nice_match > s.lookahead) { nice_match = s.lookahead; }\n\n  // Assert((ulg)s->strstart <= s->window_size-MIN_LOOKAHEAD, \"need lookahead\");\n\n  do {\n    // Assert(cur_match < s->strstart, \"no future\");\n    match = cur_match;\n\n    /* Skip to next match if the match length cannot increase\n     * or if the match length is less than 2.  Note that the checks below\n     * for insufficient lookahead only occur occasionally for performance\n     * reasons.  Therefore uninitialized memory will be accessed, and\n     * conditional jumps will be made that depend on those values.\n     * However the length of the match is limited to the lookahead, so\n     * the output of deflate is not affected by the uninitialized values.\n     */\n\n    if (_win[match + best_len]     !== scan_end  ||\n        _win[match + best_len - 1] !== scan_end1 ||\n        _win[match]                !== _win[scan] ||\n        _win[++match]              !== _win[scan + 1]) {\n      continue;\n    }\n\n    /* The check at best_len-1 can be removed because it will be made\n     * again later. (This heuristic is not always a win.)\n     * It is not necessary to compare scan[2] and match[2] since they\n     * are always equal when the other bytes match, given that\n     * the hash keys are equal and that HASH_BITS >= 8.\n     */\n    scan += 2;\n    match++;\n    // Assert(*scan == *match, \"match[2]?\");\n\n    /* We check for insufficient lookahead only every 8th comparison;\n     * the 256th check will be made at strstart+258.\n     */\n    do {\n      /*jshint noempty:false*/\n    } while (_win[++scan] === _win[++match] && _win[++scan] === _win[++match] &&\n             _win[++scan] === _win[++match] && _win[++scan] === _win[++match] &&\n             _win[++scan] === _win[++match] && _win[++scan] === _win[++match] &&\n             _win[++scan] === _win[++match] && _win[++scan] === _win[++match] &&\n             scan < strend);\n\n    // Assert(scan <= s->window+(unsigned)(s->window_size-1), \"wild scan\");\n\n    len = MAX_MATCH - (strend - scan);\n    scan = strend - MAX_MATCH;\n\n    if (len > best_len) {\n      s.match_start = cur_match;\n      best_len = len;\n      if (len >= nice_match) {\n        break;\n      }\n      scan_end1  = _win[scan + best_len - 1];\n      scan_end   = _win[scan + best_len];\n    }\n  } while ((cur_match = prev[cur_match & wmask]) > limit && --chain_length !== 0);\n\n  if (best_len <= s.lookahead) {\n    return best_len;\n  }\n  return s.lookahead;\n};\n\n\n/* ===========================================================================\n * Fill the window when the lookahead becomes insufficient.\n * Updates strstart and lookahead.\n *\n * IN assertion: lookahead < MIN_LOOKAHEAD\n * OUT assertions: strstart <= window_size-MIN_LOOKAHEAD\n *    At least one byte has been read, or avail_in == 0; reads are\n *    performed for at least two bytes (required for the zip translate_eol\n *    option -- not supported here).\n */\nconst fill_window = (s) => {\n\n  const _w_size = s.w_size;\n  let n, more, str;\n\n  //Assert(s->lookahead < MIN_LOOKAHEAD, \"already enough lookahead\");\n\n  do {\n    more = s.window_size - s.lookahead - s.strstart;\n\n    // JS ints have 32 bit, block below not needed\n    /* Deal with !@#$% 64K limit: */\n    //if (sizeof(int) <= 2) {\n    //    if (more == 0 && s->strstart == 0 && s->lookahead == 0) {\n    //        more = wsize;\n    //\n    //  } else if (more == (unsigned)(-1)) {\n    //        /* Very unlikely, but possible on 16 bit machine if\n    //         * strstart == 0 && lookahead == 1 (input done a byte at time)\n    //         */\n    //        more--;\n    //    }\n    //}\n\n\n    /* If the window is almost full and there is insufficient lookahead,\n     * move the upper half to the lower one to make room in the upper half.\n     */\n    if (s.strstart >= _w_size + (_w_size - MIN_LOOKAHEAD)) {\n\n      s.window.set(s.window.subarray(_w_size, _w_size + _w_size - more), 0);\n      s.match_start -= _w_size;\n      s.strstart -= _w_size;\n      /* we now have strstart >= MAX_DIST */\n      s.block_start -= _w_size;\n      if (s.insert > s.strstart) {\n        s.insert = s.strstart;\n      }\n      slide_hash(s);\n      more += _w_size;\n    }\n    if (s.strm.avail_in === 0) {\n      break;\n    }\n\n    /* If there was no sliding:\n     *    strstart <= WSIZE+MAX_DIST-1 && lookahead <= MIN_LOOKAHEAD - 1 &&\n     *    more == window_size - lookahead - strstart\n     * => more >= window_size - (MIN_LOOKAHEAD-1 + WSIZE + MAX_DIST-1)\n     * => more >= window_size - 2*WSIZE + 2\n     * In the BIG_MEM or MMAP case (not yet supported),\n     *   window_size == input_size + MIN_LOOKAHEAD  &&\n     *   strstart + s->lookahead <= input_size => more >= MIN_LOOKAHEAD.\n     * Otherwise, window_size == 2*WSIZE so more >= 2.\n     * If there was sliding, more >= WSIZE. So in all cases, more >= 2.\n     */\n    //Assert(more >= 2, \"more < 2\");\n    n = read_buf(s.strm, s.window, s.strstart + s.lookahead, more);\n    s.lookahead += n;\n\n    /* Initialize the hash value now that we have some input: */\n    if (s.lookahead + s.insert >= MIN_MATCH) {\n      str = s.strstart - s.insert;\n      s.ins_h = s.window[str];\n\n      /* UPDATE_HASH(s, s->ins_h, s->window[str + 1]); */\n      s.ins_h = HASH(s, s.ins_h, s.window[str + 1]);\n//#if MIN_MATCH != 3\n//        Call update_hash() MIN_MATCH-3 more times\n//#endif\n      while (s.insert) {\n        /* UPDATE_HASH(s, s->ins_h, s->window[str + MIN_MATCH-1]); */\n        s.ins_h = HASH(s, s.ins_h, s.window[str + MIN_MATCH - 1]);\n\n        s.prev[str & s.w_mask] = s.head[s.ins_h];\n        s.head[s.ins_h] = str;\n        str++;\n        s.insert--;\n        if (s.lookahead + s.insert < MIN_MATCH) {\n          break;\n        }\n      }\n    }\n    /* If the whole input has less than MIN_MATCH bytes, ins_h is garbage,\n     * but this is not important since only literal bytes will be emitted.\n     */\n\n  } while (s.lookahead < MIN_LOOKAHEAD && s.strm.avail_in !== 0);\n\n  /* If the WIN_INIT bytes after the end of the current data have never been\n   * written, then zero those bytes in order to avoid memory check reports of\n   * the use of uninitialized (or uninitialised as Julian writes) bytes by\n   * the longest match routines.  Update the high water mark for the next\n   * time through here.  WIN_INIT is set to MAX_MATCH since the longest match\n   * routines allow scanning to strstart + MAX_MATCH, ignoring lookahead.\n   */\n//  if (s.high_water < s.window_size) {\n//    const curr = s.strstart + s.lookahead;\n//    let init = 0;\n//\n//    if (s.high_water < curr) {\n//      /* Previous high water mark below current data -- zero WIN_INIT\n//       * bytes or up to end of window, whichever is less.\n//       */\n//      init = s.window_size - curr;\n//      if (init > WIN_INIT)\n//        init = WIN_INIT;\n//      zmemzero(s->window + curr, (unsigned)init);\n//      s->high_water = curr + init;\n//    }\n//    else if (s->high_water < (ulg)curr + WIN_INIT) {\n//      /* High water mark at or above current data, but below current data\n//       * plus WIN_INIT -- zero out to current data plus WIN_INIT, or up\n//       * to end of window, whichever is less.\n//       */\n//      init = (ulg)curr + WIN_INIT - s->high_water;\n//      if (init > s->window_size - s->high_water)\n//        init = s->window_size - s->high_water;\n//      zmemzero(s->window + s->high_water, (unsigned)init);\n//      s->high_water += init;\n//    }\n//  }\n//\n//  Assert((ulg)s->strstart <= s->window_size - MIN_LOOKAHEAD,\n//    \"not enough room for search\");\n};\n\n/* ===========================================================================\n * Copy without compression as much as possible from the input stream, return\n * the current block state.\n *\n * In case deflateParams() is used to later switch to a non-zero compression\n * level, s->matches (otherwise unused when storing) keeps track of the number\n * of hash table slides to perform. If s->matches is 1, then one hash table\n * slide will be done when switching. If s->matches is 2, the maximum value\n * allowed here, then the hash table will be cleared, since two or more slides\n * is the same as a clear.\n *\n * deflate_stored() is written to minimize the number of times an input byte is\n * copied. It is most efficient with large input and output buffers, which\n * maximizes the opportunites to have a single copy from next_in to next_out.\n */\nconst deflate_stored = (s, flush) => {\n\n  /* Smallest worthy block size when not flushing or finishing. By default\n   * this is 32K. This can be as small as 507 bytes for memLevel == 1. For\n   * large input and output buffers, the stored block size will be larger.\n   */\n  let min_block = s.pending_buf_size - 5 > s.w_size ? s.w_size : s.pending_buf_size - 5;\n\n  /* Copy as many min_block or larger stored blocks directly to next_out as\n   * possible. If flushing, copy the remaining available input to next_out as\n   * stored blocks, if there is enough space.\n   */\n  let len, left, have, last = 0;\n  let used = s.strm.avail_in;\n  do {\n    /* Set len to the maximum size block that we can copy directly with the\n     * available input data and output space. Set left to how much of that\n     * would be copied from what's left in the window.\n     */\n    len = 65535/* MAX_STORED */;     /* maximum deflate stored block length */\n    have = (s.bi_valid + 42) >> 3;     /* number of header bytes */\n    if (s.strm.avail_out < have) {         /* need room for header */\n      break;\n    }\n      /* maximum stored block length that will fit in avail_out: */\n    have = s.strm.avail_out - have;\n    left = s.strstart - s.block_start;  /* bytes left in window */\n    if (len > left + s.strm.avail_in) {\n      len = left + s.strm.avail_in;   /* limit len to the input */\n    }\n    if (len > have) {\n      len = have;             /* limit len to the output */\n    }\n\n    /* If the stored block would be less than min_block in length, or if\n     * unable to copy all of the available input when flushing, then try\n     * copying to the window and the pending buffer instead. Also don't\n     * write an empty block when flushing -- deflate() does that.\n     */\n    if (len < min_block && ((len === 0 && flush !== Z_FINISH$3) ||\n                        flush === Z_NO_FLUSH$2 ||\n                        len !== left + s.strm.avail_in)) {\n      break;\n    }\n\n    /* Make a dummy stored block in pending to get the header bytes,\n     * including any pending bits. This also updates the debugging counts.\n     */\n    last = flush === Z_FINISH$3 && len === left + s.strm.avail_in ? 1 : 0;\n    _tr_stored_block(s, 0, 0, last);\n\n    /* Replace the lengths in the dummy stored block with len. */\n    s.pending_buf[s.pending - 4] = len;\n    s.pending_buf[s.pending - 3] = len >> 8;\n    s.pending_buf[s.pending - 2] = ~len;\n    s.pending_buf[s.pending - 1] = ~len >> 8;\n\n    /* Write the stored block header bytes. */\n    flush_pending(s.strm);\n\n//#ifdef ZLIB_DEBUG\n//    /* Update debugging counts for the data about to be copied. */\n//    s->compressed_len += len << 3;\n//    s->bits_sent += len << 3;\n//#endif\n\n    /* Copy uncompressed bytes from the window to next_out. */\n    if (left) {\n      if (left > len) {\n        left = len;\n      }\n      //zmemcpy(s->strm->next_out, s->window + s->block_start, left);\n      s.strm.output.set(s.window.subarray(s.block_start, s.block_start + left), s.strm.next_out);\n      s.strm.next_out += left;\n      s.strm.avail_out -= left;\n      s.strm.total_out += left;\n      s.block_start += left;\n      len -= left;\n    }\n\n    /* Copy uncompressed bytes directly from next_in to next_out, updating\n     * the check value.\n     */\n    if (len) {\n      read_buf(s.strm, s.strm.output, s.strm.next_out, len);\n      s.strm.next_out += len;\n      s.strm.avail_out -= len;\n      s.strm.total_out += len;\n    }\n  } while (last === 0);\n\n  /* Update the sliding window with the last s->w_size bytes of the copied\n   * data, or append all of the copied data to the existing window if less\n   * than s->w_size bytes were copied. Also update the number of bytes to\n   * insert in the hash tables, in the event that deflateParams() switches to\n   * a non-zero compression level.\n   */\n  used -= s.strm.avail_in;    /* number of input bytes directly copied */\n  if (used) {\n    /* If any input was used, then no unused input remains in the window,\n     * therefore s->block_start == s->strstart.\n     */\n    if (used >= s.w_size) {  /* supplant the previous history */\n      s.matches = 2;     /* clear hash */\n      //zmemcpy(s->window, s->strm->next_in - s->w_size, s->w_size);\n      s.window.set(s.strm.input.subarray(s.strm.next_in - s.w_size, s.strm.next_in), 0);\n      s.strstart = s.w_size;\n      s.insert = s.strstart;\n    }\n    else {\n      if (s.window_size - s.strstart <= used) {\n        /* Slide the window down. */\n        s.strstart -= s.w_size;\n        //zmemcpy(s->window, s->window + s->w_size, s->strstart);\n        s.window.set(s.window.subarray(s.w_size, s.w_size + s.strstart), 0);\n        if (s.matches < 2) {\n          s.matches++;   /* add a pending slide_hash() */\n        }\n        if (s.insert > s.strstart) {\n          s.insert = s.strstart;\n        }\n      }\n      //zmemcpy(s->window + s->strstart, s->strm->next_in - used, used);\n      s.window.set(s.strm.input.subarray(s.strm.next_in - used, s.strm.next_in), s.strstart);\n      s.strstart += used;\n      s.insert += used > s.w_size - s.insert ? s.w_size - s.insert : used;\n    }\n    s.block_start = s.strstart;\n  }\n  if (s.high_water < s.strstart) {\n    s.high_water = s.strstart;\n  }\n\n  /* If the last block was written to next_out, then done. */\n  if (last) {\n    return BS_FINISH_DONE;\n  }\n\n  /* If flushing and all input has been consumed, then done. */\n  if (flush !== Z_NO_FLUSH$2 && flush !== Z_FINISH$3 &&\n    s.strm.avail_in === 0 && s.strstart === s.block_start) {\n    return BS_BLOCK_DONE;\n  }\n\n  /* Fill the window with any remaining input. */\n  have = s.window_size - s.strstart;\n  if (s.strm.avail_in > have && s.block_start >= s.w_size) {\n    /* Slide the window down. */\n    s.block_start -= s.w_size;\n    s.strstart -= s.w_size;\n    //zmemcpy(s->window, s->window + s->w_size, s->strstart);\n    s.window.set(s.window.subarray(s.w_size, s.w_size + s.strstart), 0);\n    if (s.matches < 2) {\n      s.matches++;       /* add a pending slide_hash() */\n    }\n    have += s.w_size;      /* more space now */\n    if (s.insert > s.strstart) {\n      s.insert = s.strstart;\n    }\n  }\n  if (have > s.strm.avail_in) {\n    have = s.strm.avail_in;\n  }\n  if (have) {\n    read_buf(s.strm, s.window, s.strstart, have);\n    s.strstart += have;\n    s.insert += have > s.w_size - s.insert ? s.w_size - s.insert : have;\n  }\n  if (s.high_water < s.strstart) {\n    s.high_water = s.strstart;\n  }\n\n  /* There was not enough avail_out to write a complete worthy or flushed\n   * stored block to next_out. Write a stored block to pending instead, if we\n   * have enough input for a worthy block, or if flushing and there is enough\n   * room for the remaining input as a stored block in the pending buffer.\n   */\n  have = (s.bi_valid + 42) >> 3;     /* number of header bytes */\n    /* maximum stored block length that will fit in pending: */\n  have = s.pending_buf_size - have > 65535/* MAX_STORED */ ? 65535/* MAX_STORED */ : s.pending_buf_size - have;\n  min_block = have > s.w_size ? s.w_size : have;\n  left = s.strstart - s.block_start;\n  if (left >= min_block ||\n     ((left || flush === Z_FINISH$3) && flush !== Z_NO_FLUSH$2 &&\n     s.strm.avail_in === 0 && left <= have)) {\n    len = left > have ? have : left;\n    last = flush === Z_FINISH$3 && s.strm.avail_in === 0 &&\n         len === left ? 1 : 0;\n    _tr_stored_block(s, s.block_start, len, last);\n    s.block_start += len;\n    flush_pending(s.strm);\n  }\n\n  /* We've done all we can with the available input and output. */\n  return last ? BS_FINISH_STARTED : BS_NEED_MORE;\n};\n\n\n/* ===========================================================================\n * Compress as much as possible from the input stream, return the current\n * block state.\n * This function does not perform lazy evaluation of matches and inserts\n * new strings in the dictionary only for unmatched strings or for short\n * matches. It is used only for the fast compression options.\n */\nconst deflate_fast = (s, flush) => {\n\n  let hash_head;        /* head of the hash chain */\n  let bflush;           /* set if current block must be flushed */\n\n  for (;;) {\n    /* Make sure that we always have enough lookahead, except\n     * at the end of the input file. We need MAX_MATCH bytes\n     * for the next match, plus MIN_MATCH bytes to insert the\n     * string following the next match.\n     */\n    if (s.lookahead < MIN_LOOKAHEAD) {\n      fill_window(s);\n      if (s.lookahead < MIN_LOOKAHEAD && flush === Z_NO_FLUSH$2) {\n        return BS_NEED_MORE;\n      }\n      if (s.lookahead === 0) {\n        break; /* flush the current block */\n      }\n    }\n\n    /* Insert the string window[strstart .. strstart+2] in the\n     * dictionary, and set hash_head to the head of the hash chain:\n     */\n    hash_head = 0/*NIL*/;\n    if (s.lookahead >= MIN_MATCH) {\n      /*** INSERT_STRING(s, s.strstart, hash_head); ***/\n      s.ins_h = HASH(s, s.ins_h, s.window[s.strstart + MIN_MATCH - 1]);\n      hash_head = s.prev[s.strstart & s.w_mask] = s.head[s.ins_h];\n      s.head[s.ins_h] = s.strstart;\n      /***/\n    }\n\n    /* Find the longest match, discarding those <= prev_length.\n     * At this point we have always match_length < MIN_MATCH\n     */\n    if (hash_head !== 0/*NIL*/ && ((s.strstart - hash_head) <= (s.w_size - MIN_LOOKAHEAD))) {\n      /* To simplify the code, we prevent matches with the string\n       * of window index 0 (in particular we have to avoid a match\n       * of the string with itself at the start of the input file).\n       */\n      s.match_length = longest_match(s, hash_head);\n      /* longest_match() sets match_start */\n    }\n    if (s.match_length >= MIN_MATCH) {\n      // check_match(s, s.strstart, s.match_start, s.match_length); // for debug only\n\n      /*** _tr_tally_dist(s, s.strstart - s.match_start,\n                     s.match_length - MIN_MATCH, bflush); ***/\n      bflush = _tr_tally(s, s.strstart - s.match_start, s.match_length - MIN_MATCH);\n\n      s.lookahead -= s.match_length;\n\n      /* Insert new strings in the hash table only if the match length\n       * is not too large. This saves time but degrades compression.\n       */\n      if (s.match_length <= s.max_lazy_match/*max_insert_length*/ && s.lookahead >= MIN_MATCH) {\n        s.match_length--; /* string at strstart already in table */\n        do {\n          s.strstart++;\n          /*** INSERT_STRING(s, s.strstart, hash_head); ***/\n          s.ins_h = HASH(s, s.ins_h, s.window[s.strstart + MIN_MATCH - 1]);\n          hash_head = s.prev[s.strstart & s.w_mask] = s.head[s.ins_h];\n          s.head[s.ins_h] = s.strstart;\n          /***/\n          /* strstart never exceeds WSIZE-MAX_MATCH, so there are\n           * always MIN_MATCH bytes ahead.\n           */\n        } while (--s.match_length !== 0);\n        s.strstart++;\n      } else\n      {\n        s.strstart += s.match_length;\n        s.match_length = 0;\n        s.ins_h = s.window[s.strstart];\n        /* UPDATE_HASH(s, s.ins_h, s.window[s.strstart+1]); */\n        s.ins_h = HASH(s, s.ins_h, s.window[s.strstart + 1]);\n\n//#if MIN_MATCH != 3\n//                Call UPDATE_HASH() MIN_MATCH-3 more times\n//#endif\n        /* If lookahead < MIN_MATCH, ins_h is garbage, but it does not\n         * matter since it will be recomputed at next deflate call.\n         */\n      }\n    } else {\n      /* No match, output a literal byte */\n      //Tracevv((stderr,\"%c\", s.window[s.strstart]));\n      /*** _tr_tally_lit(s, s.window[s.strstart], bflush); ***/\n      bflush = _tr_tally(s, 0, s.window[s.strstart]);\n\n      s.lookahead--;\n      s.strstart++;\n    }\n    if (bflush) {\n      /*** FLUSH_BLOCK(s, 0); ***/\n      flush_block_only(s, false);\n      if (s.strm.avail_out === 0) {\n        return BS_NEED_MORE;\n      }\n      /***/\n    }\n  }\n  s.insert = ((s.strstart < (MIN_MATCH - 1)) ? s.strstart : MIN_MATCH - 1);\n  if (flush === Z_FINISH$3) {\n    /*** FLUSH_BLOCK(s, 1); ***/\n    flush_block_only(s, true);\n    if (s.strm.avail_out === 0) {\n      return BS_FINISH_STARTED;\n    }\n    /***/\n    return BS_FINISH_DONE;\n  }\n  if (s.sym_next) {\n    /*** FLUSH_BLOCK(s, 0); ***/\n    flush_block_only(s, false);\n    if (s.strm.avail_out === 0) {\n      return BS_NEED_MORE;\n    }\n    /***/\n  }\n  return BS_BLOCK_DONE;\n};\n\n/* ===========================================================================\n * Same as above, but achieves better compression. We use a lazy\n * evaluation for matches: a match is finally adopted only if there is\n * no better match at the next window position.\n */\nconst deflate_slow = (s, flush) => {\n\n  let hash_head;          /* head of hash chain */\n  let bflush;              /* set if current block must be flushed */\n\n  let max_insert;\n\n  /* Process the input block. */\n  for (;;) {\n    /* Make sure that we always have enough lookahead, except\n     * at the end of the input file. We need MAX_MATCH bytes\n     * for the next match, plus MIN_MATCH bytes to insert the\n     * string following the next match.\n     */\n    if (s.lookahead < MIN_LOOKAHEAD) {\n      fill_window(s);\n      if (s.lookahead < MIN_LOOKAHEAD && flush === Z_NO_FLUSH$2) {\n        return BS_NEED_MORE;\n      }\n      if (s.lookahead === 0) { break; } /* flush the current block */\n    }\n\n    /* Insert the string window[strstart .. strstart+2] in the\n     * dictionary, and set hash_head to the head of the hash chain:\n     */\n    hash_head = 0/*NIL*/;\n    if (s.lookahead >= MIN_MATCH) {\n      /*** INSERT_STRING(s, s.strstart, hash_head); ***/\n      s.ins_h = HASH(s, s.ins_h, s.window[s.strstart + MIN_MATCH - 1]);\n      hash_head = s.prev[s.strstart & s.w_mask] = s.head[s.ins_h];\n      s.head[s.ins_h] = s.strstart;\n      /***/\n    }\n\n    /* Find the longest match, discarding those <= prev_length.\n     */\n    s.prev_length = s.match_length;\n    s.prev_match = s.match_start;\n    s.match_length = MIN_MATCH - 1;\n\n    if (hash_head !== 0/*NIL*/ && s.prev_length < s.max_lazy_match &&\n        s.strstart - hash_head <= (s.w_size - MIN_LOOKAHEAD)/*MAX_DIST(s)*/) {\n      /* To simplify the code, we prevent matches with the string\n       * of window index 0 (in particular we have to avoid a match\n       * of the string with itself at the start of the input file).\n       */\n      s.match_length = longest_match(s, hash_head);\n      /* longest_match() sets match_start */\n\n      if (s.match_length <= 5 &&\n         (s.strategy === Z_FILTERED || (s.match_length === MIN_MATCH && s.strstart - s.match_start > 4096/*TOO_FAR*/))) {\n\n        /* If prev_match is also MIN_MATCH, match_start is garbage\n         * but we will ignore the current match anyway.\n         */\n        s.match_length = MIN_MATCH - 1;\n      }\n    }\n    /* If there was a match at the previous step and the current\n     * match is not better, output the previous match:\n     */\n    if (s.prev_length >= MIN_MATCH && s.match_length <= s.prev_length) {\n      max_insert = s.strstart + s.lookahead - MIN_MATCH;\n      /* Do not insert strings in hash table beyond this. */\n\n      //check_match(s, s.strstart-1, s.prev_match, s.prev_length);\n\n      /***_tr_tally_dist(s, s.strstart - 1 - s.prev_match,\n                     s.prev_length - MIN_MATCH, bflush);***/\n      bflush = _tr_tally(s, s.strstart - 1 - s.prev_match, s.prev_length - MIN_MATCH);\n      /* Insert in hash table all strings up to the end of the match.\n       * strstart-1 and strstart are already inserted. If there is not\n       * enough lookahead, the last two strings are not inserted in\n       * the hash table.\n       */\n      s.lookahead -= s.prev_length - 1;\n      s.prev_length -= 2;\n      do {\n        if (++s.strstart <= max_insert) {\n          /*** INSERT_STRING(s, s.strstart, hash_head); ***/\n          s.ins_h = HASH(s, s.ins_h, s.window[s.strstart + MIN_MATCH - 1]);\n          hash_head = s.prev[s.strstart & s.w_mask] = s.head[s.ins_h];\n          s.head[s.ins_h] = s.strstart;\n          /***/\n        }\n      } while (--s.prev_length !== 0);\n      s.match_available = 0;\n      s.match_length = MIN_MATCH - 1;\n      s.strstart++;\n\n      if (bflush) {\n        /*** FLUSH_BLOCK(s, 0); ***/\n        flush_block_only(s, false);\n        if (s.strm.avail_out === 0) {\n          return BS_NEED_MORE;\n        }\n        /***/\n      }\n\n    } else if (s.match_available) {\n      /* If there was no match at the previous position, output a\n       * single literal. If there was a match but the current match\n       * is longer, truncate the previous match to a single literal.\n       */\n      //Tracevv((stderr,\"%c\", s->window[s->strstart-1]));\n      /*** _tr_tally_lit(s, s.window[s.strstart-1], bflush); ***/\n      bflush = _tr_tally(s, 0, s.window[s.strstart - 1]);\n\n      if (bflush) {\n        /*** FLUSH_BLOCK_ONLY(s, 0) ***/\n        flush_block_only(s, false);\n        /***/\n      }\n      s.strstart++;\n      s.lookahead--;\n      if (s.strm.avail_out === 0) {\n        return BS_NEED_MORE;\n      }\n    } else {\n      /* There is no previous match to compare with, wait for\n       * the next step to decide.\n       */\n      s.match_available = 1;\n      s.strstart++;\n      s.lookahead--;\n    }\n  }\n  //Assert (flush != Z_NO_FLUSH, \"no flush?\");\n  if (s.match_available) {\n    //Tracevv((stderr,\"%c\", s->window[s->strstart-1]));\n    /*** _tr_tally_lit(s, s.window[s.strstart-1], bflush); ***/\n    bflush = _tr_tally(s, 0, s.window[s.strstart - 1]);\n\n    s.match_available = 0;\n  }\n  s.insert = s.strstart < MIN_MATCH - 1 ? s.strstart : MIN_MATCH - 1;\n  if (flush === Z_FINISH$3) {\n    /*** FLUSH_BLOCK(s, 1); ***/\n    flush_block_only(s, true);\n    if (s.strm.avail_out === 0) {\n      return BS_FINISH_STARTED;\n    }\n    /***/\n    return BS_FINISH_DONE;\n  }\n  if (s.sym_next) {\n    /*** FLUSH_BLOCK(s, 0); ***/\n    flush_block_only(s, false);\n    if (s.strm.avail_out === 0) {\n      return BS_NEED_MORE;\n    }\n    /***/\n  }\n\n  return BS_BLOCK_DONE;\n};\n\n\n/* ===========================================================================\n * For Z_RLE, simply look for runs of bytes, generate matches only of distance\n * one.  Do not maintain a hash table.  (It will be regenerated if this run of\n * deflate switches away from Z_RLE.)\n */\nconst deflate_rle = (s, flush) => {\n\n  let bflush;            /* set if current block must be flushed */\n  let prev;              /* byte at distance one to match */\n  let scan, strend;      /* scan goes up to strend for length of run */\n\n  const _win = s.window;\n\n  for (;;) {\n    /* Make sure that we always have enough lookahead, except\n     * at the end of the input file. We need MAX_MATCH bytes\n     * for the longest run, plus one for the unrolled loop.\n     */\n    if (s.lookahead <= MAX_MATCH) {\n      fill_window(s);\n      if (s.lookahead <= MAX_MATCH && flush === Z_NO_FLUSH$2) {\n        return BS_NEED_MORE;\n      }\n      if (s.lookahead === 0) { break; } /* flush the current block */\n    }\n\n    /* See how many times the previous byte repeats */\n    s.match_length = 0;\n    if (s.lookahead >= MIN_MATCH && s.strstart > 0) {\n      scan = s.strstart - 1;\n      prev = _win[scan];\n      if (prev === _win[++scan] && prev === _win[++scan] && prev === _win[++scan]) {\n        strend = s.strstart + MAX_MATCH;\n        do {\n          /*jshint noempty:false*/\n        } while (prev === _win[++scan] && prev === _win[++scan] &&\n                 prev === _win[++scan] && prev === _win[++scan] &&\n                 prev === _win[++scan] && prev === _win[++scan] &&\n                 prev === _win[++scan] && prev === _win[++scan] &&\n                 scan < strend);\n        s.match_length = MAX_MATCH - (strend - scan);\n        if (s.match_length > s.lookahead) {\n          s.match_length = s.lookahead;\n        }\n      }\n      //Assert(scan <= s->window+(uInt)(s->window_size-1), \"wild scan\");\n    }\n\n    /* Emit match if have run of MIN_MATCH or longer, else emit literal */\n    if (s.match_length >= MIN_MATCH) {\n      //check_match(s, s.strstart, s.strstart - 1, s.match_length);\n\n      /*** _tr_tally_dist(s, 1, s.match_length - MIN_MATCH, bflush); ***/\n      bflush = _tr_tally(s, 1, s.match_length - MIN_MATCH);\n\n      s.lookahead -= s.match_length;\n      s.strstart += s.match_length;\n      s.match_length = 0;\n    } else {\n      /* No match, output a literal byte */\n      //Tracevv((stderr,\"%c\", s->window[s->strstart]));\n      /*** _tr_tally_lit(s, s.window[s.strstart], bflush); ***/\n      bflush = _tr_tally(s, 0, s.window[s.strstart]);\n\n      s.lookahead--;\n      s.strstart++;\n    }\n    if (bflush) {\n      /*** FLUSH_BLOCK(s, 0); ***/\n      flush_block_only(s, false);\n      if (s.strm.avail_out === 0) {\n        return BS_NEED_MORE;\n      }\n      /***/\n    }\n  }\n  s.insert = 0;\n  if (flush === Z_FINISH$3) {\n    /*** FLUSH_BLOCK(s, 1); ***/\n    flush_block_only(s, true);\n    if (s.strm.avail_out === 0) {\n      return BS_FINISH_STARTED;\n    }\n    /***/\n    return BS_FINISH_DONE;\n  }\n  if (s.sym_next) {\n    /*** FLUSH_BLOCK(s, 0); ***/\n    flush_block_only(s, false);\n    if (s.strm.avail_out === 0) {\n      return BS_NEED_MORE;\n    }\n    /***/\n  }\n  return BS_BLOCK_DONE;\n};\n\n/* ===========================================================================\n * For Z_HUFFMAN_ONLY, do not look for matches.  Do not maintain a hash table.\n * (It will be regenerated if this run of deflate switches away from Huffman.)\n */\nconst deflate_huff = (s, flush) => {\n\n  let bflush;             /* set if current block must be flushed */\n\n  for (;;) {\n    /* Make sure that we have a literal to write. */\n    if (s.lookahead === 0) {\n      fill_window(s);\n      if (s.lookahead === 0) {\n        if (flush === Z_NO_FLUSH$2) {\n          return BS_NEED_MORE;\n        }\n        break;      /* flush the current block */\n      }\n    }\n\n    /* Output a literal byte */\n    s.match_length = 0;\n    //Tracevv((stderr,\"%c\", s->window[s->strstart]));\n    /*** _tr_tally_lit(s, s.window[s.strstart], bflush); ***/\n    bflush = _tr_tally(s, 0, s.window[s.strstart]);\n    s.lookahead--;\n    s.strstart++;\n    if (bflush) {\n      /*** FLUSH_BLOCK(s, 0); ***/\n      flush_block_only(s, false);\n      if (s.strm.avail_out === 0) {\n        return BS_NEED_MORE;\n      }\n      /***/\n    }\n  }\n  s.insert = 0;\n  if (flush === Z_FINISH$3) {\n    /*** FLUSH_BLOCK(s, 1); ***/\n    flush_block_only(s, true);\n    if (s.strm.avail_out === 0) {\n      return BS_FINISH_STARTED;\n    }\n    /***/\n    return BS_FINISH_DONE;\n  }\n  if (s.sym_next) {\n    /*** FLUSH_BLOCK(s, 0); ***/\n    flush_block_only(s, false);\n    if (s.strm.avail_out === 0) {\n      return BS_NEED_MORE;\n    }\n    /***/\n  }\n  return BS_BLOCK_DONE;\n};\n\n/* Values for max_lazy_match, good_match and max_chain_length, depending on\n * the desired pack level (0..9). The values given below have been tuned to\n * exclude worst case performance for pathological files. Better values may be\n * found for specific files.\n */\nfunction Config(good_length, max_lazy, nice_length, max_chain, func) {\n\n  this.good_length = good_length;\n  this.max_lazy = max_lazy;\n  this.nice_length = nice_length;\n  this.max_chain = max_chain;\n  this.func = func;\n}\n\nconst configuration_table = [\n  /*      good lazy nice chain */\n  new Config(0, 0, 0, 0, deflate_stored),          /* 0 store only */\n  new Config(4, 4, 8, 4, deflate_fast),            /* 1 max speed, no lazy matches */\n  new Config(4, 5, 16, 8, deflate_fast),           /* 2 */\n  new Config(4, 6, 32, 32, deflate_fast),          /* 3 */\n\n  new Config(4, 4, 16, 16, deflate_slow),          /* 4 lazy matches */\n  new Config(8, 16, 32, 32, deflate_slow),         /* 5 */\n  new Config(8, 16, 128, 128, deflate_slow),       /* 6 */\n  new Config(8, 32, 128, 256, deflate_slow),       /* 7 */\n  new Config(32, 128, 258, 1024, deflate_slow),    /* 8 */\n  new Config(32, 258, 258, 4096, deflate_slow)     /* 9 max compression */\n];\n\n\n/* ===========================================================================\n * Initialize the \"longest match\" routines for a new zlib stream\n */\nconst lm_init = (s) => {\n\n  s.window_size = 2 * s.w_size;\n\n  /*** CLEAR_HASH(s); ***/\n  zero(s.head); // Fill with NIL (= 0);\n\n  /* Set the default configuration parameters:\n   */\n  s.max_lazy_match = configuration_table[s.level].max_lazy;\n  s.good_match = configuration_table[s.level].good_length;\n  s.nice_match = configuration_table[s.level].nice_length;\n  s.max_chain_length = configuration_table[s.level].max_chain;\n\n  s.strstart = 0;\n  s.block_start = 0;\n  s.lookahead = 0;\n  s.insert = 0;\n  s.match_length = s.prev_length = MIN_MATCH - 1;\n  s.match_available = 0;\n  s.ins_h = 0;\n};\n\n\nfunction DeflateState() {\n  this.strm = null;            /* pointer back to this zlib stream */\n  this.status = 0;            /* as the name implies */\n  this.pending_buf = null;      /* output still pending */\n  this.pending_buf_size = 0;  /* size of pending_buf */\n  this.pending_out = 0;       /* next pending byte to output to the stream */\n  this.pending = 0;           /* nb of bytes in the pending buffer */\n  this.wrap = 0;              /* bit 0 true for zlib, bit 1 true for gzip */\n  this.gzhead = null;         /* gzip header information to write */\n  this.gzindex = 0;           /* where in extra, name, or comment */\n  this.method = Z_DEFLATED$2; /* can only be DEFLATED */\n  this.last_flush = -1;   /* value of flush param for previous deflate call */\n\n  this.w_size = 0;  /* LZ77 window size (32K by default) */\n  this.w_bits = 0;  /* log2(w_size)  (8..16) */\n  this.w_mask = 0;  /* w_size - 1 */\n\n  this.window = null;\n  /* Sliding window. Input bytes are read into the second half of the window,\n   * and move to the first half later to keep a dictionary of at least wSize\n   * bytes. With this organization, matches are limited to a distance of\n   * wSize-MAX_MATCH bytes, but this ensures that IO is always\n   * performed with a length multiple of the block size.\n   */\n\n  this.window_size = 0;\n  /* Actual size of window: 2*wSize, except when the user input buffer\n   * is directly used as sliding window.\n   */\n\n  this.prev = null;\n  /* Link to older string with same hash index. To limit the size of this\n   * array to 64K, this link is maintained only for the last 32K strings.\n   * An index in this array is thus a window index modulo 32K.\n   */\n\n  this.head = null;   /* Heads of the hash chains or NIL. */\n\n  this.ins_h = 0;       /* hash index of string to be inserted */\n  this.hash_size = 0;   /* number of elements in hash table */\n  this.hash_bits = 0;   /* log2(hash_size) */\n  this.hash_mask = 0;   /* hash_size-1 */\n\n  this.hash_shift = 0;\n  /* Number of bits by which ins_h must be shifted at each input\n   * step. It must be such that after MIN_MATCH steps, the oldest\n   * byte no longer takes part in the hash key, that is:\n   *   hash_shift * MIN_MATCH >= hash_bits\n   */\n\n  this.block_start = 0;\n  /* Window position at the beginning of the current output block. Gets\n   * negative when the window is moved backwards.\n   */\n\n  this.match_length = 0;      /* length of best match */\n  this.prev_match = 0;        /* previous match */\n  this.match_available = 0;   /* set if previous match exists */\n  this.strstart = 0;          /* start of string to insert */\n  this.match_start = 0;       /* start of matching string */\n  this.lookahead = 0;         /* number of valid bytes ahead in window */\n\n  this.prev_length = 0;\n  /* Length of the best match at previous step. Matches not greater than this\n   * are discarded. This is used in the lazy match evaluation.\n   */\n\n  this.max_chain_length = 0;\n  /* To speed up deflation, hash chains are never searched beyond this\n   * length.  A higher limit improves compression ratio but degrades the\n   * speed.\n   */\n\n  this.max_lazy_match = 0;\n  /* Attempt to find a better match only when the current match is strictly\n   * smaller than this value. This mechanism is used only for compression\n   * levels >= 4.\n   */\n  // That's alias to max_lazy_match, don't use directly\n  //this.max_insert_length = 0;\n  /* Insert new strings in the hash table only if the match length is not\n   * greater than this length. This saves time but degrades compression.\n   * max_insert_length is used only for compression levels <= 3.\n   */\n\n  this.level = 0;     /* compression level (1..9) */\n  this.strategy = 0;  /* favor or force Huffman coding*/\n\n  this.good_match = 0;\n  /* Use a faster search when the previous match is longer than this */\n\n  this.nice_match = 0; /* Stop searching when current match exceeds this */\n\n              /* used by trees.c: */\n\n  /* Didn't use ct_data typedef below to suppress compiler warning */\n\n  // struct ct_data_s dyn_ltree[HEAP_SIZE];   /* literal and length tree */\n  // struct ct_data_s dyn_dtree[2*D_CODES+1]; /* distance tree */\n  // struct ct_data_s bl_tree[2*BL_CODES+1];  /* Huffman tree for bit lengths */\n\n  // Use flat array of DOUBLE size, with interleaved fata,\n  // because JS does not support effective\n  this.dyn_ltree  = new Uint16Array(HEAP_SIZE * 2);\n  this.dyn_dtree  = new Uint16Array((2 * D_CODES + 1) * 2);\n  this.bl_tree    = new Uint16Array((2 * BL_CODES + 1) * 2);\n  zero(this.dyn_ltree);\n  zero(this.dyn_dtree);\n  zero(this.bl_tree);\n\n  this.l_desc   = null;         /* desc. for literal tree */\n  this.d_desc   = null;         /* desc. for distance tree */\n  this.bl_desc  = null;         /* desc. for bit length tree */\n\n  //ush bl_count[MAX_BITS+1];\n  this.bl_count = new Uint16Array(MAX_BITS + 1);\n  /* number of codes at each bit length for an optimal tree */\n\n  //int heap[2*L_CODES+1];      /* heap used to build the Huffman trees */\n  this.heap = new Uint16Array(2 * L_CODES + 1);  /* heap used to build the Huffman trees */\n  zero(this.heap);\n\n  this.heap_len = 0;               /* number of elements in the heap */\n  this.heap_max = 0;               /* element of largest frequency */\n  /* The sons of heap[n] are heap[2*n] and heap[2*n+1]. heap[0] is not used.\n   * The same heap array is used to build all trees.\n   */\n\n  this.depth = new Uint16Array(2 * L_CODES + 1); //uch depth[2*L_CODES+1];\n  zero(this.depth);\n  /* Depth of each subtree used as tie breaker for trees of equal frequency\n   */\n\n  this.sym_buf = 0;        /* buffer for distances and literals/lengths */\n\n  this.lit_bufsize = 0;\n  /* Size of match buffer for literals/lengths.  There are 4 reasons for\n   * limiting lit_bufsize to 64K:\n   *   - frequencies can be kept in 16 bit counters\n   *   - if compression is not successful for the first block, all input\n   *     data is still in the window so we can still emit a stored block even\n   *     when input comes from standard input.  (This can also be done for\n   *     all blocks if lit_bufsize is not greater than 32K.)\n   *   - if compression is not successful for a file smaller than 64K, we can\n   *     even emit a stored file instead of a stored block (saving 5 bytes).\n   *     This is applicable only for zip (not gzip or zlib).\n   *   - creating new Huffman trees less frequently may not provide fast\n   *     adaptation to changes in the input data statistics. (Take for\n   *     example a binary file with poorly compressible code followed by\n   *     a highly compressible string table.) Smaller buffer sizes give\n   *     fast adaptation but have of course the overhead of transmitting\n   *     trees more frequently.\n   *   - I can't count above 4\n   */\n\n  this.sym_next = 0;      /* running index in sym_buf */\n  this.sym_end = 0;       /* symbol table full when sym_next reaches this */\n\n  this.opt_len = 0;       /* bit length of current block with optimal trees */\n  this.static_len = 0;    /* bit length of current block with static trees */\n  this.matches = 0;       /* number of string matches in current block */\n  this.insert = 0;        /* bytes at end of window left to insert */\n\n\n  this.bi_buf = 0;\n  /* Output buffer. bits are inserted starting at the bottom (least\n   * significant bits).\n   */\n  this.bi_valid = 0;\n  /* Number of valid bits in bi_buf.  All bits above the last valid bit\n   * are always zero.\n   */\n\n  // Used for window memory init. We safely ignore it for JS. That makes\n  // sense only for pointers and memory check tools.\n  //this.high_water = 0;\n  /* High water mark offset in window for initialized bytes -- bytes above\n   * this are set to zero in order to avoid memory check warnings when\n   * longest match routines access bytes past the input.  This is then\n   * updated to the new high water mark.\n   */\n}\n\n\n/* =========================================================================\n * Check for a valid deflate stream state. Return 0 if ok, 1 if not.\n */\nconst deflateStateCheck = (strm) => {\n\n  if (!strm) {\n    return 1;\n  }\n  const s = strm.state;\n  if (!s || s.strm !== strm || (s.status !== INIT_STATE &&\n//#ifdef GZIP\n                                s.status !== GZIP_STATE &&\n//#endif\n                                s.status !== EXTRA_STATE &&\n                                s.status !== NAME_STATE &&\n                                s.status !== COMMENT_STATE &&\n                                s.status !== HCRC_STATE &&\n                                s.status !== BUSY_STATE &&\n                                s.status !== FINISH_STATE)) {\n    return 1;\n  }\n  return 0;\n};\n\n\nconst deflateResetKeep = (strm) => {\n\n  if (deflateStateCheck(strm)) {\n    return err(strm, Z_STREAM_ERROR$2);\n  }\n\n  strm.total_in = strm.total_out = 0;\n  strm.data_type = Z_UNKNOWN;\n\n  const s = strm.state;\n  s.pending = 0;\n  s.pending_out = 0;\n\n  if (s.wrap < 0) {\n    s.wrap = -s.wrap;\n    /* was made negative by deflate(..., Z_FINISH); */\n  }\n  s.status =\n//#ifdef GZIP\n    s.wrap === 2 ? GZIP_STATE :\n//#endif\n    s.wrap ? INIT_STATE : BUSY_STATE;\n  strm.adler = (s.wrap === 2) ?\n    0  // crc32(0, Z_NULL, 0)\n  :\n    1; // adler32(0, Z_NULL, 0)\n  s.last_flush = -2;\n  _tr_init(s);\n  return Z_OK$3;\n};\n\n\nconst deflateReset = (strm) => {\n\n  const ret = deflateResetKeep(strm);\n  if (ret === Z_OK$3) {\n    lm_init(strm.state);\n  }\n  return ret;\n};\n\n\nconst deflateSetHeader = (strm, head) => {\n\n  if (deflateStateCheck(strm) || strm.state.wrap !== 2) {\n    return Z_STREAM_ERROR$2;\n  }\n  strm.state.gzhead = head;\n  return Z_OK$3;\n};\n\n\nconst deflateInit2 = (strm, level, method, windowBits, memLevel, strategy) => {\n\n  if (!strm) { // === Z_NULL\n    return Z_STREAM_ERROR$2;\n  }\n  let wrap = 1;\n\n  if (level === Z_DEFAULT_COMPRESSION$1) {\n    level = 6;\n  }\n\n  if (windowBits < 0) { /* suppress zlib wrapper */\n    wrap = 0;\n    windowBits = -windowBits;\n  }\n\n  else if (windowBits > 15) {\n    wrap = 2;           /* write gzip wrapper instead */\n    windowBits -= 16;\n  }\n\n\n  if (memLevel < 1 || memLevel > MAX_MEM_LEVEL || method !== Z_DEFLATED$2 ||\n    windowBits < 8 || windowBits > 15 || level < 0 || level > 9 ||\n    strategy < 0 || strategy > Z_FIXED || (windowBits === 8 && wrap !== 1)) {\n    return err(strm, Z_STREAM_ERROR$2);\n  }\n\n\n  if (windowBits === 8) {\n    windowBits = 9;\n  }\n  /* until 256-byte window bug fixed */\n\n  const s = new DeflateState();\n\n  strm.state = s;\n  s.strm = strm;\n  s.status = INIT_STATE;     /* to pass state test in deflateReset() */\n\n  s.wrap = wrap;\n  s.gzhead = null;\n  s.w_bits = windowBits;\n  s.w_size = 1 << s.w_bits;\n  s.w_mask = s.w_size - 1;\n\n  s.hash_bits = memLevel + 7;\n  s.hash_size = 1 << s.hash_bits;\n  s.hash_mask = s.hash_size - 1;\n  s.hash_shift = ~~((s.hash_bits + MIN_MATCH - 1) / MIN_MATCH);\n\n  s.window = new Uint8Array(s.w_size * 2);\n  s.head = new Uint16Array(s.hash_size);\n  s.prev = new Uint16Array(s.w_size);\n\n  // Don't need mem init magic for JS.\n  //s.high_water = 0;  /* nothing written to s->window yet */\n\n  s.lit_bufsize = 1 << (memLevel + 6); /* 16K elements by default */\n\n  /* We overlay pending_buf and sym_buf. This works since the average size\n   * for length/distance pairs over any compressed block is assured to be 31\n   * bits or less.\n   *\n   * Analysis: The longest fixed codes are a length code of 8 bits plus 5\n   * extra bits, for lengths 131 to 257. The longest fixed distance codes are\n   * 5 bits plus 13 extra bits, for distances 16385 to 32768. The longest\n   * possible fixed-codes length/distance pair is then 31 bits total.\n   *\n   * sym_buf starts one-fourth of the way into pending_buf. So there are\n   * three bytes in sym_buf for every four bytes in pending_buf. Each symbol\n   * in sym_buf is three bytes -- two for the distance and one for the\n   * literal/length. As each symbol is consumed, the pointer to the next\n   * sym_buf value to read moves forward three bytes. From that symbol, up to\n   * 31 bits are written to pending_buf. The closest the written pending_buf\n   * bits gets to the next sym_buf symbol to read is just before the last\n   * code is written. At that time, 31*(n-2) bits have been written, just\n   * after 24*(n-2) bits have been consumed from sym_buf. sym_buf starts at\n   * 8*n bits into pending_buf. (Note that the symbol buffer fills when n-1\n   * symbols are written.) The closest the writing gets to what is unread is\n   * then n+14 bits. Here n is lit_bufsize, which is 16384 by default, and\n   * can range from 128 to 32768.\n   *\n   * Therefore, at a minimum, there are 142 bits of space between what is\n   * written and what is read in the overlain buffers, so the symbols cannot\n   * be overwritten by the compressed data. That space is actually 139 bits,\n   * due to the three-bit fixed-code block header.\n   *\n   * That covers the case where either Z_FIXED is specified, forcing fixed\n   * codes, or when the use of fixed codes is chosen, because that choice\n   * results in a smaller compressed block than dynamic codes. That latter\n   * condition then assures that the above analysis also covers all dynamic\n   * blocks. A dynamic-code block will only be chosen to be emitted if it has\n   * fewer bits than a fixed-code block would for the same set of symbols.\n   * Therefore its average symbol length is assured to be less than 31. So\n   * the compressed data for a dynamic block also cannot overwrite the\n   * symbols from which it is being constructed.\n   */\n\n  s.pending_buf_size = s.lit_bufsize * 4;\n  s.pending_buf = new Uint8Array(s.pending_buf_size);\n\n  // It is offset from `s.pending_buf` (size is `s.lit_bufsize * 2`)\n  //s->sym_buf = s->pending_buf + s->lit_bufsize;\n  s.sym_buf = s.lit_bufsize;\n\n  //s->sym_end = (s->lit_bufsize - 1) * 3;\n  s.sym_end = (s.lit_bufsize - 1) * 3;\n  /* We avoid equality with lit_bufsize*3 because of wraparound at 64K\n   * on 16 bit machines and because stored blocks are restricted to\n   * 64K-1 bytes.\n   */\n\n  s.level = level;\n  s.strategy = strategy;\n  s.method = method;\n\n  return deflateReset(strm);\n};\n\nconst deflateInit = (strm, level) => {\n\n  return deflateInit2(strm, level, Z_DEFLATED$2, MAX_WBITS$1, DEF_MEM_LEVEL, Z_DEFAULT_STRATEGY$1);\n};\n\n\n/* ========================================================================= */\nconst deflate$2 = (strm, flush) => {\n\n  if (deflateStateCheck(strm) || flush > Z_BLOCK$1 || flush < 0) {\n    return strm ? err(strm, Z_STREAM_ERROR$2) : Z_STREAM_ERROR$2;\n  }\n\n  const s = strm.state;\n\n  if (!strm.output ||\n      (strm.avail_in !== 0 && !strm.input) ||\n      (s.status === FINISH_STATE && flush !== Z_FINISH$3)) {\n    return err(strm, (strm.avail_out === 0) ? Z_BUF_ERROR$1 : Z_STREAM_ERROR$2);\n  }\n\n  const old_flush = s.last_flush;\n  s.last_flush = flush;\n\n  /* Flush as much pending output as possible */\n  if (s.pending !== 0) {\n    flush_pending(strm);\n    if (strm.avail_out === 0) {\n      /* Since avail_out is 0, deflate will be called again with\n       * more output space, but possibly with both pending and\n       * avail_in equal to zero. There won't be anything to do,\n       * but this is not an error situation so make sure we\n       * return OK instead of BUF_ERROR at next call of deflate:\n       */\n      s.last_flush = -1;\n      return Z_OK$3;\n    }\n\n    /* Make sure there is something to do and avoid duplicate consecutive\n     * flushes. For repeated and useless calls with Z_FINISH, we keep\n     * returning Z_STREAM_END instead of Z_BUF_ERROR.\n     */\n  } else if (strm.avail_in === 0 && rank(flush) <= rank(old_flush) &&\n    flush !== Z_FINISH$3) {\n    return err(strm, Z_BUF_ERROR$1);\n  }\n\n  /* User must not provide more input after the first FINISH: */\n  if (s.status === FINISH_STATE && strm.avail_in !== 0) {\n    return err(strm, Z_BUF_ERROR$1);\n  }\n\n  /* Write the header */\n  if (s.status === INIT_STATE && s.wrap === 0) {\n    s.status = BUSY_STATE;\n  }\n  if (s.status === INIT_STATE) {\n    /* zlib header */\n    let header = (Z_DEFLATED$2 + ((s.w_bits - 8) << 4)) << 8;\n    let level_flags = -1;\n\n    if (s.strategy >= Z_HUFFMAN_ONLY || s.level < 2) {\n      level_flags = 0;\n    } else if (s.level < 6) {\n      level_flags = 1;\n    } else if (s.level === 6) {\n      level_flags = 2;\n    } else {\n      level_flags = 3;\n    }\n    header |= (level_flags << 6);\n    if (s.strstart !== 0) { header |= PRESET_DICT; }\n    header += 31 - (header % 31);\n\n    putShortMSB(s, header);\n\n    /* Save the adler32 of the preset dictionary: */\n    if (s.strstart !== 0) {\n      putShortMSB(s, strm.adler >>> 16);\n      putShortMSB(s, strm.adler & 0xffff);\n    }\n    strm.adler = 1; // adler32(0L, Z_NULL, 0);\n    s.status = BUSY_STATE;\n\n    /* Compression must start with an empty pending buffer */\n    flush_pending(strm);\n    if (s.pending !== 0) {\n      s.last_flush = -1;\n      return Z_OK$3;\n    }\n  }\n//#ifdef GZIP\n  if (s.status === GZIP_STATE) {\n    /* gzip header */\n    strm.adler = 0;  //crc32(0L, Z_NULL, 0);\n    put_byte(s, 31);\n    put_byte(s, 139);\n    put_byte(s, 8);\n    if (!s.gzhead) { // s->gzhead == Z_NULL\n      put_byte(s, 0);\n      put_byte(s, 0);\n      put_byte(s, 0);\n      put_byte(s, 0);\n      put_byte(s, 0);\n      put_byte(s, s.level === 9 ? 2 :\n                  (s.strategy >= Z_HUFFMAN_ONLY || s.level < 2 ?\n                   4 : 0));\n      put_byte(s, OS_CODE);\n      s.status = BUSY_STATE;\n\n      /* Compression must start with an empty pending buffer */\n      flush_pending(strm);\n      if (s.pending !== 0) {\n        s.last_flush = -1;\n        return Z_OK$3;\n      }\n    }\n    else {\n      put_byte(s, (s.gzhead.text ? 1 : 0) +\n                  (s.gzhead.hcrc ? 2 : 0) +\n                  (!s.gzhead.extra ? 0 : 4) +\n                  (!s.gzhead.name ? 0 : 8) +\n                  (!s.gzhead.comment ? 0 : 16)\n      );\n      put_byte(s, s.gzhead.time & 0xff);\n      put_byte(s, (s.gzhead.time >> 8) & 0xff);\n      put_byte(s, (s.gzhead.time >> 16) & 0xff);\n      put_byte(s, (s.gzhead.time >> 24) & 0xff);\n      put_byte(s, s.level === 9 ? 2 :\n                  (s.strategy >= Z_HUFFMAN_ONLY || s.level < 2 ?\n                   4 : 0));\n      put_byte(s, s.gzhead.os & 0xff);\n      if (s.gzhead.extra && s.gzhead.extra.length) {\n        put_byte(s, s.gzhead.extra.length & 0xff);\n        put_byte(s, (s.gzhead.extra.length >> 8) & 0xff);\n      }\n      if (s.gzhead.hcrc) {\n        strm.adler = crc32_1(strm.adler, s.pending_buf, s.pending, 0);\n      }\n      s.gzindex = 0;\n      s.status = EXTRA_STATE;\n    }\n  }\n  if (s.status === EXTRA_STATE) {\n    if (s.gzhead.extra/* != Z_NULL*/) {\n      let beg = s.pending;   /* start of bytes to update crc */\n      let left = (s.gzhead.extra.length & 0xffff) - s.gzindex;\n      while (s.pending + left > s.pending_buf_size) {\n        let copy = s.pending_buf_size - s.pending;\n        // zmemcpy(s.pending_buf + s.pending,\n        //    s.gzhead.extra + s.gzindex, copy);\n        s.pending_buf.set(s.gzhead.extra.subarray(s.gzindex, s.gzindex + copy), s.pending);\n        s.pending = s.pending_buf_size;\n        //--- HCRC_UPDATE(beg) ---//\n        if (s.gzhead.hcrc && s.pending > beg) {\n          strm.adler = crc32_1(strm.adler, s.pending_buf, s.pending - beg, beg);\n        }\n        //---//\n        s.gzindex += copy;\n        flush_pending(strm);\n        if (s.pending !== 0) {\n          s.last_flush = -1;\n          return Z_OK$3;\n        }\n        beg = 0;\n        left -= copy;\n      }\n      // JS specific: s.gzhead.extra may be TypedArray or Array for backward compatibility\n      //              TypedArray.slice and TypedArray.from don't exist in IE10-IE11\n      let gzhead_extra = new Uint8Array(s.gzhead.extra);\n      // zmemcpy(s->pending_buf + s->pending,\n      //     s->gzhead->extra + s->gzindex, left);\n      s.pending_buf.set(gzhead_extra.subarray(s.gzindex, s.gzindex + left), s.pending);\n      s.pending += left;\n      //--- HCRC_UPDATE(beg) ---//\n      if (s.gzhead.hcrc && s.pending > beg) {\n        strm.adler = crc32_1(strm.adler, s.pending_buf, s.pending - beg, beg);\n      }\n      //---//\n      s.gzindex = 0;\n    }\n    s.status = NAME_STATE;\n  }\n  if (s.status === NAME_STATE) {\n    if (s.gzhead.name/* != Z_NULL*/) {\n      let beg = s.pending;   /* start of bytes to update crc */\n      let val;\n      do {\n        if (s.pending === s.pending_buf_size) {\n          //--- HCRC_UPDATE(beg) ---//\n          if (s.gzhead.hcrc && s.pending > beg) {\n            strm.adler = crc32_1(strm.adler, s.pending_buf, s.pending - beg, beg);\n          }\n          //---//\n          flush_pending(strm);\n          if (s.pending !== 0) {\n            s.last_flush = -1;\n            return Z_OK$3;\n          }\n          beg = 0;\n        }\n        // JS specific: little magic to add zero terminator to end of string\n        if (s.gzindex < s.gzhead.name.length) {\n          val = s.gzhead.name.charCodeAt(s.gzindex++) & 0xff;\n        } else {\n          val = 0;\n        }\n        put_byte(s, val);\n      } while (val !== 0);\n      //--- HCRC_UPDATE(beg) ---//\n      if (s.gzhead.hcrc && s.pending > beg) {\n        strm.adler = crc32_1(strm.adler, s.pending_buf, s.pending - beg, beg);\n      }\n      //---//\n      s.gzindex = 0;\n    }\n    s.status = COMMENT_STATE;\n  }\n  if (s.status === COMMENT_STATE) {\n    if (s.gzhead.comment/* != Z_NULL*/) {\n      let beg = s.pending;   /* start of bytes to update crc */\n      let val;\n      do {\n        if (s.pending === s.pending_buf_size) {\n          //--- HCRC_UPDATE(beg) ---//\n          if (s.gzhead.hcrc && s.pending > beg) {\n            strm.adler = crc32_1(strm.adler, s.pending_buf, s.pending - beg, beg);\n          }\n          //---//\n          flush_pending(strm);\n          if (s.pending !== 0) {\n            s.last_flush = -1;\n            return Z_OK$3;\n          }\n          beg = 0;\n        }\n        // JS specific: little magic to add zero terminator to end of string\n        if (s.gzindex < s.gzhead.comment.length) {\n          val = s.gzhead.comment.charCodeAt(s.gzindex++) & 0xff;\n        } else {\n          val = 0;\n        }\n        put_byte(s, val);\n      } while (val !== 0);\n      //--- HCRC_UPDATE(beg) ---//\n      if (s.gzhead.hcrc && s.pending > beg) {\n        strm.adler = crc32_1(strm.adler, s.pending_buf, s.pending - beg, beg);\n      }\n      //---//\n    }\n    s.status = HCRC_STATE;\n  }\n  if (s.status === HCRC_STATE) {\n    if (s.gzhead.hcrc) {\n      if (s.pending + 2 > s.pending_buf_size) {\n        flush_pending(strm);\n        if (s.pending !== 0) {\n          s.last_flush = -1;\n          return Z_OK$3;\n        }\n      }\n      put_byte(s, strm.adler & 0xff);\n      put_byte(s, (strm.adler >> 8) & 0xff);\n      strm.adler = 0; //crc32(0L, Z_NULL, 0);\n    }\n    s.status = BUSY_STATE;\n\n    /* Compression must start with an empty pending buffer */\n    flush_pending(strm);\n    if (s.pending !== 0) {\n      s.last_flush = -1;\n      return Z_OK$3;\n    }\n  }\n//#endif\n\n  /* Start a new block or continue the current one.\n   */\n  if (strm.avail_in !== 0 || s.lookahead !== 0 ||\n    (flush !== Z_NO_FLUSH$2 && s.status !== FINISH_STATE)) {\n    let bstate = s.level === 0 ? deflate_stored(s, flush) :\n                 s.strategy === Z_HUFFMAN_ONLY ? deflate_huff(s, flush) :\n                 s.strategy === Z_RLE ? deflate_rle(s, flush) :\n                 configuration_table[s.level].func(s, flush);\n\n    if (bstate === BS_FINISH_STARTED || bstate === BS_FINISH_DONE) {\n      s.status = FINISH_STATE;\n    }\n    if (bstate === BS_NEED_MORE || bstate === BS_FINISH_STARTED) {\n      if (strm.avail_out === 0) {\n        s.last_flush = -1;\n        /* avoid BUF_ERROR next call, see above */\n      }\n      return Z_OK$3;\n      /* If flush != Z_NO_FLUSH && avail_out == 0, the next call\n       * of deflate should use the same flush parameter to make sure\n       * that the flush is complete. So we don't have to output an\n       * empty block here, this will be done at next call. This also\n       * ensures that for a very small output buffer, we emit at most\n       * one empty block.\n       */\n    }\n    if (bstate === BS_BLOCK_DONE) {\n      if (flush === Z_PARTIAL_FLUSH) {\n        _tr_align(s);\n      }\n      else if (flush !== Z_BLOCK$1) { /* FULL_FLUSH or SYNC_FLUSH */\n\n        _tr_stored_block(s, 0, 0, false);\n        /* For a full flush, this empty block will be recognized\n         * as a special marker by inflate_sync().\n         */\n        if (flush === Z_FULL_FLUSH$1) {\n          /*** CLEAR_HASH(s); ***/             /* forget history */\n          zero(s.head); // Fill with NIL (= 0);\n\n          if (s.lookahead === 0) {\n            s.strstart = 0;\n            s.block_start = 0;\n            s.insert = 0;\n          }\n        }\n      }\n      flush_pending(strm);\n      if (strm.avail_out === 0) {\n        s.last_flush = -1; /* avoid BUF_ERROR at next call, see above */\n        return Z_OK$3;\n      }\n    }\n  }\n\n  if (flush !== Z_FINISH$3) { return Z_OK$3; }\n  if (s.wrap <= 0) { return Z_STREAM_END$3; }\n\n  /* Write the trailer */\n  if (s.wrap === 2) {\n    put_byte(s, strm.adler & 0xff);\n    put_byte(s, (strm.adler >> 8) & 0xff);\n    put_byte(s, (strm.adler >> 16) & 0xff);\n    put_byte(s, (strm.adler >> 24) & 0xff);\n    put_byte(s, strm.total_in & 0xff);\n    put_byte(s, (strm.total_in >> 8) & 0xff);\n    put_byte(s, (strm.total_in >> 16) & 0xff);\n    put_byte(s, (strm.total_in >> 24) & 0xff);\n  }\n  else\n  {\n    putShortMSB(s, strm.adler >>> 16);\n    putShortMSB(s, strm.adler & 0xffff);\n  }\n\n  flush_pending(strm);\n  /* If avail_out is zero, the application will call deflate again\n   * to flush the rest.\n   */\n  if (s.wrap > 0) { s.wrap = -s.wrap; }\n  /* write the trailer only once! */\n  return s.pending !== 0 ? Z_OK$3 : Z_STREAM_END$3;\n};\n\n\nconst deflateEnd = (strm) => {\n\n  if (deflateStateCheck(strm)) {\n    return Z_STREAM_ERROR$2;\n  }\n\n  const status = strm.state.status;\n\n  strm.state = null;\n\n  return status === BUSY_STATE ? err(strm, Z_DATA_ERROR$2) : Z_OK$3;\n};\n\n\n/* =========================================================================\n * Initializes the compression dictionary from the given byte\n * sequence without producing any compressed output.\n */\nconst deflateSetDictionary = (strm, dictionary) => {\n\n  let dictLength = dictionary.length;\n\n  if (deflateStateCheck(strm)) {\n    return Z_STREAM_ERROR$2;\n  }\n\n  const s = strm.state;\n  const wrap = s.wrap;\n\n  if (wrap === 2 || (wrap === 1 && s.status !== INIT_STATE) || s.lookahead) {\n    return Z_STREAM_ERROR$2;\n  }\n\n  /* when using zlib wrappers, compute Adler-32 for provided dictionary */\n  if (wrap === 1) {\n    /* adler32(strm->adler, dictionary, dictLength); */\n    strm.adler = adler32_1(strm.adler, dictionary, dictLength, 0);\n  }\n\n  s.wrap = 0;   /* avoid computing Adler-32 in read_buf */\n\n  /* if dictionary would fill window, just replace the history */\n  if (dictLength >= s.w_size) {\n    if (wrap === 0) {            /* already empty otherwise */\n      /*** CLEAR_HASH(s); ***/\n      zero(s.head); // Fill with NIL (= 0);\n      s.strstart = 0;\n      s.block_start = 0;\n      s.insert = 0;\n    }\n    /* use the tail */\n    // dictionary = dictionary.slice(dictLength - s.w_size);\n    let tmpDict = new Uint8Array(s.w_size);\n    tmpDict.set(dictionary.subarray(dictLength - s.w_size, dictLength), 0);\n    dictionary = tmpDict;\n    dictLength = s.w_size;\n  }\n  /* insert dictionary into window and hash */\n  const avail = strm.avail_in;\n  const next = strm.next_in;\n  const input = strm.input;\n  strm.avail_in = dictLength;\n  strm.next_in = 0;\n  strm.input = dictionary;\n  fill_window(s);\n  while (s.lookahead >= MIN_MATCH) {\n    let str = s.strstart;\n    let n = s.lookahead - (MIN_MATCH - 1);\n    do {\n      /* UPDATE_HASH(s, s->ins_h, s->window[str + MIN_MATCH-1]); */\n      s.ins_h = HASH(s, s.ins_h, s.window[str + MIN_MATCH - 1]);\n\n      s.prev[str & s.w_mask] = s.head[s.ins_h];\n\n      s.head[s.ins_h] = str;\n      str++;\n    } while (--n);\n    s.strstart = str;\n    s.lookahead = MIN_MATCH - 1;\n    fill_window(s);\n  }\n  s.strstart += s.lookahead;\n  s.block_start = s.strstart;\n  s.insert = s.lookahead;\n  s.lookahead = 0;\n  s.match_length = s.prev_length = MIN_MATCH - 1;\n  s.match_available = 0;\n  strm.next_in = next;\n  strm.input = input;\n  strm.avail_in = avail;\n  s.wrap = wrap;\n  return Z_OK$3;\n};\n\n\nvar deflateInit_1 = deflateInit;\nvar deflateInit2_1 = deflateInit2;\nvar deflateReset_1 = deflateReset;\nvar deflateResetKeep_1 = deflateResetKeep;\nvar deflateSetHeader_1 = deflateSetHeader;\nvar deflate_2$1 = deflate$2;\nvar deflateEnd_1 = deflateEnd;\nvar deflateSetDictionary_1 = deflateSetDictionary;\nvar deflateInfo = 'pako deflate (from Nodeca project)';\n\n/* Not implemented\nmodule.exports.deflateBound = deflateBound;\nmodule.exports.deflateCopy = deflateCopy;\nmodule.exports.deflateGetDictionary = deflateGetDictionary;\nmodule.exports.deflateParams = deflateParams;\nmodule.exports.deflatePending = deflatePending;\nmodule.exports.deflatePrime = deflatePrime;\nmodule.exports.deflateTune = deflateTune;\n*/\n\nvar deflate_1$2 = {\n\tdeflateInit: deflateInit_1,\n\tdeflateInit2: deflateInit2_1,\n\tdeflateReset: deflateReset_1,\n\tdeflateResetKeep: deflateResetKeep_1,\n\tdeflateSetHeader: deflateSetHeader_1,\n\tdeflate: deflate_2$1,\n\tdeflateEnd: deflateEnd_1,\n\tdeflateSetDictionary: deflateSetDictionary_1,\n\tdeflateInfo: deflateInfo\n};\n\nconst _has = (obj, key) => {\n  return Object.prototype.hasOwnProperty.call(obj, key);\n};\n\nvar assign = function (obj /*from1, from2, from3, ...*/) {\n  const sources = Array.prototype.slice.call(arguments, 1);\n  while (sources.length) {\n    const source = sources.shift();\n    if (!source) { continue; }\n\n    if (typeof source !== 'object') {\n      throw new TypeError(source + 'must be non-object');\n    }\n\n    for (const p in source) {\n      if (_has(source, p)) {\n        obj[p] = source[p];\n      }\n    }\n  }\n\n  return obj;\n};\n\n\n// Join array of chunks to single array.\nvar flattenChunks = (chunks) => {\n  // calculate data length\n  let len = 0;\n\n  for (let i = 0, l = chunks.length; i < l; i++) {\n    len += chunks[i].length;\n  }\n\n  // join chunks\n  const result = new Uint8Array(len);\n\n  for (let i = 0, pos = 0, l = chunks.length; i < l; i++) {\n    let chunk = chunks[i];\n    result.set(chunk, pos);\n    pos += chunk.length;\n  }\n\n  return result;\n};\n\nvar common = {\n\tassign: assign,\n\tflattenChunks: flattenChunks\n};\n\n// String encode/decode helpers\n\n\n// Quick check if we can use fast array to bin string conversion\n//\n// - apply(Array) can fail on Android 2.2\n// - apply(Uint8Array) can fail on iOS 5.1 Safari\n//\nlet STR_APPLY_UIA_OK = true;\n\ntry { String.fromCharCode.apply(null, new Uint8Array(1)); } catch (__) { STR_APPLY_UIA_OK = false; }\n\n\n// Table with utf8 lengths (calculated by first byte of sequence)\n// Note, that 5 & 6-byte values and some 4-byte values can not be represented in JS,\n// because max possible codepoint is 0x10ffff\nconst _utf8len = new Uint8Array(256);\nfor (let q = 0; q < 256; q++) {\n  _utf8len[q] = (q >= 252 ? 6 : q >= 248 ? 5 : q >= 240 ? 4 : q >= 224 ? 3 : q >= 192 ? 2 : 1);\n}\n_utf8len[254] = _utf8len[254] = 1; // Invalid sequence start\n\n\n// convert string to array (typed, when possible)\nvar string2buf = (str) => {\n  if (typeof TextEncoder === 'function' && TextEncoder.prototype.encode) {\n    return new TextEncoder().encode(str);\n  }\n\n  let buf, c, c2, m_pos, i, str_len = str.length, buf_len = 0;\n\n  // count binary size\n  for (m_pos = 0; m_pos < str_len; m_pos++) {\n    c = str.charCodeAt(m_pos);\n    if ((c & 0xfc00) === 0xd800 && (m_pos + 1 < str_len)) {\n      c2 = str.charCodeAt(m_pos + 1);\n      if ((c2 & 0xfc00) === 0xdc00) {\n        c = 0x10000 + ((c - 0xd800) << 10) + (c2 - 0xdc00);\n        m_pos++;\n      }\n    }\n    buf_len += c < 0x80 ? 1 : c < 0x800 ? 2 : c < 0x10000 ? 3 : 4;\n  }\n\n  // allocate buffer\n  buf = new Uint8Array(buf_len);\n\n  // convert\n  for (i = 0, m_pos = 0; i < buf_len; m_pos++) {\n    c = str.charCodeAt(m_pos);\n    if ((c & 0xfc00) === 0xd800 && (m_pos + 1 < str_len)) {\n      c2 = str.charCodeAt(m_pos + 1);\n      if ((c2 & 0xfc00) === 0xdc00) {\n        c = 0x10000 + ((c - 0xd800) << 10) + (c2 - 0xdc00);\n        m_pos++;\n      }\n    }\n    if (c < 0x80) {\n      /* one byte */\n      buf[i++] = c;\n    } else if (c < 0x800) {\n      /* two bytes */\n      buf[i++] = 0xC0 | (c >>> 6);\n      buf[i++] = 0x80 | (c & 0x3f);\n    } else if (c < 0x10000) {\n      /* three bytes */\n      buf[i++] = 0xE0 | (c >>> 12);\n      buf[i++] = 0x80 | (c >>> 6 & 0x3f);\n      buf[i++] = 0x80 | (c & 0x3f);\n    } else {\n      /* four bytes */\n      buf[i++] = 0xf0 | (c >>> 18);\n      buf[i++] = 0x80 | (c >>> 12 & 0x3f);\n      buf[i++] = 0x80 | (c >>> 6 & 0x3f);\n      buf[i++] = 0x80 | (c & 0x3f);\n    }\n  }\n\n  return buf;\n};\n\n// Helper\nconst buf2binstring = (buf, len) => {\n  // On Chrome, the arguments in a function call that are allowed is `65534`.\n  // If the length of the buffer is smaller than that, we can use this optimization,\n  // otherwise we will take a slower path.\n  if (len < 65534) {\n    if (buf.subarray && STR_APPLY_UIA_OK) {\n      return String.fromCharCode.apply(null, buf.length === len ? buf : buf.subarray(0, len));\n    }\n  }\n\n  let result = '';\n  for (let i = 0; i < len; i++) {\n    result += String.fromCharCode(buf[i]);\n  }\n  return result;\n};\n\n\n// convert array to string\nvar buf2string = (buf, max) => {\n  const len = max || buf.length;\n\n  if (typeof TextDecoder === 'function' && TextDecoder.prototype.decode) {\n    return new TextDecoder().decode(buf.subarray(0, max));\n  }\n\n  let i, out;\n\n  // Reserve max possible length (2 words per char)\n  // NB: by unknown reasons, Array is significantly faster for\n  //     String.fromCharCode.apply than Uint16Array.\n  const utf16buf = new Array(len * 2);\n\n  for (out = 0, i = 0; i < len;) {\n    let c = buf[i++];\n    // quick process ascii\n    if (c < 0x80) { utf16buf[out++] = c; continue; }\n\n    let c_len = _utf8len[c];\n    // skip 5 & 6 byte codes\n    if (c_len > 4) { utf16buf[out++] = 0xfffd; i += c_len - 1; continue; }\n\n    // apply mask on first byte\n    c &= c_len === 2 ? 0x1f : c_len === 3 ? 0x0f : 0x07;\n    // join the rest\n    while (c_len > 1 && i < len) {\n      c = (c << 6) | (buf[i++] & 0x3f);\n      c_len--;\n    }\n\n    // terminated by end of string?\n    if (c_len > 1) { utf16buf[out++] = 0xfffd; continue; }\n\n    if (c < 0x10000) {\n      utf16buf[out++] = c;\n    } else {\n      c -= 0x10000;\n      utf16buf[out++] = 0xd800 | ((c >> 10) & 0x3ff);\n      utf16buf[out++] = 0xdc00 | (c & 0x3ff);\n    }\n  }\n\n  return buf2binstring(utf16buf, out);\n};\n\n\n// Calculate max possible position in utf8 buffer,\n// that will not break sequence. If that's not possible\n// - (very small limits) return max size as is.\n//\n// buf[] - utf8 bytes array\n// max   - length limit (mandatory);\nvar utf8border = (buf, max) => {\n\n  max = max || buf.length;\n  if (max > buf.length) { max = buf.length; }\n\n  // go back from last position, until start of sequence found\n  let pos = max - 1;\n  while (pos >= 0 && (buf[pos] & 0xC0) === 0x80) { pos--; }\n\n  // Very small and broken sequence,\n  // return max, because we should return something anyway.\n  if (pos < 0) { return max; }\n\n  // If we came to start of buffer - that means buffer is too small,\n  // return max too.\n  if (pos === 0) { return max; }\n\n  return (pos + _utf8len[buf[pos]] > max) ? pos : max;\n};\n\nvar strings = {\n\tstring2buf: string2buf,\n\tbuf2string: buf2string,\n\tutf8border: utf8border\n};\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nfunction ZStream() {\n  /* next input byte */\n  this.input = null; // JS specific, because we have no pointers\n  this.next_in = 0;\n  /* number of bytes available at input */\n  this.avail_in = 0;\n  /* total number of input bytes read so far */\n  this.total_in = 0;\n  /* next output byte should be put there */\n  this.output = null; // JS specific, because we have no pointers\n  this.next_out = 0;\n  /* remaining free space at output */\n  this.avail_out = 0;\n  /* total number of bytes output so far */\n  this.total_out = 0;\n  /* last error message, NULL if no error */\n  this.msg = ''/*Z_NULL*/;\n  /* not visible by applications */\n  this.state = null;\n  /* best guess about the data type: binary or text */\n  this.data_type = 2/*Z_UNKNOWN*/;\n  /* adler32 value of the uncompressed data */\n  this.adler = 0;\n}\n\nvar zstream = ZStream;\n\nconst toString$1 = Object.prototype.toString;\n\n/* Public constants ==========================================================*/\n/* ===========================================================================*/\n\nconst {\n  Z_NO_FLUSH: Z_NO_FLUSH$1, Z_SYNC_FLUSH, Z_FULL_FLUSH, Z_FINISH: Z_FINISH$2,\n  Z_OK: Z_OK$2, Z_STREAM_END: Z_STREAM_END$2,\n  Z_DEFAULT_COMPRESSION,\n  Z_DEFAULT_STRATEGY,\n  Z_DEFLATED: Z_DEFLATED$1\n} = constants$2;\n\n/* ===========================================================================*/\n\n\n/**\n * class Deflate\n *\n * Generic JS-style wrapper for zlib calls. If you don't need\n * streaming behaviour - use more simple functions: [[deflate]],\n * [[deflateRaw]] and [[gzip]].\n **/\n\n/* internal\n * Deflate.chunks -> Array\n *\n * Chunks of output data, if [[Deflate#onData]] not overridden.\n **/\n\n/**\n * Deflate.result -> Uint8Array\n *\n * Compressed result, generated by default [[Deflate#onData]]\n * and [[Deflate#onEnd]] handlers. Filled after you push last chunk\n * (call [[Deflate#push]] with `Z_FINISH` / `true` param).\n **/\n\n/**\n * Deflate.err -> Number\n *\n * Error code after deflate finished. 0 (Z_OK) on success.\n * You will not need it in real life, because deflate errors\n * are possible only on wrong options or bad `onData` / `onEnd`\n * custom handlers.\n **/\n\n/**\n * Deflate.msg -> String\n *\n * Error message, if [[Deflate.err]] != 0\n **/\n\n\n/**\n * new Deflate(options)\n * - options (Object): zlib deflate options.\n *\n * Creates new deflator instance with specified params. Throws exception\n * on bad params. Supported options:\n *\n * - `level`\n * - `windowBits`\n * - `memLevel`\n * - `strategy`\n * - `dictionary`\n *\n * [http://zlib.net/manual.html#Advanced](http://zlib.net/manual.html#Advanced)\n * for more information on these.\n *\n * Additional options, for internal needs:\n *\n * - `chunkSize` - size of generated data chunks (16K by default)\n * - `raw` (Boolean) - do raw deflate\n * - `gzip` (Boolean) - create gzip wrapper\n * - `header` (Object) - custom header for gzip\n *   - `text` (Boolean) - true if compressed data believed to be text\n *   - `time` (Number) - modification time, unix timestamp\n *   - `os` (Number) - operation system code\n *   - `extra` (Array) - array of bytes with extra data (max 65536)\n *   - `name` (String) - file name (binary string)\n *   - `comment` (String) - comment (binary string)\n *   - `hcrc` (Boolean) - true if header crc should be added\n *\n * ##### Example:\n *\n * ```javascript\n * const pako = require('pako')\n *   , chunk1 = new Uint8Array([1,2,3,4,5,6,7,8,9])\n *   , chunk2 = new Uint8Array([10,11,12,13,14,15,16,17,18,19]);\n *\n * const deflate = new pako.Deflate({ level: 3});\n *\n * deflate.push(chunk1, false);\n * deflate.push(chunk2, true);  // true -> last chunk\n *\n * if (deflate.err) { throw new Error(deflate.err); }\n *\n * console.log(deflate.result);\n * ```\n **/\nfunction Deflate$1(options) {\n  this.options = common.assign({\n    level: Z_DEFAULT_COMPRESSION,\n    method: Z_DEFLATED$1,\n    chunkSize: 16384,\n    windowBits: 15,\n    memLevel: 8,\n    strategy: Z_DEFAULT_STRATEGY\n  }, options || {});\n\n  let opt = this.options;\n\n  if (opt.raw && (opt.windowBits > 0)) {\n    opt.windowBits = -opt.windowBits;\n  }\n\n  else if (opt.gzip && (opt.windowBits > 0) && (opt.windowBits < 16)) {\n    opt.windowBits += 16;\n  }\n\n  this.err    = 0;      // error code, if happens (0 = Z_OK)\n  this.msg    = '';     // error message\n  this.ended  = false;  // used to avoid multiple onEnd() calls\n  this.chunks = [];     // chunks of compressed data\n\n  this.strm = new zstream();\n  this.strm.avail_out = 0;\n\n  let status = deflate_1$2.deflateInit2(\n    this.strm,\n    opt.level,\n    opt.method,\n    opt.windowBits,\n    opt.memLevel,\n    opt.strategy\n  );\n\n  if (status !== Z_OK$2) {\n    throw new Error(messages[status]);\n  }\n\n  if (opt.header) {\n    deflate_1$2.deflateSetHeader(this.strm, opt.header);\n  }\n\n  if (opt.dictionary) {\n    let dict;\n    // Convert data if needed\n    if (typeof opt.dictionary === 'string') {\n      // If we need to compress text, change encoding to utf8.\n      dict = strings.string2buf(opt.dictionary);\n    } else if (toString$1.call(opt.dictionary) === '[object ArrayBuffer]') {\n      dict = new Uint8Array(opt.dictionary);\n    } else {\n      dict = opt.dictionary;\n    }\n\n    status = deflate_1$2.deflateSetDictionary(this.strm, dict);\n\n    if (status !== Z_OK$2) {\n      throw new Error(messages[status]);\n    }\n\n    this._dict_set = true;\n  }\n}\n\n/**\n * Deflate#push(data[, flush_mode]) -> Boolean\n * - data (Uint8Array|ArrayBuffer|String): input data. Strings will be\n *   converted to utf8 byte sequence.\n * - flush_mode (Number|Boolean): 0..6 for corresponding Z_NO_FLUSH..Z_TREE modes.\n *   See constants. Skipped or `false` means Z_NO_FLUSH, `true` means Z_FINISH.\n *\n * Sends input data to deflate pipe, generating [[Deflate#onData]] calls with\n * new compressed chunks. Returns `true` on success. The last data block must\n * have `flush_mode` Z_FINISH (or `true`). That will flush internal pending\n * buffers and call [[Deflate#onEnd]].\n *\n * On fail call [[Deflate#onEnd]] with error code and return false.\n *\n * ##### Example\n *\n * ```javascript\n * push(chunk, false); // push one of data chunks\n * ...\n * push(chunk, true);  // push last chunk\n * ```\n **/\nDeflate$1.prototype.push = function (data, flush_mode) {\n  const strm = this.strm;\n  const chunkSize = this.options.chunkSize;\n  let status, _flush_mode;\n\n  if (this.ended) { return false; }\n\n  if (flush_mode === ~~flush_mode) _flush_mode = flush_mode;\n  else _flush_mode = flush_mode === true ? Z_FINISH$2 : Z_NO_FLUSH$1;\n\n  // Convert data if needed\n  if (typeof data === 'string') {\n    // If we need to compress text, change encoding to utf8.\n    strm.input = strings.string2buf(data);\n  } else if (toString$1.call(data) === '[object ArrayBuffer]') {\n    strm.input = new Uint8Array(data);\n  } else {\n    strm.input = data;\n  }\n\n  strm.next_in = 0;\n  strm.avail_in = strm.input.length;\n\n  for (;;) {\n    if (strm.avail_out === 0) {\n      strm.output = new Uint8Array(chunkSize);\n      strm.next_out = 0;\n      strm.avail_out = chunkSize;\n    }\n\n    // Make sure avail_out > 6 to avoid repeating markers\n    if ((_flush_mode === Z_SYNC_FLUSH || _flush_mode === Z_FULL_FLUSH) && strm.avail_out <= 6) {\n      this.onData(strm.output.subarray(0, strm.next_out));\n      strm.avail_out = 0;\n      continue;\n    }\n\n    status = deflate_1$2.deflate(strm, _flush_mode);\n\n    // Ended => flush and finish\n    if (status === Z_STREAM_END$2) {\n      if (strm.next_out > 0) {\n        this.onData(strm.output.subarray(0, strm.next_out));\n      }\n      status = deflate_1$2.deflateEnd(this.strm);\n      this.onEnd(status);\n      this.ended = true;\n      return status === Z_OK$2;\n    }\n\n    // Flush if out buffer full\n    if (strm.avail_out === 0) {\n      this.onData(strm.output);\n      continue;\n    }\n\n    // Flush if requested and has data\n    if (_flush_mode > 0 && strm.next_out > 0) {\n      this.onData(strm.output.subarray(0, strm.next_out));\n      strm.avail_out = 0;\n      continue;\n    }\n\n    if (strm.avail_in === 0) break;\n  }\n\n  return true;\n};\n\n\n/**\n * Deflate#onData(chunk) -> Void\n * - chunk (Uint8Array): output data.\n *\n * By default, stores data blocks in `chunks[]` property and glue\n * those in `onEnd`. Override this handler, if you need another behaviour.\n **/\nDeflate$1.prototype.onData = function (chunk) {\n  this.chunks.push(chunk);\n};\n\n\n/**\n * Deflate#onEnd(status) -> Void\n * - status (Number): deflate status. 0 (Z_OK) on success,\n *   other if not.\n *\n * Called once after you tell deflate that the input stream is\n * complete (Z_FINISH). By default - join collected chunks,\n * free memory and fill `results` / `err` properties.\n **/\nDeflate$1.prototype.onEnd = function (status) {\n  // On success - join\n  if (status === Z_OK$2) {\n    this.result = common.flattenChunks(this.chunks);\n  }\n  this.chunks = [];\n  this.err = status;\n  this.msg = this.strm.msg;\n};\n\n\n/**\n * deflate(data[, options]) -> Uint8Array\n * - data (Uint8Array|ArrayBuffer|String): input data to compress.\n * - options (Object): zlib deflate options.\n *\n * Compress `data` with deflate algorithm and `options`.\n *\n * Supported options are:\n *\n * - level\n * - windowBits\n * - memLevel\n * - strategy\n * - dictionary\n *\n * [http://zlib.net/manual.html#Advanced](http://zlib.net/manual.html#Advanced)\n * for more information on these.\n *\n * Sugar (options):\n *\n * - `raw` (Boolean) - say that we work with raw stream, if you don't wish to specify\n *   negative windowBits implicitly.\n *\n * ##### Example:\n *\n * ```javascript\n * const pako = require('pako')\n * const data = new Uint8Array([1,2,3,4,5,6,7,8,9]);\n *\n * console.log(pako.deflate(data));\n * ```\n **/\nfunction deflate$1(input, options) {\n  const deflator = new Deflate$1(options);\n\n  deflator.push(input, true);\n\n  // That will never happens, if you don't cheat with options :)\n  if (deflator.err) { throw deflator.msg || messages[deflator.err]; }\n\n  return deflator.result;\n}\n\n\n/**\n * deflateRaw(data[, options]) -> Uint8Array\n * - data (Uint8Array|ArrayBuffer|String): input data to compress.\n * - options (Object): zlib deflate options.\n *\n * The same as [[deflate]], but creates raw data, without wrapper\n * (header and adler32 crc).\n **/\nfunction deflateRaw$1(input, options) {\n  options = options || {};\n  options.raw = true;\n  return deflate$1(input, options);\n}\n\n\n/**\n * gzip(data[, options]) -> Uint8Array\n * - data (Uint8Array|ArrayBuffer|String): input data to compress.\n * - options (Object): zlib deflate options.\n *\n * The same as [[deflate]], but create gzip wrapper instead of\n * deflate one.\n **/\nfunction gzip$1(input, options) {\n  options = options || {};\n  options.gzip = true;\n  return deflate$1(input, options);\n}\n\n\nvar Deflate_1$1 = Deflate$1;\nvar deflate_2 = deflate$1;\nvar deflateRaw_1$1 = deflateRaw$1;\nvar gzip_1$1 = gzip$1;\nvar constants$1 = constants$2;\n\nvar deflate_1$1 = {\n\tDeflate: Deflate_1$1,\n\tdeflate: deflate_2,\n\tdeflateRaw: deflateRaw_1$1,\n\tgzip: gzip_1$1,\n\tconstants: constants$1\n};\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\n// See state defs from inflate.js\nconst BAD$1 = 16209;       /* got a data error -- remain here until reset */\nconst TYPE$1 = 16191;      /* i: waiting for type bits, including last-flag bit */\n\n/*\n   Decode literal, length, and distance codes and write out the resulting\n   literal and match bytes until either not enough input or output is\n   available, an end-of-block is encountered, or a data error is encountered.\n   When large enough input and output buffers are supplied to inflate(), for\n   example, a 16K input buffer and a 64K output buffer, more than 95% of the\n   inflate execution time is spent in this routine.\n\n   Entry assumptions:\n\n        state.mode === LEN\n        strm.avail_in >= 6\n        strm.avail_out >= 258\n        start >= strm.avail_out\n        state.bits < 8\n\n   On return, state.mode is one of:\n\n        LEN -- ran out of enough output space or enough available input\n        TYPE -- reached end of block code, inflate() to interpret next block\n        BAD -- error in block data\n\n   Notes:\n\n    - The maximum input bits used by a length/distance pair is 15 bits for the\n      length code, 5 bits for the length extra, 15 bits for the distance code,\n      and 13 bits for the distance extra.  This totals 48 bits, or six bytes.\n      Therefore if strm.avail_in >= 6, then there is enough input to avoid\n      checking for available input while decoding.\n\n    - The maximum bytes that a single length/distance pair can output is 258\n      bytes, which is the maximum length that can be coded.  inflate_fast()\n      requires strm.avail_out >= 258 for each loop to avoid checking for\n      output space.\n */\nvar inffast = function inflate_fast(strm, start) {\n  let _in;                    /* local strm.input */\n  let last;                   /* have enough input while in < last */\n  let _out;                   /* local strm.output */\n  let beg;                    /* inflate()'s initial strm.output */\n  let end;                    /* while out < end, enough space available */\n//#ifdef INFLATE_STRICT\n  let dmax;                   /* maximum distance from zlib header */\n//#endif\n  let wsize;                  /* window size or zero if not using window */\n  let whave;                  /* valid bytes in the window */\n  let wnext;                  /* window write index */\n  // Use `s_window` instead `window`, avoid conflict with instrumentation tools\n  let s_window;               /* allocated sliding window, if wsize != 0 */\n  let hold;                   /* local strm.hold */\n  let bits;                   /* local strm.bits */\n  let lcode;                  /* local strm.lencode */\n  let dcode;                  /* local strm.distcode */\n  let lmask;                  /* mask for first level of length codes */\n  let dmask;                  /* mask for first level of distance codes */\n  let here;                   /* retrieved table entry */\n  let op;                     /* code bits, operation, extra bits, or */\n                              /*  window position, window bytes to copy */\n  let len;                    /* match length, unused bytes */\n  let dist;                   /* match distance */\n  let from;                   /* where to copy match from */\n  let from_source;\n\n\n  let input, output; // JS specific, because we have no pointers\n\n  /* copy state to local variables */\n  const state = strm.state;\n  //here = state.here;\n  _in = strm.next_in;\n  input = strm.input;\n  last = _in + (strm.avail_in - 5);\n  _out = strm.next_out;\n  output = strm.output;\n  beg = _out - (start - strm.avail_out);\n  end = _out + (strm.avail_out - 257);\n//#ifdef INFLATE_STRICT\n  dmax = state.dmax;\n//#endif\n  wsize = state.wsize;\n  whave = state.whave;\n  wnext = state.wnext;\n  s_window = state.window;\n  hold = state.hold;\n  bits = state.bits;\n  lcode = state.lencode;\n  dcode = state.distcode;\n  lmask = (1 << state.lenbits) - 1;\n  dmask = (1 << state.distbits) - 1;\n\n\n  /* decode literals and length/distances until end-of-block or not enough\n     input data or output space */\n\n  top:\n  do {\n    if (bits < 15) {\n      hold += input[_in++] << bits;\n      bits += 8;\n      hold += input[_in++] << bits;\n      bits += 8;\n    }\n\n    here = lcode[hold & lmask];\n\n    dolen:\n    for (;;) { // Goto emulation\n      op = here >>> 24/*here.bits*/;\n      hold >>>= op;\n      bits -= op;\n      op = (here >>> 16) & 0xff/*here.op*/;\n      if (op === 0) {                          /* literal */\n        //Tracevv((stderr, here.val >= 0x20 && here.val < 0x7f ?\n        //        \"inflate:         literal '%c'\\n\" :\n        //        \"inflate:         literal 0x%02x\\n\", here.val));\n        output[_out++] = here & 0xffff/*here.val*/;\n      }\n      else if (op & 16) {                     /* length base */\n        len = here & 0xffff/*here.val*/;\n        op &= 15;                           /* number of extra bits */\n        if (op) {\n          if (bits < op) {\n            hold += input[_in++] << bits;\n            bits += 8;\n          }\n          len += hold & ((1 << op) - 1);\n          hold >>>= op;\n          bits -= op;\n        }\n        //Tracevv((stderr, \"inflate:         length %u\\n\", len));\n        if (bits < 15) {\n          hold += input[_in++] << bits;\n          bits += 8;\n          hold += input[_in++] << bits;\n          bits += 8;\n        }\n        here = dcode[hold & dmask];\n\n        dodist:\n        for (;;) { // goto emulation\n          op = here >>> 24/*here.bits*/;\n          hold >>>= op;\n          bits -= op;\n          op = (here >>> 16) & 0xff/*here.op*/;\n\n          if (op & 16) {                      /* distance base */\n            dist = here & 0xffff/*here.val*/;\n            op &= 15;                       /* number of extra bits */\n            if (bits < op) {\n              hold += input[_in++] << bits;\n              bits += 8;\n              if (bits < op) {\n                hold += input[_in++] << bits;\n                bits += 8;\n              }\n            }\n            dist += hold & ((1 << op) - 1);\n//#ifdef INFLATE_STRICT\n            if (dist > dmax) {\n              strm.msg = 'invalid distance too far back';\n              state.mode = BAD$1;\n              break top;\n            }\n//#endif\n            hold >>>= op;\n            bits -= op;\n            //Tracevv((stderr, \"inflate:         distance %u\\n\", dist));\n            op = _out - beg;                /* max distance in output */\n            if (dist > op) {                /* see if copy from window */\n              op = dist - op;               /* distance back in window */\n              if (op > whave) {\n                if (state.sane) {\n                  strm.msg = 'invalid distance too far back';\n                  state.mode = BAD$1;\n                  break top;\n                }\n\n// (!) This block is disabled in zlib defaults,\n// don't enable it for binary compatibility\n//#ifdef INFLATE_ALLOW_INVALID_DISTANCE_TOOFAR_ARRR\n//                if (len <= op - whave) {\n//                  do {\n//                    output[_out++] = 0;\n//                  } while (--len);\n//                  continue top;\n//                }\n//                len -= op - whave;\n//                do {\n//                  output[_out++] = 0;\n//                } while (--op > whave);\n//                if (op === 0) {\n//                  from = _out - dist;\n//                  do {\n//                    output[_out++] = output[from++];\n//                  } while (--len);\n//                  continue top;\n//                }\n//#endif\n              }\n              from = 0; // window index\n              from_source = s_window;\n              if (wnext === 0) {           /* very common case */\n                from += wsize - op;\n                if (op < len) {         /* some from window */\n                  len -= op;\n                  do {\n                    output[_out++] = s_window[from++];\n                  } while (--op);\n                  from = _out - dist;  /* rest from output */\n                  from_source = output;\n                }\n              }\n              else if (wnext < op) {      /* wrap around window */\n                from += wsize + wnext - op;\n                op -= wnext;\n                if (op < len) {         /* some from end of window */\n                  len -= op;\n                  do {\n                    output[_out++] = s_window[from++];\n                  } while (--op);\n                  from = 0;\n                  if (wnext < len) {  /* some from start of window */\n                    op = wnext;\n                    len -= op;\n                    do {\n                      output[_out++] = s_window[from++];\n                    } while (--op);\n                    from = _out - dist;      /* rest from output */\n                    from_source = output;\n                  }\n                }\n              }\n              else {                      /* contiguous in window */\n                from += wnext - op;\n                if (op < len) {         /* some from window */\n                  len -= op;\n                  do {\n                    output[_out++] = s_window[from++];\n                  } while (--op);\n                  from = _out - dist;  /* rest from output */\n                  from_source = output;\n                }\n              }\n              while (len > 2) {\n                output[_out++] = from_source[from++];\n                output[_out++] = from_source[from++];\n                output[_out++] = from_source[from++];\n                len -= 3;\n              }\n              if (len) {\n                output[_out++] = from_source[from++];\n                if (len > 1) {\n                  output[_out++] = from_source[from++];\n                }\n              }\n            }\n            else {\n              from = _out - dist;          /* copy direct from output */\n              do {                        /* minimum length is three */\n                output[_out++] = output[from++];\n                output[_out++] = output[from++];\n                output[_out++] = output[from++];\n                len -= 3;\n              } while (len > 2);\n              if (len) {\n                output[_out++] = output[from++];\n                if (len > 1) {\n                  output[_out++] = output[from++];\n                }\n              }\n            }\n          }\n          else if ((op & 64) === 0) {          /* 2nd level distance code */\n            here = dcode[(here & 0xffff)/*here.val*/ + (hold & ((1 << op) - 1))];\n            continue dodist;\n          }\n          else {\n            strm.msg = 'invalid distance code';\n            state.mode = BAD$1;\n            break top;\n          }\n\n          break; // need to emulate goto via \"continue\"\n        }\n      }\n      else if ((op & 64) === 0) {              /* 2nd level length code */\n        here = lcode[(here & 0xffff)/*here.val*/ + (hold & ((1 << op) - 1))];\n        continue dolen;\n      }\n      else if (op & 32) {                     /* end-of-block */\n        //Tracevv((stderr, \"inflate:         end of block\\n\"));\n        state.mode = TYPE$1;\n        break top;\n      }\n      else {\n        strm.msg = 'invalid literal/length code';\n        state.mode = BAD$1;\n        break top;\n      }\n\n      break; // need to emulate goto via \"continue\"\n    }\n  } while (_in < last && _out < end);\n\n  /* return unused bytes (on entry, bits < 8, so in won't go too far back) */\n  len = bits >> 3;\n  _in -= len;\n  bits -= len << 3;\n  hold &= (1 << bits) - 1;\n\n  /* update state and return */\n  strm.next_in = _in;\n  strm.next_out = _out;\n  strm.avail_in = (_in < last ? 5 + (last - _in) : 5 - (_in - last));\n  strm.avail_out = (_out < end ? 257 + (end - _out) : 257 - (_out - end));\n  state.hold = hold;\n  state.bits = bits;\n  return;\n};\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nconst MAXBITS = 15;\nconst ENOUGH_LENS$1 = 852;\nconst ENOUGH_DISTS$1 = 592;\n//const ENOUGH = (ENOUGH_LENS+ENOUGH_DISTS);\n\nconst CODES$1 = 0;\nconst LENS$1 = 1;\nconst DISTS$1 = 2;\n\nconst lbase = new Uint16Array([ /* Length codes 257..285 base */\n  3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 17, 19, 23, 27, 31,\n  35, 43, 51, 59, 67, 83, 99, 115, 131, 163, 195, 227, 258, 0, 0\n]);\n\nconst lext = new Uint8Array([ /* Length codes 257..285 extra */\n  16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 18,\n  19, 19, 19, 19, 20, 20, 20, 20, 21, 21, 21, 21, 16, 72, 78\n]);\n\nconst dbase = new Uint16Array([ /* Distance codes 0..29 base */\n  1, 2, 3, 4, 5, 7, 9, 13, 17, 25, 33, 49, 65, 97, 129, 193,\n  257, 385, 513, 769, 1025, 1537, 2049, 3073, 4097, 6145,\n  8193, 12289, 16385, 24577, 0, 0\n]);\n\nconst dext = new Uint8Array([ /* Distance codes 0..29 extra */\n  16, 16, 16, 16, 17, 17, 18, 18, 19, 19, 20, 20, 21, 21, 22, 22,\n  23, 23, 24, 24, 25, 25, 26, 26, 27, 27,\n  28, 28, 29, 29, 64, 64\n]);\n\nconst inflate_table = (type, lens, lens_index, codes, table, table_index, work, opts) =>\n{\n  const bits = opts.bits;\n      //here = opts.here; /* table entry for duplication */\n\n  let len = 0;               /* a code's length in bits */\n  let sym = 0;               /* index of code symbols */\n  let min = 0, max = 0;          /* minimum and maximum code lengths */\n  let root = 0;              /* number of index bits for root table */\n  let curr = 0;              /* number of index bits for current table */\n  let drop = 0;              /* code bits to drop for sub-table */\n  let left = 0;                   /* number of prefix codes available */\n  let used = 0;              /* code entries in table used */\n  let huff = 0;              /* Huffman code */\n  let incr;              /* for incrementing code, index */\n  let fill;              /* index for replicating entries */\n  let low;               /* low bits for current root entry */\n  let mask;              /* mask for low root bits */\n  let next;             /* next available space in table */\n  let base = null;     /* base value table to use */\n//  let shoextra;    /* extra bits table to use */\n  let match;                  /* use base and extra for symbol >= match */\n  const count = new Uint16Array(MAXBITS + 1); //[MAXBITS+1];    /* number of codes of each length */\n  const offs = new Uint16Array(MAXBITS + 1); //[MAXBITS+1];     /* offsets in table for each length */\n  let extra = null;\n\n  let here_bits, here_op, here_val;\n\n  /*\n   Process a set of code lengths to create a canonical Huffman code.  The\n   code lengths are lens[0..codes-1].  Each length corresponds to the\n   symbols 0..codes-1.  The Huffman code is generated by first sorting the\n   symbols by length from short to long, and retaining the symbol order\n   for codes with equal lengths.  Then the code starts with all zero bits\n   for the first code of the shortest length, and the codes are integer\n   increments for the same length, and zeros are appended as the length\n   increases.  For the deflate format, these bits are stored backwards\n   from their more natural integer increment ordering, and so when the\n   decoding tables are built in the large loop below, the integer codes\n   are incremented backwards.\n\n   This routine assumes, but does not check, that all of the entries in\n   lens[] are in the range 0..MAXBITS.  The caller must assure this.\n   1..MAXBITS is interpreted as that code length.  zero means that that\n   symbol does not occur in this code.\n\n   The codes are sorted by computing a count of codes for each length,\n   creating from that a table of starting indices for each length in the\n   sorted table, and then entering the symbols in order in the sorted\n   table.  The sorted table is work[], with that space being provided by\n   the caller.\n\n   The length counts are used for other purposes as well, i.e. finding\n   the minimum and maximum length codes, determining if there are any\n   codes at all, checking for a valid set of lengths, and looking ahead\n   at length counts to determine sub-table sizes when building the\n   decoding tables.\n   */\n\n  /* accumulate lengths for codes (assumes lens[] all in 0..MAXBITS) */\n  for (len = 0; len <= MAXBITS; len++) {\n    count[len] = 0;\n  }\n  for (sym = 0; sym < codes; sym++) {\n    count[lens[lens_index + sym]]++;\n  }\n\n  /* bound code lengths, force root to be within code lengths */\n  root = bits;\n  for (max = MAXBITS; max >= 1; max--) {\n    if (count[max] !== 0) { break; }\n  }\n  if (root > max) {\n    root = max;\n  }\n  if (max === 0) {                     /* no symbols to code at all */\n    //table.op[opts.table_index] = 64;  //here.op = (var char)64;    /* invalid code marker */\n    //table.bits[opts.table_index] = 1;   //here.bits = (var char)1;\n    //table.val[opts.table_index++] = 0;   //here.val = (var short)0;\n    table[table_index++] = (1 << 24) | (64 << 16) | 0;\n\n\n    //table.op[opts.table_index] = 64;\n    //table.bits[opts.table_index] = 1;\n    //table.val[opts.table_index++] = 0;\n    table[table_index++] = (1 << 24) | (64 << 16) | 0;\n\n    opts.bits = 1;\n    return 0;     /* no symbols, but wait for decoding to report error */\n  }\n  for (min = 1; min < max; min++) {\n    if (count[min] !== 0) { break; }\n  }\n  if (root < min) {\n    root = min;\n  }\n\n  /* check for an over-subscribed or incomplete set of lengths */\n  left = 1;\n  for (len = 1; len <= MAXBITS; len++) {\n    left <<= 1;\n    left -= count[len];\n    if (left < 0) {\n      return -1;\n    }        /* over-subscribed */\n  }\n  if (left > 0 && (type === CODES$1 || max !== 1)) {\n    return -1;                      /* incomplete set */\n  }\n\n  /* generate offsets into symbol table for each length for sorting */\n  offs[1] = 0;\n  for (len = 1; len < MAXBITS; len++) {\n    offs[len + 1] = offs[len] + count[len];\n  }\n\n  /* sort symbols by length, by symbol order within each length */\n  for (sym = 0; sym < codes; sym++) {\n    if (lens[lens_index + sym] !== 0) {\n      work[offs[lens[lens_index + sym]]++] = sym;\n    }\n  }\n\n  /*\n   Create and fill in decoding tables.  In this loop, the table being\n   filled is at next and has curr index bits.  The code being used is huff\n   with length len.  That code is converted to an index by dropping drop\n   bits off of the bottom.  For codes where len is less than drop + curr,\n   those top drop + curr - len bits are incremented through all values to\n   fill the table with replicated entries.\n\n   root is the number of index bits for the root table.  When len exceeds\n   root, sub-tables are created pointed to by the root entry with an index\n   of the low root bits of huff.  This is saved in low to check for when a\n   new sub-table should be started.  drop is zero when the root table is\n   being filled, and drop is root when sub-tables are being filled.\n\n   When a new sub-table is needed, it is necessary to look ahead in the\n   code lengths to determine what size sub-table is needed.  The length\n   counts are used for this, and so count[] is decremented as codes are\n   entered in the tables.\n\n   used keeps track of how many table entries have been allocated from the\n   provided *table space.  It is checked for LENS and DIST tables against\n   the constants ENOUGH_LENS and ENOUGH_DISTS to guard against changes in\n   the initial root table size constants.  See the comments in inftrees.h\n   for more information.\n\n   sym increments through all symbols, and the loop terminates when\n   all codes of length max, i.e. all codes, have been processed.  This\n   routine permits incomplete codes, so another loop after this one fills\n   in the rest of the decoding tables with invalid code markers.\n   */\n\n  /* set up for code type */\n  // poor man optimization - use if-else instead of switch,\n  // to avoid deopts in old v8\n  if (type === CODES$1) {\n    base = extra = work;    /* dummy value--not used */\n    match = 20;\n\n  } else if (type === LENS$1) {\n    base = lbase;\n    extra = lext;\n    match = 257;\n\n  } else {                    /* DISTS */\n    base = dbase;\n    extra = dext;\n    match = 0;\n  }\n\n  /* initialize opts for loop */\n  huff = 0;                   /* starting code */\n  sym = 0;                    /* starting code symbol */\n  len = min;                  /* starting code length */\n  next = table_index;              /* current table to fill in */\n  curr = root;                /* current table index bits */\n  drop = 0;                   /* current bits to drop from code for index */\n  low = -1;                   /* trigger new sub-table when len > root */\n  used = 1 << root;          /* use root table entries */\n  mask = used - 1;            /* mask for comparing low */\n\n  /* check available table space */\n  if ((type === LENS$1 && used > ENOUGH_LENS$1) ||\n    (type === DISTS$1 && used > ENOUGH_DISTS$1)) {\n    return 1;\n  }\n\n  /* process all codes and make table entries */\n  for (;;) {\n    /* create table entry */\n    here_bits = len - drop;\n    if (work[sym] + 1 < match) {\n      here_op = 0;\n      here_val = work[sym];\n    }\n    else if (work[sym] >= match) {\n      here_op = extra[work[sym] - match];\n      here_val = base[work[sym] - match];\n    }\n    else {\n      here_op = 32 + 64;         /* end of block */\n      here_val = 0;\n    }\n\n    /* replicate for those indices with low len bits equal to huff */\n    incr = 1 << (len - drop);\n    fill = 1 << curr;\n    min = fill;                 /* save offset to next table */\n    do {\n      fill -= incr;\n      table[next + (huff >> drop) + fill] = (here_bits << 24) | (here_op << 16) | here_val |0;\n    } while (fill !== 0);\n\n    /* backwards increment the len-bit code huff */\n    incr = 1 << (len - 1);\n    while (huff & incr) {\n      incr >>= 1;\n    }\n    if (incr !== 0) {\n      huff &= incr - 1;\n      huff += incr;\n    } else {\n      huff = 0;\n    }\n\n    /* go to next symbol, update count, len */\n    sym++;\n    if (--count[len] === 0) {\n      if (len === max) { break; }\n      len = lens[lens_index + work[sym]];\n    }\n\n    /* create new sub-table if needed */\n    if (len > root && (huff & mask) !== low) {\n      /* if first time, transition to sub-tables */\n      if (drop === 0) {\n        drop = root;\n      }\n\n      /* increment past last table */\n      next += min;            /* here min is 1 << curr */\n\n      /* determine length of next table */\n      curr = len - drop;\n      left = 1 << curr;\n      while (curr + drop < max) {\n        left -= count[curr + drop];\n        if (left <= 0) { break; }\n        curr++;\n        left <<= 1;\n      }\n\n      /* check for enough space */\n      used += 1 << curr;\n      if ((type === LENS$1 && used > ENOUGH_LENS$1) ||\n        (type === DISTS$1 && used > ENOUGH_DISTS$1)) {\n        return 1;\n      }\n\n      /* point entry in root table to sub-table */\n      low = huff & mask;\n      /*table.op[low] = curr;\n      table.bits[low] = root;\n      table.val[low] = next - opts.table_index;*/\n      table[low] = (root << 24) | (curr << 16) | (next - table_index) |0;\n    }\n  }\n\n  /* fill in remaining table entry if code is incomplete (guaranteed to have\n   at most one remaining entry, since if the code is incomplete, the\n   maximum code length that was allowed to get this far is one bit) */\n  if (huff !== 0) {\n    //table.op[next + huff] = 64;            /* invalid code marker */\n    //table.bits[next + huff] = len - drop;\n    //table.val[next + huff] = 0;\n    table[next + huff] = ((len - drop) << 24) | (64 << 16) |0;\n  }\n\n  /* set return parameters */\n  //opts.table_index += used;\n  opts.bits = root;\n  return 0;\n};\n\n\nvar inftrees = inflate_table;\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\n\n\n\n\n\nconst CODES = 0;\nconst LENS = 1;\nconst DISTS = 2;\n\n/* Public constants ==========================================================*/\n/* ===========================================================================*/\n\nconst {\n  Z_FINISH: Z_FINISH$1, Z_BLOCK, Z_TREES,\n  Z_OK: Z_OK$1, Z_STREAM_END: Z_STREAM_END$1, Z_NEED_DICT: Z_NEED_DICT$1, Z_STREAM_ERROR: Z_STREAM_ERROR$1, Z_DATA_ERROR: Z_DATA_ERROR$1, Z_MEM_ERROR: Z_MEM_ERROR$1, Z_BUF_ERROR,\n  Z_DEFLATED\n} = constants$2;\n\n\n/* STATES ====================================================================*/\n/* ===========================================================================*/\n\n\nconst    HEAD = 16180;       /* i: waiting for magic header */\nconst    FLAGS = 16181;      /* i: waiting for method and flags (gzip) */\nconst    TIME = 16182;       /* i: waiting for modification time (gzip) */\nconst    OS = 16183;         /* i: waiting for extra flags and operating system (gzip) */\nconst    EXLEN = 16184;      /* i: waiting for extra length (gzip) */\nconst    EXTRA = 16185;      /* i: waiting for extra bytes (gzip) */\nconst    NAME = 16186;       /* i: waiting for end of file name (gzip) */\nconst    COMMENT = 16187;    /* i: waiting for end of comment (gzip) */\nconst    HCRC = 16188;       /* i: waiting for header crc (gzip) */\nconst    DICTID = 16189;    /* i: waiting for dictionary check value */\nconst    DICT = 16190;      /* waiting for inflateSetDictionary() call */\nconst        TYPE = 16191;      /* i: waiting for type bits, including last-flag bit */\nconst        TYPEDO = 16192;    /* i: same, but skip check to exit inflate on new block */\nconst        STORED = 16193;    /* i: waiting for stored size (length and complement) */\nconst        COPY_ = 16194;     /* i/o: same as COPY below, but only first time in */\nconst        COPY = 16195;      /* i/o: waiting for input or output to copy stored block */\nconst        TABLE = 16196;     /* i: waiting for dynamic block table lengths */\nconst        LENLENS = 16197;   /* i: waiting for code length code lengths */\nconst        CODELENS = 16198;  /* i: waiting for length/lit and distance code lengths */\nconst            LEN_ = 16199;      /* i: same as LEN below, but only first time in */\nconst            LEN = 16200;       /* i: waiting for length/lit/eob code */\nconst            LENEXT = 16201;    /* i: waiting for length extra bits */\nconst            DIST = 16202;      /* i: waiting for distance code */\nconst            DISTEXT = 16203;   /* i: waiting for distance extra bits */\nconst            MATCH = 16204;     /* o: waiting for output space to copy string */\nconst            LIT = 16205;       /* o: waiting for output space to write literal */\nconst    CHECK = 16206;     /* i: waiting for 32-bit check value */\nconst    LENGTH = 16207;    /* i: waiting for 32-bit length (gzip) */\nconst    DONE = 16208;      /* finished check, done -- remain here until reset */\nconst    BAD = 16209;       /* got a data error -- remain here until reset */\nconst    MEM = 16210;       /* got an inflate() memory error -- remain here until reset */\nconst    SYNC = 16211;      /* looking for synchronization bytes to restart inflate() */\n\n/* ===========================================================================*/\n\n\n\nconst ENOUGH_LENS = 852;\nconst ENOUGH_DISTS = 592;\n//const ENOUGH =  (ENOUGH_LENS+ENOUGH_DISTS);\n\nconst MAX_WBITS = 15;\n/* 32K LZ77 window */\nconst DEF_WBITS = MAX_WBITS;\n\n\nconst zswap32 = (q) => {\n\n  return  (((q >>> 24) & 0xff) +\n          ((q >>> 8) & 0xff00) +\n          ((q & 0xff00) << 8) +\n          ((q & 0xff) << 24));\n};\n\n\nfunction InflateState() {\n  this.strm = null;           /* pointer back to this zlib stream */\n  this.mode = 0;              /* current inflate mode */\n  this.last = false;          /* true if processing last block */\n  this.wrap = 0;              /* bit 0 true for zlib, bit 1 true for gzip,\n                                 bit 2 true to validate check value */\n  this.havedict = false;      /* true if dictionary provided */\n  this.flags = 0;             /* gzip header method and flags (0 if zlib), or\n                                 -1 if raw or no header yet */\n  this.dmax = 0;              /* zlib header max distance (INFLATE_STRICT) */\n  this.check = 0;             /* protected copy of check value */\n  this.total = 0;             /* protected copy of output count */\n  // TODO: may be {}\n  this.head = null;           /* where to save gzip header information */\n\n  /* sliding window */\n  this.wbits = 0;             /* log base 2 of requested window size */\n  this.wsize = 0;             /* window size or zero if not using window */\n  this.whave = 0;             /* valid bytes in the window */\n  this.wnext = 0;             /* window write index */\n  this.window = null;         /* allocated sliding window, if needed */\n\n  /* bit accumulator */\n  this.hold = 0;              /* input bit accumulator */\n  this.bits = 0;              /* number of bits in \"in\" */\n\n  /* for string and stored block copying */\n  this.length = 0;            /* literal or length of data to copy */\n  this.offset = 0;            /* distance back to copy string from */\n\n  /* for table and code decoding */\n  this.extra = 0;             /* extra bits needed */\n\n  /* fixed and dynamic code tables */\n  this.lencode = null;          /* starting table for length/literal codes */\n  this.distcode = null;         /* starting table for distance codes */\n  this.lenbits = 0;           /* index bits for lencode */\n  this.distbits = 0;          /* index bits for distcode */\n\n  /* dynamic table building */\n  this.ncode = 0;             /* number of code length code lengths */\n  this.nlen = 0;              /* number of length code lengths */\n  this.ndist = 0;             /* number of distance code lengths */\n  this.have = 0;              /* number of code lengths in lens[] */\n  this.next = null;              /* next available space in codes[] */\n\n  this.lens = new Uint16Array(320); /* temporary storage for code lengths */\n  this.work = new Uint16Array(288); /* work area for code table building */\n\n  /*\n   because we don't have pointers in js, we use lencode and distcode directly\n   as buffers so we don't need codes\n  */\n  //this.codes = new Int32Array(ENOUGH);       /* space for code tables */\n  this.lendyn = null;              /* dynamic table for length/literal codes (JS specific) */\n  this.distdyn = null;             /* dynamic table for distance codes (JS specific) */\n  this.sane = 0;                   /* if false, allow invalid distance too far */\n  this.back = 0;                   /* bits back of last unprocessed length/lit */\n  this.was = 0;                    /* initial length of match */\n}\n\n\nconst inflateStateCheck = (strm) => {\n\n  if (!strm) {\n    return 1;\n  }\n  const state = strm.state;\n  if (!state || state.strm !== strm ||\n    state.mode < HEAD || state.mode > SYNC) {\n    return 1;\n  }\n  return 0;\n};\n\n\nconst inflateResetKeep = (strm) => {\n\n  if (inflateStateCheck(strm)) { return Z_STREAM_ERROR$1; }\n  const state = strm.state;\n  strm.total_in = strm.total_out = state.total = 0;\n  strm.msg = ''; /*Z_NULL*/\n  if (state.wrap) {       /* to support ill-conceived Java test suite */\n    strm.adler = state.wrap & 1;\n  }\n  state.mode = HEAD;\n  state.last = 0;\n  state.havedict = 0;\n  state.flags = -1;\n  state.dmax = 32768;\n  state.head = null/*Z_NULL*/;\n  state.hold = 0;\n  state.bits = 0;\n  //state.lencode = state.distcode = state.next = state.codes;\n  state.lencode = state.lendyn = new Int32Array(ENOUGH_LENS);\n  state.distcode = state.distdyn = new Int32Array(ENOUGH_DISTS);\n\n  state.sane = 1;\n  state.back = -1;\n  //Tracev((stderr, \"inflate: reset\\n\"));\n  return Z_OK$1;\n};\n\n\nconst inflateReset = (strm) => {\n\n  if (inflateStateCheck(strm)) { return Z_STREAM_ERROR$1; }\n  const state = strm.state;\n  state.wsize = 0;\n  state.whave = 0;\n  state.wnext = 0;\n  return inflateResetKeep(strm);\n\n};\n\n\nconst inflateReset2 = (strm, windowBits) => {\n  let wrap;\n\n  /* get the state */\n  if (inflateStateCheck(strm)) { return Z_STREAM_ERROR$1; }\n  const state = strm.state;\n\n  /* extract wrap request from windowBits parameter */\n  if (windowBits < 0) {\n    wrap = 0;\n    windowBits = -windowBits;\n  }\n  else {\n    wrap = (windowBits >> 4) + 5;\n    if (windowBits < 48) {\n      windowBits &= 15;\n    }\n  }\n\n  /* set number of window bits, free window if different */\n  if (windowBits && (windowBits < 8 || windowBits > 15)) {\n    return Z_STREAM_ERROR$1;\n  }\n  if (state.window !== null && state.wbits !== windowBits) {\n    state.window = null;\n  }\n\n  /* update state and reset the rest of it */\n  state.wrap = wrap;\n  state.wbits = windowBits;\n  return inflateReset(strm);\n};\n\n\nconst inflateInit2 = (strm, windowBits) => {\n\n  if (!strm) { return Z_STREAM_ERROR$1; }\n  //strm.msg = Z_NULL;                 /* in case we return an error */\n\n  const state = new InflateState();\n\n  //if (state === Z_NULL) return Z_MEM_ERROR;\n  //Tracev((stderr, \"inflate: allocated\\n\"));\n  strm.state = state;\n  state.strm = strm;\n  state.window = null/*Z_NULL*/;\n  state.mode = HEAD;     /* to pass state test in inflateReset2() */\n  const ret = inflateReset2(strm, windowBits);\n  if (ret !== Z_OK$1) {\n    strm.state = null/*Z_NULL*/;\n  }\n  return ret;\n};\n\n\nconst inflateInit = (strm) => {\n\n  return inflateInit2(strm, DEF_WBITS);\n};\n\n\n/*\n Return state with length and distance decoding tables and index sizes set to\n fixed code decoding.  Normally this returns fixed tables from inffixed.h.\n If BUILDFIXED is defined, then instead this routine builds the tables the\n first time it's called, and returns those tables the first time and\n thereafter.  This reduces the size of the code by about 2K bytes, in\n exchange for a little execution time.  However, BUILDFIXED should not be\n used for threaded applications, since the rewriting of the tables and virgin\n may not be thread-safe.\n */\nlet virgin = true;\n\nlet lenfix, distfix; // We have no pointers in JS, so keep tables separate\n\n\nconst fixedtables = (state) => {\n\n  /* build fixed huffman tables if first call (may not be thread safe) */\n  if (virgin) {\n    lenfix = new Int32Array(512);\n    distfix = new Int32Array(32);\n\n    /* literal/length table */\n    let sym = 0;\n    while (sym < 144) { state.lens[sym++] = 8; }\n    while (sym < 256) { state.lens[sym++] = 9; }\n    while (sym < 280) { state.lens[sym++] = 7; }\n    while (sym < 288) { state.lens[sym++] = 8; }\n\n    inftrees(LENS,  state.lens, 0, 288, lenfix,   0, state.work, { bits: 9 });\n\n    /* distance table */\n    sym = 0;\n    while (sym < 32) { state.lens[sym++] = 5; }\n\n    inftrees(DISTS, state.lens, 0, 32,   distfix, 0, state.work, { bits: 5 });\n\n    /* do this just once */\n    virgin = false;\n  }\n\n  state.lencode = lenfix;\n  state.lenbits = 9;\n  state.distcode = distfix;\n  state.distbits = 5;\n};\n\n\n/*\n Update the window with the last wsize (normally 32K) bytes written before\n returning.  If window does not exist yet, create it.  This is only called\n when a window is already in use, or when output has been written during this\n inflate call, but the end of the deflate stream has not been reached yet.\n It is also called to create a window for dictionary data when a dictionary\n is loaded.\n\n Providing output buffers larger than 32K to inflate() should provide a speed\n advantage, since only the last 32K of output is copied to the sliding window\n upon return from inflate(), and since all distances after the first 32K of\n output will fall in the output data, making match copies simpler and faster.\n The advantage may be dependent on the size of the processor's data caches.\n */\nconst updatewindow = (strm, src, end, copy) => {\n\n  let dist;\n  const state = strm.state;\n\n  /* if it hasn't been done already, allocate space for the window */\n  if (state.window === null) {\n    state.wsize = 1 << state.wbits;\n    state.wnext = 0;\n    state.whave = 0;\n\n    state.window = new Uint8Array(state.wsize);\n  }\n\n  /* copy state->wsize or less output bytes into the circular window */\n  if (copy >= state.wsize) {\n    state.window.set(src.subarray(end - state.wsize, end), 0);\n    state.wnext = 0;\n    state.whave = state.wsize;\n  }\n  else {\n    dist = state.wsize - state.wnext;\n    if (dist > copy) {\n      dist = copy;\n    }\n    //zmemcpy(state->window + state->wnext, end - copy, dist);\n    state.window.set(src.subarray(end - copy, end - copy + dist), state.wnext);\n    copy -= dist;\n    if (copy) {\n      //zmemcpy(state->window, end - copy, copy);\n      state.window.set(src.subarray(end - copy, end), 0);\n      state.wnext = copy;\n      state.whave = state.wsize;\n    }\n    else {\n      state.wnext += dist;\n      if (state.wnext === state.wsize) { state.wnext = 0; }\n      if (state.whave < state.wsize) { state.whave += dist; }\n    }\n  }\n  return 0;\n};\n\n\nconst inflate$2 = (strm, flush) => {\n\n  let state;\n  let input, output;          // input/output buffers\n  let next;                   /* next input INDEX */\n  let put;                    /* next output INDEX */\n  let have, left;             /* available input and output */\n  let hold;                   /* bit buffer */\n  let bits;                   /* bits in bit buffer */\n  let _in, _out;              /* save starting available input and output */\n  let copy;                   /* number of stored or match bytes to copy */\n  let from;                   /* where to copy match bytes from */\n  let from_source;\n  let here = 0;               /* current decoding table entry */\n  let here_bits, here_op, here_val; // paked \"here\" denormalized (JS specific)\n  //let last;                   /* parent table entry */\n  let last_bits, last_op, last_val; // paked \"last\" denormalized (JS specific)\n  let len;                    /* length to copy for repeats, bits to drop */\n  let ret;                    /* return code */\n  const hbuf = new Uint8Array(4);    /* buffer for gzip header crc calculation */\n  let opts;\n\n  let n; // temporary variable for NEED_BITS\n\n  const order = /* permutation of code lengths */\n    new Uint8Array([ 16, 17, 18, 0, 8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15 ]);\n\n\n  if (inflateStateCheck(strm) || !strm.output ||\n      (!strm.input && strm.avail_in !== 0)) {\n    return Z_STREAM_ERROR$1;\n  }\n\n  state = strm.state;\n  if (state.mode === TYPE) { state.mode = TYPEDO; }    /* skip check */\n\n\n  //--- LOAD() ---\n  put = strm.next_out;\n  output = strm.output;\n  left = strm.avail_out;\n  next = strm.next_in;\n  input = strm.input;\n  have = strm.avail_in;\n  hold = state.hold;\n  bits = state.bits;\n  //---\n\n  _in = have;\n  _out = left;\n  ret = Z_OK$1;\n\n  inf_leave: // goto emulation\n  for (;;) {\n    switch (state.mode) {\n      case HEAD:\n        if (state.wrap === 0) {\n          state.mode = TYPEDO;\n          break;\n        }\n        //=== NEEDBITS(16);\n        while (bits < 16) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        if ((state.wrap & 2) && hold === 0x8b1f) {  /* gzip header */\n          if (state.wbits === 0) {\n            state.wbits = 15;\n          }\n          state.check = 0/*crc32(0L, Z_NULL, 0)*/;\n          //=== CRC2(state.check, hold);\n          hbuf[0] = hold & 0xff;\n          hbuf[1] = (hold >>> 8) & 0xff;\n          state.check = crc32_1(state.check, hbuf, 2, 0);\n          //===//\n\n          //=== INITBITS();\n          hold = 0;\n          bits = 0;\n          //===//\n          state.mode = FLAGS;\n          break;\n        }\n        if (state.head) {\n          state.head.done = false;\n        }\n        if (!(state.wrap & 1) ||   /* check if zlib header allowed */\n          (((hold & 0xff)/*BITS(8)*/ << 8) + (hold >> 8)) % 31) {\n          strm.msg = 'incorrect header check';\n          state.mode = BAD;\n          break;\n        }\n        if ((hold & 0x0f)/*BITS(4)*/ !== Z_DEFLATED) {\n          strm.msg = 'unknown compression method';\n          state.mode = BAD;\n          break;\n        }\n        //--- DROPBITS(4) ---//\n        hold >>>= 4;\n        bits -= 4;\n        //---//\n        len = (hold & 0x0f)/*BITS(4)*/ + 8;\n        if (state.wbits === 0) {\n          state.wbits = len;\n        }\n        if (len > 15 || len > state.wbits) {\n          strm.msg = 'invalid window size';\n          state.mode = BAD;\n          break;\n        }\n\n        // !!! pako patch. Force use `options.windowBits` if passed.\n        // Required to always use max window size by default.\n        state.dmax = 1 << state.wbits;\n        //state.dmax = 1 << len;\n\n        state.flags = 0;               /* indicate zlib header */\n        //Tracev((stderr, \"inflate:   zlib header ok\\n\"));\n        strm.adler = state.check = 1/*adler32(0L, Z_NULL, 0)*/;\n        state.mode = hold & 0x200 ? DICTID : TYPE;\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        break;\n      case FLAGS:\n        //=== NEEDBITS(16); */\n        while (bits < 16) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        state.flags = hold;\n        if ((state.flags & 0xff) !== Z_DEFLATED) {\n          strm.msg = 'unknown compression method';\n          state.mode = BAD;\n          break;\n        }\n        if (state.flags & 0xe000) {\n          strm.msg = 'unknown header flags set';\n          state.mode = BAD;\n          break;\n        }\n        if (state.head) {\n          state.head.text = ((hold >> 8) & 1);\n        }\n        if ((state.flags & 0x0200) && (state.wrap & 4)) {\n          //=== CRC2(state.check, hold);\n          hbuf[0] = hold & 0xff;\n          hbuf[1] = (hold >>> 8) & 0xff;\n          state.check = crc32_1(state.check, hbuf, 2, 0);\n          //===//\n        }\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        state.mode = TIME;\n        /* falls through */\n      case TIME:\n        //=== NEEDBITS(32); */\n        while (bits < 32) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        if (state.head) {\n          state.head.time = hold;\n        }\n        if ((state.flags & 0x0200) && (state.wrap & 4)) {\n          //=== CRC4(state.check, hold)\n          hbuf[0] = hold & 0xff;\n          hbuf[1] = (hold >>> 8) & 0xff;\n          hbuf[2] = (hold >>> 16) & 0xff;\n          hbuf[3] = (hold >>> 24) & 0xff;\n          state.check = crc32_1(state.check, hbuf, 4, 0);\n          //===\n        }\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        state.mode = OS;\n        /* falls through */\n      case OS:\n        //=== NEEDBITS(16); */\n        while (bits < 16) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        if (state.head) {\n          state.head.xflags = (hold & 0xff);\n          state.head.os = (hold >> 8);\n        }\n        if ((state.flags & 0x0200) && (state.wrap & 4)) {\n          //=== CRC2(state.check, hold);\n          hbuf[0] = hold & 0xff;\n          hbuf[1] = (hold >>> 8) & 0xff;\n          state.check = crc32_1(state.check, hbuf, 2, 0);\n          //===//\n        }\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        state.mode = EXLEN;\n        /* falls through */\n      case EXLEN:\n        if (state.flags & 0x0400) {\n          //=== NEEDBITS(16); */\n          while (bits < 16) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          state.length = hold;\n          if (state.head) {\n            state.head.extra_len = hold;\n          }\n          if ((state.flags & 0x0200) && (state.wrap & 4)) {\n            //=== CRC2(state.check, hold);\n            hbuf[0] = hold & 0xff;\n            hbuf[1] = (hold >>> 8) & 0xff;\n            state.check = crc32_1(state.check, hbuf, 2, 0);\n            //===//\n          }\n          //=== INITBITS();\n          hold = 0;\n          bits = 0;\n          //===//\n        }\n        else if (state.head) {\n          state.head.extra = null/*Z_NULL*/;\n        }\n        state.mode = EXTRA;\n        /* falls through */\n      case EXTRA:\n        if (state.flags & 0x0400) {\n          copy = state.length;\n          if (copy > have) { copy = have; }\n          if (copy) {\n            if (state.head) {\n              len = state.head.extra_len - state.length;\n              if (!state.head.extra) {\n                // Use untyped array for more convenient processing later\n                state.head.extra = new Uint8Array(state.head.extra_len);\n              }\n              state.head.extra.set(\n                input.subarray(\n                  next,\n                  // extra field is limited to 65536 bytes\n                  // - no need for additional size check\n                  next + copy\n                ),\n                /*len + copy > state.head.extra_max - len ? state.head.extra_max : copy,*/\n                len\n              );\n              //zmemcpy(state.head.extra + len, next,\n              //        len + copy > state.head.extra_max ?\n              //        state.head.extra_max - len : copy);\n            }\n            if ((state.flags & 0x0200) && (state.wrap & 4)) {\n              state.check = crc32_1(state.check, input, copy, next);\n            }\n            have -= copy;\n            next += copy;\n            state.length -= copy;\n          }\n          if (state.length) { break inf_leave; }\n        }\n        state.length = 0;\n        state.mode = NAME;\n        /* falls through */\n      case NAME:\n        if (state.flags & 0x0800) {\n          if (have === 0) { break inf_leave; }\n          copy = 0;\n          do {\n            // TODO: 2 or 1 bytes?\n            len = input[next + copy++];\n            /* use constant limit because in js we should not preallocate memory */\n            if (state.head && len &&\n                (state.length < 65536 /*state.head.name_max*/)) {\n              state.head.name += String.fromCharCode(len);\n            }\n          } while (len && copy < have);\n\n          if ((state.flags & 0x0200) && (state.wrap & 4)) {\n            state.check = crc32_1(state.check, input, copy, next);\n          }\n          have -= copy;\n          next += copy;\n          if (len) { break inf_leave; }\n        }\n        else if (state.head) {\n          state.head.name = null;\n        }\n        state.length = 0;\n        state.mode = COMMENT;\n        /* falls through */\n      case COMMENT:\n        if (state.flags & 0x1000) {\n          if (have === 0) { break inf_leave; }\n          copy = 0;\n          do {\n            len = input[next + copy++];\n            /* use constant limit because in js we should not preallocate memory */\n            if (state.head && len &&\n                (state.length < 65536 /*state.head.comm_max*/)) {\n              state.head.comment += String.fromCharCode(len);\n            }\n          } while (len && copy < have);\n          if ((state.flags & 0x0200) && (state.wrap & 4)) {\n            state.check = crc32_1(state.check, input, copy, next);\n          }\n          have -= copy;\n          next += copy;\n          if (len) { break inf_leave; }\n        }\n        else if (state.head) {\n          state.head.comment = null;\n        }\n        state.mode = HCRC;\n        /* falls through */\n      case HCRC:\n        if (state.flags & 0x0200) {\n          //=== NEEDBITS(16); */\n          while (bits < 16) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          if ((state.wrap & 4) && hold !== (state.check & 0xffff)) {\n            strm.msg = 'header crc mismatch';\n            state.mode = BAD;\n            break;\n          }\n          //=== INITBITS();\n          hold = 0;\n          bits = 0;\n          //===//\n        }\n        if (state.head) {\n          state.head.hcrc = ((state.flags >> 9) & 1);\n          state.head.done = true;\n        }\n        strm.adler = state.check = 0;\n        state.mode = TYPE;\n        break;\n      case DICTID:\n        //=== NEEDBITS(32); */\n        while (bits < 32) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        strm.adler = state.check = zswap32(hold);\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        state.mode = DICT;\n        /* falls through */\n      case DICT:\n        if (state.havedict === 0) {\n          //--- RESTORE() ---\n          strm.next_out = put;\n          strm.avail_out = left;\n          strm.next_in = next;\n          strm.avail_in = have;\n          state.hold = hold;\n          state.bits = bits;\n          //---\n          return Z_NEED_DICT$1;\n        }\n        strm.adler = state.check = 1/*adler32(0L, Z_NULL, 0)*/;\n        state.mode = TYPE;\n        /* falls through */\n      case TYPE:\n        if (flush === Z_BLOCK || flush === Z_TREES) { break inf_leave; }\n        /* falls through */\n      case TYPEDO:\n        if (state.last) {\n          //--- BYTEBITS() ---//\n          hold >>>= bits & 7;\n          bits -= bits & 7;\n          //---//\n          state.mode = CHECK;\n          break;\n        }\n        //=== NEEDBITS(3); */\n        while (bits < 3) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        state.last = (hold & 0x01)/*BITS(1)*/;\n        //--- DROPBITS(1) ---//\n        hold >>>= 1;\n        bits -= 1;\n        //---//\n\n        switch ((hold & 0x03)/*BITS(2)*/) {\n          case 0:                             /* stored block */\n            //Tracev((stderr, \"inflate:     stored block%s\\n\",\n            //        state.last ? \" (last)\" : \"\"));\n            state.mode = STORED;\n            break;\n          case 1:                             /* fixed block */\n            fixedtables(state);\n            //Tracev((stderr, \"inflate:     fixed codes block%s\\n\",\n            //        state.last ? \" (last)\" : \"\"));\n            state.mode = LEN_;             /* decode codes */\n            if (flush === Z_TREES) {\n              //--- DROPBITS(2) ---//\n              hold >>>= 2;\n              bits -= 2;\n              //---//\n              break inf_leave;\n            }\n            break;\n          case 2:                             /* dynamic block */\n            //Tracev((stderr, \"inflate:     dynamic codes block%s\\n\",\n            //        state.last ? \" (last)\" : \"\"));\n            state.mode = TABLE;\n            break;\n          case 3:\n            strm.msg = 'invalid block type';\n            state.mode = BAD;\n        }\n        //--- DROPBITS(2) ---//\n        hold >>>= 2;\n        bits -= 2;\n        //---//\n        break;\n      case STORED:\n        //--- BYTEBITS() ---// /* go to byte boundary */\n        hold >>>= bits & 7;\n        bits -= bits & 7;\n        //---//\n        //=== NEEDBITS(32); */\n        while (bits < 32) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        if ((hold & 0xffff) !== ((hold >>> 16) ^ 0xffff)) {\n          strm.msg = 'invalid stored block lengths';\n          state.mode = BAD;\n          break;\n        }\n        state.length = hold & 0xffff;\n        //Tracev((stderr, \"inflate:       stored length %u\\n\",\n        //        state.length));\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        state.mode = COPY_;\n        if (flush === Z_TREES) { break inf_leave; }\n        /* falls through */\n      case COPY_:\n        state.mode = COPY;\n        /* falls through */\n      case COPY:\n        copy = state.length;\n        if (copy) {\n          if (copy > have) { copy = have; }\n          if (copy > left) { copy = left; }\n          if (copy === 0) { break inf_leave; }\n          //--- zmemcpy(put, next, copy); ---\n          output.set(input.subarray(next, next + copy), put);\n          //---//\n          have -= copy;\n          next += copy;\n          left -= copy;\n          put += copy;\n          state.length -= copy;\n          break;\n        }\n        //Tracev((stderr, \"inflate:       stored end\\n\"));\n        state.mode = TYPE;\n        break;\n      case TABLE:\n        //=== NEEDBITS(14); */\n        while (bits < 14) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        state.nlen = (hold & 0x1f)/*BITS(5)*/ + 257;\n        //--- DROPBITS(5) ---//\n        hold >>>= 5;\n        bits -= 5;\n        //---//\n        state.ndist = (hold & 0x1f)/*BITS(5)*/ + 1;\n        //--- DROPBITS(5) ---//\n        hold >>>= 5;\n        bits -= 5;\n        //---//\n        state.ncode = (hold & 0x0f)/*BITS(4)*/ + 4;\n        //--- DROPBITS(4) ---//\n        hold >>>= 4;\n        bits -= 4;\n        //---//\n//#ifndef PKZIP_BUG_WORKAROUND\n        if (state.nlen > 286 || state.ndist > 30) {\n          strm.msg = 'too many length or distance symbols';\n          state.mode = BAD;\n          break;\n        }\n//#endif\n        //Tracev((stderr, \"inflate:       table sizes ok\\n\"));\n        state.have = 0;\n        state.mode = LENLENS;\n        /* falls through */\n      case LENLENS:\n        while (state.have < state.ncode) {\n          //=== NEEDBITS(3);\n          while (bits < 3) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          state.lens[order[state.have++]] = (hold & 0x07);//BITS(3);\n          //--- DROPBITS(3) ---//\n          hold >>>= 3;\n          bits -= 3;\n          //---//\n        }\n        while (state.have < 19) {\n          state.lens[order[state.have++]] = 0;\n        }\n        // We have separate tables & no pointers. 2 commented lines below not needed.\n        //state.next = state.codes;\n        //state.lencode = state.next;\n        // Switch to use dynamic table\n        state.lencode = state.lendyn;\n        state.lenbits = 7;\n\n        opts = { bits: state.lenbits };\n        ret = inftrees(CODES, state.lens, 0, 19, state.lencode, 0, state.work, opts);\n        state.lenbits = opts.bits;\n\n        if (ret) {\n          strm.msg = 'invalid code lengths set';\n          state.mode = BAD;\n          break;\n        }\n        //Tracev((stderr, \"inflate:       code lengths ok\\n\"));\n        state.have = 0;\n        state.mode = CODELENS;\n        /* falls through */\n      case CODELENS:\n        while (state.have < state.nlen + state.ndist) {\n          for (;;) {\n            here = state.lencode[hold & ((1 << state.lenbits) - 1)];/*BITS(state.lenbits)*/\n            here_bits = here >>> 24;\n            here_op = (here >>> 16) & 0xff;\n            here_val = here & 0xffff;\n\n            if ((here_bits) <= bits) { break; }\n            //--- PULLBYTE() ---//\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n            //---//\n          }\n          if (here_val < 16) {\n            //--- DROPBITS(here.bits) ---//\n            hold >>>= here_bits;\n            bits -= here_bits;\n            //---//\n            state.lens[state.have++] = here_val;\n          }\n          else {\n            if (here_val === 16) {\n              //=== NEEDBITS(here.bits + 2);\n              n = here_bits + 2;\n              while (bits < n) {\n                if (have === 0) { break inf_leave; }\n                have--;\n                hold += input[next++] << bits;\n                bits += 8;\n              }\n              //===//\n              //--- DROPBITS(here.bits) ---//\n              hold >>>= here_bits;\n              bits -= here_bits;\n              //---//\n              if (state.have === 0) {\n                strm.msg = 'invalid bit length repeat';\n                state.mode = BAD;\n                break;\n              }\n              len = state.lens[state.have - 1];\n              copy = 3 + (hold & 0x03);//BITS(2);\n              //--- DROPBITS(2) ---//\n              hold >>>= 2;\n              bits -= 2;\n              //---//\n            }\n            else if (here_val === 17) {\n              //=== NEEDBITS(here.bits + 3);\n              n = here_bits + 3;\n              while (bits < n) {\n                if (have === 0) { break inf_leave; }\n                have--;\n                hold += input[next++] << bits;\n                bits += 8;\n              }\n              //===//\n              //--- DROPBITS(here.bits) ---//\n              hold >>>= here_bits;\n              bits -= here_bits;\n              //---//\n              len = 0;\n              copy = 3 + (hold & 0x07);//BITS(3);\n              //--- DROPBITS(3) ---//\n              hold >>>= 3;\n              bits -= 3;\n              //---//\n            }\n            else {\n              //=== NEEDBITS(here.bits + 7);\n              n = here_bits + 7;\n              while (bits < n) {\n                if (have === 0) { break inf_leave; }\n                have--;\n                hold += input[next++] << bits;\n                bits += 8;\n              }\n              //===//\n              //--- DROPBITS(here.bits) ---//\n              hold >>>= here_bits;\n              bits -= here_bits;\n              //---//\n              len = 0;\n              copy = 11 + (hold & 0x7f);//BITS(7);\n              //--- DROPBITS(7) ---//\n              hold >>>= 7;\n              bits -= 7;\n              //---//\n            }\n            if (state.have + copy > state.nlen + state.ndist) {\n              strm.msg = 'invalid bit length repeat';\n              state.mode = BAD;\n              break;\n            }\n            while (copy--) {\n              state.lens[state.have++] = len;\n            }\n          }\n        }\n\n        /* handle error breaks in while */\n        if (state.mode === BAD) { break; }\n\n        /* check for end-of-block code (better have one) */\n        if (state.lens[256] === 0) {\n          strm.msg = 'invalid code -- missing end-of-block';\n          state.mode = BAD;\n          break;\n        }\n\n        /* build code tables -- note: do not change the lenbits or distbits\n           values here (9 and 6) without reading the comments in inftrees.h\n           concerning the ENOUGH constants, which depend on those values */\n        state.lenbits = 9;\n\n        opts = { bits: state.lenbits };\n        ret = inftrees(LENS, state.lens, 0, state.nlen, state.lencode, 0, state.work, opts);\n        // We have separate tables & no pointers. 2 commented lines below not needed.\n        // state.next_index = opts.table_index;\n        state.lenbits = opts.bits;\n        // state.lencode = state.next;\n\n        if (ret) {\n          strm.msg = 'invalid literal/lengths set';\n          state.mode = BAD;\n          break;\n        }\n\n        state.distbits = 6;\n        //state.distcode.copy(state.codes);\n        // Switch to use dynamic table\n        state.distcode = state.distdyn;\n        opts = { bits: state.distbits };\n        ret = inftrees(DISTS, state.lens, state.nlen, state.ndist, state.distcode, 0, state.work, opts);\n        // We have separate tables & no pointers. 2 commented lines below not needed.\n        // state.next_index = opts.table_index;\n        state.distbits = opts.bits;\n        // state.distcode = state.next;\n\n        if (ret) {\n          strm.msg = 'invalid distances set';\n          state.mode = BAD;\n          break;\n        }\n        //Tracev((stderr, 'inflate:       codes ok\\n'));\n        state.mode = LEN_;\n        if (flush === Z_TREES) { break inf_leave; }\n        /* falls through */\n      case LEN_:\n        state.mode = LEN;\n        /* falls through */\n      case LEN:\n        if (have >= 6 && left >= 258) {\n          //--- RESTORE() ---\n          strm.next_out = put;\n          strm.avail_out = left;\n          strm.next_in = next;\n          strm.avail_in = have;\n          state.hold = hold;\n          state.bits = bits;\n          //---\n          inffast(strm, _out);\n          //--- LOAD() ---\n          put = strm.next_out;\n          output = strm.output;\n          left = strm.avail_out;\n          next = strm.next_in;\n          input = strm.input;\n          have = strm.avail_in;\n          hold = state.hold;\n          bits = state.bits;\n          //---\n\n          if (state.mode === TYPE) {\n            state.back = -1;\n          }\n          break;\n        }\n        state.back = 0;\n        for (;;) {\n          here = state.lencode[hold & ((1 << state.lenbits) - 1)];  /*BITS(state.lenbits)*/\n          here_bits = here >>> 24;\n          here_op = (here >>> 16) & 0xff;\n          here_val = here & 0xffff;\n\n          if (here_bits <= bits) { break; }\n          //--- PULLBYTE() ---//\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n          //---//\n        }\n        if (here_op && (here_op & 0xf0) === 0) {\n          last_bits = here_bits;\n          last_op = here_op;\n          last_val = here_val;\n          for (;;) {\n            here = state.lencode[last_val +\n                    ((hold & ((1 << (last_bits + last_op)) - 1))/*BITS(last.bits + last.op)*/ >> last_bits)];\n            here_bits = here >>> 24;\n            here_op = (here >>> 16) & 0xff;\n            here_val = here & 0xffff;\n\n            if ((last_bits + here_bits) <= bits) { break; }\n            //--- PULLBYTE() ---//\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n            //---//\n          }\n          //--- DROPBITS(last.bits) ---//\n          hold >>>= last_bits;\n          bits -= last_bits;\n          //---//\n          state.back += last_bits;\n        }\n        //--- DROPBITS(here.bits) ---//\n        hold >>>= here_bits;\n        bits -= here_bits;\n        //---//\n        state.back += here_bits;\n        state.length = here_val;\n        if (here_op === 0) {\n          //Tracevv((stderr, here.val >= 0x20 && here.val < 0x7f ?\n          //        \"inflate:         literal '%c'\\n\" :\n          //        \"inflate:         literal 0x%02x\\n\", here.val));\n          state.mode = LIT;\n          break;\n        }\n        if (here_op & 32) {\n          //Tracevv((stderr, \"inflate:         end of block\\n\"));\n          state.back = -1;\n          state.mode = TYPE;\n          break;\n        }\n        if (here_op & 64) {\n          strm.msg = 'invalid literal/length code';\n          state.mode = BAD;\n          break;\n        }\n        state.extra = here_op & 15;\n        state.mode = LENEXT;\n        /* falls through */\n      case LENEXT:\n        if (state.extra) {\n          //=== NEEDBITS(state.extra);\n          n = state.extra;\n          while (bits < n) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          state.length += hold & ((1 << state.extra) - 1)/*BITS(state.extra)*/;\n          //--- DROPBITS(state.extra) ---//\n          hold >>>= state.extra;\n          bits -= state.extra;\n          //---//\n          state.back += state.extra;\n        }\n        //Tracevv((stderr, \"inflate:         length %u\\n\", state.length));\n        state.was = state.length;\n        state.mode = DIST;\n        /* falls through */\n      case DIST:\n        for (;;) {\n          here = state.distcode[hold & ((1 << state.distbits) - 1)];/*BITS(state.distbits)*/\n          here_bits = here >>> 24;\n          here_op = (here >>> 16) & 0xff;\n          here_val = here & 0xffff;\n\n          if ((here_bits) <= bits) { break; }\n          //--- PULLBYTE() ---//\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n          //---//\n        }\n        if ((here_op & 0xf0) === 0) {\n          last_bits = here_bits;\n          last_op = here_op;\n          last_val = here_val;\n          for (;;) {\n            here = state.distcode[last_val +\n                    ((hold & ((1 << (last_bits + last_op)) - 1))/*BITS(last.bits + last.op)*/ >> last_bits)];\n            here_bits = here >>> 24;\n            here_op = (here >>> 16) & 0xff;\n            here_val = here & 0xffff;\n\n            if ((last_bits + here_bits) <= bits) { break; }\n            //--- PULLBYTE() ---//\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n            //---//\n          }\n          //--- DROPBITS(last.bits) ---//\n          hold >>>= last_bits;\n          bits -= last_bits;\n          //---//\n          state.back += last_bits;\n        }\n        //--- DROPBITS(here.bits) ---//\n        hold >>>= here_bits;\n        bits -= here_bits;\n        //---//\n        state.back += here_bits;\n        if (here_op & 64) {\n          strm.msg = 'invalid distance code';\n          state.mode = BAD;\n          break;\n        }\n        state.offset = here_val;\n        state.extra = (here_op) & 15;\n        state.mode = DISTEXT;\n        /* falls through */\n      case DISTEXT:\n        if (state.extra) {\n          //=== NEEDBITS(state.extra);\n          n = state.extra;\n          while (bits < n) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          state.offset += hold & ((1 << state.extra) - 1)/*BITS(state.extra)*/;\n          //--- DROPBITS(state.extra) ---//\n          hold >>>= state.extra;\n          bits -= state.extra;\n          //---//\n          state.back += state.extra;\n        }\n//#ifdef INFLATE_STRICT\n        if (state.offset > state.dmax) {\n          strm.msg = 'invalid distance too far back';\n          state.mode = BAD;\n          break;\n        }\n//#endif\n        //Tracevv((stderr, \"inflate:         distance %u\\n\", state.offset));\n        state.mode = MATCH;\n        /* falls through */\n      case MATCH:\n        if (left === 0) { break inf_leave; }\n        copy = _out - left;\n        if (state.offset > copy) {         /* copy from window */\n          copy = state.offset - copy;\n          if (copy > state.whave) {\n            if (state.sane) {\n              strm.msg = 'invalid distance too far back';\n              state.mode = BAD;\n              break;\n            }\n// (!) This block is disabled in zlib defaults,\n// don't enable it for binary compatibility\n//#ifdef INFLATE_ALLOW_INVALID_DISTANCE_TOOFAR_ARRR\n//          Trace((stderr, \"inflate.c too far\\n\"));\n//          copy -= state.whave;\n//          if (copy > state.length) { copy = state.length; }\n//          if (copy > left) { copy = left; }\n//          left -= copy;\n//          state.length -= copy;\n//          do {\n//            output[put++] = 0;\n//          } while (--copy);\n//          if (state.length === 0) { state.mode = LEN; }\n//          break;\n//#endif\n          }\n          if (copy > state.wnext) {\n            copy -= state.wnext;\n            from = state.wsize - copy;\n          }\n          else {\n            from = state.wnext - copy;\n          }\n          if (copy > state.length) { copy = state.length; }\n          from_source = state.window;\n        }\n        else {                              /* copy from output */\n          from_source = output;\n          from = put - state.offset;\n          copy = state.length;\n        }\n        if (copy > left) { copy = left; }\n        left -= copy;\n        state.length -= copy;\n        do {\n          output[put++] = from_source[from++];\n        } while (--copy);\n        if (state.length === 0) { state.mode = LEN; }\n        break;\n      case LIT:\n        if (left === 0) { break inf_leave; }\n        output[put++] = state.length;\n        left--;\n        state.mode = LEN;\n        break;\n      case CHECK:\n        if (state.wrap) {\n          //=== NEEDBITS(32);\n          while (bits < 32) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            // Use '|' instead of '+' to make sure that result is signed\n            hold |= input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          _out -= left;\n          strm.total_out += _out;\n          state.total += _out;\n          if ((state.wrap & 4) && _out) {\n            strm.adler = state.check =\n                /*UPDATE_CHECK(state.check, put - _out, _out);*/\n                (state.flags ? crc32_1(state.check, output, _out, put - _out) : adler32_1(state.check, output, _out, put - _out));\n\n          }\n          _out = left;\n          // NB: crc32 stored as signed 32-bit int, zswap32 returns signed too\n          if ((state.wrap & 4) && (state.flags ? hold : zswap32(hold)) !== state.check) {\n            strm.msg = 'incorrect data check';\n            state.mode = BAD;\n            break;\n          }\n          //=== INITBITS();\n          hold = 0;\n          bits = 0;\n          //===//\n          //Tracev((stderr, \"inflate:   check matches trailer\\n\"));\n        }\n        state.mode = LENGTH;\n        /* falls through */\n      case LENGTH:\n        if (state.wrap && state.flags) {\n          //=== NEEDBITS(32);\n          while (bits < 32) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          if ((state.wrap & 4) && hold !== (state.total & 0xffffffff)) {\n            strm.msg = 'incorrect length check';\n            state.mode = BAD;\n            break;\n          }\n          //=== INITBITS();\n          hold = 0;\n          bits = 0;\n          //===//\n          //Tracev((stderr, \"inflate:   length matches trailer\\n\"));\n        }\n        state.mode = DONE;\n        /* falls through */\n      case DONE:\n        ret = Z_STREAM_END$1;\n        break inf_leave;\n      case BAD:\n        ret = Z_DATA_ERROR$1;\n        break inf_leave;\n      case MEM:\n        return Z_MEM_ERROR$1;\n      case SYNC:\n        /* falls through */\n      default:\n        return Z_STREAM_ERROR$1;\n    }\n  }\n\n  // inf_leave <- here is real place for \"goto inf_leave\", emulated via \"break inf_leave\"\n\n  /*\n     Return from inflate(), updating the total counts and the check value.\n     If there was no progress during the inflate() call, return a buffer\n     error.  Call updatewindow() to create and/or update the window state.\n     Note: a memory error from inflate() is non-recoverable.\n   */\n\n  //--- RESTORE() ---\n  strm.next_out = put;\n  strm.avail_out = left;\n  strm.next_in = next;\n  strm.avail_in = have;\n  state.hold = hold;\n  state.bits = bits;\n  //---\n\n  if (state.wsize || (_out !== strm.avail_out && state.mode < BAD &&\n                      (state.mode < CHECK || flush !== Z_FINISH$1))) {\n    if (updatewindow(strm, strm.output, strm.next_out, _out - strm.avail_out)) ;\n  }\n  _in -= strm.avail_in;\n  _out -= strm.avail_out;\n  strm.total_in += _in;\n  strm.total_out += _out;\n  state.total += _out;\n  if ((state.wrap & 4) && _out) {\n    strm.adler = state.check = /*UPDATE_CHECK(state.check, strm.next_out - _out, _out);*/\n      (state.flags ? crc32_1(state.check, output, _out, strm.next_out - _out) : adler32_1(state.check, output, _out, strm.next_out - _out));\n  }\n  strm.data_type = state.bits + (state.last ? 64 : 0) +\n                    (state.mode === TYPE ? 128 : 0) +\n                    (state.mode === LEN_ || state.mode === COPY_ ? 256 : 0);\n  if (((_in === 0 && _out === 0) || flush === Z_FINISH$1) && ret === Z_OK$1) {\n    ret = Z_BUF_ERROR;\n  }\n  return ret;\n};\n\n\nconst inflateEnd = (strm) => {\n\n  if (inflateStateCheck(strm)) {\n    return Z_STREAM_ERROR$1;\n  }\n\n  let state = strm.state;\n  if (state.window) {\n    state.window = null;\n  }\n  strm.state = null;\n  return Z_OK$1;\n};\n\n\nconst inflateGetHeader = (strm, head) => {\n\n  /* check state */\n  if (inflateStateCheck(strm)) { return Z_STREAM_ERROR$1; }\n  const state = strm.state;\n  if ((state.wrap & 2) === 0) { return Z_STREAM_ERROR$1; }\n\n  /* save header structure */\n  state.head = head;\n  head.done = false;\n  return Z_OK$1;\n};\n\n\nconst inflateSetDictionary = (strm, dictionary) => {\n  const dictLength = dictionary.length;\n\n  let state;\n  let dictid;\n  let ret;\n\n  /* check state */\n  if (inflateStateCheck(strm)) { return Z_STREAM_ERROR$1; }\n  state = strm.state;\n\n  if (state.wrap !== 0 && state.mode !== DICT) {\n    return Z_STREAM_ERROR$1;\n  }\n\n  /* check for correct dictionary identifier */\n  if (state.mode === DICT) {\n    dictid = 1; /* adler32(0, null, 0)*/\n    /* dictid = adler32(dictid, dictionary, dictLength); */\n    dictid = adler32_1(dictid, dictionary, dictLength, 0);\n    if (dictid !== state.check) {\n      return Z_DATA_ERROR$1;\n    }\n  }\n  /* copy dictionary to window using updatewindow(), which will amend the\n   existing dictionary if appropriate */\n  ret = updatewindow(strm, dictionary, dictLength, dictLength);\n  if (ret) {\n    state.mode = MEM;\n    return Z_MEM_ERROR$1;\n  }\n  state.havedict = 1;\n  // Tracev((stderr, \"inflate:   dictionary set\\n\"));\n  return Z_OK$1;\n};\n\n\nvar inflateReset_1 = inflateReset;\nvar inflateReset2_1 = inflateReset2;\nvar inflateResetKeep_1 = inflateResetKeep;\nvar inflateInit_1 = inflateInit;\nvar inflateInit2_1 = inflateInit2;\nvar inflate_2$1 = inflate$2;\nvar inflateEnd_1 = inflateEnd;\nvar inflateGetHeader_1 = inflateGetHeader;\nvar inflateSetDictionary_1 = inflateSetDictionary;\nvar inflateInfo = 'pako inflate (from Nodeca project)';\n\n/* Not implemented\nmodule.exports.inflateCodesUsed = inflateCodesUsed;\nmodule.exports.inflateCopy = inflateCopy;\nmodule.exports.inflateGetDictionary = inflateGetDictionary;\nmodule.exports.inflateMark = inflateMark;\nmodule.exports.inflatePrime = inflatePrime;\nmodule.exports.inflateSync = inflateSync;\nmodule.exports.inflateSyncPoint = inflateSyncPoint;\nmodule.exports.inflateUndermine = inflateUndermine;\nmodule.exports.inflateValidate = inflateValidate;\n*/\n\nvar inflate_1$2 = {\n\tinflateReset: inflateReset_1,\n\tinflateReset2: inflateReset2_1,\n\tinflateResetKeep: inflateResetKeep_1,\n\tinflateInit: inflateInit_1,\n\tinflateInit2: inflateInit2_1,\n\tinflate: inflate_2$1,\n\tinflateEnd: inflateEnd_1,\n\tinflateGetHeader: inflateGetHeader_1,\n\tinflateSetDictionary: inflateSetDictionary_1,\n\tinflateInfo: inflateInfo\n};\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nfunction GZheader() {\n  /* true if compressed data believed to be text */\n  this.text       = 0;\n  /* modification time */\n  this.time       = 0;\n  /* extra flags (not used when writing a gzip file) */\n  this.xflags     = 0;\n  /* operating system */\n  this.os         = 0;\n  /* pointer to extra field or Z_NULL if none */\n  this.extra      = null;\n  /* extra field length (valid if extra != Z_NULL) */\n  this.extra_len  = 0; // Actually, we don't need it in JS,\n                       // but leave for few code modifications\n\n  //\n  // Setup limits is not necessary because in js we should not preallocate memory\n  // for inflate use constant limit in 65536 bytes\n  //\n\n  /* space at extra (only when reading header) */\n  // this.extra_max  = 0;\n  /* pointer to zero-terminated file name or Z_NULL */\n  this.name       = '';\n  /* space at name (only when reading header) */\n  // this.name_max   = 0;\n  /* pointer to zero-terminated comment or Z_NULL */\n  this.comment    = '';\n  /* space at comment (only when reading header) */\n  // this.comm_max   = 0;\n  /* true if there was or will be a header crc */\n  this.hcrc       = 0;\n  /* true when done reading gzip header (not used when writing a gzip file) */\n  this.done       = false;\n}\n\nvar gzheader = GZheader;\n\nconst toString = Object.prototype.toString;\n\n/* Public constants ==========================================================*/\n/* ===========================================================================*/\n\nconst {\n  Z_NO_FLUSH, Z_FINISH,\n  Z_OK, Z_STREAM_END, Z_NEED_DICT, Z_STREAM_ERROR, Z_DATA_ERROR, Z_MEM_ERROR\n} = constants$2;\n\n/* ===========================================================================*/\n\n\n/**\n * class Inflate\n *\n * Generic JS-style wrapper for zlib calls. If you don't need\n * streaming behaviour - use more simple functions: [[inflate]]\n * and [[inflateRaw]].\n **/\n\n/* internal\n * inflate.chunks -> Array\n *\n * Chunks of output data, if [[Inflate#onData]] not overridden.\n **/\n\n/**\n * Inflate.result -> Uint8Array|String\n *\n * Uncompressed result, generated by default [[Inflate#onData]]\n * and [[Inflate#onEnd]] handlers. Filled after you push last chunk\n * (call [[Inflate#push]] with `Z_FINISH` / `true` param).\n **/\n\n/**\n * Inflate.err -> Number\n *\n * Error code after inflate finished. 0 (Z_OK) on success.\n * Should be checked if broken data possible.\n **/\n\n/**\n * Inflate.msg -> String\n *\n * Error message, if [[Inflate.err]] != 0\n **/\n\n\n/**\n * new Inflate(options)\n * - options (Object): zlib inflate options.\n *\n * Creates new inflator instance with specified params. Throws exception\n * on bad params. Supported options:\n *\n * - `windowBits`\n * - `dictionary`\n *\n * [http://zlib.net/manual.html#Advanced](http://zlib.net/manual.html#Advanced)\n * for more information on these.\n *\n * Additional options, for internal needs:\n *\n * - `chunkSize` - size of generated data chunks (16K by default)\n * - `raw` (Boolean) - do raw inflate\n * - `to` (String) - if equal to 'string', then result will be converted\n *   from utf8 to utf16 (javascript) string. When string output requested,\n *   chunk length can differ from `chunkSize`, depending on content.\n *\n * By default, when no options set, autodetect deflate/gzip data format via\n * wrapper header.\n *\n * ##### Example:\n *\n * ```javascript\n * const pako = require('pako')\n * const chunk1 = new Uint8Array([1,2,3,4,5,6,7,8,9])\n * const chunk2 = new Uint8Array([10,11,12,13,14,15,16,17,18,19]);\n *\n * const inflate = new pako.Inflate({ level: 3});\n *\n * inflate.push(chunk1, false);\n * inflate.push(chunk2, true);  // true -> last chunk\n *\n * if (inflate.err) { throw new Error(inflate.err); }\n *\n * console.log(inflate.result);\n * ```\n **/\nfunction Inflate$1(options) {\n  this.options = common.assign({\n    chunkSize: 1024 * 64,\n    windowBits: 15,\n    to: ''\n  }, options || {});\n\n  const opt = this.options;\n\n  // Force window size for `raw` data, if not set directly,\n  // because we have no header for autodetect.\n  if (opt.raw && (opt.windowBits >= 0) && (opt.windowBits < 16)) {\n    opt.windowBits = -opt.windowBits;\n    if (opt.windowBits === 0) { opt.windowBits = -15; }\n  }\n\n  // If `windowBits` not defined (and mode not raw) - set autodetect flag for gzip/deflate\n  if ((opt.windowBits >= 0) && (opt.windowBits < 16) &&\n      !(options && options.windowBits)) {\n    opt.windowBits += 32;\n  }\n\n  // Gzip header has no info about windows size, we can do autodetect only\n  // for deflate. So, if window size not set, force it to max when gzip possible\n  if ((opt.windowBits > 15) && (opt.windowBits < 48)) {\n    // bit 3 (16) -> gzipped data\n    // bit 4 (32) -> autodetect gzip/deflate\n    if ((opt.windowBits & 15) === 0) {\n      opt.windowBits |= 15;\n    }\n  }\n\n  this.err    = 0;      // error code, if happens (0 = Z_OK)\n  this.msg    = '';     // error message\n  this.ended  = false;  // used to avoid multiple onEnd() calls\n  this.chunks = [];     // chunks of compressed data\n\n  this.strm   = new zstream();\n  this.strm.avail_out = 0;\n\n  let status  = inflate_1$2.inflateInit2(\n    this.strm,\n    opt.windowBits\n  );\n\n  if (status !== Z_OK) {\n    throw new Error(messages[status]);\n  }\n\n  this.header = new gzheader();\n\n  inflate_1$2.inflateGetHeader(this.strm, this.header);\n\n  // Setup dictionary\n  if (opt.dictionary) {\n    // Convert data if needed\n    if (typeof opt.dictionary === 'string') {\n      opt.dictionary = strings.string2buf(opt.dictionary);\n    } else if (toString.call(opt.dictionary) === '[object ArrayBuffer]') {\n      opt.dictionary = new Uint8Array(opt.dictionary);\n    }\n    if (opt.raw) { //In raw mode we need to set the dictionary early\n      status = inflate_1$2.inflateSetDictionary(this.strm, opt.dictionary);\n      if (status !== Z_OK) {\n        throw new Error(messages[status]);\n      }\n    }\n  }\n}\n\n/**\n * Inflate#push(data[, flush_mode]) -> Boolean\n * - data (Uint8Array|ArrayBuffer): input data\n * - flush_mode (Number|Boolean): 0..6 for corresponding Z_NO_FLUSH..Z_TREE\n *   flush modes. See constants. Skipped or `false` means Z_NO_FLUSH,\n *   `true` means Z_FINISH.\n *\n * Sends input data to inflate pipe, generating [[Inflate#onData]] calls with\n * new output chunks. Returns `true` on success. If end of stream detected,\n * [[Inflate#onEnd]] will be called.\n *\n * `flush_mode` is not needed for normal operation, because end of stream\n * detected automatically. You may try to use it for advanced things, but\n * this functionality was not tested.\n *\n * On fail call [[Inflate#onEnd]] with error code and return false.\n *\n * ##### Example\n *\n * ```javascript\n * push(chunk, false); // push one of data chunks\n * ...\n * push(chunk, true);  // push last chunk\n * ```\n **/\nInflate$1.prototype.push = function (data, flush_mode) {\n  const strm = this.strm;\n  const chunkSize = this.options.chunkSize;\n  const dictionary = this.options.dictionary;\n  let status, _flush_mode, last_avail_out;\n\n  if (this.ended) return false;\n\n  if (flush_mode === ~~flush_mode) _flush_mode = flush_mode;\n  else _flush_mode = flush_mode === true ? Z_FINISH : Z_NO_FLUSH;\n\n  // Convert data if needed\n  if (toString.call(data) === '[object ArrayBuffer]') {\n    strm.input = new Uint8Array(data);\n  } else {\n    strm.input = data;\n  }\n\n  strm.next_in = 0;\n  strm.avail_in = strm.input.length;\n\n  for (;;) {\n    if (strm.avail_out === 0) {\n      strm.output = new Uint8Array(chunkSize);\n      strm.next_out = 0;\n      strm.avail_out = chunkSize;\n    }\n\n    status = inflate_1$2.inflate(strm, _flush_mode);\n\n    if (status === Z_NEED_DICT && dictionary) {\n      status = inflate_1$2.inflateSetDictionary(strm, dictionary);\n\n      if (status === Z_OK) {\n        status = inflate_1$2.inflate(strm, _flush_mode);\n      } else if (status === Z_DATA_ERROR) {\n        // Replace code with more verbose\n        status = Z_NEED_DICT;\n      }\n    }\n\n    // Skip snyc markers if more data follows and not raw mode\n    while (strm.avail_in > 0 &&\n           status === Z_STREAM_END &&\n           strm.state.wrap > 0 &&\n           data[strm.next_in] !== 0)\n    {\n      inflate_1$2.inflateReset(strm);\n      status = inflate_1$2.inflate(strm, _flush_mode);\n    }\n\n    switch (status) {\n      case Z_STREAM_ERROR:\n      case Z_DATA_ERROR:\n      case Z_NEED_DICT:\n      case Z_MEM_ERROR:\n        this.onEnd(status);\n        this.ended = true;\n        return false;\n    }\n\n    // Remember real `avail_out` value, because we may patch out buffer content\n    // to align utf8 strings boundaries.\n    last_avail_out = strm.avail_out;\n\n    if (strm.next_out) {\n      if (strm.avail_out === 0 || status === Z_STREAM_END) {\n\n        if (this.options.to === 'string') {\n\n          let next_out_utf8 = strings.utf8border(strm.output, strm.next_out);\n\n          let tail = strm.next_out - next_out_utf8;\n          let utf8str = strings.buf2string(strm.output, next_out_utf8);\n\n          // move tail & realign counters\n          strm.next_out = tail;\n          strm.avail_out = chunkSize - tail;\n          if (tail) strm.output.set(strm.output.subarray(next_out_utf8, next_out_utf8 + tail), 0);\n\n          this.onData(utf8str);\n\n        } else {\n          this.onData(strm.output.length === strm.next_out ? strm.output : strm.output.subarray(0, strm.next_out));\n        }\n      }\n    }\n\n    // Must repeat iteration if out buffer is full\n    if (status === Z_OK && last_avail_out === 0) continue;\n\n    // Finalize if end of stream reached.\n    if (status === Z_STREAM_END) {\n      status = inflate_1$2.inflateEnd(this.strm);\n      this.onEnd(status);\n      this.ended = true;\n      return true;\n    }\n\n    if (strm.avail_in === 0) break;\n  }\n\n  return true;\n};\n\n\n/**\n * Inflate#onData(chunk) -> Void\n * - chunk (Uint8Array|String): output data. When string output requested,\n *   each chunk will be string.\n *\n * By default, stores data blocks in `chunks[]` property and glue\n * those in `onEnd`. Override this handler, if you need another behaviour.\n **/\nInflate$1.prototype.onData = function (chunk) {\n  this.chunks.push(chunk);\n};\n\n\n/**\n * Inflate#onEnd(status) -> Void\n * - status (Number): inflate status. 0 (Z_OK) on success,\n *   other if not.\n *\n * Called either after you tell inflate that the input stream is\n * complete (Z_FINISH). By default - join collected chunks,\n * free memory and fill `results` / `err` properties.\n **/\nInflate$1.prototype.onEnd = function (status) {\n  // On success - join\n  if (status === Z_OK) {\n    if (this.options.to === 'string') {\n      this.result = this.chunks.join('');\n    } else {\n      this.result = common.flattenChunks(this.chunks);\n    }\n  }\n  this.chunks = [];\n  this.err = status;\n  this.msg = this.strm.msg;\n};\n\n\n/**\n * inflate(data[, options]) -> Uint8Array|String\n * - data (Uint8Array|ArrayBuffer): input data to decompress.\n * - options (Object): zlib inflate options.\n *\n * Decompress `data` with inflate/ungzip and `options`. Autodetect\n * format via wrapper header by default. That's why we don't provide\n * separate `ungzip` method.\n *\n * Supported options are:\n *\n * - windowBits\n *\n * [http://zlib.net/manual.html#Advanced](http://zlib.net/manual.html#Advanced)\n * for more information.\n *\n * Sugar (options):\n *\n * - `raw` (Boolean) - say that we work with raw stream, if you don't wish to specify\n *   negative windowBits implicitly.\n * - `to` (String) - if equal to 'string', then result will be converted\n *   from utf8 to utf16 (javascript) string. When string output requested,\n *   chunk length can differ from `chunkSize`, depending on content.\n *\n *\n * ##### Example:\n *\n * ```javascript\n * const pako = require('pako');\n * const input = pako.deflate(new Uint8Array([1,2,3,4,5,6,7,8,9]));\n * let output;\n *\n * try {\n *   output = pako.inflate(input);\n * } catch (err) {\n *   console.log(err);\n * }\n * ```\n **/\nfunction inflate$1(input, options) {\n  const inflator = new Inflate$1(options);\n\n  inflator.push(input);\n\n  // That will never happens, if you don't cheat with options :)\n  if (inflator.err) throw inflator.msg || messages[inflator.err];\n\n  return inflator.result;\n}\n\n\n/**\n * inflateRaw(data[, options]) -> Uint8Array|String\n * - data (Uint8Array|ArrayBuffer): input data to decompress.\n * - options (Object): zlib inflate options.\n *\n * The same as [[inflate]], but creates raw data, without wrapper\n * (header and adler32 crc).\n **/\nfunction inflateRaw$1(input, options) {\n  options = options || {};\n  options.raw = true;\n  return inflate$1(input, options);\n}\n\n\n/**\n * ungzip(data[, options]) -> Uint8Array|String\n * - data (Uint8Array|ArrayBuffer): input data to decompress.\n * - options (Object): zlib inflate options.\n *\n * Just shortcut to [[inflate]], because it autodetects format\n * by header.content. Done for convenience.\n **/\n\n\nvar Inflate_1$1 = Inflate$1;\nvar inflate_2 = inflate$1;\nvar inflateRaw_1$1 = inflateRaw$1;\nvar ungzip$1 = inflate$1;\nvar constants = constants$2;\n\nvar inflate_1$1 = {\n\tInflate: Inflate_1$1,\n\tinflate: inflate_2,\n\tinflateRaw: inflateRaw_1$1,\n\tungzip: ungzip$1,\n\tconstants: constants\n};\n\nconst { Deflate, deflate, deflateRaw, gzip } = deflate_1$1;\n\nconst { Inflate, inflate, inflateRaw, ungzip } = inflate_1$1;\n\n\n\nvar Deflate_1 = Deflate;\nvar deflate_1 = deflate;\nvar deflateRaw_1 = deflateRaw;\nvar gzip_1 = gzip;\nvar Inflate_1 = Inflate;\nvar inflate_1 = inflate;\nvar inflateRaw_1 = inflateRaw;\nvar ungzip_1 = ungzip;\nvar constants_1 = constants$2;\n\nvar pako = {\n\tDeflate: Deflate_1,\n\tdeflate: deflate_1,\n\tdeflateRaw: deflateRaw_1,\n\tgzip: gzip_1,\n\tInflate: Inflate_1,\n\tinflate: inflate_1,\n\tinflateRaw: inflateRaw_1,\n\tungzip: ungzip_1,\n\tconstants: constants_1\n};\n\n\n\n\n//# sourceURL=webpack://semanticfinder/./node_modules/pako/dist/pako.esm.mjs?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/******/ 	// expose the modules object (__webpack_modules__)
/******/ 	__webpack_require__.m = __webpack_modules__;
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/compat get default export */
/******/ 	(() => {
/******/ 		// getDefaultExport function for compatibility with non-harmony modules
/******/ 		__webpack_require__.n = (module) => {
/******/ 			var getter = module && module.__esModule ?
/******/ 				() => (module['default']) :
/******/ 				() => (module);
/******/ 			__webpack_require__.d(getter, { a: getter });
/******/ 			return getter;
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/create fake namespace object */
/******/ 	(() => {
/******/ 		var getProto = Object.getPrototypeOf ? (obj) => (Object.getPrototypeOf(obj)) : (obj) => (obj.__proto__);
/******/ 		var leafPrototypes;
/******/ 		// create a fake namespace object
/******/ 		// mode & 1: value is a module id, require it
/******/ 		// mode & 2: merge all properties of value into the ns
/******/ 		// mode & 4: return value when already ns object
/******/ 		// mode & 16: return value when it's Promise-like
/******/ 		// mode & 8|1: behave like require
/******/ 		__webpack_require__.t = function(value, mode) {
/******/ 			if(mode & 1) value = this(value);
/******/ 			if(mode & 8) return value;
/******/ 			if(typeof value === 'object' && value) {
/******/ 				if((mode & 4) && value.__esModule) return value;
/******/ 				if((mode & 16) && typeof value.then === 'function') return value;
/******/ 			}
/******/ 			var ns = Object.create(null);
/******/ 			__webpack_require__.r(ns);
/******/ 			var def = {};
/******/ 			leafPrototypes = leafPrototypes || [null, getProto({}), getProto([]), getProto(getProto)];
/******/ 			for(var current = mode & 2 && value; typeof current == 'object' && !~leafPrototypes.indexOf(current); current = getProto(current)) {
/******/ 				Object.getOwnPropertyNames(current).forEach((key) => (def[key] = () => (value[key])));
/******/ 			}
/******/ 			def['default'] = () => (value);
/******/ 			__webpack_require__.d(ns, def);
/******/ 			return ns;
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/get javascript chunk filename */
/******/ 	(() => {
/******/ 		// This function allow to reference async chunks
/******/ 		__webpack_require__.u = (chunkId) => {
/******/ 			// return url for filenames based on template
/******/ 			return "" + chunkId + ".bundle.js";
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/global */
/******/ 	(() => {
/******/ 		__webpack_require__.g = (function() {
/******/ 			if (typeof globalThis === 'object') return globalThis;
/******/ 			try {
/******/ 				return this || new Function('return this')();
/******/ 			} catch (e) {
/******/ 				if (typeof window === 'object') return window;
/******/ 			}
/******/ 		})();
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/publicPath */
/******/ 	(() => {
/******/ 		var scriptUrl;
/******/ 		if (__webpack_require__.g.importScripts) scriptUrl = __webpack_require__.g.location + "";
/******/ 		var document = __webpack_require__.g.document;
/******/ 		if (!scriptUrl && document) {
/******/ 			if (document.currentScript)
/******/ 				scriptUrl = document.currentScript.src;
/******/ 			if (!scriptUrl) {
/******/ 				var scripts = document.getElementsByTagName("script");
/******/ 				if(scripts.length) {
/******/ 					var i = scripts.length - 1;
/******/ 					while (i > -1 && (!scriptUrl || !/^http(s?):/.test(scriptUrl))) scriptUrl = scripts[i--].src;
/******/ 				}
/******/ 			}
/******/ 		}
/******/ 		// When supporting browsers where an automatic publicPath is not supported you must specify an output.publicPath manually via configuration
/******/ 		// or pass an empty string ("") and set the __webpack_public_path__ variable from your code to use your own logic.
/******/ 		if (!scriptUrl) throw new Error("Automatic publicPath is not supported in this browser");
/******/ 		scriptUrl = scriptUrl.replace(/#.*$/, "").replace(/\?.*$/, "").replace(/\/[^\/]+$/, "/");
/******/ 		__webpack_require__.p = scriptUrl;
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/jsonp chunk loading */
/******/ 	(() => {
/******/ 		__webpack_require__.b = document.baseURI || self.location.href;
/******/ 		
/******/ 		// object to store loaded and loading chunks
/******/ 		// undefined = chunk not loaded, null = chunk preloaded/prefetched
/******/ 		// [resolve, reject, Promise] = chunk loading, 0 = chunk loaded
/******/ 		var installedChunks = {
/******/ 			"main": 0
/******/ 		};
/******/ 		
/******/ 		// no chunk on demand loading
/******/ 		
/******/ 		// no prefetching
/******/ 		
/******/ 		// no preloaded
/******/ 		
/******/ 		// no HMR
/******/ 		
/******/ 		// no HMR manifest
/******/ 		
/******/ 		// no on chunks loaded
/******/ 		
/******/ 		// no jsonp function
/******/ 	})();
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module can't be inlined because the eval devtool is used.
/******/ 	var __webpack_exports__ = __webpack_require__("./src/js/index.js");
/******/ 	
/******/ })()
;